@inproceedings{tamascelli_academic_2025,
  title = {Academic {Advising},
  author = {Tamascelli, Michael and Bunch, Olivia and Fowler, Blake and Taeb, Maryam and Cohen, Achraf},
  year = {2025},
  doi = {10.1145/3696673.3723065},
  url = {https://doi.org/10.1145/3696673.3723065},
  pages = {195 -- 202},
  note = {Type: Conference paper},
  keywords = {academic advising, AI agent, chatbot, higher education, large language models, retrieval-augmented generation, source: ACM},
  annote = {Cited by: 0; All Open Access; Gold Open Access},
}

@inproceedings{quinn_accelerating_2025,
  title = {Accelerating {Retrieval},
  author = {Quinn, Derrick and Nouri, Mohammad and Patel, Neel and Salihu, John and Salemi, Alireza and Lee, Sukhan and Zamani, Hamed and Alian, Mohammad},
  year = {2025},
  doi = {10.1145/3669940.3707264},
  url = {https://doi.org/10.1145/3669940.3707264},
  booktitle = {International {Conference},
  volume = {1},
  pages = {15 -- 32},
  note = {Type: Conference paper},
  keywords = {database acceleration, dense retrieval, retrieval-augmented generation (rag), source: ACM},
  annote = {Cited by: 6},
}

@inproceedings{zhang_survey_2025,
  title = {A {Survey},
  author = {Zhang, Xueqiang and Dong, Xiaofei and Wang, Yiru and Zhang, Dan and Cao, Feng},
  year = {2025},
  doi = {10.1145/3707292.3707383},
  url = {https://doi.org/10.1145/3707292.3707383},
  pages = {318 -- 323},
  note = {Type: Conference paper},
  keywords = {development analysis, key technology, Large models, theory foundation, source: ACM},
  annote = {Cited by: 0},
}

@inproceedings{sun_adaptive_2024,
  title = {Adaptive {In},
  author = {Sun, Zhu and Feng, Kaidong and Yang, Jie and Qu, Xinghua and Fang, Hui and Ong, Yew Soon and Liu, Wenyuan},
  year = {2024},
  doi = {10.1145/3626772.3657808},
  url = {https://doi.org/10.1145/3626772.3657808},
  pages = {966 -- 976},
  note = {Type: Conference paper},
  keywords = {bundle generation, in-context learning, large language models, recommendation, user intent inference, source: ACM},
  annote = {Cited by: 3},
}

@article{shi_amsnet-kg_2025,
  title = {{AMSnet},
  author = {Shi, Yichen and Tao, Zhuofu and Gao, YuHao and Zhou, Tianjia and Chang, Cheng and Wang, Yaxin and Chen, Bingyu and Zhang, Genhao and Liu, Alvin and Yu, Zhiping and Lin, Ting-Jung and He, Lei},
  year = {2025},
  doi = {10.1145/3736166},
  url = {https://doi.org/10.1145/3736166},
  journal = {ACM Trans. Des. Autom. Electron. Syst.},
  volume = {30},
  number = {6},
  note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
  keywords = {AMSnet, EDA, knowledge graph, LLM, RAG, topology design, source: ACM},
  abstract = {High-performance analog and mixed-signal (AMS) circuits are mainly full-custom designed, which is time-consuming and labor-intensive. A significant portion of the effort is experience-driven, which makes the automation of AMS circuit design a formidable challenge. Large language models (LLMs) have emerged as powerful tools for electronic design automation (EDA) applications, fostering advancements in the automatic design process for large-scale AMS circuits. However, the absence of high-quality datasets has led to issues such as model hallucination, which undermines the robustness of automatically generated circuit designs. To address this issue, this article introduces AMSnet-KG, a dataset encompassing various AMS circuit schematics and netlists. We construct a knowledge graph with annotations on detailed functional and performance characteristics. Facilitated by AMSnet-KG, we propose an automated AMS circuit generation framework that utilizes the comprehensive knowledge embedded in LLMs. The flow first formulate a design strategy (e.g., circuit architecture using a number of circuit components) based on required specifications. Next, matched subcircuits are retrieved and assembled into a complete topology, and transistor sizing is obtained through Bayesian optimization. Simulation results of the netlist are automatically fed back to the LLM for further topology refinement, ensuring the circuit design specifications are met. We perform case studies of operational amplifier and comparator design to verify the automatic design flow from specifications to netlists with minimal human effort. The dataset used in this article is available at .},
  annote = {Query date: 2025-10-25 20:50:36},
  issn = {1084-4309},
  month = {oct},
}

@article{zhang_survey_2025-1,
  title = {A {Survey},
  author = {Zhang, Zeyu and Dai, Quanyu and Bo, Xiaohe and Ma, Chen and Li, Rui and Chen, Xu and Zhu, Jieming and Dong, Zhenhua and Wen, Ji-Rong},
  year = {2025},
  doi = {10.1145/3748302},
  url = {https://doi.org/10.1145/3748302},
  journal = {ACM Trans. Inf. Syst.},
  volume = {43},
  number = {6},
  note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
  keywords = {Agent, Information Processing, Information System, Large Language Model, Memory Mechanism, source: ACM},
  abstract = {Large language model (LLM)-based agents have recently attracted much attention from the research and industry communities. Compared with original LLMs, LLM-based agents are featured in their self-evolving capability, which is the basis for solving real-world problems that need long-term and complex agent-environment interactions. The key component to support agent-environment interactions is the memory of the agents. While previous studies have proposed many promising memory mechanisms, they are scattered in different papers, and there lacks a systematical review to summarize and compare these works from a holistic perspective, failing to abstract common and effective designing patterns for inspiring future studies. To bridge this gap, in this article, we propose a comprehensive survey on the memory mechanism of LLM-based agents. In specific, we first discuss “what is” and “why do we need” the memory in LLM-based agents. Then, we systematically review previous studies on how to design and evaluate the memory module. In addition, we also present many agent applications, where the memory module plays an important role. At last, we analyze the limitations of existing work and show important future directions. To keep up with the latest advances in this field, we create a repository at .},
  issn = {1046-8188},
  month = {sep},
}

@article{deng_ai_2025,
  title = {{AI},
  author = {Deng, Zehang and Guo, Yongjian and Han, Changzhou and Ma, Wanlun and Xiong, Junwu and Wen, Sheng and Xiang, Yang},
  year = {2025},
  doi = {10.1145/3716628},
  url = {https://doi.org/10.1145/3716628},
  journal = {ACM Comput. Surv.},
  volume = {57},
  number = {7},
  note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
  keywords = {AI agent, security, trustworthiness, source: ACM},
  abstract = {An Artificial Intelligence (AI) agent is a software entity that autonomously performs tasks or makes decisions based on pre-defined objectives and data inputs. AI agents, capable of perceiving user inputs, reasoning and planning tasks, and executing actions, have seen remarkable advancements in algorithm development and task performance. However, the security challenges they pose remain under-explored and unresolved. This survey delves into the emerging security threats faced by AI agents, categorizing them into four critical knowledge gaps: unpredictability of multi-step user inputs, complexity in internal executions, variability of operational environments, and interactions with untrusted external entities. By systematically reviewing these threats, this article highlights both the progress made and the existing limitations in safeguarding AI agents. The insights provided aim to inspire further research into addressing the security threats associated with AI agents, thereby fostering the development of more robust and secure AI agent applications.},
  issn = {0360-0300},
  month = {feb},
}