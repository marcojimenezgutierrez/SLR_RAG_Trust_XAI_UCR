{"id":"01_make_dirs","shell":"powershell","cmd":"mkdir -Force logs, cache, checkpoints, Deduplicacion | Out-Null"}
{"id":"02_venv","shell":"powershell","cmd":"py -3 -m venv .venv; .\\.venv\\Scripts\\python -m pip install -U pip"}
{"id":"03_requirements","shell":"powershell","cmd":"@'\nbibtexparser>=1.4\nhttpx>=0.27\npython-dotenv>=1.0\ntenacity>=8.5\nbeautifulsoup4>=4.12\nlxml>=5.2\ntldextract>=5.1\nlangdetect>=1.0\nrapidfuzz>=3.9\npypdf>=5.0\npdfminer.six>=20240706\norjson>=3.10\nopenai>=1.54\ncharset-normalizer>=3.3\n'@ | Set-Content -Encoding UTF8 requirements.txt; .\\.venv\\Scripts\\pip install -r requirements.txt"}
{"id":"04_env","shell":"powershell","cmd":"@'\nOPENROUTER_API_KEY=\nOPENROUTER_SITE_URL=https://tu-sitio-o-repo\nOPENROUTER_APP_NAME=SLR Abstract Enricher\nCROSSREF_MAILTO=tu_email@dominio\nSCOPUS_API_KEY=\n'@ | Set-Content -Encoding UTF8 .env"}
{"id":"05_script","shell":"powershell","cmd":"@'\nimport os, re, json, time, argparse, csv\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nimport bibtexparser\nfrom bibtexparser.bwriter import BibTexWriter\nfrom openai import OpenAI\nfrom tenacity import retry, stop_after_attempt, wait_exponential\nfrom langdetect import detect\n\n# Load env\nload_dotenv()\nOPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\nHTTP_REFERER = os.getenv('OPENROUTER_SITE_URL','')\nX_TITLE = os.getenv('OPENROUTER_APP_NAME','SLR Abstract Enricher')\n\n# Policies\nLANG_POLICY = 'preserve'\nTARGET_WORDS = (120, 200)\nMIN_CHARS = 400\nKEYWORDS = [\n    'rag', 'retrieval-augmented', 'llm', 'large language model',\n    'hallucination', 'faithfulness', 'factuality', 'trust', 'confidence', 'credibility',\n    'citation', 'grounding', 'provenance', 'explainability', 'xai',\n    'user perception', 'perceived reliability', 'overtrust', 'trustworthiness',\n    'hallucinations', 'accuracy', 'grounded', 'correctness', 'consistency',\n    'explainable ai', 'interpretable', 'interpretability',\n    'transparency', 'attribution', 'saliency', 'attention',\n    'citations', 'reference', 'source attribution',\n    'evidence', 'evidence highlighting', 'highlighting',\n    'calibration', 'brier', 'ece',\n    'evaluation', 'evaluation metric', 'evaluation metrics', 'metric', 'metrics',\n    'methodology', 'methodologies', 'method', 'methods', 'protocol',\n    'instrument', 'questionnaire', 'scale', 'survey', 'user study',\n    'benchmark', 'dataset', 'guideline', 'framework', 'pipeline'\n]\n\n# OpenRouter client\nclient = OpenAI(base_url='https://openrouter.ai/api/v1', api_key=OPENROUTER_API_KEY, default_headers={'HTTP-Referer': HTTP_REFERER, 'X-Title': X_TITLE})\n\n@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=8))\ndef chat_complete(model, system, user):\n    return client.chat.completions.create(\n        model=model,\n        messages=[{'role': 'system', 'content': system}, {'role': 'user', 'content': user}],\n        temperature=0.2,\n    )\n\ndef pick_language(text):\n    try:\n        return detect(text or '')\n    except Exception:\n        return 'en'\n\ndef needs_enrichment(abstract):\n    if not abstract:\n        return True\n    t = abstract.strip()\n    if len(t) < MIN_CHARS:\n        return True\n    lower = t.lower()\n    found = sum(1 for k in KEYWORDS if k in lower)\n    return found < 2\n\ndef build_prompt(title, abstract, lang):\n    goal = f\"Expand and refine the abstract to be concise, specific, and faithful. Target {TARGET_WORDS[0]}-{TARGET_WORDS[1]} words.\"\n    policy = 'Preserve the original language.' if LANG_POLICY == 'preserve' else f'Write in {lang}.'\n    kws = ', '.join(KEYWORDS[:20]) + ', ...'\n    hints = 'Include concrete contributions, methods, datasets, and evaluation metrics when available. Avoid speculation.'\n    user = f\"Title: {title or ''}\\nOriginal abstract:\\n{abstract or ''}\\n\\nKeywords of interest: {kws}\"\n    system = f\"You are an expert research editor. {policy} {goal} {hints}\"\n    return system, user\n\ndef call_with_fallbacks(model, fallbacks, system, user):\n    models = [model] + [m for m in fallbacks if m]\n    last_err = None\n    for m in models:\n        try:\n            resp = chat_complete(m, system, user)\n            content = resp.choices[0].message.content.strip()\n            if content:\n                return content, m\n        except Exception as e:\n            last_err = e\n            time.sleep(1.5)\n    raise last_err or RuntimeError('All models failed')\n\ndef load_state(state_path):\n    done = set()\n    p = Path(state_path)\n    if p.exists():\n        with p.open('r', encoding='utf-8') as f:\n            for line in f:\n                try:\n                    obj = json.loads(line)\n                    if obj.get('status') == 'enriched':\n                        done.add(obj.get('key'))\n                except Exception:\n                    pass\n    return done\n\ndef append_state(state_path, obj):\n    p = Path(state_path)\n    p.parent.mkdir(parents=True, exist_ok=True)\n    with p.open('a', encoding='utf-8') as f:\n        f.write(json.dumps(obj, ensure_ascii=False) + '\\n')\n\ndef ensure_parent(path):\n    Path(path).parent.mkdir(parents=True, exist_ok=True)\n\ndef enrich_bib(in_path, out_path, audit_path, state_path, model, fallbacks, dry_run=False, resume=False, force_retry=False):\n    ensure_parent(out_path)\n    ensure_parent(audit_path)\n    ensure_parent(state_path)\n\n    done_keys = load_state(state_path) if resume and not force_retry else set()\n    with open(in_path, 'r', encoding='utf-8') as f:\n        db = bibtexparser.load(f)\n\n    writer = BibTexWriter()\n    writer.order_entries_by = ('ID',)\n\n    audit_rows = []\n    changed = 0\n    total = 0\n    for entry in db.entries:\n        total += 1\n        key = entry.get('ID') or entry.get('id') or entry.get('citekey') or f'entry_{total}'\n        title = entry.get('title', '')\n        abstract = entry.get('abstract', '') or entry.get('annotation', '') or ''\n\n        if resume and key in done_keys:\n            append_state(state_path, {'key': key, 'status': 'skipped', 'reason': 'resume', 'ts': time.time()})\n            continue\n\n        if not needs_enrichment(abstract):\n            append_state(state_path, {'key': key, 'status': 'skipped', 'reason': 'sufficient', 'ts': time.time()})\n            continue\n\n        lang = pick_language((abstract or title) or '')\n        system, user = build_prompt(title, abstract, lang)\n\n        if dry_run or not OPENROUTER_API_KEY:\n            enriched = abstract or ''\n            used_model = None\n            status = 'dry-run'\n        else:\n            try:\n                enriched, used_model = call_with_fallbacks(model, fallbacks, system, user)\n                status = 'enriched'\n            except Exception as e:\n                append_state(state_path, {'key': key, 'status': 'error', 'error': str(e), 'ts': time.time()})\n                continue\n\n        if enriched and enriched != abstract:\n            entry['abstract'] = enriched\n            changed += 1\n\n        audit_rows.append([key, status, len(abstract or ''), len(entry.get('abstract', '') or ''), lang, used_model or ''])\n        append_state(state_path, {'key': key, 'status': status, 'model': used_model, 'ts': time.time()})\n\n    with open(out_path, 'w', encoding='utf-8') as f:\n        bibtexparser.dump(db, f)\n\n    import csv as _csv\n    with open(audit_path, 'w', encoding='utf-8', newline='') as f:\n        w = _csv.writer(f)\n        w.writerow(['key', 'status', 'old_chars', 'new_chars', 'lang', 'model'])\n        w.writerows(audit_rows)\n\n    return {'total': total, 'changed': changed}\n\nif __name__ == '__main__':\n    import argparse as _argparse\n    p = _argparse.ArgumentParser()\n    p.add_argument('--input', required=True)\n    p.add_argument('--out', required=True)\n    p.add_argument('--audit', default='logs/enrich_abstracts_audit.csv')\n    p.add_argument('--state', default='logs/enrich_state.jsonl')\n    p.add_argument('--dry-run', action='store_true')\n    p.add_argument('--resume', action='store_true')\n    p.add_argument('--force-retry', action='store_true')\n    p.add_argument('--model', default='xai/grok-2-mini')\n    p.add_argument('--fallbacks', default='openai/gpt-4o-mini,anthropic/claude-3.5-sonnet')\n    a = p.parse_args()\n    fallbacks = [x.strip() for x in a.fallbacks.split(',') if x.strip()]\n    enrich_bib(a.input, a.out, a.audit, a.state, a.model, fallbacks, dry_run=a.dry_run, resume=a.resume, force_retry=a.force_retry)\n'@ | Set-Content -Encoding UTF8 enrich_abstracts.py"}
{"id":"06_dryrun","shell":"powershell","cmd":".\\.venv\\Scripts\\python enrich_abstracts.py --input 'Deduplicacion/SLR_RAG_master_clean.dedup.bib' --out 'Deduplicacion/SLR_RAG_master_enriched.bib' --audit 'logs/enrich_audit.csv' --state 'logs/enrich_state.jsonl' --model 'xai/grok-2-mini' --fallbacks 'openai/gpt-4o-mini,anthropic/claude-3.5-sonnet' --dry-run --resume"}
{"id":"07_realrun","shell":"powershell","cmd":".\\.venv\\Scripts\\python enrich_abstracts.py --input 'Deduplicacion/SLR_RAG_master_clean.dedup.bib' --out 'Deduplicacion/SLR_RAG_master_enriched.bib' --audit 'logs/enrich_audit.csv' --state 'logs/enrich_state.jsonl' --model 'xai/grok-2-mini' --fallbacks 'openai/gpt-4o-mini,anthropic/claude-3.5-sonnet' --resume"}
