{"id":"01_make_dirs","shell":"powershell","cmd":"mkdir -Force logs, cache, checkpoints, DeduplicaciÃ³n | Out-Null"}
{"id":"02_venv","shell":"powershell","cmd":"py -3.12 -m venv .venv; .\.venv\Scripts\python -m pip install -U pip"}
{"id":"03_requirements","shell":"powershell","cmd":"@'\nbibtexparser>=1.4\nhttpx>=0.27\npython-dotenv>=1.0\ntenacity>=8.5\nbeautifulsoup4>=4.12\nlxml>=5.2\ntldextract>=5.1\nlangdetect>=1.0\nrapidfuzz>=3.9\npypdf>=5.0\npdfminer.six>=20240706\norjson>=3.10\nopenai>=1.54\ncharset-normalizer>=3.3\n'@ | Set-Content -Encoding UTF8 requirements.txt; .\.venv\Scripts\pip install -r requirements.txt"}
{"id":"04_env","shell":"powershell","cmd":"@'\nOPENROUTER_API_KEY=\nOPENROUTER_SITE_URL=[https://tu-sitio-o-repo\nOPENROUTER_APP_NAME=SLR](https://tu-sitio-o-repo\nOPENROUTER_APP_NAME=SLR) Abstract Enricher\nCROSSREF_MAILTO=tu_email@dominio\nSCOPUS_API_KEY=\n'@ | Set-Content -Encoding UTF8 .env"}
{"id":"05_script","shell":"powershell","cmd":"@'\nimport os, re, json, time, datetime, threading\nfrom pathlib import Path\nfrom urllib.parse import urlparse\n\nimport httpx\nfrom tenacity import retry, stop_after_attempt, wait_exponential\nfrom dotenv import load_dotenv\nimport bibtexparser\nfrom bibtexparser.bwriter import BibTexWriter\nfrom openai import OpenAI\nfrom langdetect import detect\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\n# Load env\nload_dotenv()\nOPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\nHTTP_REFERER = os.getenv('OPENROUTER_SITE_URL','')\nX_TITLE = os.getenv('OPENROUTER_APP_NAME','')\nCROSSREF_MAILTO = os.getenv('CROSSREF_MAILTO','')\nSCOPUS_API_KEY = os.getenv('SCOPUS_API_KEY','')\n\n# Policies\nLANG_POLICY = 'preserve'\nOVERWRITE_IF_BETTER = True\nTARGET_WORDS = (120, 200)\nMIN_CHARS = 400\nKEYWORDS = [\n    'rag', 'retrieval-augmented', 'llm', 'large language model',\n    'hallucination', 'faithfulness', 'factuality', 'trust', 'confidence', 'credibility',\n    'citation', 'grounding', 'provenance', 'explainability', 'xai',\n    'user perception', 'perceived reliability', 'overtrust', 'trustworthiness',\n    'hallucinations', 'accuracy', 'grounded', 'correctness', 'consistency',\n    'explainable ai', 'interpretable', 'interpretability',\n    'transparency', 'attribution', 'saliency', 'attention',\n    'citations', 'reference', 'source attribution',\n    'evidence', 'evidence highlighting', 'highlighting',\n    'calibration', 'brier', 'ece',\n    'evaluation', 'evaluation metric', 'evaluation metrics', 'metric', 'metrics',\n    'methodology', 'methodologies', 'method', 'methods', 'protocol',\n    'instrument', 'questionnaire', 'scale', 'survey', 'user study',\n    'benchmark', 'dataset', 'guideline', 'framework', 'pipeline'\n]\n\nMAX_WORKERS = 4\nPAUSE_SEC = 2.0\nENABLE_SCRAPING = False\nENABLE_PDF = False\n\nHEADERS = {'User-Agent': f'abstract-enricher/1.0 (+mailto:{CROSSREF_MAILTO})'}\nif SCOPUS_API_KEY:\n    ELS_HEADERS = {'X-ELS-APIKey': SCOPUS_API_KEY, 'Accept': 'application/json', **HEADERS}\nelse:\n    ELS_HEADERS = HEADERS\n\nclient = OpenAI(base_url='[https://openrouter.ai/api/v1](https://openrouter.ai/api/v1)', api_key=OPENROUTER_API_KEY)\n\n_last_call = {}\n_lock_last = threading.Lock()\n\ndef _throttle(url: str):\n    host = urlparse(url).netloc or 'default'\n    with _lock_last:\n        last = _last_call.get(host, 0.0)\n        now = time.time()\n        wait = PAUSE_SEC - (now - last)\n        if wait > 0:\n            time.sleep(wait)\n        _last_call[host] = time.time()\n\n@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=1, max=8))\n\ndef get_json(url: str, params=None, headers=None):\n    _throttle(url)\n    with httpx.Client(timeout=30, headers=headers or HEADERS, follow_redirects=True) as s:\n        r = s.get(url, params=params)\n        r.raise_for_status()\n        return r.json()\n\n# API functions\n\ndef crossref_by_doi(doi: str):\n    return get_json(f'[https://api.crossref.org/works/{doi}')\n\ndef](https://api.crossref.org/works/{doi}'%29\n\ndef) openalex_by_doi(doi: str):\n    return get_json(f'[https://api.openalex.org/works/https://doi.org/{doi}')\n\ndef](https://api.openalex.org/works/https://doi.org/{doi}'%29\n\ndef) scopus_by_doi(doi: str):\n    if not SCOPUS_API_KEY:\n        return None\n    try:\n        return get_json(f'[https://api.elsevier.com/content/abstract/doi/{doi}](https://api.elsevier.com/content/abstract/doi/{doi})', headers=ELS_HEADERS)\n    except Exception:\n        pass\n    try:\n        return get_json('[https://api.elsevier.com/content/search/scopus](https://api.elsevier.com/content/search/scopus)', params={'query': f'DOI({doi})'}, headers=ELS_HEADERS)\n    except Exception:\n        return None\n\ndef strip_jats(s: str) -> str:\n    return re.sub('<[^>]+>', ' ', s or '').replace('\n',' ').strip()\n\ndef reconstruct_openalex(inv_idx: dict) -> str:\n    if not inv_idx:\n        return ''\n    maxpos = max(p for poss in inv_idx.values() for p in poss)\n    arr = ['']*(maxpos+1)\n    for token, poss in inv_idx.items():\n        for p in poss:\n            arr[p] = token\n    return ' '.join(t for t in arr if t)\n\ndef parse_scopus_json(j: dict) -> str:\n    if not j:\n        return ''\n    try:\n        core = j.get('abstracts-retrieval-response',{}).get('coredata',{})\n        desc = core.get('dc:description')\n        if desc:\n            return strip_jats(desc)\n    except Exception:\n        pass\n    try:\n        absnode = j.get('abstracts-retrieval-response',{}).get('item',{}).get('bibrecord',{}).get('head',{}).get('abstracts',{}).get('abstract')\n        if isinstance(absnode, dict):\n            paras = absnode.get('ce:para')\n            if isinstance(paras, list):\n                return ' '.join(strip_jats(p) for p in paras)\n            if isinstance(paras, str):\n                return strip_jats(paras)\n    except Exception:\n        pass\n    try:\n        entries = j.get('search-results',{}).get('entry',[])\n        for e in entries:\n            d = e.get('dc:description')\n            if d:\n                return strip_jats(d)\n    except Exception:\n        pass\n    return ''\n\ndef extract_from_apis(doi: str) -> tuple[str, str]:\n    try:\n        cj = crossref_by_doi(doi)\n        abs_j = cj.get('message',{}).get('abstract')\n        if abs_j:\n            return strip_jats(abs_j), 'crossref'\n    except Exception:\n        pass\n    try:\n        oj = openalex_by_doi(doi)\n        abs_plain = oj.get('abstract')\n        if abs_plain:\n            return abs_plain.strip(), 'openalex'\n        inv = oj.get('abstract_inverted_index')\n        if inv:\n            return reconstruct_openalex(inv), 'openalex_inverted'\n    except Exception:\n        pass\n    try:\n        sj = scopus_by_doi(doi)\n        sabs = parse_scopus_json(sj)\n        if sabs:\n            return sabs, 'scopus'\n    except Exception:\n        pass\n    return '', ''\n\ndef now_iso():\n    return datetime.datetime.utcnow().replace(microsecond=0).isoformat() + 'Z'\n\ndef llm_clean_preserve(text: str, model_primary: str, fallbacks: list[str]):\n    lang = ''\n    try:\n        if len(text) > 20:\n            lang = detect(text)\n    except Exception:\n        lang = ''\n    target = lang or 'EN'\n    sys = f'Clean and standardize the abstract. Keep the original language ({target}). Return ONLY the abstract as plain text, about {TARGET_WORDS[0]}-{TARGET_WORDS[1]} words, no headers, no HTML.'\n    messages = [\n        {'role':'system','content': sys},\n        {'role':'user','content': text[:12000]}\n    ]\n    extra = {}\n    if HTTP_REFERER:\n        extra['HTTP-Referer'] = HTTP_REFERER\n    if X_TITLE:\n        extra['X-Title'] = X_TITLE\n    kwargs = {'model': model_primary, 'messages': messages, 'temperature': 0.1}\n    if extra:\n        kwargs['extra_headers'] = extra\n    if fallbacks:\n        kwargs['models'] = [model_primary] + [m for m in fallbacks]\n    resp = client.chat.completions.create(**kwargs)\n    return resp.choices[0].message.content.strip(), target\n\ndef is_valid_abs(text: str) -> bool:\n    if not text:\n        return False\n    t = text.strip()\n    if len(t) < MIN_CHARS:\n        return False\n    if re.search(r'graphical abstract|no abstract available', t, re.I):\n        return False\n    hits = sum(1 for k in KEYWORDS if k.lower() in t.lower())\n    return hits >= 1\n\ndef score_abs(text: str) -> tuple:\n    t = text.strip() if text else ''\n    hits = sum(1 for k in KEYWORDS if k.lower() in t.lower())\n    return (int(len(t) >= MIN_CHARS), hits, len(t))\n\n# State functions\n\ndef load_state(state_path: str) -> dict:\n    done = {}\n    p = Path(state_path)\n    if not p.exists():\n        return done\n    with p.open('r', encoding='utf-8') as f:\n        for line in f:\n            try:\n                rec = json.loads(line)\n                done[rec.get('bibkey')] = rec\n            except Exception:\n                continue\n    return done\n\n_state_lock = threading.Lock()\n\ndef append_state(state_path: str, record: dict):\n    Path(state_path).parent.mkdir(parents=True, exist_ok=True)\n    with _state_lock:\n        with open(state_path, 'a', encoding='utf-8') as fo:\n            fo.write(json.dumps(record, ensure_ascii=False) + '\n')\n\ndef process_entry(entry, opts):\n    key = entry.get('ID') or entry.get('id') or entry.get('key')\n    doi = (entry.get('doi') or '').lower().replace('[https://doi.org/','')\n](https://doi.org/',''%29\n)    cur = (entry.get('abstract') or '').strip()\n\n    st = opts['state'].get(key)\n    if opts['resume'] and st and st.get('status') in {'ok','skip_existing'} and not opts['force_retry']:\n        return key, None, {'status':'resume_skip','source':'','lang_b':'','lang_a':'','len':len(cur)}\n\n    lang_before = ''\n    if cur:\n        try:\n            lang_before = detect(cur) if len(cur) > 20 else ''\n        except Exception:\n            lang_before = ''\n\n    best_text = cur\n    best_source = 'existing' if cur else ''\n\n    if doi:\n        a, s = extract_from_apis(doi)\n        if a:\n            if not best_text or score_abs(a) > score_abs(best_text):\n                best_text, best_source = a, s\n\n    # Scraping or PDF not enabled\n\n    if best_text and OPENROUTER_API_KEY:\n        cleaned, target_lang = llm_clean_preserve(best_text, opts['model'], opts['fallbacks'])\n        if cleaned:\n            best_text = cleaned\n            best_source = (best_source + '+llm') if best_source else 'llm'\n\n    final_text = cur\n    final_source = 'existing' if cur else ''\n    final_lang = ''\n    if not cur:\n        if best_text and is_valid_abs(best_text):\n            final_text = best_text\n            final_source = best_source\n    else:\n        if best_text and is_valid_abs(best_text) and score_abs(best_text) > score_abs(cur):\n            final_text = best_text\n            final_source = best_source\n\n    status = 'skip_existing'\n    if not cur and final_text:\n        status = 'ok'\n    if cur and final_text != cur:\n        status = 'ok'\n    if not cur and not final_text:\n        status = 'none'\n\n    if final_text and (not cur or final_text != cur):\n        entry['abstract'] = final_text\n        try:\n            final_lang = detect(final_text) if len(final_text) > 20 else ''\n        except Exception:\n            final_lang = ''\n        entry['abstract_lang'] = final_lang\n        entry['abstract_source'] = final_source\n    entry['x_enrich_status'] = status\n    entry['x_enrich_source'] = final_source\n    entry['x_enrich_ts'] = now_iso()\n\n    stat = {\n        'status': status,\n        'source': final_source,\n        'lang_b': lang_before,\n        'lang_a': final_lang,\n        'len': len(final_text) if final_text else 0\n    }\n    return key, entry if (not cur or final_text != cur) else None, stat\n\ndef enrich_bib(in_path: str, out_path: str, audit_csv: str, state_path: str,\n               model_primary='xai/grok-2-mini', fallbacks=None,\n               dry_run=True, resume=True, force_retry=False):\n    with open(in_path, 'r', encoding='utf-8') as f:\n        db = bibtexparser.load(f)\n\n    state = load_state(state_path) if resume else {}\n    logs = []\n    opts = {\n        'state': state,\n        'resume': resume,\n        'force_retry': force_retry,\n        'model': model_primary,\n        'fallbacks': fallbacks or ['openai/gpt-4o-mini', 'anthropic/claude-3.5-sonnet']\n    }\n    updated_entries = {}\n    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n        futures = {ex.submit(process_entry, e, opts): e for e in db.entries}\n        for fu in as_completed(futures):\n            key, updated, stat = fu.result()\n            entry = futures[fu]\n            logs.append((key, (entry.get('doi') or '').lower().replace('[https://doi.org/](https://doi.org/)',''), stat.get('source','') or stat.get('status',''), stat.get('lang_b',''), stat.get('lang_a',''), stat.get('len',0)))\n            append_state(state_path, {\n                'bibkey': key,\n                'doi': (entry.get('doi') or '').lower().replace('[https://doi.org/',''),\n](https://doi.org/',''%29,\n)                'status': stat['status'],\n                'source': stat.get('source',''),\n                'lang_before': stat.get('lang_b',''),\n                'lang_after': stat.get('lang_a',''),\n                'ts': now_iso()\n            })\n            if updated is not None:\n                updated_entries[key] = updated\n\n    if not dry_run:\n        for i, e in enumerate(db.entries):\n            k = e.get('ID') or e.get('id') or e.get('key')\n            if k in updated_entries:\n                db.entries[i] = updated_entries[k]\n        writer = BibTexWriter()\n        with open(out_path, 'w', encoding='utf-8') as fo:\n            fo.write(writer.write(db))\n\n    Path(audit_csv).parent.mkdir(parents=True, exist_ok=True)\n    with open(audit_csv, 'w', encoding='utf-8') as fo:\n        fo.write('bibkey,doi,source_used,lang_before,lang_after,len_chars\n')\n        for r in logs:\n            fo.write(','.join(str(x or '') for x in r) + '\n')\n\nif **name** == '**main**':\n    import argparse\n    p = argparse.ArgumentParser()\n    p.add_argument('--input', required=True)\n    p.add_argument('--out', required=True)\n    p.add_argument('--audit', default='logs/enrich_abstracts_audit.csv')\n    p.add_argument('--state', default='logs/enrich_state.jsonl')\n    p.add_argument('--dry-run', action='store_true')\n    p.add_argument('--resume', action='store_true')\n    p.add_argument('--force-retry', action='store_true')\n    p.add_argument('--model', default='xai/grok-2-mini')\n    p.add_argument('--fallbacks', default='openai/gpt-4o-mini,anthropic/claude-3.5-sonnet')\n    a = p.parse_args()\n    fallbacks = [x.strip() for x in a.fallbacks.split(',') if x.strip()]\n    enrich_bib(a.input, a.out, a.audit, a.state,\n               a.model, fallbacks,\n               dry_run=a.dry_run, resume=a.resume, force_retry=a.force_retry)\n'@ | Set-Content -Encoding UTF8 enrich_abstracts.py"}
{"id":"06_dryrun","shell":"powershell","cmd":".\.venv\Scripts\python enrich_abstracts.py --input 'DeduplicaciÃ³n/SLR_RAG_master_clean.dedup.bib' --out 'DeduplicaciÃ³n/SLR_RAG_master_enriched.bib' --audit 'logs/enrich_audit.csv' --state 'logs/enrich_state.jsonl' --model 'xai/grok-2-mini' --fallbacks 'openai/gpt-4o-mini,anthropic/claude-3.5-sonnet' --dry-run --resume"}
{"id":"07_realrun","shell":"powershell","cmd":".\.venv\Scripts\python enrich_abstracts.py --input 'DeduplicaciÃ³n/SLR_RAG_master_clean.dedup.bib' --out 'DeduplicaciÃ³n/SLR_RAG_master_enriched.bib' --audit 'logs/enrich_audit.csv' --state 'logs/enrich_state.jsonl' --model 'xai/grok-2-mini' --fallbacks 'openai/gpt-4o-mini,anthropic/claude-3.5-sonnet' --resume"}