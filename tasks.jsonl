{"id": "01_make_dirs", "shell": "powershell", "cmd": "mkdir -Force logs, cache, checkpoints | Out-Null; New-Item -ItemType Directory -Path 'Deduplicación' -Force | Out-Null"}
{"id": "02_venv", "shell": "powershell", "cmd": "py -3 -m venv .venv; .\\.venv\\Scripts\\python -m pip install -U pip"}
{"id": "03_requirements", "shell": "powershell", "cmd": "@'\nbibtexparser>=1.4\nhttpx>=0.27\npython-dotenv>=1.0\ntenacity>=8.5\nbeautifulsoup4>=4.12\nlxml>=5.2\ntldextract>=5.1\nlangdetect>=1.0\nrapidfuzz>=3.9\npypdf>=5.0\npdfminer.six>=20240706\norjson>=3.10\nopenai>=1.54\ncharset-normalizer>=3.3\n'@ | Set-Content -Encoding UTF8 requirements.txt; .\\.venv\\Scripts\\pip install -r requirements.txt"}
{"id": "04_env", "shell": "powershell", "cmd": "@'\nOPENROUTER_API_KEY=\nOPENROUTER_SITE_URL=https://tu-sitio-o-repo\nOPENROUTER_APP_NAME=SLR Abstract Enricher\nCROSSREF_MAILTO=tu_email@dominio\nSCOPUS_API_KEY=\n'@ | Set-Content -Encoding UTF8 .env"}
{"id": "05_script", "shell": "powershell", "cmd": "@'\n﻿import os, json, time, argparse, csv, sys\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nimport bibtexparser\nfrom bibtexparser.bwriter import BibTexWriter\nfrom bibtexparser.bibdatabase import BibDatabase\nfrom openai import OpenAI\nfrom tenacity import retry, stop_after_attempt, wait_exponential\nfrom langdetect import detect\n\n# Load env\nload_dotenv()\nOPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\nHTTP_REFERER = os.getenv('OPENROUTER_SITE_URL','')\nX_TITLE = os.getenv('OPENROUTER_APP_NAME','SLR Abstract Enricher')\n\n# Policies\nLANG_POLICY = 'preserve'\nTARGET_WORDS = (120, 200)\nMIN_CHARS = 400\nKEYWORDS = [\n    'rag', 'retrieval-augmented', 'llm', 'large language model',\n    'hallucination', 'faithfulness', 'factuality', 'trust', 'confidence', 'credibility',\n    'citation', 'grounding', 'provenance', 'explainability', 'xai',\n    'user perception', 'perceived reliability', 'overtrust', 'trustworthiness',\n    'hallucinations', 'accuracy', 'grounded', 'correctness', 'consistency',\n    'explainable ai', 'interpretable', 'interpretability',\n    'transparency', 'attribution', 'saliency', 'attention',\n    'citations', 'reference', 'source attribution',\n    'evidence', 'evidence highlighting', 'highlighting',\n    'calibration', 'brier', 'ece',\n    'evaluation', 'evaluation metric', 'evaluation metrics', 'metric', 'metrics',\n    'methodology', 'methodologies', 'method', 'methods', 'protocol',\n    'instrument', 'questionnaire', 'scale', 'survey', 'user study',\n    'benchmark', 'dataset', 'guideline', 'framework', 'pipeline'\n]\n\nsys.setrecursionlimit(max(5000, sys.getrecursionlimit()))\n\n# OpenRouter client\nclient = None\nif OPENROUTER_API_KEY:\n    client = OpenAI(base_url='https://openrouter.ai/api/v1', api_key=OPENROUTER_API_KEY, default_headers={'HTTP-Referer': HTTP_REFERER, 'X-Title': X_TITLE})\n\n@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=8))\ndef chat_complete(model, system, user):\n    if client is None:\n        raise RuntimeError('OpenRouter API key not configured')\n    return client.chat.completions.create(\n        model=model,\n        messages=[{'role': 'system', 'content': system}, {'role': 'user', 'content': user}],\n        temperature=0.2,\n    )\n\ndef pick_language(text):\n    try:\n        return detect(text or '')\n    except Exception:\n        return 'en'\n\ndef needs_enrichment(abstract):\n    if not abstract:\n        return True\n    t = abstract.strip()\n    if len(t) < MIN_CHARS:\n        return True\n    lower = t.lower()\n    found = sum(1 for k in KEYWORDS if k in lower)\n    return found < 2\n\ndef build_prompt(title, abstract, lang):\n    goal = f\"Expand and refine the abstract to be concise, specific, and faithful. Target {TARGET_WORDS[0]}-{TARGET_WORDS[1]} words.\"\n    policy = 'Preserve the original language.' if LANG_POLICY == 'preserve' else f'Write in {lang}.'\n    kws = ', '.join(KEYWORDS[:20]) + ', ...'\n    hints = 'Include concrete contributions, methods, datasets, and evaluation metrics when available. Avoid speculation.'\n    user = f\"Title: {title or ''}\\nOriginal abstract:\\n{abstract or ''}\\n\\nKeywords of interest: {kws}\"\n    system = f\"You are an expert research editor. {policy} {goal} {hints}\"\n    return system, user\n\ndef call_with_fallbacks(model, fallbacks, system, user):\n    models = [model] + [m for m in fallbacks if m]\n    last_err = None\n    for m in models:\n        try:\n            resp = chat_complete(m, system, user)\n            content = resp.choices[0].message.content.strip()\n            if content:\n                return content, m\n        except Exception as e:\n            last_err = e\n            time.sleep(1.5)\n    raise last_err or RuntimeError('All models failed')\n\ndef load_state(state_path):\n    done = set()\n    p = Path(state_path)\n    if p.exists():\n        with p.open('r', encoding='utf-8') as f:\n            for line in f:\n                try:\n                    obj = json.loads(line)\n                    if obj.get('status') == 'enriched':\n                        done.add(obj.get('key'))\n                except Exception:\n                    pass\n    return done\n\ndef append_state(state_path, obj):\n    p = Path(state_path)\n    p.parent.mkdir(parents=True, exist_ok=True)\n    with p.open('a', encoding='utf-8') as f:\n        f.write(json.dumps(obj, ensure_ascii=False) + '\\n')\n\ndef ensure_parent(path):\n    Path(path).parent.mkdir(parents=True, exist_ok=True)\n\ndef load_bib_database(in_path):\n    text = Path(in_path).read_text(encoding='utf-8', errors='ignore')\n    entries = []\n    i = 0\n    n = len(text)\n    while i < n:\n        if text[i] != '@':\n            i += 1\n            continue\n        start_entry = i\n        i += 1\n        while i < n and text[i] not in '{(':\n            i += 1\n        entry_type = text[start_entry + 1:i].strip().lower()\n        if i >= n:\n            break\n        open_char = text[i]\n        close_char = '}' if open_char == '{' else ')'\n        i += 1\n        content_start = i\n        depth = 1\n        while i < n and depth > 0:\n            ch = text[i]\n            if ch == open_char:\n                depth += 1\n            elif ch == close_char:\n                depth -= 1\n            i += 1\n        content = text[content_start:i - 1]\n        entry = _parse_entry(entry_type, content)\n        if entry:\n            entries.append(entry)\n    db = BibDatabase()\n    db.entries = entries\n    return db\n\n\ndef _parse_entry(entry_type, content):\n    key, body = _split_key_and_body(content)\n    if not key:\n        return None\n    fields = _parse_fields(body)\n    entry = {'ENTRYTYPE': entry_type, 'ID': key}\n    entry.update(fields)\n    return entry\n\n\ndef _split_key_and_body(content):\n    depth = 0\n    for idx, ch in enumerate(content):\n        if ch == '{':\n            depth += 1\n        elif ch == '}':\n            depth = max(0, depth - 1)\n        elif ch == ',' and depth == 0:\n            key = content[:idx].strip()\n            body = content[idx + 1:]\n            return key, body\n    return content.strip(), ''\n\n\ndef _parse_fields(body):\n    fields = {}\n    i = 0\n    n = len(body)\n    while i < n:\n        while i < n and body[i] in ' \\t\\r\\n,':\n            i += 1\n        if i >= n:\n            break\n        name_start = i\n        while i < n and body[i] not in '=\\r\\n':\n            if body[i] == ',':\n                break\n            i += 1\n        name = body[name_start:i].strip()\n        while i < n and body[i] != '=':\n            if body[i] == ',':\n                break\n            i += 1\n        if i >= n or body[i] != '=':\n            while i < n and body[i] != ',':\n                i += 1\n            continue\n        i += 1\n        while i < n and body[i] in ' \\t\\r\\n':\n            i += 1\n        value, i = _parse_field_value(body, i)\n        if name:\n            fields[name.lower()] = value.strip()\n        if i < n and body[i] == ',':\n            i += 1\n    return fields\n\n\ndef _parse_field_value(body, i):\n    n = len(body)\n    if i >= n:\n        return '', n\n    if body[i] == '{':\n        start = i + 1\n        depth = 1\n        i += 1\n        while i < n:\n            ch = body[i]\n            if ch == '{':\n                depth += 1\n            elif ch == '}':\n                depth -= 1\n                if depth == 0:\n                    value = body[start:i]\n                    i += 1\n                    break\n            elif ch == ',' and depth == 1:\n                value = body[start:i]\n                break\n            i += 1\n        else:\n            value = body[start:i]\n        value = _balance_braces(value)\n        return value, i\n    if body[i] == '\"':\n        start = i + 1\n        i += 1\n        while i < n and body[i] != '\"':\n            i += 1\n        value = body[start:i]\n        i = min(i + 1, n)\n        return value, i\n    start = i\n    while i < n and body[i] != ',':\n        i += 1\n    value = body[start:i].strip()\n    return value, i\n\n\ndef _balance_braces(value):\n    opens = value.count('{')\n    closes = value.count('}')\n    if opens > closes:\n        value = value + '}' * (opens - closes)\n    return value\n\n\ndef enrich_bib(in_path, out_path, audit_path, state_path, model, fallbacks, dry_run=False, resume=False, force_retry=False):\n    ensure_parent(out_path)\n    ensure_parent(audit_path)\n    ensure_parent(state_path)\n\n    done_keys = load_state(state_path) if resume and not force_retry else set()\n    db = load_bib_database(in_path)\n\n    writer = BibTexWriter()\n    writer.order_entries_by = ('ID',)\n\n    audit_rows = []\n    changed = 0\n    total = 0\n    for entry in db.entries:\n        total += 1\n        key = entry.get('ID') or entry.get('id') or entry.get('citekey') or f'entry_{total}'\n        title = entry.get('title', '')\n        abstract = entry.get('abstract', '') or entry.get('annotation', '') or ''\n\n        if resume and key in done_keys:\n            append_state(state_path, {'key': key, 'status': 'skipped', 'reason': 'resume', 'ts': time.time()})\n            continue\n\n        if not needs_enrichment(abstract):\n            append_state(state_path, {'key': key, 'status': 'skipped', 'reason': 'sufficient', 'ts': time.time()})\n            continue\n\n        lang = pick_language((abstract or title) or '')\n        system, user = build_prompt(title, abstract, lang)\n\n        if dry_run or client is None:\n            enriched = abstract or ''\n            used_model = None\n            status = 'dry-run'\n        else:\n            try:\n                enriched, used_model = call_with_fallbacks(model, fallbacks, system, user)\n                status = 'enriched'\n            except Exception as e:\n                append_state(state_path, {'key': key, 'status': 'error', 'error': str(e), 'ts': time.time()})\n                continue\n\n        if enriched and enriched != abstract:\n            entry['abstract'] = enriched\n            changed += 1\n\n        audit_rows.append([key, status, len(abstract or ''), len(entry.get('abstract', '') or ''), lang, used_model or ''])\n        append_state(state_path, {'key': key, 'status': status, 'model': used_model, 'ts': time.time()})\n\n    with open(out_path, 'w', encoding='utf-8') as f:\n        bibtexparser.dump(db, f)\n\n    with open(audit_path, 'w', encoding='utf-8', newline='') as f:\n        w = csv.writer(f)\n        w.writerow(['key', 'status', 'old_chars', 'new_chars', 'lang', 'model'])\n        w.writerows(audit_rows)\n\n    return {'total': total, 'changed': changed}\n\nif __name__ == '__main__':\n    p = argparse.ArgumentParser()\n    p.add_argument('--input', required=True)\n    p.add_argument('--out', required=True)\n    p.add_argument('--audit', default='logs/enrich_abstracts_audit.csv')\n    p.add_argument('--state', default='logs/enrich_state.jsonl')\n    p.add_argument('--dry-run', action='store_true')\n    p.add_argument('--resume', action='store_true')\n    p.add_argument('--force-retry', action='store_true')\n    p.add_argument('--model', default='xai/grok-2-mini')\n    p.add_argument('--fallbacks', default='openai/gpt-4o-mini,anthropic/claude-3.5-sonnet')\n    args = p.parse_args()\n    fallbacks = [x.strip() for x in args.fallbacks.split(',') if x.strip()]\n    enrich_bib(args.input, args.out, args.audit, args.state, args.model, fallbacks, dry_run=args.dry_run, resume=args.resume, force_retry=args.force_retry)\n\n'@ | Set-Content -Encoding UTF8 'Deduplicaci\\u00f3n/enrich_abstracts.py'"}
{"id": "06_dryrun", "shell": "powershell", "cmd": ".\\.venv\\Scripts\\python 'Deduplicación/enrich_abstracts.py' --input 'Deduplicación/SLR_RAG_master_clean.dedup.bib' --out 'Deduplicación/SLR_RAG_master_enriched.bib' --audit 'logs/enrich_audit.csv' --state 'logs/enrich_state.jsonl' --model 'xai/grok-2-mini' --fallbacks 'openai/gpt-4o-mini,anthropic/claude-3.5-sonnet' --dry-run --resume"}
{"id": "07_realrun", "shell": "powershell", "cmd": ".\\.venv\\Scripts\\python 'Deduplicación/enrich_abstracts.py' --input 'Deduplicación/SLR_RAG_master_clean.dedup.bib' --out 'Deduplicación/SLR_RAG_master_enriched.bib' --audit 'logs/enrich_audit.csv' --state 'logs/enrich_state.jsonl' --model 'xai/grok-2-mini' --fallbacks 'openai/gpt-4o-mini,anthropic/claude-3.5-sonnet' --resume"}
{"id":"08_screening","shell":"powershell","cmd":".\\.venv\\Scripts\\python 'Clasificación de Kitchenham - Screening\\rag_screening.py' --bib 'Deduplicación/SLR_RAG_master_enriched.bib' --outdir 'screening_out'"}
