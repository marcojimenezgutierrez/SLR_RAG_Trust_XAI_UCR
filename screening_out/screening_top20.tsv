id	title	year	RQs	score	reason
Agl7ugyu1N4 and propose novel task-specific evaluation metrics to control for alignment and hallucination. Our tool is available at https://job-aligned-resume.streamlit.app.}}	"\{{PoisonedRAG}, author = {Zou, W. and Geng, R. and Wang, B. and Jia, J.}, year = {2025}, url = {https://www.usenix.org/conference/usenixsecurity25/presentation/zou-poisonedrag}, journal = {34th USENIX Security Symposium …}, note = {Publisher: usenix.org}, keywords = {source: Google Scholar}, abstract = {… database of a RAG system to induce an LLM to generate an … RAG enables an LLM to utilize external knowledge in a plug-and-play manner. Moreover, RAG can reduce hallucinations …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{cohn_personalizing_2025, title = {Personalizing {Student}, author = {Cohn, C. and Rayala, S. and Snyder, C. and Fonteles, J. and Jain, S. and {...}, year = {2025}, url = {https://arxiv.org/abs/2505.17238}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… hallucinations can undermine confidence, trust, and instructional value. Retrieval-augmented generation (RAG) grounds LLM … log-contextualized RAG (LC-RAG), which enhances RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{finlayson_post-training_2025, title = {Post-training an {LLM}, author = {Finlayson, M. and Kulikov, I. and Bikel, D. M. and Oguz, B. and {...}, year = {2025}, url = {https://arxiv.org/abs/2502.10596}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM RAG performance by fine-tuning on retrievalaugmented instructions, but must beware that this can cause undesirable model behaviors like hallucinations… for training RAG-enabled …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{hu_position_2025, title = {Position: {Towards}, author = {Hu, J. and Dong, Y. and Ao, S. and Li, Z. and Wang, B. and Singh, L. and {...}, year = {2025}, url = {https://arxiv.org/abs/2502.01714}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… and Large Language Modelpowered Multi-Agent Systems (LLM… and Retrieval-Augmented Generation have expanded LLM … on confidence levels and uses textual prompts to convey …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{hu_patchwork_2025, title = {Patchwork: {A}, author = {Hu, B. and Pabon, L. and Agarwal, S. and Akella, A.}, year = {2025}, url = {https://arxiv.org/abs/2505.07833}, journal = {arXiv preprint arXiv:2505.07833}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… As illustrated, a RAG system supplements an LLM with a knowledge base—often an … both the factual accuracy and generation quality of LLM outputs. Moreover, RAG systems offer a …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sun_pankb_2025, title = {{PanKB}, author = {Sun, B. and Pashkova, L. and Pieters, P. A. and Harke, A. S. and {...}, year = {2025}, url = {https://academic.oup.com/nar/article-abstract/53/D1/D806/7906839}, journal = {Nucleic Acids …}, note = {Publisher: academic.oup.com}, keywords = {source: Google Scholar}, abstract = {… hallucinations (40–42). Modern databases can benefit from the integration of a RAG-LLM … -access pangenomics articles and integrates a RAG-enhanced LLM interface (AI Assistant). …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{basit_pennylang_2025, title = {Pennylang: {Pioneering}, author = {Basit, A. and Innan, N. and Asif, M. H. and Shao, M. and Kashif, M. and {...}, year = {2025}, url = {https://arxiv.org/abs/2503.02497}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… curated to train/fine-tune LLM-based quantum code assistance. Our key … LLM training efficiency; and (3) a thorough evaluation, based on a Retrieval-Augmented Generation (RAG) …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wu_perspectives_2025, title = {Perspectives: {LLM}, author = {Wu, S. and Shi, C. and Leung, A. and Otake, Y. and Konishi, C. and Zhou, M. and {...}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S3050483X25000358}, journal = {Geodata and AI}, note = {Publisher: Elsevier Type: HTML}, keywords = {source: Google Scholar}, abstract = {This paper explores the transformative potential of Large Language Model (LLM)-based agentic artificial intelligence (AI) in addressing longstanding challenges in geotechnical …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yang_pseudo-knowledge_2025, title = {Pseudo-{Knowledge}, author = {Yang, Y. and Wu, H. and Wang, T. and Yang, J. and Ma, H. and Luo, G.}, year = {2025}, url = {https://arxiv.org/abs/2503.00309}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… , RAG enhances factual … LLM-VDB (LLM with Vector Database RAG). In this setup, we enhance the language model’s capabilities by integrating a retrievalaugmented generation (RAG) …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{noauthor_proceedings_2025, title = {Proceedings of the 2025 {AAAI}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016685791&partnerID=40&md5=e8f537ee19d42f3b15b8d16a3addaaca}, volume = {5}, number = {1}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{noauthor_proceedings_2025-1, title = {Proceedings - 19th {IEEE}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016119442&partnerID=40&md5=bd352e483669b71ad5f8068f01ef1017}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{noauthor_proceedings_2025-2, title = {Proceedings - 2025 {IEEE}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009592210&partnerID=40&md5=5dfbbbe5607ba331b9dd25ad2da5a7f4}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{wolfe_implications_2025, title = {The {Implications}, author = {Wolfe, Robert and Mitra, Tanushree}, year = {2025}, booktitle = {Proceedings of the 2024 {AAAI}, pages = {1595--1607}, publisher = {AAAI Press}, keywords = {source: ACM}, abstract = {Calls to use open generative language models in academic research have highlighted the need for reproducibility and transparency in scientific research. However, the impact of generative AI extends well beyond academia, as corporations and public interest organizations have begun integrating these models into their data science pipelines. We expand this lens to include the impact of open models on organizations, focusing specifically on fact-checking organizations, which use AI to observe and analyze large volumes of circulating misinformation, yet must also ensure the reproducibility and impartiality of their work. We wanted to understand where fact-checking organizations use open models in their data science pipelines; what motivates their use of open models or proprietary models; and how their use of open or proprietary models can inform research on the societal impact of generative AI. To answer these questions, we conducted an interview study with N=24 professionals at 20 fact-checking organizations on six continents. Based on these interviews, we offer a five-component conceptual model of where fact-checking organizations employ generative AI to support or automate parts of their data science pipeline, including Data Ingestion, Data Analysis, Data Retrieval, Data Delivery, and Data Sharing. We then provide taxonomies of fact-checking organizations' motivations for using open models and the limitations that prevent them for further adopting open models, finding that they prefer open models for Organizational Autonomy, Data Privacy and Ownership, Application Specificity, and Capability Transparency. However, they nonetheless use proprietary models due to perceived advantages in Performance, Usability, and Safety, as well as Opportunity Costs related to participation in emerging generative AI ecosystems. Finally, we propose a research agenda to address limitations of both open and proprietary models. Our research provides novel perspective on open models in data-driven organizations.}, address = {San Jose, California, USA}, series = {{AIES}, } @inproceedings{jokinen_towards_2025, title = {Towards {Domain}, author = {Jokinen, Kristiina and Wilcock, Graham}, year = {2025}, booktitle = {Proceedings of the 2025 {ACM}, pages = {1373--1377}, publisher = {IEEE Press}, keywords = {conversational grounding, human-robot dialogues, knowledge graphs, sustainability}, abstract = {Knowledge graphs have been used to improve robot dialogues by providing more sophisticated world knowledge. We now propose a new role for knowledge graphs in GenAI-based HRI that aims to reduce dialogue errors by better conversational grounding. This approach uses both domain knowledge graphs and dialogue history graphs, constructing shared knowledge via entity linking. We present first steps towards these aims, and also address sustainability by supporting the use of smaller models.}, address = {Melbourne, Australia}, series = {{HRI}, } @article{das_two-layer_2025-1, title = {Two-layer retrieval-augmented generation framework for low-resource medical question answering using reddit data: proof-of-concept study}, author = {Das, S. and Ge, Y. and Guo, Y. and Rajwal, S. and Hairston, J. M. and {...}, year = {2025}, url = {https://www.jmir.org/2025/1/e66220/}, journal = {Journal of Medical …}, note = {Publisher: jmir.org Type: HTML}, keywords = {source: Google Scholar}, abstract = {… the performance of a quantized large language model (Nous-… of relevance, length, hallucination, coverage, and coherence … issue with LLM-generated text for MQA is “hallucination”: …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{leschanowsky_transparent_2025, title = {Transparent nlp: {Using}, author = {Leschanowsky, A. and Kolagar, Z. and Çano, E. and Habernal, I. and {...}, year = {2025}, url = {https://arxiv.org/abs/2502.06652}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… However, because RAG systems are built on … LLM hallucination when providing such generated answers to data processing questions. This is a well-known problem of RAG and LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{martinon_towards_2025, title = {Towards a rigorous evaluation of {RAG}, author = {Martinon, G. and Brionne, AL de and Bohard, J. and Lojou, A. and {...}, year = {2025}, url = {https://arxiv.org/abs/2507.21753}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… This study evaluates a RAG system used in due diligence for an investment fund. We … and LLM-Judge annotations to identify system failures, like hallucinations, off-topic, failed citations, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{dhole_retrieve_2025, title = {To retrieve or not to retrieve? uncertainty detection for dynamic retrieval augmented generation}, author = {Dhole, K. D.}, year = {2025}, url = {https://arxiv.org/abs/2501.09292}, journal = {arXiv preprint arXiv:2501.09292}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Unlike traditional methods that rely on rigid heuristics or external classifiers, uncertainty detection leverages the inherent variability in LLM-generated responses to estimate confidence …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ni_tp-rag_2025, title = {{TP}, author = {Ni, H. and Liu, F. and Ma, X. and Su, L. and Wang, S. and Yin, D. and Xiong, H. and {...}, year = {2025}, url = {https://arxiv.org/abs/2504.08694}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… may indicate hallucinations by the LLM agents. • Repetition Rate (RR): We measure the frequency of POI repetition in plans to assess basic commonsense awareness of the agents. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{tas_turk-lettucedetect_2025, title = {Turk-{LettuceDetect}, author = {Taş, S. and Huseyni, M. E. and Ezerceli, Ö and Bayraktar, R. and {...}, year = {2025}, url = {https://arxiv.org/abs/2509.17671}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… When analyzing LLM hallucination behavior, we observe that GPT-4.1 and Mistral models achieve high recall (up to 0.9938), indicating a strong tendency to generate content flagged as …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{lesperance_taxonomic_2025, title = {Taxonomic {Reasoning}, author = {Lesperance, N. and Ratnasingham, S. and Taylor, G. W.}, year = {2025}, url = {https://arxiv.org/abs/2503.10886}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… the RAG model relative to the Naïve LLM shows reasoning over the additional retrieved context provides a small boost to LLM confidence … The RAG models did not see the same sharp …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{krupp_talk2xopen-source_2025, title = {{Talk2X}, author = {Krupp, L. and Geißler, D. and Hevesi, P. and Hirsch, M. and {...}, year = {2025}, url = {https://arxiv.org/abs/2504.03343}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Integrated into websites, LLM-powered chatbots offer … an adapted retrieval-augmented generation approach (RAG) … sources we enabled Talk2X to cite its sources of information, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{vungarala_tpu-gen_2025-1, title = {Tpu-gen: {Llm}, author = {Vungarala, D. and Elbtity, M. E. and Pandit, K. and {...}, year = {2025}, url = {https://ieeexplore.ieee.org/abstract/document/11106005/}, journal = {… Conference on LLM …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… hallucinations leveraging RAG and fine-tuning, to align best for the LLMs to streamline the approximate TPU design generation process considering budgetary constraints (eg, power, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{tang_lottery_2025, title = {The {Lottery}, author = {Tang, Z. and Liu, X. and Wang, Q. and Dong, P. and He, B. and Chu, X. and {...}, year = {2025}, url = {https://arxiv.org/abs/2502.17535}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… in LLMs related to retrievalaugmented generation, multi-step … enhance LLM performance. Then, we propose a lottery … within LLM parameters if RAG can accurately retrieve factual …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yang_timerag_2025-1, title = {Timerag: {Boosting}, author = {Yang, S. and Wang, D. and Zheng, H. and Jin, R.}, year = {2025}, url = {https://ieeexplore.ieee.org/abstract/document/10889933/}, journal = {ICASSP 2025-2025 IEEE …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… Our work demonstrates the potential of RAG in amplifying LLM performance in time series forecasting, which offers a promising approach for future research in knowledgeenhanced …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhou_efficiency_2025, title = {The {Efficiency}, author = {Zhou, H. and Gu, H. and Liu, X. and Zhou, K. and Liang, M. and Xiao, Y. and {...}, year = {2025}, url = {https://arxiv.org/abs/2501.02173}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… that combines Retrieval-Augmented Generation (RAG) with … real-time predictive confidence assessments across multiple … efficient, real-time LLM deployment in commercial systems. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sood_paradigm_2025, title = {The {Paradigm}, author = {Sood, A. K. and Zeadally, S. and Hong, E. K.}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S0045790625002502}, journal = {Computers and Electrical Engineering}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… We present a taxonomy of hallucinations in LLMs for cybersecurity, including mapping LLM responses to classification … Finally, we discuss mitigation strategies to combat hallucinations. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{adam_traceable_2025, title = {Traceable {LLM}, author = {Adam, D. and Kliegr, T.}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S0306457325000706}, journal = {Information Processing \&Management}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… , our approach is to avoid using internal LLM factual knowledge altogether. Instead, verified … To assess the possible application of this retrieval augmented generation (RAG) workflow …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sheng_talk2traffic_2025-1, title = {Talk2traffic: {Interactive}, author = {Sheng, Z. and Huang, Z. and Qu, Y. and Leng, Y. and {...}, year = {2025}, url = {https://openaccess.thecvf.com/content/CVPR2025W/WDFM-AD/html/Sheng_Talk2Traffic_Interactive_and_Editable_Traffic_Scenario_Generation_for_Autonomous_Driving_CVPRW_2025_paper.html}, journal = {Proceedings of the …}, note = {Publisher: openaccess.thecvf.com}, keywords = {source: Google Scholar}, abstract = {… a retrieval-augmented generation (RAG) approach that grounds MLLMs’ outputs in verified code snippets, effectively reducing hallucinations … that reduces hallucinations and ensures …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kumar_tfhe-coder_2025, title = {Tfhe-coder: {Evaluating}, author = {Kumar, M. and Xue, J. and Zheng, M. and Lou, Q.}, year = {2025}, url = {https://arxiv.org/abs/2503.12217}, journal = {arXiv preprint arXiv:2503.12217}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… generation (RAG) is introduced to provide the LLM with … LLM has access to accurate API definitions and usage examples, reducing errors such as incorrect function calls or hallucinated …}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{ma_role_2025, title = {The {Role}, author = {Ma, Chuangtao}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015692597&partnerID=40&md5=db9b224fe16411ddb110caff9b605e5d}, booktitle = {{CEUR}, volume = {4018}, pages = {4 -- 11}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{huang_trust_2025, title = {{TO}, author = {Huang, Yukun and Chen, Sanxing and Cai, Hongyi and Dhingra, Bhuwan}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010216227&partnerID=40&md5=ded391c226ff0803bcb2f23a25b5a9f4}, pages = {50497 -- 50526}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{sahitaj_towards_2025, title = {Towards {Automated}, author = {Sahitaj, Premtim and Maab, Iffat and Yamagishi, Junichi and Kolanowski, Jawan and Möller, Sebastian and Schmitt, Vera}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009905987&partnerID=40&md5=804a0d103ea8f2fc53e00860ea6f6ef9}, booktitle = {{CEUR}, volume = {3986}, pages = {11 -- 23}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 2}, } @inproceedings{shastri_automating_2025, title = {Automating {Transparency}, author = {Shastri, Ishana and Jain, Shomik and Engelhardt, Barbara and Wilson, Ashia}, year = {2025}, booktitle = {Proceedings of the 2024 {AAAI}, pages = {1357--1367}, publisher = {AAAI Press}, keywords = {source: ACM}, abstract = {Bringing more transparency to the judicial system for the purposes of increasing accountability often demands extensive effort from auditors who must meticulously sift through numerous disorganized legal case files to detect patterns of bias and errors. For example, the high-profile investigation into the Curtis Flowers case took seven reporters a full year to assemble evidence about the prosecutor's history of selecting racially biased juries. LLMs have the potential to automate and scale these transparency pipelines, especially given their demonstrated capabilities to extract information from unstructured documents. We discuss the opportunities and challenges of using LLMs to provide transparency in two important court processes: jury selection in criminal trials and housing eviction cases.}, address = {San Jose, California, USA}, series = {{AIES}, } @article{oche_systematic_2025, title = {A systematic review of key retrieval-augmented generation (rag) systems: {Progress}, author = {Oche, A. J. and Folashade, A. G. and Ghosal, T. and Biswas, A.}, year = {2025}, url = {https://arxiv.org/abs/2507.18910}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG architecture is illustrated in Figure 1 below. A key distinction between RAG and pure large language model (LLM… Overall, RAG became a cornerstone for credible LLM deployments …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chen_application_2025, title = {Application of retrieval-augmented generation for interactive industrial knowledge management via a large language model}, author = {Chen, L. C. and Pardeshi, M. S. and Liao, Y. X. and Pai, K. C.}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S0920548925000248}, journal = {Computer Standards \&Interfaces}, note = {Publisher: Elsevier Type: HTML}, keywords = {source: Google Scholar}, abstract = {… model with a retrieval-augmented generation (RAG)-based LLM as a sustainable solution … RAG-based generative pretrained transformer (GPT) models for customized solutions. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhang_survey_2025-3, title = {A survey of graph retrieval-augmented generation for customized large language models}, author = {Zhang, Q. and Chen, S. and Bei, Y. and Yuan, Z. and Zhou, H. and {...}, year = {2025}, url = {https://arxiv.org/abs/2501.13958}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… new hallucinations and even experiencing severe catastrophic forgetting [11]. Retrieval-Augmented generation (RAG… within RAG focuses on bolstering the quality and efficiency of LLM-…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{bingol_accuracy_2025, title = {Accuracy of {Current}, author = {Bingöl, F. G. and Ağagündüz, D. and Bingol, M. C.}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S1051227625000135}, journal = {Journal of Renal Nutrition}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… Customization of LLMs in specific areas such as nutrition or the development of a nutrition-specific RAG framework by improving LLM structures with current guidelines and articles may …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{voznyuk_advacheck_2025, title = {Advacheck at semeval-2025 task 3: {Combining}, author = {Voznyuk, A. and Gritsai, G. and Grabovoy, A.}, year = {2025}, url = {https://aclanthology.org/2025.semeval-1.160/}, journal = {Proceedings of the 19th …}, note = {Publisher: aclanthology.org}, keywords = {source: Google Scholar}, abstract = {… from LLM judges into initial answer. Through this method, we aim to detect and fix factual hallucinations from the text and thus contribute to ongoing efforts in hallucination detection and …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{mei_survey_2025, title = {A survey of multimodal retrieval-augmented generation}, author = {Mei, L. and Mo, S. and Yang, Z. and Chen, C.}, year = {2025}, url = {https://arxiv.org/abs/2504.08748}, journal = {arXiv preprint arXiv:2504.08748}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… This approach enhances response accuracy and timeliness, particularly in domain-specific contexts, while reducing the risk of hallucinations common in LLM outputs. In multi-turn …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{abootorabi_ask_2025, title = {Ask in any modality: {A}, author = {Abootorabi, M. M. and Zobeiri, A. and Dehghani, M. and {...}, year = {2025}, url = {https://arxiv.org/abs/2502.08826}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RetrievalAugmented Generation (RAG) mitigates these issues by integrating external dynamic information for improved factual … enhance ASR accuracy through LLM in-context learning. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{misrahi_adapting_2025, title = {Adapting {Large}, author = {Misrahi, A. and Chirkova, N. and Louis, M. and Nikoulina, V.}, year = {2025}, url = {https://arxiv.org/abs/2504.02411}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… factuality, but multi-domain applications face challenges like lack of diverse benchmarks … for RAG. We show that commonly used tuning of an LLM for RAG on standard question …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{xie_rag-based_2025, title = {A rag-based multi-agent llm system for natural hazard resilience and adaptation}, author = {Xie, Y. and Jiang, B. and Mallick, T. and Bergerson, J. D. and {...}, year = {2025}, url = {https://arxiv.org/abs/2504.17200}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… In this work we propose a retrieval-augmented generation (RAG)-based multi-agent LLM … datasets, and scientific literature through an RAG framework, the system ensures both the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{cossio_comprehensive_2025, title = {A comprehensive taxonomy of hallucinations in large language models}, author = {Cossio, M.}, year = {2025}, url = {https://arxiv.org/abs/2508.01781}, journal = {arXiv preprint arXiv:2508.01781}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… This report provides a comprehensive taxonomy of LLM hallucinations, beginning with a formal … For instance, Retrieval-Augmented Generation (RAG) is frequently cited as an effective …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kurland_augmenting_2025, title = {Augmenting large language models with automated, bibliometrics-powered literature search for knowledge distillation: a pilot study for common spinal pathologies}, author = {Kurland, D. B. and Alber, D. A. and Palla, A. and Souza, DN de and {...}, year = {2025}, url = {https://journals.lww.com/neurosurgery/fulltext/2025/08000/augmenting_large_language_models_with_automated,.12.aspx}, journal = {…}, note = {Publisher: journals.lww.com}, keywords = {source: Google Scholar}, abstract = {… RAG retrieval augmented generation … that every statement in the LLM-generated summary is cited. By backing up LLM-generated summaries with citations, our approach provides …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wu_automated_2025, title = {Automated literature research and review-generation method based on large language models}, author = {Wu, S. and Ma, X. and Luo, D. and Li, L. and Shi, X. and Chang, X. and {...}, year = {2025}, url = {https://academic.oup.com/nsr/article-abstract/12/6/nwaf169/8120226}, journal = {National Science …}, note = {Publisher: academic.oup.com}, keywords = {source: Google Scholar}, abstract = {… ; LitLLM [20] combining RAG with LLM reranking to generate high-quality … hallucination mitigation, we employed a confusion matrix to classify outcomes according to whether the LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wu_addressing_2025, title = {Addressing the sustainable {AI}, author = {Wu, H. and Wang, X. and Fan, Z.}, year = {2025}, url = {https://arxiv.org/abs/2501.08262}, journal = {arXiv preprint arXiv:2501.08262}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… While traditional LLM applications depend solely on the … -enabled LLM agents or Retrieval-Augmented Generation (RAG) [22… advanced applications by mitigating LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{singh_advanced_2025, title = {Advanced {Real}, author = {Singh, G. and Singh, P. and Singh, M.}, year = {2025}, url = {https://arxiv.org/abs/2501.15290}, journal = {arXiv preprint arXiv:2501.15290}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… This section discusses the primary advantages of the RAG based LLM model over the … Additionally, the challenge of LLM hallucination, where the model may generate unnecessary or …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{li_survey_2025, title = {A survey of personalization: {From}, author = {Li, X. and Jia, P. and Xu, D. and Wen, Y. and Zhang, Y. and Zhang, W. and {...}, year = {2025}, url = {https://arxiv.org/abs/2504.10147}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG, we further extend its capabilities into the realm of Personalized LLM-based Agents, which enhance traditional RAG … as outdated responses and hallucinations, which severely …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{tang_adapting_2025, title = {Adapting to non-stationary environments: {Multi}, author = {Tang, X. and Li, J. and Du, N. and Xie, S.}, year = {2025}, url = {https://ojs.aaai.org/index.php/AAAI/article/view/33380}, journal = {Proceedings of the AAAI Conference on …}, note = {Publisher: ojs.aaai.org}, keywords = {source: Google Scholar}, abstract = {… Retrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs that encapsulate extensive factual … method across different Large Language Model generators to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{liu_application_2025, title = {Application of large language models in medicine}, author = {Liu, F. and Zhou, H. and Gu, B. and Zou, X. and Huang, J. and Wu, J. and {...}, year = {2025}, url = {https://www.nature.com/articles/s44222-025-00279-5}, journal = {Nature Reviews …}, note = {Publisher: nature.com}, keywords = {source: Google Scholar}, abstract = {… to minimize hallucinations, … ChatGPT on clinical scenario evaluations, particularly in terms of completeness and safety. Another example is QA-RAG 61 , which utilizes RAG with LLM for …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhang_ai-driven_2025, title = {{AI}, author = {Zhang, S. and Huang, M. and Liu, S. and Meng, F. and Xie, Y. and Ren, X. and {...}, year = {2025}, url = {https://ieeexplore.ieee.org/abstract/document/11029010/}, journal = {IEEE …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… online information, employing retrieval-augmented generation (RAG) to mitigate the lack of specialized knowledge and reduce hallucinations in large language model outputs. Chain-of-…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yang_agrigpt_2025, title = {Agrigpt: {A}, author = {Yang, B. and Zhang, Y. and Feng, L. and Chen, Y. and Zhang, J. and {...}, year = {2025}, url = {https://arxiv.org/abs/2508.08632}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… factual grounding, we employ Tri-RAG, a three-channel RetrievalAugmented Generation … , we propose a three channel RetrievalAugmented Generation (Tri-RAG) framework that incor…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{xu_align-grag_2025, title = {Align-{GRAG}, author = {Xu, D. and Jia, P. and Li, X. and Zhang, Y. and Wang, M. and Liu, Q. and {...}, year = {2025}, url = {https://arxiv.org/abs/2505.16237}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of LLM remain, leading to challenges like hallucinations (… Retrieval-augmented generation (RAG) systems have been … the LLM’s outputs in verifiable, external knowledge, RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ilapaka_comprehensive_2025, title = {A {Comprehensive}, author = {Ilapaka, A. and Ghosh, R.}, year = {2025}, url = {https://ieeexplore.ieee.org/abstract/document/11017017/}, journal = {2025 7th International Congress on …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… The chatbot uses Retrieval-Augmented Generation (RAG) to improve the relevance of its responses and make interactions more personalized. It also leverages LangChain’s …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ding_automatic_2025, title = {An automatic patent literature retrieval system based on {LLM}, author = {Ding, Y. and Wu, Y. and Ding, Z.}, year = {2025}, url = {https://arxiv.org/abs/2508.14064}, journal = {arXiv preprint arXiv:2508.14064}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… in this study, RetrievalAugmented Generation (RAG) serves as a core framework, acting as a bridge between semantic retrieval and contextual generation. RAG combines the strengths …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{bazgir_agentichypothesis_2025, title = {Agentichypothesis: {A}, author = {Bazgir, A. and Zhang, Y.}, year = {2025}, url = {https://openreview.net/forum?id=UeeyfR4CUg}, journal = {Towards Agentic AI for Science: Hypothesis …}, note = {Publisher: openreview.net}, keywords = {source: Google Scholar}, abstract = {… for LLM-based hypothesis generation, including Retrieval Augmented Generation (RAG), … LLMs employ citation graph integration to ground hypotheses in existing literature, thereby …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhao_smart_2025, title = {A smart multimodal healthcare copilot with powerful llm reasoning}, author = {Zhao, X. and Liu, S. and Yang, S. Y. and Miao, C.}, year = {2025}, url = {https://arxiv.org/abs/2506.02470}, journal = {arXiv preprint arXiv:2506.02470}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of the backbone LLM. Retrieval-Augmented Generation To provide backbone LLM with case-… information and mitigate hallucinations in generated outputs, we apply the RAG method, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{devine_aloftrag_2025, title = {{ALoFTRAG}, author = {Devine, P.}, year = {2025}, url = {https://arxiv.org/abs/2501.11929}, journal = {arXiv preprint arXiv:2501.11929}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM for RAG. We show that the ALoFTRAG approach improves both the citation accuracy and answer accuracy of RAG … increase the accuracy of LLM-based RAG systems while using …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{li_review_2025, title = {A review of prominent paradigms for llm-based agents: {Tool}, author = {Li, X.}, year = {2025}, url = {https://aclanthology.org/2025.coling-main.652/}, journal = {Proceedings of the 31st International Conference on …}, note = {Publisher: aclanthology.org}, keywords = {source: Google Scholar}, abstract = {… LLM-profiled roles as the foundation for the development of algorithmic frameworks across different paradigms. Notably, Wang et al. (2024a) also discuss LLM … to their citations on …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{shirdel_aprescot_2025, title = {{AprèsCoT}, author = {Shirdel, M. and Rorseth, J. and Godfrey, P. and Golab, L. and Srivastava, D. and {...}, year = {2025}, url = {https://www.openproceedings.org/2025/conf/edbt/paper-337.pdf}, publisher = {openproceedings.org}, note = {Type: PDF}, keywords = {source: Google Scholar}, abstract = {… up the nearest documents to the output generated by the LLM as a form of citation. However, our … RAG mode, where the facts identified by the subgraph retriever are given to the LLM as …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{anaroua_ai-driven_2025, title = {{AI}, author = {Anaroua, F. I. and Li, Q. and Tang, Y. and Liu, H. P.}, year = {2025}, url = {https://arxiv.org/abs/2509.20369}, journal = {arXiv preprint arXiv:2509.20369}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… The paper concludes with implementation lessons and a roadmap (RAG integration, hallucination mitigation, and LTI 1.3/OpenID Connect) to guide multi-course evaluations and …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yue_survey_2025, title = {A survey of large language model agents for question answering}, author = {Yue, M.}, year = {2025}, url = {https://arxiv.org/abs/2503.19213}, journal = {arXiv preprint arXiv:2503.19213}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… in retrieval-augmented generation systems is determining when to trust the LLM’s internal knowledge versus relying on external documents. The critical LLM in SelfRAG addresses this …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{odubola_ai_2025, title = {{AI}, author = {Odubola, O. and Adeyemi, T. S. and Olajuwon, O. O. and {...}, year = {2025}, url = {https://www.researchgate.net/profile/Oluwatimilehin-Odubola/publication/389525988_AI_in_Social_Good_LLM_powered_Interventions_in_Crisis_Management_and_Disaster_Response/links/67ddb99e35f7044c924f6afe/AI-in-Social-Good-LLM-powered-Interventions-in-Crisis-Management-and-Disaster-Response.pdf}, journal = {Journal of Artificial …}, note = {Publisher: researchgate.net Type: PDF}, keywords = {source: Google Scholar}, abstract = {… retrieval-augmented generation (RAG) for flood disaster reporting has also been explored, with studies demonstrating that LLM… databases, improving factual accuracy and reducing the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wan_aviationllm_2025, title = {{AviationLLM}, author = {Wan, J. and Shen, F. and Li, F. and Sun, Y. and Li, Y. and Zhang, S.}, year = {2025}, url = {https://arxiv.org/abs/2506.14336}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM Qwen and adapt it to aviation theory training through DPO-based domain alignment. Simultaneously, to mitigate hallucinations … RAG to develop an aviation training-oriented LLM. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kermani_systematic_2025, title = {A {Systematic}, author = {Kermani, A. and Perez-Rosas, V. and Metsis, V.}, year = {2025}, url = {https://arxiv.org/abs/2503.24307}, journal = {arXiv preprint arXiv:2503.24307}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG can operate with much fewer training examples than is usually required to fine-tune an LLM model on a specific task, we consider RAG … We implement a RAG model that …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{liu_adaptive_2025, title = {Adaptive {Contextual}, author = {Liu, G. and Liu, Y. and Wang, J. and Du, H. and Niyato, D. and Kang, J. and {...}, year = {2025}, url = {https://arxiv.org/abs/2501.09383}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Biased or skewed training data may cause the LLM to generate hallucinations, ie, … This paper has introduced an ACC framework for mobileedge LLM services, enhancing RAG through …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{luo_agentauditor_2025, title = {Agentauditor: {Human}, author = {Luo, H. and Dai, S. and Ni, C. and Li, X. and Zhang, G. and Wang, K. and Liu, T. and {...}, year = {2025}, url = {https://arxiv.org/abs/2506.00641}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… aware retrieval-augmented generation process then dynamically retrieves the most relevant reasoning experiences to guide the LLM … of LLM outputs and reducing model hallucinations, …}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{chen_self-improving_2025, title = {A {Self}, author = {Chen, Xiaorui and Hao, Haiyan}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008009216&partnerID=40&md5=3e0ed587d66038792fd2e010a3e32e3b}, booktitle = {Proceedings of the {International}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{ocker_grounded_2025, title = {A {Grounded}, author = {Ocker, Felix and Deigmoeller, Joerg and Smirnov, Pavel and Eggert, Julian P.}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017117149&partnerID=40&md5=60254072155f8735400959884a8a9a08}, booktitle = {{CEUR}, volume = {4020}, pages = {1 -- 8}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{agrawal_algoace_2025, title = {{AlgoAce}, author = {Agrawal, Anav and Vie, Jill Jênn}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017115267&partnerID=40&md5=1ff3a4ee54b42f54386351f1546d7ff4}, booktitle = {{CEUR}, volume = {4019}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{leemann_auto-gda_2025, title = {{AUTO}, author = {Leemann, Tobias and Petridis, Periklis and Vietri, Giuseppe and Manousakas, DIonysis and Roth, Aaron L. and Aydöre, Sergül}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010261957&partnerID=40&md5=00d53ba28c1e27e4ef4a44edcafa83b5}, pages = {90986 -- 91017}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{chen_attention_2025, title = {{ATTENTION}, author = {Chen, Shijie and Gutierrez, Bernal Jiménez and Su, Yu}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010249161&partnerID=40&md5=23bfc973cfb6d14351645c8fc8ddd763}, pages = {100148 -- 100170}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 2}, } @inproceedings{firsanova_aggile_2025, title = {{AGGILE}, author = {Firsanova, Victoria and Khlusova, Yana}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008498345&partnerID=40&md5=298247b0d9a24b29d9dfabd7f1c7b737}, booktitle = {{CEUR}, volume = {3977}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{arnold_pilot_2025, title = {A {Pilot}, author = {Arnold, Christian M. and Robertson, Paul and Robertson, Zoe and Laddaga, Robert M. and Katz, Boris and Barbu, Andrei}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005138825&partnerID=40&md5=92452f1477d21048c791ff0169212739}, booktitle = {{CEUR}, volume = {3957}, pages = {391 -- 401}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{zhang_automatic_2025, title = {An {Automatic}, author = {Zhang, Chi and Datla, Vivek V. and Shrivastava, Aditya and Samuel, Alfy and Huang, Zhiqi and Kumar, Anoop and Liu, Daben}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000157880&partnerID=40&md5=f75d433471cccbae6cd13b10a7f72836}, booktitle = {Proceedings - {International}, pages = {603 -- 611}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 1}, } @article{chen_decentralized_2024, title = {Decentralized natural policy gradient with variance reduction for collaborative multi-agent reinforcement learning}, author = {Chen, Jinchi and Feng, Jie and Gao, Weiguo and Wei, Ke}, year = {2024}, journal = {J. Mach. Learn. Res.}, volume = {25}, number = {1}, note = {Publisher: JMLR.org}, keywords = {decentralized optimization, multi-agent reinforcement learning, natural policy gradient, variance reduction, source: ACM}, abstract = {This paper studies a policy optimization problem arising from collaborative multi-agent reinforcement learning in a decentralized setting where agents communicate with their neighbors over an undirected graph to maximize the sum of their cumulative rewards. A novel decentralized natural policy gradient method, dubbed Momentum-based Decentralized Natural Policy Gradient (MDNPG), is proposed, which incorporates natural gradient, momentum-based variance reduction, and gradient tracking into the decentralized stochastic gradient ascent framework. The O(n-1ε-3) sample complexity for MDNPG to converge to an ε-stationary point has been established under standard assumptions, where n is the number of agents. It indicates that MDNPG can achieve the optimal convergence rate for decentralized policy gradient methods and possesses a linear speedup in contrast to centralized optimization methods. Moreover, superior empirical performance of MDNPG over other state-of-the-art algorithms has been demonstrated by extensive numerical experiments.}, issn = {1532-4435}, month = {jan}, } @article{prabhune_deploying_2024, title = {Deploying large language models with retrieval augmented generation}, author = {Prabhune, S. and Berndt, D. J.}, year = {2024}, url = {https://arxiv.org/abs/2411.11895}, journal = {arXiv preprint arXiv:2411.11895}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… (LLM) are sometimes hampered by tendencies to hallucinate or create non-factual responses, … have increasingly focused on methods to ground generated outputs in factual data. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ke_development_2024, title = {Development and testing of retrieval augmented generation in large language models–a case study report}, author = {Ke, Y. H. and Jin, L. and Elangovan, K. and Abdullah, H. R. and Liu, N. and {...}, year = {2024}, url = {https://arxiv.org/abs/2402.01733}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM-RAG pipeline, tailored specifically for preoperative medicine. The primary objective is to evaluate the accuracy of the LLM-RAG … Both models have similar hallucination rates of 1.2\%…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chang_detecting_2024, title = {Detecting hallucination and coverage errors in retrieval augmented generation for controversial topics}, author = {Chang, T. A. and Tomanek, K. and Hoffmann, J. and Thain, N. and {...}, year = {2024}, url = {https://arxiv.org/abs/2403.08904}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… In this paper, we investigate how LLMs can be used with retrieval augmented generation for … in the tuned LLM responses. In retrieval augmented generation, factual information is re…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{su_dragin_2024, title = {{DRAGIN}, author = {Su, W. and Tang, Y. and Ai, Q. and Wu, Z. and Liu, Y.}, year = {2024}, url = {https://arxiv.org/abs/2403.10081}, journal = {arXiv preprint arXiv:2403.10081}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG enhances LLMs by retrieving and incorporating relevant … of RAG typically rely on single-round retrieval, using the LLM’s … retrieval dynamically when the LLM’s confidence (ie, the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{khan_developing_2024, title = {Developing retrieval augmented generation ({RAG}, author = {Khan, A. A. and Hasan, M. T. and Kemell, K. K. and Rasku, J. and {...}, year = {2024}, url = {https://arxiv.org/abs/2410.15944}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG models enhance the factual grounding of their outputs from the up-to-date knowledge. A generic workflow of Retrieval Augmented Generation (RAG… knowledge, the RAG process is …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ni_diras_2024, title = {Diras: {Efficient}, author = {Ni, J. and Schimanski, T. and Lin, M. and Sachan, M. and Ash, E. and {...}, year = {2024}, url = {https://arxiv.org/abs/2406.14162}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… ]; “Ask” means the result is calibrated by the generated confidence score in [Confidence] field; and “Tok” means we take the token-level probability of “Yes/No” after “[Guess]:” as the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{arslan_driving_2024, title = {Driving sustainable energy transitions with a multi-source {RAG}, author = {Arslan, M. and Mahdjoubi, L. and Munawar, S.}, year = {2024}, url = {https://www.sciencedirect.com/science/article/pii/S0378778824009435}, journal = {Energy and Buildings}, note = {Publisher: Elsevier Type: HTML}, keywords = {source: Google Scholar}, abstract = {… this gap, this research introduces an Energy Chatbot, a sustainable IS that utilizes Large Language Models (LLMs) integrated with multi-source Retrieval Augmented Generation (RAG). …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jiao_duetrag_2024, title = {Duetrag: {Collaborative}, author = {Jiao, D. and Cai, L. and Huang, J. and Zhang, W. and Tang, S. and {...}, year = {2024}, url = {https://arxiv.org/abs/2405.13002}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG Recently, related work has studied how to improve the overall performance by fine-tuning the LLM or retriever in the RAG … learns to independently weigh the credibility of Mi and Me’…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{barron_domain-specific_2024-1, title = {Domain-specific retrieval-augmented generation using vector stores, knowledge graphs, and tensor factorization}, author = {Barron, R. C. and Grantcharov, V. and Wanna, S. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10903241/}, journal = {2024 International …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… a highly domainspecific LLM framework, that integrates RAG with KG and a vector store (VS) that store factual domain specific information. Importantly, to avoid hallucinations in the KG, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{peng_data_2024, title = {Data extraction attacks in retrieval-augmented generation via backdoors}, author = {Peng, Y. and Wang, J. and Yu, H. and Houmansadr, A.}, year = {2024}, url = {https://arxiv.org/abs/2411.01705}, journal = {arXiv preprint arXiv:2411.01705}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Wikichat: Stopping the hallucination of large language model chatbots by few-shot … a scenario where the RAG system owner directly uses a publicly available LLM that has already been …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{eghbali_-hallucinator_2024, title = {De-{Hallucinator}, author = {Eghbali, A. and Pradel, M.}, year = {2024}, url = {https://arxiv.org/abs/2401.01701}, journal = {arXiv preprint arXiv:2401.01701}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Retrieval-augmented generation (RAG) [28] proposes to retrieve relevant context based on … we refer to as the RAG prompt type. The idea of augmenting an LLM with well-grounded facts …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{park_development_2024, title = {Development of dental consultation chatbot using retrieval augmented llm}, author = {Park, J.}, year = {2024}, journal = {The Journal of the Institute of Internet …}, note = {Publisher: The Institute of Internet … Type: CITATION}, keywords = {source: Google Scholar}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ong_development_2024, title = {Development and testing of a novel large language model-based clinical decision support systems for medication safety in 12 clinical specialties}, author = {Ong, J. C. L. and Jin, L. and Elangovan, K. and Lim, G. Y. S. and {...}, year = {2024}, url = {https://arxiv.org/abs/2402.01741}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… The accuracy of DRP detection with RAG-LLM improved in several categories but at the … This study established that a RAG-LLM based CDSS significantly boosts the accuracy of …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{cai_driving_2024, title = {Driving with regulation: {Interpretable}, author = {Cai, T. and Liu, Y. and Zhou, Z. and Ma, H. and Zhao, S. Z. and Wu, Z. and {...}, year = {2024}, url = {https://arxiv.org/abs/2410.04759}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… (TRR) Agent based on Retrieval-Augmented Generation (RAG) to … powered by a Large Language Model (LLM) to interpret … effectiveness in enhancing LLM accuracy and factual correct…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{li_dmqr-rag_2024, title = {Dmqr-rag: {Diverse}, author = {Li, Z. and Wang, J. and Jiang, Z. and Mao, H. and Chen, Z. and Du, J. and {...}, year = {2024}, url = {https://arxiv.org/abs/2411.13154}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… In contrast, “What is the citation count for the Transformer paper?” is a general-purpose … In this section, we will first explore various LLM-based rewriting strategies from an informational …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{werheid_designing_2024, title = {Designing an llm-based copilot for manufacturing equipment selection}, author = {Werheid, J. and Melnychuk, O. and Zhou, H. and Huber, M. and {...}, year = {2024}, url = {https://arxiv.org/abs/2412.13774}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… However, no studies have been identified that propose LLM-driven methods or tools … To address this gap, we propose a factual-driven copilot based on RAG-LLMs designed to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{huang_datagen_2024, title = {Datagen: {Unified}, author = {Huang, Y. and Wu, S. and Gao, C. and Chen, D. and Zhang, Q. and {...}, year = {2024}, url = {https://openreview.net/forum?id=F5R0lG74Tu}, journal = {The Thirteenth …}, note = {Publisher: openreview.net}, keywords = {source: Google Scholar}, abstract = {… a Retrieval-Augmented Generation (RAG)-based validation method to check the factuality of … Motivated by this finding, we require the LLM to generate Python code to solve the given …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{burgan_developing_2024, title = {Developing a {Retrieval}, author = {Burgan, C. and Kowalski, J. and Liao, W.}, year = {2024}, url = {https://www.pwvas.org/index.php/pwvas/article/view/1068}, journal = {… of the West Virginia Academy of Science}, note = {Publisher: pwvas.org}, keywords = {source: Google Scholar}, abstract = {… Testing each LLM helped assess answer types and accuracy. … a local LLM based on Google's Gemini model. Ollama framework aids in automatic LLM selection based on user prompts. …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{chen_dynamic_2024, title = {Dynamic supplementation of federated search results for reducing hallucinations in llms}, author = {Chen, J. and Huang, X. and Li, Y.}, year = {2024}, url = {https://files.osf.io/v1/resources/x5vge/providers/osfstorage/66615e3565e1de503e893ab6?format=pdf\&action=download\&direct\&version=2}, publisher = {files.osf.io}, note = {Type: PDF}, keywords = {source: Google Scholar}, abstract = {… The use of retrieval-augmented generation (RAG) … in hallucinations by grounding responses in verifiable facts [34… inference for reducing large language model hallucinations. In: …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sharma_decoding_2024, title = {Decoding {BACnet}, author = {Sharma, R. and Okada, H. and Oba, T. and Subramanian, K. and {...}, year = {2024}, url = {https://arxiv.org/abs/2407.15428}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… ’s outputs in factual information retrieved from trusted sources [Nightfall]. … RAG (Method 1) In summarization generation without RAG, we pass the processed packet content to the LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{bouvard_derby_2024, title = {Derby {LLM}, author = {Bouvard, C. and Ciancone, M. and Gourru, A. and {...}, year = {2024}, url = {https://hal.science/hal-04638460/}, journal = {10 ème Conférence …}, note = {Publisher: hal.science}, keywords = {source: Google Scholar}, abstract = {… le processus expérimental mis en place pour comparer la RAG et le fine-tuning d’un LLM. … La fidélité peut facilement être liée à la détection d’hallucinations. La plupart des outils …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{rashid_monotonic_2020, title = {Monotonic value function factorisation for deep multi-agent reinforcement learning}, author = {Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon}, year = {2020}, journal = {J. Mach. Learn. Res.}, volume = {21}, number = {1}, note = {Publisher: JMLR.org}, keywords = {multi-agent coordination, multi-agent learning, reinforcement learning, source: ACM}, abstract = {In many real-world settings, a team of agents must coordinate its behaviour while acting in a decentralised fashion. At the same time, it is often possible to train the agents in a centralised fashion where global state information is available and communication constraints are lifted. Learning joint action-values conditioned on extra state information is an attractive way to exploit centralised learning, but the best strategy for then extracting decentralised policies is unclear. Our solution is QMIX, a novel value-based method that can train decentralised policies in a centralised end-to-end fashion. QMIX employs a mixing network that estimates joint action-values as a monotonic combination of per-agent values. We structurally enforce that the joint-action value is monotonic in the per-agent values, through the use of non-negative weights in the mixing network, which guarantees consistency between the centralised and decentralised policies. To evaluate the performance of QMIX, we propose the StarCraft Multi-Agent Challenge (SMAC) as a new benchmark for deep multi-agent reinforcement learning. We evaluate QMIX on a challenging set of SMAC scenarios and show that it significantly outperforms existing multi-agent reinforcement learning methods.}, issn = {1532-4435}, month = {jan}, } @article{zhou_malib_2023, title = {{MALib}, author = {Zhou, Ming and Wan, Ziyu and Wang, Hanjing and Wen, Muning and Wu, Runzhe and Wen, Ying and Yang, Yaodong and Yu, Yong and Wang, Jun and Zhang, Weinan}, year = {2023}, journal = {J. Mach. Learn. Res.}, volume = {24}, number = {1}, note = {Publisher: JMLR.org}, keywords = {source: ACM}, abstract = {Population-based multi-agent reinforcement learning (PB-MARL) encompasses a range of methods that merge dynamic population selection with multi-agent reinforcement learning algorithms (MARL). While PB-MARL has demonstrated notable achievements in complex multi-agent tasks, its sequential execution is plagued by low computational efficiency due to the diversity in computing patterns and policy combinations. We propose a solution involving a stateless central task dispatcher and stateful workers to handle PB-MARL's subroutines, thereby capitalizing on parallelism across various components for efficient problem-solving. In line with this approach, we introduce MALib, a parallel framework that incorporates a task control model, independent data servers, and an abstraction of MARL training paradigms. The framework has undergone extensive testing and is available under the MIT license (https://github.com/sjtu-marl/malib).}, month = {jan}, issn = {1532-4435}, } @article{narang_multiplayer_2023, title = {Multiplayer performative prediction: learning in decision-dependent games}, author = {Narang, Adhyyan and Faulkner, Evan and Drusvyatskiy, Dmitriy and Fazel, Maryam and Ratliff, Lillian J.}, year = {2023}, journal = {J. Mach. Learn. Res.}, volume = {24}, number = {1}, note = {Publisher: JMLR.org}, keywords = {source: ACM}, abstract = {Learning problems commonly exhibit an interesting feedback mechanism wherein the population data reacts to competing decision makers' actions. This paper formulates a new game theoretic framework for this phenomenon, called multi-player performative prediction. We focus on two distinct solution concepts, namely (i) performatively stable equilibria and (ii) Nash equilibria of the game. The latter equilibria are arguably more informative, but are generally computationally difficult to find since they are solutions of nonmonotone games. We show that under mild assumptions, the performatively stable equilibria can be found efficiently by a variety of algorithms, including repeated retraining and the repeated (stochastic) gradient method. We then establish transparent sufficient conditions for strong monotonicity of the game and use them to develop algorithms for finding Nash equilibria. We investigate derivative free methods and adaptive gradient algorithms wherein each player alternates between learning a parametric description of their distribution and gradient steps on the empirical risk. Synthetic and semi-synthetic numerical experiments illustrate the results.}, month = {jan}, issn = {1532-4435}, } @article{saxena_minimizing_2023, title = {Minimizing factual inconsistency and hallucination in large language models}, author = {Saxena, S. and Prasad, S. and Prakash, M. V. and Shankar, A. and {...}, year = {2023}, url = {https://arxiv.org/abs/2311.13878}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… hallucination into input, context, and factconflicting. In particular, fact-conflicting hallucination … Existing approaches such as Retrieval-Augmented Generation (RAG) [10] augment LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{lan_warpdrive_2022, title = {{WarpDrive}, author = {Lan, Tian and Srinivasa, Sunil and Wang, Huan and Zheng, Stephan}, year = {2022}, journal = {J. Mach. Learn. Res.}, volume = {23}, number = {1}, note = {Publisher: JMLR.org}, keywords = {deep reinforcement learning, GPU acceleration, multi-agent systems, source: ACM}, abstract = {WarpDrive is a flexible, lightweight, and easy-to-use open-source framework for end-to-end deep multi-agent reinforcement learning (MARL) on a Graphics Processing Unit (GPU), available at https://github.com/salesforce/warp-drive. It addresses key system bottlenecks when applying MARL to complex environments with high-dimensional state, observation, or action spaces. For example, WarpDrive eliminates data copying between the CPU and GPU and runs thousands of simulations and agents in parallel. It also enables distributed training on multiple GPUs and scales to millions of agents. In all, WarpDrive enables orders-of-magnitude faster MARL compared to common CPU-GPU implementations. For example, WarpDrive yields 2.9 million environment steps/second with 2000 environments and 1000 agents (at least 100× faster than a CPU version) in a 2d-Tag simulation. It is user-friendly: e.g., it provides a lightweight, extendable Python interface and flexible environment wrappers. It is also compatible with PyTorch. In all, WarpDrive offers a platform to significantly accelerate reinforcement learning research and development.}, issn = {1532-4435}, month = {jan}, } @article{li_f2a2_2023, title = {{F2A2}, author = {Li, Wenhao and Jin, Bo and Wang, Xiangfeng and Yan, Junchi and Zha, Hongyuan}, year = {2023}, journal = {J. Mach. Learn. Res.}, volume = {24}, number = {1}, note = {Publisher: JMLR.org}, keywords = {actor-critic, cooperative MARL, decentralized, primal-dual method, source: ACM}, abstract = {Traditional centralized multi-agent reinforcement learning (MARL) algorithms are sometimes unpractical in complicated applications due to non-interactivity between agents, the curse of dimensionality, and computation complexity. Hence, several decentralized MARL algorithms are motivated. However, existing decentralized methods only handle the fully cooperative setting where massive information needs to be transmitted in training. The block coordinate gradient descent scheme they used for successive independent actor and critic steps can simplify the calculation, but it causes serious bias. This paper proposes a exible fully decentralized actor-critic MARL framework, which can combine most of the actor-critic methods and handle large-scale general cooperative multi-agent settings. A primal-dual hybrid gradient descent type algorithm framework is designed to learn individual agents separately for decentralization. From the perspective of each agent, policy improvement and value evaluation are jointly optimized, which can stabilize multi-agent policy learning. Furthermore, the proposed framework can achieve scalability and stability for the large-scale environment. This framework also reduces information transmission by the parameter sharing mechanism and novel modeling-other-agents methods based on theory-of-mind and online supervised learning. Sufficient experiments in cooperative Multi-agent Particle Environment and StarCraft II show that the proposed decentralized MARL instantiation algorithms perform competitively against conventional centralized and decentralized methods.}, issn = {1532-4435}, month = {jan}, } @article{colverd_floodbrain_2023, title = {Floodbrain: {Flood}, author = {Colverd, G. and Darm, P. and Silverberg, L. and {...}, year = {2023}, url = {https://arxiv.org/abs/2311.02597}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Despite our efforts to curb hallucination risks via a human-in-the-loop inspect methodology, … This tool is designed for collaborative report writing between human and LLM, to be used …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{izacard_atlas_2023, title = {Atlas: few-shot learning with retrieval augmented language models}, author = {Izacard, Gautier and Lewis, Patrick and Lomeli, Maria and Hosseini, Lucas and Petroni, Fabio and Schick, Timo and Dwivedi-Yu, Jane and Joulin, Armand and Riedel, Sebastian and Grave, Edouard}, year = {2023}, journal = {J. Mach. Learn. Res.}, volume = {24}, number = {1}, note = {Publisher: JMLR.org}, keywords = {information retrieval, language models, retrieval augmented language models, source: ACM}, abstract = {Large language models have shown impressive few-shot results on a wide range of tasks. However, when knowledge is key for such results, as is the case for tasks such as question answering and fact checking, massive parameter counts to store knowledge seem to be needed. Retrieval-augmented models are known to excel at knowledge intensive tasks without the need for as many parameters, but it is unclear whether they work in few-shot settings. In this work we present Atlas, a carefully designed and pre-trained retrieval-augmented language model able to learn knowledge intensive tasks with very few training examples. We perform evaluations on a wide range of tasks, including MMLU, KILT and Natural Questions, and study the impact of the content of the document index, showing that it can easily be updated. Notably, Atlas reaches over 42\% accuracy on Natural Questions using only 64 examples, outperforming a 540B parameter model by 3\% despite having 50x fewer parameters.}, issn = {1532-4435}, month = {jan}, } @article{rahman_general_2023, title = {A general learning framework for open ad hoc teamwork {Using}, author = {Rahman, Arrasy and Carlucho, Ignacio and Höpner, Niklas and Albrecht, Stefano V.}, year = {2023}, journal = {J. Mach. Learn. Res.}, volume = {24}, number = {1}, note = {Publisher: JMLR.org}, keywords = {source: ACM}, abstract = {Open ad hoc teamwork is the problem of training a single agent to efficiently collaborate with an unknown group of teammates whose composition may change over time. A variable team composition creates challenges for the agent, such as the requirement to adapt to new team dynamics and dealing with changing state vector sizes. These challenges are aggravated in real-world applications in which the controlled agent only has a partial view of the environment. In this work, we develop a class of solutions for open ad hoc teamwork under full and partial observability. We start by developing a solution for the fully observable case that leverages graph neural network architectures to obtain an optimal policy based on reinforcement learning. We then extend this solution to partially observable scenarios by proposing different methodologies that maintain belief estimates over the latent environment states and team composition. These belief estimates are combined with our solution for the fully observable case to compute an agent's optimal policy under partial observability in open ad hoc teamwork. Empirical results demonstrate that our solution can learn efficient policies in open ad hoc teamwork in fully and partially observable cases. Further analysis demonstrates that our methods' success is a result of effectively learning the effects of teammates' actions while also inferring the inherent state of the environment under partial observability.}, month = {jan}, issn = {1532-4435}, } @article{saad-falcon_ares_2023, title = {Ares: {An}, author = {Saad-Falcon, J. and Khattab, O. and Potts, C. and {...}, year = {2023}, url = {https://arxiv.org/abs/2311.09476}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… confidence interval for each component of the RAG, we find the midpoint of each confidence interval and use the midpoints to rank the RAG … т for RAG ranking with the ARES LLM judge …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jeong_study_2023, title = {A study on the implementation of generative ai services using an enterprise data-based llm application architecture}, author = {Jeong, C.}, year = {2023}, url = {https://arxiv.org/abs/2309.01105}, journal = {arXiv preprint arXiv:2309.01105}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… , RAG informs the LLM of pertinent queries and associated reference materials in advance, mitigating hallucination … pertinent to LLM, as well as demarcates the realm of RAG that is the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{smith_strategic_2023, title = {Strategic knowledge transfer}, author = {Smith, Max Olan and Anthony, Thomas and Wellman, Michael P.}, year = {2023}, journal = {J. Mach. Learn. Res.}, volume = {24}, number = {1}, note = {Publisher: JMLR.org}, keywords = {empirical game theoretic analysis, multiagent learning, reinforcement learning, transfer learning, source: ACM}, abstract = {In the course of playing or solving a game, it is common to face a series of changing other-agent strategies. These strategies often share elements: the set of possible policies to play has overlap, and the policies are sampled at the beginning of play by possibly differing distributions. As it faces the series of strategies, therefore, an agent has the opportunity to transfer its learned play against the previously encountered other-agent policies. We tackle two problems: (1) how can learned responses transfer across changing opponent strategies, and (2) how can this transfer be used to reduced the cumulative cost of learning in game solving. The first problem we characterize as the strategic knowledge transfer problem. For value-based response policies, we demonstrate that Q-Mixing approximately solves this problem by appropriately averaging the component Q-values. Solutions to the first problem can be applied to reduce the computational cost of learning-based game solving algorithms. We offer two algorithms that operate within the Policy-Space Response Oracles (PSRO) framework. Mixed-Oracles reduces the per-policy construction cost by transferring responses from previously encountered opponents. Mixed-Opponents performs strategic knowledge transfer by combining the previously encountered opponents into a single novel policy. Experimental evaluation of these methods on general-sum grid-world games provide evidence about their advantages and limitations in comparison to standard PSRO.}, issn = {1532-4435}, month = {jan}, } @article{wang_survey_2023, title = {Survey on factuality in large language models: {Knowledge}, author = {Wang, C. and Liu, X. and Yue, Y. and Tang, X. and Zhang, T. and {...}, year = {2023}, url = {https://arxiv.org/abs/2310.07521}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM factuality, emphasizing key metrics, benchmarks, and studies. We further explore strategies for enhancing LLM factuality… This framework primarily assesses the RAG system’s ability …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{asai_self-rag_2023-1, title = {Self-rag: {Self}, author = {Asai, A. and Wu, Z. and Wang, Y. and Sil, A. and {...}, year = {2023}, url = {https://openreview.net/forum?id=jbNjgmE0OP}, journal = {NeurIPS 2023 workshop on …}, note = {Publisher: openreview.net}, keywords = {source: Google Scholar}, abstract = {… This work aims to improve the factuality of LLM outputs, the lack of which continues to cause numerous real-world problems (eg, spread of misinformation and provision of incorrect and …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ornik_learning_2021, title = {Learning and planning for time-varying {MDPs}, author = {Ornik, Melkior and Topcu, Ufuk}, year = {2021}, journal = {J. Mach. Learn. Res.}, volume = {22}, number = {1}, note = {Publisher: JMLR.org}, keywords = {changing environment, Markov decision processes, maximum likelihood estimation, online learning, uncertainty quantification, source: ACM}, abstract = {This paper proposes a formal approach to online learning and planning for agents operating in a priori unknown, time-varying environments. The proposed method computes the maximally likely model of the environment, given the observations about the environment made by an agent earlier in the system run and assuming knowledge of a bound on the maximal rate of change of system dynamics. Such an approach generalizes the estimation method commonly used in learning algorithms for unknown Markov decision processes with time-invariant transition probabilities, but is also able to quickly and correctly identify the system dynamics following a change. Based on the proposed method, we generalize the exploration bonuses used in learning for time-invariant Markov decision processes by introducing a notion of uncertainty in a learned time-varying model, and develop a control policy for time-varying Markov decision processes based on the exploitation and exploration trade-off. We demonstrate the proposed methods on four numerical examples: a patrolling task with a change in system dynamics, a two-state MDP with periodically changing outcomes of actions, a wind ow estimation task, and a multi-armed bandit problem with periodically changing probabilities of different rewards.}, issn = {1532-4435}, month = {jan}, } @article{chavan_global-local_2025, title = {Global-{Local}, author = {Chavan, Apala Lahiri and Sivasubramaniam, Revathy}, year = {2025}, journal = {J. User Exper.}, volume = {19}, number = {3}, pages = {115--122}, note = {Place: Bloomingdale, IL Publisher: Usability Professionals' Association}, keywords = {source: ACM}, abstract = {We live in a connected world in which people and places are closer than ever, thanks to advances in technology and transportation. This interconnectedness has opened huge global markets for products and services which, for designers, presents both exciting opportunities and tough challenges. Designing for people from different cultures is difficult because it involves catering to a need—the core characteristic of the product—but in a way that aligns with their cultural expectations. It is a careful balance because excessive localization, or too little of it, can result in failure. Notable examples are American companies such as Mattel®, Home Depot®, and Best Buy™, which struggled in China due to differences in how people shop there. Even as big a player as Google™ has faced tough competition in places like South Korea.}, issn = {1931-3357}, month = {feb}, } @article{barry_graphrag_2025, title = {Graphrag: leveraging graph-based efficiency to minimize hallucinations in llm-driven rag for finance data}, author = {Barry, M. and Caillaut, G. and Halftermeyer, P. and Qader, R. and {...}, year = {2025}, url = {https://hal.science/hal-04907346/}, journal = {… Knowledge Graph \& …}, note = {Publisher: hal.science}, keywords = {source: Google Scholar}, abstract = {… DeepEval relies on a strong LLM to automatically score RAG … In order to evaluate the propensity to hallucinate, we report in … a good proxy for hallucination because we expect the LLM’s …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhu_graph-based_2025, title = {Graph-based {Approaches}, author = {Zhu, Z. and Huang, T. and Wang, K. and Ye, J. and Chen, X. and {...}, year = {2025}, url = {https://arxiv.org/abs/2504.10499}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM capabilities but also provide actionable strategies for leveraging graph expertise to advance RAG … in many RAG systems by serving as structured repositories of factual knowledge. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{da_ge-chat_2025, title = {{GE}, author = {Da, L. and Shah, P. M. and Liou, K. R. and Zhang, J. and Wei, H.}, year = {2025}, url = {https://arxiv.org/abs/2505.10143}, journal = {arXiv preprint arXiv:2505.10143}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… trust issues among users. To tackle such issue, this paper proposes GE-Chat, a knowledge Graph enhanced retrieval-augmented generation … We compare with the direct LLM source …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{filice_generating_2025, title = {Generating {Diverse}, author = {Filice, S. and Horowitz, G. and Carmel, D. and Karnin, Z. and {...}, year = {2025}, url = {https://arxiv.org/abs/2501.12789}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Enhancing llm factual accuracy with rag to counter hallucinations: A case study on domain-specific queries in private knowledge-bases. arXiv preprint arXiv:2403.10446 (2024). [18] …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{filice_generating_2025-1, title = {Generating {Q}, author = {Filice, S. and Horowitz, G. and Carmel, D. and Karnin, Z. and {...}, year = {2025}, url = {https://aclanthology.org/2025.acl-industry.33/}, journal = {Proceedings of the …}, note = {Publisher: aclanthology.org}, keywords = {source: Google Scholar}, abstract = {… LLM (Claude Sonnet 3.5). Appendix D provides further details about the metrics, as well as the LLM … Enhancing llm factual accuracy with rag to counter hallucinations: A case study on …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{patel_graph-enhanced_2025, title = {Graph-{Enhanced}, author = {Patel, P.}, year = {2025}, url = {https://arxiv.org/abs/2509.14267}, journal = {arXiv preprint arXiv:2509.14267}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… a novel retrieval-augmented generation (RAG) … the factual grounding. We examine recent advances in knowledge-augmented RAG and chatbots based on large language models (LLM…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{mavromatis_gnn-rag_2025, title = {Gnn-rag: {Graph}, author = {Mavromatis, C. and Karypis, G.}, year = {2025}, url = {https://aclanthology.org/2025.findings-acl.856/}, journal = {Findings of the Association for …}, note = {Publisher: aclanthology.org}, keywords = {source: Google Scholar}, abstract = {… The input given to the LLM contains the KG factual information along with the question and a prompt. For instance, the input becomes “Knowledge: Jamaica → language\_spoken → …}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{muller_grouse_2025, title = {{GroUSE}, author = {Muller, Sacha and Loison, António and Omrani, Bilel and Viaud, Gautier}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218500040&partnerID=40&md5=6a46fd103e200b5feb9cc139a0cc2f17}, booktitle = {Proceedings - {International}, pages = {4510 -- 4534}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{cerqueira_grounded_2025, title = {Grounded {Ethical}, author = {Cerqueira, Jose Antonio Siqueira De and Khan, Ayman Asad and Rousi, Rebekah A. and Xi, Nannan and Hamari, Juho J. and Kemell, Kai Kristian and Abrahamsson, Pekka}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218445480&partnerID=40&md5=177ec8602df7141e5ba2d379301de978}, booktitle = {{CEUR}, volume = {3921}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{cutler_stochastic_2024, title = {Stochastic {Approximation}, author = {Cutler, Joshua and Díaz, Mateo and Drusvyatskiy, Dmitriy}, year = {2024}, journal = {J. Mach. Learn. Res.}, volume = {25}, number = {1}, note = {Publisher: JMLR.org}, keywords = {asymptotic normality, decision-dependent distributions, local asymptotic minimax optimality, performative prediction, stochastic approximation, source: ACM}, abstract = {We analyze a stochastic approximation algorithm for decision-dependent problems, wherein the data distribution used by the algorithm evolves along the iterate sequence. The primary examples of such problems appear in performative prediction and its multiplayer extensions. We show that under mild assumptions, the deviation between the average iterate of the algorithm and the solution is asymptotically normal, with a covariance that clearly decouples the effects of the gradient noise and the distributional shift. Moreover, building on the work of Hájek and Le Cam, we show that the asymptotic performance of the algorithm with averaging is locally minimax optimal.}, issn = {1532-4435}, month = {jan}, } @inproceedings{barnett_seven_2024-1, title = {Seven {Failure}, author = {Barnett, Scott and Kurniawan, Stefanus and Thudumu, Srikanth and Brannelly, Zach and Abdelrazek, Mohamed}, year = {2024}, booktitle = {2024 {IEEE}, pages = {194--199}, keywords = {Case Study, Chatbots, Education, Information retrieval, RAG, Retrieval Augmented Generation, Robustness, SE4AI, Semantic search, Software, Task analysis, source: IEEE}, abstract = {Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.CCS CONCEPTS• Software and its engineering → Empirical software validation.}, month = {apr}, } @article{martin_semantic_2024, title = {Semantic verification in large language model-based retrieval augmented generation}, author = {Martin, A. and Witschel, H. F. and Mandl, M. and {...}, year = {2024}, url = {https://ojs.aaai.org/index.php/AAAI-SS/article/view/31199}, journal = {Proceedings of the AAAI …}, note = {Publisher: ojs.aaai.org}, keywords = {source: Google Scholar}, abstract = {… verification in Large Language Model-based Retrieval Augmented Generation (LLM-RAG) … Large Language Models (LLMs) in maintaining factual integrity, this research proposes an …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{nguyen_sfr-rag_2024, title = {Sfr-rag: {Towards}, author = {Nguyen, X. P. and Pandit, S. and Purushwalkam, S. and Xu, A. and {...}, year = {2024}, url = {https://arxiv.org/abs/2409.09916}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… SFRRAG, a small LLM that is instruction-tuned with an emphasis on context-grounded generation and hallucination … on the generator LLM component of the RAG framework. Traditional …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{joren_sufficient_2024, title = {Sufficient context: {A}, author = {Joren, H. and Zhang, J. and Ferng, C. S. and Juan, D. C. and Taly, A. and {...}, year = {2024}, url = {https://arxiv.org/abs/2411.06037}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Building on our findings, we explore ways to reduce hallucinations in RAG systems, including a new selective … Another line of study aims to reduce LLM hallucinations in RAG settings. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{bora_systematic_2024-1, title = {Systematic analysis of retrieval-augmented generation-based llms for medical chatbot applications}, author = {Bora, A. and Cuayáhuitl, H.}, year = {2024}, url = {https://www.mdpi.com/2504-4990/6/4/116}, journal = {Machine Learning and Knowledge Extraction}, note = {Publisher: mdpi.com Type: HTML}, keywords = {source: Google Scholar}, abstract = {… of RAG systems to mitigate hallucinations [13], a prevalent issue with LLMs. Hallucination … When an LLM receives a query, the RAG system employs the same embedding model used …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{li_simple_2024, title = {Simple is effective: {The}, author = {Li, M. and Miao, S. and Li, P.}, year = {2024}, url = {https://arxiv.org/abs/2410.20724}, journal = {arXiv preprint arXiv:2410.20724}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… To evaluate the capability of LLM reasoners in knowledge-grounded hallucination-free question answering, we introduce WebQSP-sub and CWQ-sub, where we remove samples …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yu_simulated_2024, title = {Simulated patient systems are intelligent when powered by large language model-based {AI}, author = {Yu, H. and Zhou, J. and Li, L. and Chen, S. and Gallifant, J. and {...}, year = {2024}, url = {https://www.researchgate.net/profile/Huizi-Yu/publication/384447372_AIPatient_Simulating_Patients_with_EHRs_and_LLM_Powered_Agentic_Workflow/links/66fd50b1869f1104c6c3dba0/AIPatient-Simulating-Patients-with-EHRs-and-LLM-Powered-Agentic-Workflow.pdf}, journal = {arXiv preprint arXiv …}, note = {Publisher: researchgate.net Type: PDF}, keywords = {source: Google Scholar}, abstract = {… Reasoning RAG leverages six LLM powered agents spanning tasks including retrieval, KG … Our Reasoning RAG agentic framework improves accuracy and minimizes hallucination risk…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{tang_symphony_2024, title = {Symphony: {Towards}, author = {Tang, N. and Yang, C. and Zhang, Z. and Luo, Y. and Fan, J. and {...}, year = {2024}, url = {http://sites.computer.org/debull/A24dec/p135.pdf}, journal = {IEEE Data Eng …}, note = {Publisher: sites.computer.org}, keywords = {source: Google Scholar}, abstract = {… trust in LLM outputs. By 2023, analysts estimated that chatbots hallucinate as much as 27\% of the time1, and factual … natural language question Q requiring factual or objective answers, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ong_surgeryllm_2024, title = {{SurgeryLLM}, author = {Ong, C. S. and Obey, N. T. and Zheng, Y. and Cohan, A. and {...}, year = {2024}, url = {https://www.nature.com/articles/s41746-024-01391-3}, journal = {npj Digital …}, note = {Publisher: nature.com Type: HTML}, keywords = {source: Google Scholar}, abstract = {… RAG improves LLM output by incorporating information from an approved, trusted, curated … We sought to assess the feasibility of and potential benefits of incorporating RAG in a LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kortukov_studying_2024, title = {Studying large language model behaviors under context-memory conflicts with real documents}, author = {Kortukov, E. and Rubinstein, A. and Nguyen, E. and Oh, S. J.}, year = {2024}, url = {https://arxiv.org/abs/2404.16032}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… -world RAG application and allows us to study LLM knowledge-… , or irrelevant documents into the LLM prompt. However, … goal is to achieve factual correctness using RAG. Asserting the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{saleh_sg-rag_2024, title = {{SG}, author = {Saleh, A. O. M. and Tür, G. and Saygin, Y.}, year = {2024}, url = {https://aclanthology.org/2024.icnlsp-1.45.pdf}, journal = {Proceedings of the 7th International …}, note = {Publisher: aclanthology.org Type: PDF}, keywords = {source: Google Scholar}, abstract = {… Large Language Models (LLM) such as GPT3 and Llama tend to hallucinate, especially for … LLM for our evaluation. To analyze that issue further, we evaluated SG-RAG, and RAG on the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{arslan_sustainable_2024, title = {Sustainable digitalization of business with multi-agent rag and llm}, author = {Arslan, M. and Munawar, S. and Cruz, C.}, year = {2024}, url = {https://www.sciencedirect.com/science/article/pii/S1877050924023627}, journal = {Procedia Computer Science}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… and enhance factuality and reasoning in LLMs. MetaGPT [33] introduces a specialized LLM … AutoGen2 [11], an open-source framework, enables developers to create LLM applications …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{iannelli_sla_2024, title = {{SLA}, author = {Iannelli, M. and Kuchipudi, S. and Dvorak, V.}, year = {2024}, url = {https://arxiv.org/abs/2412.06832}, journal = {arXiv preprint arXiv:2412.06832}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… hallucination, ie the generation of false assertions [10]. Retrieval Augmented Generation (RAG) … , enabling the LLM to function as a reasoning layer rather than a static repository of facts. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{garigliotti_sdg_2024, title = {{SDG}, author = {Garigliotti, D.}, year = {2024}, url = {https://aclanthology.org/2024.climatenlp-1.19/}, journal = {Proceedings of the 1st Workshop on Natural …}, note = {Publisher: aclanthology.org}, keywords = {source: Google Scholar}, abstract = {… by an LLM to refer to each passage that the LLM considers to … allowing that the LLM may hallucinate typical reference … as expected that ChatGPT is the best performing LLM in several …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{liu_stall_2024, title = {Stall+: {Boosting}, author = {Liu, J. and Chen, Y. and Liu, M. and Peng, X. and Lou, Y.}, year = {2024}, url = {https://arxiv.org/abs/2406.10018}, journal = {arXiv preprint arXiv:2406.10018}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG with individual or multiple integration strategies can further substantially improve LLM-based … To mitigate the hallucination of LLM-based generation, there is an increasing body of …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{fossi_swiftdossier_2024, title = {Swiftdossier: {Tailored}, author = {Fossi, G. and Boulaimen, Y. and Outemzabet, L. and Jeanray, N. and {...}, year = {2024}, url = {https://arxiv.org/abs/2409.15817}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of an advanced RAG system can help the LLM to … citations to allow us to track back which sources are used for each section and slide. For example, when the LLM is using the RAG, the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{arslan_sustainable_2024-1, title = {Sustainable {Energy}, author = {Arslan, M. and Munawar, S. and Sibilla, M.}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10836639/}, journal = {… International Conference on …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… This section starts by describing the process of creating a dataset aimed at enhancing RAG-LLM-based IS, developed for the Energy sector to serve as an Energy QA Assistant. The …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kortukov_studying_2024-1, title = {Studying large language model behaviors under realistic knowledge conflicts}, author = {Kortukov, E. and Rubinstein, A. and Nguyen, E. and Oh, S. J.}, year = {2024}, url = {https://openreview.net/forum?id=N0VeagzHq1}, journal = {CoRR}, note = {Publisher: openreview.net}, keywords = {source: Google Scholar}, abstract = {… : Retrieval-augmented generation (RAG) mitigates many problems of fully parametric language models, such as temporal degradation, hallucinations, and lack of grounding. In RAG, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{li_seeing_2024, title = {Seeing is believing: {Black}, author = {Li, Y. and Liu, G. and Yang, Y. and Wang, C.}, year = {2024}, url = {https://ui.adsabs.harvard.edu/abs/2024arXiv240619234L/abstract}, journal = {arXiv e-prints}, note = {Publisher: ui.adsabs.harvard.edu}, keywords = {source: Google Scholar}, abstract = {… to mitigate common LLM issues such as hallucinations and outdated … RAG systems, making them susceptible to attacks like jailbreaks and prompt injections, the security of the RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{noauthor_sigir-ap_2024, title = {{SIGIR}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215525372&partnerID=40&md5=2e14aa68b7e9aa3ebcc889b137a9122e}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{noauthor_sicsa-reallm_2024, title = {{SICSA}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210021824&partnerID=40&md5=a37311d16502cece39ea494853bb34f1}, booktitle = {{CEUR}, volume = {3822}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{collado-montanez_separating_2024, title = {Separating {Linguistic}, author = {Collado-Montañez, Jaime}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207942482&partnerID=40&md5=1cbd34555c4d57f3f6b225758090062d}, booktitle = {{CEUR}, volume = {3797}, pages = {173 -- 177}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{asai_self-rag_2024, title = {{SELF}, author = {Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avirup and Hajishirzi, Hannaneh}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200583576&partnerID=40&md5=11f85d13cc96fb96d39fbb16ba5f717d}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 126}, } @article{chalumeau_qdax_2024, title = {{QDax}, author = {Chalumeau, Felix and Lim, Bryan and Boige, Raphaël and Allard, Maxime and Grillotti, Luca and Flageat, Manon and Macé, Valentin and Richard, Guillaume and Flajolet, Arthur and Pierrot, Thomas and Cully, Antoine}, year = {2024}, journal = {J. Mach. Learn. Res.}, volume = {25}, number = {1}, note = {Publisher: JMLR.org}, keywords = {source: ACM}, abstract = {qdax is an open-source library with a streamlined and modular API for Quality-Diversity (QD) optimisation algorithms in jax. The library serves as a versatile tool for optimisation purposes, ranging from black-box optimisation to continuous control. QDAX offers implementations of popular QD, Neuroevolution, and Reinforcement Learning (RL) algorithms, supported by various examples. All the implementations can be just-in-time compiled with JAX, facilitating efficient execution across multiple accelerators, including GPUs and TPUs. These implementations effectively demonstrate the framework's flexibility and user-friendliness, easing experimentation for research purposes. Furthermore, the library is thoroughly documented and has 93\% test coverage.}, month = {jan}, issn = {1532-4435}, } @article{raina_question-based_2024, title = {Question-based retrieval using atomic units for enterprise rag}, author = {Raina, V. and Gales, M.}, year = {2024}, url = {https://arxiv.org/abs/2405.12363}, journal = {arXiv preprint arXiv:2405.12363}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM using the RAG pipeline. … RAG as the information content of the context is based on extracts from novels. As the stories are fictional and not factual, the parametric memory of an LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{beauchemin_quebec_2024, title = {Quebec {Automobile}, author = {Beauchemin, David and Gagnon, Zachary and Khoury, Richard}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216927418&partnerID=40&md5=555e93fb7f633adc5844318ab0f77446}, pages = {48 -- 60}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{hang_under-bagging_2022, title = {Under-bagging nearest neighbors for imbalanced classification}, author = {Hang, Hanyuan and Cai, Yuchao and Yang, Hanfang and Lin, Zhouchen}, year = {2022}, journal = {J. Mach. Learn. Res.}, volume = {23}, number = {1}, note = {Publisher: JMLR.org}, keywords = {arithmetic mean measure, bagging, ensemble learning, imbalanced classification, k-nearest neighbors, learning theory, optimal convergence rates, under-sampling, source: ACM}, abstract = {In this paper, we propose an ensemble learning algorithm called under-bagging k-nearest neighbors (under-bagging k-NN) for imbalanced classification problems. On the theoretical side, by developing a new learning theory analysis, we show that with properly chosen parameters, i.e., the number of nearest neighbors k, the expected sub-sample size s, and the bagging rounds B, optimal convergence rates for under-bagging k-NN can be achieved under mild assumptions w.r.t. the arithmetic mean (AM) of recalls. Moreover, we show that with a relatively small B, the expected sub-sample size s can be much smaller than the number of training data n at each bagging round, and the number of nearest neighbors k can be reduced simultaneously, especially when the data are highly imbalanced, which leads to substantially lower time complexity and roughly the same space complexity. On the practical side, we conduct numerical experiments to verify the theoretical results on the benefits of the under-bagging technique by the promising AM performance and efficiency of our proposed algorithm.}, issn = {1532-4435}, month = {jan}, } @article{patterson_generalized_2022, title = {A generalized projected bellman error for off-policy value estimation in reinforcement learning}, author = {Patterson, Andrew and White, Adam and White, Martha}, year = {2022}, journal = {J. Mach. Learn. Res.}, volume = {23}, number = {1}, note = {Publisher: JMLR.org}, keywords = {off-policy learning, reinforcement learning, temporal difference learning, source: ACM}, abstract = {Many reinforcement learning algorithms rely on value estimation, however, the most widely used algorithms–namely temporal difference algorithms–can diverge under both off-policy sampling and nonlinear function approximation. Many algorithms have been developed for off-policy value estimation based on the linear mean squared projected Bellman error (PBE) and are sound under linear function approximation. Extending these methods to the nonlinear case has been largely unsuccessful. Recently, several methods have been introduced that approximate a different objective–the mean-squared Bellman error (BE)– which naturally facilitate nonlinear approximation. In this work, we build on these insights and introduce a new generalized PBE that extends the linear PBE to the nonlinear setting. We show how this generalized objective unifies previous work and obtain new bounds for the value error of the solutions of the generalized objective. We derive an easy-to-use, but sound, algorithm to minimize the generalized objective, and show that it is more stable across runs, is less sensitive to hyperparameters, and performs favorably across four control domains with neural network function approximation.}, issn = {1532-4435}, month = {jan}, } @article{zhang_global_2022, title = {Global optimality and finite sample analysis of softmax off-policy actor critic under state distribution mismatch}, author = {Zhang, Shangtong and Des Combes, Remi Tachet and Laroche, Romain}, year = {2022}, journal = {J. Mach. Learn. Res.}, volume = {23}, number = {1}, note = {Publisher: JMLR.org}, keywords = {actor-critic, density ratio, distribution Mismatch, off-policy learning, policy gradient, source: ACM}, abstract = {In this paper, we establish the global optimality and convergence rate of an off-policy actor critic algorithm in the tabular setting without using density ratio to correct the discrepancy between the state distribution of the behavior policy and that of the target policy. Our work goes beyond existing works on the optimality of policy gradient methods in that existing works use the exact policy gradient for updating the policy parameters while we use an approximate and stochastic update step. Our update step is not a gradient update because we do not use a density ratio to correct the state distribution, which aligns well with what practitioners do. Our update is approximate because we use a learned critic instead of the true value function. Our update is stochastic because at each step the update is done for only the current state action pair. Moreover, we remove several restrictive assumptions from existing works in our analysis. Central to our work is the finite sample analysis of a generic stochastic approximation algorithm with time-inhomogeneous update operators on time-inhomogeneous Markov chains, based on its uniform contraction properties.}, issn = {1532-4435}, month = {jan}, } @article{zhang_truncated_2022, title = {Truncated emphatic temporal difference methods for prediction and control}, author = {Zhang, Shangtong and Whiteson, Shimon}, year = {2022}, journal = {J. Mach. Learn. Res.}, volume = {23}, number = {1}, note = {Publisher: JMLR.org}, keywords = {approximate value iteration, emphatic methods, finite sample analysis, off-policy learning, reinforcement learning, source: ACM}, abstract = {Emphatic Temporal Diérence (TD) methods are a class of off-policy Reinforcement Learning (RL) methods involving the use of followon traces. Despite the theoretical success of emphatic TD methods in addressing the notorious deadly triad of off-policy RL, there are still two open problems. First, followon traces typically suffer from large variance, making them hard to use in practice. Second, though Yu (2015) confirms the asymptotic convergence of some emphatic TD methods for prediction problems, there is still no finite sample analysis for any emphatic TD method for prediction, much less control. In this paper, we address those two open problems simultaneously via using truncated followon traces in emphatic TD methods. Unlike the original followon traces, which depend on all previous history, truncated followon traces depend on only finite history, reducing variance and enabling the finite sample analysis of our proposed emphatic TD methods for both prediction and control.}, issn = {1532-4435}, month = {jan}, } @article{zhang_dynamic_2021, title = {Dynamic tensor recommender systems}, author = {Zhang, Yanqing and Bi, Xuan and Tang, Niansheng and Qu, Annie}, year = {2021}, journal = {J. Mach. Learn. Res.}, volume = {22}, number = {1}, note = {Publisher: JMLR.org}, keywords = {contextual information, dynamic recommender systems, polynomial spline approximation, prediction interval, product sales forecasting, source: ACM}, abstract = {Recommender systems have been extensively used by the entertainment industry, business marketing and the biomedical industry. In addition to its capacity of providing preference-based recommendations as an unsupervised learning methodology, it has been also proven useful in sales forecasting, product introduction and other production related businesses. Since some consumers and companies need a recommendation or prediction for future budget, labor and supply chain coordination, dynamic recommender systems for precise forecasting have become extremely necessary. In this article, we propose a new recommendation method, namely the dynamic tensor recommender system (DTRS), which aims particularly at forecasting future recommendation. The proposed method utilizes a tensor-valued function of time to integrate time and contextual information, and creates a time-varying coefficient model for temporal tensor factorization through a polynomial spline approximation. Major advantages of the proposed method include competitive future recommendation predictions and effective prediction interval estimations. In theory, we establish the convergence rate of the proposed tensor factorization and asymptotic normality of the spline coefficient estimator. The proposed method is applied to simulations, IRI marketing data and Last.fm data. Numerical studies demonstrate that the proposed method outperforms existing methods in terms of future time forecasting.}, issn = {1532-4435}, month = {jan}, } @article{henderson_towards_2020, title = {Towards the systematic reporting of the energy and carbon footprints of machine learning}, author = {Henderson, Peter and Hu, Jieru and Romoff, Joshua and Brunskill, Emma and Jurafsky, Dan and Pineau, Joelle}, year = {2020}, journal = {J. Mach. Learn. Res.}, volume = {21}, number = {1}, note = {Publisher: JMLR.org}, keywords = {climate change, deep learning, energy efficiency, green computing, reinforcement learning, source: ACM}, abstract = {Accurate reporting of energy and carbon usage is essential for understanding the potential climate impacts of machine learning research. We introduce a framework that makes this easier by providing a simple interface for tracking realtime energy consumption and carbon emissions, as well as generating standardized online appendices. Utilizing this framework, we create a leaderboard for energy efficient reinforcement learning algorithms to incentivize responsible research in this area as an example for other areas of machine learning. Finally, based on case studies using our framework, we propose strategies for mitigation of carbon emissions and reduction of energy consumption. By making accounting easier, we hope to further the sustainable development of machine learning experiments and spur more research into energy efficient algorithms.}, issn = {1532-4435}, month = {jan}, } @article{namer_what_2025, title = {What 96 {Designers}, author = {Namer, Lexi and Joines, Sharon}, year = {2025}, journal = {J. User Exper.}, volume = {20}, number = {3}, pages = {125--142}, note = {Place: Bloomingdale, IL Publisher: Usability Professionals' Association}, keywords = {digital product design, ethical awareness, harm reduction, harm-aware design, survey, user experience design, source: ACM}, abstract = {Potential harm within digital product design has long been underexplored, despite the growing influence that consumer-facing digital products exert on individuals' daily lives. This paper presents the methodology and findings from an online survey conducted with 96 US-based UX- and product-designers working on customer-facing digital products. The survey focused on the attitudes, behaviors, challenges, and needs that designers encounter while considering harm in their daily work. Our findings resulted in several recommendations for future research to develop practice-based design solutions that enable designers to more effectively identify, discuss, and mitigate potential harm stemming from their work.}, month = {may}, issn = {1931-3357}, } @article{zeng_worse_2025, title = {Worse than zero-shot? a fact-checking dataset for evaluating the robustness of rag against misleading retrievals}, author = {Zeng, L. and Gupta, R. and Motwani, D. and Yang, D. and {...}, year = {2025}, url = {https://arxiv.org/abs/2502.16101}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Retrieval-augmented generation (RAG) systems have shown significant promise in mitigating LLM hallucination and enhancing trustworthiness. By combining the generative …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zou_weak--strong_2025, title = {Weak-to-{Strong}, author = {Zou, D. and Chen, Y. and Li, M. and Miao, S. and Liu, C. and Han, B. and {...}, year = {2025}, url = {https://arxiv.org/abs/2506.22518}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… reduce hallucinations. However, LLMs often rely on a weak retriever in graph-based RAG: I) … Recent efforts in text-based RAG have explored using LLM feedback to directly optimize the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{cohen_wixqa_2025, title = {Wixqa: {A}, author = {Cohen, D. and Burg, L. and Pykhnivskyi, S. and Gur, H. and {...}, year = {2025}, url = {https://arxiv.org/abs/2505.08643}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… context and avoided introducing factual errors or hallucinations. For our experiments, we utilized GPT-4o as the LLM judge for this metric. • Context Recall: An LLM-based judge metric …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_what_2025-1, title = {What are {Models}, author = {Wang, P. and Liu, Y. and Lu, Y. and Hong, J. and Wu, Y.}, year = {2025}, url = {https://arxiv.org/abs/2502.13490}, journal = {arXiv preprint arXiv:2502.13490}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of RAG on LLM inference. For each question, the answer was converted into a retrieval-augmented knowledge base (RAG) to assist the LLM. … : with and without RAG. Features such as …}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{zhang_wikigenbench_2025, title = {{WIKIGENBENCH}, author = {Zhang, Jiebin and Yu, Eugene J. and Chen, Qinyu and Xiong, Chenhao and Zhu, Dawei and Qian, Han and Song, Mingbo and Xiong, Weimin and Li, Xiaoguang and Liu, Qun and Li, Sujian}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218502400&partnerID=40&md5=4ab1f3c4ddd441a0d6652f76a00cfc69}, booktitle = {Proceedings - {International}, pages = {5191 -- 5210}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{noauthor_workshop_2025, title = {Workshop on {Generative}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217667532&partnerID=40&md5=37ba42220fa19d6f67561cd2dd5e4328}, booktitle = {Proceedings - {International}, volume = {2025-January}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{noauthor_workshop_2025-1, title = {Workshop on {Advanced}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009784071&partnerID=40&md5=5c4e3510f1d89763919f44fbcd1a4f9b}, journal = {Lecture Notes in Computer Science}, volume = {15835 LNAI}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @misc{noauthor_ieee_nodate, title = {{IEEE}, url = {https://ieeexplore.proxyucr.elogim.com/search/searchresult.jsp?action=search&newsearch=true&matchBoolean=true&queryText=(%22All%20Metadata%22:%22retrieval-augmented%20generation%22%20OR%20%22All%20Metadata%22:%22RAG%22)%20AND%20(%22All%20Metadata%22:%22large%20language%20model%22%20OR%20%22All%20Metadata%22:%22LLM%22%20OR%20%22All%20Metadata%22:%22LLMs%22%20OR%20%22All%20Metadata%22:%22generative%20AI%22%20OR%20%22All%20Metadata%22:%22ChatGPT%22)%20AND%20(%22All%20Metadata%22:%22trust%22%20OR%20%22All%20Metadata%22:%22confidence%22%20OR%20%22All%20Metadata%22:%22credibility%22%20OR%20%22All%20Metadata%22:%22user%20perception%22%20OR%20%22All%20Metadata%22:%22perceived%20reliability%22%20OR%20%22All%20Metadata%22:%22overtrust%22%20OR%20%22All%20Metadata%22:%22calibration%22%20OR%20%22All%20Metadata%22:%22hallucination%22%20OR%20%22All%20Metadata%22:%22hallucinations%22%20OR%20%22All%20Metadata%22:%22factuality%22%20OR%20%22All%20Metadata%22:%22factual%20accuracy%22%20OR%20%22All%20Metadata%22:%22faithfulness%22%20OR%20%22All%20Metadata%22:%22citation%22%20OR%20%22All%20Metadata%22:%22citations%22%20OR%20%22All%20Metadata%22:%22reference%22%20OR%20%22All%20Metadata%22:%22source%20attribution%22%20OR%20%22All%20Metadata%22:%22provenance%22%20OR%20%22All%20Metadata%22:%22grounding%22%20OR%20%22All%20Metadata%22:%22explainable%20artificial%20intelligence%22%20OR%20%22All%20Metadata%22:%22explainable%20AI%22%20OR%20%22All%20Metadata%22:%22XAI%22%20%20%20%20%20%20OR%20%22All%20Metadata%22:%22interpretable%20AI%22%20OR%20%22All%20Metadata%22:%22interpretable%20artificial%20intelligence%22%20%20%20%20%20%20OR%20%22All%20Metadata%22:%22AI%20explainability%22%20OR%20%22All%20Metadata%22:%22AI%20interpretability%22%20%20%20%20%20%20OR%20%22All%20Metadata%22:%22transparent%20AI%22%20OR%20%22All%20Metadata%22:%22AI%20transparency%22%20%20%20%20%20%20OR%20%22All%20Metadata%22:%22model%20interpretability%22%20OR%20%22All%20Metadata%22:%22post-hoc%20explanation%22%20OR%20%22All%20Metadata%22:%22feature%20attribution%22)&ranges=2020_2025_Year}, keywords = {source: IEEE}, file = {IEEE Xplore Search Results:C\:\\Users\\Marco\\Zotero\\storage\\VQJXQ254\\searchresult.html:text/html}, urldate = {2025-10-26}, } @book{farris_notitle_2025, author = {Farris, Drew and Raff, Edward and Biderman, Stella}, year = {2025}, url = {https://ieeexplore.proxyucr.elogim.com/document/11079740}, publisher = {Manning}, note = {Publication Title: How Large Language Models Work}, keywords = {AI book, artificial intelligence, ChatGPT, Gemini, GPT, large language models, LLM application, machine learning, natural language processing, prompt engineering, retrieval augmented generation, RLHF, supervised fine-tuning, tokenization, transformers, source: IEEE}, abstract = {Learn how large language models like GPT and Gemini work under the hood in plain English. How Large Language Models Work translates years of expert research on Large Language Models into a readable, focused introduction to working with these amazing systems. It explains clearly how LLMs function, introduces the optimization techniques to fine-tune them, and shows how to create pipelines and processes to ensure your AI applications are efficient and error-free. In How Large Language Models Work you will learn how to: Test and evaluate LLMs Use human feedback, supervised fine-tuning, and Retrieval Augmented Generation (RAG) Reducing the risk of bad outputs, high-stakes errors, and automation bias Human-computer interaction systems Combine LLMs with traditional ML How Large Language Models Work is authored by top machine learning researchers at Booz Allen Hamilton, including researcher Stella Biderman, Director of AI/ML Research Drew Farris, and Director of Emerging AI Edward Raff. They lay out how LLM and GPT technology works in plain language that’s accessible and engaging for all.}, isbn = {978-1-63343-708-1}, } @book{kimothi_notitle_2025, author = {Kimothi, Abhinav}, year = {2025}, url = {https://ieeexplore.proxyucr.elogim.com/document/11079738}, publisher = {Manning}, note = {Publication Title: A Simple Guide to Retrieval Augmented Generation}, keywords = {AI hallucination reduction, AI pipelines, generative AI, knowledge base, LangChain, large language models, LLMs, OpenAI, prompt engineering, Python AI, RAG evaluation, RAG guide, RAG tools, retrieval augmented generation, Transformers, vector databases, source: IEEE}, abstract = {Everything you need to know about Retrieval Augmented Generation in one human-friendly guide. Retrieval Augmented Generation—or RAG—enhances an LLM’s available data by adding context from an external knowledge base, so it can answer accurately about proprietary content, recent information, and even live conversations. RAG is powerful, and with A Simple Guide to Retrieval Augmented Generation, it’s also easy to understand and implement! In A Simple Guide to Retrieval Augmented Generation you’ll learn: The components of a RAG system How to create a RAG knowledge base The indexing and generation pipeline Evaluating a RAG system Advanced RAG strategies RAG tools, technologies, and frameworks A Simple Guide to Retrieval Augmented Generation gives an easy, yet comprehensive, introduction to RAG for AI beginners. You’ll go from basic RAG that uses indexing and generation pipelines, to modular RAG and multimodal data from images, spreadsheets, and more.}, isbn = {978-1-63343-585-8}, } @book{raieli_notitle_2025, author = {Raieli, Salvatore and Iuculano, Gabriele}, year = {2025}, url = {https://ieeexplore.proxyucr.elogim.com/document/11099035}, publisher = {Packt Publishing}, note = {Publication Title: Building AI Agents with LLMs, RAG, and Knowledge Graphs: A practical guide to autonomous and modern AI agents}, keywords = {source: IEEE}, abstract = {Master LLM fundamentals to advanced techniques like RAG, reinforcement learning, and knowledge graphs to build, deploy, and scale intelligent AI agents that reason, retrieve, and act autonomouslyKey FeaturesImplement RAG and knowledge graphs for advanced problem-solvingLeverage innovative approaches like LangChain to create real-world intelligent systemsIntegrate large language models, graph databases, and tool use for next-gen AI solutionsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionThis AI agents book addresses the challenge of building AI that not only generates text but also grounds its responses in real data and takes action. Authored by AI specialists with deep expertise in drug discovery and systems optimization, this guide empowers you to leverage retrieval-augmented generation (RAG), knowledge graphs, and agent-based architectures to engineer truly intelligent behavior. By combining large language models (LLMs) with up-to-date information retrieval and structured knowledge, you'll create AI agents capable of deeper reasoning and more reliable problem-solving. Inside, you'll find a practical roadmap from concept to implementation. You’ll discover how to connect language models with external data via RAG pipelines for increasing factual accuracy and incorporate knowledge graphs for context-rich reasoning. The chapters will help you build and orchestrate autonomous agents that combine planning, tool use, and knowledge retrieval to achieve complex goals. Concrete Python examples built on popular libraries, along with real-world case studies, reinforce each concept and show you how these techniques come together. By the end of this book, you’ll be well-equipped to build intelligent AI agents that reason, retrieve, and interact dynamically, empowering you to deploy powerful AI solutions across industries.What you will learnLearn how LLMs work, their structure, uses, and limits, and design RAG pipelines to link them to external dataBuild and query knowledge graphs for structured context and factual groundingDevelop AI agents that plan, reason, and use tools to complete tasksIntegrate LLMs with external APIs and databases to incorporate live dataApply techniques to minimize hallucinations and ensure accurate outputsOrchestrate multiple agents to solve complex, multi-step problemsOptimize prompts, memory, and context handling for long-running tasksDeploy and monitor AI agents in production environmentsWho this book is forIf you are a data scientist or researcher who wants to learn how to create and deploy an AI agent to solve limitless tasks, this book is for you. To get the most out of this book, you should have basic knowledge of Python and Gen AI. This book is also excellent for experienced data scientists who want to explore state-of-the-art developments in LLM and LLM-based applications.}, isbn = {978-1-83508-038-2}, } @book{anthapu_notitle_2025, author = {Anthapu, Ravindranatha and Agarwal, Siddhant and Webber, Dr. Jim and Risch, Dr. Julian}, year = {2025}, url = {https://ieeexplore.proxyucr.elogim.com/document/11099031}, publisher = {Packt Publishing}, note = {Publication Title: Building Neo4j-Powered Applications with LLMs: Create LLM-driven search and recommendations applications with Haystack, LangChain4j, and Spring AI}, keywords = {source: IEEE}, abstract = {A comprehensive guide to building cutting-edge generative AI applications using Neo4j's knowledge graphs and vector search capabilitiesKey FeaturesDesign vector search and recommendation systems with LLMs using Neo4j GenAI, Haystack, Spring AI, and LangChain4jApply best practices for graph exploration, modeling, reasoning, and performance optimizationBuild and consume Neo4j knowledge graphs and deploy your GenAI apps to Google CloudPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionEmbark on an expert-led journey into building LLM-powered applications using Retrieval-Augmented Generation (RAG) and Neo4j knowledge graphs. Written by Ravindranatha Anthapu, Principal Consultant at Neo4j, and Siddhant Agrawal, a Google Developer Expert in GenAI, this comprehensive guide is your starting point for exploring alternatives to LangChain, covering frameworks such as Haystack, Spring AI, and LangChain4j. As LLMs (large language models) reshape how businesses interact with customers, this book helps you develop intelligent applications using RAG architecture and knowledge graphs, with a strong focus on overcoming one of AI’s most persistent challenges—mitigating hallucinations. You'll learn how to model and construct Neo4j knowledge graphs with Cypher to enhance the accuracy and relevance of LLM responses. Through real-world use cases like vector-powered search and personalized recommendations, the authors help you build hands-on experience with Neo4j GenAI integrations across Haystack and Spring AI. With access to a companion GitHub repository, you’ll work through code-heavy examples to confidently build and deploy GenAI apps on Google Cloud. By the end of this book, you’ll have the skills to ground LLMs with RAG and Neo4j, optimize graph performance, and strategically select the right cloud platform for your GenAI applications.What you will learnDesign, populate, and integrate a Neo4j knowledge graph with RAGModel data for knowledge graphsIntegrate AI-powered search to enhance knowledge explorationMaintain and monitor your AI search application with HaystackUse LangChain4j and Spring AI for recommendations and personalizationSeamlessly deploy your applications to Google Cloud PlatformWho this book is forThis LLM book is for database developers and data scientists who want to leverage knowledge graphs with Neo4j and its vector search capabilities to build intelligent search and recommendation systems. Working knowledge of Python and Java is essential to follow along. Familiarity with Neo4j, the Cypher query language, and fundamental concepts of databases will come in handy.}, isbn = {978-1-83620-622-4}, } @book{de_notitle_2025, author = {De, Banibrata}, year = {2025}, url = {https://ieeexplore.proxyucr.elogim.com/document/11107332}, publisher = {Packt Publishing}, note = {Publication Title: Hands-On MLOps on Azure: Automate, secure, and scale ML workflows with the Azure ML CLI, GitHub, and LLMOps}, keywords = {source: IEEE}, abstract = {A practical guide to building, deploying, automating, monitoring, and scaling ML and LLM solutions in productionKey FeaturesBuild reproducible ML pipelines with Azure ML CLI and GitHub ActionsAutomate ML workflows end to end, including deployment and monitoringApply LLMOps principles to deploy and manage generative AI responsibly across cloudsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionEffective machine learning (ML) now demands not just building models but deploying and managing them at scale. Written by a seasoned senior software engineer with high-level expertise in both MLOps and LLMOps, Hands-On MLOps on Azure equips ML practitioners, DevOps engineers, and cloud professionals with the skills to automate, monitor, and scale ML systems across environments. The book begins with MLOps fundamentals and their roots in DevOps, exploring training workflows, model versioning, and reproducibility using pipelines. You'll implement CI/CD with GitHub Actions and the Azure ML CLI, automate deployments, and manage governance and alerting for enterprise use. The author draws on their production ML experience to provide you with actionable guidance and real-world examples. A dedicated section on LLMOps covers operationalizing large language models (LLMs) such as GPT-4 using RAG patterns, evaluation techniques, and responsible AI practices. You'll also work with case studies across Azure, AWS, and GCP that offer practical context for multi-cloud operations. Whether you're building pipelines, packaging models, or deploying LLMs, this guide delivers end-to-end strategy to build robust, scalable systems. By the end of this book, you'll be ready to design, deploy, and maintain enterprise-grade ML solutions with confidence. What you will learnUnderstand the DevOps to MLOps transitionBuild reproducible, reusable pipelines using the Azure ML CLISet up CI/CD for training and deployment workflowsMonitor ML applications and detect model/data driftCapture and secure governance and lineage dataOperationalize LLMs using RAG and prompt flowsApply MLOps across Azure, AWS, and GCP use casesWho this book is forThis book is for DevOps and Cloud engineers and SREs interested in or responsible for managing the lifecycle of machine learning models. Professionals who are already familiar with their ML workloads and want to improve their practices, or those who are new to MLOps and want to learn how to effectively manage machine learning models in this environment, will find this book beneficial. The book is also useful for technical decision-makers and project managers looking to understand the process and benefits of MLOps.}, isbn = {978-1-83620-032-1}, } @inproceedings{djoudi_notitle_2025, author = {Djoudi, Anya Amel Nait and null, null and null, null and Badache, Ismail and Chifu, Adrian Gabriel and Bellot, Patrice}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105019062765&partnerID=40&md5=9eb12756c985549ca3f719687c2de8d7}, booktitle = {{CEUR}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{borazio_notitle_2025, author = {Borazio, Federico and null, null and Croce, Danilo and Basili, Roberto}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105019054960&partnerID=40&md5=2a7a116863c4a3bafcf4d9b2c85568d6}, booktitle = {{CEUR}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{kim_notitle_2025, author = {Kim, To Eun and Coelho, João and Onilude, Gbemileke and null, null}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105019052751&partnerID=40&md5=0793589bbc7cf9cb419a1bbe4226846f}, booktitle = {{CEUR}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 1}, } @book{bourne_notitle_2024, author = {Bourne, Keith and Es, Shahul}, year = {2024}, url = {https://ieeexplore.proxyucr.elogim.com/document/10769240}, publisher = {Packt Publishing}, note = {Publication Title: Unlocking Data with Generative AI and RAG: Enhance generative AI systems by integrating internal data with large language models using RAG}, keywords = {source: IEEE}, abstract = {Leverage cutting-edge generative AI techniques such as RAG to realize the potential of your data and drive innovation as well as gain strategic advantageKey FeaturesOptimize data retrieval and generation using vector databasesBoost decision-making and automate workflows with AI agentsOvercome common challenges in implementing real-world RAG systemsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionGenerative AI is helping organizations tap into their data in new ways, with retrieval-augmented generation (RAG) combining the strengths of large language models (LLMs) with internal data for more intelligent and relevant AI applications. The author harnesses his decade of ML experience in this book to equip you with the strategic insights and technical expertise needed when using RAG to drive transformative outcomes. The book explores RAG’s role in enhancing organizational operations by blending theoretical foundations with practical techniques. You’ll work with detailed coding examples using tools such as LangChain and Chroma’s vector database to gain hands-on experience in integrating RAG into AI systems. The chapters contain real-world case studies and sample applications that highlight RAG’s diverse use cases, from search engines to chatbots. You’ll learn proven methods for managing vector databases, optimizing data retrieval, effective prompt engineering, and quantitatively evaluating performance. The book also takes you through advanced integrations of RAG with cutting-edge AI agents and emerging non-LLM technologies. By the end of this book, you’ll be able to successfully deploy RAG in business settings, address common challenges, and push the boundaries of what’s possible with this revolutionary AI technique.What you will learnUnderstand RAG principles and their significance in generative AIIntegrate LLMs with internal data for enhanced operationsMaster vectorization, vector databases, and vector search techniquesDevelop skills in prompt engineering specific to RAG and design for precise AI responsesFamiliarize yourself with AI agents' roles in facilitating sophisticated RAG applicationsOvercome scalability, data quality, and integration issuesDiscover strategies for optimizing data retrieval and AI interpretabilityWho this book is forThis book is for AI researchers, data scientists, software developers, and business analysts looking to leverage RAG and generative AI to enhance data retrieval, improve AI accuracy, and drive innovation. It is particularly suited for anyone with a foundational understanding of AI who seeks practical, hands-on learning. The book offers real-world coding examples and strategies for implementing RAG effectively, making it accessible to both technical and non-technical audiences. A basic understanding of Python and Jupyter Notebooks is required.}, isbn = {978-1-83588-791-2}, } @book{gheorghiu_notitle_2024, author = {Gheorghiu, Andrei}, year = {2024}, url = {https://ieeexplore.proxyucr.elogim.com/document/10540158}, publisher = {Packt Publishing}, note = {Publication Title: Building Data-Driven Applications with LlamaIndex: A practical guide to retrieval-augmented generation (RAG) to enhance LLM applications}, keywords = {source: IEEE}, abstract = {Solve real-world problems easily with artificial intelligence (AI) using the LlamaIndex data framework to enhance your LLM-based Python applications Key FeaturesExamine text chunking effects on RAG workflows and understand security in RAG app developmentDiscover chatbots and agents and learn how to build complex conversation enginesBuild as you learn by applying the knowledge you gain to a hands-on projectBook DescriptionDiscover the immense potential of Generative AI and Large Language Models (LLMs) with this comprehensive guide. Learn to overcome LLM limitations, such as contextual memory constraints, prompt size issues, real-time data gaps, and occasional ‘hallucinations’. Follow practical examples to personalize and launch your LlamaIndex projects, mastering skills in ingesting, indexing, querying, and connecting dynamic knowledge bases. From fundamental LLM concepts to LlamaIndex deployment and customization, this book provides a holistic grasp of LlamaIndex's capabilities and applications. By the end, you'll be able to resolve LLM challenges and build interactive AI-driven applications using best practices in prompt engineering and troubleshooting Generative AI projects.What you will learnUnderstand the LlamaIndex ecosystem and common use casesMaster techniques to ingest and parse data from various sources into LlamaIndexDiscover how to create optimized indexes tailored to your use casesUnderstand how to query LlamaIndex effectively and interpret responsesBuild an end-to-end interactive web application with LlamaIndex, Python, and StreamlitCustomize a LlamaIndex configuration based on your project needsPredict costs and deal with potential privacy issuesDeploy LlamaIndex applications that others can useWho this book is forThis book is for Python developers with basic knowledge of natural language processing (NLP) and LLMs looking to build interactive LLM applications. Experienced developers and conversational AI developers will also benefit from the advanced techniques covered in the book to fully unleash the capabilities of the framework.}, isbn = {978-1-80512-440-5}, } @book{bahree_notitle_2024, author = {Bahree, Amit}, year = {2024}, url = {https://ieeexplore.proxyucr.elogim.com/document/10745288}, publisher = {Manning}, note = {Publication Title: Generative AI in Action}, keywords = {architectural patterns, Bard, ChatGPT, Copilot, enterprise, ethics, hallucinations, integration, jailbreaks, LLMs, model fine tuning, multi-modality, prompt engineering, RAG, safety, source: IEEE}, abstract = {Generative AI can transform your business by streamlining the process of creating text, images, and code. This book will show you how to get in on the action! Generative AI in Action is the comprehensive and concrete guide to generative AI you’ve been searching for. It introduces both AI’s fundamental principles and its practical applications in an enterprise context—from generating text and images for product catalogs and marketing campaigns, to technical reporting, and even writing software. Inside, author Amit Bahree shares his experience leading Generative AI projects at Microsoft for nearly a decade, starting well before the current GPT revolution. Inside Generative AI in Action you will find: A practical overview of of generative AI applications Architectural patterns, integration guidance, and best practices for generative AI The latest techniques like RAG, prompt engineering, and multi-modality The challenges and risks of generative AI like hallucinations and jailbreaks How to integrate generative AI into your business and IT strategy Generative AI in Action is full of real-world use cases for generative AI, showing you where and how to start integrating this powerful technology into your products and workflows. You’ll benefit from tried-and-tested implementation advice, as well as application architectures to deploy GenAI in production at enterprise scale.}, isbn = {978-1-63343-694-7}, } @book{bustos_notitle_2024, author = {Bustos, Juan Pablo and Soria, Luis Lopez and Arsanjani, Dr. Ali}, year = {2024}, url = {https://ieeexplore.proxyucr.elogim.com/document/10769230}, publisher = {Packt Publishing}, note = {Publication Title: Generative AI Application Integration Patterns: Integrate large language models into your applications}, keywords = {source: IEEE}, abstract = {Unleash the transformative potential of GenAI with this comprehensive guide that serves as an indispensable roadmap for integrating large language models into real-world applications. Gain invaluable insights into identifying compelling use cases, leveraging state-of-the-art models effectively, deploying these models into your applications at scale, and navigating ethical considerations.Key FeaturesGet familiar with the most important tools and concepts used in real scenarios to design GenAI appsInteract with GenAI models to tailor model behavior to minimize hallucinationsGet acquainted with a variety of strategies and an easy to follow 4 step frameworks for integrating GenAI into applicationsBook DescriptionExplore the transformative potential of GenAI in the application development lifecycle. Through concrete examples, you will go through the process of ideation and integration, understanding the tradeoffs and the decision points when integrating GenAI. With recent advances in models like Google Gemini, Anthropic Claude, DALL-E and GPT-4o, this timely resource will help you harness these technologies through proven design patterns. We then delve into the practical applications of GenAI, identifying common use cases and applying design patterns to address real-world challenges. From summarization and metadata extraction to intent classification and question answering, each chapter offers practical examples and blueprints for leveraging GenAI across diverse domains and tasks. You will learn how to fine-tune models for specific applications, progressing from basic prompting to sophisticated strategies such as retrieval augmented generation (RAG) and chain of thought. Additionally, we provide end-to-end guidance on operationalizing models, including data prep, training, deployment, and monitoring. We also focus on responsible and ethical development techniques for transparency, auditing, and governance as crucial design patterns.What you will learnConcepts of GenAI: pre-training, fine-tuning, prompt engineering, and RAGFramework for integrating AI: entry points, prompt pre-processing, inference, post-processing, and presentationPatterns for batch and real-time integrationCode samples for metadata extraction, summarization, intent classification, question-answering with RAG, and moreEthical use: bias mitigation, data privacy, and monitoringDeployment and hosting options for GenAI modelsWho this book is forThis book is not an introduction to AI/ML or Python. It offers practical guides for designing, building, and deploying GenAI applications in production. While all readers are welcome, those who benefit most include: Developer engineers with foundational tech knowledge Software architects seeking best practices and design patterns Professionals using ML for data science, research, etc., who want a deeper understanding of Generative AI Technical product managers with a software development background This concise focus ensures practical, actionable insights for experienced professionals}, isbn = {978-1-83588-761-5}, } @book{palmer_notitle_2024, author = {Palmer, Rachelle and Perlmutter, Ben and Gangadhar, Ashwin and Larew, Nicholas and Narváez, Sigfrido and Rueckstiess, Thomas and Weller, Henry and Alake, Richmond and Ranjan, Shubham}, year = {2024}, url = {https://ieeexplore.proxyucr.elogim.com/document/10769331}, publisher = {Packt Publishing}, note = {Publication Title: Building AI Intensive Python Applications: Create intelligent apps with LLMs and vector databases}, keywords = {source: IEEE}, abstract = {Master retrieval-augmented generation architecture and fine-tune your AI stack, along with discovering real-world use cases and best practices to create powerful AI appsKey FeaturesGet to grips with the fundamentals of LLMs, vector databases, and Python frameworksImplement effective retrieval-augmented generation strategies with MongoDB AtlasOptimize AI models for performance and accuracy with model compression and deployment optimizationPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionThe era of generative AI is upon us, and this book serves as a roadmap to harness its full potential. With its help, you’ll learn the core components of the AI stack: large language models (LLMs), vector databases, and Python frameworks, and see how these technologies work together to create intelligent applications. The chapters will help you discover best practices for data preparation, model selection, and fine-tuning, and teach you advanced techniques such as retrieval-augmented generation (RAG) to overcome common challenges, such as hallucinations and data leakage. You’ll get a solid understanding of vector databases, implement effective vector search strategies, refine models for accuracy, and optimize performance to achieve impactful results. You’ll also identify and address AI failures to ensure your applications deliver reliable and valuable results. By evaluating and improving the output of LLMs, you’ll be able to enhance their performance and relevance. By the end of this book, you’ll be well-equipped to build sophisticated AI applications that deliver real-world value.What you will learnUnderstand the architecture and components of the generative AI stackExplore the role of vector databases in enhancing AI applicationsMaster Python frameworks for AI developmentImplement Vector Search in AI applicationsFind out how to effectively evaluate LLM outputOvercome common failures and challenges in AI developmentWho this book is forThis book is for software engineers and developers looking to build intelligent applications using generative AI. While the book is suitable for beginners, a basic understanding of Python programming is required to make the most of it.}, isbn = {978-1-83620-724-5}, } @book{antic_notitle_2024, author = {Antić, Zhenya and Chakravarty, Saurabh}, year = {2024}, url = {https://ieeexplore.proxyucr.elogim.com/document/10769274}, publisher = {Packt Publishing}, note = {Publication Title: Python Natural Language Processing Cookbook: Over 60 recipes for building powerful NLP solutions using Python and LLM libraries}, keywords = {source: IEEE}, abstract = {Updated to include three new chapters on transformers, natural language understanding (NLU) with explainable AI, and dabbling with popular LLMs from Hugging Face and OpenAIKey FeaturesLeverage ready-to-use recipes with the latest LLMs, including Mistral, Llama, and OpenAI modelsUse LLM-powered agents for custom tasks and real-world interactionsGain practical, in-depth knowledge of transformers and their role in implementing various NLP tasks with open-source and advanced LLMsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionHarness the power of Natural Language Processing to overcome real-world text analysis challenges with this recipe-based roadmap written by two seasoned NLP experts with vast experience transforming various industries with their NLP prowess. You’ll be able to make the most of the latest NLP advancements, including large language models (LLMs), and leverage their capabilities through Hugging Face transformers. Through a series of hands-on recipes, you’ll master essential techniques such as extracting entities and visualizing text data. The authors will expertly guide you through building pipelines for sentiment analysis, topic modeling, and question-answering using popular libraries like spaCy, Gensim, and NLTK. You’ll also learn to implement RAG pipelines to draw out precise answers from a text corpus using LLMs. This second edition expands your skillset with new chapters on cutting-edge LLMs like GPT-4, Natural Language Understanding (NLU), and Explainable AI (XAI)—fostering trust and in your NLP models. By the end of this book, you'll be equipped with the skills to apply advanced text processing techniques, use pre-trained transformer models, build custom NLP pipelines to extract valuable insights from text data to drive informed decision-making.What you will learnUnderstand fundamental NLP concepts along with their applications using examples in PythonClassify text quickly and accurately with rule-based and supervised methodsTrain NER models and perform sentiment analysis to identify entities and emotions in textExplore topic modeling and text visualization to reveal themes and relationships within textLeverage Hugging Face and OpenAI LLMs to perform advanced NLP tasksUse question-answering techniques to handle both open and closed domainsApply XAI techniques to better understand your model predictionsWho this book is forThis updated edition of the Python Natural Language Processing Cookbook is for data scientists, machine learning engineers, and developers with a background in Python. Whether you’re looking to learn NLP techniques, extract valuable insights from textual data, or create foundational applications, this book will equip you with basic to intermediate skills. No prior NLP knowledge is necessary to get started. All you need is familiarity with basic programming principles. For seasoned developers, the updated sections offer the latest on transformers, explainable AI, and Generative AI with LLMs.}, isbn = {978-1-80324-144-9}, } @book{meyer_notitle_2024, author = {Meyer, Lucas A.}, year = {2024}, url = {https://ieeexplore.proxyucr.elogim.com/document/10769215}, publisher = {Packt Publishing}, note = {Publication Title: Building AI Applications with Microsoft Semantic Kernel: Easily integrate generative AI capabilities and copilot experiences into your applications}, keywords = {source: IEEE}, abstract = {Unlock the power of GenAI by effortlessly linking your C\# and Python apps with cutting-edge models, orchestrating diverse AI services with finesse, and crafting bespoke applications through immersive, real-world examplesKey FeaturesLink your C\# and Python applications with the latest AI models from OpenAICombine and orchestrate different AI services such as text and image generatorsCreate your own AI apps with real-world use case examples that show you how to use basic generative AI, create images, process documents, use a vector databasePurchase of the print or Kindle book includes a free PDF eBookBook DescriptionIn the fast-paced world of AI, developers are constantly seeking efficient ways to integrate AI capabilities into their apps. Microsoft Semantic Kernel simplifies this process by using the GenAI features from Microsoft and OpenAI. Written by Lucas A. Meyer, a Principal Research Scientist in Microsoft’s AI for Good Lab, this book helps you get hands on with Semantic Kernel. It begins by introducing you to different generative AI services such as GPT-3.5 and GPT-4, demonstrating their integration with Semantic Kernel. You’ll then learn to craft prompt templates for reuse across various AI services and variables. Next, you’ll learn how to add functionality to Semantic Kernel by creating your own plugins. The second part of the book shows you how to combine multiple plugins to execute complex actions, and how to let Semantic Kernel use its own AI to solve complex problems by calling plugins, including the ones made by you. The book concludes by teaching you how to use vector databases to expand the memory of your AI services and how to help AI remember the context of earlier requests. You’ll also be guided through several real-world examples of applications, such as RAG and custom GPT agents. By the end of this book, you'll have gained the knowledge you need to start using Semantic Kernel to add AI capabilities to your applications.What you will learnWrite reusable AI prompts and connect to different AI providersCreate new plugins that extend the capabilities of AI servicesUnderstand how to combine multiple plugins to execute complex actionsOrchestrate multiple AI services to accomplish a taskLeverage the powerful planner to automatically create appropriate AI callsUse vector databases as additional memory for your AI tasksDeploy your application to ChatGPT, making it available to hundreds of millions of usersWho this book is forThis book is for beginner-level to experienced .NET or Python software developers who want to quickly incorporate the latest AI technologies into their applications, without having to learn the details of every new AI service. Product managers with some development experience will find this book helpful while creating proof-of-concept applications. This book requires working knowledge of programming basics.}, isbn = {978-1-83546-959-0}, } @inproceedings{cummings_rag_2025, title = {{RAG}, author = {Cummings, Aaron and Zhang, Xinyue and Olaniran, Mercy and Akintomide, Modupe}, year = {2025}, booktitle = {2025 {IEEE}, pages = {139--143}, note = {ISSN: 2832-2975}, keywords = {Computational modeling, Context modeling, Dementia, FineTuning, Healthcare, Large Language Model, Large language models, Pipelines, Question Answering, Question answering (information retrieval), Retrieval augmented generation, Retrieval Augmented Generation, Scalability, Terminology, Training, source: IEEE}, abstract = {In closed-domain Question Answering (QA), Large Language Models (LLMs) often fail to deliver responses specialized enough for niche subdomains. Broadly trained models may not capture the nuanced terminology and contextual precision required in these fields, which frequently lack domain-specific conversational data and face computational constraints. To address this, we propose a methodology leveraging a Retrieval-Augmented Generation (RAG) framework that integrates data extraction with fine-tuning using domain-specific question-answer pairs. Our approach employs Question-Answer Generation (QAG) to create tailored training datasets, enabling fine-tuned models to incorporate specialized jargon and context while remaining computationally accessible to domain experts. To exemplify this methodology, we demonstrate its application within the medical domain through a case study centered on the creation of a dementia care chat assistant. A significant benefit of this approach lies in its ease of replication across various domains and scalability for integration into diverse user groups, making it a versatile solution for enhancing chat assistants.CCS Concepts• Computing methodologies → Natural language generation; • Human-centered computing → Natural language interfaces.}, month = {jun}, } @incollection{bergeret_retrievalx2010augmented_2025, title = {Retrieval\&\#x2010;{Augmented}, author = {Bergeret, Olivier and Abbasi, Asif and Farvault, Joel}, year = {2025}, url = {https://ieeexplore.proxyucr.elogim.com/document/10982315}, booktitle = {{GenAI}, pages = {263--294}, publisher = {Wiley}, keywords = {Accuracy, Adaptation models, Artificial intelligence, Data models, Information retrieval, Knowledge based systems, Large language models, Prompt engineering, Retrieval augmented generation, Soft sensors, source: IEEE}, abstract = {{\textless}, isbn = {978-1-394-28130-5}, } @article{mortaheb_rag-check_2025-1, title = {Rag-check: {Evaluating}, author = {Mortaheb, M. and Khojastepour, M. A. A. and {...}, year = {2025}, url = {https://arxiv.org/abs/2501.03995}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… In particular, multi-modal RAG systems process each … provided to the LLM in the final stage of the RAG system along … that provide hallucination scores specifically for multi-modal RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_retrieval-augmented_2025-1, title = {Retrieval-augmented generation with conflicting evidence}, author = {Wang, H. and Prasad, A. and Stengel-Eskin, E. and {...}, year = {2025}, url = {https://arxiv.org/abs/2504.13079}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… using the parametric knowledge of the LLM (ie, the No RAG baseline which does not see … , making it harder for the LLM to distinguish factual documents from inaccurate ones. These …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sardana_real-time_2025, title = {Real-{Time}, author = {Sardana, A.}, year = {2025}, url = {https://arxiv.org/abs/2503.21157}, journal = {arXiv preprint arXiv:2503.21157}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… between 0 and 1 indicating how confident we can be that the … while hallucination sometimes refers to specific types of LLM … (ie what ultimately matters to users of a real RAG system). …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{gan_retrieval_2025, title = {Retrieval {Augmented}, author = {Gan, A. and Yu, H. and Zhang, K. and Liu, Q. and Yan, W. and Huang, Z. and {...}, year = {2025}, url = {https://arxiv.org/abs/2504.14891}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… for RAG evaluation, bridging traditional and LLM-driven methods, and serves as a critical resource for advancing RAG … method to measure the hallucination in RAG, which indicates the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yu_rag-kg-il_2025, title = {Rag-kg-il: {A}, author = {Yu, H. Q. and McQuade, F.}, year = {2025}, url = {https://arxiv.org/abs/2503.13514}, journal = {arXiv preprint arXiv:2503.13514}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… than RAG-only but generates significantly more hallucinations when measured against our provided ground truth. To summarise, RAG-KG-IL … In contrast, RAG-only shows the highest …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{xiao_retrieval-augmented_2025, title = {Retrieval-{Augmented}, author = {Xiao, L. and Dai, W. and Chen, S. and Qin, B. and Shi, C. and Jing, H. and {...}, year = {2025}, url = {https://arxiv.org/abs/2501.05475}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… credible evidence, our work builds an effective RAG framework to address the hallucination … Settings We choose GLM4-9B-chat(THUDM 2024) LLM as the base LLM for all baseline and …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zheng_retrieval_2025, title = {Retrieval augmented generation and understanding in vision: {A}, author = {Zheng, X. and Weng, Z. and Lyu, Y. and Jiang, L. and Xue, H. and Ren, B. and {...}, year = {2025}, url = {https://arxiv.org/abs/2503.18016}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… [8] investigate the integration of knowledge graphs with LLM-based RAG systems. Zhou et al. [9] focus on … We divide it into RAG-related datasets and hallucination detection datasets. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{spielberger_retrieval_2025, title = {Retrieval {Augmented}, author = {Spielberger, G. and Artinger, F. M. and Reb, J. and {...}, year = {2025}, url = {https://arxiv.org/abs/2502.20963}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of LLM agents (in our case the ReAct agent) for Agentic RAG … (2024b) addressed the issue of hallucinations in LLM-based … reduced the number of hallucinated topics while producing …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{berman_retrieval_2025-1, title = {Retrieval augmented therapy suggestion for molecular tumor boards: algorithmic development and validation study}, author = {Berman, E. and Malek, H. Sundberg and Bitzer, M. and Malek, N. and {...}, year = {2025}, url = {https://www.jmir.org/2025/1/e64364/}, journal = {Journal of Medical …}, note = {Publisher: jmir.org Type: HTML}, keywords = {source: Google Scholar}, abstract = {… As shown in Table 1, we do not instruct the LLM to cite a specified number of sources. As a … In this study, we developed a RAG approach to LLM text generation to develop treatment …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhu_radio_2025-1, title = {Radio: {Real}, author = {Zhu, J. and Guo, H. and Shi, W. and Chen, Z. and Meo, P. De}, year = {2025}, url = {https://ojs.aaai.org/index.php/AAAI/article/view/34809}, journal = {Proceedings of the AAAI …}, note = {Publisher: ojs.aaai.org}, keywords = {source: Google Scholar}, abstract = {… enhanced real-time hallucination detection approach for triggering retrieval within dynamic RAG frameworks which takes into … The woRAG means the LLM does not apply any RAG. SR-…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ren_retrieval-augmented_2025, title = {Retrieval-{Augmented}, author = {Ren, T. and Zhang, Z. and Jia, B. and Zhang, S.}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S0957417425009285}, journal = {Expert Systems with Applications}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… This paper proposed a novel Retrieval-Augmented Generation (RAG)-aided model to assist in identifying the causes of aviation safety incidents. The model consists of a retrieval …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{akbar_retrieval_2025, title = {Retrieval {Augmented}, author = {Akbar, K. A. and Uddin, M. N. and Khan, L. and Hockstad, T. and {...}, year = {2025}, url = {https://arxiv.org/abs/2505.18426}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM hallucination in legal contexts is critical due to: 1) the … Specifically, RAG mitigates LLM hallucinations by supplying … To this end, we develop a RAG-based LLM capable of …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhang_ratt_2025-1, title = {Ratt: {A}, author = {Zhang, J. and Wang, X. and Ren, W. and Jiang, L. and Wang, D. and {...}, year = {2025}, url = {https://ojs.aaai.org/index.php/AAAI/article/view/34876}, journal = {Proceedings of the AAAI …}, note = {Publisher: ojs.aaai.org}, keywords = {source: Google Scholar}, abstract = {… LLM thought structures. With optimized tree structure and RAG, our method is capable of reducing factual … pθ with parameters θ, we aim to enhance the performance of LLM on task A …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{hu_removal_2025, title = {Removal of {Hallucination}, author = {Hu, W. and Zhang, W. and Jiang, Y. and Zhang, C. J. and Wei, X. and {...}, year = {2025}, url = {https://arxiv.org/abs/2505.18581}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… The capabilities of MAD align well with the second-order hallucination problem in RAG, and this … We provide detailed comparisons of average LLM and retrieval calls on StrategyQA, as …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{pradhan_ragevalx_2025, title = {{RAGEvalX}, author = {Pradhan, R.}, year = {2025}, url = {https://ijctece.com/index.php/IJCTEC/article/view/170}, journal = {International Journal of Computer Technology and …}, note = {Publisher: ijctece.com}, keywords = {source: Google Scholar}, abstract = {… ABSTRACT: Retrieval-Augmented Generation (RAG) has emerged as a cornerstone for building context-aware and factual Large Language Model (LLM) applications. However, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{mohsin_retrieval_2025-1, title = {Retrieval augmented generation with multi-modal llm framework for wireless environments}, author = {Mohsin, M. A. and Bilal, A. and Bhattacharya, S. and {...}, year = {2025}, url = {https://arxiv.org/abs/2503.07670}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… captured in real time to train the RAG-based LLM for wireless environment perception. Due to … RAG-based LLM models do not hallucinate much in comparison to fine-tuned models due …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{li_r3-rag_2025, title = {R3-{RAG}, author = {Li, Y. and Luo, Q. and Li, X. and Li, B. and Cheng, Q. and Wang, B. and {...}, year = {2025}, url = {https://arxiv.org/abs/2505.23794}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… factual correctness and mitigate hallucination. However, dense retrievers often become the bottleneck of RAG … R3-RAG, which uses Reinforcement learning to make the LLM learn how …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{grislain_rag_2025-1, title = {Rag with differential privacy}, author = {Grislain, N.}, year = {2025}, url = {https://ieeexplore.ieee.org/abstract/document/11050672/}, journal = {2025 IEEE Conference on Artificial Intelligence …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… (RAG) has emerged as the dominant technique to provide Large Language Models (LLM) with fresh and relevant context, mitigating the risk of hallucinations and improving the overall …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{gan_rag-mcp_2025, title = {Rag-mcp: {Mitigating}, author = {Gan, T. and Sun, Q.}, year = {2025}, url = {https://arxiv.org/abs/2505.03275}, journal = {arXiv preprint arXiv:2505.03275}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… In particular, RAG-MCP yields substantially higher accuracy in choosing the appropriate tool and reduces errors such as hallucinated or mis-parameterized function calls. These results …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{mostafa_rag-enabled_2025, title = {Rag-enabled intent reasoning for application-network interaction}, author = {Mostafa, S. and Abdel-Aziz, M. K. and Elbamby, M. S. and {...}, year = {2025}, url = {https://arxiv.org/abs/2505.09339}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… translation, and avoid hallucination in the translated intents. … -RAG framework compared to LLM and vanilla-RAG benchmarks… it to an LLM (no-RAG) model, where a prompt and LLM are …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{tavasoli_responsible_2025, title = {Responsible innovation: {A}, author = {Tavasoli, A. and Sharbaf, M. and Madani, S. M.}, year = {2025}, url = {https://arxiv.org/abs/2504.02165}, journal = {arXiv preprint arXiv:2504.02165}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… deploy RAG for up-to-date references while using parameter-efficient tuning to embed … could opt for a proprietary model supplemented by RAG for continuous factual grounding. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{pang_reconstruction_2025, title = {Reconstruction of landslide events using {LLM}, author = {Pang, H. and Lo, M. K. and Leung, Y. F. and Wu, S.}, year = {2025}, url = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5340542}, journal = {Available at SSRN 5340542}, note = {Publisher: papers.ssrn.com}, keywords = {source: Google Scholar}, abstract = {… In 100 this study, RAG is applied to extract … agentic LLM that processes witness accounts and 154 outputs a report summarizing technical information related to a landslide, with citations …}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{wang_richrag_2025, title = {{RichRAG}, author = {Wang, Shuting and Yu, Xin and Wang, Mang and Chen, Weipeng and Zhu, Yutao and Dou, Zhicheng}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218504376&partnerID=40&md5=b9da46758fa9e42f0738a175e81c6b7f}, booktitle = {Proceedings - {International}, pages = {11317 -- 11333}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 1}, } @inproceedings{tel_rag_2025, title = {{RAG}, author = {Tel, Tolga}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011097591&partnerID=40&md5=66aa434fab68d9b661e5968829a77de3}, booktitle = {{CEUR}, volume = {3993}, pages = {111 -- 115}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{sun_redeep_2025, title = {{REDEEP}, author = {Sun, Zhongxiang and Zang, Xiaoxue and Zheng, Kai and Xu, Jun and Zhang, Xiao and Yu, Weijie and Song, Yang and Li, Han}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010266950&partnerID=40&md5=cfa5652cea20f146a799c650cf61b723}, pages = {102578 -- 102607}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 2}, } @inproceedings{jiang_reasoning-enhanced_2025, title = {{REASONING}, author = {Jiang, Pengcheng and Xiao, Cao and Jiang, Minhao and Bhatia, Parminder and Kass-Hout, Taha and Sun, Jimeng and Han, Jiawei}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010212722&partnerID=40&md5=78ab38187148116e3f71a2cdb4633838}, pages = {14546 -- 14591}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 1}, } @inproceedings{li_rag-ddr_2025, title = {{RAG}, author = {Li, Xinze and Mei, Sen and Liu, Zhenghao and Yan, Yukun and Wang, Shuo and Yu, Shi and Zeng, Zheni and Chen, Hao and Yu, Ge and Liu, Zhiyuan and Sun, Maosong and Xiong, Chenyan}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010192409&partnerID=40&md5=062d8b94f694546fa9222ecf653b2932}, pages = {68459 -- 68480}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 1}, } @inproceedings{malandri_re-fin_2025, title = {{RE}, author = {Malandri, Lorenzo and Mercorio, Fabio and Mezzanzanica, Mario and Pallucchini, Filippo}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000193593&partnerID=40&md5=3b2a76a600b0c14951c93a70f06f01e8}, booktitle = {Proceedings - {International}, pages = {751 -- 759}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{li_enhancing_2024-1, title = {Enhancing llm factual accuracy with rag to counter hallucinations: {A}, author = {Li, J. and Yuan, Y. and Zhang, Z.}, year = {2024}, url = {https://arxiv.org/abs/2403.10446}, journal = {arXiv preprint arXiv:2403.10446}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG pipeline with upstream datasets processing and downstream performance evaluation. Addressing the challenge of LLM hal… This research highlights the potential of RAG systems in …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{lee_enhancing_2024-1, title = {Enhancing large language model reliability: minimizing hallucinations with dual retrieval-augmented generation based on the latest diabetes guidelines}, author = {Lee, J. and Cha, H. and Hwangbo, Y. and Cheon, W.}, year = {2024}, url = {https://www.mdpi.com/2075-4426/14/12/1131}, journal = {Journal of Personalized Medicine}, note = {Publisher: mdpi.com Type: HTML}, keywords = {source: Google Scholar}, abstract = {… novel retrieval system to enhance LLM reliability in diabetes … a dual retrieval-augmented generation (RAG) system … an effective dual RAG system that enhances LLM reliability in …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_evaluating_2024, title = {Evaluating quality of answers for retrieval-augmented generation: {A}, author = {Wang, Y. and Hernandez, A. G. and Kyslyi, R. and {...}, year = {2024}, url = {https://arxiv.org/abs/2406.18064}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of answer quality evaluation in Retrieval-Augmented Generation (RAG) applications using vRAG… grading hallucinations, we fix the temperature parameter for each LLM call at T = 0.0. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{da_evidencechat_2024, title = {Evidencechat: {A}, author = {Da, L. and Shah, P. M. and Singh, A. and Wei, H.}, year = {2024}, url = {https://www.researchgate.net/profile/Parth-Shah-142/publication/385173895_EvidenceChat_A_RAG_Enhanced_LLM_Framework_for_Trustworthy_and_Evidential_Response_Generation/links/671983dadf4b534d4eeddf46/EvidenceChat-A-RAG-Enhanced-LLM-Framework-for-Trustworthy-and-Evidential-Response-Generation.pdf}, journal = {… A RAG Enhanced LLM …}, note = {Publisher: researchgate.net Type: PDF}, keywords = {source: Google Scholar}, abstract = {… upon the retrieval augmented generation agent (RAG agent), … the process of constructing the RAG agent, and then explain … Towards mitigating LLM hallucination via self reflection. In …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{li_enhanced_2024, title = {Enhanced large language models-based legal query responses through retrieval augmented generation}, author = {Li, R.}, year = {2024}, url = {https://books.google.com/books?hl=en\&lr=\&id=RpUjEQAAQBAJ\&oi=fnd\&pg=PA237\&dq=%22retrieval+augmented+generation%22%7C%22rag%22+%22large+language+model%22%7C%22llm%22%7C%22chatgpt%22+trust%7Cconfidence%7Ccredibility%7Challucination%7Cfactuality%7Ccitation\&ots=z7ads6N7Yw\&sig=ZddnJKk6QmuOAhvZUZpk_a_ZO4w}, journal = {Proceedings of the 2024 International Conference on …}, note = {Publisher: books.google.com}, keywords = {source: Google Scholar}, abstract = {… LLM solving law problems using RAG is proposed. RAG is used to overcome hallucination … evaluation, which indicates that the LLM’s hallucination problem is basically solved, and …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{gummadi_enhancing_2024-1, title = {Enhancing communication and data transmission security in rag using large language models}, author = {Gummadi, V. and Udayaraju, P. and Sarabu, V. R. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10763024/}, journal = {2024 4th …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… RAG with LLM produces more accurate results and essential user information. This can gain more trust … This paper proposes a large language model (LLM) to secure data in RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{abolghasemi_evaluation_2024, title = {Evaluation of {Attribution}, author = {Abolghasemi, A. and Azzopardi, L. and Hashemi, S. Hadi and {...}, year = {2024}, url = {https://ui.adsabs.harvard.edu/abs/2024arXiv241012380A/abstract}, journal = {arXiv e …}, note = {Publisher: ui.adsabs.harvard.edu}, keywords = {source: Google Scholar}, abstract = {… in RAG pipelines, namely attribution sensitivity and bias with respect to authorship information. We explicitly inform an LLM … documents can influence LLMs' trust, and how they attribute …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{pelletier_explainable_2024, title = {Explainable biomedical hypothesis generation via retrieval augmented generation enabled large language models}, author = {Pelletier, A. R. and Ramirez, J. and Adam, I. and Sankar, S. and {...}, year = {2024}, url = {https://arxiv.org/abs/2407.12888}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Retrieval-Augmented Generation (RAG) is a system designed to minimize LLM hallucinations… reliable and trustworthy sources, RAG grounds LLM responses in evidence, enhancing …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{singhal_evidence-backed_2024, title = {Evidence-backed fact checking using {RAG}, author = {Singhal, R. and Patwa, P. and Patwa, P. and Chadha, A. and {...}, year = {2024}, url = {https://arxiv.org/abs/2408.12060}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Answer Generation: After generating the question, we provide a single document to an LLM … ments in retrieval-augmented generation (RAG) pipelines which alleviate hallucination and …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhang_enhancing_2024, title = {Enhancing large language model performance to answer questions and extract information more accurately}, author = {Zhang, L. and Jijo, K. and Setty, S. and Chung, E. and Javid, F. and {...}, year = {2024}, url = {https://arxiv.org/abs/2402.01722}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of the LLM to be a financial chatbot that does not hallucinate … to the LLM the same way it would be in a traditional RAG … finance LLM, we need to develop a strong RAG model too, or …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{meduri_efficient_2024, title = {Efficient {RAG}, author = {Meduri, K. and Nadella, G. S. and Gonaygunta, H. and {...}, year = {2024}, url = {https://www.researchgate.net/profile/Karthik-Meduri/publication/380265505_Efficient_RAG_Framework_for_Large-Scale_Knowledge_Bases/links/66330b9a08aa54017ad48c42/Efficient-RAG-Framework-for-Large-Scale-Knowledge-Bases.pdf}, journal = {Efficient RAG …}, note = {Publisher: researchgate.net Type: PDF}, keywords = {source: Google Scholar}, abstract = {… to maximize LLM efficiency and resource usage, whereas RAG combines external … the generating process, RAG generates replies that are rich in background and factual. The …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{huang_embedding-informed_2024, title = {Embedding-{Informed}, author = {Huang, C. and Xia, Y. and Wang, R. and Xie, K. and Yu, T. and {...}, year = {2024}, url = {https://arxiv.org/abs/2404.03514}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Our approach reveals higher confidence in the LLM’s intrinsic knowledge than PARAG, resulting in fewer retrievals and more precise answers, demonstrating our method’s superior …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{darji_enhancing_2024-1, title = {Enhancing financial risk analysis using rag-based large language models}, author = {Darji, A. and Kheni, F. and Chodvadia, D. and Goel, P. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10841711/}, journal = {2024 3rd …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… Zhang, “Enhancing LLM factual accuracy with RAG to counter hallucinations: A case study on domain-specific queries in private knowledge-bases,” arXiv preprint arXiv:2403.10446, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{alinejad_evaluating_2024, title = {Evaluating the retrieval component in llm-based question answering systems}, author = {Alinejad, A. and Kumar, K. and Vahdat, A.}, year = {2024}, url = {https://arxiv.org/abs/2406.06458}, journal = {arXiv preprint arXiv:2406.06458}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… erating inaccurate responses or hallucinations. Although the … retrievers in Retrieval-Augmented Generation (RAG)-based … well as potential errors and hallucinations in their responses. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kim_enhancing_2024, title = {Enhancing {Scientific}, author = {Kim, S. and Mazumder, R.}, year = {2024}, url = {https://arxiv.org/abs/2409.15076}, journal = {arXiv preprint arXiv:2409.15076}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs). We describe the development of the BCO assistant tool that leverages RAG … as LLM hallucination and long…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{vidivelli_efficiency-driven_2024, title = {Efficiency-{Driven}, author = {Vidivelli, S. and Ramachandran, M. and {...}, year = {2024}, url = {https://file.sciopen.com/sciopen_public/1838514775850065922.pdf}, journal = {Computers, Materials \& …}, note = {Publisher: file.sciopen.com Type: PDF}, keywords = {source: Google Scholar}, abstract = {… RAG permits it to get to outer information for uncommon questions outside its pre-… and Factuality: Fine-tuning assists the LLM with learning area explicit wording and accurate data. RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{gutu_exploring_2024, title = {Exploring data analysis methods in generative models: from {Fine}, author = {Guțu, B. M. and Popescu, N.}, year = {2024}, url = {https://www.mdpi.com/2073-431X/13/12/327}, journal = {Computers}, note = {Publisher: mdpi.com Type: HTML}, keywords = {source: Google Scholar}, abstract = {… and timeliness in LLM outputs. By incorporating RAG, the problem of hallucination in LLMs is … the advantages of RAG by integrating real-time data retrieval with LLM capabilities, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{church_emerging_2024-1, title = {Emerging trends: a gentle introduction to {RAG}, author = {Church, K. W. and Sun, J. and Yue, R. and Vickers, P. and {...}, year = {2024}, url = {https://www.cambridge.org/core/journals/natural-language-engineering/article/emerging-trends-a-gentle-introduction-to-rag/4FF461F4066A0C16135F2D2849E3356A}, journal = {Natural Language …}, note = {Publisher: cambridge.org}, keywords = {source: Google Scholar}, abstract = {… Without RAG, an LLM trained on 2021 data would likely hallucinate when asked about 2023. RAG fills in gaps in the knowledge base by uploading a pdf file, sample\_files/World\_Series/…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{khaled_evaluating_2024, title = {Evaluating large language models for {Arabic}, author = {Khaled, S. and Mohamed, E. H. and Medhat, W.}, year = {2024}, url = {https://www.sciencedirect.com/science/article/pii/S1877050924030114}, journal = {Procedia Computer Science}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… experimenting generative generative LLMs and RAG models on text classification and … LLM model and the RAG methodology for handling the generative generative LLM hallucinations…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{rackauckas_evaluating_2024, title = {Evaluating rag-fusion with ragelo: an automated elo-based framework}, author = {Rackauckas, Z. and Câmara, A. and Zavrel, J.}, year = {2024}, url = {https://arxiv.org/abs/2406.14783}, journal = {arXiv preprint arXiv:2406.14783}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… ,” we leverage an LLM-as-a-judge process, where a strong LLM is used to evaluate the … the judging LLM, enabling higher reliability and trust when evaluating different RAG pipelines. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{saha_enhancing_2024, title = {Enhancing international graduate student experience through ai-driven support systems: {A}, author = {Saha, B. and Saha, U.}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10651944/}, journal = {… Conference on Data Science and Its …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… 3 shows that the custom RAG-LLM provides specific, … useful, whereas the regular LLM provides general information lacking … generate fabricated responses or hallucinate, the use of a …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chen_eyegpt_2024-1, title = {Eyegpt: {Ophthalmic}, author = {Chen, X. and Zhao, Z. and Zhang, W. and Xu, P. and Gao, L. and Xu, M. and {...}, year = {2024}, url = {https://arxiv.org/abs/2403.00840}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM designed specifically for ophthalmology, using three optimization strategies including role-playing, finetuning, and retrieval-augmented generation. In … In this study, hallucination …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{xue_enhanced_2024, title = {Enhanced multimodal rag-llm for accurate visual question answering}, author = {Xue, J. and Deng, Q. and Yu, F. and Wang, Y. and Wang, J. and Li, Y.}, year = {2024}, url = {https://arxiv.org/abs/2412.20927}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… an enhanced multimodal RAGLLM framework for accurate … Bing, “Can ChatGPT-like generative models guarantee factual … , “Overcoming llm challenges using rag-driven precision in …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{kieu_empowering_2024, title = {Empowering {Automotive}, author = {KIEU, K. and BERGSTRAND, O.}, year = {2024}, url = {https://gupea.ub.gu.se/handle/2077/83663}, publisher = {gupea.ub.gu.se}, keywords = {source: Google Scholar}, abstract = {… This study calls attention to the complex nature of hallucinations and errors that can occur even with accurate context. To overcome some of the challenges found in an …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{hsu_evaluating_2024, title = {Evaluating {ChatNetZero}, author = {Hsu, A. and Laney, M. and Zhang, J. and Manya, D. and {...}, year = {2024}, url = {https://openreview.net/forum?id=MmTaM7lmvu}, journal = {… meets Climate Change …}, note = {Publisher: openreview.net}, keywords = {source: Google Scholar}, abstract = {… a large-language model (LLM) chatbot developed through Retrieval-Augmented Generation (RAG… for our assessment of the factual accuracy of five LLM outputs, including ChatNetZero. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{nazar_enwar_2024, title = {Enwar: {A}, author = {Nazar, A. M. and Celik, A. and Selim, M. Y. and Abdallah, A. and {...}, year = {2024}, url = {https://arxiv.org/abs/2410.18104}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… assessment of an LLM’s capabilities across various metrics such as answer relevancy, factual correctness, and hallucinations avoidance. However, RAG-based systems require a more …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{roychowdhury_evaluation_2024, title = {Evaluation of rag metrics for question answering in the telecom domain}, author = {Roychowdhury, S. and Soman, S. and Ranjani, H. G. and {...}, year = {2024}, url = {https://arxiv.org/abs/2407.12873}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We establish, for RQ3, that Factual Correctness metric improves with instruction fine tuning … purposes in RAG pipeline. We demonstrate that domain adaptation of RAG LLM improves the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{al-zuraiqi_evaluating_2024, title = {Evaluating {Alignment}, author = {Al-Zuraiqi, A. and Greer, D.}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10903215/}, journal = {2024 International Conference on …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… These methods aim to eliminate LLM hallucination, where the model … Retrieval-Augmented Generation (RAG) and the training dataset as benchmark systems for the fine-tuned LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{gonzalez_exploring_2024, title = {Exploring augmentation and cognitive strategies for {AI}, author = {Gonzalez, R. A. and DiPaola, S.}, year = {2024}, url = {https://arxiv.org/abs/2404.10890}, journal = {arXiv preprint arXiv:2404.10890}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of whether LLM hallucinations can be directly equated to human hallucinations remains … Augmented RAG (Autonoesis): GPT-3.5 with RAG using the LLM-generated autobiography (…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhu_emerge_2024-1, title = {Emerge: {Integrating}, author = {Zhu, Y. and Ren, C. and Wang, Z. and Zheng, X. and Xie, S. and {...}, year = {2024}, url = {https://www.researchgate.net/profile/Zixiang-Wang-13/publication/381126633_EMERGE_Integrating_RAG_for_Improved_Multimodal_EHR_Predictive_Modeling/links/6668192da54c5f0b945da986/EMERGE-Integrating-RAG-for-Improved-Multimodal-EHR-Predictive-Modeling.pdf}, journal = {arXiv preprint arXiv …}, note = {Publisher: researchgate.net Type: PDF}, keywords = {source: Google Scholar}, abstract = {… Entities Refinement: Considering the hallucination issue associated with LLM, we design a … in the original text; secondly, we leverage LLM to filter entities not in disease type; and finally, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{lee_evaluating_2024, title = {Evaluating consistencies in llm responses through a semantic clustering of question answering}, author = {Lee, Y. and Kim, J.}, year = {2024}, url = {https://arxiv.org/abs/2410.15440}, journal = {arXiv preprint arXiv:2410.15440}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… as context like the RAG pattern or use Zero-shot-CoT to improve performance of LLM itself. We apply … We do not consider model confidence in this study, but plan to do so in future work. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jiang_efficient_2024, title = {Efficient knowledge infusion via {KG}, author = {Jiang, Z. and Zhong, L. and Sun, M. and Xu, J. and Sun, R. and Cai, H. and {...}, year = {2024}, url = {https://arxiv.org/abs/2406.03746}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… -hallucination responses. Firstly, we train a knowledge extraction model based on an LLM using … As for basic 2-shot RAG experiment on ChatGPT-3.5, although there is an improvement …}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{noauthor_emnlp_2024, title = {{EMNLP}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216812904&partnerID=40&md5=49be7e7d710a377b84f298b6f3133b41}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{penzkofer_evaluating_2024, title = {Evaluating and {Fine}, author = {Penzkofer, Vinzent and Baumann, Timo}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216766595&partnerID=40&md5=cc66e9b01a75d3eb9369b4416d744db3}, pages = {57 -- 64}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{oro_evaluating_2024, title = {Evaluating {Retrieval}, author = {Oro, Ermelinda and Granata, Francesco Maria and Lanza, Antonio and Bachir, Amir and de Grandis, Luca and Ruffolo, Massimo}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205590448&partnerID=40&md5=db794c2d8058e9c827a5d03c019d5441}, booktitle = {{CEUR}, volume = {3762}, pages = {129 -- 134}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{kang_c-rag_2024, title = {C-rag: {Certified}, author = {Kang, M. and Gürel, N. M. and Yu, N. and Song, D. and Li, B.}, year = {2024}, url = {https://arxiv.org/abs/2402.03181}, journal = {arXiv preprint arXiv:2402.03181}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… C-RAG, a novel framework to certify generation risks for RAG … for RAG models and certify an upper confidence bound of … of RAG is lower than that of the corresponding vanilla LLM in …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{yan_corrective_2024, title = {Corrective retrieval augmented generation}, author = {Yan, S. Q. and Gu, J. C. and Zhu, Y. and Ling, Z. H.}, year = {2024}, url = {https://openreview.net/forum?id=JnWJbrnaUE}, publisher = {openreview.net}, keywords = {source: Google Scholar}, abstract = {… (LLMs) inevitably exhibit hallucinations since the accuracy … LLM ChatGPT on the document retrieval results was shown in Table 4. The prompts of ChatGPT, ChatGPT-CoT, and ChatGPT…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jang_calibrated_2024, title = {Calibrated decision-making through llm-assisted retrieval}, author = {Jang, C. and Lee, H. and Lee, S. and Lee, J.}, year = {2024}, url = {https://arxiv.org/abs/2411.08891}, journal = {arXiv preprint arXiv:2411.08891}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… response z and the LLM’s confidence c. Our goal is to align the model confidence with accuracy of … an unseen LLM as the RAG model for decision-making task. We use Mistral-7B for the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{addison_c-fedrag_2024, title = {C-fedrag: {A}, author = {Addison, P. and Nguyen, M. T. H. and Medan, T. and Shah, J. and {...}, year = {2024}, url = {https://arxiv.org/abs/2412.13163}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG has emerged as a popular method that offers significant … for grounding LLMs in factual information (Shuster et al.… and impact of RAG-based systems in reducing LLM hallucinations, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yang_crag-comprehensive_2024, title = {Crag-comprehensive rag benchmark}, author = {Yang, X. and Sun, K. and Xin, H. and Sun, Y. and Bhalla, N. and {...}, year = {2024}, url = {https://proceedings.neurips.cc/paper_files/paper/2024/hash/1435d2d0fca85a84d83ddcb754f58c29-Abstract-Datasets_and_Benchmarks_Track.html}, journal = {Advances in …}, note = {Publisher: proceedings.neurips.cc}, keywords = {source: Google Scholar}, abstract = {… Retrieval-Augmented Generation (RAG) has recently emerged as a promising solution to alleviate Large Language Model (LLM… the Comprehensive RAG Benchmark (CRAG), a factual …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chen_controlling_2024-1, title = {Controlling risk of retrieval-augmented generation: a counterfactual prompting framework}, author = {Chen, L. and Zhang, R. and Guo, J. and Fan, Y. and Cheng, X.}, year = {2024}, url = {https://arxiv.org/abs/2409.16146}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… latent factors affecting RAG’s confidence in its predictions: … To guide RAG models in assessing their own confidence based … We find that risk control works better with ChatGPT than with …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{xu_crp-rag_2024, title = {Crp-rag: {A}, author = {Xu, K. and Zhang, K. and Li, J. and Huang, W. and Wang, Y.}, year = {2024}, url = {https://www.mdpi.com/2079-9292/14/1/47}, journal = {Electronics}, note = {Publisher: mdpi.com Type: HTML}, keywords = {source: Google Scholar}, abstract = {… CRP-RAG outperforms the best LLM and RAG baselines by 2.46 in open-… 4.2 in factual verification. Experiments also show the superior factual consistency and robustness of CRP-RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{singh_chunkrag_2024, title = {Chunkrag: {Novel}, author = {Singh, I. S. and Aggarwal, R. and Allahverdiyev, I. and Taha, M. and {...}, year = {2024}, url = {https://arxiv.org/abs/2410.19572}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We introduced ChunkRAG, an LLM-driven chunk filtering method that enhances retrieval-augmented generation precision and factuality through dynamic greedy chunk aggregation. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{baumann_combining_2024, title = {Combining retrieval-augmented generation and few-shot learning for model synthesis of uncommon dsls}, author = {Baumann, N. and Diaz, J. S. and Michael, J. and Netz, L. and Nqiri, H. and {...}, year = {2024}, url = {https://dl.gi.de/items/2e7293bb-7e2b-4682-9c45-af6022ad9fa5}, journal = {… 2024 Satellite Events}, note = {Publisher: dl.gi.de}, keywords = {source: Google Scholar}, abstract = {… LLM’s context. Furthermore, we employ a technique known as ’retrieval-augmented generation’ (RAG) to assist the LLM … It has been used as way to mitigate LLM hallucinations [To24], …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{liu_ctrla_2024, title = {{CtrlA}, author = {Liu, H. and Zhang, H. and Guo, Z. and Wang, J. and Dong, K. and Li, X. and {...}, year = {2024}, url = {https://arxiv.org/abs/2405.18727}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM toward honesty and monitor its confidence, we extract features aligned with the directions of honesty and confidence within LLM’s … —we can shift the LLM’s representation space to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{roychowdhury_confusedpilot_2024, title = {Confusedpilot: {Confused}, author = {RoyChowdhury, A. and Luo, M. and Sahu, P. and Banerjee, S. and {...}, year = {2024}, url = {https://arxiv.org/abs/2408.04870}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of security vulnerabilities of RAG systems that confuse Copilot … in RAG, corrupting the responses generated by the LLM. … how malicious actors can exploit trust and shared access to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{nikishina_creating_2024, title = {Creating a {Taxonomy}, author = {Nikishina, I. and Sevgili, Ö and Li, M. M. and Biemann, C. and {...}, year = {2024}, url = {https://arxiv.org/abs/2408.02854}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… for RAG applications, illustrating how RAG can be systematically implemented to improve LLM … Those papers already comprise over 2000 citations, resulting in more than twenty-eight …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{rouzrokh_conflare_2024, title = {Conflare: conformal large language model retrieval}, author = {Rouzrokh, P. and Faghani, S. and Gamble, C. U. and {...}, year = {2024}, url = {https://arxiv.org/abs/2404.04287}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… This mitigates hallucinations and allows updating the knowledge without retraining the LLM. … Despite the popularity of RAG, it does not guarantee that an LLM will generate a valid …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{li_citation-enhanced_2024-1, title = {Citation-enhanced generation for {LLM}, author = {Li, W. and Li, J. and Ma, W. and Liu, Y.}, year = {2024}, url = {https://arxiv.org/abs/2402.16063}, journal = {arXiv preprint arXiv:2402.16063}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… However, a vital challenge of LLMbased chatbots is that they may produce hallucinated … been made to alleviate hallucination, such as retrieval augmented generation and reinforcement …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ayyamperumal_current_2024, title = {Current state of {LLM}, author = {Ayyamperumal, S. G. and Ge, L.}, year = {2024}, url = {https://arxiv.org/abs/2406.12934}, journal = {arXiv preprint arXiv:2406.12934}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… at the internal word embedding cite[] representation of an LLM without directly looking at the … RAG architectures address this vulnerability by grounding LLM responses in provided …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{dhole_conqret_2024, title = {{ConQRet}, author = {Dhole, K. D. and Shu, K. and Agichtein, E.}, year = {2024}, url = {https://arxiv.org/abs/2412.05206}, journal = {arXiv preprint arXiv:2412.05206}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… the LLM Judges are prompted to generate the individual RAG … LLM judges are reliable for identifying hallucinated content in their argument. To simulate varying levels of hallucinations, …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{tsai_comparative_2024, title = {Comparative analysis of automatic literature review using {Mistral}, author = {Tsai, H. C. and Huang, Y. F. and Kuo, C. W.}, year = {2024}, url = {https://assets-eu.researchsquare.com/files/rs-4022248/v1_covered_31b35741-397a-47a8-aa52-d71a4150153f.pdf}, publisher = {assets-eu.researchsquare.com}, note = {Type: PDF}, keywords = {source: Google Scholar}, abstract = {… of applying the Mistral LLM, augmented with Retrieval-Augmented Generation, to the … LLM-powered literature review itself is not immune to the generic issue of LLM hallucination in LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{tamanna_chatgpt_2024, title = {{ChatGPT}, author = {Tamanna, S. B. and Uddin, G. and Wang, S. and Xia, L. and {...}, year = {2024}, url = {https://arxiv.org/abs/2411.07360}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG-based ChatGPT (ie, ChatGPT … hallucinated by producing incorrect or irrelevant answers. We manually examined each hallucination case and identified two limitations in ChatGPT …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sacoransky_chatgpt_2024, title = {{ChatGPT}, author = {Sacoransky, E. and Kwan, B. Y. M. and Soboleski, D.}, year = {2024}, url = {https://www.sciencedirect.com/science/article/pii/S0363018824001130}, journal = {Current Problems in Diagnostic …}, note = {Publisher: Elsevier Type: HTML}, keywords = {source: Google Scholar}, abstract = {… ChatGPT and assistive AI have significant potential to transform radiology reporting, … few-shot prompting, ChatGPT, and Retrieval Augmented Generation (RAG) into diagnostic workflows…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{shen_citekit_2024, title = {Citekit: {A}, author = {Shen, J. and Zhou, T. and Chen, Y. and Liu, K.}, year = {2024}, url = {https://arxiv.org/abs/2408.04662}, journal = {arXiv preprint arXiv:2408.04662}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Prompt self-RAG As for Llama3-8B and GPT-4o, there is no trained version for self-RAG, we use prompt to make the LLM retrieve documents and generate, then use an NLI model to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jiao_can_2024, title = {Can we trust embodied agents? exploring backdoor attacks against embodied {LLM}, author = {Jiao, R. and Xie, S. and Yue, J. and Sato, T. and Wang, L. and Wang, Y. and {...}, year = {2024}, url = {https://arxiv.org/abs/2405.20774}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… for RAG-based LLM decisionmaking systems (BALD-RAG). The … from a database to augment the LLM’s input context. Recent … attack mechanism for RAG-based LLM systems as follows. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{liu_ctrla_2024-1, title = {Ctrla: {Adaptive}, author = {Liu, H. and Zhang, H. and Guo, Z. and Dong, K. and Li, X. and Lee, Y. Q. and {...}, year = {2024}, url = {https://ui.adsabs.harvard.edu/abs/2024arXiv240518727L/abstract}, journal = {arXiv e …}, note = {Publisher: ui.adsabs.harvard.edu}, keywords = {source: Google Scholar}, abstract = {… to regulate the LLM's behavior by manipulating its representations for increased honesty, and a confidence probe to monitor the internal states of LLM and assess confidence levels, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{tan_chinese_2024, title = {Chinese safetyqa: {A}, author = {Tan, Y. and Zheng, B. and Zheng, B. and Cao, K. and Jing, H. and Wei, J. and {...}, year = {2024}, url = {https://arxiv.org/abs/2412.15265}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… To address these challenges and better evaluate the factuality ability of LLMs to … factuality abilities of existing LLMs and analyze how these capabilities relate to LLM abilities, eg, RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{trofimova_coderefine_2024, title = {{CodeRefine}, author = {Trofimova, E. and Sataev, E. and Jowhari, A. S.}, year = {2024}, url = {https://arxiv.org/abs/2408.13366}, journal = {arXiv preprint arXiv:2408.13366}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Retrieval Augmented Generation (RAG) concept to improve the quality and accuracy of generated text. In RAG, … helps control LLM hallucinations, as we aim to avoid the LLM introducing …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{he_chinese_2024, title = {Chinese simpleqa: {A}, author = {He, Y. and Li, S. and Liu, J. and Tan, Y. and Wang, W. and Huang, H. and {...}, year = {2024}, url = {https://arxiv.org/abs/2411.07140}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… After that, to ensure the quality of Chinese SimpleQA, we use LLM to remove samples, … , which guides the LLM to evaluate the factual correctness of answers based on the RAG system. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{omar_chatgpt_2024, title = {{ChatGPT}, author = {Omar, M. and Ullanat, V. and Loda, M. and Marchionni, L. and {...}, year = {2024}, url = {https://www.thelancet.com/journals/landig/article/PIIS2589-7500(24)00114-6/fulltext}, journal = {The Lancet Digital …}, note = {Publisher: thelancet.com Type: HTML}, keywords = {source: Google Scholar}, abstract = {… the performance of GPT4DFCI-RAG against the generic ChatGPT-4 model in responding to … ChatGPT-4 also showed a high rate of hallucinations, featuring papers or applications that …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhou_cogmg_2024, title = {Cogmg: {Collaborative}, author = {Zhou, T. and Chen, Y. and Liu, K. and Zhao, J.}, year = {2024}, url = {https://arxiv.org/abs/2406.17231}, journal = {arXiv preprint arXiv:2406.17231}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… hallucinations and factually inaccurate content. Querying knowledge graphs to reduce hallucinations in LLM … preference alignment are familiar with RAG, we utilize prompt engineering …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yin_chathpc_2024, title = {chathpc: {Empowering}, author = {Yin, J. and Hines, J. and Herron, E. and Ghosal, T. and Liu, H. and {...}, year = {2024}, url = {https://www.osti.gov/biblio/2538074}, journal = {Journal of …}, note = {Publisher: osti.gov}, keywords = {source: Google Scholar}, abstract = {… technical complexities and gaps, LLM trustworthiness, safety, … Retrieval augmented generation (RAG) has emerged as a … hybrid deployment integrates RAG with LLM generation, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{gregory_chatgpt_2024, title = {{ChatGPT}, author = {Gregory, G. and Vito, L.}, year = {2024}, url = {https://www.sciencedirect.com/science/article/pii/S1544612324013783}, journal = {Finance Research Letters}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… known as Retrieval Augmented Generation (RAG)… Retrieval Augmented Generation (RAG) techniques generate more “specific, diverse, and factual language than a state-of-the-art LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chang_conversational_2024, title = {Conversational product recommendation using {LLM}, author = {Chang, T. J. and Lin, L. H. M. and Tsai, R. T. H.}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10602608/}, journal = {… Internet of Things and Big Data …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… Retrieval augmented generation (RAG) is expected to serve … key for LLM to avoid hallucinations, provide credible information, … In this study, we used LLM as a user and sales …}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{armant_can_2024, title = {Can {Knowledge}, author = {Armant, Vincent and Mouakher, Amira and Vargas-Rojas, Felipe and Symeonidou, Danai and Guérin, Joris and Mougenot, Isabelle and Desconnets, Jean Christophe}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211180646&partnerID=40&md5=5406aeb192f487bae497d1a983229118}, booktitle = {{CEUR}, volume = {3833}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{anantha_context_2024, title = {Context {Tuning}, author = {Anantha, Raviteja and Bethi, Tharun and Vodianik, Danil and Chappidi, Srinivas}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188662450&partnerID=40&md5=3f5361f13607a04776ebc34f7519e6b1}, pages = {15 -- 22}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 3}, } @inproceedings{kurniawan_cykg-rag_2024, title = {{CyKG}, author = {Kurniawan, Kabul and Kiesling, Elmar and Ekelhart, Andreas}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002730892&partnerID=40&md5=aecc4dc3ce324cdf9c9473ba10603bfc}, booktitle = {{CEUR}, volume = {3950}, pages = {51 -- 64}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 1}, } @inproceedings{wu_clasheval_2024, title = {{ClashEval}, author = {Wu, Kevin E. and Wu, Eric and Zou, James Y.}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000548768&partnerID=40&md5=778686bf20bc3637d8d55c9f121472f0}, booktitle = {Advances in {Neural}, volume = {37}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 6}, } @article{choi_combining_2024, title = {Combining {Multiple}, author = {Choi, Jason Ingyu and Collins, Marcus D. and Agichtein, Eugene and Rokhlenko, Oleg and Malmasi, Shervin}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000213823&partnerID=40&md5=ab4fc178f9ac8d71e9d28e1f5e3a7a0f}, pages = {40 -- 50}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{niu_ragtruth_2023, title = {Ragtruth: {A}, author = {Niu, C. and Wu, Y. and Zhu, J. and Xu, S. and Shum, K. and Zhong, R. and {...}, year = {2023}, url = {https://arxiv.org/abs/2401.00396}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… in identifying hallucinations by fine-tuning LLM with … wordlevel hallucination evaluation dataset specifically for the RAG … method of fine-tuning LLM for hallucination detection. It is shown …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{gao_retrieval-augmented_2023, title = {Retrieval-augmented generation for large language models: {A}, author = {Gao, Y. and Xiong, Y. and Gao, X. and Jia, K. and Pan, J. and Bi, Y. and {...}, year = {2023}, url = {https://simg.baai.ac.cn/paperfile/25a43194-c74c-4cd3-b60f-0a1f27f8b8af.pdf}, journal = {arXiv preprint arXiv …}, note = {Publisher: simg.baai.ac.cn Type: PDF}, keywords = {source: Google Scholar}, abstract = {… , such as hallucinations, slow … RAG The Naive RAG research paradigm represents the earliest methodology gained prominence shortly after the widespread adoption of ChatGPT…}, annote = {Query date: 2025-10-25 20:50:36}, } @book{bergvall_reducing_2023, title = {Reducing {LLM}, author = {Bergvall, P.}, year = {2023}, url = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5223641}, publisher = {papers.ssrn.com}, keywords = {source: Google Scholar}, abstract = {… in hallucinations, though we also explore the trade-offs between strict factual grounding and … This work highlights the potential of RAG pipelines to improve the reliability of LLM-powered …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{levonian_retrieval-augmented_2023, title = {Retrieval-augmented generation to improve math question-answering: {Trade}, author = {Levonian, Z. and Li, C. and Zhu, W. and Gade, A. and Henkel, O. and {...}, year = {2023}, url = {https://arxiv.org/abs/2310.03184}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… implementation We adopted a commercially-realistic chatbot context as the underlying LLM, … We identified 51 factual and conceptual questions that have sufficient context to be …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{manathunga_retrieval_2023, title = {Retrieval augmented generation and representative vector summarization for large unstructured textual data in medical education}, author = {Manathunga, S. S. and Illangasekara, Y. A.}, year = {2023}, url = {https://arxiv.org/abs/2308.00479}, journal = {arXiv preprint arXiv:2308.00479}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of hallucination and producing harmful answers. Retrieval Augmented Generation (RAG) … pharmacology from LLM without a non-parametric knowledgebase and a RAG model with …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ryu_retrieval-based_2023, title = {Retrieval-based evaluation for {LLMs}, author = {Ryu, C. and Lee, S. and Pang, S. and Choi, C. and Choi, H. and {...}, year = {2023}, url = {https://aclanthology.org/2023.nllp-1.13/}, journal = {Proceedings of the …}, note = {Publisher: aclanthology.org}, keywords = {source: Google Scholar}, abstract = {… potential presence of factual errors. Motivated by this issue, we propose Eval-RAG, a new evaluation method for LLM-generated texts. Unlike existing methods, Eval-RAG evaluates the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{_rag_2023, title = {{RAG}, author = {{조찬영}, year = {2023}, url = {https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE11652073}, journal = {Proceedings of KIIT Conference}, note = {Publisher: dbpia.co.kr}, keywords = {source: Google Scholar}, abstract = {… LLM is widely used to support chatbots. However, LLM is susceptible to hallucinations that … framework, a type of RAG, to solve the hallucination problem. The proposed architecture uses …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{su_implementing_2024, title = {Implementing retrieval-augmented generation (rag) for large language models to build confidence in traditional chinese medicine}, author = {Su, X. and Gu, Y.}, year = {2024}, url = {https://files.osf.io/v1/resources/ns2v3_v1/providers/osfstorage/66678b7a65e1de5555893ab1?action=download\&direct\&version=1}, publisher = {files.osf.io}, note = {Type: PDF}, keywords = {source: Google Scholar}, abstract = {… [14] MI Rafat, “Ai-powered legal virtual assistant: Utilizing rag-optimized llm for housing dispute resolution in finland.” 2024. [15] K. Krishna, “Towards robust long-form text generation …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{chidipothu_improving_2024, title = {Improving large language model (llm) performance with retrieval augmented generation (rag): {Development}, author = {Chidipothu, N. and Samuel, J. and Esguerra, J. and Anderson, R. and {...}, year = {2024}, url = {https://scholarship.libraries.rutgers.edu/esploro/outputs/preprint/Improving-large-language-model-LLM-performance/991032165917804646?institution=01RUT_INST}, publisher = {scholarship.libraries.rutgers.edu}, keywords = {source: Google Scholar}, abstract = {… significantly greater than 1 will result in hallucinations. In our design, we choose a low temperature so that the LLM prioritizes factuality during the response process rather than …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{miao_integrating_2024-1, title = {Integrating retrieval-augmented generation with large language models in nephrology: advancing practical applications}, author = {Miao, J. and Thongprayoon, C. and Suppadungsuk, S. and {...}, year = {2024}, url = {https://www.mdpi.com/1648-9144/60/3/445}, journal = {Medicina}, note = {Publisher: mdpi.com Type: HTML}, keywords = {source: Google Scholar}, abstract = {… factual data, the RAG approach effectively reduces the occurrence of inaccuracy or hallucinations… To illustrate the process of creating a customized ChatGPT model with a RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yu_defense_2024, title = {In defense of rag in the era of long-context language models}, author = {Yu, T. and Xu, A. and Akkiraju, R.}, year = {2024}, url = {https://arxiv.org/abs/2409.01666}, journal = {arXiv preprint arXiv:2409.01666}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… making RAG less attractive. Recent studies show that long-context LLMs significantly … RAG in long-context applications. Unlike the existing works favoring the long-context LLM over RAG…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{setty_improving_2024, title = {Improving retrieval for rag based question answering models on financial documents}, author = {Setty, S. and Thakkar, H. and Lee, A. and Chung, E. and Vidra, N.}, year = {2024}, url = {https://arxiv.org/abs/2404.07221}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… documents into the large language model. In order to prevent hallucinations, some sort of in-… Fake RAG uses the same LLM model but is given the correct context to answer the original …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{perak_incorporating_2024, title = {Incorporating dialect understanding into llm using rag and prompt engineering techniques for causal commonsense reasoning}, author = {Perak, B. and Beliga, S. and Meštrović, A.}, year = {2024}, url = {https://aclanthology.org/2024.vardial-1.19/}, journal = {… of the Eleventh Workshop on NLP …}, note = {Publisher: aclanthology.org}, keywords = {source: Google Scholar}, abstract = {… various prompts engineering and the Retrieval-Augmented Generation (RAG) technique. Initially, … Next, we enhance prompts using the RAG technique specifically for the Chakavian and …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{alessio_improving_2024, title = {Improving rag systems via sentence clustering and reordering}, author = {Alessio, M. and Faggioli, G. and Ferro, N. and Nardini, F. M. and {...}, year = {2024}, url = {https://www.research.unipd.it/bitstream/11577/3538814/2/paper4.pdf}, journal = {CEUR WORKSHOP …}, note = {Publisher: research.unipd.it Type: PDF}, keywords = {source: Google Scholar}, abstract = {… well-known Large Language Model (LLM) hallucination problem, … with LLM positional dependencies and the difficulties of RAG … of RAG responses and to the use of an “LLMas-a-judge”. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{pradeep_initial_2024, title = {Initial nugget evaluation results for the trec 2024 rag track with the autonuggetizer framework}, author = {Pradeep, R. and Thakur, N. and Upadhyay, S. and Campos, D. and {...}, year = {2024}, url = {https://arxiv.org/abs/2411.09607}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… (RAG) Track. There is, obviously, tremendous excitement and interest in RAG, but we feel that the evaluation of RAG … Thus, we do not consider possible LLM hallucinations at all. We will …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{fang_ingest-and-ground_2024, title = {Ingest-{And}, author = {Fang, C. and Larson, D. and Zhu, S. and Zeng, S. and Summer, W. and {...}, year = {2024}, url = {https://arxiv.org/abs/2410.02825}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… efficiency with LLM and RAG. To reduce hallucination, we continually pre-train the base LLM model with a privacy-specific knowledge base and then augment it with a semantic RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_identifying_2024, title = {Identifying performance-sensitive configurations in software systems through code analysis with llm agents}, author = {Wang, Z. and Kim, D. J. and Chen, T. H.}, year = {2024}, url = {https://arxiv.org/abs/2406.12806}, journal = {arXiv preprint arXiv:2406.12806}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… and that copies bear this notice and the full citation on the first page. Copyrights for components of … on large language models (LLM) agents and retrieval-augmented generation (RAG). …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{rachha_incorporating_2024, title = {Incorporating {LLM}, author = {Rachha, A. K.}, year = {2024}, url = {https://vtechworks.lib.vt.edu/items/3d08a8cd-effe-4e41-9830-0204637e53da}, publisher = {vtechworks.lib.vt.edu}, keywords = {source: Google Scholar}, abstract = {… This section leverages the feature of RAG to enhance LLM capabilities to provide accurate and contextually … The reviewers highlighted the reliability of the LLM to counter hallucinations. …}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{han_improving_2024, title = {Improving {Assessment}, author = {Han, Zifei and Lin, Jionghao and Gurung, Ashish and Thomas, Danielle R. and Chen, Eason and Borchers, Conrad and Gupta, Shivang and Koedinger, Kenneth R.}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203842530&partnerID=40&md5=153e0790aa4f52ed2c9aa79d5f39eb99}, booktitle = {Proceedings of {Machine}, volume = {257}, pages = {66 -- 76}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{ozaki_understanding_2024, title = {Understanding the impact of confidence in retrieval augmented generation: {A}, author = {Ozaki, S. and Kato, Y. and Feng, S. and Tomita, M. and Hayashi, K. and {...}, year = {2024}, url = {https://arxiv.org/abs/2412.20309}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We evaluate if RAG boosts LLM confidence using entropy, best probability, accuracy, and Adaptive Calibration Error. In our multiple-choice QA task, each question has one correct …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_unims-rag_2024, title = {Unims-rag: {A}, author = {Wang, H. and Huang, W. and Deng, Y. and Wang, R. and Wang, Z. and {...}, year = {2024}, url = {https://arxiv.org/abs/2401.13256}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… as hallucinations [36], factuality [37] … -RAG w/ GPT4o is much better than UniMS-RAG w/ ChatGPT due to more accurate similarity labels provided by GPT4o, we believe that UniMS-RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{pasquarelli__2024, title = {… {Utility}, author = {Pasquarelli, L. and Koutcheme, C. and Hellas, A.}, year = {2024}, url = {https://arxiv.org/abs/2410.13326}, journal = {arXiv preprint arXiv:2410.13326}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… With RAG, search results can be traced back to the original source, providing the user with … the source of the LLM answers – RAG has also been found to reduce hallucination [18]1. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{nemeth_using_2024, title = {Using a {RAG}, author = {Németh, R. and Tátrai, A. and Szabó, M. and Tamási, Á}, year = {2024}, url = {https://www.ksh.hu/statszemle_archive/en/2024/2024_02/2024_02_003.pdf}, journal = {Hungarian Statistical Review}, note = {Publisher: ksh.hu Type: PDF}, keywords = {source: Google Scholar}, abstract = {… They were asked whether they used ChatGPT or had used a similar tool during their undergraduate studies, and we also asked them about their trust in these tools. Notably, user and …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{ogbo-gebhardt_using_2024, title = {Using a {Large}, author = {Ogbo-Gebhardt, E. and Ogbo, O.}, year = {2024}, url = {https://www.econstor.eu/handle/10419/302517}, publisher = {econstor.eu}, keywords = {source: Google Scholar}, abstract = {… LLM-powered assistant] was most useful?” and “On a scale of 1 to 5, where a higher number indicates more trust, to what extent do you trust … located the LLM inference servers and RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wu_usable_2024, title = {Usable {XAI}, author = {Wu, X. and Zhao, H. and Zhu, Y. and Shi, Y. and Yang, F. and Hu, L. and Liu, T. and {...}, year = {2024}, url = {https://arxiv.org/abs/2403.08946}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Given a query prompt and its ChatGPT response, we aim to build a classifier to detect if the response contains hallucination. Since the gradients of ChatGPT is inaccessible, we apply …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{antico_unimib_2024, title = {Unimib {Assistant}, author = {Antico, C. and Giordano, S. and Koyuturk, C. and {...}, year = {2024}, url = {https://arxiv.org/abs/2411.19554}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… between the LLM and the data. Finally, practical testing of how the RAG-LLM system … ChatGPT remains prone to hallucinations and provides unclickable links from time to time if …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wu_unigen_2024, title = {Unigen: {A}, author = {Wu, S. and Huang, Y. and Gao, C. and Chen, D. and Zhang, Q. and {...}, year = {2024}, url = {https://arxiv.org/abs/2406.18966}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Generation (RAG)-based validation method to check the factuality of generated statements to … Motivated by this finding, we require the LLM to generate Python code to solve the given …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{xian_understanding_2024, title = {Understanding {Data}, author = {Xian, X. and Wang, T. and You, L. and Qi, Y.}, year = {2024}, url = {https://openreview.net/forum?id=2aL6gcFX7q}, publisher = {openreview.net}, keywords = {source: Google Scholar}, abstract = {… Retrieval-Augmented Generation (RAG) effectively alleviates these problems by … the factual accuracy of LLM-generated content. However, recent studies reveal that RAG systems are …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{cheng_unified_2024, title = {Unified active retrieval for retrieval augmented generation}, author = {Cheng, Q. and Li, X. and Li, S. and Zhu, Q. and Yin, Z. and Shao, Y. and Li, L. and {...}, year = {2024}, url = {https://arxiv.org/abs/2406.12534}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… with only LLM, RAG involves an additional retrieval process and the longer LLM input, … entries from Self-RAG’s non-retrieval-required data, and factual knowledge questions from TAQA …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{huang_understanding_2024, title = {Understanding the planning of {LLM}, author = {Huang, X. and Liu, W. and Chen, X. and Wang, X. and Wang, H. and {...}, year = {2024}, url = {https://www.researchgate.net/profile/Xu-Huang-37/publication/380756642_Understanding_the_planning_of_LLM_agents_A_survey/links/664d5a9dbc86444c72f64b6f/Understanding-the-planning-of-LLM-agents-A-survey.pdf}, journal = {arXiv preprint arXiv …}, note = {Publisher: researchgate.net Type: PDF}, keywords = {source: Google Scholar}, abstract = {… trajectories may lead to LLM experiencing hallucinations, deviating from the … LLM-Agents, there are currently two major approaches to enhance planning abilities through memory: RAG…}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{siragusa_unipa-gpt_2024, title = {Unipa-{GPT}, author = {Siragusa, Irene and Pirrone, Roberto}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214426005&partnerID=40&md5=5b30020b93ef53258163ddf847601ecb}, booktitle = {{CEUR}, volume = {3878}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{fore_unlearning_2024, title = {Unlearning {Climate}, author = {Fore, Michael and Singh, Simranjit and Lee, Chaehong and Pandey, Amritanshu and Anastasopoulos, Antonios and Stamoulis, Dimitrios}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204448847&partnerID=40&md5=c5ecf9d1c0656b00a191da6157277b6d}, pages = {178 -- 192}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 2}, } @article{noauthor_uncertainlp_2024, title = {{UncertaiNLP}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188661032&partnerID=40&md5=9d3acf2024519c49a637c850efa75aaa}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{chow_unified_2024, title = {Unified {Generative}, author = {Chow, Wei and Li, Juncheng and Yu, Qifan and Pan, Kaihang and Fei, Hao and Ge, Zhiqi and Yang, Shuai and Siliang, Tang and Zhang, Hanwang and Sun, Qianru}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000489048&partnerID=40&md5=da04cde9542bddb2b204d14d2b66c4d8}, booktitle = {Advances in {Neural}, volume = {37}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{zhou_trustworthiness_2024, title = {Trustworthiness in retrieval-augmented generation systems: {A}, author = {Zhou, Y. and Liu, Y. and Li, X. and Jin, J. and Qian, H. and Liu, Z. and Li, C. and {...}, year = {2024}, url = {https://arxiv.org/abs/2409.10102}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… the RAG context: As shown in Figure 1, we define trustworthiness across six dimensions: (1) … scenarios, we focus on assessing the correctness of the intermediate steps in the LLM’s …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zimmerman_two-tiered_2024-1, title = {Two-tiered encoder-based hallucination detection for retrieval-augmented generation in the wild}, author = {Zimmerman, I. and Tredup, J. and Selfridge, E. and {...}, year = {2024}, url = {https://aclanthology.org/2024.emnlp-industry.2/}, journal = {Proceedings of the 2024 …}, note = {Publisher: aclanthology.org}, keywords = {source: Google Scholar}, abstract = {… -tuned LLM … RAG, the model was given the input prompt including the user’s question, retrieved KBs, and a sentence from the LLM Response (the statement being classified for factual …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{pham_towards_2024, title = {Towards reliable medical question answering: {Techniques}, author = {Pham, D. K. and Vo, B. Q.}, year = {2024}, url = {https://arxiv.org/abs/2408.13808}, journal = {arXiv preprint arXiv:2408.13808}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Key methods covered in the paper include Retrieval-Augmented Generation (RAG)-based … LLM limitations in healthcare applications and provide insights into addressing hallucinations. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ma_think--graph_2024, title = {Think-on-graph 2.0: {Deep}, author = {Ma, S. and Xu, C. and Jiang, X. and Li, M. and Qu, H. and Yang, C. and Mao, J. and {...}, year = {2024}, url = {https://arxiv.org/abs/2407.10805}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {Retrieval-augmented generation (RAG) has improved large language models (LLMs) by using knowledge retrieval to overcome knowledge deficiencies. However, current RAG … RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{william_text_2024, title = {Text {Embedding}, author = {William, I. O. and Altamimi, M.}, year = {2024}, url = {https://www.researchgate.net/profile/Mubarak-Altamimi/publication/381105654_Text_Embedding_Implementation_Using_Retrieval_Augmented_Generation_RAG_Model_Combined_With_Large_Language_Model/links/665c78e30b0d2845747c0fe8/Text-Embedding-Implementation-Using-Retrieval-Augmented-Generation-RAG-Model-Combined-With-Large-Language-Model.pdf}, journal = {International Journal of Advanced Natural …}, note = {Publisher: researchgate.net Type: PDF}, keywords = {source: Google Scholar}, abstract = {… evaluation for tasks requiring factual accuracy, to assess the performance of your RAG model. We follow software engineering concepts and maintain excellent coding standards …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{fatehkia_t-rag_2024, title = {T-{RAG}, author = {Fatehkia, M. and Lucas, J. K. and Chawla, S.}, year = {2024}, url = {https://arxiv.org/abs/2402.07483}, journal = {arXiv preprint arXiv:2402.07483}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of RAG with a finetuned open-source LLM. Additionally, our system, which we call Tree-RAG (T-RAG… As we observed earlier, finetuned models are still prone to hallucinations especially …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{su_towards_2024, title = {Towards more robust retrieval-augmented generation: {Evaluating}, author = {Su, J. and Zhou, J. P. and Zhang, Z. and Nakov, P. and Cardie, C.}, year = {2024}, url = {https://arxiv.org/abs/2412.16708}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Retrieval-Augmented Generation (RAG) systems have emerged as a promising solution to mitigate LLM hallucinations … use the Non-RAG setting as a proxy to gauge an LLM’s internal …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhao_towards_2024, title = {Towards understanding retrieval accuracy and prompt quality in rag systems}, author = {Zhao, S. and Huang, Y. and Song, J. and Wang, Z. and Wan, C. and {...}, year = {2024}, url = {https://arxiv.org/abs/2411.19463}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We also observed that higher LLM confidence (perplexity) aligned with higher retrieval … In this paper, our study of LLMdriven RAG system design offers the first exploratory un…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ridder_hallurag_2024, title = {The {HalluRAG}, author = {Ridder, F. and Schilling, M.}, year = {2024}, url = {https://arxiv.org/abs/2412.17056}, journal = {arXiv preprint arXiv:2412.17056}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We aim to train an MLP to identify sentence-level hallucinations by analyzing specific internal states in RAG applications. In particular, we focus on closed-domain hallucinations, which …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhao_tcaf_2024, title = {{TCAF}, author = {Zhao, J. and Liu, X.}, year = {2024}, url = {https://openreview.net/forum?id=nvjfWv7uGY}, journal = {… Cup Workshop for Retrieval Augmented Generation}, note = {Publisher: openreview.net}, keywords = {source: Google Scholar}, abstract = {… the LLM to cite the ID of the supporting document in its response, this design significantly reduces the incidence of hallucination, … LLM to match that of a 70B LLM in the RAG system. The …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jiang_tc-rag_2024, title = {Tc-rag: turing-complete rag's case study on medical llm systems}, author = {Jiang, X. and Fang, Y. and Qiu, R. and Zhang, H. and Xu, Y. and Chen, H. and {...}, year = {2024}, url = {https://arxiv.org/abs/2408.09199}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG not only mitigates hallucination issues during LLM inference but also provides up-to-date, task-specific knowledge, significantly boosting both interpretability and performance on …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{fazlija_toward_2024, title = {Toward optimising a retrieval augmented generation pipeline using large language model}, author = {Fazlija, G.}, year = {2024}, url = {https://wwwmatthes.in.tum.de/file/1vzgjh1an34u0/Sebis-Public-Website/-/Master-s-Thesis-Gentrit-Fazlija/Master%20Thesis_Gentrit%20Fazlija_signed.pdf}, publisher = {wwwmatthes.in.tum.de}, note = {Type: PDF}, keywords = {source: Google Scholar}, abstract = {… This approach not only ""shows"" the LLM the anticipated quality and relevance of responses but also aids in mitigating issues of hallucination and inconsistency. By demonstrating …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yang_geometry_2024, title = {The {Geometry}, author = {Yang, E. and Amar, J. and Lee, J. H. and Kumar, B. and Jia, Y.}, year = {2024}, url = {https://arxiv.org/abs/2407.18044}, journal = {arXiv preprint arXiv:2407.18044}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Unlike relying solely on the LLM’s internal knowledge, RAG … knowledge base to inform the LLM’s answer generation … QB-RAG are more frequently grounded on our trusted source of …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{habib_taxtajweez_2024, title = {Taxtajweez: {A}, author = {Habib, M. A. and Amin, S. and Oqba, M. and Jaipal, S. and {...}, year = {2024}, url = {https://journals.flvc.org/FLAIRS/article/view/135648}, journal = {The International …}, note = {Publisher: journals.flvc.org}, keywords = {source: Google Scholar}, abstract = {… Generation (RAG) system powered by the OpenAI GPT-3.5-turbo LLM, designed specifically … , TaxTajweez leverages the RAG pipeline to mitigate model hallucinations, enhancing the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{finardi_chronicles_2024, title = {The chronicles of rag: {The}, author = {Finardi, P. and Avila, L. and Castaldoni, R. and Gengo, P. and {...}, year = {2024}, url = {https://arxiv.org/abs/2401.07883}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… possible to obtain the maximum score that an evaluated LLM could reach for a RAG system. … Demonstrating confidence in transfer learning, we found that a few examples were sufficient…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{suresh_towards_2024-1, title = {Towards a rag-based summarization agent for the electron-ion collider}, author = {Suresh, K. and Kackar, N. and Schleck, L. and Fanelli, C.}, year = {2024}, url = {https://arxiv.org/abs/2403.15729}, journal = {arXiv preprint arXiv:2403.15729}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Since its proposal, RAG methods have continuously evolved to achieve superior performance in grounding LLM to truth and reducing hallucinations. Different RAG methods that involve …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{li_targeting_2024, title = {Targeting the core: {A}, author = {Li, X. and Li, Z. and Kosuga, Y. and Yoshida, Y. and Bian, V.}, year = {2024}, url = {https://arxiv.org/abs/2412.04415}, journal = {arXiv preprint arXiv:2412.04415}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… , hallucinations, privacy breaches, and a lack of transparency. This paper investigates a critical vulnerability: adversarial attacks targeting the LLM … the fragility of existing LLM defenses. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{liang_thames_2024, title = {Thames: {An}, author = {Liang, M. and Arun, A. and Wu, Z. and Munoz, C. and Lutch, J. and {...}, year = {2024}, url = {https://arxiv.org/abs/2409.11353}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Unlike these frameworks, our type definitions were designed not for retrievalaugmented generation (RAG) systems but for general LLM hallucination evaluation. We also introduced …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{abeysinghe_challenges_2024, title = {The challenges of evaluating llm applications: {An}, author = {Abeysinghe, B. and Circi, R.}, year = {2024}, url = {https://arxiv.org/abs/2406.03339}, journal = {arXiv preprint arXiv:2406.03339}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Other components performance such as the semantic search used for retrieval in RAG is not … But this is not the case always, in most instances LLM evaluators tend to be overly confident …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{leto_toward_2024, title = {Toward optimal search and retrieval for rag}, author = {Leto, A. and Aguerrebere, C. and Bhati, I. and Willke, T. and {...}, year = {2024}, url = {https://arxiv.org/abs/2411.07396}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… with separately trained retriever and LLM components, as training … citation metrics vary with more retrieved documents, adding new data to a small literature on attributed QA with RAG…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{nikbakht_tspec-llm_2024, title = {Tspec-llm: {An}, author = {Nikbakht, R. and Benzaghta, M. and Geraci, G.}, year = {2024}, url = {https://arxiv.org/abs/2406.01768}, journal = {arXiv preprint arXiv:2406.01768}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… the RAG framework, detail how to employ TSpecLLM for RAG, … Confidence levels: We analyze the confidence levels of … the questionnaire when applying RAG on the TSpec-LLM dataset. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kashmira_tobugraph_2024, title = {{TOBUGraph}, author = {Kashmira, S. and Dantanarayana, J. L. and Brodsky, J. and {...}, year = {2024}, url = {https://arxiv.org/abs/2412.05447}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… (I4) Hallucinations during memory retrieval failures: Baseline RAG models hallucinate when … Figure 5b shows RAGv2 hallucinating because RAG relies on unstructured data, losing …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{anderson_design_2024, title = {The design of an llm-powered unstructured analytics system}, author = {Anderson, E. and Fritz, J. and Lee, A. and Li, B. and Lindblad, M. and {...}, year = {2024}, url = {https://arxiv.org/abs/2409.00847}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of simple LLM-based operations, we can make the query plan as a whole more reliable than RAG-… While the RAG approach somewhat mitigates hallucination, LLM context windows are …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{gong_potential_2024, title = {The potential clinical utility of the customized large language model in gastroenterology: {A}, author = {Gong, E. J. and Bang, C. S. and Lee, J. J. and Park, J. and Kim, E. and Kim, S. and {...}, year = {2024}, url = {https://www.mdpi.com/2306-5354/12/1/1}, journal = {Bioengineering}, note = {Publisher: mdpi.com Type: HTML}, keywords = {source: Google Scholar}, abstract = {… Conventional GPT-4o is an advanced LLM capable of retrieval-augmented generation (RAG… and reproducibility of LLM outputs is another key regulatory requirement to foster trust and …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wu_thinking_2024, title = {Thinking with knowledge graphs: {Enhancing}, author = {Wu, X. and Tsioutsiouliklis, K.}, year = {2024}, url = {https://arxiv.org/abs/2412.10654}, journal = {arXiv preprint arXiv:2412.10654}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… These summaries are subsequently used by the LLM via RAG to help answer questions … relationships helps improve LLM multi-hop reasoning ability and reduce hallucination. The …}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{kim_thorr_2024, title = {{THoRR}, author = {Kim, Kihun and Kim, Mintae and Lee, Hokyung and Park, Seongik and Han, Youngsub and Jeon, Byoung-ki}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207524029&partnerID=40&md5=ae6dfa0a2f47b4fa1992d7b91dae75f2}, booktitle = {{CEUR}, volume = {3784}, pages = {50 -- 55}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{zhang_trustworthy_2024, title = {Trustworthy {Alignment}, author = {Zhang, Zongmeng and Shi, Yufeng and Zhu, Jinhua and Zhou, Wengang and Qi, Xiang and Zhang, Peng and Li, Houqiang}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203826205&partnerID=40&md5=4df19b55392ac0a1c4fd77a5f8c9ac89}, booktitle = {Proceedings of {Machine}, volume = {235}, pages = {59827 -- 59850}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{ramoneda_role_2024, title = {The {Role}, author = {Ramoneda, Pedro and Parada-Cabaleiro, Emilia and Weck, Benno and Serra, Xavier}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000189844&partnerID=40&md5=bbfe780a4b835cbbd5a8e56bf696571b}, pages = {81 -- 86}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{wu_medical_2024, title = {Medical graph rag: {Towards}, author = {Wu, J. and Zhu, J. and Qi, Y. and Chen, J. and Xu, M. and Menolascina, F. and {...}, year = {2024}, url = {https://arxiv.org/abs/2408.04187}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG data to credible medical papers and foundational medical dictionaries. This process generates triples [RAG … It enhances LLM reasoning and ensures responses are traceable to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{song_measuring_2024, title = {Measuring and enhancing trustworthiness of {LLMs}, author = {Song, M. and Sim, S. H. and Bhardwaj, R. and Chieu, H. L. and {...}, year = {2024}, url = {https://arxiv.org/abs/2409.11242}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We define hallucination as an erroneous LLM response, categorized into five types: (1) … We aim to measure two aspects of an LLM in RAG: 1) the Correctness of the generated …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{asbai_mitigating_2024, title = {Mitigating {Hallucination}, author = {Asbai, A.}, year = {2024}, url = {https://www.diva-portal.org/smash/record.jsf?pid=diva2:1887431}, publisher = {diva-portal.org}, keywords = {source: Google Scholar}, abstract = {… This study evaluated the RAG hallucination mitigation strategy on ChatGPT and Gemini to … More specifically, the study evaluated the RAG techniques’ ability to mitigate hallucination in …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{agrawal_mindful-rag_2024-1, title = {Mindful-rag: {A}, author = {Agrawal, G. and Kumarage, T. and Alghamdi, Z. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10852457/}, journal = {2024 2nd International …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… of ChatGPT without RAG on both datasets. The results, presented in Figure 1, show that Mindful-RAG, … Zhang, “Enhancing llm factual accuracy with rag to counter hallucinations: A case …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{tang_multihop-rag_2024, title = {Multihop-rag: {Benchmarking}, author = {Tang, Y. and Yang, Y.}, year = {2024}, url = {https://arxiv.org/abs/2401.15391}, journal = {arXiv preprint arXiv:2401.15391}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM) by retrieving relevant knowledge, showing promising potential in mitigating LLM hallucinations … However, we find that existing RAG systems are inadequate in answering multi-hop …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yu_multi-source_2024, title = {Multi-source knowledge pruning for retrieval-augmented generation: {A}, author = {Yu, S. and Cheng, M. and Liu, Q. and Wang, D. and Yang, J. and {...}, year = {2024}, url = {https://arxiv.org/abs/2409.13694}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… on either the LLM’s internal knowledge or external knowledge. Another combines the LLM’s … the internal knowledge of LLM before retrieval tends to generate hallucinations due to the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{qi_model_2024-1, title = {Model internals-based answer attribution for trustworthy retrieval-augmented generation}, author = {Qi, J. and Sarti, G. and Fernández, R. and Bisazza, A.}, year = {2024}, url = {https://arxiv.org/abs/2406.13663}, journal = {arXiv preprint arXiv:2406.13663}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… 15For completeness, we also report MIRAGE results without self-citation prompting in … 16ALCE is an evaluation framework for RAG, evaluating LLM responses in terms of citation quality…}, annote = {Query date: 2025-10-25 20:50:36}, } @book{xiong_merging_2024, title = {Merging mixture of experts and retrieval augmented generation for enhanced information retrieval and reasoning}, author = {Xiong, X. and Zheng, M.}, year = {2024}, url = {https://assets-eu.researchsquare.com/files/rs-3978298/v1_covered_c16e21c8-7b04-448d-bc48-d44b0f430b4e.pdf}, publisher = {assets-eu.researchsquare.com}, note = {Type: PDF}, keywords = {source: Google Scholar}, abstract = {… through research demonstrating RAG’s capacity to improve factual accuracy and relevance … to systematically integrate MoE and RAG into the Mistral Large Language Model (LLM), and …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chang_main-rag_2024, title = {Main-rag: {Multi}, author = {Chang, C. Y. and Jiang, Z. and Rakesh, V. and Pan, M. and {...}, year = {2024}, url = {https://arxiv.org/abs/2501.00332}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… This indicates that the LLM (here is Mistral-7B) is more confident … , suggesting that the LLM is less confident and may misjudge … We acknowledge that LLM inference under RAG workflow …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_m-rag_2024, title = {M-{RAG}, author = {Wang, Z. and Teo, S. X. and Ouyang, J. and Xu, Y. and Shi, W.}, year = {2024}, url = {https://arxiv.org/abs/2405.16420}, journal = {arXiv preprint arXiv:2405.16420}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… M-RAG, designed to facilitate RAG across multiple partitions of a database. M-RAG addresses … However, its quality faces significant challenges such as low precision, hallucination, and …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{choi_malade_2024, title = {{MALADE}, author = {Choi, J. and Palumbo, N. and Chalasani, P. and Engelhard, M. M. and {...}, year = {2024}, url = {https://arxiv.org/abs/2408.01869}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… a confidence score that indicates how confident an LLM is about its label assignment. These scores permit a rigorous quantitative evaluation against the well-established Observational …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kriman_measuring_2024, title = {Measuring text summarization factuality using atomic facts entailment metrics in the context of retrieval augmented generation}, author = {Kriman, N. E.}, year = {2024}, url = {https://arxiv.org/abs/2408.15171}, journal = {arXiv preprint arXiv:2408.15171}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… In this section, we describe our approach for evaluating the factuality of summary texts with respect to their source texts. Our methodology leverages a large language model (LLM) to …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{amatriain_measuring_2024, title = {Measuring and mitigating hallucinations in large language models: amultifaceted approach}, author = {Amatriain, X.}, year = {2024}, url = {https://amatria.in/blog/images/Mitigating_Hallucinations.pdf}, publisher = {amatria.in}, note = {Type: PDF}, keywords = {source: Google Scholar}, abstract = {… A hallucination in an LLM is defined as ”the generation of content that is nonsensical … , RAG can be effectively utilized to ground LLM responses, reducing the likelihood of hallucinations …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kimura_mapping_2024, title = {Mapping drug terms via integration of a retrieval-augmented generation algorithm with a large language model}, author = {Kimura, E. and Kawakami, Y. and Inoue, S. and {...}, year = {2024}, url = {https://synapse.koreamed.org/articles/1516088909}, journal = {Healthcare Informatics …}, note = {Publisher: synapse.koreamed.org Type: HTML}, keywords = {source: Google Scholar}, abstract = {… RAG that distinguished the final candidates from the baseline. We assessed the efficacy of the LLM with RAG … To prevent LLM hallucinations, all candidate strings were verified against …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{penkov_mitigating_2024, title = {Mitigating hallucinations in large language models via semantic enrichment of prompts: {Insights}, author = {Penkov, S.}, year = {2024}, url = {https://aclanthology.org/2024.clib-1.30/}, journal = {Proceedings of the Sixth International Conference on …}, note = {Publisher: aclanthology.org}, keywords = {source: Google Scholar}, abstract = {… By embedding deeper semantic understanding directly into LLM prompts, our approach extends the ethos behind RAG, enhancing its capability to improve LLM reliability. This proactive …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{bei_manufacturing_2024-1, title = {Manufacturing domain qa with integrated term enhanced rag}, author = {Bei, Y. and Fang, Z. and Mao, S. and Yu, S. and Jiang, Y. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10649905/}, journal = {… Joint Conference on …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… hallucination issues in domain-specific LLMs, the most prevalent method currently is RetrievalAugmented Generation (RAG… is then input into a Large Language Model (LLM) to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{thakur_mirage-bench_2024, title = {{MIRAGE}, author = {Thakur, N. and Kazi, S. and Luo, G. and Lin, J. and Ahmad, A.}, year = {2024}, url = {https://arxiv.org/abs/2410.13716}, journal = {arXiv preprint arXiv:2410.13716}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… ized arena-based multilingual RAG benchmark for 18 diverse … RAG extensively coupling both heuristic features and LLM as … We use boostrapping to obtain confidence bounds for better …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{besta_multi-head_2024, title = {Multi-head rag: {Solving}, author = {Besta, M. and Kubicek, A. and Gerstenberger, R. and {...}, year = {2024}, url = {https://arxiv.org/abs/2406.05085}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… hallucinations (by grounding the LLM reply in reliable … We ensure the relevance of our RAG datasets in real use cases … all of which actively use RAG in their own LLM infrastructures. Our …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{gao_modular_2024, title = {Modular rag: {Transforming}, author = {Gao, Y. and Xiong, Y. and Wang, M. and Wang, H.}, year = {2024}, url = {https://arxiv.org/abs/2407.21059}, journal = {arXiv preprint arXiv:2407.21059}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… challenges, such as hallucination and … RAG technology has been accelerated by LLM technology and practical application needs. Researchers are examining and organizing the RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{lu_multimodal_2024, title = {Multimodal large language model driven scenario testing for autonomous vehicles}, author = {Lu, Q. and Wang, X. and Jiang, Y. and Zhao, G. and Ma, M. and {...}, year = {2024}, url = {https://arxiv.org/abs/2409.06450}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… but also encourages rational thought with minimal hallucination. For further evidence of the … testing an LLM-driven AV within them. Thirdly, we showcase the effectiveness of RAG module…}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{noauthor_mai-xai24_2024, title = {{MAI}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210016656&partnerID=40&md5=657ed9ed152a33fdd58cc97ac5c1fafd}, booktitle = {{CEUR}, volume = {3803}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{nguyen_my_2024, title = {My {Climate}, author = {Nguyen, Vincent and Karimi, Sarvnaz and Hallgren, Willow and Harkin, Ashley and Prakash, Mahesh}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204439657&partnerID=40&md5=77ba849127c1ef47344eef4bc5e39a70}, pages = {27 -- 45}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 5}, } @article{wu_multirag_2025-1, title = {Multirag: a knowledge-guided framework for mitigating hallucination in multi-source retrieval augmented generation}, author = {Wu, W. and Wang, H. and Li, B. and Huang, P. and Zhao, X. and {...}, year = {2025}, url = {https://ieeexplore.ieee.org/abstract/document/11113128/}, journal = {2025 IEEE 41st …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… a promising solution to address hallucination issues in Large … hallucination in multi-source retrieval-augmented generation … context of the LLM to generate a credible retrieval answer. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sok_metarag_2025, title = {{MetaRAG}, author = {Sok, C. and Luz, D. and Haddam, Y.}, year = {2025}, url = {https://arxiv.org/abs/2509.09360}, journal = {arXiv preprint arXiv:2509.09360}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We obtain F using an LLM-based extractor with a fixed prompt that enforces one proposition per line, prohibits paraphrasing or inference beyond A, and co-reference resolution. The full …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wu_medical_2025, title = {Medical graph rag: {Evidence}, author = {Wu, J. and Zhu, J. and Qi, Y. and Chen, J. and Xu, M. and {...}, year = {2025}, url = {https://aclanthology.org/2025.acl-long.1381/}, journal = {Proceedings of the …}, note = {Publisher: aclanthology.org}, keywords = {source: Google Scholar}, abstract = {… RAG data to credible medical papers and foundational medical dictionaries. This process generates triples [RAG … It enhances LLM reasoning and ensures responses are traceable to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{cerqueira_mapping_2025, title = {Mapping trustworthiness in large language models: {A}, author = {Cerqueira, JS de and Kemell, K. K. and Rousi, R. and Xi, N. and {...}, year = {2025}, url = {https://arxiv.org/abs/2503.04785}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… To address this, we propose a structured mapping of 20 trust-enhancing techniques across the LLM lifecycle, including retrieval-augmented generation (RAG), explainability techniques, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{shi_mkrag_2025, title = {Mkrag: {Medical}, author = {Shi, Y. and Xu, S. and Yang, T. and Liu, Z. and Liu, T. and Li, X. and {...}, year = {2025}, url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC12099378/}, journal = {AMIA Annual …}, note = {Publisher: pmc.ncbi.nlm.nih.gov Type: HTML}, keywords = {source: Google Scholar}, abstract = {… This work underscores the potential of RAG to enhance LLM performance, offering a … LLM performance on the CounterFact dataset 6 , which consists of general domain factual …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zheng_miriad_2025, title = {{MIRIAD}, author = {Zheng, Q. and Abdullah, S. and Rawal, S. and Zakka, C. and {...}, year = {2025}, url = {https://arxiv.org/abs/2506.06091}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM-based annotation to a small sample of 15,000 QA pairs, instructing GPT-4 to assess each example along two axes: factual … retrieval-augmented generation (RAG), we compare RAG…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{xu_mantra_2025, title = {Mantra: {Enhancing}, author = {Xu, Y. and Lin, F. and Yang, J. and Tsantalis, N.}, year = {2025}, url = {https://arxiv.org/abs/2503.14340}, journal = {arXiv preprint arXiv:2503.14340}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Moreover, in comparison to IntelliJ’s LLM-powered refactoring … emphasize the growing potential of LLM-based systems in … copies bear this notice and the full citation on the first page. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{massenon__2025, title = {” {My}, author = {Massenon, R. and Gambo, I. and Khan, J. A. and Agbonkhese, C. and {...}, year = {2025}, url = {https://www.nature.com/articles/s41598-025-15416-8}, journal = {Scientific Reports}, note = {Publisher: nature.com Type: HTML}, keywords = {source: Google Scholar}, abstract = {… User-Reported LLM Hallucination Detection algorithm were … of user reports indicative of LLM hallucinations, which was … When a user reports a factual error in a RAG-powered app, it …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{lavrinovics_multihal_2025, title = {{MultiHal}, author = {Lavrinovics, E. and Biswas, R. and Hose, K. and Bjerva, J.}, year = {2025}, url = {https://arxiv.org/abs/2505.14101}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… the factuality of LLM outputs. The main advantage of RAG is that it does not require retraining the generator LLM, a … However, RAG is still limited by the LLM context window size [56], its …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{darwish_mitigating_2025, title = {Mitigating {LLM}, author = {Darwish, A. M. and Rashed, E. A. and Khoriba, G.}, year = {2025}, url = {https://www.mdpi.com/2078-2489/16/7/517}, journal = {Information}, note = {Publisher: mdpi.com Type: HTML}, keywords = {source: Google Scholar}, abstract = {… For instance, models like MrRank and RAG-Prompter refine retrieval quality, while approaches such as WikiChat and Retrieval-Augmented Generation demonstrate the empirical …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{he_multi-faceted_2025, title = {Multi-{Faceted}, author = {He, P. and Xing, Y. and Xu, H. and Xiang, Z. and Tang, J.}, year = {2025}, url = {https://arxiv.org/abs/2502.14182}, journal = {arXiv preprint arXiv:2502.14182}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… applications such as Retrieval-augmented generation (RAG) and LLM agents which retrieve … We propose to explore how trust-centric data poisoning can be leveraged to defend against …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yang_multimodal_2025, title = {Multimodal large language model for wheat breeding: a new exploration of smart breeding}, author = {Yang, G. and Li, Y. and He, Y. and Zhou, Z. and Ye, L. and Fang, H. and Luo, Y. and {...}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S0924271625001339}, journal = {ISPRS Journal of …}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… fine-tuning (SFT), retrieval-augmented generation (RAG), and … the combination of SFT, RAG, and RLHF technologies can … generated answer, and reduce hallucinations and biases. The …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{restrepo_multi-ophthalingua_2025, title = {Multi-{OphthaLingua}, author = {Restrepo, D. and Wu, C. and Tang, Z. and Shuai, Z. and {...}, year = {2025}, url = {https://ojs.aaai.org/index.php/AAAI/article/view/35053}, journal = {Proceedings of the …}, note = {Publisher: ojs.aaai.org}, keywords = {source: Google Scholar}, abstract = {… ities in LLM performance for ophthalmology, we present … We curated a diverse set of RAG corpora from three distinct sources… Full details of our RAG sources can be found in Table 4. We …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{fatouros_marketsenseai_2025, title = {Marketsenseai 2.0: {Enhancing}, author = {Fatouros, G. and Metaxas, K. and Soldatos, J. and {...}, year = {2025}, url = {https://arxiv.org/abs/2502.00415}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… combining Retrieval-Augmented Generation and LLM agents… This work marks a significant advancement in applying LLM … lengthy documents, mitigating hallucination risks, and …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{cao_multi-agent_2025, title = {Multi-{Agent}, author = {Cao, H. and Driouich, I. and Singh, R. and Thomas, E.}, year = {2025}, url = {https://arxiv.org/abs/2504.02867}, journal = {arXiv preprint arXiv:2504.02867}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM based applications such as Retrieval Augmented Generation (RAG) systems, several … answer and the factual similarity based on arguments measured by LLM judge to arrive at the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chen_meet2mitigate_2025, title = {{Meet2Mitigate}, author = {Chen, G. and Alsharef, A. and Ovid, A. and Albert, A. and {...}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S1474034624007195}, journal = {Advanced Engineering …}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… (M2M) framework, which integrates cutting-edge technologies, including speaker diarization, automatic speech recognition (ASR), LLMs, and retrieval-augmented generation (RAG) to …}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{tashkovska_memoire_2025, title = {Memoire: {Harnessing}, author = {Tashkovska, Matea and Neshaei, Seyed Parsa and Mejia-Domenzain, Paola and Käser, Tanja}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011254844&partnerID=40&md5=1621532bd889318945b70dbe495f984f}, booktitle = {{CEUR}, volume = {3994}, pages = {65 -- 73}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{song_measuring_2025, title = {{MEASURING}, author = {Song, Maojia and Sim, Shang Hong and Bhardwaj, Rishabh and Chieu, Hai Leong and Majumder, Navonil and Poria, Soujanya}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010244761&partnerID=40&md5=27e1ab2ddaef3c4965582fdbefc9f422}, pages = {47215 -- 47255}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 3}, } @article{hwang_retrieval-augmented_2024, title = {Retrieval-{Augmented}, author = {Hwang, J. and Park, J. and Park, H. and Kim, D. and Park, S. and Ok, J.}, year = {2024}, url = {https://arxiv.org/abs/2410.22954}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG enhances LLM performance by retrieving information from external databases, reducing hallucinations, and improving access to up-to-date knowledge (Lewis et al.…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{es_ragas_2024, title = {Ragas: {Automated}, author = {Es, S. and James, J. and Anke, L. E. and {...}, year = {2024}, url = {https://aclanthology.org/2024.eacl-demo.16/}, journal = {Proceedings of the 18th …}, note = {Publisher: aclanthology.org}, keywords = {source: Google Scholar}, abstract = {… factual answers are more stable: when an answer is factual, we … this is less likely to be the case for hallucinated answers. … To estimate faithfulness, we first use an LLM to extract a set of …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhao_retrieval_2024, title = {Retrieval augmented generation (rag) and beyond: {A}, author = {Zhao, S. and Yang, Y. and Wang, Z. and He, Z. and Qiu, L. K. and {...}, year = {2024}, url = {https://arxiv.org/abs/2409.14924}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… tailoring LLM applications to meet specific industry needs. Through techniques like RAG and fine tuning, data augmented LLM … • Reduction in Model Hallucination: Data augmented LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhao_retrieval-augmented_2024, title = {Retrieval-augmented generation for ai-generated content: {A}, author = {Zhao, P. and Zhang, H. and Yu, Q. and Wang, Z. and Geng, Y. and Fu, F. and {...}, year = {2024}, url = {https://arxiv.org/abs/2402.19473}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… -based RAG is also applicable to scenarios that use LLM … iteratively by employing a static LLM for document ranking and … -to-end RAG system, enhancing the retrieval quality and factual …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{hu_rag_2024, title = {Rag and rau: {A}, author = {Hu, Y. and Lu, Y.}, year = {2024}, url = {https://arxiv.org/abs/2404.19543}, journal = {arXiv preprint arXiv:2404.19543}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… (NLP), yet they encounter challenges such as hallucination and the need for domain-specific … In Sections 6 and 7, we presented some evaluation criteria for large language model tasks …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{bechard_reducing_2024, title = {Reducing hallucination in structured outputs via {Retrieval}, author = {Béchard, P. and Ayala, O. M.}, year = {2024}, url = {https://arxiv.org/abs/2404.08189}, journal = {arXiv preprint arXiv:2404.08189}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… • We provide an application of RAG in workflow generation, a structured … RAG reduces hallucination and improves results. • We demonstrate that RAG allows deploying a smaller LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sree_retrieval-augmented_2024, title = {Retrieval-augmented generation based large language model chatbot for improving diagnosis for physical and mental health}, author = {Sree, Y. B. and Sathvik, A. and Akshit, D. S. H. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10815693/}, journal = {2024 6th International …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… be ingested in order for a Large Language Model (LLM) to be trained … By fine tuning an LLM we can engineer a specialized … This database - comprises more than 35 million citations for …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{he_retrieving_2024-1, title = {Retrieving, rethinking and revising: {The}, author = {He, B. and Chen, N. and He, X. and Yan, L. and Wei, Z. and Luo, J. and {...}, year = {2024}, url = {https://arxiv.org/abs/2410.05801}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… introduce a novel mechanism for enhancing the factuality and consistency in RAG. … RAG Augmentation: To enhance the diversity and robustness of the training data, we utilize ChatGPT …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{li_rac_2024, title = {Rac: {Efficient}, author = {Li, C. and Flanigan, J.}, year = {2024}, url = {https://arxiv.org/abs/2410.15667}, journal = {arXiv preprint arXiv:2410.15667}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We report numbers with retrieval augmented generation (RAG) and without RAG. * indicates we reproduced a previous approach using the same retrieved documents and LLM as our …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{efeoglu_retrieval-augmented_2024, title = {Retrieval-augmented generation-based relation extraction}, author = {Efeoglu, S. and Paschke, A.}, year = {2024}, url = {https://arxiv.org/abs/2404.13397}, journal = {arXiv preprint arXiv:2404.13397}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… hallucination issues on these datasets, our RAG-… RAG-based LLM prompting approach. We also claim that RAG4RE has outperformed the performance of the simple query (Vanilla LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jiang_rag-thief_2024, title = {Rag-thief: {Scalable}, author = {Jiang, C. and Pan, X. and Hong, G. and Bao, C. and Yang, M.}, year = {2024}, url = {https://arxiv.org/abs/2411.14110}, journal = {arXiv preprint arXiv:2411.14110}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG mitigates the issue of hallucinations in LLMs by incorporating realtime, domain-specific … In this experiment, we fix the LLM component of the RAG application as GLM-4-Plus, the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{feldman_ragged_2024-1, title = {Ragged edges: {The}, author = {Feldman, P. and Foulds, J. R. and Pan, S.}, year = {2024}, url = {https://arxiv.org/abs/2403.01193}, journal = {arXiv preprint arXiv:2403.01193}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… nature of hallucinations and the need for more robust solutions to ensure LLM reliability in real-world applications. We offer practical recommendations for RAG deployment and discuss …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{muludi_retrieval-augmented_2024, title = {Retrieval-{Augmented}, author = {Muludi, K. and Fitria, K. M. and Triloka, J.}, year = {2024}, url = {https://search.ebscohost.com/login.aspx?direct=true\&profile=ehost\&scope=site\&authtype=crawler\&jrnl=2158107X\&AN=176379076\&h=mmXDdbx%2FAKKXE5HxVbZop7XacHkdE6WLAF%2BzfxKas%2BXNrm8iN7hcr%2FcAbBl17BHfwst667MJ%2FM%2FG8lWuepC86w%3D%3D\&crl=c}, journal = {International Journal of …}, note = {Publisher: search.ebscohost.com}, keywords = {source: Google Scholar}, abstract = {… for QA systems without modifications tend to generate hallucinatory answers, lacking … the large language model within the ChatGPT systems, gpt3.5-turbo within the framework of RAG. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{friel_ragbench_2024, title = {Ragbench: {Explainable}, author = {Friel, R. and Belyi, M. and Sanyal, A.}, year = {2024}, url = {https://arxiv.org/abs/2407.11005}, journal = {arXiv preprint arXiv:2407.11005}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Thorough extensive benchmarking, we find that LLM-based RAG evaluation methods strug… outperforms LLM judges in hallucination/attribution detection but also excels on the new RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chan_rq-rag_2024, title = {Rq-rag: {Learning}, author = {Chan, C. M. and Xu, C. and Yuan, R. and Luo, H. and Xue, W. and Guo, Y. and {...}, year = {2024}, url = {https://arxiv.org/abs/2404.00610}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… prone to generating inaccurate or hallucinatory responses. This … these challenges, Retrieval-Augmented Generation (RAG) … while we train the LLM to refine queries by itself in this …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{arasteh_radiorag_2024, title = {{RadioRAG}, author = {Arasteh, S. T. and Lotfinia, M. and Bressem, K. and {...}, year = {2024}, url = {https://www.researchgate.net/profile/Soroosh-Tayebi-Arasteh/publication/382459583_RadioRAG_Factual_large_language_models_for_enhanced_diagnostics_in_radiology_using_online_retrieval_augmented_generation/links/6782ac0f32c79152e3cd3b68/RadioRAG-Factual-large-language-models-for-enhanced-diagnostics-in-radiology-using-online-retrieval-augmented-generation.pdf}, journal = {arXiv preprint arXiv …}, note = {Publisher: researchgate.net Type: PDF}, keywords = {source: Google Scholar}, abstract = {… Secondly, LLMs can access up-to-date information through RAG, while conventional LLM … the occurrence of hallucinations and 2) RadioRAG improves the accuracy of LLM responses to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sun_redeep_2024, title = {Redeep: {Detecting}, author = {Sun, Z. and Zang, X. and Zheng, K. and Song, Y. and Xu, J. and Zhang, X. and {...}, year = {2024}, url = {https://arxiv.org/abs/2410.11414}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… , a novel method that detects hallucinations by decoupling LLM’s utilization of … RAG hallucination detection accuracy. Additionally, we introduce AARF, which mitigates hallucinations by …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ding_retrieve_2024, title = {Retrieve only when it needs: {Adaptive}, author = {Ding, H. and Pang, L. and Wei, Z. and Shen, H. and Cheng, X.}, year = {2024}, url = {https://arxiv.org/abs/2402.10612}, journal = {arXiv preprint arXiv:2402.10612}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Our objective is to enhance the factuality of LLM responses by integrating parametric and … ChatGPT language model. We re-implement all baselines, except Self-RAG, using ChatGPT to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yuan_rag-driver_2024, title = {Rag-driver: {Generalisable}, author = {Yuan, J. and Sun, S. and Omeiza, D. and Zhao, B. and Newman, P. and {...}, year = {2024}, url = {https://arxiv.org/abs/2402.10828}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Abstract—We need to trust robots that use often opaque AI methods. They need to explain … , we introduce RAG-Driver, a novel retrieval-augmented multi-modal large language model …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{toukmaji_retrieval-augmented_2024-1, title = {Retrieval-augmented generation and llm agents for biomimicry design solutions}, author = {Toukmaji, C. and Tee, A.}, year = {2024}, url = {https://ojs.aaai.org/index.php/AAAI-SS/article/view/31210}, journal = {Proceedings of the AAAI Symposium Series}, note = {Publisher: ojs.aaai.org}, keywords = {source: Google Scholar}, abstract = {… to mitigate hallucination issues in LLMs is LLM agents. … We evaluate the quality of LLM-generated biomimetic design … As a result, we opt to use the prompting LLM with RAG setting …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{khaliq_ragar_2024, title = {Ragar, your falsehood radar: {Rag}, author = {Khaliq, M. A. and Chang, P. and Ma, M. and Pflugfelder, B. and {...}, year = {2024}, url = {https://arxiv.org/abs/2404.12065}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… hallucination in text generation, current fact-checking pipelines often implement a RAG approach, wherein an LLM … pairs generated by our LLM-based and RAG-augmented reasoning …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chirkova_retrieval-augmented_2024, title = {Retrieval-augmented generation in multilingual settings}, author = {Chirkova, N. and Rau, D. and Déjean, H. and Formal, T. and {...}, year = {2024}, url = {https://arxiv.org/abs/2407.01463}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Retrieval-augmented generation (RAG) has recently emerged as a promising … LLM factuality, but is predominantly studied in English-only settings. In this work, we consider RAG in the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yu_retrieval_2024, title = {Retrieval {Augmented}, author = {Yu, J.}, year = {2024}, url = {https://arxiv.org/abs/2407.14838}, journal = {arXiv preprint arXiv:2407.14838}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… , we aim to foster greater trust in blockchain technologies. This trust is crucial for the widespread … In order to construct an expansive and robust dataset for our RAG-LLM pipeline, we …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{bhat_retrieval_2024, title = {Retrieval augmented generation (rag) based restaurant chatbot with ai testability}, author = {Bhat, V. and Cheerla, S. D. and Mathew, J. R. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10730393/}, journal = {2024 IEEE 10th …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… of ChatGPT, the latest research focuses on utilizing Retrieval Augmented Generation (RAG) … Therefore, in this paper, we propose a multi-modal integration of the RAG model and LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{veturi_rag_2024, title = {Rag based question-answering for contextual response prediction system}, author = {Veturi, S. and Vaichal, S. and Jagadheesh, R. L. and Tripto, N. I. and {...}, year = {2024}, url = {https://arxiv.org/abs/2409.03708}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Overall, RAG LLM improves accuracy by reducing hallucinations … Evaluating RAG LLM and BERT-based models on … We thoroughly evaluate the quality of RAG LLM and BERT …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sohn_rationale-guided_2024, title = {Rationale-guided retrieval augmented generation for medical question answering}, author = {Sohn, J. and Park, Y. and Yoon, C. and Park, S. and Hwang, H. and {...}, year = {2024}, url = {https://arxiv.org/abs/2411.00300}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… the LLM prompt increases the confidence of the LLM’s rationale (or reduces its perplexity). tion), a novel framework that improves the reliability of RAG in … for the base LLM, selectively …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{hasegawa_rag_2024-1, title = {Rag certainty: {Quantifying}, author = {Hasegawa, K. and Hidano, S. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10903445/}, journal = {… Conference on Machine …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… • We propose a metric called RAG certainty to quantify the certainty of LLM outputs in a RAG … Since we use the RAG certainty to identify whether the output is hallucinated, prioritizing the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{cheng_remoterag_2024, title = {{RemoteRAG}, author = {Cheng, Y. and Zhang, L. and Wang, J. and Yuan, M. and Yao, Y.}, year = {2024}, url = {https://arxiv.org/abs/2412.12775}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… into the context of prompts to improve the output of LLM (Izacard and Grave… LLM to provide answers with credible literature makes RAG an important technique in the application of LLM, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhu_realm_2024, title = {Realm: {Rag}, author = {Zhu, Y. and Ren, C. and Xie, S. and Liu, S. and Ji, H. and Wang, Z. and Sun, T. and {...}, year = {2024}, url = {https://arxiv.org/abs/2402.07016}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… REALM, a Retrieval-Augmented Generation (RAG) driven … Firstly, we apply Large Language Model (LLM) to encode … Entities Refinement: To mitigate hallucination issues of LLM, we …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jeong_retrieval-augmented_2024, title = {Retrieval-{Augmented}, author = {Jeong, M. and Kim, T. and Kim, S. and Kim, H.}, year = {2024}, journal = {International …}, note = {Publisher: Korea Institute of Construction … Type: CITATION}, keywords = {source: Google Scholar}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sharma_retrieval_2024, title = {Retrieval augmented generation for domain-specific question answering}, author = {Sharma, S. and Yoon, D. S. and Dernoncourt, F. and Sultania, D. and {...}, year = {2024}, url = {https://arxiv.org/abs/2404.14760}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… -aware finetuning of a Large Language model and use a query … Our overall approach reduces hallucinations during genera… the source credibility (Helpx {\textgreater}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ji_rag-rlrc-laysum_2024, title = {Rag-rlrc-laysum at biolaysumm: {Integrating}, author = {Ji, Y. and Li, Z. and Meng, R. and Sivarajkumar, S. and Wang, Y. and {...}, year = {2024}, url = {https://arxiv.org/abs/2405.13179}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… (2023), which also serves as our baseline LLM. We aim to create … The RAG-RLRC-LaySum framework effectively simplifies complex biomedical texts, enhancing readability and factual …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{henkel_retrieval-augmented_2024, title = {Retrieval-augmented generation to improve math question-answering: {Trade}, author = {Henkel, O. and Levonian, Z. and Li, C. and {...}, year = {2024}, url = {https://educationaldatamining.org/edm2024/proceedings/2024.EDM-short-papers.28/}, journal = {Proceedings of the …}, note = {Publisher: educationaldatamining.org Type: HTML}, keywords = {source: Google Scholar}, abstract = {… We identified 51 factual and conceptual questions that have sufficient context to be … RAG implementation - We adopted a chatbot context as the underlying LLM, generating all …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{freitas_retail-gpt_2024, title = {Retail-gpt: leveraging retrieval augmented generation (rag) for building e-commerce chat assistants}, author = {Freitas, BAT de and Lotufo, R. A.}, year = {2024}, url = {https://arxiv.org/abs/2408.08925}, journal = {arXiv preprint arXiv:2408.08925}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… significant hallucination … RAG-based approach for building conversational chatbots for retail e-commerce. The system is built around a DIET classifier and a large language model (LLM) …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{stefano_rag_2024, title = {Rag and roll: {An}, author = {Stefano, G. De and Schönherr, L. and Pellegrino, G.}, year = {2024}, url = {https://arxiv.org/abs/2408.05025}, journal = {arXiv preprint arXiv:2408.05025}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Traditional LLM applications generate responses based on factual … is LLM hallucinations, which are responses to users’ questions that are inconsistent or incoherent with the factual …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zelin_rare_2024, title = {Rare disease diagnosis using knowledge guided retrieval augmentation for {ChatGPT}, author = {Zelin, C. and Chung, W. K. and Jeanne, M. and Zhang, G. and {...}, year = {2024}, url = {https://www.sciencedirect.com/science/article/pii/S1532046424001205}, journal = {Journal of Biomedical …}, note = {Publisher: Elsevier Type: HTML}, keywords = {source: Google Scholar}, abstract = {… ChatGPT’s suitability for rare disease diagnostic support with the enhancement provided by Retrieval Augmented Generation (RAG… hallucinations and improve the accuracy of ChatGPT, …}, annote = {Query date: 2025-10-25 20:50:36}, } @misc{pahwa_reliable_2024, title = {Reliable {Medical}, author = {Pahwa, K.}, year = {2024}, note = {Type: CITATION}, keywords = {source: Google Scholar}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ko_retrieval_2024, title = {Retrieval {Augmented}, author = {Ko, K. and Nyein, T. Y. and Oo, K. K. and Oo, T. Z. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10754919/}, journal = {2024 5th International …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… By combining the power of RAG and the LLM, this document query system offers a robust … LIMITATION Hallucination is a key challenge in LLM. LLM hallucination occurs when the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{joshi_robust_2024-1, title = {Robust multi model rag pipeline for documents containing text, table \&images}, author = {Joshi, P. and Gupta, A. and Kumar, P. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10574972/}, journal = {2024 3rd International …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… Multimodal RAG over two different other multimodal LLM ie, … the proposed solution fits best with LLM in different cases. … also hallucinate because the context which is provided to LLM for …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{han_rag-qa_2024, title = {{RAG}, author = {Han, R. and Zhang, Y. and Qi, P. and Xu, Y. and Wang, J. and Liu, L. and {...}, year = {2024}, url = {https://arxiv.org/abs/2407.13998}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… aligns with RAG-QA ARENA, but the 95\% confidence interval (… We rank these pairs with the same LLM evaluator as in the … We propose a reliable LLM-based evaluation framework, RAG…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{shlyk_real_2024, title = {{REAL}, author = {Shlyk, D. and Groza, T. and Montanelli, S. and Cavalleri, E. and {...}, year = {2024}, url = {https://air.unimi.it/handle/2434/1122499}, journal = {Proceedings of the 23rd …}, note = {Publisher: air.unimi.it}, keywords = {source: Google Scholar}, abstract = {… RAG in the field of biomedical concept recognition (CR). In REAL, we employ RAG to assist the LLM … Our approach relies on the LLM to produce factual definitions for extracted mentions…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{bernardi_report_2024-1, title = {Report generation from x-ray imaging by retrieval-augmented generation and improved image-text matching}, author = {Bernardi, M. L. and Cimitile, M.}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10650332/}, journal = {2024 International Joint Conference …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… the pretraining of the LLM network using RAG our approach is … A promising solution to improve LLM accuracy and credibility … represented by the Retrieval-Augmented Generation (RAG) […}, annote = {Query date: 2025-10-25 20:50:36}, } @article{pan_raglog_2024-1, title = {Raglog: {Log}, author = {Pan, J. and Liang, W. S. and Yidi, Y.}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10607047/}, journal = {2024 IEEE World Forum on Public …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… responses with no other textual hallucination noted. … RAG construct with a locally deployed LLM. This is to address any privacy and confidentiality concerns with the use of online LLM. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhang_raft_2024, title = {Raft: {Adapting}, author = {Zhang, T. and Patil, S. G. and Jain, N. and Shen, S. and Zaharia, M. and {...}, year = {2024}, url = {https://arxiv.org/abs/2403.10131}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… is trained as a general-purpose LLM is largely dependent on the … Here, we know apriori the domain in which the LLM will be … and in-addition, clearly citing sources enhances the model’s …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kulkarni_reinforcement_2024-1, title = {Reinforcement learning for optimizing rag for domain chatbots}, author = {Kulkarni, M. and Tangarajan, P. and Kim, K. and Trivedi, A.}, year = {2024}, url = {https://arxiv.org/abs/2401.06800}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… and an LLM, we optimize the number of LLM tokens using … to the RAG, which interacts with the RAG pipeline through … a prompt that minimizes hallucinations with ChatGPT. Apart from …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{reichman_retrieval-augmented_2024, title = {Retrieval-{Augmented}, author = {Reichman, B. and Heck, L.}, year = {2024}, url = {https://southnlp.github.io/southnlp2024/papers/southnlp2024-poster-46.pdf}, journal = {arXiv preprint arXiv:2402.11035}, note = {Publisher: southnlp.github.io Type: PDF}, keywords = {source: Google Scholar}, abstract = {… the retrieval augmented generation (RAG) paradigm for improving large language models (LLM… Trust in these systems to give accurate information is crucial to their ability to help people …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sundar_revolutionizing_2024-1, title = {Revolutionizing assessment: {Ai}, author = {Sundar, K. and Manohar, E. and Vijay, K. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10760285/}, journal = {2024 2nd International …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… We discovered ChatGPT's ability to advance medical … AI systems confront challenges like hallucinations, legal dangers, and … Next, we turn to the question of evaluation of RAG and other …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhu_rageval_2024, title = {Rageval: {Scenario}, author = {Zhu, K. and Luo, Y. and Xu, D. and Yan, Y. and Liu, Z. and Yu, S. and Wang, R. and {...}, year = {2024}, url = {https://arxiv.org/abs/2408.01262}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… To validate the consistency between LLM evaluations and human assessments, we compare the LLM-reported metrics—completeness, hallucination, and irrelevance—with those …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{tan_revprag_2024, title = {{RevPRAG}, author = {Tan, X. and Luan, H. and Luo, M. and Sun, X. and Chen, P. and Dai, J.}, year = {2024}, url = {https://arxiv.org/abs/2411.18948}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We conducted experiments to test if our approach can distinguish hallucinations and RAG poisoning. Fig. 8 shows the t-SNE representation of mean activations for poisoned response …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{christmann_rag-based_2024, title = {Rag-based question answering over heterogeneous data and text}, author = {Christmann, P. and Weikum, G.}, year = {2024}, url = {https://arxiv.org/abs/2412.07420}, journal = {arXiv preprint arXiv:2412.07420}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… The RAG paradigm came up as a principled way of enhancing LLM factuality incl. provenance and mitigating the risk of hallucination [12, 21]. It is highly related to the earlier retriever-…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ouyang_revisiting_2024, title = {Revisiting the solution of meta kdd cup 2024: {Crag}, author = {Ouyang, J. and Luo, Y. and Cheng, M. and Wang, D. and Yu, S. and {...}, year = {2024}, url = {https://arxiv.org/abs/2409.15337}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… the RAG Baseline, our solutions demonstrate superior results with reduced hallucination rates … that this study will make a modest contribution to the broader RAG and LLM communities. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_retcare_2024, title = {Retcare: {Towards}, author = {Wang, Z. and Zhu, Y. and Gao, J. and Zheng, X. and Zeng, Y. and {...}, year = {2024}, url = {https://openreview.net/forum?id=jqo1vk63qE}, journal = {… Intelligence and Data …}, note = {Publisher: openreview.net}, keywords = {source: Google Scholar}, abstract = {… that they place significant trust in authoritative medical literature. … leveraging the Retrieval-Augmented Generation (RAG) … medical large language model’s pretraining phase and …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{lyu_retrieve-plan-generation_2024, title = {Retrieve-plan-generation: {An}, author = {Lyu, Y. and Niu, Z. and Xie, Z. and Zhang, C. and Xu, T. and Wang, Y. and {...}, year = {2024}, url = {https://arxiv.org/abs/2406.14979}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… factual errors due to their limited internal knowledge. Retrieval-Augmented Generation (RAG), … And we evaluate the Self-RAG model, which enhances the standard RAG by introducing …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sun_r-bot_2024, title = {R-bot: {An}, author = {Sun, Z. and Zhou, X. and Li, G. and Yu, X. and Feng, J. and Zhang, Y.}, year = {2024}, url = {https://arxiv.org/abs/2412.01661}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… To address the hallucination problem of LLMs [25], we perform an offline stage to extract query … of LLMs, including LLM prompting and retrieval augmented generation (RAG), which are …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{desrochers_reducing_2024, title = {Reducing hallucinations in large language models through contextual position encoding}, author = {Desrochers, S. and Wilson, J. and Beauchesne, M.}, year = {2024}, url = {https://files.osf.io/v1/resources/exjqb_v1/providers/osfstorage/665921bd65e1de48d5893f4d?action=download\&direct\&version=2}, publisher = {files.osf.io}, note = {Type: PDF}, keywords = {source: Google Scholar}, abstract = {… to lower hallucination rates [16], [17]. Retrieval-augmented generation (RAG) techniques … Mistral Large, a state-of-the-art large language model, was chosen for this study due to its …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{bui_rambo_2024, title = {Rambo: {Enhancing}, author = {Bui, T. D. and Luu-Van, D. T. and Nguyen, T. P. and Nguyen, T. T. and {...}, year = {2024}, url = {https://arxiv.org/abs/2409.15204}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… However, the employed code LLM may hallucinate code, … To mitigate code LLM hallucination, after analyzing, RAMBO … Code LLM’s Size: We studied the effect of code LLM sizes on …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhang_rag4itops_2024, title = {{RAG4ITOps}, author = {Zhang, T. and Jiang, Z. and Bai, S. and Zhang, T. and Lin, L. and Liu, Y. and {...}, year = {2024}, url = {https://arxiv.org/abs/2410.15805}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM to utilize relevant and latest background knowledge, and it enables the LLM to generate factual … In addition to using RAG to enhance the LLM’s understanding of documents, we …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{nazar_revolutionizing_2024, title = {Revolutionizing undergraduate learning: {CourseGPT}, author = {Nazar, A. M. and Selim, M. Y. and Gaffar, A. and Ahmed, S.}, year = {2024}, url = {https://arxiv.org/abs/2407.18310}, journal = {arXiv preprint arXiv:2407.18310}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… This work evaluates RAG-based-LLM effectiveness as intelligent university course … RAGs overcome outdated knowledge and hallucination by combining the LLM’s intrinsic knowledge …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{_rag_2024, title = {{RAG}, author = {{정효정}, year = {2024}, url = {https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE11891076}, journal = {대한전자공학회 학술 …}, note = {Publisher: dbpia.co.kr}, keywords = {source: Google Scholar}, abstract = {… hallucination problems. Therefore, we introduce the framework that can evaluate the performance of RAG methods using the RAG … , answer, and context, LLM answers to queries. Then, …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{lea_reducing_2024, title = {Reducing {AI}, author = {Lea, D. M. and Cooley, R. S. and Cutshaw, M. A. and Priest, Z. M.}, year = {2024}, url = {https://www.osti.gov/biblio/2474834}, publisher = {osti.gov}, keywords = {source: Google Scholar}, abstract = {… ) attempts to diminish hallucination by providing context to the LLM from data stores (… The LLM uses this context to formulate its response. RAG systems can still suffer from hallucination …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{buhnila_retrieve_2024, title = {Retrieve, {Generate}, author = {Buhnila, Ioana and Sinha, Aman and Constant, Matthieu}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204905785&partnerID=40&md5=01d079dcca16b43a1d1944fcd2058b7d}, pages = {189 -- 203}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{wendelken_roux-lette_2024, title = {Roux-lette at “{Discharge}, author = {Wendelken, Suzanne M. and Antony, A. and Korutla, Rajashekar and Pachipala, B. and Mahajan, Danish and Shanahan, J. G. and Saba, Walid S.}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204422297&partnerID=40&md5=7d2a93cbf33b6b7877f0f82e5d0463ad}, pages = {719 -- 723}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 1}, } @inproceedings{rehulka_rag_2024, title = {{RAG}, author = {Řehulka, Erik and Šuppa, Marek}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201614999&partnerID=40&md5=832380a21dc27483fce0ccfb200ec746}, booktitle = {{CEUR}, volume = {3740}, pages = {3021 -- 3031}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 1}, } @inproceedings{garigliotti_retrieval-augmented_2024, title = {Retrieval-{Augmented}, author = {Garigliotti, Darío}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002709216&partnerID=40&md5=83aec9594ccc26341748d3c5cf8cd724}, booktitle = {{CEUR}, volume = {3950}, pages = {23 -- 30}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{shi_reference_2024, title = {Reference {Trustable}, author = {Shi, Luohe and Yao, Yao and Li, Zuchao and Zhang, Lefei and Zhao, Hai}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000474591&partnerID=40&md5=d634d05b7658407471e531e2f3f498fa}, booktitle = {Advances in {Neural}, volume = {37}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{oreski_retrieval_2024, title = {Retrieval {Augmented}, author = {Oreški, Dijana and Vlahek, Dino}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000393580&partnerID=40&md5=cc250260e7cc30b3db83002109d7a406}, booktitle = {{CEUR}, volume = {3938}, pages = {12 -- 23}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{han_automating_2024-1, title = {Automating systematic literature reviews with retrieval-augmented generation: a comprehensive overview}, author = {Han, B. and Susnjak, T. and Mathrani, A.}, year = {2024}, url = {https://www.mdpi.com/2076-3417/14/19/9103}, journal = {Applied Sciences}, note = {Publisher: mdpi.com Type: HTML}, keywords = {source: Google Scholar}, abstract = {… RAG enhances LLM performance by grounding responses in dynamically updated and … citations based on context; RAG models tested on this benchmark outperformed ChatGPT-4. In …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{gai_achieving_2024, title = {Achieving higher factual accuracy in llama llm with weighted distribution of retrieval-augmented generation}, author = {Gai, Z. and Tong, L. and Ge, Q.}, year = {2024}, url = {https://files.osf.io/v1/resources/ctw8v_v1/providers/osfstorage/664c901d2f167d17c20e7d42?action=download\&direct\&version=1}, publisher = {files.osf.io}, note = {Type: PDF}, keywords = {source: Google Scholar}, abstract = {… Retrieval-Augmented Generation (RAG) with the Llama Large language model significantly enhances factual … the effectiveness of the weighted RAG mechanism in prioritizing high-…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{shi_ask-eda_2024-1, title = {Ask-eda: {A}, author = {Shi, L. and Kazda, M. and Sears, B. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10691824/}, journal = {2024 IEEE LLM Aided …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… exhibits noticeable enhancements over both sparse-only and dense-only RAG. One of our … models to enhance RAG even further. We will also explore improving the LLM model further …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_astute_2024, title = {Astute rag: {Overcoming}, author = {Wang, F. and Wan, X. and Sun, R. and Chen, J. and Arık, SÖ}, year = {2024}, url = {https://arxiv.org/abs/2410.07176}, journal = {arXiv preprint arXiv:2410.07176}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Second, we propose Astute RAG, which explicitly addresses conflicts between LLM-internal … accurate, relevant, and hallucinationfree. Moreover, we allow the LLM to perform adaptive …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{gupta_comprehensive_2024, title = {A comprehensive survey of retrieval-augmented generation (rag): {Evolution}, author = {Gupta, S. and Ranjan, R. and Singh, S. N.}, year = {2024}, url = {https://arxiv.org/abs/2410.12837}, journal = {arXiv preprint arXiv:2410.12837}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG systems utilize self-attention within the LLM to manage … the generation of coherent, factual outputs from incomplete or … a RAG system, BART has been shown to improve the factual …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{priola_addressing_2024, title = {Addressing hallucinations with rag and nmiss in italian healthcare llm chatbots}, author = {Priola, M. P.}, year = {2024}, url = {https://arxiv.org/abs/2412.04235}, journal = {arXiv preprint arXiv:2412.04235}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… I develop a RAG-based architecture to integrate external knowledge into the generation process, ensuring that models are grounded in factual data. The methodology leverages a …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{alan_rag-based_2024, title = {A rag-based question answering system proposal for understanding islam: {Mufassirqas}, author = {Alan, A. Y. and Karaarslan, E. and Aydin, Ö}, year = {2024}, url = {https://arxiv.org/abs/2401.15378}, journal = {arXiv preprint arXiv:2401.15378}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM chatbots use NLP techniques to establish connections … false information, known as hallucination. Also, the chatbots' … -based Retrieval Augmented Generation (RAG) approach to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{malik_assessing_2024, title = {Assessing {ChatGPT4}, author = {Malik, S. and Kharel, H. and Dahiya, D. S. and Ali, H. and {...}, year = {2024}, url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC11372545/}, journal = {Annals of …}, note = {Publisher: pmc.ncbi.nlm.nih.gov Type: HTML}, keywords = {source: Google Scholar}, abstract = {… ChatGPT-4’s performance was also compared to that of ChatGPT-3.5 and ChatGPT4-RAG. … In addition, none of the gastroenterologists surveyed would trust ChatGPT to autonomously …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{patel_comparative_2024, title = {A comparative analysis of large language models with retrieval-augmented generation based question answering system}, author = {Patel, H. N. and Surti, A. and Goel, P. and Patel, B.}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10714814/}, journal = {… on I-SMAC (IoT in Social …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… Zhang, “Enhancing llm factual accuracy with rag to counter hallucinations: A case study on domain-specific queries in private knowledge-bases,” arXiv preprint arXiv:2403.10446, 2024. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{tonmoy_comprehensive_2024, title = {A comprehensive survey of hallucination mitigation techniques in large language models}, author = {Tonmoy, S. and Zaman, S. M. and Jain, V. and Rani, A. and {...}, year = {2024}, url = {https://www.amanchadha.com/research/2401.01313.pdf}, journal = {arXiv preprint arXiv …}, note = {Publisher: amanchadha.com Type: PDF}, keywords = {source: Google Scholar}, abstract = {… In essence, the contributions of this paper to the realm of LLM hallucination are threefold: … RAG effectively mitigates the issue of hallucination in LLMs by generating responses that are …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{bahaj_asthmabot_2024, title = {{AsthmaBot}, author = {Bahaj, A. and Ghogho, M.}, year = {2024}, url = {https://arxiv.org/abs/2409.15815}, journal = {arXiv preprint arXiv:2409.15815}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… from factual sources to augment the limited knowledge of the LLM and increase the likelihood of having a factual … We used the Google Gemini LLM to infer the results of different queries. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yuan_hybrid_2024, title = {A hybrid {RAG}, author = {Yuan, Y. and Liu, C. and Yuan, J. and Sun, G. and Li, S. and Zhang, M.}, year = {2024}, url = {https://arxiv.org/abs/2408.05141}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… hallucinations by integrating external knowledge bases. In this paper, we introduce a hybrid RAG … attribute predictors to reduce hallucinations, conducted LLM Knowledge Extractor and …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{ammann_analysis_2024, title = {Analysis of {Risks}, author = {Ammann, L. and Ott, S.}, year = {2024}, publisher = {OST Ostschweizer Fachhochschule}, note = {Type: CITATION}, keywords = {source: Google Scholar}, annote = {Query date: 2025-10-25 20:50:36}, } @article{arslan_survey_2024, title = {A {Survey}, author = {Arslan, M. and Ghanem, H. and Munawar, S. and Cruz, C.}, year = {2024}, url = {https://www.sciencedirect.com/science/article/pii/S1877050924021860}, journal = {Procedia computer science}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… generation, significantly reducing the risk of hallucinations and improving the overall quality of … how RAG integration with the LLM handles queries that fall outside the scope of the LLM’s …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chandrasekhar_amgpt_2024, title = {{AMGPT}, author = {Chandrasekhar, A. and Chan, J. and Ogoke, F. and {...}, year = {2024}, url = {https://www.sciencedirect.com/science/article/pii/S2772369024000409}, journal = {Additive Manufacturing …}, note = {Publisher: Elsevier Type: HTML}, keywords = {source: Google Scholar}, abstract = {… We introduce “AMGPT”, a specialized LLM text generator … Hugging Face in a Retrieval-Augmented Generation (RAG) setup, … embeddings from the RAG setup accelerate response times …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{mandikal_ancient_2024, title = {Ancient {Wisdom}, author = {Mandikal, P.}, year = {2024}, url = {https://arxiv.org/abs/2408.11903}, journal = {arXiv preprint arXiv:2408.11903}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… is often hindered by factual inaccuracies and hallucinations, … potential of retrieval-augmented generation (RAG) models for … benchmark a RAG model against a standard, non-RAG LLM, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{benfenati_retrieval-augmented_2024, title = {A retrieval-augmented generation application for question-answering in nutrigenetics domain}, author = {Benfenati, D. and Filippis, GM De and Rinaldi, A. M. and {...}, year = {2024}, url = {https://www.sciencedirect.com/science/article/pii/S1877050924025092}, journal = {Procedia Computer …}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… Large Language Model, circumventing the exhaustive model fine-tuning process. As a result, our RAG … Towards mitigating llm hallucination via self reflection, in: The 2023 Conference …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{saha_advancing_2024, title = {Advancing retrieval-augmented generation with inverted question matching for enhanced qa performance}, author = {Saha, B. and Saha, U. and Malik, M. Z.}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10781379/}, journal = {IEEE Access}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… between our LLM-powered modified RAG system and a traditional RAG system, employing … A major challenge with RAG is its tendency to hallucinate with large text volumes. Our study …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{simon_methodology_2024, title = {A methodology for evaluating rag systems: {A}, author = {Simon, S. and Mailach, A. and Dorn, J. and Siegmund, N.}, year = {2024}, url = {https://arxiv.org/abs/2410.08801}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… a RAG system and a vanilla LLM as they represent the factual and timely data on which an LLM can … What if we had not compared the RAG system to the vanilla LLM baseline? The …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{he_simple_2024, title = {A simple yet effective retrieval-augmented generation framework for the meta {KDD}, author = {He, L. and Li, R. and Shen, S. and Lu, J. and Zhu, L. and Su, Y. and {...}, year = {2024}, url = {https://openreview.net/forum?id=s9QAadOn6H}, journal = {… Augmented Generation}, note = {Publisher: openreview.net}, keywords = {source: Google Scholar}, abstract = {… and the full citation on the … LLM to generate reasoning trajectories and actions for specific tasks in an interleaved manner. For this task, we created a web retrieval tool that allows LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yadav_aeroquery_2024-1, title = {Aeroquery rag and llm for aerospace query in designs, development, standards, certifications}, author = {Yadav, S.}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10677028/}, journal = {2024 IEEE International Conference on Electronics …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… hallucinations, delays, and inefficiencies.To address this issue, our approach leverages the concepts of Retrieval-Augmented Generation (RAG) and … capabilities through RAG, enabling …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{raja_rag-based_2024, title = {A rag-based medical assistant especially for infectious diseases}, author = {Raja, M. and Yuvaraajan, E.}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10544639/}, journal = {2024 International Conference on …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… retrieval augmented generation (RAG) blends external information sources with massive language models. Without requiring the LLM to be retrained, RAG ingests real-time factual … LLM…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{leemann_auto-gda_2024, title = {Auto-{GDA}, author = {Leemann, T. and Petridis, P. and Vietri, G. and Manousakas, D. and {...}, year = {2024}, url = {https://arxiv.org/abs/2410.03461}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… While retrieval-augmented generation (RAG) has been shown to enhance factuality of large language model (LLM) outputs, LLMs still suffer from hallucination, generating incorrect or …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jeong_study_2024, title = {A study on the implementation method of an agent-based advanced rag system using graph}, author = {Jeong, C.}, year = {2024}, url = {https://arxiv.org/abs/2407.19994}, journal = {arXiv preprint arXiv:2407.19994}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… , and being less susceptible to hallucinations, this study aims … database and then using an LLM to verify the relevance of … standard RAG pipeline to generate a response using the LLM…}, annote = {Query date: 2025-10-25 20:50:36}, } @book{rafat_ai-powered_2024, title = {{AI}, author = {Rafat, M. I.}, year = {2024}, url = {https://www.theseus.fi/handle/10024/859826}, publisher = {theseus.fi}, keywords = {source: Google Scholar}, abstract = {… This question investigates the specific impact of RAG optimization on the factual accuracy of LLMgenerated responses within the domain of housing disputes in Finland, comparing the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chen_llm_2024, title = {An llm agent for automatic geospatial data analysis}, author = {Chen, Y. and Wang, W. and Lobry, S. and Kurtz, C.}, year = {2024}, url = {https://arxiv.org/abs/2410.18792}, journal = {arXiv preprint arXiv:2410.18792}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… However, we lack a geospatial RAG database to prompt … API hallucinations account for up to 15\% of all hallucinations … In this work, we opt to implement RAG only when the library …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{marcantonio_artificial_2024, title = {Artificial {Intelligence}, author = {Marcantonio, G. Di}, year = {2024}, url = {https://u-pad.unimc.it/handle/11393/343610}, journal = {… 2024-Navigare la complessità-Infrastrutture e …}, note = {Publisher: u-pad.unimc.it}, keywords = {source: Google Scholar}, abstract = {… research projects (such as INTERPARES TRUST AI) that seek to … by the use of LLM and RAG in digital environments designed … Users need to trust that the information they access about …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sung_new_2024-1, title = {A new pipeline for generating instruction dataset via {RAG}, author = {Sung, C. W. and Lee, Y. K. and Tsai, Y. T.}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10633534/}, journal = {2024 IEEE 48th Annual Computers …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… of LLMs and the Retrieval-Augmented Generation (RAG) related … The resulting fine-tuned LLM demonstrates showcases the … domain intricacies while maintaining factual accuracy. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{rezaei_at-rag_2024, title = {At-rag: {An}, author = {Rezaei, M. R. and Hafezi, M. and Satpathy, A. and Hodge, L. and {...}, year = {2024}, url = {https://arxiv.org/abs/2410.12886}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… The Hallucination Grader: Verifies the factual accuracy of the answer by cross-… LLM to identify the date and reason for the visit. Our method retrieved the correct details, while naive RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{li_alleviating_2024-1, title = {Alleviating action hallucination for llm-based embodied agents via inner and outer alignment}, author = {Li, K. and Zheng, Q. and Zhan, Y. and Zhang, C. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10826957/}, journal = {2024 7th …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… strategy based on retrievalaugmented generation proposed in this … Secondly, the RAG system generates actions by retrieving … reducing the risk of hallucinatory content [19]. Finally, the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yamin_applications_2024, title = {Applications of llms for generating cyber security exercise scenarios}, author = {Yamin, M. M. and Hashmi, E. and Ullah, M. and Katt, B.}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10695083/}, journal = {IEEE Access}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… LLM hallucination to create a sophisticated and adaptive cyber threat scenario. Our approach transforms this hallucination … LLM The bounded rationality of this LLM, enhanced by RAG, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{shethiya_architecting_2024, title = {Architecting {Intelligent}, author = {Shethiya, A. S.}, year = {2024}, url = {http://academianexusjournal.com/index.php/anj/article/view/25}, journal = {Academia Nexus Journal}, note = {Publisher: academianexusjournal.com}, keywords = {source: Google Scholar}, abstract = {… patterns that support LLM integration, such as retrieval-augmented generation (RAG), … —such as showing source documents or confidence scores—can further reinforce trust[12]. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{li_review_2024, title = {A review of prominent paradigms for llm-based agents: {Tool}, author = {Li, X.}, year = {2024}, url = {https://arxiv.org/abs/2406.05804}, journal = {arXiv preprint arXiv:2406.05804}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM-profiled roles as the foundation for the development of algorithmic frameworks across different paradigms. Notably, Wang et al. (2024a) also discuss LLM … to their citations on …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chen_agentpoison_2024, title = {Agentpoison: {Red}, author = {Chen, Z. and Xiang, Z. and Xiao, C. and Song, D. and {...}, year = {2024}, url = {https://proceedings.neurips.cc/paper_files/paper/2024/hash/eb113910e9c3f6242541c1652e30dfd6-Abstract-Conference.html}, journal = {Advances in Neural …}, note = {Publisher: proceedings.neurips.cc}, keywords = {source: Google Scholar}, abstract = {… We consider LLM agents with a RAG mechanism based on corpus retrieval. For a user query q, we retrieve knowledge or past experiences from a memory database D, containing a set …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{aksoy_architecting_2024, title = {Architecting and {Evaluating}, author = {Aksoy, N. and Güven, Z. A. and Ünalır, M. O.}, year = {2024}, url = {https://www.researchgate.net/profile/Yeliz-Karaca/publication/382079038_Demystifying_Fractional_Order_Chaotic_Respiratory_Disease_System_with_XAI/links/668c9a85c1cf0d77ffc38d60/Demystifying-Fractional-Order-Chaotic-Respiratory-Disease-System-with-XAI.pdf#page=214}, journal = {ICAMƩ'24}, note = {Publisher: researchgate.net Type: PDF}, keywords = {source: Google Scholar}, abstract = {… , and it was observed that LLM did not create hallucinations when a correct"" prompt"" was … LLM was observed to answer questions not included in the dataset and produce hallucinations…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhang_arl2_2024-1, title = {Arl2: {Aligning}, author = {Zhang, L. and Yu, Y. and Wang, K. and Zhang, C.}, year = {2024}, url = {https://arxiv.org/abs/2402.13542}, journal = {arXiv preprint arXiv:2402.13542}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG has shown promising results in improving LLM re- … more effectively to LLM because it’s trained on LLM-labeled … in middle, LLM can still obtain some external factual information …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{dong_survey_2024-1, title = {A survey of llm-based agents: {Theories}, author = {Dong, X. and Zhang, X. and Bu, W. and Zhang, D. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10748304/}, journal = {2024 3rd International …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… With the scheme, RAG has demonstrated impressive strength for knowledge retrieval and … , LLM-based agents ought to invoke the planning reflection to handle hallucination and “…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{gu_survey_2024, title = {A survey on llm-as-a-judge}, author = {Gu, J. and Jiang, X. and Shi, Z. and Tan, H. and Zhai, X. and Xu, C. and Li, W. and {...}, year = {2024}, url = {https://arxiv.org/abs/2411.15594}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… survey of LLM-as-a-Judge, addressing the core question: How can reliable LLM-as-a-Judge … Additionally, we propose methodologies for evaluating the reliability of LLM-as-a-Judge …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{meyer_comparison_2024, title = {A {Comparison}, author = {Meyer, S. and Singh, S. and Tam, B. and Ton, C. and Ren, A.}, year = {2024}, url = {https://arxiv.org/abs/2408.03562}, journal = {arXiv preprint arXiv:2408.03562}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… [9] RAG is a text generation method for outsourcing relevant information, from a knowledge … , factual and quality information, to supply an LLM with contextual clues for producing factual …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{neumann_llm-driven_2024, title = {An llm-driven chatbot in higher education for databases and information systems}, author = {Neumann, A. T. and Yin, Y. and Sowe, S. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10706931/}, journal = {IEEE Transactions on …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… “hallucinations,” where it produces incorrect content [47], [48], [49], [50]. The presented solution in this article adopts an retrieval-augmented generation (RAG… utilizing an RAG approach […}, annote = {Query date: 2025-10-25 20:50:36}, } @article{redelaar_attributed_2024, title = {Attributed {Question}, author = {Redelaar, Felicia and van Drie, Romy A.N. and Verberne, Suzan and de Boer, Maaike H.T.}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216932007&partnerID=40&md5=756bba2df695d85f3d127ed6de52fe6b}, pages = {154 -- 165}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{ullrich_aic_2024, title = {{AIC}, author = {Ullrich, Herbert and Mlynář, Tomáš and Drchal, Jan}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210659993&partnerID=40&md5=d26171b7bbf5ca15fd3af902c1c84b83}, pages = {137 -- 150}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 2}, } @article{yokoyama_aggregating_2024, title = {Aggregating {Impressions}, author = {Yokoyama, Hibiki and Tsuchida, Rikuto and Buma, Kosei and Miyakawa, Sho and Utsuro, Takehito and Yoshioka, Masaharu}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204884253&partnerID=40&md5=6da87cea93f74b845eb50be2047f06b0}, pages = {59 -- 72}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{li_alphafin_2024, title = {{AlphaFin}, author = {Li, Xiang and Li, Zhenyu and Shi, Chen and Xu, Yong and Du, Qing and Tan, Mingkui and Huang, Jun}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195934691&partnerID=40&md5=d7f5acab0a70f5aff9a75286b4203402}, pages = {773 -- 783}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 6}, } @inproceedings{gonzalez_torres_automated_2024, title = {Automated {Question}, author = {González Torres, Juan José and Bîndilă, Mihai Bogdan and Hofstee, Sebastiaan B.H.C. and Szondy, Daniel and Nguyen, Quang Hung and Wang, Shenghui and Englebienne, Gwenn}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195187720&partnerID=40&md5=a0f86b391fb3d4f8998babf57c56d152}, pages = {204 -- 214}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 4}, } @inproceedings{toxopeus_accelerate_2024, title = {Accelerate your subsurface workflow: chatting with your data using custom plugins}, author = {Toxopeus, Gerrit J. and Aarsheim, G. and Kallestad, Jakob Vigerust and Mortensen, J. H.H. and Lervik, T. and Haughom, E. and Abeland, J. O.}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003181055&partnerID=40&md5=432b7ddde57e19b97c1498339ed03e16}, volume = {2}, pages = {1171 -- 1175}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{kirchenbauer_hallucination_2024, title = {Hallucination reduction in large language models with retrieval-augmented generation using wikipedia knowledge}, author = {Kirchenbauer, J. and Barns, C.}, year = {2024}, url = {https://files.osf.io/v1/resources/pv7r5/providers/osfstorage/6657166cd835c421594ce333?format=pdf\&action=download\&direct\&version=1}, journal = {ArXiv Preprint. https://doi. org/10.31219/osf. io …}, note = {Publisher: files.osf.io Type: PDF}, keywords = {source: Google Scholar}, abstract = {… Retrieval-augmented generation (RAG) has been widely recognized for its potential to enhance the factual accuracy of LLM … Implementations of RAG combined a retrieval module with …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chen_honest_2024, title = {Honest {AI}, author = {Chen, X. and Wang, L. and Wu, W. and Tang, Q. and Liu, Y.}, year = {2024}, url = {https://arxiv.org/abs/2410.09699}, journal = {arXiv preprint arXiv:2410.09699}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… out that RAG alone is not enough to alleviate hallucination in … Our results show that the hybrid approach using both RAG and … Great thanks to Ermo Wei, who shared invaluable LLM fine-…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhu_halueval-wild_2024, title = {Halueval-wild: {Evaluating}, author = {Zhu, Z. and Yang, Y. and Sun, Z.}, year = {2024}, url = {https://arxiv.org/abs/2403.04307}, journal = {arXiv preprint arXiv:2403.04307}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG during reference answer generation (discussed in Section 2.3). To further validate the effectiveness of RAG… a pioneering benchmark for evaluating LLM hallucinations in real-world …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{liu_how_2024-1, title = {How much can rag help the reasoning of llm?}, author = {Liu, J. and Lin, J. and Liu, Y.}, year = {2024}, url = {https://arxiv.org/abs/2410.02338}, journal = {arXiv preprint arXiv:2410.02338}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… new knowledge and reducing hallucinations. However, the deep understanding of RAG remains limited, how does RAG help the reasoning process and can RAG help improve the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{edwards_hybrid_2024, title = {Hybrid context retrieval augmented generation pipeline: {LLM}, author = {Edwards, C.}, year = {2024}, url = {https://arxiv.org/abs/2405.15436}, journal = {arXiv preprint arXiv:2405.15436}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… into an LLM as a prompt to generate a relevant response. The challenges of the Naive RAG … , and generation issues, including hallucinations where generated responses are not based …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{su_hybrid_2024, title = {Hybrid {RAG}, author = {Su, C. and Wen, J. and Kang, J. and Wang, Y. and Su, Y. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10812735/}, journal = {IEEE Internet of …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… To this end, this article proposes a hybrid Retrieval-Augmented Generation (RAG)-… of MLLMs by using hybrid RAG that filters different unimodal RAG results using multimodal metrics …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{liu_hallucination-aware_2024, title = {Hallucination-aware {Optimization}, author = {Liu, Y. and Liu, G. and Zhang, R. and Niyato, D. and Xiong, Z. and Kim, D. I. and {...}, year = {2024}, url = {https://arxiv.org/abs/2412.06007}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… mitigation strategies, including both model-based approaches, such as prompt engineering and Retrieval Augmented Generation (RAG), and system-based methods, such as Mixture-of…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wu_how_2024, title = {How well do {LLMs}, author = {Wu, K. and Wu, E. and Cassasola, A. and Zhang, A. and Wei, K. and {...}, year = {2024}, url = {https://arxiv.org/abs/2402.02008}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of LLM responses are not fully supported by the sources they provide. We also evaluate GPT-4 with retrieval augmented generation (RAG… Given the rapid pace of LLM development and …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{goyal_hacking_2024, title = {Hacking, the lazy way: {LLM}, author = {Goyal, D. and Subramanian, S. and Peela, A. and {...}, year = {2024}, url = {https://arxiv.org/abs/2409.09493}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… In our research, we introduce a new concept called “LLM Augmented Pentesting” … implementation of Retrieval-Augmented Generation (RAG) minimizes hallucinations and en…}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{kalra_hypa-rag_2024, title = {{HyPA}, author = {Kalra, Rishi and Wu, Zekun and Gulley, Ayesha and Hilliard, Airlie and Guan, Xin and Koshiyama, Adriano Soares and Treleaven, Philip C.}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216564032&partnerID=40&md5=3da5d6954cf104b3d9a661f21f7d5ccd}, pages = {237 -- 256}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 2}, } @inproceedings{basaragin_how_2024, title = {How do you know that? {Teaching}, author = {Bašaragin, Bojana and Ljajić, Adela and Medvecki, Darija and Cassano, Lorenzo and Košprdić, Miloš and Milošević, Nikola}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204109013&partnerID=40&md5=d920b3fcb8ffcc97abd036d73568b0e7}, pages = {536 -- 547}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 2}, } @article{chen_benchmarking_2024-1, title = {Benchmarking large language models in retrieval-augmented generation}, author = {Chen, J. and Lin, H. and Han, X. and Sun, L.}, year = {2024}, url = {https://ojs.aaai.org/index.php/AAAI/article/view/29728}, journal = {Proceedings of the AAAI Conference on …}, note = {Publisher: ojs.aaai.org}, keywords = {source: Google Scholar}, abstract = {… use ChatGPT to conduct additional evaluation of the responses. Specifically, we prompt ChatGPT … can reflect information that is not present in the document or identify any factual errors. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{xue_badrag_2024, title = {Badrag: {Identifying}, author = {Xue, J. and Zheng, M. and Hu, Y. and Liu, F. and Chen, X. and Lou, Q.}, year = {2024}, url = {https://arxiv.org/abs/2406.00083}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM’s output by injecting real, biased articles into the RAG corpus. This method causes the … the LLM’s alignment because the selected passages are factual and likely included in the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chen_black-box_2024, title = {Black-box opinion manipulation attacks to retrieval-augmented generation of large language models}, author = {Chen, Z. and Liu, J. and Liu, H. and Cheng, Q. and Zhang, F. and Lu, W. and {...}, year = {2024}, url = {https://arxiv.org/abs/2407.13757}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… As RAG is designed to overcome the hallucination problem in LLMs and enhance their … of the RAG. Specially, the manipulator can only call the interface of the LLM in RAG instead of …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{bouchard_building_2024, title = {Building {LLMs}, author = {Bouchard, L. F. and Peters, L.}, year = {2024}, url = {https://books.google.com/books?hl=en\&lr=\&id=olJTEQAAQBAJ\&oi=fnd\&pg=PT10\&dq=%22retrieval+augmented+generation%22%7C%22rag%22+%22large+language+model%22%7C%22llm%22%7C%22chatgpt%22+trust%7Cconfidence%7Ccredibility%7Challucination%7Cfactuality%7Ccitation\&ots=iZN1YUXqn6\&sig=TEn3lsT2U5bz7gb1CUGfOro1R7k}, publisher = {books.google.com}, note = {Type: BOOK}, keywords = {source: Google Scholar}, abstract = {… Reducing hallucinations by limiting the LLM to answer based on existing chosen data. 2. Helping with explainability, error checking, and copyright issues by clearly referencing its …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{knollmeyer_benchmarking_2024-1, title = {Benchmarking of retrieval augmented generation: {A}, author = {Knollmeyer, S. and Caymazer, O. and Koval, L. and {...}, year = {2024}, url = {https://www.scitepress.org/Papers/2024/130657/130657.pdf}, journal = {Proceedings of the …}, note = {Publisher: scitepress.org Type: PDF}, keywords = {source: Google Scholar}, abstract = {… of Large Language Models (LLM), traditional benchmarks have … performance of Retrieval Augmented Generation (RAG) systems. … citation quality focuses on assessing whether an LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{clop_backdoored_2024, title = {Backdoored retrievers for prompt injection attacks on retrieval augmented generation of large language models}, author = {Clop, C. and Teglia, Y.}, year = {2024}, url = {https://arxiv.org/abs/2410.14479}, journal = {arXiv preprint arXiv:2410.14479}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM (3), which generates an answer based on the retrieved content (4). Since the LLM’s answer is grounded in recent and factual … understanding of LLM vulnerabilities to RAG prompt …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{shandilya_boosting_2024, title = {Boosting the {Capabilities}, author = {Shandilya, B. and Palmer, A.}, year = {2024}, url = {https://arxiv.org/abs/2410.00387}, journal = {arXiv preprint arXiv:2410.00387}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… augmented generation (RAG) framework backed by a large language model (LLM) to correct … Instead of evaluating the retriever, we make the LLM itself generate confidence scores for …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_biorag_2024, title = {Biorag: {A}, author = {Wang, C. and Long, Q. and Xiao, M. and Cai, X. and Wu, C. and Meng, Z. and {...}, year = {2024}, url = {https://arxiv.org/abs/2408.01107}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… To address these issues, we introduce BioRAG, a novel Retrieval-Augmented Generation (RAG) … fine-tuned LLM, LLM with search engines, and other scientific RAG frameworks across …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sanna_building_2024, title = {Building certified medical chatbots: {Overcoming}, author = {Sanna, L. and Bellan, P. and Magnolini, S. and Segala, M. and {...}, year = {2024}, url = {https://aclanthology.org/2024.cl4health-1.15/}, journal = {Proceedings of the …}, note = {Publisher: aclanthology.org}, keywords = {source: Google Scholar}, abstract = {… Finally, we propose a modular RAG model to implement a Large Language Model in a … Moreover, the model is quite sparse, with an average confidence on correct predictions of 0.27. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kang_bim_2024, title = {{BIM}, author = {Kang, T. W. and Park, S. H.}, year = {2024}, journal = {Journal of KIBIM}, note = {Publisher: Korean Institute of Building … Type: CITATION}, keywords = {source: Google Scholar}, annote = {Query date: 2025-10-25 20:50:36}, } @book{andersson_bridging_2024, title = {Bridging the {Skills}, author = {Andersson, M. and Enqvist, T.}, year = {2024}, url = {https://www.diva-portal.org/smash/record.jsf?pid=diva2:1883256}, publisher = {diva-portal.org}, keywords = {source: Google Scholar}, abstract = {… ) is an architecture that strengthens the capabilities of the LLM. It … In this thesis, the notion of using an LLM and the RAG … the general trust towards and evaluation of AI and RAG in …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{riedler_beyond_2024, title = {Beyond text: {Optimizing}, author = {Riedler, M. and Langer, S.}, year = {2024}, url = {https://arxiv.org/abs/2410.21943}, journal = {arXiv preprint arXiv:2410.21943}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM-as-a-Judge approach. Our results reveal that multimodal RAG can outperform single-modality RAG … they share common LLM limitations, including inaccuracies, hallucinations, and …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{li_bordirlines_2024, title = {{BORDIRLINES}, author = {Li, Bryan and Haider, Samar and Luo, Fiona and Agashe, Adwait and Callison-Burch, Chris}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216921129&partnerID=40&md5=4bb68c54c1d258051aa7249007c63a9a}, pages = {1 -- 13}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 1}, } @inproceedings{zhou_boosting_2024, title = {Boosting the {Potential}, author = {Zhou, Yujia and Liu, Zheng and Dou, Zhicheng}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000514057&partnerID=40&md5=1878887f114d614aa68d2ce32b0b294a}, booktitle = {Advances in {Neural}, volume = {37}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 3}, } @article{zhang_hallucination_2025-1, title = {Hallucination mitigation for retrieval-augmented large language models: a review}, author = {Zhang, W. and Zhang, J.}, year = {2025}, url = {https://www.mdpi.com/2227-7390/13/5/856}, journal = {Mathematics}, note = {Publisher: mdpi.com}, keywords = {source: Google Scholar}, abstract = {… Investigating the root causes of hallucinations in the RAG paradigm helps to understand the mechanisms of its components at different stages and how their limitations affect LLM-…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{rahman_hallucination_2025, title = {Hallucination to truth: {A}, author = {Rahman, S. S. and Islam, M. A. and Alam, M. M. and Zeba, M. and {...}, year = {2025}, url = {https://arxiv.org/abs/2508.03860}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… This review systematically analyzes how LLM-generated content is evaluated for factual … [30] introduce Fact-CheckThen-RAG which improves LLM factual accuracy by evaluating each …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{anjum_halo_2025-1, title = {Halo: {Hallucination}, author = {Anjum, S. and Zhang, H. and Zhou, W. and Paek, E. J. and {...}, year = {2025}, url = {https://ieeexplore.ieee.org/abstract/document/11121104/}, journal = {2025 IEEE/ACM …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… In LangChain, multiquery generation [8] utilizes an LLM to … integrates the LLM through an API, in our case, ChatGPT-3.5, … Retrieval augmented generation (RAG) is a novel framework …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{godinez_hysemrag_2025, title = {{HySemRAG}, author = {Godinez, A.}, year = {2025}, url = {https://arxiv.org/abs/2508.05666}, journal = {arXiv preprint arXiv:2508.05666}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… citation data in the context, the system prevents the Large Language Model from generating its own citations, … limitations of standard RAG architectures, namely noisy retrieval and LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{mala_hybrid_2025, title = {Hybrid {Retrieval}, author = {Mala, C. S. and Gezici, G. and Giannotti, F.}, year = {2025}, url = {https://arxiv.org/abs/2504.05324}, journal = {arXiv preprint arXiv:2504.05324}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We have also evaluated our hybrid RAG pipeline by comparing it with the baseline LLM(Llama-3-instruct-8B) model, the results are illustrated in Appendix B. The results emphasize the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{liu_hoprag_2025, title = {Hoprag: {Multi}, author = {Liu, H. and Wang, Z. and Chen, X. and Li, Z. and Xiong, F. and Yu, Q. and {...}, year = {2025}, url = {https://arxiv.org/abs/2502.12442}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Specifically, we adopt LLM to generate two groups of pseudoqueries for each passage pi: (1… in the vertices and thus avoids LLM hallucination during summarization, information loss …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jeon_hybrid_2025, title = {Hybrid large language model approach for prompt and sensitive defect management: {A}, author = {Jeon, K. and Lee, G.}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S1474034624007274}, journal = {Advanced Engineering Informatics}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… closed-source LLM for generating a … retrieval-augmented generation (GraphRAG)-based QA systems, which have been extensively studied recently. Our results show that the hybrid LLM…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ping_hdlcore_2025-1, title = {Hdlcore: {A}, author = {Ping, H. and Li, S. and Zhang, P. and Cheng, A. and Duan, S. and {...}, year = {2025}, url = {https://arxiv.org/abs/2503.16528}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… • Efficient Heterogeneous RAG: We establish a comprehensive heterogeneous database from carefully selected open-source HDL datasets. Our proposed RAG system extracts multiple …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{pattnayak_hybrid_2025, title = {Hybrid ai for responsive multi-turn online conversations with novel dynamic routing and feedback adaptation}, author = {Pattnayak, P. and Agarwal, A. and Meghwani, H. and Patel, H. L. and {...}, year = {2025}, url = {https://arxiv.org/abs/2506.02097}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… 2024) further optimizes RAG for precision and adaptability in complex applications. By re… inference, RAG systems mitigate common LLM challenges such as hallucinations and outdated …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_healthq_2025, title = {Healthq: {Unveiling}, author = {Wang, Z. and Li, H. and Huang, D. and Kim, H. S. and Shin, C. W. and {...}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S2352648325000315}, journal = {Smart Health}, note = {Publisher: Elsevier Type: HTML}, keywords = {source: Google Scholar}, abstract = {… for evaluating the questioning capabilities of LLM healthcare chains. By implementing advanced LLM chains, including Retrieval-Augmented Generation (RAG), Chain of Thought (CoT)…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{li_how_2025, title = {How llms react to industrial spatio-temporal data? assessing hallucination with a novel traffic incident benchmark dataset}, author = {Li, Q. and Tan, M. and Zhao, X. and Zhang, D. and Zhang, D. and {...}, year = {2025}, url = {https://aclanthology.org/2025.naacl-industry.4/}, journal = {Proceedings of the …}, note = {Publisher: aclanthology.org}, keywords = {source: Google Scholar}, abstract = {… Moreover, the predominance of English in LLM development … Generation (RAG) to further examine LLM hallucinations in … the types of hallucinations that RAG can mitigate and how it …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_human-llm_2025, title = {Human-llm collaboration in generative design for customization}, author = {Wang, X. and Jiang, Z. and Xiong, Y. and Liu, A.}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S0278612525000731}, journal = {Journal of Manufacturing Systems}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… Against the background, this paper explores the potential of LLM in redefining GDfC. Based … three human-LLM collaboration schemes to demonstrate the potential roles of LLM in GDfC. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{paudel_hallucinot_2025, title = {Hallucinot: {Hallucination}, author = {Paudel, B. and Lyzhov, A. and Joshi, P. and Anand, P.}, year = {2025}, url = {https://arxiv.org/abs/2504.07069}, journal = {arXiv preprint arXiv:2504.07069}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… for detecting hallucinations in large language model (LLM) … taxonomy of LLM responses specific to hallucination in enterprise … to LLM response verification builds on established RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{tyndall_impact_2025, title = {Impact of retrieval augmented generation and large language model complexity on undergraduate exams created and taken by {AI}, author = {Tyndall, E. and Gayheart, C. and Some, A. and Genz, J. and Wagner, T. and {...}, year = {2025}, url = {https://www.cambridge.org/core/journals/data-and-policy/article/impact-of-retrieval-augmented-generation-and-large-language-model-complexity-on-undergraduate-exams-created-and-taken-by-ai-agents/498B8CB29AA37695AC5EACBE1B2089B4}, journal = {Data \&Policy}, note = {Publisher: cambridge.org}, keywords = {source: Google Scholar}, abstract = {… allows it to leverage RAG and the textbook … ChatGPT-4 Turbo model, which did not have access to the college textbook. While this study did not directly test for hallucinations, citations …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{liu_improving_2025-3, title = {Improving large language model applications in biomedicine with retrieval-augmented generation: a systematic review, meta-analysis, and clinical …}, author = {Liu, S. and McCoy, A. B. and Wright, A.}, year = {2025}, journal = {Journal of the American Medical …}, note = {Publisher: Oxford Academic Type: CITATION}, keywords = {source: Google Scholar}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kumar_improving_2025, title = {Improving the reliability of {LLMs}, author = {Kumar, A. and Kim, H. and Nathani, J. S. and Roy, N.}, year = {2025}, url = {https://arxiv.org/abs/2505.09031}, journal = {arXiv preprint arXiv:2505.09031}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… retrieval-augmented generation (RAG), as well as applying self-consistency and selfverification strategies, can reduce hallucinations and improve factual … to tackle LLM Hallucinations. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{hou_improving_2025-1, title = {Improving dietary supplement information retrieval: {Development}, author = {Hou, Y. and Bishop, J. R. and Liu, H. and Zhang, R.}, year = {2025}, url = {https://www.jmir.org/2025/1/e67677/}, journal = {Journal of medical Internet research}, note = {Publisher: jmir.org Type: HTML}, keywords = {source: Google Scholar}, abstract = {… An RAG system operates in two phases: first, it retrieves relevant data from a … LLM to generate responses [20,21]. By integrating iDISK with an RAG system, we mitigate the hallucination …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhang_injury_2025, title = {Injury degree appraisal of large language model based on retrieval-augmented generation and deep learning}, author = {Zhang, F. and Luo, Y. and Gao, Z. and Han, A.}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S0160252725000032}, journal = {International Journal of Law and Psychiatry}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… a novel approach that combines Retrieval-Augmented Generation (RAG) with graph-based … By integrating this model with a graph-based knowledge base, our RAG strategy significantly …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{lakatos_investigating_2025-1, title = {Investigating the performance of retrieval-augmented generation and domain-specific fine-tuning for the development of {AI}, author = {Lakatos, R. and Pollner, P. and Hajdu, A. and Joo, T.}, year = {2025}, url = {https://www.mdpi.com/2504-4990/7/1/15}, journal = {Machine Learning and Knowledge …}, note = {Publisher: mdpi.com Type: HTML}, keywords = {source: Google Scholar}, abstract = {… the performance of RAG and DFT on several LLM architectures, … RAG-based architecture that maximizes efficiency and reduces hallucination, underscoring the advantages of RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yang_implementation_2025, title = {Implementation of {Retrieval}, author = {Yang, C. B. and Kim, Y. S.}, year = {2025}, journal = {Smart Media Journal}, note = {Publisher: THE KOREAN INSTITUTE OF … Type: CITATION}, keywords = {source: Google Scholar}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wen_interactivesurvey_2025, title = {Interactivesurvey: {An}, author = {Wen, Z. and Cao, J. and Wang, Z. and Guo, B. and Yang, R. and Liu, S.}, year = {2025}, url = {https://arxiv.org/abs/2504.08762}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Citation Generation To facilitate researchers’ reading experience, we also generate citations in … Categorization also includes the time for LLM-based RAG, we anticipate that with more …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{xing_investigating_2025, title = {Investigating knowledge graphs as structured external memory to enhance large language models' generation for mathematical concept answering}, author = {Xing, W. and Li, C. and Li, H. and Zhu, W. and Lyu, B. and Yan, Z.}, year = {2025}, url = {https://osf.io/mx83s_v2/}, publisher = {osf.io}, keywords = {source: Google Scholar}, abstract = {… However, the issue of LLM hallucination has been well-documented in the research … RAG is using a knowledge graph (KG). In this paper, we design a method to construct a KG with LLM…}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{noauthor_ictir_2025, title = {{ICTIR}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013792692&partnerID=40&md5=20090fa2896f14818c33f80e360afd50}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{noauthor_icsob-c_2025, title = {{ICSOB}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218677724&partnerID=40&md5=66cf2a5328aa6f0fb536d3be4ef2207f}, booktitle = {{CEUR}, volume = {3921}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{noauthor_international_2025, title = {International {Conference}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010609553&partnerID=40&md5=f9451467becb3b6779703978ff98906a}, journal = {Lecture Notes in Networks and Systems}, volume = {1355 LNNS}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{noauthor_icocseti_2025, title = {{ICoCSETI}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009967373&partnerID=40&md5=0e47d45688e8511c09c9cb9b3f3d160c}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{clay_information_2025, title = {Information for {Conversation}, author = {Clay, Alex and Jimeńez-Ruiz, Ernesto}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003708783&partnerID=40&md5=3228c55802e79874af0d38ce187b5f58}, booktitle = {{CEUR}, volume = {3953}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{sharma_og-rag_2024, title = {Og-rag: {Ontology}, author = {Sharma, K. and Kumar, P. and Li, Y.}, year = {2024}, url = {https://arxiv.org/abs/2412.15235}, journal = {arXiv preprint arXiv:2412.15235}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Through extensive experiments on two agriculture datasets and a news dataset, we demonstrate that OG-RAG significantly improves the factual accuracy of LLM-generated responses, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{islam_open-rag_2024-2, title = {Open-rag: {Enhanced}, author = {Islam, S. B. and Rahman, M. A. and Hossain, K. S. M. and Hoque, E. and {...}, year = {2024}, url = {https://arxiv.org/abs/2410.01782}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… tokens and measure the confidence of outputs conditioned on … that our OPENRAG significantly improves the overall factual ac… We define OPEN-RAG LLM as a model MG that, given an …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhao_optimizing_2024, title = {Optimizing {LLM}, author = {Zhao, Y. and Singh, P. and Bhathena, H. and Ramos, B. and {...}, year = {2024}, url = {https://aclanthology.org/2024.naacl-industry.23/}, journal = {Proceedings of the …}, note = {Publisher: aclanthology.org}, keywords = {source: Google Scholar}, abstract = {… Instruction Following Ability Practical RAG deployments typically require the LLM returns answer in a specific language style and may require citations in certain structured format that …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{finsas_optimizing_2024, title = {Optimizing rag systems for technical support with llm-based relevance feedback and multi-agent patterns}, author = {Finsås, M. and Maksim, J.}, year = {2024}, url = {https://ntnuopen.ntnu.no/ntnu-xmlui/handle/11250/3160478}, publisher = {ntnuopen.ntnu.no}, keywords = {source: Google Scholar}, abstract = {… 3.5 we examine studies on mitigating hallucination in LLMs and multi-agent LLM design patterns, … current methods for evaluating LLM-based systems, including RAG-specific evaluation …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kumar_overcoming_2024, title = {Overcoming llm challenges using rag-driven precision in coffee leaf disease remediation}, author = {Kumar, S. S. and Khan, AKMA and Banday, I. A. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10543859/}, journal = {… in Computer Science …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… Serving as a dynamic bridge, RAG minimizes the risk of hallucination, enhancing GenAI application … RAG’s role in overcoming LLM limitations is central to our research, promising a …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{koo_optimizing_2024, title = {Optimizing query generation for enhanced document retrieval in rag}, author = {Koo, H. and Kim, M. and Hwang, S. J.}, year = {2024}, url = {https://arxiv.org/abs/2407.12325}, journal = {arXiv preprint arXiv:2407.12325}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… hallucination of LLM continues to undermine user belief. Among the strategies to mitigate, the Retrieval-Augmented Generation (RAG… query, we utilize a Large Language Model (LLM) to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{feng_optimizing_2024, title = {Optimizing microservice deployment in edge computing with large language models: {Integrating}, author = {Feng, K. and Luo, L. and Xia, Y. and Luo, B. and He, X. and Li, K. and Zha, Z. and Xu, B. and {...}, year = {2024}, url = {https://www.mdpi.com/2073-8994/16/11/1470}, journal = {Symmetry}, note = {Publisher: mdpi.com Type: HTML}, keywords = {source: Google Scholar}, abstract = {… Additionally, we prompted the LLM to generate code without the use of the RAG database … for the LLM to generate appropriate responses, significantly enhancing the factual accuracy …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhao_ontology-aware_2024, title = {Ontology-aware rag for improved question-answering in cybersecurity education}, author = {Zhao, C. and Agrawal, G. and Kumarage, T. and Tan, Z. and Deng, Y. and {...}, year = {2024}, url = {https://arxiv.org/abs/2412.14191}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG approach helps reduce hallucinations and address domain knowledge issues to some extent, the reliability of LLM-… cybersecurity content using RAG and validate LLM outputs with …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jin_orthodoc_2024, title = {Orthodoc: {Multimodal}, author = {Jin, Y. and Zhang, Y.}, year = {2024}, url = {https://arxiv.org/abs/2409.09052}, journal = {arXiv preprint arXiv:2409.09052}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… their conditions and enhancing doctor-patient trust. Computed Tomography (CT) is … Retrieval-Augmented Generation(RAG) module capable of effectively mitigating model hallucinations…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kaintura_orassistant_2024, title = {{ORAssistant}, author = {Kaintura, A. and Luar, S. S. and Almeida, I. I.}, year = {2024}, url = {https://arxiv.org/abs/2410.03845}, journal = {arXiv preprint arXiv:2410.03845}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… as the base LLM model to build and test ORAssistant. Early evaluation results of the RAG-based … ’s output by ensuring that knowledge is retrieved from trusted data sources, generating …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kluibenschadl_fiction_2024, title = {{FROM}, author = {Kluibenschädl, S. and Schlögl, S. and Kruschel, S.}, year = {2024}, url = {https://library.iated.org/view/KLUIBENSCHADL2024FRO}, journal = {ICERI2024 Proceedings}, note = {Publisher: library.iated.org}, keywords = {source: Google Scholar}, abstract = {… Our work has outlined how a RAG-augmented educational LLM can be built using various … We have furthermore shown how the RAG-augmentation helped improve factual accuracy, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{krishna_fact_2024, title = {Fact, fetch, and reason: {A}, author = {Krishna, S. and Krishna, K. and Mohananey, A. and {...}, year = {2024}, url = {https://arxiv.org/abs/2409.12941}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… hallucinated questions and answers from the obtained set. We then evaluated the same LLM … while also mitigating the issues of hallucination present in LLM-generated content. Human …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zeng_federated_2024-2, title = {Federated recommendation via hybrid retrieval augmented generation}, author = {Zeng, H. and Yue, Z. and Jiang, Q. and Wang, D.}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10825302/}, journal = {2024 IEEE International …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… Our proposed hybrid retrieval mechanism and LLM-… LLM, overcoming data sparsity and heterogeneity in FR. Finally, the RAG nature of GPT-FedRec also prevents LLM hallucination, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sui_fidelis_2024, title = {Fidelis: {Faithful}, author = {Sui, Y. and He, Y. and Liu, N. and He, X. and Wang, K. and Hooi, B.}, year = {2024}, url = {https://arxiv.org/abs/2405.13873}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… hallucinations and enable verifiable reasoning, we propose FiDeLiS to improve the factuality of LLM … Our retrieval module Path-RAG mitigate this issue by constraining candidate set St …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ju_flooding_2024, title = {Flooding spread of manipulated knowledge in llm-based multi-agent communities}, author = {Ju, T. and Wang, Y. and Ma, X. and Cheng, P. and Zhao, H. and Wang, Y. and {...}, year = {2024}, url = {https://arxiv.org/abs/2407.07791}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… our attack method can successfully induce LLM-based agents to … through popular retrieval-augmented generation frameworks, … The LLM may not always verify the factual accuracy …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jain_rag_2024, title = {From rag to riches: {Retrieval}, author = {Jain, P. and Soares, L. B. and Kwiatkowski, T.}, year = {2024}, url = {https://arxiv.org/abs/2407.00361}, journal = {arXiv preprint arXiv:2407.00361}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… , the typical approaches chain LLM generations with calls to … evidence corpus using a single LLM and decoding process. … is partially attributed, with LLM hallucinating based on partial …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{bao_faithbench_2024, title = {Faithbench: {A}, author = {Bao, F. S. and Li, M. and Qu, R. and Luo, G. and Wan, E. and Tang, Y. and {...}, year = {2024}, url = {https://arxiv.org/abs/2410.13210}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Retrieval-Augmented Generation (RAG). However, existing evaluations of hallucinations in LLM-… Filtering samples by LLM To balance annotator effort with our goal of LLM diversity, we …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{mohammadjafari_natural_2024, title = {From natural language to sql: {Review}, author = {Mohammadjafari, A. and Maida, A. S. and {...}, year = {2024}, url = {https://arxiv.org/abs/2410.01066}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of LLM-based text-to-SQL systems, from early rule-based models to advanced LLM approaches that use (RAG… transparent AI procedures to build trust in LLM-based text-to-SQL systems. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yepes_financial_2024, title = {Financial report chunking for effective retrieval augmented generation}, author = {Yepes, A. J. and You, Y. and Milczek, J. and Laverde, S. and Li, R.}, year = {2024}, url = {https://arxiv.org/abs/2402.05131}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… problem with LLMs [15,43] when recovering factual information directly from an LLM. In RAG, instead of answering a user query directly using an LLM, the user query is used to retrieve …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{elsharef_facilitating_2024, title = {Facilitating threat modeling by leveraging large language models}, author = {Elsharef, I. and Zeng, Z. and Gu, Z.}, year = {2024}, url = {https://www.ndss-symposium.org/wp-content/uploads/aiscc2024-16-paper.pdf}, journal = {Workshop on AI Systems with …}, note = {Publisher: ndss-symposium.org Type: PDF}, keywords = {source: Google Scholar}, abstract = {… Table V shows the example of hallucination from RAG-based LLM … this RAG-enhance LLM solution for threat modeling. Based on the observations in this study, the RAGenhanced LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{rothman__2024, title = {… for {Natural}, author = {Rothman, D.}, year = {2024}, url = {https://books.google.com/books?hl=en\&lr=\&id=q9P3EAAAQBAJ\&oi=fnd\&pg=PP1\&dq=%22retrieval+augmented+generation%22%7C%22rag%22+%22large+language+model%22%7C%22llm%22%7C%22chatgpt%22+trust%7Cconfidence%7Ccredibility%7Challucination%7Cfactuality%7Ccitation\&ots=-g2PrskpL0\&sig=pnxifQa6ht_TYS3vx4v8LABKL9U}, publisher = {books.google.com}, note = {Type: BOOK}, keywords = {source: Google Scholar}, abstract = {… I want to thank the corporations that trusted me from the start to deliver artificial intelligence … Retrieval Augmented Generation (RAG). We will implement an example of automated RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{maes_fixing_2024, title = {Fixing {Reference}, author = {Maes, S. H.}, year = {2024}, publisher = {OSF}, note = {Type: CITATION}, keywords = {source: Google Scholar}, annote = {Query date: 2025-10-25 20:50:36}, } @article{deventer_interests_2024, title = {From {Interests}, author = {Deventer, H. Van and Mills, M. and Evrard, A.}, year = {2024}, url = {https://arxiv.org/abs/2412.19312}, journal = {arXiv preprint arXiv:2412.19312}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We introduce a two-stage retrieval process for a RAG-based LLM course recommender … with both an explanation and a confidence rating. We show that the LLM’s embedding space …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kommineni_human_2024, title = {From human experts to machines: {An}, author = {Kommineni, V. K. and König-Ries, B. and Samuel, S.}, year = {2024}, url = {https://arxiv.org/abs/2403.08345}, journal = {arXiv preprint arXiv:2403.08345}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Retrieval-Augmented-Generation (RAG) as well as the KG concepts automatically extracted using LLMs, we design a judge LLM, … studies, a prerequisite to trust and validation of results. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{lin_flame_2024, title = {Flame: {Factuality}, author = {Lin, S. C. and Gao, L. and Oguz, B. and Xiong, W. and {...}, year = {2024}, url = {https://proceedings.neurips.cc/paper_files/paper/2024/hash/d16152d53088ad779ffa634e7bf66166-Abstract-Conference.html}, journal = {Advances in Neural …}, note = {Publisher: proceedings.neurips.cc}, keywords = {source: Google Scholar}, abstract = {… the LLM alignment process more factual, by first identifying factors that lead to hallucination in … This is likely because the supervision from RAG contains information unknown to the LLM; …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{barnett_fine-tuning_2024, title = {Fine-tuning or fine-failing? debunking performance myths in large language models}, author = {Barnett, S. and Brannelly, Z. and Kurniawan, S. and {...}, year = {2024}, url = {https://arxiv.org/abs/2406.11201}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… integration allows RAG systems to enhance LLM responses by leveraging domain-specific … , demonstrated a significant reduction in hallucination compared to other generalised LLMs …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{edge_local_2024, title = {From local to global: {A}, author = {Edge, D. and Trinh, H. and Cheng, N. and Bradley, J. and Chao, A. and {...}, year = {2024}, url = {https://arxiv.org/abs/2404.16130}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Specifically, our approach uses the LLM to infer the potential users would use the RAG … AFaCTA: Assisting the annotation of factual claim detection with reliable LLM annotators. In Ku, L.…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{_fine-tuning_2024, title = {Fine-tuning 과 {RAG}, author = {{손지원}, year = {2024}, url = {https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE11825516}, journal = {Proceedings of KIIT …}, note = {Publisher: dbpia.co.kr}, keywords = {source: Google Scholar}, abstract = {… the RAG method … , hallucinations and answer errors occurred frequently, and accuracy and correct response rate were low. On the other hand, the RAG method had fewer hallucinations …}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{tekkesinoglu_feature_2024, title = {From {Feature}, author = {Tekkesinoglu, Sule and Kunze, Lars}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210017268&partnerID=40&md5=e6e40614fddb549ddd0b546564e69448}, booktitle = {{CEUR}, volume = {3803}, pages = {114 -- 132}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 1}, } @article{lala_paperqa_2023, title = {Paperqa: {Retrieval}, author = {Lála, J. and O'Donoghue, O. and Shtedritski, A. and Cox, S. and {...}, year = {2023}, url = {https://arxiv.org/abs/2312.07559}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Nevertheless, standard RAG models follow a fixed, linear flow, … breaking RAG into modular pieces, allowing an agent LLM to … We assessed citation hallucinations from GPT-3.5, GPT4, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{tamber_benchmarking_2025, title = {Benchmarking {LLM}, author = {Tamber, M. S. and Bao, F. S. and Xu, C. and Luo, G. and Kazi, S. and {...}, year = {2025}, url = {https://arxiv.org/abs/2505.04847}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… This paper presents our efforts to measure LLM hallucinations with a focus on … introduce hallucinations when summarizing documents. We discuss Vectara’s existing LLM hallucination …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhang_beefbot_2025, title = {Beefbot: {Harnessing}, author = {Zhang, Z. and Wilson, C. A. and Hay, R. and {...}, year = {2025}, url = {https://aclanthology.org/2025.coling-demos.7/}, journal = {Proceedings of the …}, note = {Publisher: aclanthology.org}, keywords = {source: Google Scholar}, abstract = {… Model fine-tuning can inject factual knowledge into LLM parameters and provide promising results for completing in-domain tasks. We finetune the Llama-3 which is the latest …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{lu_boosting_2025, title = {Boosting {GPT}, author = {Lu, S. and Cosgun, E.}, year = {2025}, url = {https://academic.oup.com/bioinformaticsadvances/article-abstract/5/1/vbaf019/8002096}, journal = {Bioinformatics Advances}, note = {Publisher: academic.oup.com}, keywords = {source: Google Scholar}, abstract = {… In our project, we aimed to improve LLM performance in genomics by adding variant annotation data to LLMs by retrieval-augmented generation (RAG) and fine-tuning techniques. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{li_biomedrag_2025, title = {Biomedrag: {A}, author = {Li, M. and Kilicoglu, H. and Xu, H. and Zhang, R.}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S1532046424001874}, journal = {Journal of Biomedical Informatics}, note = {Publisher: Elsevier Type: HTML}, keywords = {source: Google Scholar}, abstract = {… Retrieval-augmented generation (RAG) involves a solution by retrieving knowledge from an established database to enhance the performance of large language models (LLM)… the LLM. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jiang_bi_2025, title = {Bi'an: {A}, author = {Jiang, Z. and Sun, M. and Zhang, Z. and Liang, L.}, year = {2025}, url = {https://arxiv.org/abs/2502.19209}, journal = {arXiv preprint arXiv:2502.19209}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… an LLM to assess whether the RAG system’s output aligns with the input text. However, the application of LLM-as-a-Judge in RAG hallucination … , for RAG hallucination detection and …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{tomkou_bridging_2025-1, title = {Bridging industrial expertise and xr with llm-powered conversational agents}, author = {Tomkou, D. and Fatouros, G. and Andreou, A. and Makridis, G. and {...}, year = {2025}, url = {https://arxiv.org/abs/2504.05527}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Building upon this existing research, our work integrates RAG-enhanced LLM conversational … from LLM Chat Engine to a user query requesting assistance in troubleshooting citing the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{cui_bailicai_2025, title = {Bailicai: {A}, author = {Cui, L. and Liu, Y. and Ouyang, C. and Yu, Y. and Zhang, J. and {...}, year = {2025}, url = {https://file.sciopen.com/sciopen_public/1895014766676131841.pdf}, journal = {Big Data Mining and …}, note = {Publisher: file.sciopen.com Type: PDF}, keywords = {source: Google Scholar}, abstract = {… In addition, the integration of RAG and LLM in the medical field is still in its infancy[25], and … from factual accuracy[15, 16]. Early research on RAG primarily focused on developing …}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{shandilya_boosting_2025, title = {Boosting the {Capabilities}, author = {Shandilya, Bhargav and Palmer, Alexis}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218492374&partnerID=40&md5=69ec59b9d9594d9cadcbaec2332300a2}, booktitle = {Proceedings - {International}, pages = {7470 -- 7483}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{li_benchmarking_2025, title = {{BENCHMARKING}, author = {Li, Yangning and Li, Yinghui and Wang, Xinyu and Jiang, Yong and Zhang, Zhen and Zheng, Xinran and Wang, Hui and Zheng, Haitao and Huang, Fei and Zhou, Jingren and Yu, Philip S.}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010268589&partnerID=40&md5=49e099f7db1a4f114dacec9d75085fd6}, pages = {90296 -- 90318}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{procko_graph_2024, title = {Graph retrieval-augmented generation for large language models: {A}, author = {Procko, T. T. and Ochoa, O.}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10771030/}, journal = {2024 Conference on AI, Science …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… This paper surveys work incorporating KGs with LLM RAG, intending to equip scientists with a … to tasks from several domains and lessens LLM hallucination. Edge et al. present a Graph …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{an_golden-retriever_2024, title = {Golden-retriever: high-fidelity agentic retrieval augmented generation for industrial knowledge base}, author = {An, Z. and Ding, X. and Fu, Y. C. and Chu, C. C. and Li, Y. and Du, W.}, year = {2024}, url = {https://arxiv.org/abs/2408.00798}, journal = {arXiv preprint arXiv:2408.00798}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Despite its advantages, RAG also faces challenges to be … documents, RAG’s LLM backbone may hallucinate and … method with vanilla LLM (without RAG) and the vanilla RAG method. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{mavromatis_gnn-rag_2024, title = {Gnn-rag: {Graph}, author = {Mavromatis, C. and Karypis, G.}, year = {2024}, url = {https://arxiv.org/abs/2405.20139}, journal = {arXiv preprint arXiv:2405.20139}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… The input given to the LLM contains the KG factual information along with the question and a prompt. For instance, the input becomes “Knowledge: Jamaica → language\_spoken → …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{he_g-retriever_2024, title = {G-retriever: {Retrieval}, author = {He, X. and Tian, Y. and Sun, Y. and Chawla, N. and {...}, year = {2024}, url = {https://proceedings.neurips.cc/paper_files/paper/2024/hash/efaf1c9726648c8ba363a5c927440529-Abstract-Conference.html}, journal = {Advances in …}, note = {Publisher: proceedings.neurips.cc}, keywords = {source: Google Scholar}, abstract = {… the LLM’s pretrained language capabilities, we freeze the LLM and use a soft prompting approach on the output of the GNN. Our RAG-based design mitigates hallucinations … the LLM’s …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{peng_graph_2024, title = {Graph retrieval-augmented generation: {A}, author = {Peng, B. and Zhu, Y. and Liu, Y. and Bo, X. and Shi, H. and Hong, C. and {...}, year = {2024}, url = {https://arxiv.org/abs/2408.08921}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… knowledge base, RAG refines LLM outputs, effectively mitigating issues such as “hallucination”, lack … entities in databases presents challenges for RAG systems. In response, GraphRAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{taiwo_generative_2024, title = {Generative {AI}, author = {Taiwo, R. and Bello, I. T. and Abdulai, S. F. and Yussif, A. M. and {...}, year = {2024}, url = {https://arxiv.org/abs/2402.09939}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… A retrievalaugmented generation (RAG) system was implemented to improve the base LLM further. This mitigated hallucinated text by grounding outputs in relevant dataset …}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{gonzalez_generative_2024, title = {Generative {AI}, author = {Gonzalez, Claudio and Onwuegbuche, Faithful Chiagoziem}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002675634&partnerID=40&md5=55fe03d63c85bb5594fc328e2018c801}, booktitle = {{CEUR}, volume = {3910}, pages = {408 -- 420}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{dong_how_2023, title = {How to build an {AI}, author = {Dong, C.}, year = {2023}, url = {https://arxiv.org/abs/2311.17696}, journal = {arXiv preprint arXiv:2311.17696}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… The system effectively utilizes LLMs and RAG techniques to create an adaptive knowledge base, delivering accurate and personalized responses to student queries. Citations are …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{xie_weknow-rag_2024, title = {Weknow-rag: {An}, author = {Xie, W. and Liang, X. and Liu, Y. and Ni, K. and Cheng, H. and Hu, Z.}, year = {2024}, url = {https://arxiv.org/abs/2408.07611}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… level is below the threshold, we conclude that the LLM lacks sufficient confidence to answer the question and will output ""I don’t know"". Experiments on performance with various …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{cherumanal_walert_2024-1, title = {Walert: {Putting}, author = {Cherumanal, S. P. and Tian, L. and Abushaqra, F. M. and {...}, year = {2024}, url = {https://arxiv.org/abs/2401.07216}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of an open-source LLM; (ii) monitoring the problem of hallucinations (ie, the introduction of … of LLM-based conversational systems [18]. Finally, we plan to deploy RAG approaches to …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{li_wiping_2024, title = {Wiping out the limitations of {Large}, author = {Li, M. M. and Nikishina, I. and Sevgili, Ö and Semmann, M.}, year = {2024}, url = {https://www.alexandria.unisg.ch/entities/publication/e03dcba0-380a-4546-864a-c25f97c92fc9}, publisher = {alexandria.unisg.ch}, keywords = {source: Google Scholar}, abstract = {… for RAG applications, illustrating how RAG can be systematically implemented to improve LLM tasks and … shift roles of human workers?; How does RAGs foster trust in humans? …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{xiong_when_2024, title = {When graph meets retrieval augmented generation for wireless networks: {A}, author = {Xiong, Y. and Zhang, R. and Liu, Y. and Niyato, D. and Xiong, Z. and {...}, year = {2024}, url = {https://arxiv.org/abs/2412.07189}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… frameworks in networking, including robust updates, mitigation of hallucination, and … In RAG, an LLM is augmented by an external knowledge base that retrieves and supplies relevant …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jovanovic_ward_2024, title = {Ward: {Provable}, author = {Jovanović, N. and Staab, R. and Baader, M. and Vechev, M.}, year = {2024}, url = {https://arxiv.org/abs/2410.03537}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… The query q is generally combined with Dq, and fed into an LLM to generate a more factual response r = M(q, Dq). Expanding D also enables access to new information without costly …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wan_what_2024-1, title = {What evidence do language models find convincing?}, author = {Wan, A. and Wallace, E. and Klein, D.}, year = {2024}, url = {https://arxiv.org/abs/2402.11782}, journal = {arXiv preprint arXiv:2402.11782}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We use this dataset to perform sensitivity and counterfactual analyses to explore which text … production RAG models work. However, we could have instead just directly asked the LLM, “…}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{leekha_war_2024, title = {War of {Words}, author = {Leekha, Rohan Singh and Simek, Olga and Dagli, Charlie K.}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200443688&partnerID=40&md5=1dc1aaa21c3e1c7f352b573c2dcd7709}, booktitle = {Proceedings of the {International}, volume = {37}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 2}, } @inproceedings{hou_wikicontradict_2024, title = {{WikiContradict}, author = {Hou, Yufang and Pascale, Alessandra and Carnerero-Cano, Javier and Tchrakian, Tigran T. and Marinescu, Radu and Daly, Elizabeth M. and Padhi, Inkit and Sattigeri, Prasanna S.}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000533993&partnerID=40&md5=e276b1ce26774dfbb3cb1fc79e294253}, booktitle = {Advances in {Neural}, volume = {37}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 1}, } @article{azher_futuregen_2025-1, title = {Futuregen: {Llm}, author = {Azher, I. A. and Mokarrama, M. J. and Guo, Z. and Choudhury, S. R. and {...}, year = {2025}, url = {https://arxiv.org/abs/2503.16561}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… an LLM-as-a-judge approach for evaluation. Our results demonstrated that the RAGbased approach with LLM feedback … Hallucination Rate We evaluated hallucinations by treating each …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{lee_finetune-rag_2025, title = {Finetune-{RAG}, author = {Lee, Z. P. and Lin, A. and Tan, C.}, year = {2025}, url = {https://arxiv.org/abs/2505.10792}, journal = {arXiv preprint arXiv:2505.10792}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… , a simple and effective fine-tuning approach that features the first-of-its-kind RAG … -RAG improves factual accuracy by 21.2\% over the base model. We also propose Bench-RAG, an LLM-…}, annote = {Query date: 2025-10-25 20:50:36}, } @book{aquino_rag_2025, title = {From {RAG}, author = {Aquino, GA e and Azevedo, NS de and Okimoto, L. Y. S. and {...}, year = {2025}, url = {https://www.preprints.org/frontend/manuscript/12d92f418fc17b4bd3e6b6144acf951c/download_pub}, publisher = {preprints.org}, note = {Type: PDF}, keywords = {source: Google Scholar}, abstract = {… in LLM development, ranging from traditional RAG techniques to … progression from traditional RAG to graph-based RAG, and … hallucinations and factual inconsistencies, diminishing user …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{shojaee_federated_2025, title = {Federated retrieval augmented generation for multi-product question answering}, author = {Shojaee, P. and Harsha, S. S. and Luo, D. and Maharaj, A. and Yu, T. and {...}, year = {2025}, url = {https://arxiv.org/abs/2501.14998}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG-QA approaches either query all domains indiscriminately, increasing computational costs and LLM hallucinations, … significantly boosts multi-product RAG-QA performance in terms …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{mukherjee_documents_2025, title = {From {Documents}, author = {Mukherjee, M. and Kim, S. and Chen, X. and Luo, D. and Yu, T. and {...}, year = {2025}, url = {https://arxiv.org/abs/2502.15237}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… The confidence score allows us to filter the KG based on its … for confidence score for constructing the KG for the KG-RAG … our KG-RAG based retriever can be integrated with an LLM to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{su_fast_2025, title = {Fast or better? balancing accuracy and cost in retrieval-augmented generation with flexible user control}, author = {Su, J. and Healey, J. and Nakov, P. and Cardie, C.}, year = {2025}, url = {https://arxiv.org/abs/2502.12145}, journal = {arXiv preprint arXiv:2502.12145}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Retrieval-Augmented Generation (RAG) has emerged as a powerful approach to mitigate large language model (LLM) hallucinations … However, existing RAG frameworks often apply …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{gutierrez_rag_2025, title = {From rag to memory: {Non}, author = {Gutiérrez, B. J. and Shu, Y. and Qi, W. and Zhou, S. and Su, Y.}, year = {2025}, url = {https://arxiv.org/abs/2502.14802}, journal = {arXiv preprint arXiv:2502.14802}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… continual learning solution for production LLM systems. However, … Several RAG frameworks that engage an LLM to explicitly … To evaluate how well RAG systems retain factual memory …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ferrag_llm_2025, title = {From llm reasoning to autonomous ai agents: {A}, author = {Ferrag, M. A. and Tihanyi, N. and Debbah, M.}, year = {2025}, url = {https://arxiv.org/abs/2504.19678}, journal = {arXiv preprint arXiv:2504.19678}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… and hallucinated responses [7], [8], a limitation that RetrievalAugmented Generation (RAG) … employing reflection, planning, and multi-agent collaboration has given rise to Agentic RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_financial_2025, title = {Financial analysis: {Intelligent}, author = {Wang, J. and Ding, W. and Zhu, X.}, year = {2025}, url = {https://arxiv.org/abs/2504.06279}, journal = {arXiv preprint arXiv:2504.06279}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Our findings validate the effectiveness of integrating RAG technology with LLMs for financial analysis tasks and provide valuable insights for future developments in intelligent financial …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang__2025, title = {From"" {Hallucination}, author = {Wang, Q.}, year = {2025}, url = {https://arxiv.org/abs/2503.14392}, journal = {arXiv preprint arXiv:2503.14392}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… the Anchor-RAG framework to mitigate hallucinations. Unlike … analyze the root causes of hallucinations in LLMs. Based on … in reducing hallucinations, enhancing LLM performance, and …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{hyk_queries_2025, title = {From queries to criteria: {Understanding}, author = {Hyk, A. and McCormick, K. and Zhong, M. and Ciucă, I. and {...}, year = {2025}, url = {https://arxiv.org/abs/2507.15715}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… : an LLM-powered retrieval-augmented generation bot for … we deploy is a retrieval augmented generation (RAG) LLM: a … passed to an LLM to provide a response with citations to the user…}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{ongris_frog_2025, title = {{FrOG}, author = {Ongris, Jaycent Gunawan and Tjitrahardja, Eduardus and Darari, Fariz and Ekaputra, Fajar J.}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017116638&partnerID=40&md5=fdae2ea8884ef0e03c866796d59acbc9}, booktitle = {{CEUR}, volume = {4020}, pages = {116 -- 134}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{ming_faitheval_2025, title = {{FAITHEVAL}, author = {Ming, Yifei and Purushwalkam, Senthil and Pandit, Shrey and Ke, Zixuan and Nguyen, Xuan Phi and Xiong, Caiming and Joty, Shafiq Rayhan}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010276740&partnerID=40&md5=3324b70f735fc314ed436005631cb179}, pages = {85296 -- 85322}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 1}, } @article{chen_llms_2024, title = {Llms are biased evaluators but not biased for retrieval augmented generation}, author = {Chen, Y. S. and Jin, J. and Kuo, P. T. and Huang, C. W. and {...}, year = {2024}, url = {https://arxiv.org/abs/2410.20833}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… selfpreference effect in RAG frameworks. Instead, we observe that factual accuracy significantly … Our work extends the exploration of LLM’s self-preference to the RAG framework and …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhao_longrag_2024, title = {Longrag: {A}, author = {Zhao, Q. and Wang, R. and Cen, Y. and Zha, D. and Tan, S. and Dong, Y. and {...}, year = {2024}, url = {https://arxiv.org/abs/2410.18050}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… factual details due to substantial noise. To this end, we propose LongRAG, a general, dual-perspective, and robust LLM-based RAG system paradigm for LCQA to enhance RAG’s …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{hu_lrp4rag_2024, title = {Lrp4rag: {Detecting}, author = {Hu, H. and He, C. and Xie, X. and Zhang, Q.}, year = {2024}, url = {https://arxiv.org/abs/2408.15533}, journal = {arXiv preprint arXiv:2408.15533}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… However, during the RAG process, we find that the LLM’s internal thoughts diverge significantly from the correct answer, leading to failure in answering ""Who did John Evelyn support …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{pipitone_legalbench-rag_2024, title = {Legalbench-rag: {A}, author = {Pipitone, N. and Alami, G. H.}, year = {2024}, url = {https://arxiv.org/abs/2408.10343}, journal = {arXiv preprint arXiv:2408.10343}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… the context window of an LLM, which poses a significant risk … of hallucinated content at the generation step of RAG systems… phase of the RAG pipeline, assessing how well the LLM can …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chiang_llamp_2024, title = {{LLaMP}, author = {Chiang, Y. and Hsieh, E. and Chou, C. H. and Riebesell, J.}, year = {2024}, url = {https://arxiv.org/abs/2401.17244}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Our result indicates that without RAG, vanilla LLMs suffer from hallucinations and misclassify the magnetic orderings of materials. LLaMP with GPT-4 as backend can counteract the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{tao_llm-r_2024, title = {{LLM}, author = {Tao, L. and Huang, Q. and Wu, X. and Zhang, W. and Wu, Y. and Li, B. and {...}, year = {2024}, url = {https://arxiv.org/abs/2411.04476}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… for fine-tuning the LLM. This method … RetrievalAugmented Generation (RAG) technologies are adopted to optimize the generation steps and mitigate the phenomenon of hallucination …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{comendant_large_2024, title = {Large language model-based sport coaching system using retrieval-augmented generation and user models}, author = {Comendant, C.}, year = {2024}, publisher = {University of Twente}, note = {Type: CITATION}, keywords = {source: Google Scholar}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yu_large-language_2024, title = {Large-language models: {The}, author = {Yu, S. and Ran, N. and Liu, J.}, year = {2024}, url = {https://www.sciencedirect.com/science/article/pii/S2949747724000344}, journal = {Artificial Intelligence Chemistry}, note = {Publisher: Elsevier Type: HTML}, keywords = {source: Google Scholar}, abstract = {Large Language Models (LLMs), such as GPT-4, are precipitating a new ""industrial revolution"" by significantly enhancing productivity across various domains. These models encode an …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_llms_2024, title = {Llms know what they need: {Leveraging}, author = {Wang, K. and Duan, F. and Li, P. and Wang, S. and Cai, X.}, year = {2024}, url = {https://arxiv.org/abs/2404.14043}, journal = {arXiv preprint arXiv:2404.14043}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Retrieval-Augmented Generation (RAG) demonstrates great value in alleviating outdated knowledge or hallucination … fully utilize the LLM’s parametric knowledge, we prompt the LLM to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jacobs_leveraging_2024-1, title = {Leveraging lecture content for improved feedback: {Explorations}, author = {Jacobs, S. and Jaschke, S.}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10663001/}, journal = {2024 36th International Conference on …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… to the Large Language Model GPT-4 as external knowledge source together with timestamps as metainformation by using RAG. The purpose of this is to prevent hallucinations and to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{belyi_luna_2024, title = {Luna: an evaluation foundation model to catch language model hallucinations with high accuracy and low cost}, author = {Belyi, M. and Friel, R. and Shao, S. and Sanyal, A.}, year = {2024}, url = {https://arxiv.org/abs/2406.00975}, journal = {arXiv preprint arXiv:2406.00975}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of RAG in production settings, we identify long-context RAG … precision long-context RAG hallucination detection. Through extensive … We find that LLM responses often contain transition …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{cederlund_llmrag_2024, title = {Llmrag: {An}, author = {Cederlund, O. and Alawadi, S. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10710181/}, journal = {2024 9th International …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… The introduction of an LLM agent as a digital co-worker to IT technicians in support … as Retrieval-Augmented Generation (RAG), the LLM is equipped to avoid generating hallucinations […}, annote = {Query date: 2025-10-25 20:50:36}, } @article{fuad_llm-ref_2024, title = {Llm-ref: {Enhancing}, author = {Fuad, K. A. A. and Chen, L.}, year = {2024}, url = {https://arxiv.org/abs/2411.00294}, journal = {arXiv preprint arXiv:2411.00294}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of our tool over existing RAG-based systems. The proposed LLM-Ref demonstrates significant per… Despite their popularity, RAG-based systems fall short in offering citations. While …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sriramanan_llm-check_2024, title = {Llm-check: {Investigating}, author = {Sriramanan, G. and Bharti, S. and Sadasivan, V. S. and {...}, year = {2024}, url = {https://proceedings.neurips.cc/paper_files/paper/2024/hash/3c1e1fdf305195cd620c118aaa9717ad-Abstract-Conference.html}, journal = {Advances in …}, note = {Publisher: proceedings.neurips.cc}, keywords = {source: Google Scholar}, abstract = {… detection in scenarios where ground-truth references are also available, such as in the setting of Retrieval-Augmented Generation (RAG). We demonstrate that the proposed detection …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ravi_lynx_2024, title = {Lynx: {An}, author = {Ravi, S. S. and Mielczarek, B. and Kannappan, A. and Kiela, D. and {...}, year = {2024}, url = {https://arxiv.org/abs/2407.08488}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… detection LLM that is capable of advanced reasoning on challenging real-world hallucination … , our work focuses on the problem of hallucination detection as it applies to RAG settings. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{benzinho_llm_2024, title = {{LLM}, author = {Benzinho, J. and Ferreira, J. and Batista, J. and Pereira, L. and {...}, year = {2024}, url = {https://www.mdpi.com/2076-3417/14/19/8856}, journal = {applied sciences}, note = {Publisher: mdpi.com Type: HTML}, keywords = {source: Google Scholar}, abstract = {… RAG provides models with sources of information that can be cited and consulted by the user, thus enhancing confidence … agent powered by RAG-based LLM technology, we can …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{dejean_let_2024, title = {Let your {LLM}, author = {Déjean, H.}, year = {2024}, url = {https://arxiv.org/abs/2412.11536}, journal = {arXiv preprint arXiv:2412.11536}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… , indicating that the LLM is confident in answering questions without resorting to RAG. TriviaQA is … efficient to halt the LLM as early as possible and then assess whether RAG activation is …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{masoudifard_leveraging_2024, title = {Leveraging graph-rag and prompt engineering to enhance llm-based automated requirement traceability and compliance checks}, author = {Masoudifard, A. and Sorond, M. M. and Madadi, M. and {...}, year = {2024}, url = {https://arxiv.org/abs/2412.08593}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Moreover, hallucination, where models generate factually incorrect yet plausible content, … Graph-RAG to retrieve the most relevant content from reference texts. Graph-RAG enhances …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{abshari_llm-assisted_2024, title = {Llm-assisted physical invariant extraction for cyber-physical systems anomaly detection}, author = {Abshari, D. and Fu, C. and Sridhar, M.}, year = {2024}, url = {https://www.researchgate.net/profile/Danial-Abshari/publication/385920298_LLM-assisted_Physical_Invariant_Extraction_for_Cyber-Physical_Systems_Anomaly_Detection/links/679c8c94207c0c20fa6b0b57/LLM-assisted-Physical-Invariant-Extraction-for-Cyber-Physical-Systems-Anomaly-Detection.pdf}, journal = {arXiv preprint arXiv:2411.10918}, note = {Publisher: researchgate.net Type: PDF}, keywords = {source: Google Scholar}, abstract = {… To overcome the challenges of the unstructured documents format and LLM hallucination, we propose the enhancement of multi-modal RAG and dedicated chain-of-thought prompt …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{park_literature_2024, title = {Literature review of {AI}, author = {Park, D. M. and Lee, H. J.}, year = {2024}, journal = {Informatization Policy}, note = {Publisher: National Information Society Agency Type: CITATION}, keywords = {source: Google Scholar}, annote = {Query date: 2025-10-25 20:50:36}, } @article{emonet_llm-based_2024, title = {Llm-based sparql query generation from natural language over federated knowledge graphs}, author = {Emonet, V. and Bolleman, J. and Duvaud, S. and Farias, TM de and {...}, year = {2024}, url = {https://arxiv.org/abs/2410.06062}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We introduce a Retrieval-Augmented Generation (RAG) system for translating user … To enhance accuracy and reduce hallucinations in query generation, our system utilises metadata …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{liang_learning_2024, title = {Learning to trust your feelings: {Leveraging}, author = {Liang, Y. and Song, Z. and Wang, H. and Zhang, J.}, year = {2024}, url = {https://arxiv.org/abs/2401.15449}, journal = {arXiv preprint arXiv:2401.15449}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of fact-conflicting hallucination, where LLM produces fluent … hallucination mitigation methods, such as retrieval augmentation generation (RAG), address fact-conflict hallucination of LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{nikolakopoulos_large_2024, title = {Large language models in modern forensic investigations: {Harnessing}, author = {Nikolakopoulos, A. and Evangelatos, S. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10654427/}, journal = {… \& Education (EEITE)}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… of a Retrieval Augmented Generation (RAG) LLM, trained with … Suspect recommendation with confidence level estimation: … confidence level, feeding them to the RAG LLM for the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{hashemi_llm-rubric_2024, title = {{LLM}, author = {Hashemi, H. and Eisner, J. and Rosset, C. and Durme, B. Van and {...}, year = {2024}, url = {https://arxiv.org/abs/2501.00274}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… But can LLM evaluation be trusted? It solves the time, scaling, and … LLM but by a real human. The assistant in these three systems may be summarized as “no RAG” (DS1), “oracle RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chen_leverage_2024, title = {Leverage knowledge graph and large language model for law article recommendation: {A}, author = {Chen, Y. and Chen, M. and Zhu, Y. and Pei, J. and Chen, S. and Zhou, Y. and {...}, year = {2024}, url = {https://arxiv.org/abs/2410.04949}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… TFIDF-RAG, LightRAG, Graph-RAG method. This indicates that the proposed approach effectively mitigates the hallucinations in LLMs. We believe this is because other RAG method …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{li_llm_2024-1, title = {Llm inference serving: {Survey}, author = {Li, B. and Jiang, Y. and Gadepally, V. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10938426/}, journal = {2024 IEEE High …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… LLM serving include retrieval-augmented generation (RAG) and mixtureof-experts (MoE) inference. RAG … tendency to generate inaccurate or fabricated information (hallucinations) [45]. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jho_leveraging_2024, title = {Leveraging generative {AI}, author = {Jho, H.}, year = {2024}, url = {https://www.researchgate.net/profile/Hunkoog-Jho/publication/383561189_Leveraging_Generative_AI_in_Physics_Education_Addressing_Hallucination_Issues_in_Large_Language_Models/links/6819b0a0d1054b0207ea3d26/Leveraging-Generative-AI-in-Physics-Education-Addressing-Hallucination-Issues-in-Large-Language-Models.pdf}, journal = {New Phys}, note = {Publisher: researchgate.net Type: PDF}, keywords = {source: Google Scholar}, abstract = {… , reasoning, iterative querying, and Retrieval-Augmented Generation (RAG). These methods aim … Comparison of answers about the same question generated by generic LLM and RAG. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{_llm_2024, title = {{LLM}, author = {{강태욱}, year = {2024}, url = {https://scholar.kyobobook.co.kr/article/detail/4010069980447}, journal = {KIBIM Magazine}, note = {Publisher: scholar.kyobobook.co.kr}, keywords = {source: Google Scholar}, abstract = {… processing, and hallucination problems must be solved. This study proposes an LLM-based … This study focuses on the RAG (Retrieval- Augmented Generation) document generation …}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{xie_leveraging_2024, title = {Leveraging {Grounded}, author = {Xie, Eric and Xiong, Guangzhi and Yang, Haolin and Coleman, Olivia Fudge and Kennedy, Michael J. and Zhang, Aidong}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219553031&partnerID=40&md5=ace3fc343db7dbd2e2ec0d9158b48ff7}, booktitle = {Proceedings of {Machine}, volume = {264}, pages = {207 -- 220}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 1}, } @inproceedings{zemicheal_llm_2024, title = {{LLM}, author = {ZeMicheal, Tadesse and Chen, Hsin and Davis, Shawn and Allen, Rachel and Demoret, Michael and Song, Ashley}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218407315&partnerID=40&md5=3b6b5ffd7ae35fa504261cce4bba00a9}, booktitle = {{CEUR}, volume = {3920}, pages = {161 -- 173}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{thakur_nomiracl_2023, title = {Nomiracl: {Knowing}, author = {Thakur, N. and Bonifacio, L. and Zhang, X. and Ogundepo, O. and {...}, year = {2023}, url = {https://arxiv.org/abs/2312.11361}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM hallucinations against first-stage retrieval errors in RAG. (… lenges in LLM robustness by often hallucinating an answer … on LLM’s generation results, and find several hallucination …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wu_knowledge_2024, title = {Knowledge graph integration and self-verification for comprehensive retrieval-augmented generation}, author = {Wu, C. and Shen, T. and Yan, R. and Wang, H. and Liu, Z. and {...}, year = {2024}, url = {https://openreview.net/forum?id=457wTt0ngj}, journal = {… Retrieval Augmented …}, note = {Publisher: openreview.net}, keywords = {source: Google Scholar}, abstract = {… contextual understanding and reduce hallucinations on RAG. LLM’s advanced capabilities … advanced capabilities of LLM to enhance the robustness and credibility of our information …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yang_knowledge_2024, title = {Knowledge {Graph}, author = {Yang, C. and Xu, R. and Luo, L. and Pan, S.}, year = {2024}, url = {https://www.cs.emory.edu/~jyang71/files/klc.pdf}, journal = {IEEE Data Engineering Bulletin}, note = {Publisher: cs.emory.edu Type: PDF}, keywords = {source: Google Scholar}, abstract = {… of KG and LLM co-learning, especially through a structure-oriented retrieval augmented generation (… facts from KGs during the LLM reasoning process, which are used to mitigate factual …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sanmartin_kg-rag_2024, title = {Kg-rag: {Bridging}, author = {Sanmartin, D.}, year = {2024}, url = {https://arxiv.org/abs/2405.12035}, journal = {arXiv preprint arXiv:2405.12035}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… employs an LLM configured with a standard RAG prompt as … -RAG approach against vector RAG and no RAG specifically, … to quantify the incidence of hallucinations. These metrics allow …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{lima_know_2024, title = {Know {Your}, author = {Lima, RT De and Gupta, S. and Berrospi, C. and Mishra, L. and {...}, year = {2024}, url = {https://arxiv.org/abs/2411.19710}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… ) have been developed for automated LLMassisted evaluation of RAG systems. While these … probability of an LLM hallucination grows with each query. These hallucinations can lead to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{radhakrishnan_knowing_2024, title = {Knowing {When}, author = {Radhakrishnan, P. and Chen, J. and Xu, B. and Ramaswami, P. and {...}, year = {2024}, url = {https://arxiv.org/abs/2409.13741}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… For RAG, we measure the fraction of LLM-generated statistical claims that are accurate (ie, not hallucinated). This means we evaluate the generated statistical value against the table …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{xiao_krail_2024, title = {Krail: {A}, author = {Xiao, X. and Chen, P. and Qi, B. and Zhao, H. and Liang, J. and Tong, J. and {...}, year = {2024}, url = {https://arxiv.org/abs/2412.18627}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM-based two-stage framework: We propose a novel LLM- … of LLM factual accuracy with RAG to mitigate hallucinations, … Inspired by these advancements, we aim to leverage RAG to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{febrian_kemenkeugpt_2024, title = {{KemenkeuGPT}, author = {Febrian, G. F. and Figueredo, G.}, year = {2024}, url = {https://arxiv.org/abs/2407.21459}, journal = {arXiv preprint arXiv:2407.21459}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM … ChatGPT and LLaMA, this approach achieves a 15\% to 48\% performance gain in accuracy and F1 scores [Zhang et al. 2023]. RAG addresses the issue of factual accuracy in LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{noauthor_knowllm_2024, title = {{KnowLLM}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204904251&partnerID=40&md5=dfebedd156b2fd9e9827b3c0f7da4388}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{noauthor_knowledgenlp_2024, title = {{KnowledgeNLP}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204892873&partnerID=40&md5=f25eb3d69cd9ba28a97ae467c5286220}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{xu_knowledge_2024, title = {Knowledge {Graph}, author = {Xu, Zihao and Shen, Zhejun and Zhou, Qunzhi and Ristoski, Petar}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002727392&partnerID=40&md5=c8ab1c010fa6698e51f3a777260abcd6}, booktitle = {{CEUR}, volume = {3950}, pages = {31 -- 39}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{zhang_knowgpt_2024, title = {{KnowGPT}, author = {Zhang, Qinggang and Dong, Junnan and Chen, Hao and Zha, Daochen and Yu, Zailiang and Huang, Xiao}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000537404&partnerID=40&md5=1fccdd8217ca84a55e4d4f0ec8d42ff8}, booktitle = {Advances in {Neural}, volume = {37}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 5}, } @article{bansal_understanding_2025, title = {Understanding and {Mitigating}, author = {Bansal, R. and Chandra, R. and Lulla, K.}, year = {2025}, url = {https://www.researchgate.net/profile/Rishab-Bansal-5/publication/392513063_Understanding_and_Mitigating_Strategies_for_Large_Language_Model_LLMs_Hallucinations_in_HR_Chatbots/links/68bdfa68c76fc271eb321a42/Understanding-and-Mitigating-Strategies-for-Large-Language-Model-LLMs-Hallucinations-in-HR-Chatbots.pdf}, journal = {International Journal of …}, note = {Publisher: researchgate.net Type: PDF}, keywords = {source: Google Scholar}, abstract = {… [19] Under a RAG system, the LLM is expected to base its response on relevant material obtained from a trustworthy knowledge source (such as a corporate HR policy database or …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{budakoglu_unveiling_2025, title = {Unveiling the {Power}, author = {Budakoglu, G. and Emekci, H.}, year = {2025}, url = {https://ieeexplore.ieee.org/abstract/document/10887212/}, journal = {IEEE Access}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… The present work has shown that fine-tuned LLM integration in RAG pipelines is not without its … emphasis needs to be given to semantic and factual integrity in the generated text. Our …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{gao_u-niah_2025, title = {U-niah: {Unified}, author = {Gao, Y. and Xiong, Y. and Wu, W. and Huang, Z. and Li, B. and {...}, year = {2025}, url = {https://arxiv.org/abs/2503.00353}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We identify typical error patterns including omission due to noise, hallucination under high noise critical condition, and self-doubt behaviors. Our work not only highlights the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ma_unifying_2025, title = {Unifying {Large}, author = {Ma, C. and Chen, Y. and Wu, T. and Khan, A. and Wang, H.}, year = {2025}, url = {https://www.openproceedings.org/2025/conf/edbt/paper-T4.pdf}, journal = {EDBT}, note = {Publisher: openproceedings.org Type: PDF}, keywords = {source: Google Scholar}, abstract = {… The Graph RAG enhances the explainability of LLM responses by tracing relevant subgraphs … Mitigating large language model hallucinations via autonomous knowledge graph-based …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{rajendran_uppgiftsanpassning_2025, title = {Uppgiftsanpassning av {LLM}, author = {Rajendran, A. Asalatha and Saji, B. Annamma}, year = {2025}, url = {https://www.diva-portal.org/smash/record.jsf?pid=diva2:1969027}, publisher = {diva-portal.org}, keywords = {source: Google Scholar}, abstract = {… introduces a hybrid approach that combines LoRA and RAG… patterns efficiently, while RAG injects relevant external knowledge … of LoRA and RAG based on the model's confidence. This …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_using_2025, title = {Using {Large}, author = {Wang, Chenkai and Ke, Chengrong and Huang, Ming Siang and Chong, Inn Wen and Yang, Yihsin and Tseng, S. Vincent Shin Mu and Dai, Hong Jie}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212611510&partnerID=40&md5=59439a85628c0fdd94322a4ad548c719}, journal = {Pacific Symposium on Biocomputing}, volume = {30}, pages = {121 -- 137}, note = {Type: Article}, keywords = {source: Scopus}, annote = {Cited by: 3}, } @inproceedings{wright_using_2025, title = {Using {Digital}, author = {Wright, Brian and Guruvayur, Vishwanath and Napolitano, Luke and Ozar, Doruk and Rivera, Ali and Sai, Ananya and Tafesse, Bereket}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013474172&partnerID=40&md5=7d42e3a5c9b4a3443cb0133e10be7f17}, booktitle = {{CEUR}, volume = {4010}, pages = {59 -- 70}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{xu_using_2025, title = {Using {Clinical}, author = {Xu, Xingru and Dumontier, Michel J. and Sun, Chang}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012093656&partnerID=40&md5=9413007753d2abbc6649416d698bf552}, booktitle = {{CEUR}, volume = {4001}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{meng_kerag_r_2025, title = {{KERAG}, author = {Meng, Z. and Yi, Z. and Ounis, I.}, year = {2025}, url = {https://arxiv.org/abs/2507.05863}, journal = {arXiv preprint arXiv:2507.05863}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… to inaccuracies or hallucinations, … RAG by pre-training a graph attention network (GAT) to select the most relevant triple for the target users for the used LLM, thereby enhancing the LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_knowledge_2025, title = {Knowledge graph retrieval-augmented generation for llm-based recommendation}, author = {Wang, S. and Fan, W. and Feng, Y. and Lin, S. and Ma, X. and Wang, S. and {...}, year = {2025}, url = {https://arxiv.org/abs/2501.02226}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… advancements, LLM-… LLM backbones, particularly issues of hallucinations and the lack of up-todate and domain-specific knowledge. Recently, Retrieval-Augmented Generation (RAG) …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ma_knowledge_2025, title = {Knowledge graph-based retrieval-augmented generation for schema matching}, author = {Ma, C. and Chakrabarti, S. and Khan, A. and Molnár, B.}, year = {2025}, url = {https://arxiv.org/abs/2501.08686}, journal = {arXiv preprint arXiv:2501.08686}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… To highlight the hallucinations mitigation of our KGRAG4SM, we ask the LLM to return the results for the given schema-matching questions and provide explanations. Case Verification. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jiang_knowledge_2025, title = {Knowledge assimilation: {Implementing}, author = {Jiang, J. and Yan, L. and Liu, H. and Xia, Z. and Wang, H. and Yang, Y. and {...}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S0950705125002448}, journal = {Knowledge-based …}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… a novel Knowledge-guided Agriculture LLM (KALLM) designed … At the sentence level, we introduce a self-reflective RAG … LLMs and the current SFT-RAG pipeline show that our KALLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{hasan_llm_2025, title = {{LLM}, author = {Hasan, S. and Rezai, A.}, year = {2025}, url = {https://www.diva-portal.org/smash/record.jsf?pid=diva2:1968861}, publisher = {diva-portal.org}, keywords = {source: Google Scholar}, abstract = {… this study is to compare factual accuracy, retrieval quality and hyperparameter sensitivity of a RAG system built on a relatively smaller LLM, against a state-of-the-art large LLM on open-…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{dong_leveraging_2025, title = {Leveraging {LLM}, author = {Dong, G. and Li, X. and Zhang, Y. and Deng, M.}, year = {2025}, url = {https://arxiv.org/abs/2506.21384}, journal = {arXiv preprint arXiv:2506.21384}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… , factuality, and relevance of generated text. Recent efforts [5, 7, 23, 24] have leveraged RAG to … better alignment with the information needs of the LLM. Additionally, some studies [2, 43] …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kovacs_lettucedetect_2025, title = {Lettucedetect: {A}, author = {Kovács, Á and Recski, G.}, year = {2025}, url = {https://arxiv.org/abs/2502.17125}, journal = {arXiv preprint arXiv:2502.17125}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… both hallucinations and coverage errors in LLM-generated responses. Fine-tuned LLM … note that we were unable to compare our results with RAG-HAT on this task because they did not …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{sobhan_llm-assisted_2025, title = {{LLM}, author = {Sobhan, S. and Haque, M. A.}, year = {2025}, url = {https://arxiv.org/abs/2506.23136}, journal = {arXiv preprint arXiv:2506.23136}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… On the other hand, the typical RAG pipeline suffered from hallucination because the question was about transformer, and also the given document was about transformer, even though it …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{li_lokis_2025, title = {Loki's {Dance}, author = {Li, C. and Wang, P. and Wang, C. and Zhang, L. and Liu, Z. and Ye, Q. and {...}, year = {2025}, url = {https://arxiv.org/abs/2507.02870}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… First, we establish the first unified theoretical framework for LLM hallucinations, formally re… In conclusion, RAG constitutes a fundamental approach to augmenting the capabilities of …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{erickson_llm_2025, title = {{LLM}, author = {Erickson, J. S. and Santos, H. and Pinheiro, V. and Mccusker, J. P. and {...}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S1570826824000398}, journal = {Journal of Web …}, note = {Publisher: Elsevier Type: HTML}, keywords = {source: Google Scholar}, abstract = {… hallucinations and hence provides more insight into where in the LLM’s response a hallucination … , verifying, and analyzing LLM responses using RAG systems and Knowledge Graphs (…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{smajic_large_2025-1, title = {Large language models for structured and semi-structured data, recommender systems and knowledge base engineering: a survey of recent techniques and …}, author = {Smajić, A. and Karlović, R. and Dasko, M. Bobanović and Lorencin, I.}, year = {2025}, url = {https://www.mdpi.com/2079-9292/14/15/3153}, journal = {Electronics}, note = {Publisher: mdpi.com Type: HTML}, keywords = {source: Google Scholar}, abstract = {… Although this review primarily focuses on the technical and application aspects of LLM-… like RAG and KG enhancement significantly improve factual accuracy and reduce hallucinations. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{bezerra_llmquoter_2025, title = {Llmquoter: enhancing rag capabilities through efficient quote extraction from large contexts}, author = {Bezerra, Y. F. and Weigang, L.}, year = {2025}, url = {https://arxiv.org/abs/2501.05554}, journal = {arXiv preprint arXiv:2501.05554}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… The applications of LLM distillation are diverse, ranging from mitigating hallucinations to … To achieve this, we employ a distillation process in which a large LLM generates high-…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wahidur_legal_2025-1, title = {Legal query rag}, author = {Wahidur, R. S. M. and Kim, S. and Choi, H. and Bhatti, D. S. and Lee, H. N.}, year = {2025}, url = {https://ieeexplore.ieee.org/abstract/document/10887211/}, journal = {IEEE Access}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… RAG aids in reducing hallucinations and facilitates continuous knowledge updates and … embedding LLM and the generative LLM. In contrast, the RAG Layer integrates advanced RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{galat_llm_2025, title = {{LLM}, author = {Galat, D. and Molla-Aliod, D.}, year = {2025}, url = {https://arxiv.org/abs/2509.08596}, journal = {arXiv preprint arXiv:2509.08596}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… through RAG consistently improves answer quality and factual accuracy compared to LLM … terms LLM or Large Language Model in their title, and 3 additional papers used the terms …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{belyi_luna_2025, title = {Luna: {A}, author = {Belyi, M. and Friel, R. and Shao, S. and Sanyal, A.}, year = {2025}, url = {https://aclanthology.org/2025.coling-industry.34/}, journal = {Proceedings of the 31st …}, note = {Publisher: aclanthology.org}, keywords = {source: Google Scholar}, abstract = {… of RAG in production settings, we identify long-context RAG … high precision long-context RAG hallucination detection. Through … 2023) LLM judges leverage LLM’s inherent reasoning …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{ning_less_2025, title = {Less {LLM}, author = {Ning, J. and Kong, Y. and Long, Y. and Callan, J.}, year = {2025}, url = {https://arxiv.org/abs/2510.02657}, journal = {arXiv preprint arXiv:2510.02657}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {Retrieval-Augmented Generation (RAG) couples document … that corpus scaling consistently strengthens RAG and can often … stronger RAG, often comparable to enlarging the LLM itself. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zhao_lmar_2025, title = {Lmar: {Language}, author = {Zhao, Y. and Ding, Y. and Zhang, Z. and Yao, D. and Xu, Y.}, year = {2025}, url = {https://arxiv.org/abs/2508.05672}, journal = {arXiv preprint arXiv:2508.05672}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… sources, RAG substantially mitigates hallucination and … LLM-augmented text clustering mechanism that distills the contextual understanding and discrimination capabilities of the LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{iranmanesh_llm-assisted_2025, title = {{LLM}, author = {Iranmanesh, S. and Saadany, H. and Vakaj, E.}, year = {2025}, url = {https://arxiv.org/abs/2504.16813}, journal = {arXiv preprint arXiv:2504.16813}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Mitigating large language model hallucinations via autonomous knowledge graph-based retrofitting. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{fayyazi_llm_2025, title = {{LLM}, author = {Fayyazi, R. and Zuzak, M. and Yang, S. J.}, year = {2025}, url = {https://arxiv.org/abs/2506.12100}, journal = {arXiv preprint arXiv:2506.12100}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… This analysis reveals how RAG affects the model’s confidence in generating specific tokens and provides insight into the contextual dependencies introduced by the retrieved …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{savage_large_2025, title = {Large language model uncertainty proxies: discrimination and calibration for medical diagnosis and treatment}, author = {Savage, T. and Wang, J. and Gallo, R. and Boukil, A. and {...}, year = {2025}, url = {https://academic.oup.com/jamia/article-abstract/32/1/139/7819854}, journal = {Journal of the …}, note = {Publisher: academic.oup.com}, keywords = {source: Google Scholar}, abstract = {… context provided by RAG can errantly lead the … LLM uncertainty are important for building medical LLM-RAG systems. In this study we evaluate 3 proxies of LLM uncertainty: confidence …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wu_leveraging_2025, title = {Leveraging {FDA}, author = {Wu, L. and Fang, H. and Qu, Y. and Xu, J. and Tong, W.}, year = {2025}, url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC12098182/}, journal = {Drug Safety}, note = {Publisher: pmc.ncbi.nlm.nih.gov Type: HTML}, keywords = {source: Google Scholar}, abstract = {… will not risk a hallucination in the results… RAG, which restricted the reference used in the LLM inference solely to the specific labeling documents instead of using the full scope of the LLM’…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kalyuzhnaya_llm_2025, title = {{LLM}, author = {Kalyuzhnaya, A. and Mityagin, S. and Lutsenko, E. and {...}, year = {2025}, url = {https://search.ebscohost.com/login.aspx?direct=true\&profile=ehost\&scope=site\&authtype=crawler\&jrnl=26246511\&AN=183336541\&h=0pICgql%2Bey7ZL1YAQE4iib5dbwaBiWjyLc6tqZE3sd6vLsiLGJ4U0smDycxB2boqa%2FC0RX3jT2MvCufSaSMFnw%3D%3D\&crl=c}, journal = {… Cities (2624-6511 …}, note = {Publisher: search.ebscohost.com}, keywords = {source: Google Scholar}, abstract = {… Effectiveness In this subsection, we discuss the results of using RAG to answer questions. First, … Unlike LLMs generating answers without context, the LLM-based system relies on factual …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{mukherjee_llm-driven_2025, title = {{LLM}, author = {Mukherjee, K. and Kantarcioglu, M.}, year = {2025}, url = {https://arxiv.org/abs/2508.21323}, journal = {arXiv preprint arXiv:2508.21323}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We highlight how LLM and RAG introduce new opportunities and challenges in provenance-… A recurring risk with LLM-driven systems is hallucination when generated outputs diverge …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{aratchige_llms_2025, title = {Llms working in harmony: {A}, author = {Aratchige, R. M. and Ilmini, W.}, year = {2025}, url = {https://arxiv.org/abs/2504.01963}, journal = {arXiv preprint arXiv:2504.01963}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… To tackle the issue of LLM hallucinations, the authors implement a code… RAG’s impact goes beyond immediate performance gains; it laid the groundwork for future developments in LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_large_2025-1, title = {Large language model as a catalyst: {A}, author = {Wang, Y. and Afzal, M. M. and Li, Z. and Zhou, J. and Feng, C. and {...}, year = {2025}, url = {https://ieeexplore.ieee.org/abstract/document/10915543/}, journal = {IEEE Transactions …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… , our framework integrates retrieval-augmented generation (RAG), … to explore the use of LLM and RAG to solve the BSS problem… LLM interaction can mitigate the impact of hallucinations, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{paul_llm-assisted_2025, title = {{LLM}, author = {Paul, S. and Alemi, F. and Macwan, R.}, year = {2025}, url = {https://arxiv.org/abs/2504.00428}, journal = {arXiv preprint arXiv:2504.00428}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… reduces hallucinations and enhances factual accuracy [5], [41]. Additionally, RAG allows … This review of the literature evaluates the leading technologies in LLM and RAG techniques …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{qian_large_2025, title = {Large language model-empowered paradigm for automated geotechnical site planning and geological characterization}, author = {Qian, Z. and Shi, C.}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S0926580525001438}, journal = {Automation in Construction}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… LLM-based agent named “Geologist” to streamline geotechnical site planning and subsequent geological interpretation. A Multihop-Retrieval-Augmented Generation … the proposed LLM-…}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{wang_llms_2025, title = {{LLMs}, author = {Wang, Keheng and Duan, Feiyu and Li, Peiguang and Wang, Sirui and Cai, Xunliang}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218420242&partnerID=40&md5=d29b223c39c202b3a323bd2681bf7bdf}, booktitle = {Proceedings - {International}, pages = {2379 -- 2400}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 2}, } @inproceedings{emonet_llm-based_2025, title = {{LLM}, author = {Emonet, Vincent and Bolleman, Jerven Tjalling and Duvaud, Séverine and de Farias, Tarcisio Mendes and Sima, Ana Claudia}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003725579&partnerID=40&md5=b4f921224527cdda4878a73c92235b62}, booktitle = {{CEUR}, volume = {3953}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{li_traq_2023, title = {Traq: {Trustworthy}, author = {Li, S. and Park, S. and Lee, I. and Bastani, O.}, year = {2023}, url = {https://arxiv.org/abs/2307.04642}, journal = {arXiv preprint arXiv:2307.04642}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG reduces hallucinations by retrieving passages from a knowledge base such as Wikipedia and then using an LLM to … rates of retriever and LLM sets (named Ret and LLM), and with …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{liu_detecting_2025-1, title = {Detecting emergencies in patient portal messages using large language models and knowledge graph-based retrieval-augmented generation}, author = {Liu, S. and Wright, A. P. and McCoy, A. B. and Huang, S. S. and {...}, year = {2025}, journal = {Journal of the …}, note = {Publisher: Oxford Academic Type: CITATION}, keywords = {source: Google Scholar}, annote = {Query date: 2025-10-25 20:50:36}, } @article{xiong_dr-rag_2025, title = {{DR}, author = {Xiong, X. and Cai, H. and Yu, H. and Shen, B. and Hu, P.}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S1474034625005816}, journal = {Advanced Engineering Informatics}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… data using a hybrid R2D-LLM approach. We create a rule … a retrieval-augmented generation pipeline with a binary classifier guides rule selection and prompt templates enhance LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{pyae_developing_2025, title = {Developing a {RAG}, author = {Pyae, M. S. and Phyo, S. S. and Kyaw, STMM and Lin, T. S. and {...}, year = {2025}, url = {https://ieeexplore.ieee.org/abstract/document/10961967/}, journal = {… on Digital Arts …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… retrieves and generates sequentially, while Advanced RAG ensures factual accuracy and … SouLLMate, an adaptive LLM-driven system that leverages advanced technologies like RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{cremaschi_decoding_2025, title = {Decoding the mind: {A}, author = {Cremaschi, M. and Ditolve, D. and Curcio, C. and Panzeri, A. and {...}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S0957417425008139}, journal = {Expert Systems with …}, note = {Publisher: Elsevier Type: HTML}, keywords = {source: Google Scholar}, abstract = {… LLMind Chat leverages a Retrieval Augmented Generation (RAG) model based on the Gemma 2 (27B parameters), specifically adapted to the context of the ICD-11. This RAG model …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{xu_does_2025, title = {Does context matter? contextualjudgebench for evaluating llm-based judges in contextual settings}, author = {Xu, A. and Bansal, S. and Ming, Y. and Yavuz, S. and Joty, S.}, year = {2025}, url = {https://arxiv.org/abs/2503.15620}, journal = {arXiv preprint arXiv:2503.15620}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… survey specifically cite trust loss due to hallucinations as a top concern. Hallucinations are … For QA-Feedback, we use approach H to create preference pairs from RAG responses …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{lee_performance_2024, title = {Performance comparison of retrieval-augmented generation and fine-tuned large language models for construction safety management knowledge retrieval}, author = {Lee, J. and Ahn, S. and Kim, D. and Kim, D.}, year = {2024}, url = {https://www.sciencedirect.com/science/article/pii/S092658052400582X}, journal = {Automation in Construction}, note = {Publisher: Elsevier}, keywords = {source: Google Scholar}, abstract = {… fine-tuned LLM was fine-… RAG model improving by 21.5 \% and the fine-tuned LLM by 26 \%. The findings highlight the relative strengths and weaknesses of the RAG and fine-tuned LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kang_prompt-rag_2024-1, title = {Prompt-rag: {Pioneering}, author = {Kang, B. and Kim, J. and Yun, T. R. and Kim, C. E.}, year = {2024}, url = {https://arxiv.org/abs/2401.11246}, journal = {arXiv preprint arXiv:2401.11246}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… ChatGPT and conventional vector embedding-based RAG models. This study not only highlights the challenges of conventional RAG … thereby aiming to minimize hallucination. In cases …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{naik_probabilistic_2024, title = {Probabilistic consensus through ensemble validation: {A}, author = {Naik, N.}, year = {2024}, url = {https://arxiv.org/abs/2411.06535}, journal = {arXiv preprint arXiv:2411.06535}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Retrieval-Augmented Generation (RAG) (Lewis et al., 2020; Izacard \&Grave, 2021), aim to enhance factual accuracy by grounding LLM outputs in trusted … context, RAG systems have …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{baek_probing-rag_2024, title = {Probing-rag: {Self}, author = {Baek, I. and Chang, H. and Kim, B. and Lee, J. and Lee, H.}, year = {2024}, url = {https://arxiv.org/abs/2410.13339}, journal = {arXiv preprint arXiv:2410.13339}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… of Figure 1, Probing-RAG focuses on the hidden states of the LLM’s intermediate layers. … : external classifier based, LLM-based feedback, and confidence-based techniques. External …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wu_pa-rag_2024, title = {Pa-rag: {Rag}, author = {Wu, J. and Cai, H. and Yan, L. and Sun, H. and Li, X. and Wang, S. and Yin, D. and {...}, year = {2024}, url = {https://arxiv.org/abs/2412.14510}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… When constructing the training data, we employ ChatGPT-3.5 (GPT-3.5-Turbo-1106) and introduce a citation rewrite mechanism to create near-perfect responses. An overview of the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{bai_pistis-rag_2024, title = {Pistis-{RAG}, author = {Bai, Y. and Miao, Y. and Chen, L. and Li, D. and Ren, Y. and Xie, H. and {...}, year = {2024}, url = {https://ui.adsabs.harvard.edu/abs/2024arXiv240700072B/abstract}, journal = {arXiv e …}, note = {Publisher: ui.adsabs.harvard.edu}, keywords = {source: Google Scholar}, abstract = {… , trust, and reliability, echoing the core principles of RAG in … RAG systems. It adheres to information retrieval principles while considering the unique business scenario captured by LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wen_perception_2024, title = {Perception of knowledge boundary for large language models through semi-open-ended question answering}, author = {Wen, Z. and Tian, Z. and Jian, Z. and Huang, Z. and Ke, P. and {...}, year = {2024}, url = {https://proceedings.neurips.cc/paper_files/paper/2024/hash/a1e0d6fa0c30b7d4f75dd9c7ed6189f2-Abstract-Conference.html}, journal = {Advances in …}, note = {Publisher: proceedings.neurips.cc}, keywords = {source: Google Scholar}, abstract = {… the results from the RAG-based evaluation and LLM self-… the knowledge boundary of the target LLM. Following our method, … that advanced LLM (ie GPT-4) is easy to hallucinate on semi-…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{razafinirina_pedagogical_2024, title = {Pedagogical alignment of large language models (llm) for personalized learning: a survey, trends and challenges}, author = {Razafinirina, M. A. and Dimbisoa, W. G. and {...}, year = {2024}, journal = {Journal of …}, note = {Publisher: Scientific Research Publishing Type: CITATION}, keywords = {source: Google Scholar}, annote = {Query date: 2025-10-25 20:50:36}, } @article{maio_pirates_2024, title = {Pirates of the rag: {Adaptively}, author = {Maio, C. Di and Cosci, C. and Maggini, M. and Poggioni, V. and {...}, year = {2024}, url = {https://arxiv.org/abs/2412.18295}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Given a pre-trained LLM, we describe a RAG system by an architectures composed of four … dentiality within the system, undermining its trustworthiness and security guarantees not only …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{garza_privcomp-kg_2024-1, title = {Privcomp-kg: {Leveraging}, author = {Garza, L. and Elluri, L. and Kotal, A. and Piplai, A. and Gupta, D. and {...}, year = {2024}, url = {https://arxiv.org/abs/2404.19744}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… In our approach, we have utilized the power of RAG to limit the possibilities of hallucinations … of the retrieved article numbers by the LLM. As RAG is integral to the LLM, we assess the …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{lin_pe-gpt_2024, title = {{PE}, author = {Lin, F. and Li, X. and Lei, W. and Rodriguez-Andina, J. J. and {...}, year = {2024}, url = {https://ieeexplore.ieee.org/abstract/document/10701612/}, journal = {IEEE Transactions …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… LLM tailored for PE design applications, named PE-GPT. The methodology involves enhancing PE-GPT with retrieval augmented generation … LLM,s hallucination by the PE-tailored RAG…}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{noauthor_proceedings_2024, title = {Proceedings of {ALTRUIST}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217185920&partnerID=40&md5=b2db96197f85c74983379a12427933bf}, booktitle = {{CEUR}, volume = {3906}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{noauthor_proceedings_2024-1, title = {Proceedings - 2024 {International}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213952249&partnerID=40&md5=d66d551d5ec8c17f8e34e6a396ac21f6}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{zerhoudi_personarag_2024, title = {{PersonaRAG}, author = {Zerhoudi, Saber and Granitzer, Michael}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207482267&partnerID=40&md5=00e17c80859e082ded877a219383d2f5}, booktitle = {{CEUR}, volume = {3784}, pages = {1 -- 11}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{chu_patent_2024, title = {Patent {Response}, author = {Chu, Jungmei and Lo, Haocheng and Hsiang, Jieh and Cho, Chunchieh}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204918162&partnerID=40&md5=0ee730886a4380a0c00ae2074002599c}, pages = {146 -- 155}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 4}, } @inproceedings{noauthor_proceedings_2024-3, title = {Proceedings of the 2024 {AAAI}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203829053&partnerID=40&md5=03c425dfd05b375a2763743c28f0c36b}, booktitle = {Proceedings of {Machine}, volume = {257}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{chandrasekhar_nanogpt_2025, title = {{NANOGPT}, author = {Chandrasekhar, A. and Farimani, O. B. and Ajenifujah, O. T. and {...}, year = {2025}, url = {https://arxiv.org/abs/2502.20541}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… , RAG significantly reduces the likelihood of hallucinations and inaccuracies compared to raw LLM … The LLM-RAG system presented in this work utilizes the LLaMA3.1-8b-Instruct model, …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{tufino_notebooklm_2025, title = {{NotebookLM}, author = {Tufino, E.}, year = {2025}, url = {http://203.160.84.158:9988/papers/2504.09720v1.NotebookLM__An_LLM_with_RAG_for_active_learning_and_collaborative_tutoring.pdf}, journal = {arXiv preprint arXiv:2504.09720}, note = {Publisher: 203.160.84.158 Type: PDF}, keywords = {source: Google Scholar}, abstract = {… on internal training data, a RAG-based system actively retrieves relevant documents to ground its responses in factual information. Remarkable examples of RAG-based applications in …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{akarajaradwong_nitibench_2025, title = {Nitibench: {A}, author = {Akarajaradwong, P. and Pothavorn, P. and {...}, year = {2025}, url = {https://arxiv.org/abs/2502.10868}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We evaluate retrieval-augmented generation (RAG) and long-context LLM-based … In order to control the quality of judge LLM when assessing coverage and citation score, we iteratively …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{christodoulou_nlpdame_2025, title = {{NLPDame}, author = {Christodoulou, C.}, year = {2025}, url = {https://ceur-ws.org/Vol-4038/paper_147.pdf}, journal = {Working Notes of CLEF}, note = {Publisher: ceur-ws.org Type: PDF}, keywords = {source: Google Scholar}, abstract = {… RAG was employed as it provides external knowledge from the most relevant texts and minimizes LLM hallucinations. It was used to provide context to assist the LLM in performing …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{xiao_network_2025, title = {Network for knowledge {Organization}, author = {Xiao, Z. and Pakrasi, H. B. and Chen, Y. and Tang, Y. J.}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S1096717624001484}, journal = {Metabolic Engineering}, note = {Publisher: Elsevier Type: HTML}, keywords = {source: Google Scholar}, abstract = {… pipeline to store and distillate factual knowledge. Knowledge graphs have emerged as a … an example LLM in this study due to its exceptional Retrieval Augmented Generation (RAG) …}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{bender_next_2025, title = {Next {Sentence}, author = {Bender, Alexandre Thurow and Gomes, Gabriel A. and Corrêa, Ulisses Brisolara and Araújo, Ricardo Matsumura}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007896132&partnerID=40&md5=10af8b2ba73502a14194d3fad0ea674b}, booktitle = {Proceedings of the {International}, volume = {38}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{dodgson_establishing_2023, title = {Establishing performance baselines in fine-tuning, retrieval-augmented generation and soft-prompting for non-specialist llm users}, author = {Dodgson, J. and Nanzheng, L. and Peh, J. and Pattirane, A. R. J. and {...}, year = {2023}, url = {https://arxiv.org/abs/2311.05903}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… The LLM Deployer Module incorporates multi-model collaborative agents and instructional … LLM analysis engines. In this context, different LLMs are used to retrieve user-relevant factual …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kang_ever_2023, title = {Ever: {Mitigating}, author = {Kang, H. and Ni, J. and Yao, H.}, year = {2023}, url = {https://mk322.github.io/papers/KangEVER2024.pdf}, journal = {arXiv preprint arXiv:2311.09114}, note = {Publisher: mk322.github.io Type: PDF}, keywords = {source: Google Scholar}, abstract = {… better preference data to essentially enhance the factuality LLM by preference tuning. Here, as … we’ve identified for RAG and post-hoc edit methods? (2) Can EVER effectively reduce …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chavva_enhanced_2023, title = {Enhanced {Hybrid}, author = {Chavva, M. and Veera, S.}, year = {2023}, url = {https://journals.theusinsight.com/index.php/AJAI/article/view/70}, journal = {American Journal of AI \&Innovation}, note = {Publisher: journals.theusinsight.com}, keywords = {source: Google Scholar}, abstract = {… This paper presents an enhanced Hybrid Retrieval-Augmented Generation with Large Language Model (RAG-LLM) architecture tailored for domain-specific cloud infrastructure …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{garigliotti_explainable_2023, title = {Explainable {LLM}, author = {Garigliotti, D.}, year = {2023}, url = {https://ceur-ws.org/Vol-3953/368.pdf}, publisher = {ceur-ws.org}, note = {Type: PDF}, keywords = {source: Google Scholar}, abstract = {… LLM is also requested to cite the passages that support the correctness of the generated answer, and answer and citation … through the entire RAG assessment while the LLM has access …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kazoom_vault_2025, title = {Vault: {Vigilant}, author = {Kazoom, R. and Cohen, O. and Puzis, R. and Shabtai, A. and {...}, year = {2025}, url = {https://arxiv.org/abs/2508.00965}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We introduce VAULT, a fully automated adversarial RAG pipeline … Next, we assemble these contexts into LLM prompts to generate ad… Then use high-confidence examples for training; …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{cao_video_2025, title = {Video simpleqa: {Towards}, author = {Cao, M. and Hu, P. and Wang, Y. and Gu, J. and Tang, H. and Zhao, H. and {...}, year = {2025}, url = {https://arxiv.org/abs/2503.18923}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… To further enhance the reliability, we train expert annotators to refine the LLM-generated QA … RAG yields significant gains at the cost of inference efficiency: We explore RAG to facilitate …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{chung_verifact_2025, title = {Verifact: {Verifying}, author = {Chung, P. and Swaminathan, A. and Goodell, A. J. and Kim, Y. and {...}, year = {2025}, url = {https://arxiv.org/abs/2501.16672}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… factuality of LLM-generated text given the needle-in-a-haystack challenge of identifying subtle errors and hallucinations[… that atomic claims improve information retrieval for RAG[29], but …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_veridebug_2025, title = {Veridebug: {A}, author = {Wang, N. and Yao, B. and Zhou, J. and Hu, Y. and Wang, X. and {...}, year = {2025}, url = {https://ieeexplore.ieee.org/abstract/document/11106068/}, journal = {… Conference on LLM …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… to enhance the LLM’s outputs during debugging tasks [5]. However, RAG methods introduce … Figure 5 illustrates hallucination in LLM debugging. Instruction (Figure 5a) shows the actual …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kang_deficiency_2023, title = {Deficiency of large language models in finance: {An}, author = {Kang, H. and Liu, X. Y.}, year = {2023}, url = {https://arxiv.org/abs/2311.15548}, journal = {arXiv preprint arXiv:2311.15548}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… LLM models’ capacity of querying historical stock prices. Third, to alleviate the hallucination … To mitigate hallucinations, we show the effectiveness of the RAG method and prompt-based …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{yue_democratizing_2023, title = {Democratizing financial knowledge with {ChatGPT}, author = {Yue, T. and Au, D. and Au, C. C. and Iu, K. Y.}, year = {2023}, url = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4346152}, journal = {Available at SSRN 4346152}, note = {Publisher: papers.ssrn.com}, keywords = {source: Google Scholar}, abstract = {… Within the RAG framework, the LLM model is allowed to reference external data during … significant issues with AI hallucinations. We recognize that LLM hallucinations are likely to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{mansurova_development_2023, title = {Development of a question answering chatbot for blockchain domain}, author = {Mansurova, A. and Nugumanova, A. and {...}, year = {2023}, url = {https://sj.astanait.edu.kz/wp-content/uploads/2023/11/Journal_AITU_15vol_sept23-%D0%B2%D0%B5%D1%80%D1%81%D0%B8%D1%8F-4-27-40.pdf}, journal = {Scientific Journal of …}, note = {Publisher: sj.astanait.edu.kz Type: PDF}, keywords = {source: Google Scholar}, abstract = {… of simplified reports created using ChatGPT was mostly accurate. … They do, however, tend to generate hallucinations. Therefore… Retrieval-augmented generation (RAG) is a technique in …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{liu_judge_2025, title = {Judge as a judge: {Improving}, author = {Liu, S. and Li, X. and Liu, Z. and Yan, Y. and Yang, C. and Zeng, Z. and Liu, Z. and {...}, year = {2025}, url = {https://arxiv.org/abs/2502.18817}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… that enhances LLM-based judgment models to generate more accurate evaluations for RAG … Additionally, the vanilla LLM prioritizes factual correctness, while the SFT model focuses on …}, annote = {Query date: 2025-10-25 20:50:36}, } @book{wu_joint_2025, title = {Joint modeling of intelligent retrieval-augmented generation in {LLM}, author = {Wu, D. and Pan, S.}, year = {2025}, url = {https://www.researchsquare.com/article/rs-7739042/latest}, publisher = {researchsquare.com}, keywords = {source: Google Scholar}, abstract = {… utilization by proposing a retrieval-augmented generation method enhanced with intelligent … generation and ensuring semantic coverage, factual consistency, and contextual coherence. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{suri_visdom_2024, title = {Visdom: {Multi}, author = {Suri, M. and Mathur, P. and Dernoncourt, F. and Goswami, K. and {...}, year = {2024}, url = {https://arxiv.org/abs/2412.10704}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Evidence Curation: As a first step, we prompt the LLM to extract relevant evidence from the … the model’s reasoning abilities by filtering out noise and helps mitigate LLM hallucinations. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{an_vitality_2024, title = {Vitality 2: {Reviewing}, author = {An, H. and Narechania, A. and Wall, E. and Xu, K.}, year = {2024}, url = {https://arxiv.org/abs/2408.13450}, journal = {arXiv preprint arXiv:2408.13450}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… uses a Large Language Model or LLM-… RAG mitigates LLMs hallucinations by providing additional contextual information. In future work, we can further reduce hallucinations in RAG by …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{friel_chainpoll_2023, title = {Chainpoll: {A}, author = {Friel, R. and Sanyal, A.}, year = {2023}, url = {https://arxiv.org/abs/2310.18344}, journal = {arXiv preprint arXiv:2310.18344}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… We propose 2 new metrics to quantify LLM hallucinations - Adherence and Correctness. The former pertinent to Retrieval Augmented Generation (RAG) workflows measuring an LLM’s …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{xu_context-aware_2023, title = {Context-aware decoding reduces hallucination in query-focused summarization}, author = {Xu, Z.}, year = {2023}, url = {https://arxiv.org/abs/2312.14335}, journal = {arXiv preprint arXiv:2312.14335}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… However, applying large language models (LLM) potentially leads to hallucinations, especially … In retrieval augmented generation, we mainly focus on intrinsic hallucination. Pre-trained …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{cao_learn_2023, title = {Learn to refuse: {Making}, author = {Cao, L.}, year = {2023}, url = {https://arxiv.org/abs/2311.01041}, journal = {arXiv preprint arXiv:2311.01041}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… type of hallucination, namely fact-conflicting hallucination, … Our objective is for the LLM to function solely as a machine … with the general retrieval augmented generation (RAG) method. In …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{shethiya_llm-powered_2023, title = {{LLM}, author = {Shethiya, A. S.}, year = {2023}, url = {http://academianexusjournal.com/index.php/anj/article/view/21}, journal = {Academia Nexus Journal}, note = {Publisher: academianexusjournal.com}, keywords = {source: Google Scholar}, abstract = {… is the Retrieval-Augmented Generation (RAG) architecture. RAG augments the LLM with … and capabilities of the LLM, possibly offering ""why"" explanations or citations where feasible. …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{_llm_2023, title = {{LLM}, author = {{정천수}, year = {2023}, url = {https://www.researchgate.net/profile/Cheonsu-Jeong/publication/376893991_Generative_AI_service_implementation_using_LLM_application_architecture_based_on_RAG_model_and_LangChain_framework/links/658e9c136f6e450f19b310b1/Generative-AI-service-implementation-using-LLM-application-architecture-based-on-RAG-model-and-LangChain-framework.pdf}, journal = {지능정보연구}, note = {Publisher: researchgate.net Type: PDF}, keywords = {source: Google Scholar}, abstract = {… Accordingly, this study presents a method of implementing generative AI services using the LLM application architecture using the most widely used LangChain framework. To this end, …}, annote = {Query date: 2025-10-25 20:50:36}, } @inproceedings{cheng_lift_2023, title = {Lift {Yourself}, author = {Cheng, Xin and Luo, Di and Chen, Xiuying and Liu, Lemao and Zhao, Dong-Yan and Yan, Rui}, year = {2023}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205561550&partnerID=40&md5=f01f9f055070db2780dc35daed6a4fbd}, booktitle = {Advances in {Neural}, volume = {36}, note = {Type: Conference paper}, keywords = {source: Scopus}, annote = {Cited by: 41}, } @article{chen_you_2025, title = {You {Don}, author = {Chen, S. and Zhou, C. and Yuan, Z. and Zhang, Q. and Cui, Z. and {...}, year = {2025}, url = {https://arxiv.org/abs/2508.06105}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… Retrieval-augmented generation (RAG) addresses this by retrieving query-relevant contexts from knowledge bases to support LLM … becomes prematurely confident and produces an …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wang_jmlr_2024, title = {Jmlr: {Joint}, author = {Wang, J. and Yang, Z. and Yao, Z. and Yu, H.}, year = {2024}, url = {https://arxiv.org/abs/2402.17887}, journal = {arXiv preprint arXiv:2402.17887}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… (RAG) has limited success in addressing hallucinations. Unlike previous methods in RAG … separately from the LLM, we introduce JMLR (for Jointly trains LLM and information Retrieval) …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{liu_xrag_2025, title = {{XRAG}, author = {Liu, W. and Trenous, S. and Ribeiro, L. F. R. and Byrne, B. and {...}, year = {2025}, url = {https://arxiv.org/abs/2505.10089}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… RAG setting (GPT-4o achieves only 62.4\% accuracy, see Table 4). We develop a novel LLM-… 2024), the Q\&A pairs generated by the LLM may contain factual errors. Therefore, we ask a …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{mohammed_diabetiq_nodate, title = {{DiabetIQ}, author = {Mohammed, S. and Nabil, N. I. and Nipa, H. R. and Setu, U. S. H.}, url = {https://www.researchgate.net/profile/Saif-Mohammed-18/publication/391479329_DiabetIQ_An_Intelligent_Diabetes_Management_Application_with_an_Integrated_LLM-Augmented_RAG_Chatbot_and_ML-Based_Risk_Early_Prediction/links/6819c216df0e3f544f52211e/DiabetIQ-An-Intelligent-Diabetes-Management-Application-with-an-Integrated-LLM-Augmented-RAG-Chatbot-and-ML-Based-Risk-Early-Prediction.pdf}, journal = {researchgate.net}, note = {Type: PDF}, keywords = {source: Google Scholar}, abstract = {… is the Retrieval-Augmented Generation (RAG) pipeline, … base Large Language Model (LLM) while ensuring factual grounding. … the LLM with both the user’s question and relevant factual …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kloker_new_2024, title = {New {Curriculum}, author = {Kloker, S. and Bukoli, H. and Kateete, T.}, year = {2024}, url = {https://arxiv.org/abs/2408.07542}, journal = {arXiv preprint arXiv:2408.07542}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… the ""confidence conundrum"": the LLM presents information … of RAG for lesson plan creation in the context of Ugandan secondary schools. We developed a prototype, that utilizes an LLM …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{wilcock_new_2024, title = {New technologies for spoken dialogue systems: {LLMs}, author = {Wilcock, G.}, year = {2024}, url = {https://researchportal.helsinki.fi/files/320056326/IWSDS-short-final-v10.pdf}, journal = {14th International Workshop on Spoken …}, note = {Publisher: researchportal.helsinki.fi Type: PDF}, keywords = {source: Google Scholar}, abstract = {… RAG with Llama2 to generate natural language answers to user questions about the document contents. Note that the LLM generates confident … uses vector-based RAG with Llama2 to …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{kang_nadine_2024, title = {Nadine: an {LLM}, author = {Kang, H. and Moussa, M. B. and {...}, year = {2024}, url = {https://arxiv.org/abs/2405.20189}, journal = {arXiv preprint arXiv …}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… This approach aims to reduce LLM hallucinations and incorporate data from external … In this section, we demonstrate the RAG system adopted in our interaction module. The RAG …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{shin_qa_2023, title = {{QA}, author = {Shin, J. and Lee, J. and Kim, K. and Lee, T. and {...}, year = {2023}, journal = {Annual …}, note = {Publisher: Human and Language Technology Type: CITATION}, keywords = {source: Google Scholar}, annote = {Query date: 2025-10-25 20:50:36}, } @article{martineau_what_2023, title = {What is retrieval-augmented generation?}, author = {Martineau, K. and Explainable, A. I. and Generative, A. I.}, year = {2023}, url = {https://research.ibm.com/blog/retrieval-augmented-generation-RAG?ref=blog.zatrok.com}, journal = {IBM Research Blog}, note = {Publisher: research.ibm.com Type: HTML}, keywords = {source: Google Scholar}, abstract = {… Implementing RAG in an LLM-based question answering … By grounding an LLM on a set of external, verifiable facts, the … that an LLM will leak sensitive data, or ‘hallucinate’ incorrect …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jeong_generative_2023, title = {Generative {AI}, author = {Jeong, C.}, year = {2023}, journal = {Journal of Intelligence and Information …}, note = {Publisher: Korea Intelligent Information System … Type: CITATION}, keywords = {source: Google Scholar}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zarza_optimized_2023, title = {Optimized financial planning: integrating individual and cooperative budgeting models with {LLM}, author = {Zarzà, I. De and Curtò, J. De and Roig, G. and Calafate, C. T.}, year = {2023}, url = {https://www.mdpi.com/2673-2688/5/1/6}, journal = {AI}, note = {Publisher: mdpi.com Type: HTML}, keywords = {source: Google Scholar}, abstract = {… potential for LLM hallucination, the methodology could integrate a retrieval augmented generation (RAG) … The incorporation of RAG into our recommendation generation process can be …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{hannah_legal_2025, title = {On the legal implications of {Large}, author = {Hannah, G. and Sousa, R. T. and Dasoulas, I. and d'Amato, C.}, year = {2025}, url = {https://www.sciencedirect.com/science/article/pii/S1570826824000295}, journal = {Journal of Web Semantics}, note = {Publisher: Elsevier Type: HTML}, keywords = {source: Google Scholar}, abstract = {… Nevertheless, there are cases where the LLM recommends actions that have potential legal … the LLM answers, is also able to provide actual evidence for them by supplying citations of …}, annote = {Query date: 2025-10-25 20:50:36}, } @article{bilal_onrl-rag_2025-1, title = {Onrl-rag: {Real}, author = {Bilal, A. and Lin, B.}, year = {2025}, url = {https://arxiv.org/abs/2504.02894}, journal = {arXiv preprint arXiv:2504.02894}, note = {Publisher: arxiv.org}, keywords = {source: Google Scholar}, abstract = {… While RAG offers the correct information, it may not best … -based Retrieval-Augmented Generation (OnRL-RAG) system … compared to standard RAG and simple LLM via GPT-4o, GPT-4o-…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{gajjar_oran-bench-13k_2025, title = {Oran-bench-13k: {An}, author = {Gajjar, P. and Shah, V. K.}, year = {2025}, url = {https://ieeexplore.ieee.org/abstract/document/10975994/}, journal = {2025 IEEE 22nd Consumer …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… Our findings indicate that current popular LLM models are not … We also propose a RAG-based pipeline named ORANSight … Fung, “Towards mitigating llm hallucination via self reflection,…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{jain_mitigating_2025-1, title = {On mitigating code {LLM}, author = {Jain, N. and Kwiatkowski, R. and Ray, B. and {...}, year = {2025}, url = {https://ieeexplore.ieee.org/abstract/document/11121691/}, journal = {2025 IEEE/ACM 47th …}, note = {Publisher: ieeexplore.ieee.org}, keywords = {source: Google Scholar}, abstract = {… Hence, to address API hallucinations, we adopt retrieval augmented generation with documentation, ie, Documentation Augmented Generation (DAG), which has shown early promise […}, annote = {Query date: 2025-10-25 20:50:36}, } @article{zheng_-device_nodate, title = {On-{Device}, author = {Zheng, D.}, url = {https://dqzheng.com/wp-content/uploads/2025/10/SEA_2025-2.pdf}, journal = {dqzheng.com}, note = {Type: PDF}, keywords = {source: Google Scholar}, abstract = {… The agentric system uses a hybrid LLM-RAG architecture with … we demonstrate 90\% LLM success rate with 10\% RAG fallback, … confidence scores fall below threshold (confidence {\textless}, annote = {Query date: 2025-10-25 20:50:36}, } @article{__2024, title = {검색 증강 생성 ({RAG}, author = {{이은빈}, year = {2024}, url = {https://kiss.kstudy.com/Detail/Ar?key=4118382}, journal = {정보처리학회 논문지 (KTSDE)}, note = {Publisher: kiss.kstudy.com}, keywords = {source: Google Scholar}, abstract = {… databases, thereby reducing the hallucination phenomenon often seen in LLMs … RAG, reviews recent research trends aimed at enhancing the retrieval capabilities of LLMs through RAG…}, annote = {Query date: 2025-10-25 20:50:36}, } @article{__2023, title = {カスタマーサポートにおける {LLM}, author = {{二宮大空}, year = {2023}, url = {https://www.jstage.jst.go.jp/article/jsaislud/99/0/99_191/_article/-char/ja/}, journal = {人工知能学会研究会資料 言語・音声理解と対話処理研究 …}, note = {Publisher: jstage.jst.go.jp}, keywords = {source: Google Scholar}, abstract = {… , including issues like hallucination, necessitating … an LLM-simulated user interacts with the RAG-based dialogue system, and the resulting dialogue data is evaluated using the LLM. …}, annote = {Query date: 2025-10-25 20:50:36}, } @misc{noauthor_scopus_nodate, title = {Scopus - {Document}, url = {https://www.scopus.com/results/results.uri?sort=plf-f&src=s&sid=004b5458677e4972e2b44cdf9b71d3cc&sot=a&sdt=a&cluster=scolang%2C%22English%22%2Ct%2C%22Spanish%22%2Ct&sl=756&s=TITLE-ABS-KEY%28+%28%22retrieval-augmented+generation%22+OR+RAG%29+AND+%28%22large+language+model*%22+OR+LLM*+OR+%22generative+AI%22+OR+ChatGPT%29+AND+%28+%28trust+OR+confidence+OR+credibility+OR+%22user+perception%22+OR+%22perceived+reliability%22+OR+%22overtrust%22+OR+calibration%29+OR+%28hallucination*+OR+factuality+OR+%22factual+accuracy%22+OR+faithfulness+OR+citation+OR+citations+OR+reference+OR+%22source+attribution%22+OR+provenance+OR+grounding%29+OR+%28%22explainable+artificial+intelligence%22+OR+%22explainable+AI%22+OR+XAI+OR+%22interpretable+AI%22+OR+%22interpretable+artificial+intelligence%22+OR+%22AI+explainability%22+OR+%22AI+interpretability%22+OR+%22transparent+AI%22+OR+%22AI+transparency%22+OR+%22model+interpretability%22+OR+%22post-hoc+explanation%22+OR+%22feature+attribution%22%29%29+%29+AND+PUBYEAR+%26gt%3B+2019+AND+PUBYEAR+%26lt%3B+2026&origin=searchadvanced&editSaveSearch=&txGid=e9ebf783d0fd1690e1ec752586b783f5&sessionSearchId=004b5458677e4972e2b44cdf9b71d3cc&limit=10}, keywords = {source: Scopus}, file = {Scopus - Document search results | Signed in:C\:\\Users\\Marco\\Zotero\\storage\\3W35T745\\results.html:text/html}, urldate = {2025-10-26}, } @article{noauthor_43rd_2025, title = {43rd {International}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209551458&partnerID=40&md5=8beac58109dd074a36359432bcbc8d8a}, journal = {Lecture Notes in Computer Science}, volume = {15238 LNCS}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{noauthor_2025_2025, title = {2025 11th {International}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011583044&partnerID=40&md5=587b88ef744122f032bc2e9c067d04a6}, journal = {International Conference on Web Research, ICWR}, number = {2025}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{noauthor_8th_2025, title = {8th {International}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002920066&partnerID=40&md5=42ad37c3f901a0db6bf011b5720de306}, journal = {Lecture Notes in Computer Science}, volume = {15545 LNCS}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{noauthor_11th_2025, title = {11th {International}, year = {2025}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001862693&partnerID=40&md5=feb70896a8fec78cc8baada933229ca5}, booktitle = {International {Conference}, volume = {1}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @inproceedings{noauthor_2024_2024, title = {2024 {Design}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215933813&partnerID=40&md5=29034e1cfb47df740ae0cff805094709}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } @article{noauthor_32nd_2024, title = {32nd {International}, year = {2024}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198482399&partnerID=40&md5=909e46f468f0730419b64b5c01b1f99e}, journal = {Lecture Notes in Computer Science}, volume = {14775 LNAI}, note = {Type: Conference review}, keywords = {source: Scopus}, annote = {Cited by: 0}, } }}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}, to each individual student while ensuring that learning goals are met. in a between-participants study (n = {47)}, url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011087821&partnerID=40&md5=923f213fc1c02773e19136dd1bd75652}, urldate = {2025-10-26}, users can interact with the system to further customize the content and presentation formats of the notes according to their preferences. we conducted both a technical evaluation and a comparison user study (n = {36). The solid performance in objective metrics and the positive user feedback demonstrated the effectiveness of the pipeline and the overall usability of NoteIt."		RQ1,RQ2,RQ3,RQ4	4.0	Confianza/percepción y Factualidad/alucinaciones y XAI/calibración y Métricas/metodologías
30) show that the emphasis proposal module outperforms off-the-shelf LLMs in identifying suitable gesture regions}		2025	-	0.0	Fuera de alcance
tamascelli_academic_2025			-	0.0	Fuera de alcance
