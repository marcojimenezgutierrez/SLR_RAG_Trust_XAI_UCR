
@inproceedings{tamascelli_academic_2025,
	title = {Academic {Advising} {Chatbot} {Powered} with {AI} {Agent}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007411907&doi=10.1145%2F3696673.3723065&partnerID=40&md5=040026bc3ac236df37784a10cbea5761},
	doi = {10.1145/3696673.3723065},
	author = {Tamascelli, Michael and Bunch, Olivia and Fowler, Blake and Taeb, Maryam and Cohen, Achraf},
	year = {2025},
	note = {Type: Conference paper},
	keywords = {academic advising, AI agent, chatbot, higher education, large language models, retrieval-augmented generation},
	pages = {195 -- 202},
	annote = {Cited by: 0; All Open Access; Gold Open Access},
}

@inproceedings{quinn_accelerating_2025,
	title = {Accelerating {Retrieval}-{Augmented} {Generation}},
	volume = {1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002368055&doi=10.1145%2F3669940.3707264&partnerID=40&md5=9f2570e878c5d67eb086a2ecde14a53b},
	doi = {10.1145/3669940.3707264},
	booktitle = {International {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems} - {ASPLOS}},
	author = {Quinn, Derrick and Nouri, Mohammad and Patel, Neel and Salihu, John and Salemi, Alireza and Lee, Sukhan and Zamani, Hamed and Alian, Mohammad},
	year = {2025},
	note = {Type: Conference paper},
	keywords = {database acceleration, dense retrieval, retrieval-augmented generation (rag)},
	pages = {15 -- 32},
	annote = {Cited by: 6},
}

@inproceedings{zhang_survey_2025,
	title = {A {Survey} of {Theory} {Foundation} and {Key} {Technology} in {Large} {Models}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219174603&doi=10.1145%2F3707292.3707383&partnerID=40&md5=ca2528033b2931424afa28417692ff7b},
	doi = {10.1145/3707292.3707383},
	author = {Zhang, Xueqiang and Dong, Xiaofei and Wang, Yiru and Zhang, Dan and Cao, Feng},
	year = {2025},
	note = {Type: Conference paper},
	keywords = {development analysis, key technology, Large models, theory foundation},
	pages = {318 -- 323},
	annote = {Cited by: 0},
}

@inproceedings{sun_adaptive_2024,
	title = {Adaptive {In}-{Context} {Learning} with {Large} {Language} {Models} for {Bundle} {Generation}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200543793&doi=10.1145%2F3626772.3657808&partnerID=40&md5=79665ea91d6c8947310ee468be6bfd93},
	doi = {10.1145/3626772.3657808},
	author = {Sun, Zhu and Feng, Kaidong and Yang, Jie and Qu, Xinghua and Fang, Hui and Ong, Yew Soon and Liu, Wenyuan},
	year = {2024},
	note = {Type: Conference paper},
	keywords = {bundle generation, in-context learning, large language models, recommendation, user intent inference},
	pages = {966 -- 976},
	annote = {Cited by: 3},
}

@article{shi_amsnet-kg_2025,
	title = {{AMSnet}-{KG}: {A} {Netlist} {Dataset} for {LLM}-based {AMS} {Circuit} {Auto}-design {Using} {Knowledge} {Graph} {RAG}},
	volume = {30},
	issn = {1084-4309},
	url = {https://doi.org/10.1145/3736166},
	doi = {10.1145/3736166},
	abstract = {High-performance analog and mixed-signal (AMS) circuits are mainly full-custom designed, which is time-consuming and labor-intensive. A significant portion of the effort is experience-driven, which makes the automation of AMS circuit design a formidable challenge. Large language models (LLMs) have emerged as powerful tools for electronic design automation (EDA) applications, fostering advancements in the automatic design process for large-scale AMS circuits. However, the absence of high-quality datasets has led to issues such as model hallucination, which undermines the robustness of automatically generated circuit designs. To address this issue, this article introduces AMSnet-KG, a dataset encompassing various AMS circuit schematics and netlists. We construct a knowledge graph with annotations on detailed functional and performance characteristics. Facilitated by AMSnet-KG, we propose an automated AMS circuit generation framework that utilizes the comprehensive knowledge embedded in LLMs. The flow first formulate a design strategy (e.g., circuit architecture using a number of circuit components) based on required specifications. Next, matched subcircuits are retrieved and assembled into a complete topology, and transistor sizing is obtained through Bayesian optimization. Simulation results of the netlist are automatically fed back to the LLM for further topology refinement, ensuring the circuit design specifications are met. We perform case studies of operational amplifier and comparator design to verify the automatic design flow from specifications to netlists with minimal human effort. The dataset used in this article is available at .},
	number = {6},
	journal = {ACM Trans. Des. Autom. Electron. Syst.},
	author = {Shi, Yichen and Tao, Zhuofu and Gao, YuHao and Zhou, Tianjia and Chang, Cheng and Wang, Yaxin and Chen, Bingyu and Zhang, Genhao and Liu, Alvin and Yu, Zhiping and Lin, Ting-Jung and He, Lei},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {AMSnet, EDA, knowledge graph, LLM, RAG, topology design},
	annote = {8 cites: https://scholar.google.com/scholar?cites=18096057598545424232\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_survey_2025-1,
	title = {A {Survey} on the {Memory} {Mechanism} of {Large} {Language} {Model}-based {Agents}},
	volume = {43},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/3748302},
	doi = {10.1145/3748302},
	abstract = {Large language model (LLM)-based agents have recently attracted much attention from the research and industry communities. Compared with original LLMs, LLM-based agents are featured in their self-evolving capability, which is the basis for solving real-world problems that need long-term and complex agent-environment interactions. The key component to support agent-environment interactions is the memory of the agents. While previous studies have proposed many promising memory mechanisms, they are scattered in different papers, and there lacks a systematical review to summarize and compare these works from a holistic perspective, failing to abstract common and effective designing patterns for inspiring future studies. To bridge this gap, in this article, we propose a comprehensive survey on the memory mechanism of LLM-based agents. In specific, we first discuss “what is” and “why do we need” the memory in LLM-based agents. Then, we systematically review previous studies on how to design and evaluate the memory module. In addition, we also present many agent applications, where the memory module plays an important role. At last, we analyze the limitations of existing work and show important future directions. To keep up with the latest advances in this field, we create a repository at .},
	number = {6},
	journal = {ACM Trans. Inf. Syst.},
	author = {Zhang, Zeyu and Dai, Quanyu and Bo, Xiaohe and Ma, Chen and Li, Rui and Chen, Xu and Zhu, Jieming and Dong, Zhenhua and Wen, Ji-Rong},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Agent, Information Processing, Information System, Large Language Model, Memory Mechanism},
}

@article{deng_ai_2025,
	title = {{AI} {Agents} {Under} {Threat}: {A} {Survey} of {Key} {Security} {Challenges} and {Future} {Pathways}},
	volume = {57},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3716628},
	doi = {10.1145/3716628},
	abstract = {An Artificial Intelligence (AI) agent is a software entity that autonomously performs tasks or makes decisions based on pre-defined objectives and data inputs. AI agents, capable of perceiving user inputs, reasoning and planning tasks, and executing actions, have seen remarkable advancements in algorithm development and task performance. However, the security challenges they pose remain under-explored and unresolved. This survey delves into the emerging security threats faced by AI agents, categorizing them into four critical knowledge gaps: unpredictability of multi-step user inputs, complexity in internal executions, variability of operational environments, and interactions with untrusted external entities. By systematically reviewing these threats, this article highlights both the progress made and the existing limitations in safeguarding AI agents. The insights provided aim to inspire further research into addressing the security threats associated with AI agents, thereby fostering the development of more robust and secure AI agent applications.},
	number = {7},
	journal = {ACM Comput. Surv.},
	author = {Deng, Zehang and Guo, Yongjian and Han, Changzhou and Ma, Wanlun and Xiong, Junwu and Wen, Sheng and Xiang, Yang},
	month = feb,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {AI agent, security, trustworthiness},
}

@article{lu_adda_2025,
	title = {Adda: {Towards} {Efficient} in-{Database} {Feature} {Generation} via {LLM}-based {Agents}},
	volume = {3},
	url = {https://doi.org/10.1145/3725262},
	doi = {10.1145/3725262},
	abstract = {Integrating machine learning (ML) analytics into existing database management systems (DBMSs) not only eliminates the need for costly data transfers to external ML platforms but also ensures compliance with regulatory standards. While some DBMSs have integrated functionalities for training and applying ML models for analytics, these tasks still present challenges, particularly due to limited support for automatic feature engineering (AutoFE), which is crucial for optimizing ML model performance. In this paper, we introduce Adda, an agent-driven in-database feature generation tool designed to automatically create high-quality features for ML analytics directly within the database. Adda interprets ML analytics tasks described in natural language and generates code for feature construction by leveraging the power of large language models (LLMs) integrated with specialized agents. This code is then translated into SQL statements using a predefined set of operators and compiled just-in-time (JIT) into user-defined functions (UDFs). The result is a seamless, fully in-database solution for feature generation, specifically tailored for ML analytics tasks. Extensive experiments across 14 public datasets, with five ML tasks per dataset, show that Adda improves the AUC by up to 33.2\% and reduces end-to-end latency by up to 100x compared to Madlib.},
	number = {3},
	journal = {Proc. ACM Manag. Data},
	author = {Lu, Kuan and Yang, Zhihui and Wu, Sai and Xia, Ruichen and Zhang, Dongxiang and Chen, Gang},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {auto feature engineering, in-database machine learning, LLM agent},
}

@article{qiang_agent-om_2024,
	title = {Agent-{OM}: {Leveraging} {LLM} {Agents} for {Ontology} {Matching}},
	volume = {18},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3712221.3712222},
	doi = {10.14778/3712221.3712222},
	abstract = {Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM agents have revolutionised data engineering and have been applied creatively in many domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With consideration of several specific challenges in leveraging LLM agents for OM, we propose a generic framework, namely Agent-OM (Agent for Ontology Matching), consisting of two Siamese agents for retrieval and matching, with a set of OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAEI) tracks over state-of-the-art OM systems show that our system can achieve results very close to the long-standing best performance on simple OM tasks and can significantly improve the performance on complex and few-shot OM tasks.},
	number = {3},
	journal = {Proc. VLDB Endow.},
	author = {Qiang, Zhangcheng and Wang, Weiqing and Taylor, Kerry},
	month = nov,
	year = {2024},
	note = {Publisher: VLDB Endowment},
	pages = {516--529},
	annote = {19 cites: https://scholar.google.com/scholar?cites=11537150885406125790\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{huang_survey_2025,
	title = {A {Survey} on {Hallucination} in {Large} {Language} {Models}: {Principles}, {Taxonomy}, {Challenges}, and {Open} {Questions}},
	volume = {43},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/3703155},
	doi = {10.1145/3703155},
	abstract = {The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), fueling a paradigm shift in information acquisition. Nevertheless, LLMs are prone to hallucination, generating plausible yet nonfactual content. This phenomenon raises significant concerns over the reliability of LLMs in real-world information retrieval (IR) systems and has attracted intensive research to detect and mitigate such hallucinations. Given the open-ended general-purpose attributes inherent to LLMs, LLM hallucinations present distinct challenges that diverge from prior task-specific models. This divergence highlights the urgency for a nuanced understanding and comprehensive overview of recent advances in LLM hallucinations. In this survey, we begin with an innovative taxonomy of hallucination in the era of LLM and then delve into the factors contributing to hallucinations. Subsequently, we present a thorough overview of hallucination detection methods and benchmarks. Our discussion then transfers to representative methodologies for mitigating LLM hallucinations. Additionally, we delve into the current limitations faced by retrieval-augmented LLMs in combating hallucinations, offering insights for developing more robust IR systems. Finally, we highlight the promising research directions on LLM hallucinations, including hallucination in large vision-language models and understanding of knowledge boundaries in LLM hallucinations.},
	number = {2},
	journal = {ACM Trans. Inf. Syst.},
	author = {Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and Liu, Ting},
	month = jan,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Factuality, Faithfulness, Hallucination, Large Language Models},
	annote = {2979 cites: https://scholar.google.com/scholar?cites=12755344437467074574\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mo_survey_2025,
	title = {A {Survey} of {Conversational} {Search}},
	volume = {43},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/3759453},
	doi = {10.1145/3759453},
	abstract = {As a cornerstone of modern information access, search engines have become indispensable in everyday life. With the rapid advancements in AI and natural language processing (NLP) technologies, particularly large language models (LLMs), search engines have evolved to support more intuitive and intelligent interactions between users and systems. Conversational search, an emerging paradigm for next-generation search engines, leverages natural language dialogue to facilitate complex and precise information retrieval, thus attracting significant attention. Unlike traditional keyword-based search engines, conversational search systems enhance user experience by supporting intricate queries, maintaining context over multi-turn interactions, and providing robust information integration and processing capabilities. Key components such as query reformulation, search clarification, conversational retrieval, and response generation work in unison to enable these sophisticated interactions. In this survey, we explore the recent advancements and potential future directions in conversational search, examining the critical modules that constitute a conversational search system. We highlight the integration of LLMs in enhancing these systems and discuss the challenges and opportunities that lie ahead in this dynamic field. Additionally, we provide insights into real-world applications and robust evaluations of current conversational search systems, aiming to guide future research and development in conversational search.},
	number = {6},
	journal = {ACM Trans. Inf. Syst.},
	author = {Mo, Fengran and Mao, Kelong and Zhao, Ziliang and Qian, Hongjin and Chen, Haonan and Cheng, Yiruo and Li, Xiaoxi and Zhu, Yutao and Dou, Zhicheng and Nie, Jian-Yun},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Benchmark and Evaluation, Conversational Retrieval and Generation, Conversational Search, Domain-specific and User-centric Application, Query Reformulation, Search Clarification},
}

@article{wang_comprehensive_2025,
	title = {A {Comprehensive} {Survey} of {Small} {Language} {Models} in the {Era} of {Large} {Language} {Models}: {Techniques}, {Enhancements}, {Applications}, {Collaboration} with {LLMs}, and {Trustworthiness}},
	issn = {2157-6904},
	url = {https://doi.org/10.1145/3768165},
	doi = {10.1145/3768165},
	abstract = {Large language models (LLMs) have demonstrated emergent abilities in text generation, question answering, and reasoning, facilitating various tasks and domains. Despite their proficiency in various tasks, LLMs like PaLM 540B and Llama-3.1 405B face limitations due to large parameter sizes and computational demands, often requiring cloud API use which raises privacy concerns, limits real-time applications on edge devices, and increases fine-tuning costs. Additionally, LLMs often underperform in specialized domains such as healthcare and law due to insufficient domain-specific knowledge, necessitating specialized models. Therefore, Small Language Models (SLMs) are increasingly favored for their low inference latency, cost-effectiveness, efficient development, and easy customization and adaptability. These models are particularly well-suited for resource-limited environments and domain knowledge acquisition, addressing LLMs’ challenges and proving ideal for applications that require localized data handling for privacy, minimal inference latency for efficiency, and domain knowledge acquisition through lightweight fine-tuning. The rising demand for SLMs has spurred extensive research and development. However, a comprehensive survey investigating issues related to the definition, acquisition, application, enhancement, and reliability of SLM remains lacking, prompting us to conduct a detailed survey on these topics. The definition of SLMs varies widely, thus to standardize, we propose defining SLMs by their capability to perform specialized tasks and suitability for resource-constrained settings, setting boundaries based on the minimal size for emergent abilities and the maximum size sustainable under resource constraints. For other aspects, we provide a taxonomy of relevant models/methods and develop general frameworks for each category to enhance and utilize SLMs effectively. We have compiled the collected SLM models and related methods on GitHub: .},
	journal = {ACM Trans. Intell. Syst. Technol.},
	author = {Wang, Fali and Zhang, Zhiwei and Zhang, Xianren and Wu, Zongyu and Mo, TzuHao and Lu, Qiuhao and Wang, Wanjing and Li, Rui and Xu, Junjie and Tang, Xianfeng and He, Qi and Ma, Yao and Huang, Ming and Wang, Suhang},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Domain-specific Models, On-Device LLMs, Small Language Models, Trustworthiness},
	annote = {Just Accepted},
	annote = {Just Accepted},
}

@article{joel_survey_2025,
	title = {A {Survey} on {LLM}-based {Code} {Generation} for {Low}-{Resource} and {Domain}-{Specific} {Programming} {Languages}},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3770084},
	doi = {10.1145/3770084},
	abstract = {Large Language Models (LLMs) have shown remarkable capabilities in code generation for popular programming languages. However, their performance in Low-Resource Programming Languages (LRPLs) and Domain-Specific Languages (DSLs) remains a critical challenge. This gap affects millions of developers - with Rust alone having 3.5 million users - who are currently unable to fully leverage LLM capabilities. LRPLs and DSLs face unique challenges, including severe data scarcity and, for DSLs, highly specialized syntax and semantics that are poorly represented in general-purpose datasets. Addressing these challenges is crucial as LRPLs and DSLs significantly enhance development efficiency in specialized domains and applications, including financial and scientific works. While several surveys on LLMs for software engineering and code exist, none comprehensively address the challenges and opportunities specific to LRPLs and DSLs. Our survey fills this gap by providing a systematic review of the current state, methodologies, and challenges in leveraging LLMs for code generation in LRPL and DSL. We filtered 111 papers from over 27,000 published studies from 2020 – 2024 to understand the capabilities and limitations of LLMs in these specialized domains. We also expanded our literature search to include 5 recent papers from 2024 – 2025. We report LLMs used, benchmarks, and metrics to evaluate code generation in LRPLs and DSLs, as well as strategies used to enhance LLM performance, and the collected datasets and curation methods in this context.We identified four main evaluation techniques used in the literature, along with several metrics to assess code generation in LRPL and DSL. We categorized the methods used for LLM improvement into six main groups and summarized the novel methods and architectures proposed by the researchers. We also classified different approaches used for data collection and preparation. While different techniques, metrics, and datasets are used, there is a lack of a standard approach and a benchmark dataset to evaluate code generation in several LRPLs and DSLs. We discuss several distinctions of the studied approaches with the ones used in high-resource programming languages (HRPLs), as well as several challenges unique to these languages, especially DSLs. The challenges stem from the scarcity of data, the unique requirements, and specialized domains, which often need expertise guidelines or domain-specific tools. Accordingly, we provide insights into different research opportunities for the studied aspects. This survey serves as a comprehensive resource for researchers and practitioners working at the intersection of LLMs, software engineering, and specialized programming languages, providing a foundation for future advancements in LRPL and DSL code generation. A GitHub repository was created to organize the papers of this survey at .},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Joel, Sathvik and Wu, Jie and Fard, Fatemeh},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {code generation, domain-specific languages (DSLs), Large language models, low-resource programming languages (LRPLs), systematic literature review},
	annote = {Just Accepted},
	annote = {Just Accepted},
}

@article{zhang_survey_2025-2,
	title = {A {Survey} of {AIOps} in the {Era} of {Large} {Language} {Models}},
	volume = {58},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3746635},
	doi = {10.1145/3746635},
	abstract = {As large language models (LLMs) grow increasingly sophisticated and pervasive, their application to various Artificial Intelligence for IT Operations (AIOps) tasks has garnered significant attention. However, a comprehensive understanding of the impact, potential, and limitations of LLMs in AIOps remains in its infancy. To address this gap, we conducted a detailed survey of LLM4AIOps, focusing on how LLMs can optimize processes and improve outcomes in this domain. We analyzed 183 research articles published between January 2020 and December 2024 to answer four key research questions (RQs). In RQ1, we examine the diverse failure data sources utilized, including advanced LLM-based processing techniques for legacy data and the incorporation of new data sources enabled by LLMs. RQ2 explores the evolution of AIOps tasks, highlighting the emergence of novel tasks and the publication trends across these tasks. RQ3 investigates the various LLM-based methods applied to address AIOps challenges. Finally, RQ4 reviews evaluation methodologies tailored to assess LLM-integrated AIOps approaches. Based on our findings, we discuss the state-of-the-art advancements and trends, identify gaps in existing research, and propose promising directions for future exploration.},
	number = {2},
	journal = {ACM Comput. Surv.},
	author = {Zhang, Lingzhe and Jia, Tong and Jia, Mengxi and Wu, Yifan and Liu, Aiwei and Yang, Yong and Wu, Zhonghai and Hu, Xuming and Yu, Philip and Li, Ying},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {AIOps, anomaly detection, assisted remediation, failure perception, incident report, Large language model, logs, metrics, root cause analysis, time series},
}

@article{bui_systematic_2024,
	title = {A {Systematic} {Comparison} of {Large} {Language} {Models} {Performance} for {Intrusion} {Detection}},
	volume = {2},
	url = {https://doi.org/10.1145/3696379},
	doi = {10.1145/3696379},
	abstract = {We explore the capabilities of Large Language Models (LLMs) to assist or substitute devices (i.e., firewalls) and humans (i.e., security experts) respectively in the detection and analysis of security incidents. We leverage transformer-based technologies, from relatively small to foundational sizes, to address the problem of correctly identifying the attack severity (and accessorily identifying and explaining the attack type). We contrast a broad range of LLM techniques (prompting, retrieval augmented generation, and fine-tuning of several models) using state-of-the-art machine learning models as a baseline. Using proprietary data from commercial deployment, our study provides an unbiased picture of the strengths and weaknesses of LLM for intrusion detection.},
	number = {CoNEXT4},
	journal = {Proc. ACM Netw.},
	author = {Bui, Minh-Thanh and Boffa, Matteo and Valentim, Rodolfo Vieira and Navarro, Jose Manuel and Chen, Fuxing and Bao, Xiaosheng and Houidi, Zied Ben and Rossi, Dario},
	month = nov,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {computing methodologies, firewalls, intrusion detection systems, machine learning, natural language processing, security and privacy},
}

@article{pan_survey_2025,
	title = {A {Survey} of {Research} in {Large} {Language} {Models} for {Electronic} {Design} {Automation}},
	volume = {30},
	issn = {1084-4309},
	url = {https://doi.org/10.1145/3715324},
	doi = {10.1145/3715324},
	abstract = {Within the rapidly evolving domain of Electronic Design Automation (EDA), Large Language Models (LLMs) have emerged as transformative technologies, offering unprecedented capabilities for optimizing and automating various aspects of electronic design. This survey provides a comprehensive exploration of LLM applications in EDA, focusing on advancements in model architectures, the implications of varying model sizes, and innovative customization techniques that enable tailored analytical insights. By examining the intersection of LLM capabilities and EDA requirements, the article highlights the significant impact these models have on extracting nuanced understandings from complex datasets. Furthermore, it addresses the challenges and opportunities in integrating LLMs into EDA workflows, paving the way for future research and application in this dynamic field. Through this detailed analysis, the survey aims to offer valuable insights to professionals in the EDA industry, AI researchers, and anyone interested in the convergence of advanced AI technologies and electronic design.},
	number = {3},
	journal = {ACM Trans. Des. Autom. Electron. Syst.},
	author = {Pan, Jingyu and Zhou, Guanglei and Chang, Chen-Chia and Jacobson, Isaac and Hu, Jiang and Chen, Yiran},
	month = feb,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {electronic design automation, Large language models, machine learning},
}

@article{shi_survey_2025,
	title = {A {Survey} on {Employing} {Large} {Language} {Models} for {Text}-to-{SQL} {Tasks}},
	volume = {58},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3737873},
	doi = {10.1145/3737873},
	abstract = {With the development of the Large Language Models (LLMs), a large range of LLM-based Text-to-SQL(Text2SQL) methods have emerged. This survey provides a comprehensive review of LLM-based Text2SQL studies. We first enumerate classic benchmarks and evaluation metrics. For the two mainstream methods, prompt engineering and finetuning, we introduce a comprehensive taxonomy and offer practical insights into each subcategory. We present an overall analysis of the above methods and various models evaluated on well-known datasets and extract some characteristics. Finally, we discuss the challenges and future directions in this field.},
	number = {2},
	journal = {ACM Comput. Surv.},
	author = {Shi, Liang and Tang, Zhengju and Zhang, Nan and Zhang, Xiaotong and Yang, Zhi},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {fine-tuning, Large language models, prompt engineering, Text-to-SQL},
}

@article{qin_ai-based_2025,
	title = {{AI}-{Based} {Speaking} {Assistant}: {Supporting} {Non}-{Native} {Speakers}' {Speaking} in {Real}-{Time} {Multilingual} {Communication}},
	volume = {9},
	url = {https://doi.org/10.1145/3757455},
	doi = {10.1145/3757455},
	abstract = {Non-native speakers (NNSs) often face speaking challenges in real-time multilingual communication, such as struggling to articulate their thoughts. To address this issue, we developed an AI-based speaking assistant (AISA) that provides speaking references for NNSs based on their input queries, task background, and conversation history. To explore NNSs' interaction with AISA and its impact on NNSs' speaking during real-time multilingual communication, we conducted a mixed-method study involving a within-subject experiment and follow-up interviews. In the experiment, two native speakers (NSs) and one NNS formed a team (31 teams in total) and completed two collaborative tasks-one with access to the AISA and one without. Overall, our study revealed four types of AISA input patterns among NNSs, each reflecting different levels of effort and language preferences. Although AISA did not improve NNSs' speaking competence, follow-up interviews revealed that it helped improve the logical flow and depth of their speech. Moreover, the additional multitasking introduced by AISA, such as entering and reviewing system output, potentially elevated NNSs' workload and anxiety. Based on these observations, we discuss the pros and cons of implementing tools to assist NNS in real-time multilingual communication and offer design recommendations.},
	number = {7},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Qin, Peinuan and Zhu, Zicheng and Yamashita, Naomi and Yang, Yitian and Suga, Keita and Lee, Yi-Chieh},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {AI-mediated communication, multilingual communication, non-native speakers, real-time, speaking support},
}

@article{naveed_comprehensive_2025,
	title = {A {Comprehensive} {Overview} of {Large} {Language} {Models}},
	volume = {16},
	issn = {2157-6904},
	url = {https://doi.org/10.1145/3744746},
	doi = {10.1145/3744746},
	abstract = {Large Language Models (LLMs) have recently demonstrated remarkable capabilities in natural language processing tasks and beyond. This success of LLMs has led to a large influx of research contributions in this direction. These works encompass diverse topics such as architectural innovations, better training strategies, context length improvements, fine-tuning, multimodal LLMs, robotics, datasets, benchmarking, efficiency, and more. With the rapid development of techniques and regular breakthroughs in LLM research, it has become considerably challenging to perceive the bigger picture of the advances in this direction. Considering the rapidly emerging plethora of literature on LLMs, it is imperative that the research community is able to benefit from a concise yet comprehensive overview of the recent developments in this field. This article provides an overview of the literature on a broad range of LLM-related concepts. Our self-contained comprehensive overview of LLMs discusses relevant background concepts along with covering the advanced topics at the frontier of research in LLMs. This review article is intended to provide not only a systematic survey but also a quick, comprehensive reference for the researchers and practitioners to draw insights from extensive, informative summaries of the existing works to advance the LLM research.},
	number = {5},
	journal = {ACM Trans. Intell. Syst. Technol.},
	author = {Naveed, Humza and Khan, Asad Ullah and Qiu, Shi and Saqib, Muhammad and Anwar, Saeed and Usman, Muhammad and Akhtar, Naveed and Barnes, Nick and Mian, Ajmal},
	month = aug,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Augmented LLMs, chatGPT, Large Language Models, LLM Benchmarking, LLM training, LLMs, Multimodal LLMs},
}

@article{israelsen_good_2025,
	title = {“{A} {Good} {Bot} {Always} {Knows} {Its} {Limitations}”: {Assessing} {Autonomous} {System} {Decision}-{Making} {Competencies} through {Factorized} {Machine} {Self}-{Confidence}},
	volume = {14},
	url = {https://doi.org/10.1145/3732794},
	doi = {10.1145/3732794},
	abstract = {How can intelligent machines assess their competency to complete a task? This question has come into focus for autonomous systems that algorithmically make decisions under uncertainty. We argue that machine self-confidence—a form of meta-reasoning based on self-assessments of system knowledge about the state of the world, itself, and ability to reason about and execute tasks—leads to many computable and useful competency indicators for such agents. This article presents our body of work, so far, on this concept in the form of the Factorized Machine Self-Confidence (FaMSeC) framework, which holistically considers several major factors driving competency in algorithmic decision-making: outcome assessment, solver quality, model quality, alignment quality, and past experience. In FaMSeC, self-confidence indicators are derived via “problem-solving statistics” embedded in Markov Decision Process solvers and related approaches. These statistics come from evaluating probabilistic exceedance margins in relation to certain outcomes and associated competency standards specified by an evaluator. Once designed, and evaluated, the statistics can be easily incorporated into autonomous agents and serve as indicators of competency. We include detailed descriptions and examples for Markov Decision Process agents and show how outcome assessment and solver quality factors can be found for a range of tasking contexts through novel use of meta-utility functions, behavior simulations, and surrogate prediction models. Numerical evaluations are performed to demonstrate that FaMSeC indicators perform as desired (references to human subject studies beyond the scope of this article are provided).},
	number = {4},
	journal = {J. Hum.-Robot Interact.},
	author = {Israelsen, Brett and Ahmed, Nisar R. and Aitken, Matthew and Frew, Eric W. and Lawrence, Dale A. and Argrow, Brian M.},
	month = jul,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {autonomous robots, human-autonomy interaction, Markov decision processes, probabilistic models, proficiency assessment},
}

@article{jiang_survey_2025,
	title = {A {Survey} on {Large} {Language} {Models} for {Code} {Generation}},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3747588},
	doi = {10.1145/3747588},
	abstract = {Large Language Models (LLMs) have garnered remarkable advancements across diverse code-related tasks, known as Code LLMs, particularly in code generation that generates source code with LLM from natural language descriptions. This burgeoning field has captured significant interest from both academic researchers and industry professionals due to its practical significance in software development, e.g., GitHub Copilot. Despite the active exploration of LLMs for a variety of code tasks, either from the perspective of natural language processing (NLP) or software engineering (SE) or both, there is a noticeable absence of a comprehensive and up-to-date literature review dedicated to LLM for code generation. In this survey, we aim to bridge this gap by providing a systematic literature review that serves as a valuable reference for researchers investigating the cutting-edge progress in LLMs for code generation. We introduce a taxonomy to categorize and discuss the recent developments in LLMs for code generation, covering aspects such as data curation, latest advances, performance evaluation, ethical implications, environmental impact, and real-world applications. In addition, we present a historical overview of the evolution of LLMs for code generation and provide a quantitative and qualitative comparative analysis of experimental results of code LLMs, sourced from their original papers to ensure a fair comparison on the HumanEval, MBPP, and BigCodeBench benchmarks, across various levels of difficulty and types of programming tasks, to highlight the progressive enhancements in LLM capabilities for code generation. We identify critical challenges and promising opportunities regarding the gap between academia and practical development. Furthermore, we have established a dedicated resource GitHub page () to continuously document and disseminate the most recent advances in the field.},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Jiang, Juyong and Wang, Fan and Shen, Jiasi and Kim, Sungju and Kim, Sunghun},
	month = jul,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Code Generation, Code Large Language Models, Large Language Models},
	annote = {Just Accepted},
	annote = {Just Accepted},
}

@article{chau_is_2025,
	title = {An {IS} {Research} {Agenda} on {Large} {Language} {Models}: {Development}, {Applications}, and {Impacts} on {Business} and {Management}},
	volume = {16},
	issn = {2158-656X},
	url = {https://doi.org/10.1145/3713032},
	doi = {10.1145/3713032},
	abstract = {Large language models have been advancing very rapidly and are making substantial impacts on all areas of business and management. We review the development of large language models and their applications in business and management, and identify the major issues and challenges faced by both practitioners and researchers. Based on our review, we propose an agenda for information systems researchers on large language models and discuss some of the potential directions for future research. Lastly, we present the articles in the special issue as exemplary research on large language models and discuss their implications.},
	number = {1},
	journal = {ACM Trans. Manage. Inf. Syst.},
	author = {Chau, Michael and Xu, Jennifer},
	month = feb,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {artificial intelligence, business and management, information systems research, Large language models},
}

@article{zhang_systematic_2025,
	title = {A {Systematic} {Survey} of {Text} {Summarization}: {From} {Statistical} {Methods} to {Large} {Language} {Models}},
	volume = {57},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3731445},
	doi = {10.1145/3731445},
	abstract = {Text summarization research has undergone several significant transformations with the advent of deep neural networks, pre-trained language models (PLMs), and recent large language models (LLMs). This survey thus provides a comprehensive review of the research progress and evolution in text summarization through the lens of these paradigm shifts. It is organized into two main parts: (1) a detailed overview of datasets, evaluation metrics, and summarization methods before the LLM era, encompassing traditional statistical methods, deep learning approaches, and PLM fine-tuning techniques, and (2) the first detailed examination of recent advancements in benchmarking, modeling, and evaluating summarization in the LLM era. By synthesizing existing literature and presenting a cohesive overview, this survey also discusses research trends, open challenges, and proposes promising research directions in summarization, aiming to guide researchers through the evolving landscape of summarization research.},
	number = {11},
	journal = {ACM Comput. Surv.},
	author = {Zhang, Haopeng and Yu, Philip S. and Zhang, Jiawei},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {dataset, deep learning, large language model, Summarization},
}

@article{fu_ai_2025,
	title = {{AI} for {DevSecOps}: {A} {Landscape} and {Future} {Opportunities}},
	volume = {34},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3712190},
	doi = {10.1145/3712190},
	abstract = {DevOps has emerged as one of the most rapidly evolving software development paradigms. With the growing concerns surrounding security in software systems, the DevSecOps paradigm has gained prominence, urging practitioners to incorporate security practices seamlessly into the DevOps workflow. However, integrating security into the DevOps workflow can impact agility and impede delivery speed. Recently, the advancement of artificial intelligence (AI) has revolutionized automation in various software domains, including software security. AI-driven security approaches, particularly those leveraging machine learning or deep learning, hold promise in automating security workflows. They have the potential to reduce manual efforts and can be incorporated into DevOps practices to support consistent delivery speed while aligning with the principles of the DevSecOps paradigm. This article seeks to contribute to the critical intersection of AI and DevSecOps by presenting a comprehensive landscape of AI-driven security techniques applicable to DevOps and identifying avenues for enhancing security, trust, and efficiency in software development processes. We analyzed 99 research papers spanning from 2017 to 2023. Specifically, we address two key research questions (RQs). In RQ1, we identified 12 security tasks associated with the DevSecOps process and reviewed existing AI-driven security approaches, the problems they addressed, and the 65 benchmarks used to evaluate those approaches. Drawing insights from our findings, in RQ2, we discussed state-of-the-art AI-driven security approaches, highlighted 15 challenges in existing research, and proposed 15 corresponding avenues for future opportunities.},
	number = {4},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Fu, Michael and Pasuksmit, Jirat and Tantithamthavorn, Chakkrit},
	month = apr,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {AI Security, Artificial Intelligence, Deep Learning, DevOps, DevSecOps, Machine Learning, Supply Chain Security, Vulnerability},
}

@article{yu_survey_2022,
	title = {A {Survey} of {Knowledge}-enhanced {Text} {Generation}},
	volume = {54},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3512467},
	doi = {10.1145/3512467},
	abstract = {The goal of text-to-text generation is to make machines express like a human in many applications such as conversation, summarization, and translation. It is one of the most important yet challenging tasks in natural language processing (NLP). Various neural encoder-decoder models have been proposed to achieve the goal by learning to map input text to output text. However, the input text alone often provides limited knowledge to generate the desired output, so the performance of text generation is still far from satisfaction in many real-world scenarios. To address this issue, researchers have considered incorporating (i) internal knowledge embedded in the input text and (ii) external knowledge from outside sources such as knowledge base and knowledge graph into the text generation system. This research topic is known as knowledge-enhanced text generation. In this survey, we present a comprehensive review of the research on this topic over the past five years. The main content includes two parts: (i) general methods and architectures for integrating knowledge into text generation; (ii) specific techniques and applications according to different forms of knowledge data. This survey can have broad audiences, researchers and practitioners, in academia and industry.},
	number = {11s},
	journal = {ACM Comput. Surv.},
	author = {Yu, Wenhao and Zhu, Chenguang and Li, Zaitang and Hu, Zhiting and Wang, Qingyun and Ji, Heng and Jiang, Meng},
	month = nov,
	year = {2022},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Knowledge-enhanced Methods, Natural language generation},
}

@article{barbosa_cost-effective_2025,
	title = {A {Cost}-{Effective} {LLM}-based {Approach} to {Identify} {Wildlife} {Trafficking} in {Online} {Marketplaces}},
	volume = {3},
	url = {https://doi.org/10.1145/3725256},
	doi = {10.1145/3725256},
	abstract = {Wildlife trafficking remains a critical global issue, significantly impacting biodiversity, ecological stability, and public health. Despite efforts to combat this illicit trade, the rise of e-commerce platforms has made it easier to sell wildlife products, putting new pressure on wild populations of endangered and threatened species. The use of these platforms also opens a new opportunity: as criminals sell wildlife products online, they leave digital traces of their activity that can provide insights into trafficking activities as well as how they can be disrupted. The challenge lies in finding these traces. Online marketplaces publish ads for a plethora of products, and identifying ads for wildlife-related products is like finding a needle in a haystack. Learning classifiers can automate ad identification, but creating them requires costly, time-consuming data labeling that hinders support for diverse ads and research questions. This paper addresses a critical challenge in the data science pipeline for wildlife trafficking analytics: generating quality labeled data for classifiers that select relevant data. While large language models (LLMs) can directly label advertisements, doing so at scale is prohibitively expensive. We propose a cost-effective strategy that leverages LLMs to generate pseudo labels for a small sample of the data and uses these labels to create specialized classification models. Our novel method automatically gathers diverse and representative samples to be labeled while minimizing the labeling costs. Our experimental evaluation shows that our classifiers achieve up to 95\% F1 score, outperforming LLMs at a lower cost. We present real use cases that demonstrate the effectiveness of our approach in enabling analyses of different aspects of wildlife trafficking.},
	number = {3},
	journal = {Proc. ACM Manag. Data},
	author = {Barbosa, Juliana Silva and Gondhali, Ulhas and Petrossian, Gohar and Sharma, Kinshuk and Chakraborty, Sunandan and Jacquet, Jennifer and Freire, Juliana},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {large language models, pseudo-labeling, wildlife},
}

@article{li_structure-aware_2025,
	title = {A {Structure}-aware {Approach} {Leveraging} {Semantic} {Relevance} {Graph} for {Annotation} {Alignment} of {Chinese} {Classics}},
	volume = {24},
	issn = {2375-4699},
	url = {https://doi.org/10.1145/3725733},
	doi = {10.1145/3725733},
	abstract = {Throughout the long history of China, ideologists have annotated classical texts, providing a valuable resource for scholarly study. Many of these annotations are presented as entire paragraphs, each sentence of which must be linked to the corresponding classical sentences, also in paragraph form. However, there has been a lack of definitions and datasets for this specific task. In this article, we propose a definition for the task of annotation alignment of Chinese classics and present a corresponding dataset. We observe that directly matching an annotation sentence to a classical sentence may encounter challenges due to limitations in classical Chinese semantic models. Furthermore, an annotation sentence may not be directly related to the target classical sentence but may instead be more closely associated with other neighboring annotation sentences. Based on these observations, we propose a semantic relevance graph-based approach that leverages task-specific structural features. Our proposed method achieves a macro precision of 82.17 and a micro precision of 86.55, significantly surpassing all baseline models including large language models, which attests to the effectiveness of our approach.},
	number = {5},
	journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
	author = {Li, Wei and Li, Yi and Shao, Yanqiu and Bi, Mengxi},
	month = apr,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Annotation alignment, Chinese classics, community detection},
}

@article{prakash_all_2024,
	title = {All in {One} {Place}: {Ensuring} {Usable} {Access} to {Online} {Shopping} {Items} for {Blind} {Users}},
	volume = {8},
	url = {https://doi.org/10.1145/3664639},
	doi = {10.1145/3664639},
	abstract = {Perusing web data items such as shopping products is a core online user activity. To prevent information overload, the content associated with data items is typically dispersed across multiple webpage sections over multiple web pages. However, such content distribution manifests an unintended side effect of significantly increasing the interaction burden for blind users, since navigating to-and-fro between different sections in different pages is tedious and cumbersome with their screen readers. While existing works have proposed methods for the context of a single webpage, solutions enabling usable access to content distributed across multiple webpages are few and far between. In this paper, we present InstaFetch, a browser extension that dynamically generates an alternative screen reader-friendly user interface in real-time, which blind users can leverage to almost instantly access different item-related information such as description, full specification, and user reviews, all in one place, without having to tediously navigate to different sections in different webpages. Moreover, InstaFetch also supports natural language queries about any item, a feature blind users can exploit to quickly obtain desired information, thereby avoiding manually trudging through reams of text. In a study with 14 blind users, we observed that the participants needed significantly lesser time to peruse data items with InstaFetch, than with a state-of-the-art solution.},
	number = {EICS},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Prakash, Yash and Nayak, Akshay Kolgar and Sunkara, Mohan and Jayarathna, Sampath and Lee, Hae-Na and Ashok, Vikas},
	month = jun,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Blind, Online shopping, Screen reader, Visual impairment, Web usability},
}

@article{ibrahimzada_alphatrans_2025,
	title = {{AlphaTrans}: {A} {Neuro}-{Symbolic} {Compositional} {Approach} for {Repository}-{Level} {Code} {Translation} and {Validation}},
	volume = {2},
	url = {https://doi.org/10.1145/3729379},
	doi = {10.1145/3729379},
	abstract = {Code translation transforms programs from one programming language (PL) to another. One prominent use case is application modernization to enhance maintainability and reliability. Several rule-based transpilers have been designed to automate code translation between different pairs of PLs. However, the rules can become obsolete as the PLs evolve and cannot generalize to other PLs. Recent studies have explored the automation of code translation using Large Language Models (LLMs). One key observation is that such techniques may work well for crafted benchmarks but fail to generalize to the scale and complexity of real-world projects with inter- and intra-class dependencies, custom types, PL-specific features, etc. We propose AlphaTrans, a neuro-symbolic approach to automate repository-level code translation. AlphaTrans translates both source and test code, and employs multiple levels of validation to ensure the translation preserves the functionality of the source program. To break down the problem for LLMs, AlphaTrans leverages program analysis to decompose the program into fragments and translates them in the reverse call order. We leveraged AlphaTrans to translate ten real-world open-source projects consisting of ⟨836, 8575, 2719⟩ (application and test) classes, (application and test) methods, and unit tests. AlphaTrans breaks down these projects into 17874 fragments and translates the entire repository. 96.40\% of the translated fragments are syntactically correct, and AlphaTrans validates the translations’ runtime behavior and functional correctness for 27.03\% and 25.14\% of the application method fragments. On average, integrated translation and validation takes 34 hours (min=3, max=121) to translate a project, showing its scalability in practice. For the syntactically or semantically incorrect translations, AlphaTrans generates a report including existing translation, stack trace, test errors, or assertion failures. We provided these artifacts to two developers to fix the translation bugs in four projects. They fixed the issues in 20.1 hours on average (5.5 hours for the smallest and 34 hours for the largest project) and achieved all passing tests. Without AlphaTrans, translating and validating such big projects could take weeks, if not months.},
	number = {FSE},
	journal = {Proc. ACM Softw. Eng.},
	author = {Ibrahimzada, Ali Reza and Ke, Kaiyao and Pawagi, Mrigank and Abid, Muhammad Salman and Pan, Rangeet and Sinha, Saurabh and Jabbarvand, Reyhaneh},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Neuro-Symbolic Code Translation and Validation},
}

@article{srba_survey_2025,
	title = {A {Survey} on {Automatic} {Credibility} {Assessment} {Using} {Textual} {Credibility} {Signals} in the {Era} of {Large} {Language} {Models}},
	issn = {2157-6904},
	url = {https://doi.org/10.1145/3770077},
	doi = {10.1145/3770077},
	abstract = {In the age of social media and generative AI, the ability to automatically assess the credibility of online content has become increasingly critical, complementing traditional approaches to false information detection. Credibility assessment relies on aggregating diverse credibility signals – small units of information, such as content subjectivity, bias, or a presence of persuasion techniques – into a final credibility label/score. However, current research in automatic credibility assessment and credibility signals detection remains highly fragmented, with many signals studied in isolation and lacking integration. Notably, there is a scarcity of approaches that detect and aggregate multiple credibility signals simultaneously. These challenges are further exacerbated by the absence of a comprehensive and up-to-date overview of research works that connects these research efforts under a common framework and identifies shared trends, challenges, and open problems. In this survey, we address this gap by presenting a systematic and comprehensive literature review of 175 research papers, focusing on textual credibility signals within the field of Natural Language Processing (NLP), which undergoes a rapid transformation due to advancements in Large Language Models (LLMs). While positioning the NLP research into the the broader multidisciplinary landscape, we examine both automatic credibility assessment methods as well as the detection of nine categories of credibility signals. We provide an in-depth analysis of three key categories: 1) factuality, subjectivity and bias, 2) persuasion techniques and logical fallacies, and 3) check-worthy and fact-checked claims. In addition to summarising existing methods, datasets, and tools, we outline future research direction and emerging opportunities, with particular attention to evolving challenges posed by generative AI.},
	journal = {ACM Trans. Intell. Syst. Technol.},
	author = {Srba, Ivan and Razuvayevskaya, Olesya and Leite, João A. and Moro, Robert and Schlicht, Ipek Baris and Tonelli, Sara and García, Francisco Moreno and Lottmann, Santiago Barrio and Teyssou, Denis and Porcellini, Valentin and Scarton, Carolina and Bontcheva, Kalina and Bielikova, Maria},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Credibility Assessment, Credibility Signals, Large Language Models, Literature Survey, Natural Language Processing, NLP},
	annote = {Just Accepted},
	annote = {Just Accepted},
}

@article{koh_empirical_2022,
	title = {An {Empirical} {Survey} on {Long} {Document} {Summarization}: {Datasets}, {Models}, and {Metrics}},
	volume = {55},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3545176},
	doi = {10.1145/3545176},
	abstract = {Long documents such as academic articles and business reports have been the standard format to detail out important issues and complicated subjects that require extra attention. An automatic summarization system that can effectively condense long documents into short and concise texts to encapsulate the most important information would thus be significant in aiding the reader’s comprehension. Recently, with the advent of neural architectures, significant research efforts have been made to advance automatic text summarization systems, and numerous studies on the challenges of extending these systems to the long document domain have emerged. In this survey, we provide a comprehensive overview of the research on long document summarization and a systematic evaluation across the three principal components of its research setting: benchmark datasets, summarization models, and evaluation metrics. For each component, we organize the literature within the context of long document summarization and conduct an empirical analysis to broaden the perspective on current research progress. The empirical analysis includes a study on the intrinsic characteristics of benchmark datasets, a multi-dimensional analysis of summarization models, and a review of the summarization evaluation metrics. Based on the overall findings, we conclude by proposing possible directions for future exploration in this rapidly growing field.},
	number = {8},
	journal = {ACM Comput. Surv.},
	author = {Koh, Huan Yee and Ju, Jiaxin and Liu, Ming and Pan, Shirui},
	month = dec,
	year = {2022},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {datasets, Document summarization, language models, neural networks, transformer},
}

@article{schoeffer_ai_2025,
	title = {{AI} {Reliance} and {Decision} {Quality}: {Fundamentals}, {Interdependence}, and the {Effects} of {Interventions}},
	volume = {82},
	issn = {1076-9757},
	url = {https://doi.org/10.1613/jair.1.15873},
	doi = {10.1613/jair.1.15873},
	abstract = {In AI-assisted decision-making, a central promise of having a human-in-the-loop is that they should be able to complement the AI system by overriding its wrong recommendations. In practice, however, we often see that humans cannot assess the correctness of AI recommendations and, as a result, adhere to wrong or override correct advice. Different ways of relying on AI recommendations have immediate, yet distinct, implications for decision quality. Unfortunately, reliance and decision quality are often inappropriately conflated in the current literature on AI-assisted decision-making. In this work, we disentangle and formalize the relationship between reliance and decision quality, and we characterize the conditions under which human-AI complementarity is achievable. To illustrate how reliance and decision quality relate to one another, we propose a visual framework and demonstrate its usefulness for interpreting empirical findings, including the effects of interventions like explanations. Overall, our research highlights the importance of distinguishing between reliance behavior and decision quality in AI-assisted decision-making.},
	journal = {J. Artif. Int. Res.},
	author = {Schoeffer, Jakob and Jakubik, Johannes and Vössing, Michael and Kühl, Niklas and Satzger, Gerhard},
	month = apr,
	year = {2025},
	note = {Place: El Segundo, CA, USA
Publisher: AI Access Foundation},
	pages = {471--501},
}

@article{ye_gradual_2023,
	title = {A {Gradual} {Probabilistic} {Lambda} {Calculus}},
	volume = {7},
	url = {https://doi.org/10.1145/3586036},
	doi = {10.1145/3586036},
	abstract = {Probabilistic programming languages have recently gained a lot of attention, in particular due to their applications in domains such as machine learning and differential privacy. To establish invariants of interest, many such languages include some form of static checking in the form of type systems. However, adopting such a type discipline can be cumbersome or overly conservative. Gradual typing addresses this problem by supporting a smooth transition between static and dynamic checking, and has been successfully applied for languages with different constructs and type abstractions. Nevertheless, its benefits have never been explored in the context of probabilistic languages. In this work, we present and formalize GPLC, a gradual source probabilistic lambda calculus. GPLC includes a binary probabilistic choice operator and allows programmers to gradually introduce/remove static type–and probability–annotations. The static semantics of GPLC heavily relies on the notion of probabilistic couplings, as required for defining several relations, such as consistency, precision, and consistent transitivity. The dynamic semantics of GPLC is given via elaboration to the target language TPLC, which features a distribution-based semantics interpreting programs as probability distributions over final values. Regarding the language metatheory, we establish that TPLC–and therefore also GPLC–is type safe and satisfies two of the so-called refined criteria for gradual languages, namely, that it is a conservative extension of a fully static variant and that it satisfies the gradual guarantee, behaving smoothly with respect to type precision.},
	number = {OOPSLA1},
	journal = {Proc. ACM Program. Lang.},
	author = {Ye, Wenjia and Toro, Matías and Olmedo, Federico},
	month = apr,
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Gradual Typing, Probabilistic Lambda Calculus, Type Systems},
}

@article{metzger_user_2024,
	title = {A {User} {Study} on {Explainable} {Online} {Reinforcement} {Learning} for {Adaptive} {Systems}},
	volume = {19},
	issn = {1556-4665},
	url = {https://doi.org/10.1145/3666005},
	doi = {10.1145/3666005},
	abstract = {Online reinforcement learning (RL) is increasingly used for realizing adaptive systems in the presence of design time uncertainty because Online RL can leverage data only available at run time. With Deep RL gaining interest, the learned knowledge is no longer represented explicitly but hidden in the parameterization of the underlying artificial neural network. For a human, it thus becomes practically impossible to understand the decision-making of Deep RL, which makes it difficult for (1) software engineers to perform debugging, (2) system providers to comply with relevant legal frameworks, and (3) system users to build trust. The explainable RL technique XRL-DINE, introduced in earlier work, provides insights into why certain decisions were made at important time steps. Here, we perform an empirical user study concerning XRL-DINE involving 73 software engineers split into treatment and control groups. The treatment group is given access to XRL-DINE, while the control group is not. We analyze (1) the participants’ performance in answering concrete questions related to the decision-making of Deep RL, (2) the participants’ self-assessed confidence in giving the right answers, (3) the perceived usefulness and ease of use of XRL-DINE, and (4) the concrete usage of the XRL-DINE dashboard.},
	number = {3},
	journal = {ACM Trans. Auton. Adapt. Syst.},
	author = {Metzger, Andreas and Laufer, Jan and Feit, Felix and Pohl, Klaus},
	month = sep,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {adaptive system, debugging, explainability, interpretability, machine learning, reinforcement learning},
}

@article{baumer_algorithmic_2024,
	title = {Algorithmic {Subjectivities}},
	volume = {31},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/3660344},
	doi = {10.1145/3660344},
	abstract = {This article considers how subjectivities are enlivened in algorithmic systems. We first review related literature to clarify how we see “subjectivities” as emerging through a tangled web of processes and actors. We then offer two case studies exemplifying the emergence of algorithmic subjectivities: one involving computational topic modeling of blogs written by parents with children on the autism spectrum and one involving algorithmic moderation of social media content. Drawing on these case studies, we then articulate a series of qualities that characterizes algorithmic subjectivities. We also compare and contrast these qualities with a number of related concepts from prior literature to articulate how algorithmic subjectivities constitute a novel theoretical contribution, as well as how it offers a focal lens for future empirical investigation and for design. In short, this article points out how certain worlds are being made and/or being made possible via algorithmic systems, and it asks Human–Computer Interaction (HCI) to consider what other worlds might be possible.},
	number = {3},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	author = {Baumer, Eric P. S. and Taylor, Alex S. and Brubaker, Jed R. and McGee, Micki},
	month = aug,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {algorithms, reflective HCI, Subjectivity},
}

@article{cai_after_2021,
	title = {After {Violation} {But} {Before} {Sanction}: {Understanding} {Volunteer} {Moderators}' {Profiling} {Processes} {Toward} {Violators} in {Live} {Streaming} {Communities}},
	volume = {5},
	url = {https://doi.org/10.1145/3479554},
	doi = {10.1145/3479554},
	abstract = {Content moderation is an essential part of online community health and governance. While much of extant research is centered on what happens to the content, moderation also involves the management of violators. This study focuses on how moderators (mods) make decisions about their actions after the violation takes place but before the sanction by examining how they "profile" the violators. Through observations and interviews with volunteer mods on Twitch, we found that mods engage in a complex process of collaborative evidence collection and profile violators into different categories to decide the type and extent of punishment. Mods consider violators' characteristics as well as behavioral history and violation context before taking moderation action. The main purpose of the profiling was to avoid excessive punishment and aim to integrate violators more into the community. We discuss the contributions of profiling to moderation practice and suggest design mechanisms to facilitate mods' profiling processes.},
	number = {CSCW2},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Cai, Jie and Wohn, Donghee Yvette},
	month = oct,
	year = {2021},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {content moderation, live streaming, profiling, volunteer moderator},
}

@article{meylan_study_2020,
	title = {A {Study} on the {Use} of {Checksums} for {Integrity} {Verification} of {Web} {Downloads}},
	volume = {24},
	issn = {2471-2566},
	url = {https://doi.org/10.1145/3410154},
	doi = {10.1145/3410154},
	abstract = {App stores provide access to millions of different programs that users can download on their computers. Developers can also make their programs available for download on their websites and host the program files either directly on their website or on third-party platforms, such as mirrors. In the latter case, as users download the software without any vetting from the developers, they should take the necessary precautions to ensure that it is authentic. One way to accomplish this is to check that the published file’s integrity verification code—the checksum—matches that (if provided) of the downloaded file. To date, however, there is little evidence to suggest that such a process is effective. Even worse, very few usability studies about it exist.In this article, we provide the first comprehensive study that assesses the usability and effectiveness of the manual checksum verification process. First, by means of an in-situ experiment with 40 participants and eye-tracking technology, we show that the process is cumbersome and error-prone. Second, after a 4-month-long in-the-wild experiment with 134 participants, we demonstrate how our proposed solution—a Chrome extension that verifies checksums automatically—significantly reduces human errors, improves coverage, and has only limited impact on usability. It also confirms that, sadly, only a tiny minority of websites that link to executable files in our sample provide checksums (0.01\%), which is a strong call to action for web standards bodies, service providers, and content creators to increase the use of file integrity verification on their properties.},
	number = {1},
	journal = {ACM Trans. Priv. Secur.},
	author = {Meylan, Alexandre and Cherubini, Mauro and Chapuis, Bertil and Humbert, Mathias and Bilogrevic, Igor and Huguenin, Kévin},
	month = sep,
	year = {2020},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Checksums, integrity, security, usability, web downloads},
}

@article{hamed_comparison_2025,
	title = {A {Comparison} of {Open} {Data} {Observatories}},
	volume = {17},
	issn = {1936-1955},
	url = {https://doi.org/10.1145/3705863},
	doi = {10.1145/3705863},
	abstract = {Open Data Observatories refer to online platforms that provide real-time and historical data for a particular application context, e.g., urban/non-urban environments or a specific application domain. They are generally developed to facilitate collaboration within one or more communities through reusable datasets, analysis tools, and interactive visualizations. Open Data Observatories collect and integrate various data from multiple disparate data sources—some providing mechanisms to support real-time data capture and ingest. Data types can include sensor data (soil, weather, traffic, pollution levels) and satellite imagery. Data sources can include Open Data providers, interconnected devices, and services offered through the Internet of Things. The continually increasing volume and variety of such data require timely integration, management, and analysis, yet presented in a way that end-users can easily understand. Data released for open access preserve their value and enable a more in-depth understanding of real-world choices. This survey compares 13 Open Data Observatories and their data management approaches—investigating their aims, design, and types of data. We conclude with research challenges that influence the implementation of these observatories, outlining some strengths and limitations for each one and recommending areas for improvement. Our goal is to identify best practices learned from the selected observatories to aid the development of new Open Data Observatories.},
	number = {1},
	journal = {J. Data and Information Quality},
	author = {Hamed, Naeima and Rana, Omer and Orozco-terWengel, Pablo and Goossens, Benoît and Perera, Charith},
	month = mar,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Data integration, Data platforms, FAIR Open Data principles, Urban and non-urban data observatories},
}

@article{irrera_novel_2023,
	title = {A {Novel} {Curated} {Scholarly} {Graph} {Connecting} {Textual} and {Data} {Publications}},
	volume = {15},
	issn = {1936-1955},
	url = {https://doi.org/10.1145/3597310},
	doi = {10.1145/3597310},
	abstract = {In the last decade, scholarly graphs became fundamental to storing and managing scholarly knowledge in a structured and machine-readable way. Methods and tools for discovery and impact assessment of science rely on such graphs and their quality to serve scientists, policymakers, and publishers. Since research data became very important in scholarly communication, scholarly graphs started including dataset metadata and their relationships to publications. Such graphs are the foundations for Open Science investigations, data-article publishing workflows, discovery, and assessment indicators. However, due to the heterogeneity of practices (FAIRness is indeed in the making), they often lack the complete and reliable metadata necessary to perform accurate data analysis; e.g., dataset metadata is inaccurate, author names are not uniform, and the semantics of the relationships is unknown, ambiguous or incomplete.This work describes an open and curated scholarly graph we built and published as a training and test set for data discovery, data connection, author disambiguation, and link prediction tasks. Overall the graph contains 4,047 publications, 5,488 datasets, 22 software, 21,561 authors; 9,692 edges interconnect publications to datasets and software and are labeled with semantics that outline whether a publication is citing, referencing, documenting, supplementing another product.To ensure high-quality metadata and semantics, we relied on the information extracted from PDFs of the publications and the datasets and software webpages to curate and enrich nodes metadata and edges semantics. To the best of our knowledge, this is the first ever published resource, including publications and datasets with manually validated and curated metadata.},
	number = {3},
	journal = {J. Data and Information Quality},
	author = {Irrera, Ornella and Mannocci, Andrea and Manghi, Paolo and Silvello, Gianmaria},
	month = aug,
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {data curation, data enrichment, datasets, open science, Scholarly knowledge graphs},
}

@inproceedings{xu_generative_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {Generative {AI} and {Retrieval}-{Augmented} {Generation} ({RAG}) {Systems} for {Enterprise}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3680117},
	doi = {10.1145/3627673.3680117},
	abstract = {This workshop introduces generative AI applications for enterprise, with a focus on retrieval-augmented generation (RAG) systems. Generative AI is a field of artificial intelligence that can create new content and solve complex problems. RAG systems are a novel generative AI technique that combines information retrieval with text generation to generate rich and diverse responses. RAG systems can leverage enterprise data, which is often specific, structured, and dynamic, to provide customized solutions for various domains. However, enterprise data also poses challenges such as scalability, security, and data quality. This workshop convenes researchers and practitioners to explore RAG and other generative AI systems in real-world enterprise scenarios, fostering knowledge exchange, collaboration, and identification of future directions. Relevant to the CIKM community, the workshop intersects with core areas of data science and machine learning, offering potential benefits across various domains.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Xu, Anbang and Yu, Tan and Du, Min and Gundecha, Pritam and Guo, Yufan and Zhu, Xinliang and Wang, May and Li, Ping and Chen, Xinyun},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {enterprise application, generation, rag, retrieval},
	pages = {5599--5602},
}

@inproceedings{feng_response_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Response {Quality} {Assessment} for {Retrieval}-{Augmented} {Generation} via {Conditional} {Conformal} {Factuality}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730244},
	doi = {10.1145/3726302.3730244},
	abstract = {Existing research on Retrieval-Augmented Generation (RAG) primarily focuses on improving overall question-answering accuracy, often overlooking the quality of sub-claims within generated responses. Recent methods that attempt to improve RAG trustworthiness, such as through auto-evaluation metrics, lack probabilistic guarantees or require ground truth answers. To address these limitations, we propose Conformal-RAG, a novel framework inspired by recent applications of conformal prediction (CP) on large language models (LLMs). Conformal-RAG leverages CP and internal information from the RAG mechanism to offer statistical guarantees on response quality. It ensures group-conditional coverage spanning multiple sub-domains without requiring manual labelling of conformal sets, making it suitable for complex RAG applications. Compared to existing RAG auto-evaluation methods, Conformal-RAG offers statistical guarantees on the quality of refined sub-claims, ensuring response reliability without the need for ground truth answers. Additionally, our experiments demonstrate that by leveraging information from the RAG system, Conformal-RAG retains up to 60\% more high-quality sub-claims from the response compared to direct applications of CP to LLMs, while maintaining the same reliability guarantee.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Feng, Naihe and Sui, Yi and Hou, Shiyi and Cresswell, Jesse C. and Wu, Ga},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {conformal prediction, retrieval augmented generation},
	pages = {2832--2836},
}

@inproceedings{prahlad_personalizing_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Personalizing {Large} {Language} {Models} using {Retrieval} {Augmented} {Generation} and {Knowledge} {Graph}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715473},
	doi = {10.1145/3701716.3715473},
	abstract = {The advent of large language models (LLMs) has allowed numerous applications, including the generation of queried responses, to be leveraged in chatbots and other conversational assistants. Being trained on a plethora of data, LLMs often undergo high levels of over-fitting, resulting in the generation of extra and incorrect data, thus causing hallucinations in output generation. One of the root causes of such problems is the lack of timely, factual, and personalized information fed to the LLM. In this paper, we propose an approach to address these problems by introducing retrieval augmented generation (RAG) using knowledge graphs (KGs) to assist the LLM in personalized response generation tailored to the users. KGs have the advantage of storing continuously updated factual information in a structured way. While our KGs can be used for a variety of frequently updated personal data, such as calendar, contact, and location data, we focus on calendar data in this paper. Our experimental results show that our approach works significantly better in understanding personal information and generating accurate responses compared to the baseline LLMs using personal data as text inputs, with a moderate reduction in response time.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Prahlad, Deeksha and Lee, Chanhee and Kim, Dongha and Kim, Hokeun},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {knowledge graph, large language model, personalization, retrieval augmented generation},
	pages = {1259--1263},
}

@inproceedings{salemi_evaluating_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Evaluating {Retrieval} {Quality} in {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657957},
	doi = {10.1145/3626772.3657957},
	abstract = {Evaluating retrieval-augmented generation (RAG) presents challenges, particularly for retrieval models within these systems. Traditional end-to-end evaluation methods are computationally expensive. Furthermore, evaluation of the retrieval model's performance based on query-document relevance labels shows a small correlation with the RAG system's downstream performance. We propose a novel evaluation approach, eRAG, where each document in the retrieval list is individually utilized by the large language model within the RAG system. The output generated for each document is then evaluated based on the downstream task ground truth labels. In this manner, the downstream performance for each document serves as its relevance label. We employ various downstream task metrics to obtain document-level annotations and aggregate them using set-based or ranking metrics. Extensive experiments on a wide range of datasets demonstrate that eRAG achieves a higher correlation with downstream RAG performance compared to baseline methods, with improvements in Kendall's tau correlation ranging from 0.168 to 0.494. Additionally, eRAG offers significant computational advantages, improving runtime and consuming up to 50 times less GPU memory than end-to-end evaluation.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Salemi, Alireza and Zamani, Hamed},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {evaluation, retrieval quality, retrieval-augmented generation},
	pages = {2395--2400},
}

@inproceedings{jin_flashrag_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{FlashRAG}: {A} {Modular} {Toolkit} for {Efficient} {Retrieval}-{Augmented} {Generation} {Research}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715313},
	doi = {10.1145/3701716.3715313},
	abstract = {With the advent of large language models (LLMs) and multimodal large language models (MLLMs), the potential of retrieval-augmented generation (RAG) has attracted considerable research attention. However, the absence of a standardized framework for implementation, coupled with the inherently complex RAG process, makes it challenging and time-consuming for researchers to compare and evaluate these approaches in a consistent environment. In response to this challenge, we develop FlashRAG, an efficient and modular open-source toolkit designed to assist researchers in reproducing and comparing existing RAG methods and developing their own algorithms within a unified framework. Our toolkit has implemented 16 advanced RAG methods and gathered and organized 38 benchmark datasets. It has various features, including a customizable modular framework, a rich collection of pre-implemented RAG works, comprehensive datasets, efficient auxiliary pre-processing scripts, and extensive and standard evaluation metrics. Our toolkit and resources are available at https://github.com/RUC-NLPIR/FlashRAG.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Jin, Jiajie and Zhu, Yutao and Dou, Zhicheng and Dong, Guanting and Yang, Xinyu and Zhang, Chenghao and Zhao, Tong and Yang, Zhao and Wen, Ji-Rong},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {efficient, rag, research, retrieval augmented generation, toolkit},
	pages = {737--740},
}

@inproceedings{xu_rallrec_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{RALLRec}: {Improving} {Retrieval} {Augmented} {Large} {Language} {Model} {Recommendation} with {Representation} {Learning}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715508},
	doi = {10.1145/3701716.3715508},
	abstract = {Large Language Models (LLMs) have been integrated into recommendation systems to enhance user behavior comprehension. The Retrieval Augmented Generation (RAG) technique is further incorporated into these systems to retrieve more relevant items and improve system performance. However, existing RAG methods rely primarily on textual semantics and often fail to incorporate the most relevant items, limiting the effectiveness of the systems.In this paper, we propose Representation learning for retrieval-Augmented Large Language model Recommendation (RALLRec). Specifically, we enhance textual semantics by prompting LLMs to generate more detailed item descriptions, followed by joint representation learning of textual and collaborative semantics, which are extracted by the LLM and recommendation models, respectively. Considering the potential time-varying characteristics of user interest, a simple yet effective reranking method is further introduced to capture the dynamics of user preference. We conducted extensive experiments on three real-world datasets, and the evaluation results validated the effectiveness of our method. Code is made public at https://github.com/JianXu95/RALLRec.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Xu, Jian and Luo, Sichun and Chen, Xiangyu and Huang, Haoming and Hou, Hanxu and Song, Linqi},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {large language model, recommender system, retrieval-augmented generation},
	pages = {1436--1440},
}

@inproceedings{wang_r3ag_2024,
	address = {New York, NY, USA},
	series = {{SIGIR}-{AP} 2024},
	title = {{R3AG}: {First} {Workshop} on {Refined} and {Reliable} {Retrieval} {Augmented} {Generation}},
	isbn = {979-8-4007-0724-7},
	url = {https://doi.org/10.1145/3673791.3698435},
	doi = {10.1145/3673791.3698435},
	abstract = {Retrieval-augmented generation (RAG) has gained wide attention as the key component to improve generative models with external knowledge augmentation from information retrieval. It has shown great prominence in enhancing the functionality and performance of large language model (LLM)-based applications. However, with the comprehensive application of RAG, more and more problems and limitations have been identified, thus urgently requiring further fundamental exploration to improve current RAG frameworks. This workshop aims to explore in depth how to conduct refined and reliable RAG for downstream AI tasks.To this end, we propose to organize the first R3AG workshop at SIGIR-AP 2024 to call for participants to re-examine and formulate the basic principles and practical implementation of refined and reliable RAG. The workshop serves as a platform for both academia and industry researchers to conduct discussions, share insights, and foster research to build the next generation of RAG systems. Participants will engage in discussions and presentations focusing on fundamental challenges, cutting-edge research, and potential pathways to improve RAG. At the end of the workshop, we aim to have a clearer understanding of how to improve the reliability and applicability of RAG with more robust information retrieval and language generation.},
	booktitle = {Proceedings of the 2024 {Annual} {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval} in the {Asia} {Pacific} {Region}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Zihan and Ge, Xuri and Jose, Joemon M. and Yu, Haitao and Ma, Weizhi and Ren, Zhaochun and Xin, Xin},
	year = {2024},
	note = {event-place: Tokyo, Japan},
	keywords = {information retrieval, large lan- guage models, reliability, retrieval-augmented generation},
	pages = {307--310},
}

@inproceedings{sudhi_rag-ex_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {{RAG}-{Ex}: {A} {Generic} {Framework} for {Explaining} {Retrieval} {Augmented} {Generation}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657660},
	doi = {10.1145/3626772.3657660},
	abstract = {Owing to their size and complexity, large language models (LLMs) hardly explain why they generate a response. This effectively reduces the trust and confidence of end users in LLM-based applications, including Retrieval Augmented Generation (RAG) for Question Answering (QA) tasks. In this work, we introduce RAG-Ex, a model- and language-agnostic explanation framework that presents approximate explanations to the users revealing why the LLMs possibly generated a piece of text as a response, given the user input. Our framework is compatible with both open-source and proprietary LLMs. We report the significance scores of the approximated explanations from our generic explainer in both English and German QA tasks and also study their correlation with the downstream performance of LLMs. In the extensive user studies, our explainer yields an F1-score of 76.9\% against the end user annotations and attains almost on-par performance with model-intrinsic approaches.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Sudhi, Viju and Bhat, Sinchana Ramakanth and Rudat, Max and Teucher, Roman},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {explainability, large language models, retrieval augmented generation},
	pages = {2776--2780},
}

@inproceedings{lin_raccoon_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{RACCOON}: {A} {Retrieval}-{Augmented} {Generation} {Approach} for {Location} {Coordinate} {Capture} from {News} {Articles}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715501},
	doi = {10.1145/3701716.3715501},
	abstract = {Geocoding involves automatic extraction of location coordinates of incidents reported in news articles, and can be used for epidemic intelligence or disaster management. This paper introduces Retrieval-Augmented Coordinate Capture Of Online News articles (RACCOON), an open-source geocoding approach that extracts geolocations from news articles. RACCOON uses a retrieval-augmented generation (RAG) approach where candidate locations and associated information are retrieved in the form of context from a location database, and a prompt containing the retrieved context, location mentions and news articles is fed to an LLM to generate the location coordinates. Our evaluation on three datasets, two underlying LLMs, three baselines and several ablation tests based on the components of RACCOON demonstrate the utility of RACCOON. To the best of our knowledge, RACCOON is the first RAG-based approach for geocoding using pre-trained LLMs.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Lin, Jonathan and Joshi, Aditya and Paik, Hye-young and Doung, Tri Dung and Gurdasani, Deepti},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {geocoding, large language models, location extraction, news articles, rag, retrieval-augmented generation},
	pages = {1123--1127},
}

@inproceedings{xu_retrieval-augmented_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Retrieval-{Augmented} {Generation} with {Knowledge} {Graphs} for {Customer} {Service} {Question} {Answering}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3661370},
	doi = {10.1145/3626772.3661370},
	abstract = {In customer service technical support, swiftly and accurately retrieving relevant past issues is critical for efficiently resolving customer inquiries. The conventional retrieval methods in retrieval-augmented generation (RAG) for large language models (LLMs) treat a large corpus of past issue tracking tickets as plain text, ignoring the crucial intra-issue structure and inter-issue relations, which limits performance. We introduce a novel customer service question-answering method that amalgamates RAG with a knowledge graph (KG). Our method constructs a KG from historical issues for use in retrieval, retaining the intra-issue structure and inter-issue relations. During the question-answering phase, our method parses consumer queries and retrieves related sub-graphs from the KG to generate answers. This integration of a KG not only improves retrieval accuracy by preserving customer service structure information but also enhances answering quality by mitigating the effects of text segmentation. Empirical assessments on our benchmark datasets, utilizing key retrieval (MRR, Recall@K, NDCG@K) and text generation (BLEU, ROUGE, METEOR) metrics, reveal that our method outperforms the baseline by 77.6\% in MRR and by 0.32 in BLEU. Our method has been deployed within LinkedIn's customer service team for approximately six months and has reduced the median per-issue resolution time by 28.6\%.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Xu, Zhentao and Cruz, Mark Jerome and Guevara, Matthew and Wang, Tie and Deshpande, Manasi and Wang, Xiaofeng and Li, Zheng},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {knowledge graph, large language model, question answering, retrieval-augmented generation},
	pages = {2905--2909},
}

@inproceedings{kaiser_preference-based_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Preference-based {Learning} with {Retrieval} {Augmented} {Generation} for {Conversational} {Question} {Answering}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715544},
	doi = {10.1145/3701716.3715544},
	abstract = {Conversational Question Answering (ConvQA) involves multiple subtasks, i) to understand incomplete questions in their context, ii) to retrieve relevant information, and iii) to generate answers. This work presents PRAISE, a pipeline-based approach for ConvQA that trains LLM adapters for each of the three subtasks. As labeled training data for individual subtasks is unavailable in practice, PRAISE learns from its own generations using the final answering performance as feedback signal without human intervention and treats intermediate information, like relevant evidence, as weakly labeled data. We apply Direct Preference Optimization by contrasting successful and unsuccessful samples for each subtask. In our experiments, we show the effectiveness of this training paradigm: PRAISE shows improvements per subtask and achieves new state-of-the-art performance on a popular ConvQA benchmark, by gaining 15.5 percentage points increase in precision over baselines.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Kaiser, Magdalena and Weikum, Gerhard},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {conversational question answering, preference-based learning, retrieval augmented generation},
	pages = {1053--1057},
}

@inproceedings{xu_rlg-rag_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{RLG}-{RAG}: {Guiding} the {Knowledge} {Retrieval} and {Evaluation} in {Retrieval}-{Augmented} {Generation} {Framework} by {Reasoning} {Logic}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715554},
	doi = {10.1145/3701716.3715554},
	abstract = {The knowledge retrieval, integration, and evaluation processes in the RAG method lack the guidance of reasoning logic, leading to ongoing challenges in maintaining factual consistency. To address these issues, this paper proposes the RLG-RAG framework, which constructs a reasoning graph based on user queries to guide the knowledge retrieval, integration, and evaluation processes. By fully representing the reasoning logic of RAG, RLG-RAG dynamically models and integrates knowledge relationships during retrieval and defines a precise scope of relevant knowledge through sufficiency evaluation. This reduces inference-irrelevant knowledge that large language models may obtain. Experimental analyses on accuracy, factual consistency, and robustness demonstrate that RLG-RAG resists interference and provides accurate, factually consistent answers. The project URL is https://doi.org/10.5281/zenodo.14852250.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Xu, Kehan and Zhang, Kun and Huang, Wei and Li, Jingyuan and Wang, Yuanzhuo},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {knowledge evaluation, knowledge retrieval, reasoning graph, retrieval-augmented generation},
	pages = {1450--1454},
}

@inproceedings{yang_cascadercg_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{CascadeRCG}: {Retrieval}-{Augmented} {Generation} for {Enhancing} {Professionalism} and {Knowledgeability} in {Online} {Mental} {Health} {Support}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715466},
	doi = {10.1145/3701716.3715466},
	abstract = {Online mental health support(OMHS) plays a crucial role in promoting well-being, but the shortage of mental health professionals necessitates automated systems to address complex care needs. While large language models (LLMs) are widely adopted, they often fall short in OMHS settings due to the complexity and ambiguity of the questions posed. Additionally, providing accurate answers requires extensive knowledge, which LLMs may lack, leading to responses that often lack depth, professionalism, and critical detail. To address these limitations, we introduce a new task tailored to OMHS scenarios, focusing on enhancing the professionalism and knowledgeability of generated responses. Furthermore, we propose a comprehensive benchmark designed to systematically evaluate the quality of responses. Building on these foundations, we propose the CascadeRCG framework, an optimized approach based on Retrieval-Augmented Generation (RAG). This framework first employs a knowledge management strategy, then introduces a two-stage cross-iterative Retrieval mechanism and a Clustering-then-summarizing module, followed by the final Generation stage. Experimental results on both single-turn and multi-turn psychological dialogue datasets, compared to other RAG-based baselines across different LLMs, show significant improvements in response professionalism and knowledge depth. This enhancement in response quality provides an effective methodology and strategy for further improving OMHS systems. Our code is available at https://github.com/CAS-SIAT-XinHai/CascadeRCG.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Yang, Di and Zhu, Jingwei and Wu, Haihong and Tan, Minghuan and Li, Chengming and Yang, Min},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {LLM, NLP, online mental health support, RAG},
	pages = {1465--1469},
}

@inproceedings{zhou_navigating_2025,
	address = {New York, NY, USA},
	series = {{CHIWORK} '25 {Adjunct}},
	title = {Navigating {Generative} {AI} {Disclosure}, {Ownership}, and {Accountability} in {Co}-{Creative} {Domains}},
	isbn = {979-8-4007-1397-2},
	url = {https://doi.org/10.1145/3707640.3729212},
	doi = {10.1145/3707640.3729212},
	abstract = {The increasing integration of generative AI into work has amplified issues of disclosure, ownership, and accountability, including whether and how to acknowledge AI use, who owns AI-generated or co-created work, and who is accountable for risks. In response, governments, organizations, and researchers are introducing new policies, guidelines, and methods for enhanced transparency. However, the complex interplay between multiple stakeholders and technologies, coupled with growing AI agency, continues to spark debates about ownership and accountability of co-created work, leading to open questions about whether, when, and how to disclose and attribute human-AI co-created work. To address these emergent issues, this workshop aims to gather interdisciplinary researchers, practitioners, and experts to discuss key questions from law, technology, design, and HCI research standpoints, with the ultimate goal of promoting responsible generative AI use for work.},
	booktitle = {Adjunct {Proceedings} of the 4th {Annual} {Symposium} on {Human}-{Computer} {Interaction} for {Work}},
	publisher = {Association for Computing Machinery},
	author = {Zhou, Yujia and Ji, Wei and Ge, Xuri and Ai, Qingyao and Jose, Joemon M. and Liu, Yiqun and Do, Hyo Jin and Feldman, Molly Q and He, Jessica and Hwang, Angel Hsing-Chi and Kim, Seyun},
	year = {2025},
	keywords = {Accountability, Attribution, Authorship, Co-creation, Disclosure, Generative AI, Ownership, Responsibility},
	pages = {4176--4179},
}

@inproceedings{siro_llm4eval_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{LLM4Eval}: {Large} {Language} {Model} for {Evaluation} in {IR}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730367},
	doi = {10.1145/3726302.3730367},
	abstract = {Large language models (LLMs) have demonstrated increasing task-solving abilities not present in smaller models. Utilizing the capabilities and responsibilities of LLMs for automated evaluation (LLM4Eval) has recently attracted considerable attention in multiple research communities. Building on the success of previous workshops, which established foundations in automated judgments and RAG evaluation, this third iteration aims to address emerging challenges as IR systems become increasingly personalized and interactive. The main goal of the third LLM4Eval workshop is to bring together researchers from industry and academia to explore three critical areas: the evaluation of personalized IR systems while maintaining fairness, the boundaries between automated and human assessment in subjective scenarios, and evaluation methodologies for systems that combine multiple IR paradigms (search, recommendations, and dialogue). By examining these challenges, we seek to understand how evaluation approaches can evolve to match the sophistication of modern IR applications. The format of the workshop is interactive, including roundtable discussion sessions, fostering dialogue about the future of IR evaluation while avoiding one-sided discussions. This is the third iteration of the workshop series, following successful events at SIGIR 2024 and WSDM 2025, with the first iteration attracting over 50 participants.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Siro, Clemencia and Rahmani, Hossein A. and Aliannejadi, Mohammad and Craswell, Nick and Clarke, Charles L. A. and Faggioli, Guglielmo and Mitra, Bhaskar and Thomas, Paul and Yilmaz, Emine},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {automated evaluation, generative models, large language models},
	pages = {4188--4191},
}

@inproceedings{huang_paracoder_2025,
	address = {New York, NY, USA},
	series = {{FCPC} '25},
	title = {{ParaCoder}: {Parallel} {Code} {Generation} with {Large} {Language} {Model}},
	isbn = {979-8-4007-1446-7},
	url = {https://doi.org/10.1145/3711708.3723442},
	doi = {10.1145/3711708.3723442},
	abstract = {High-performance parallel code generation is a complex and fascinating area in computer science that focuses on producing code that executes as quickly and efficiently as possible. In our paper, we designed a new architecture for parallel code generation agent with 4 inter-connected components of LLM—Memory, Planning, Tools and Action. It also incooperated with two techniques: data augmentation, prompting and retrieval-augmented editing to improve the performance of the parallel codes. Data augmentation is implemented by extracting and processing PIE dataset, and also synthesis dataset generated by LLM models with ParEval benchmark. Finally planning-oriented prompting, code verification and retrieval augmented editing are used to promote the actual performance of the LLM generated code. The evaluation results confirm that a rough speedup of 6.06X and 5.13X are achieved using Qwen2.5-Coder-7B-Instruct, Qwen2.5-Coder-14B-Instruct LLM models.},
	booktitle = {Proceedings of the 1st {FastCode} {Programming} {Challenge}},
	publisher = {Association for Computing Machinery},
	author = {Huang, Xiaowen and Zhang, Xu and Tao, Lvfang and Mao, Renjie and Zhou, Nan and Zhu, Wenxi and Deng, Minwen and Meng, Jintao and Wei, Yanjie and Zhou, Amelie Chi and Wang, Bingqiang and Feng, Shengzhong},
	year = {2025},
	note = {event-place: The Westin Las Vegas Hotel \&amp; Spa, Las Vegas, NV, USA},
	keywords = {code generation, LLM, parallelization},
	pages = {1--7},
}

@inproceedings{rahmani_llm4eval_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {{LLM4Eval}: {Large} {Language} {Model} for {Evaluation} in {IR}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657992},
	doi = {10.1145/3626772.3657992},
	abstract = {Large language models (LLMs) have demonstrated increasing task-solving abilities not present in smaller models. Utilizing the capabilities and responsibilities of LLMs for automated evaluation (LLM4Eval) has recently attracted considerable attention in multiple research communities. For instance, LLM4Eval models have been studied in the context of automated judgments, natural language generation, and retrieval augmented generation systems. We believe that the information retrieval community can significantly contribute to this growing research area by designing, implementing, analyzing, and evaluating various aspects of LLMs with applications to LLM4Eval tasks. The main goal of LLM4Eval workshop is to bring together researchers from industry and academia to discuss various aspects of LLMs for evaluation in information retrieval, including automated judgments, retrieval-augmented generation pipeline evaluation, altering human evaluation, robustness, and trustworthiness of LLMs for evaluation in addition to their impact on real-world applications. We also plan to run an automated judgment challenge prior to the workshop, where participants will be asked to generate labels for a given dataset while maximising correlation with human judgments. The format of the workshop is interactive, including roundtable and keynote sessions and tends to avoid the one-sided dialogue of a mini-conference.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Rahmani, Hossein A. and Siro, Clemencia and Aliannejadi, Mohammad and Craswell, Nick and Clarke, Charles L. A. and Faggioli, Guglielmo and Mitra, Bhaskar and Thomas, Paul and Yilmaz, Emine},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {automated evaluation, generative models, large language models},
	pages = {3040--3043},
}

@inproceedings{vizgirda_socialgenpod_2024,
	address = {New York, NY, USA},
	series = {{WWW} '24},
	title = {{SocialGenPod}: {Privacy}-{Friendly} {Generative} {AI} {Social} {Web} {Applications} with {Decentralised} {Personal} {Data} {Stores}},
	isbn = {979-8-4007-0172-6},
	url = {https://doi.org/10.1145/3589335.3651251},
	doi = {10.1145/3589335.3651251},
	abstract = {We present SocialGenPod, a decentralised and privacy-friendly way of deploying generative AI Web applications. Unlike centralised Web and data architectures that keep user data tied to application and service providers, we show how one can use Solid - a decentralised Web specification - to decouple user data from generative AI applications. We demonstrate SocialGenPod using a prototype that allows users to converse with different Large Language Models, optionally leveraging Retrieval Augmented Generation to generate answers grounded in private documents stored in any Solid Pod that the user is allowed to access, directly or indirectly. SocialGenPod makes use of Solid access control mechanisms to give users full control of determining who has access to data stored in their Pods. SocialGenPod keeps all user data (chat history, app configuration, personal documents, etc) securely in the user's personal Pod; separate from specific model or application providers. Besides better privacy controls, this approach also enables portability across different services and applications. Finally, we discuss challenges, posed by the large compute requirements of state-of-the-art models, that future research in this area should address. Our prototype is open-source and available at: https://github.com/Vidminas/socialgenpod/.},
	booktitle = {Companion {Proceedings} of the {ACM} {Web} {Conference} 2024},
	publisher = {Association for Computing Machinery},
	author = {Vizgirda, Vidminas and Zhao, Rui and Goel, Naman},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	keywords = {decentralised web, privacy, retrieval augmented generation, solid},
	pages = {1067--1070},
}

@inproceedings{zhou_img2loc_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {{Img2Loc}: {Revisiting} {Image} {Geolocalization} using {Multi}-modality {Foundation} {Models} and {Image}-based {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657673},
	doi = {10.1145/3626772.3657673},
	abstract = {Geolocating precise locations from images presents a challenging problem in computer vision and information retrieval. Traditional methods typically employ either classification-dividing the Earth's surface into grid cells and classifying images accordingly, or retrieval-identifying locations by matching images with a database of image-location pairs. However, classification-based approaches are limited by the cell size and cannot yield precise predictions, while retrieval-based systems usually suffer from poor search quality and inadequate coverage of the global landscape at varied scale and aggregation levels. To overcome these drawbacks, we present Img2Loc, a novel system that redefines image geolocalization as a text generation task. This is achieved using cutting-edge large multi-modality models (LMMs) like GPT-4V or LLaVA with retrieval augmented generation. Img2Loc first employs CLIP-based representations to generate an image-based coordinate query database. It then uniquely combines query results with images itself, forming elaborate prompts customized for LMMs. When tested on benchmark datasets such as Im2GPS3k and YFCC4k, Img2Loc not only surpasses the performance of previous state-of-the-art models but does so without any model training. A video demonstration of the system can be accessed via this link https://drive.google.com/file/d/16A6A-mc7AyUoKHRH3\_WBRToRC13sn7tU/view?usp=sharing},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zhou, Zhongliang and Zhang, Jielu and Guan, Zihan and Hu, Mengxuan and Lao, Ni and Mu, Lan and Li, Sheng and Mai, Gengchen},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {image localization, large multi-modality models, vector database},
	pages = {2749--2754},
}

@inproceedings{frobe_large_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Large {Language} {Model} {Relevance} {Assessors} {Agree} {With} {One} {Another} {More} {Than} {With} {Human} {Assessors}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730218},
	doi = {10.1145/3726302.3730218},
	abstract = {Relevance judgments can differ between assessors, but previous work has shown that such disagreements have little impact on the effectiveness rankings of retrieval systems. This applies to disagreements between humans as well as between human and large language model (LLM) assessors. However, the agreement between different LLM assessors has not yet been systematically investigated. To close this gap, we compare eight LLM assessors on the TREC DL tracks and the retrieval task of the RAG track with each other and with human assessors. We find that the agreement between LLM assessors is higher than between LLMs and humans and, importantly, that LLM assessors favor retrieval systems that use LLMs in their ranking decisions: our analyses with 30-50 retrieval systems show that the system rankings obtained by LLM assessors overestimate LLM-based re-rankers by 9 to 17 positions on average.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Fröbe, Maik and Parry, Andrew and Schlatt, Ferdinand and MacAvaney, Sean and Stein, Benno and Potthast, Martin and Hagen, Matthias},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {inter-annotator agreement, ir evaluation, reproducibility},
	pages = {2858--2863},
}

@inproceedings{zhu_finir_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{FinIR}: {The} 2nd {Workshop} on {Financial} {Information} {Retrieval} in the {Era} of {Generative} {AI}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730366},
	doi = {10.1145/3726302.3730366},
	abstract = {Recent advancements in Generative AI, such as Large Language Models (LLMs), have demonstrated remarkable success across various general tasks. Extensive studies have explored leveraging generative models in finance, but significant challenges persist. This half-day workshop explores potential approaches and research directions to address these challenges by equipping generative models with advanced Information Retrieval (IR) models. Specifically, this workshop seeks to provide a platform for discussing innovative ideas that facilitate the advancement of IR technology to enrich generative models in finance from four key perspectives: (i) financial IR techniques (ii) financial IR benchmarking and evaluation (iii) financial systems and agents/assistants (iv) and trustworthiness, privacy and security when applying financial IR and generative models. This workshop aims to deepen understanding, accelerate progress, and support the advancement of IR technology to enhance generative models to address financial challenges.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zhu, Fengbin and Ma, Yunshan and Feng, Fuli and Wang, Chao and Luan, Huanbo and Ye, Guangnan and Zhang, Shuo and Mehta, Dhagash and Chen, Pingping and Xiang, Bing and Chua, Tat-Seng},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {bing xiang, chao wang, dhagash mehta, fengbin zhu, fuli feng, guangnan ye, huanbo luan, pingping chen, shuo zhang, tat-seng chua, yunshan ma},
	pages = {4184--4187},
}

@inproceedings{lajewska_ginger_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{GINGER}: {Grounded} {Information} {Nugget}-{Based} {Generation} of {Responses}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730166},
	doi = {10.1145/3726302.3730166},
	abstract = {Retrieval-augmented generation (RAG) faces challenges related to factual correctness, source attribution, and response completeness. To address them, we propose a modular pipeline for grounded response generation that operates on information nuggets - minimal, atomic units of relevant information extracted from retrieved documents. The multistage pipeline encompasses nugget detection, clustering, ranking, top cluster summarization, and fluency enhancement. It guarantees grounding in specific facts, facilitates source attribution, and ensures maximum information inclusion within length constraints. Experiments on the TREC RAG'24 dataset, using the AutoNuggetizer framework, demonstrate that GINGER achieves state-of-the-art performance on this benchmark.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Łajewska, Weronika and Balog, Krisztian},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {grounding, retrieval-augmented generation, source attribution},
	pages = {2723--2727},
}

@inproceedings{rogers_what_2024,
	address = {New York, NY, USA},
	series = {{HRI} '24},
	title = {What {Should} a {Robot} {Do}? {Comparing} {Human} and {Large} {Language} {Model} {Recommendations} for {Robot} {Deception}},
	isbn = {979-8-4007-0323-2},
	url = {https://doi.org/10.1145/3610978.3640752},
	doi = {10.1145/3610978.3640752},
	abstract = {This study compares human ethical judgments with Large Language Models (LLMs) on robotic deception in various scenarios. Surveying human participants and querying LLMs, we presented ethical dilemmas in high-risk and low-risk contexts. Findings reveal alignment between humans and LLMs in high-risk scenarios, prioritizing safety, but notable divergences in low-risk situations, reflecting challenges in AI development to accurately capture human social nuances and moral expectations.},
	booktitle = {Companion of the 2024 {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Rogers, Kantwon and Webber, Reiden John Allen and Gorostiaga Zubizarreta, Geronimo and Melo Cruz, Arthur and Chen, Shengkang and Arkin, Ronald C. and Borenstein, Jason and Wagner, Alan R.},
	year = {2024},
	note = {event-place: Boulder, CO, USA},
	keywords = {deception, ethical dilemmas, human-robot interaction, LLM},
	pages = {906--910},
}

@inproceedings{thakur_assessing_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Assessing {Support} for the {TREC} 2024 {RAG} {Track}: {A} {Large}-{Scale} {Comparative} {Study} of {LLM} and {Human} {Evaluations}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730165},
	doi = {10.1145/3726302.3730165},
	abstract = {Retrieval-augmented generation (RAG) enables large language models (LLMs) to generate answers with citations from source documents containing ”ground truth”. A crucial factor in RAG evaluation is ”support”, or whether the information in the cited documents supports the answer. We conducted a comparative study of submissions to the TREC 2024 RAG Track, evaluating an automatic LLM judge (GPT-4o) against human judges for support assessment. We considered two conditions: (1) fully manual assessments from scratch and (2) manual assessments with post-editing of LLM predictions. Our results indicate good agreement between human and GPT-4o predictions. Further analysis of the disagreements shows that an independent human judge correlates better with GPT-4o than a human judge, suggesting that LLM judges can be a reliable alternative for support assessment. We provide a qualitative analysis of human and GPT-4o errors to help guide future evaluations.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Thakur, Nandan and Pradeep, Ronak and Upadhyay, Shivani and Campos, Daniel and Craswell, Nick and Soboroff, Ian and Dang, Hoa Trang and Lin, Jimmy},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {llm judge, retrieval-augmented generation, support evaluation},
	pages = {2759--2763},
}

@inproceedings{belikova_data-efficient_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Data-efficient {Meta}-models for {Evaluation} of {Context}-based {Questions} and {Answers} in {LLMs}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3731969},
	doi = {10.1145/3726302.3731969},
	abstract = {Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems are increasingly deployed in industry applications, yet their reliability remains hampered by challenges in detecting hallucinations. While supervised state-of-the-art (SOTA) methods that leverage LLM hidden states-such as activation tracing and representation analysis-show promise, their dependence on extensively annotated datasets limits scalability in real-world applications. This paper addresses the critical bottleneck of data annotation by investigating the feasibility of reducing training data requirements for two SOTA hallucination detection frameworks: Lookback Lens, which analyzes attention head dynamics, and probing-based approaches, which decode internal model representations. We propose a methodology combining efficient classification algorithms with dimensionality reduction techniques to minimize sample size demands while maintaining competitive performance. Evaluations on standardized question-answering RAG benchmarks show that our approach achieves performance comparable to strong proprietary LLM-based baselines with only 250 training samples. These results highlight the potential of lightweight, data-efficient paradigms for industrial deployment, particularly in annotation-constrained scenarios.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Belikova, Julia and Polev, Konstantin and Parchiev, Rauf and Simakov, Dmitry},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {data efficiency, hallucination detection, model probing, question-answering, retrieval-augmented generation},
	pages = {4385--4389},
}

@inproceedings{arabzadeh_ir-rag_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{IR}-{RAG} @{SIGIR25}: {The} {Second} {Edition} of the {Workshop} on {Information} {Retrieval}'s {Role} in {RAG} {Systems}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730362},
	doi = {10.1145/3726302.3730362},
	abstract = {In recent years, Retrieval-Augmented Generation (RAG) systems have become a cornerstone of artificial intelligence, attracting considerable attention in a variety of fields. By integrating the strengths of information retrieval and generative models, these systems have shown immense potential to push the boundaries of machine learning applications. Nevertheless, RAG systems still face significant challenges and offer ample room for advancement and innovation.This workshop aims to highlight the central role of information retrieval within RAG frameworks, which we believe has often been overshadowed by the emphasis on the generative components. While the generative models are integral to these systems, the quality and effectiveness of the retrieval mechanism is equally critical, as it has a direct impact on the overall system performance and outcomes. We invite papers that rethink and prioritise the fundamental aspects of RAG systems, particularly in strengthening the information retrieval component. Through this workshop, we aim to gain deeper insights into how improved retrieval methods can enhance the performance and reliability of RAG systems. The event will bring together leading experts, researchers and practitioners to provide a collaborative platform for exchanging ideas, sharing results and fostering innovation. Our aim is to stimulate research and discussion that reaffirms the essential role of information retrieval in shaping the next generation of generative systems.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Arabzadeh, Negar and Chen, Ziheng and Petroni, Fabio and Siciliano, Federico and Silvestri, Fabrizio and Trappolini, Giovanni},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {generative models, neural databases, retrieval augmented generation},
	pages = {4168--4171},
}

@inproceedings{azimi_towards_2025,
	address = {New York, NY, USA},
	series = {{MHV} '25},
	title = {Towards an {Energy}-{Efficient} {Video} {Processing} {Tool} with {LLMs}},
	isbn = {979-8-4007-1488-7},
	url = {https://doi.org/10.1145/3715675.3715835},
	doi = {10.1145/3715675.3715835},
	abstract = {Large language models (LLMs), the backbone of generative artificial intelligence (AI) like ChatGPT, have become more widely integrated in different fields, including multimedia. The rising number of conversational queries on such platforms now emits as much CO2 as everyday activities, leading to an exponential growth of energy consumption and underscoring urgent sustainability challenges. This short paper introduces an energy-aware LLM-based video processing tool. Employing open-source LLM models and techniques like fine-tuning and Retrieval-Augmented Generation (RAG), this tool recommends video processing commands and executes them in an energy-aware manner. Preliminary results show that it achieves reduced energy consumption per prompt compared to baselines.},
	booktitle = {Proceedings of the 4th {Mile}-{High} {Video} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Azimi, Zoha and Farahani, Reza and Timmerer, Christian and Prodan, Radu},
	year = {2025},
	note = {event-place: Denver, CO, USA},
	keywords = {Energy Efficiency, FFmpeg, LLM, Retrieval-Augmented Generation, Video Processing},
	pages = {89--90},
}

@inproceedings{avula_measuring_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Measuring the {Fairness} {Gap} {Between} {Retrieval} and {Generation} in {RAG} {Systems} using a {Cognitive} {Complexity} {Framework}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730230},
	doi = {10.1145/3726302.3730230},
	abstract = {In this paper, we investigate the problem of quantifying fairness in Retrieval-Augmented Generation (RAG) systems, particularly for complex cognitive tasks that go beyond factual question-answering. While RAG systems have demonstrated effectiveness in information extraction tasks, their fairness implications for cognitively complex tasks - including ideation, content creation, and analytical reasoning - remain under-explored. We propose a novel evaluation framework that extends IR fairness metrics by incorporating centrality-based measures to account for influence of retrieved documents on generated output beyond ranking. Our framework evaluates RAG systems across various cognitive dimensions using two ranking approaches: lexical (BM25) and dense (BGE), and language models of varying sizes. Our findings provide insights into: (1) the propagation of fairness disparities from retrieval to generation phases, and (2) the variation in system performance across different cognitive dimensions.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Avula, Sandeep and Lee, Chia-Jung and Zhang, Rongting and Murdock, Vanessa},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {fairness, information retrieval, rag, retrieval augmented generation},
	pages = {2994--2998},
}

@inproceedings{li_neutronrag_2025,
	address = {New York, NY, USA},
	series = {{SIGMOD}/{PODS} '25},
	title = {{NeutronRAG}: {Towards} {Understanding} the {Effectiveness} of {RAG} from a {Data} {Retrieval} {Perspective}},
	isbn = {979-8-4007-1564-8},
	url = {https://doi.org/10.1145/3722212.3725119},
	doi = {10.1145/3722212.3725119},
	abstract = {Retrieval-Augmented Generation (RAG) has been widely used to enhance the generation quality of large language models (LLMs), particularly in domain-specific tasks. As application requirements become increasingly diverse, various RAG methods have been proposed to optimize the retrieval and generation quality of different task scenarios, such as VectorRAG, GraphRAG, and HybridRAG. However, RAG faces two key challenges in these retrieval methods: evaluating different retrieval methods and optimizing parameter configurations. First, different retrieval methods show different performances. How to uniformly compare and analyze the advantages and disadvantages of these retrieval methods remains an open research problem. Second, the effectiveness of RAG is highly sensitive to key parameter configurations. Optimizing these parameters is challenging due to the complexity of the parameter space and the difficulty in identifying the sources of errors in the generated responses. Existing RAG tools typically use a single retrieval method, lacking analytical capabilities and multi-strategy support. To address these challenges, we introduce NeutronRAG, a demonstration of understanding the effectiveness of RAG from a data retrieval perspective. NeutronRAG supports hybrid retrieval strategies and helps researchers iteratively refine RAG configuration to improve retrieval and generation quality through systematic analysis, visual feedback, and parameter adjustment advice. It facilitates data-driven decisions to enhance LLM generation quality while exploring effective retrieval strategies in RAG systems. The web app is available at: https://github.com/iDC-NEU/NeutronRAG.},
	booktitle = {Companion of the 2025 {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {Li, Peizheng and Chen, Chaoyi and Yuan, Hao and Fu, Zhenbo and Shen, Hang and Yang, Xinbo and Wang, Qiange and Ai, Xin and Zhang, Yanfeng and Wen, Yingyou and Yu, Ge},
	year = {2025},
	note = {event-place: Berlin, Germany},
	keywords = {GraphRAG, HybridRAG, retrieval-augmented generation, VectorRAG},
	pages = {163--166},
}

@inproceedings{lee_rag-enhanced_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{RAG}-{Enhanced} {Evidence} {Recommendation} in {Financial} {Legal} {Resolutions}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715520},
	doi = {10.1145/3701716.3715520},
	abstract = {The complexity of legal documents, particularly in financial legal disputes, poses significant challenges for both experts and automated systems. This study introduces a system leveraging Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) technology to recommend key evidence in financial advisor dispute cases. Unlike traditional legal AI tasks focused on outcome prediction, our approach emphasizes supporting judicial reasoning by recommending key evidence relevant to adjudication. We constructed a dataset of 371 annotated cases from Taiwan, spanning 25 years, including claims, judicial opinions, and final judgments, with annotations highlighting key evidence. Using RAG, our system retrieves and generates evidence recommendations grounded in analogous past cases while maintaining temporal and contextual consistency. This methodology enhances judicial efficiency and supports equitable legal decision-making by streamlining the recommendation of critical evidence.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Lee, Hsiu-Hung and Chen, Chung-Chi and Yen, An-Zi},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {evidence recommendation, financial advisory, retrieval augmented generation},
	pages = {1096--1099},
}

@inproceedings{jokinen_exploring_2024,
	address = {New York, NY, USA},
	series = {{HRI} '24},
	title = {Exploring a {Japanese} {Cooking} {Database}},
	isbn = {979-8-4007-0323-2},
	url = {https://doi.org/10.1145/3610978.3640622},
	doi = {10.1145/3610978.3640622},
	abstract = {The paper describes ongoing work applying Generative AI to a real world application. We use Retrieval Augmented Generation and other GenAI tools that combine large language models with Neo4j knowledge graphs. These tools help a robot to chat in English about Japanese cooking using a knowledge base that is in Japanese.},
	booktitle = {Companion of the 2024 {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Jokinen, Kristiina and Wilcock, Graham},
	year = {2024},
	note = {event-place: Boulder, CO, USA},
	keywords = {cypher query language, generative AI, graph databases, Japanese cooking, knowledge graphs, large language models, retrieval augmented generation, semantic search, social robots},
	pages = {578--582},
}

@inproceedings{petroni_ir-rag_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {{IR}-{RAG} @ {SIGIR24}: {Information} {Retrieval}'s {Role} in {RAG} {Systems}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657984},
	doi = {10.1145/3626772.3657984},
	abstract = {In recent years, Retrieval Augmented Generation (RAG) systems have emerged as a pivotal component in the field of artificial intelligence, gaining significant attention and importance across various domains. These systems, which combine the strengths of information retrieval and generative models, have shown promise in enhancing the capabilities and performance of machine learning applications. However, despite their growing prominence, RAG systems are not without their limitations and continue to be in need of exploration and improvement. This workshop seeks to focus on the critical aspect of information retrieval and its integral role within RAG frameworks. We argue that current efforts have undervalued the role of Information Retrieval (IR) in the RAG and have concentrated their attention on the generative part. As the cornerstone of these systems, IR's effectiveness dramatically influences the overall performance and outcomes of RAG models. We call for papers that will seek to revisit and emphasize the fundamental principles underpinning RAG systems. At the end of the workshop, we aim to have a clearer understanding of how robust information retrieval mechanisms can significantly enhance the capabilities of RAG systems. The workshop will serve as a platform for experts, researchers, and practitioners. We intend to foster discussions, share insights, and encourage research that underscores the vital role of Information Retrieval in the future of generative systems.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Petroni, Fabio and Siciliano, Federico and Silvestri, Fabrizio and Trappolini, Giovanni},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {generative models, neural databases, retrieval augmented generation},
	pages = {3036--3039},
}

@inproceedings{alrabie_towards_2025,
	address = {New York, NY, USA},
	series = {{CHItaly} '25},
	title = {Towards {Human}-{Centered} {RAG}: {A} {Study} of {AI}-{Supported} {Testing} {Practices} in {Italian} {Public} {Administration}},
	isbn = {979-8-4007-2102-1},
	url = {https://doi.org/10.1145/3750069.3750103},
	doi = {10.1145/3750069.3750103},
	abstract = {This study examines the integration of a Retrieval-Augmented Generation (RAG)–based AI testing assistant within an Italian public administration, focusing on its practical benefits and challenges. Qualitative feedback from 15 software testers reveals that while the assistant improves testing efficiency and supports knowledge retrieval, challenges regarding accuracy, consistency, and transparency reduce user trust and effectiveness. Participants highlighted the need for enhanced data curation, improved interaction, and finer-grained control over the system, indicating areas for future improvements to the assistant and its surrounding workflows. The findings emphasize the importance of adopting a human-centered approach in the design and integration of AI solutions in the public sector, offering valuable insights for the ongoing development of human-centered RAG research.},
	booktitle = {Proceedings of the 16th {Biannual} {Conference} of the {Italian} {SIGCHI} {Chapter}},
	publisher = {Association for Computing Machinery},
	author = {Alrabie, Lina and Andolina, Salvatore},
	year = {2025},
	keywords = {Artificial intelligence, HCAI, Human-centered AI, Large Language Models, LLM, Retrieval Augmented Generation, Software testing},
}

@inproceedings{yang_explaingen_2025,
	address = {New York, NY, USA},
	series = {{HumanSys} '25},
	title = {{ExplainGen}: a {Human}-{Centered} {LLM} {Assistant} for {Combating} {Misinformation}},
	isbn = {979-8-4007-1609-6},
	url = {https://doi.org/10.1145/3722570.3726897},
	doi = {10.1145/3722570.3726897},
	abstract = {While LLMs show promise in identifying misinformation, they often struggle with context-dependent cases and may even reinforce falsehoods due to biases in their training data. Instead of making final decisions on misinformation, we propose leveraging LLMs as human-centered assistants to generate context-based explanations that support human judgment in combating misinformation. This paper introduces ExplainGen, an LLM-based web app designed to provide fact-grounded explanations for assessing the credibility of statements. Due to limited transparency in LLM training data and the scarcity of high-quality fact-checking datasets, we scrape data from various domains and combine them with publicly available fact-checking instructions to fine-tune ExplainGen. Our evaluation shows that ExplainGen generates well-supported explanations that outperform the baseline models. As future work, we plan to conduct survey-based experiments to evaluate the effectiveness of ExplainGen for human decision-making, and incorporate retrieval-augmented generation (RAG) to reduce hallucinations of ExplainGen LLM. Our source code and datasets are available on our GitHub page: https://github.com/Accuracy98/ExplainGen.},
	booktitle = {Proceedings of the 3rd {International} {Workshop} on {Human}-{Centered} {Sensing}, {Modeling}, and {Intelligent} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Yang, Zhicheng and Jia, Xinle and Jiang, Xiaopeng},
	year = {2025},
	note = {event-place: Irvine, CA, USA},
	keywords = {Human-centered Computing, Large Language Model, Misinformation},
	pages = {120--123},
}

@inproceedings{chu_chatasd_2024,
	address = {New York, NY, USA},
	series = {{BCB} '24},
	title = {{ChatASD}: {A} {Dialogue} {Framework} for {LLMs} {Enhanced} by {Autism} {Knowledge} {Graph} {Retrieval}},
	isbn = {979-8-4007-1302-6},
	url = {https://doi.org/10.1145/3698587.3701538},
	doi = {10.1145/3698587.3701538},
	abstract = {Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized by developmental delays, communication difficulties, repetitive behaviors, and restricted interests. Large Language Models (LLMs) have demonstrated exceptional capabilities in various natural language tasks, particularly in providing personalized question-and-answer(Q\&amp;A) services, making them well-suited for constructing dialogue engines for autism Q\&amp;A systems. However, general LLMs often lack integrated autism knowledge during training, limiting their professional competency in autism consultation. Additionally, the automatic evaluation of scientific accuracy in autism medical knowledge Q\&amp;A remains underexplored. To address this gap, we propose ChatASD, an autism knowledge Q\&amp;A framework based on Graph Retrieval-Augmented Generation (GraphRAG) technology. This framework leverages LLMs and retrieves relevant information from medical literature to generate an autism knowledge graph, employing a combination of global and community queries to produce reliable responses. Compared to traditional methods, ChatASD effectively addresses the sparse distribution of autism knowledge, providing more accurate and comprehensive answersAutomatic efficacy evaluations and competitive experiments on system responses indicate our approach significantly improves reliability of autism-related professional knowledge queries.},
	booktitle = {Proceedings of the 15th {ACM} {International} {Conference} on {Bioinformatics}, {Computational} {Biology} and {Health} {Informatics}},
	publisher = {Association for Computing Machinery},
	author = {Chu, Lei and Wu, Hongyan and Pan, Yi},
	year = {2024},
	note = {event-place: Shenzhen, China},
	keywords = {Autism, Knowledge Graph, LLM, Question-and-Answer System, Retrieval-Augmented Generation},
}

@inproceedings{bendel_animal_2024,
	address = {New York, NY, USA},
	series = {{ACI} '24},
	title = {The {Animal} {Whisperer} {Project}},
	isbn = {979-8-4007-1175-6},
	url = {https://doi.org/10.1145/3702336.3702347},
	doi = {10.1145/3702336.3702347},
	abstract = {Generative AI has become widespread since 2022. Technical advancements have resulted in multimodal large language models and other AI models that generate, analyze, and evaluate texts, images, and sounds. Such capabilities can be helpful in encounters between humans and animals. For example, apps with generative AI on a smartphone can be used to assess the body language and behavior of animals – e.g., during a walk or hike – and provide a recommendation for human behavior. It is often useful to take into account the animal's environment and situation. The apps can help people to avert approaches and attacks, and thus also protect animals. In “The Animal Whisperer Project”, three apps were developed as prototypes based on the multimodal large language model GPT-4 from OpenAI from the beginning to mid-2024. Three specific GPTs resulted: the Cow Whisperer, the Horse Whisperer, and the Dog Whisperer. All three showed impressive capabilities after the first prompt engineering. These were improved by implementing information from expert interviews and adding labeled images of animals and other materials. AI-based apps for interpreting body language, behavior, and the overall situation can apparently be created today, without much effort, in a low-budget project. However, turning them into products would certainly raise questions, such as liability in the event of accidents.},
	booktitle = {Proceedings of the {International} {Conference} on {Animal}-{Computer} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Bendel, Oliver and Zbinden, Nick},
	year = {2024},
	keywords = {Animal Body Language, Animal-Computer Interaction, Artificial Intelligence, Generative AI, GPT, Multimodal Large Language Model},
}

@inproceedings{sokol_ventana_2025,
	address = {New York, NY, USA},
	series = {{WSDM} '25},
	title = {Ventana a la {Verdad} ({Window} to the {Truth}): {A} {Chatbot} {Application} for {Navigating} {The} {Colombian} {Truth} {Commission}'s {Archives}},
	isbn = {979-8-4007-1329-3},
	url = {https://doi.org/10.1145/3701551.3704123},
	doi = {10.1145/3701551.3704123},
	abstract = {We present Ventana a la Verdad, a chatbot designed to make the Clar- ification Archive and the reports of the Colombian Truth Commis- sion [6] more accessible to a wider audience. These archives contain a wealth of documents, interviews, and testimonies from Colom- bia's armed conflict, but navigating them can be challenging due to their volume and complexity. Using existing large language models (LLMs) and natural language processing techniques, our chatbot allows users to interact with the archives through natural language queries, receiving relevant and contextually appropriate responses. In the sensitive context of peace and reconciliation, where misin- formation or hallucinations can have significant adverse effects, ensuring the accuracy and reliability of information is paramount. This tool aims to facilitate better understanding and engagement with historical content, supporting educational and research efforts. We discuss the development of the chatbot, the challenges encoun- tered, and its potential impact on making the Colombian Truth Commission's archives more accessible. The chatbot is available by link here: http://ventanaverdad.lucyapps.net:1337/},
	booktitle = {Proceedings of the {Eighteenth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Sokol, Anna and Sisk, Matthew L. and Alvarez, Josefina Echavarría and Chawla, Nitesh},
	year = {2025},
	note = {event-place: Hannover, Germany},
	keywords = {conversational ai, generative ai, large language models, retrieval-augmented generation},
	pages = {1052--1055},
}

@inproceedings{lu_taxonomy_2024,
	address = {New York, NY, USA},
	series = {{CAIN} '24},
	title = {A {Taxonomy} of {Foundation} {Model} based {Systems} through the {Lens} of {Software} {Architecture}},
	isbn = {979-8-4007-0591-5},
	url = {https://doi.org/10.1145/3644815.3644956},
	doi = {10.1145/3644815.3644956},
	abstract = {Large language model (LLM) based chatbots, such as ChatGPT, have attracted huge interest in foundation models. It is widely believed that foundation models will serve as the fundamental building blocks for future AI systems. However, the architecture design of foundation model based systems has not yet been systematically explored. There is limited understanding about the impact of introducing foundation models in software architecture. Therefore, in this paper, we propose a taxonomy of foundation model based systems, which classifies and compares the characteristics of foundation models and system design options. Our taxonomy comprises three categories: the pretraining and adaptation of foundation models, the architecture design of foundation model based systems, and responsible-AI-by-design. This taxonomy can serve as concrete guidance for designing foundation model based systems.},
	booktitle = {Proceedings of the {IEEE}/{ACM} 3rd {International} {Conference} on {AI} {Engineering} - {Software} {Engineering} for {AI}},
	publisher = {Association for Computing Machinery},
	author = {Lu, Qinghua and Zhu, Liming and Xu, Xiwei and Liu, Yue and Xing, Zhenchang and Whittle, Jon},
	year = {2024},
	note = {event-place: Lisbon, Portugal},
	keywords = {foundation model, generative AI, large language model, LLM, responsible AI, software architecture, taxonomy},
	pages = {1--6},
}

@inproceedings{chen_behaviorally_2025,
	address = {New York, NY, USA},
	series = {{MuC} '25},
	title = {Behaviorally {Aligned} {Retrieval}-{Augmented} {Chatbot} for {Industrial} {Design} {Thesis} {Support}},
	isbn = {979-8-4007-1582-2},
	url = {https://doi.org/10.1145/3743049.3748567},
	doi = {10.1145/3743049.3748567},
	abstract = {Retrieval-Augmented Generation (RAG) chatbots show promise in educational settings, yet their application in industrial design, with its iterative and reflective workflows, remains underexplored. This study investigates how master’s students in industrial design perceive the effectiveness of a RAG chatbot in supporting their graduation projects. We developed a chatbot prototype trained on 132 industrial design theses (2021–2023), employing semantic search, multimodal capabilities, and stage-specific guidance, and evaluated it through a mixed-methods approach involving a quantitative question-ranking task (n=7) and a qualitative focus group (n=4). Findings indicate strong performance for practical, early-stage queries but highlight issues with irrelevant corpus results, verbose outputs, and underused features, with five key themes emerging: corpus relevance, output reliability, interaction clarity, multimodal support, and experience-oriented learning. These results inform design guidelines for behaviorally aligned RAG chatbots, enhancing support for critical thinking and process navigation in industrial design education.},
	booktitle = {Proceedings of the {Mensch} {Und} {Computer} 2025},
	publisher = {Association for Computing Machinery},
	author = {Chen, Qiurui and Niforatos, Evangelos and Kortuem, Gerd},
	year = {2025},
	keywords = {Chatbot, Education, Human-Computer Interaction, Industrial Design, Retrieval-Augmented Generation},
	pages = {494--502},
}

@inproceedings{liu_treatrag_2025,
	address = {New York, NY, USA},
	series = {{RecSys} '25},
	title = {{TreatRAG}: {A} {Framework} for {Personalized} {Treatment} {Recommendation}},
	isbn = {979-8-4007-1364-4},
	url = {https://doi.org/10.1145/3705328.3748022},
	doi = {10.1145/3705328.3748022},
	abstract = {Medication recommendation is a critical function of clinical decision support systems, directly influencing patient safety and treatment efficacy. While large language models (LLMs) show promise in clinical tasks such as summarization and question answering, their ability to make accurate treatment predictions remains limited, in part, due to their lack of specialized medical knowledge and exposure to real-world patient data. We introduce TreatRAG, an interpretable, model-agnostic retrieval-augmented generation (RAG) framework aimed at early-stage development to enhance medication recommendation accuracy using publicly available clinical data; thus, TreatRAG forms a critical foundational step toward future clinical validation and domain expert involvement. TreatRAG retrieves similar patient cases, i.e., so called "digital twins", using interpretable N-gram Jaccard similarity and augments the input prompt to ground LLM predictions in real clinical scenarios. We evaluate our framework on the MIMIC-IV dataset using BioGPT, BioMistral, Phi3, and Flan-T5. TreatRAG-enhanced BioGPT improves its F1-score from 0.14 to 0.34, BioMistral from 0.22 to 0.54, Phi-3 from 0.09 to 0.16, and Flan-T5 from 0.23 to 0.30, while also lowering, often significantly, the hallucination rate. Our model-agnostic framework offers a flexible, effective, and interpretable solution to advance the reliability of LLMs in clinical decision support.},
	booktitle = {Proceedings of the {Nineteenth} {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Chao-Chin and Yao, Hao-Ren and Chang, Der-Chen and Frieder, Ophir},
	year = {2025},
	keywords = {Large Language Models, Medical Digital Twins, Medication Recommendation, Retrieval-Augmented Generation},
	pages = {690--695},
}

@inproceedings{zachariah_multi-model_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Multi-{Model} {Workflows} for {Advanced} {Visual} {Understanding}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715188},
	doi = {10.1145/3701716.3715188},
	abstract = {This paper introduces a novel task-agnostic system for visual question answering, designed to address the limitations of existing visual-language models in scenarios requiring fine-grained reasoning and contextual understanding. By integrating computer vision, natural language processing, and retrieval-augmented generation, the system dynamically selects models and interprets diverse visual inputs without necessitating task-specific retraining. It leverages scene graph extraction and a model multiplexer to process visual content contextually, while an instruction execution engine transforms multimodal data into actionable insights. The system emphasizes explainability through annotated outputs and textual responses, enhancing user trust and comprehension. Its modular design ensures scalability and adaptability, enabling seamless incorporation of new models and datasets for evolving applications. This work represents a significant step forward in visual question answering, offering a transparent and versatile solution tailored to real-world complexities. The complete source code can be found at https://github.com/NVIDIA/Multi-Model-Workflows.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Zachariah, Arun George and Praveen, Varun and Ochoa, Samuel and Sriram, Parthasarathy},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {ai systems, retrieval-augmented generation, visual question answering},
	pages = {2943--2946},
}

@inproceedings{portaz_harmonizing_2024,
	address = {New York, NY, USA},
	series = {{UMAP} {Adjunct} '24},
	title = {Harmonizing {Ethical} {Principles}: {Feedback} {Generation} {Approaches} in {Modeling} {Human} {Factors} for {Assisted} {Psychomotor} {Systems}},
	isbn = {979-8-4007-0466-6},
	url = {https://doi.org/10.1145/3631700.3664900},
	doi = {10.1145/3631700.3664900},
	abstract = {As the demand for personalized and adaptive learning experiences increase, there is a urgent need for providing effective feedback mechanisms within critical systems, such as in psychomotor learning systems. This proposal introduces an approach for the integration of retrieval-augmented generation tools to provide comprehensive and insightful feedback to users. By combining the strengths of retrieval-based techniques and generative models, these tools offer the potential to enhance learning outcomes by delivering tailored feedback that is both informative and engaging. The proposal also emphasises the importance of incorporating explainability and transparency concepts. Following the hybrid intelligence paradigm it is possible to ensure that the feedback provided by these tools is not only accurate but also understandable to humans. This approach fosters trust and promotes a deeper understanding of the psychomotor learning process, empowering users and facilitators to make informed decisions about the psychomotor learning path. The hybrid intelligence paradigm, which combines the strengths of both human and artificial intelligence, plays a crucial role in the deployment of these solutions. By taking advantage of the cognitive capabilities of human experts alongside the computational power of artificial intelligence algorithms, it is possible to offer personalised feedback that takes into account both technical accuracy and pedagogical effectiveness. Through these collaborative efforts it is also possible to create learning environments that are inclusive, adaptable, and beneficial to lifelong learning. In conclusion, this proposal introduces retrieval-augmented generation tools for providing feedback in psychomotor learning systems, which represents a significant step towards in its personalization, and whose ethical implications align with the new regulations on the implementation of intelligent technologies in critical systems.},
	booktitle = {Adjunct {Proceedings} of the 32nd {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {Association for Computing Machinery},
	author = {Portaz, Miguel and Manjarres, Angeles and Santos, Olga C.},
	year = {2024},
	note = {event-place: Cagliari, Italy},
	keywords = {Collaborative Learning, Ethics, Human-Centered, Hybrid Intelligence, Intelligent Psychomotor Systems, Retrieval Augmented Generation, XAI},
	pages = {380--385},
}

@inproceedings{esposito_leveraging_2024,
	address = {New York, NY, USA},
	series = {{EASE} '24},
	title = {Leveraging {Large} {Language} {Models} for {Preliminary} {Security} {Risk} {Analysis}: {A} {Mission}-{Critical} {Case} {Study}},
	isbn = {979-8-4007-1701-7},
	url = {https://doi.org/10.1145/3661167.3661226},
	doi = {10.1145/3661167.3661226},
	abstract = {Preliminary security risk analysis (PSRA) provides a quick approach to identify, evaluate, and propose remediation to potential risks in specific scenarios. The extensive expertise required for an effective PSRA and the substantial textual-related tasks hinders quick assessments in mission-critical contexts, where timely and prompt actions are essential. The speed and accuracy of human experts in PSRA significantly impact response time. A large language model can quickly summarise information in less time than a human. To our knowledge, no prior study has explored the capabilities of fine-tuned models (FTM) in PSRA. Our case study investigates the proficiency of FTM in assisting practitioners in PSRA. We manually curated 141 representative samples from over 50 mission-critical analyses archived by the industrial context team in the last five years. We compared the proficiency of the FTM versus seven human experts. Within the industrial context, our approach has proven successful in reducing errors in PSRA, hastening security risk detection, and minimizing false positives and negatives. This translates to cost savings for the company by averting unnecessary expenses associated with implementing unwarranted countermeasures. Therefore, experts can focus on more comprehensive risk analysis, leveraging LLMs for an effective preliminary assessment within a condensed timeframe.},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Evaluation} and {Assessment} in {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Esposito, Matteo and Palagiano, Francesco},
	year = {2024},
	note = {event-place: Salerno, Italy},
	keywords = {Analysis, Fine-Tuning, Generative AI, Human Experts, Large Language Model, LLM, Management, Preliminary, Risk, Security, Standards},
	pages = {442--445},
}

@inproceedings{lee_llm-driven_2024,
	address = {New York, NY, USA},
	series = {Middleware '24},
	title = {An {LLM}-driven {Framework} for {Dynamic} {Infrastructure} as {Code} {Generation}},
	isbn = {979-8-4007-1354-5},
	url = {https://doi.org/10.1145/3704440.3704778},
	doi = {10.1145/3704440.3704778},
	abstract = {This paper proposes a Large Language Model (LLM)-driven framework for generation of Infrastructure as Code (IaC) in dynamic environments. While IaC simplifies infrastructure management, static templates are often inadequate. Leveraging recent LLM advancements, we design and integrate requirements refinement, retrieval-augmented generation (RAG), and code ensemble methods to improve IaC code accuracy. Preliminary results show that, despite challenges(syntax errors and hallucinations), manual adjustments enable executable code, suggesting potential for dynamic generation.},
	booktitle = {Proceedings of the 25th {International} {Middleware} {Conference}: {Demos}, {Posters} and {Doctoral} {Symposium}},
	publisher = {Association for Computing Machinery},
	author = {Lee, Junhee and Kang, SungJoo and Ko, In-Young},
	year = {2024},
	note = {event-place: Hong Kong, Hong Kong},
	keywords = {Dynamic Generation, IaC, LLM},
	pages = {9--10},
}

@inproceedings{spitzer_looking_2024,
	address = {New York, NY, USA},
	series = {{MuC} '24},
	title = {Looking {Through} the {Deep} {Glasses}: {How} {Large} {Language} {Models} {Enhance} {Explainability} of {Deep} {Learning} {Models}},
	isbn = {979-8-4007-0998-2},
	url = {https://doi.org/10.1145/3670653.3677488},
	doi = {10.1145/3670653.3677488},
	abstract = {As AI becomes more powerful, it also becomes more complex. Traditionally, eXplainable AI (XAI) is used to make these models more transparent and interpretable to decision-makers. However, research shows that decision-makers can lack the ability to properly interpret XAI techniques. Large language models (LLMs) offer a solution to this challenge by providing natural language text in combination with XAI techniques to provide more understandable explanations. However, previous work has only explored this approach for inherently interpretable models–an understanding of how LLMs can assist decision-makers when using deep learning models is lacking. To fill this gap, we investigate how different augmentation strategies of LLMs assist decision-makers in interacting with deep learning models. We evaluate the satisfaction and preferences of decision-makers through a user study. Overall, our results provide first insights into how LLMs support decision-makers in interacting with deep learning models and open future avenues to continue this endeavor.},
	booktitle = {Proceedings of {Mensch} {Und} {Computer} 2024},
	publisher = {Association for Computing Machinery},
	author = {Spitzer, Philipp and Celis, Sebastian and Martin, Dominik and Kühl, Niklas and Satzger, Gerhard},
	year = {2024},
	note = {event-place: Karlsruhe, Germany},
	keywords = {Artificial Intelligence, Explainable AI, Human-Computer Interaction, Large Language Models},
	pages = {566--570},
}

@inproceedings{ye_boosting_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Boosting {Conversational} {Question} {Answering} with {Fine}-{Grained} {Retrieval}-{Augmentation} and {Self}-{Check}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657980},
	doi = {10.1145/3626772.3657980},
	abstract = {Retrieval-Augmented Generation (RAG) aims to generate more reliable and accurate responses, by augmenting large language models(LLMs) with the external vast and dynamic knowledge. Most previous work focuses on using RAG for single-round question answering, while how to adapt RAG to the complex conversational setting wherein the question is interdependent on the preceding context is not well studied. In this paper, we propose a conversation-level RAG (ConvRAG) approach, which incorporates fine-grained retrieval augmentation and self-check for conversational question answering (CQA). In particular, our approach consists of three components, namely conversational question refiner, fine-grained retriever and self-check based response generator, which work collaboratively for question understanding and relevant information acquisition in conversational settings. Extensive experiments demonstrate the great advantages of our approach over the state-of-the-art baselines. Moreover, we also release a Chinese CQA dataset with new features including reformulated question, extracted keyword, retrieved paragraphs and their helpfulness, which facilitates further researches in RAG enhanced CQA.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Ye, Linhao and Lei, Zhikai and Yin, Jianghao and Chen, Qin and Zhou, Jie and He, Liang},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {conversational question answering, large language models, retrieval-augmented generation},
	pages = {2301--2305},
}

@inproceedings{recio_abad_automatic_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {Automatic {Proof} {Generation}: {Fine}-tuning and {RAG} in {Reasoner} vs. {Math} {LLMs}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3728705},
	doi = {10.1145/3696630.3728705},
	abstract = {Software formal verification is an important and challenging tool to ensure software correctness. It requires tools to formulate and verify mathematical theorems. One example of such a tool is Isabelle/HOL, a proof assistant that supports higher-order logic (HOL), enabling rigorous mathematical reasoning that could be useful for formal verification in software and hardware systems. However, the use of these tools requires a human expert on theorem proving in many cases. With the advent of LLMs (Large Language Models) a research line emerged to use them for proof inference. This paper investigates the effectiveness of math LLMs, reasoner LLMs, and hybrid math-reasoner LLMs in Isabelle/HOL proof inference, evaluating their capabilities across three configurations: base models without domain-specific training, fine-tuned variants adapted to the formal proof domain, and systems based on Retrieval Augmented Generation (RAG). The significance of this comparison extends beyond theoretical interest, potentially informing the development of hybrid systems that leverage the complementary strengths of all approaches.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Recio Abad, Juan Carlos and Saborido, Rubén and Chicano, Francisco},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {formal methods, isabelle/HOL, large language models, software verification},
	pages = {1679--1682},
}

@inproceedings{krueger_towards_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {Towards a {LLM}-{Based} {System} for {Generating} and {Validating} {Product} {Requirements}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3731673},
	doi = {10.1145/3696630.3731673},
	abstract = {This position paper motivates the development of a large language model (LLM) -based system for creating comprehensive, testable product requirements documents (PRDs). The intention is to guide innovators who lack formal product management experience— clinicians, researchers, academics, and other specialists—in producing specifications detailed enough for successful contracting with engineering or manufacturing partners. The LLM would be augmented with a retrieval-augmented generation (RAG) component and set up in a conversational manner, mitigating issues that arise when under-specified requirements are handed to contract firms.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Krueger, Evan and Carpenter, Taylor and Leach, Kevin and Weimer, James},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {LLM-based design, software requirements},
	pages = {1538--1539},
}

@inproceedings{chen_llm-powered_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{LLM}-powered {Heterogeneous} {Information} {Network} {Analytics}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715450},
	doi = {10.1145/3701716.3715450},
	abstract = {Most existing Knowledge Base Question Answering methods focus primarily on retrieving factual information, leaving more complex, analysis-driven tasks relatively unexplored. However, real-world queries often involve graph-based computations such as degree calculation or community detection, which require more advanced reasoning. In this paper, we introduce LLM4GraphAna, a Large Language Model-based approach designed to handle these challenging, analysis-focused queries within the KBQA framework. By integrating Function Orchestration and Parameterization, LLM4GraphAna can invoke our well-defined functions to perform graph analytics. Experimental results demonstrate that our method significantly improves performance on analysis-intensive questions.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Chen, Hao and Du, Lun and Chen, Xu and Ma, Xiaojun and Zhang, Jiang},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {graph analytics, heterogeneous information network, large language model},
	pages = {903--906},
}

@inproceedings{soman_observations_2024,
	address = {New York, NY, USA},
	series = {{AIMLSystems} '23},
	title = {Observations on {LLMs} for {Telecom} {Domain}: {Capabilities} and {Limitations}},
	isbn = {979-8-4007-1649-2},
	url = {https://doi.org/10.1145/3639856.3639892},
	doi = {10.1145/3639856.3639892},
	abstract = {The landscape for building conversational interfaces (chatbots) has witnessed a paradigm shift with recent developments in generative Artificial Intelligence (AI) based Large Language Models (LLMs), such as ChatGPT by OpenAI (GPT3.5 and GPT4), Google’s Bard, Large Language Model Meta AI (LLaMA), among others. In this paper, we analyze capabilities and limitations of incorporating such models in conversational interfaces for the telecommunication domain, specifically for enterprise wireless products and services. Using Cradlepoint’s publicly available data for our experiments, we present a comparative analysis of the responses from such models for multiple use-cases including domain adaptation for terminology and product taxonomy, context continuity, robustness to input perturbations and errors. We believe this evaluation would provide useful insights to data scientists engaged in building customized conversational interfaces for domain-specific requirements.},
	booktitle = {Proceedings of the {Third} {International} {Conference} on {AI}-{ML} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Soman, Sumit and H. G., Ranjani},
	year = {2024},
	note = {event-place: Bangalore, India},
	keywords = {Bard, Chatbot, ChatGPT, Enterprise Wireless., Generative AI, GPT3.5, GPT4, Large Language Models, LLaMA, Telecom},
}

@inproceedings{zhu_multimodal_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Multimodal {Representation} and {Retrieval} [{MRR} 2024]},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657987},
	doi = {10.1145/3626772.3657987},
	abstract = {Multimodal data is available in many applications like e-commerce production listings, social media posts and short videos. However, existing algorithms dealing with those types of data still focus on uni-modal representation learning by vision-language alignment and cross-modal retrieval. In this workshop, we target to bring a new retrieval problem where both queries and documents are multimodal. With the popularity of vision language modeling, large language models (LLMs), retrieval augmented generation (RAG), and multimodal LLM, we see a lot of new opportunities for multimodal representation and retrieval tasks. This event will be a comprehensive half-day workshop focusing on the subject of multimodal representation and retrieval. The agenda includes keynote speeches, oral presentations, and an interactive panel discussion.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zhu, Xinliang and Dhua, Arnab and Gray, Douglas and Yalniz, I. Zeki and Yu, Tan and Elhoseiny, Mohamed and Plummer, Bryan},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {large language model, multimodal large language model, multimodal representation, multimodal retrieval, vision language modeling},
	pages = {3047--3050},
}

@inproceedings{salminen_using_2024,
	address = {New York, NY, USA},
	series = {L@{S} '24},
	title = {Using {Cipherbot}: {An} {Exploratory} {Analysis} of {Student} {Interaction} with an {LLM}-{Based} {Educational} {Chatbot}},
	isbn = {979-8-4007-0633-2},
	url = {https://doi.org/10.1145/3657604.3664690},
	doi = {10.1145/3657604.3664690},
	abstract = {Cipherbot, an educational chatbot using large language models to answer student questions concerning learning materials uploaded by the educator, was pilot tested in a classroom setting. Forty-four students used Cipherbot for seven weeks, sending 8077 messages. The average number of messages sent per student was 184 (SD = 80), with an average length of 98 characters (SD = 80). The engagement followed a non-normal distribution, with few power users, implying that most students are still hesitant to adopt tools like Cipherbot. Cipherbot was able to answer 82.5\% of the student questions, demonstrating a scalable ability to address students' learning queries, with some room for improvement.},
	booktitle = {Proceedings of the {Eleventh} {ACM} {Conference} on {Learning} @ {Scale}},
	publisher = {Association for Computing Machinery},
	author = {Salminen, Joni and Jung, Soon-gyo and Medina, Johanne and Aldous, Kholoud and Azem, Jinan and Akhtar, Waleed and Jansen, Bernard J.},
	year = {2024},
	note = {event-place: Atlanta, GA, USA},
	keywords = {cipherbot, generative AI, LLMs, student interaction},
	pages = {279--283},
}

@inproceedings{fung_automatic_2024,
	address = {New York, NY, USA},
	series = {L@{S} '24},
	title = {Automatic {Feedback} {Generation} on {K}-12 {Students}' {Data} {Science} {Education} by {Prompting} {Cloud}-based {Large} {Language} {Models}},
	isbn = {979-8-4007-0633-2},
	url = {https://doi.org/10.1145/3657604.3664673},
	doi = {10.1145/3657604.3664673},
	abstract = {Since data science is traditionally an advanced field taught at the college or university level, introducing its concepts to K-12 students can present unique learning challenges. As educational environments increasingly adopt data science curricula for K-12 students, the need for scalable, personalized teaching tools becomes critical. While the integration of large language models (LLMs) in educational environments offers significant potential for scalability and automation, it is important to note that the generated language output may not always be highly suitable for K-12 students. In this paper, we introduce the DSRAG, a novel educational automatic feedback generation framework that leverages Retrieval-Augmented Generation (RAG) and cloud-based LLMs to provide automated and personalized feedback for K-12 students engaged in data science education. DSRAG employs Langchain question-answering and RAG systems to manage educational content and generate feedback on the top of GPT-4. We also demonstrate the framework's capability to simplify complex concepts and align its responses to be pedagogically appropriate and understandable for K-12 students.},
	booktitle = {Proceedings of the {Eleventh} {ACM} {Conference} on {Learning} @ {Scale}},
	publisher = {Association for Computing Machinery},
	author = {Fung, Sze Ching Evelyn and Wong, Man Fai and Tan, Chee Wei},
	year = {2024},
	note = {event-place: Atlanta, GA, USA},
	keywords = {large language models, learning technologies, prompt engineering, retrieval-augmented generation},
	pages = {255--258},
}

@inproceedings{emerson_codedocs_2025,
	address = {New York, NY, USA},
	series = {{PEARC} '25},
	title = {{CodeDocs}: {GenAI} to generate documentation from {Git} {Repositories}},
	isbn = {979-8-4007-1398-9},
	url = {https://doi.org/10.1145/3708035.3736102},
	doi = {10.1145/3708035.3736102},
	abstract = {Managing and understanding large-scale software repositories remains a challenge in research software development. This paper presents CodeDocs, an AI-powered tool that automates the generation of structured documentation for GitHub repositories using Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs). The tool leverages Dartmouth’s Dartmouth Chat interface and the LangChain\_Dartmouth Python package to scan repository structures, extract meaningful code insights and generate a README.md file to improve usability, maintainability, and collaboration by providing structured project documentation that supports shared understanding across teams. We evaluate the tool’s performance against manually curated documentation and discuss its implications for research computing. It should be noted that this approach can be implemented using the standard LangChain Python package and any LLM, making it accessible beyond Dartmouth’s infrastructure.},
	booktitle = {Practice and {Experience} in {Advanced} {Research} {Computing} 2025: {The} {Power} of {Collaboration}},
	publisher = {Association for Computing Machinery},
	author = {Emerson, Amanda and Meehan, Tim and Rogers, Matt and Cowen, William and Darabos, Christian},
	year = {2025},
	keywords = {Artificial Intelligence, Collaboration, GitHub, Large Language Models, Research Computing, Retrieval-Augmented Generation, Software Documentation},
}

@inproceedings{carmel_liverag_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {The {LiveRAG} {Challenge} at {SIGIR} 2025},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3733591},
	doi = {10.1145/3726302.3733591},
	abstract = {The LiveRAG Challenge at SIGIR 2025 provides a competitive platform for advancing Retrieval-Augmented Generation (RAG) technologies. Participants from academia and industry have been invited to build a RAG-based question answering system using a fixed corpus (Fineweb-10BT) and a common open-source LLM (Falcon3-10B-Instruct). The goal is to enable fair, focused comparisons on retrieval and prompting strategies. During the Live Challenge Day, the competing teams must provide answers and supportive information to 500 unseen questions within a strict two-hour window. Evaluation is conducted in two stages: automated LLM-as-a-judge scoring mechanism for correctness and faithfulness, followed by a manual review of top ranked submissions. The winners will be announced and prizes awarded during the LiveRAG Workshop at SIGIR 2025 in Padua, Italy.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Carmel, David and Filice, Simone and Horowitz, Guy and Maarek, Yoelle and Somekh, Oren and Tavory, Ran},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {evaluation, llm, rag},
	pages = {4199--4201},
}

@inproceedings{sun_d-bot_2025,
	address = {New York, NY, USA},
	series = {{SIGMOD}/{PODS} '25},
	title = {D-{Bot}: {An} {LLM}-{Powered} {DBA} {Copilot}},
	isbn = {979-8-4007-1564-8},
	url = {https://doi.org/10.1145/3722212.3725091},
	doi = {10.1145/3722212.3725091},
	abstract = {Database administrators (DBAs) play an important role in maintaining the high performance and high availability of database systems. However, database diagnosis by DBAs often takes tedious efforts and time, which is insufficient for the large amount of database instances (e.g., millions of instances on the cloud). Besides, existing diagnosis tools built with rules and small-scale learned models lack the capability for flexible reasoning and report generation, and thus can only serve as ”one small piece of a bigger puzzle”. Recently, Large language models (LLMs) have exhibited superiority in natural language understanding, reasoning and generation, positioning them as a potential comprehensive copilot to DBAs to address these limitations. Thus, we introduce D-Bot, an LLM-powered DBA copilot that can automatically acquire pertinent knowledge from diagnostic documents, interact with users for self-refinement, and generate reasonable and well-founded diagnosis reports (i.e., specifying root causes, solutions, and references). We will show that D-Bot can effectively automate database diagnosis in real scenarios, even for complex anomalies.},
	booktitle = {Companion of the 2025 {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {Sun, Zhaoyan and Zhou, Xuanhe and Wu, Jianming and Zhou, Wei and Li, Guoliang},
	year = {2025},
	note = {event-place: Berlin, Germany},
	keywords = {database diagnosis, database system, large language model},
	pages = {235--238},
}

@inproceedings{wang_andromeda_2025,
	address = {New York, NY, USA},
	series = {{SIGMOD}/{PODS} '25},
	title = {Andromeda: {Debugging} {Database} {Performance} {Issues} with {Retrieval}-{Augmented} {Large} {Language} {Models}},
	isbn = {979-8-4007-1564-8},
	url = {https://doi.org/10.1145/3722212.3725080},
	doi = {10.1145/3722212.3725080},
	abstract = {Debugging performance issues in a database management system (DBMS) is tedious and challenging, even for experienced database administrators (DBAs). Thus, with the rapid advancement of large language models (LLMs), developing an LLM-powered co-pilot to assist or even replace DBAs by automatically diagnosing issues and generating recommendations for resolution presents a promising direction. However, directly prompting LLMs for DBMS performance debugging often yields either generic or irrelevant responses, as LLMs may lack both domain knowledge in performance debugging and a deep understanding of DBMS internals. In this paper, we introduce Andromeda, a retrieval-augmented, LLM-powered system for automatic DBMS performance debugging. Andromeda enables users to pose natural language questions about various performance issues and provides context-aware and actionable recommendations for resolution. To achieve this, Andromeda first retrieves relevant evidence from multiple sources, including historical questions, troubleshooting manuals, DBMS telemetry data, and execution logs. It then leverages effective training strategies to adapt an open-source LLM, empowering it to diagnose and resolve issues based on the retrieved evidence. We have developed a web application for Andromeda and demonstrated its effectiveness in debugging real-world DBMS performance issues.},
	booktitle = {Companion of the 2025 {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Pengyi and Chen, Sibei and Fan, Ju and Wu, Bin and Tang, Nan and Tan, Jian},
	year = {2025},
	note = {event-place: Berlin, Germany},
	keywords = {database performance debugging, retrieval-augmented generation},
	pages = {243--246},
}

@inproceedings{zhang_sortinghat_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{SortingHat}: {Redefining} {Operating} {Systems} {Education} with a {Tailored} {Digital} {Teaching} {Assistant}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715199},
	doi = {10.1145/3701716.3715199},
	abstract = {Operating Systems (OS) courses are among the most challenging in computer science education due to the complexity of internal structures and the diversity of running environments. Traditional teaching methods often fail to address the diverse backgrounds, learning speeds, and practical needs of students. To tackle these challenges, we present SortingHat, a personalized digital teaching assistant tailored specifically for OS education. SortingHat integrates advanced AI technologies, including a retrieval-augmented generation (RAG) framework and multi-agent reinforcement learning (MARL), to deliver adaptive, scalable, and effective educational support. SortingHat features a 3D digital human interface powered by large language models (LLMs) to provide personalized, empathetic, and context-aware guidance. It generates tailored exercises based on each student's learning history and academic performance, reinforcing weak areas and challenging advanced concepts. Additionally, the system incorporates a robust evaluation pipeline that ensures fair, consistent, and unbiased grading of student submissions while delivering personalized, actionable feedback for improvement. By combining personalized guidance, adaptive content creation, and automated assessment, SortingHat transforms OS education into an engaging, immersive, and scalable experience.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Yifan and Zhao, Xinkui and Wang, Zuxin and Zhou, Zhengyi and Cheng, Guanjie and Deng, Shuiguang and Yin, Jianwei},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {digital human, education, large language models, multi agent reinforcement learning, retrieval augmented generation},
	pages = {2951--2954},
}

@inproceedings{kopkow_high_2025,
	address = {New York, NY, USA},
	series = {{MuC} '25},
	title = {High {Expectations}, {High} {Hurdles}: {A} {Survey} with {Professionals} in {Austrian} {SMEs} on their {GenAI} {Usage}, {Concerns}, and {Literacy}},
	isbn = {979-8-4007-1582-2},
	url = {https://doi.org/10.1145/3743049.3748576},
	doi = {10.1145/3743049.3748576},
	abstract = {Professionals in small and medium-sized enterprises (SMEs) have high expectations towards GenAI technologies. They are a large and particular target user group and therefore interesting for research on (designing) GenAI technologies for the workplace due to SMEs’ typical characteristics of high agility but low resources for innovation. In this paper, we present a survey study with 37 professionals working in Austrian SMEs on their use of GenAI, their plans and concerns for future use, and their GenAI literacy. Our findings show that GenAI is used frequently, and primarily for simple tasks such as content generation and search, despite concerns about data security and professionals’ limited confidence in usage. The GenAI literacy of the participants varied and was generally low. Good design that addresses the needs of SMEs for productivity in key tasks, ease-of-use, and trustworthiness, while improving GenAI literacy and supporting long-term human learning, will be needed to fulfill expectations and facilitate effective and sustainable usage of GenAI in SMEs.},
	booktitle = {Proceedings of the {Mensch} {Und} {Computer} 2025},
	publisher = {Association for Computing Machinery},
	author = {Kopkow, Alina and Bangerl, Mia Magdalena and Pammer-Schindler, Viktoria},
	year = {2025},
	keywords = {GenAI Literacy, Generative AI, LLMs, SME},
	pages = {637--647},
}

@inproceedings{khurana_table_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Table {Retrieval} using {LLMs} and {Semantic} {Table} {Similarity}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715558},
	doi = {10.1145/3701716.3715558},
	abstract = {Searching for relevant tables in response to a textual phrase or a question is an important task for large tabular data repositories, such as relational databases, CSV files in data lakes, etc. It is somewhat different from the problem of web document search because the subjects of search are tables rather than documents, while the query remains textual. In this paper, we explore a novel technique for table search on large repositories using natural language queries. It is based on a generative methodology that aims to maximize the semantic connection between the query and the resulting tables. Unlike traditional keyword search approaches, our technique can find the needed tables more effectively through deeper semantic concept discovery rather than simply searching for exact keyword matches. Additionally, our technique supports natural language queries rather than plain keyword queries. In this paper, we describe the core ideas, implementation, and effectiveness of our method using two different benchmarks with diverse queries.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Khurana, Udayan and Suneja, Sahil and Samulowitz, Horst},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {generative ai, large language models, semantic similarity, structured data search, table retrieval},
	pages = {1072--1076},
}

@inproceedings{schmidt_detecting_2024,
	address = {New York, NY, USA},
	series = {{WWW} '24},
	title = {Detecting {Generated} {Native} {Ads} in {Conversational} {Search}},
	isbn = {979-8-4007-0172-6},
	url = {https://doi.org/10.1145/3589335.3651489},
	doi = {10.1145/3589335.3651489},
	abstract = {Conversational search engines such as YouChat and Microsoft Copilot use large language models (LLMs) to generate responses to queries. It is only a small step to also let the same technology insert ads within the generated responses - instead of separately placing ads next to a response. Inserted ads would be reminiscent of native advertising and product placement, both of which are very effective forms of subtle and manipulative advertising. Considering the high computational costs associated with LLMs, for which providers need to develop sustainable business models, users of conversational search engines may very well be confronted with generated native ads in the near future. In this paper, we thus take a first step to investigate whether LLMs can also be used as a countermeasure, i.e., to block generated native ads. We compile the Webis Generated Native Ads 2024 dataset of queries and generated responses with automatically inserted ads, and evaluate whether LLMs or fine-tuned sentence transformers can detect the ads. In our experiments, the investigated LLMs struggle with the task but sentence transformers achieve precision and recall values above 0.9.},
	booktitle = {Companion {Proceedings} of the {ACM} {Web} {Conference} 2024},
	publisher = {Association for Computing Machinery},
	author = {Schmidt, Sebastian and Zelch, Ines and Bevendorff, Janek and Stein, Benno and Hagen, Matthias and Potthast, Martin},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	keywords = {advertising, llm, retrieval-augmented generation},
	pages = {722--725},
}

@inproceedings{ardimento_enhancing_2024,
	address = {New York, NY, USA},
	series = {{MODELS} {Companion} '24},
	title = {Enhancing {Software} {Modeling} {Learning} with {AI}-{Powered} {Scaffolding}},
	isbn = {979-8-4007-0622-6},
	url = {https://doi.org/10.1145/3652620.3687776},
	doi = {10.1145/3652620.3687776},
	abstract = {This study introduces an innovative AI-powered scaffolding approach aimed at enhancing software modeling learning through UML diagrams. The focus of this research is on defining the principles and functions comprising the scaffolding. Leveraging recent advancements in generative AI, our approach provides a structured educational framework to improve comprehension and proficiency in modeling concepts. We present the initial implementation of the scaffolding, specifically highlighting the feedback function. By integrating theoretical insights with practical applications, this study seeks to advance Model-Driven Software Engineering education and underscores the potential of AI in enhancing instructional methodologies.},
	booktitle = {Proceedings of the {ACM}/{IEEE} 27th {International} {Conference} on {Model} {Driven} {Engineering} {Languages} and {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ardimento, Pasquale and Bernardi, Mario Luca and Cimitile, Marta and Scalera, Michele},
	year = {2024},
	note = {event-place: Linz, Austria},
	keywords = {education, generative AI, model-driven software engineering, scaffolding, software modelling, UML},
	pages = {103--106},
}

@inproceedings{li_enhancing_2024,
	address = {New York, NY, USA},
	series = {{LLM4Code} '24},
	title = {Enhancing {LLM}-{Based} {Coding} {Tools} through {Native} {Integration} of {IDE}-{Derived} {Static} {Context}},
	isbn = {979-8-4007-0579-3},
	url = {https://doi.org/10.1145/3643795.3648392},
	doi = {10.1145/3643795.3648392},
	abstract = {Large Language Models (LLMs) have achieved remarkable success in code completion, as evidenced by their essential roles in developing code assistant services such as Copilot. Being trained on in-file contexts, current LLMs are quite effective in completing code for single source files. However, it is challenging for them to conduct repository-level code completion for large software projects that require cross-file information. Existing research on LLM-based repository-level code completion identifies and integrates cross-file contexts, but it suffers from low accuracy and limited context length of LLMs. In this paper, we argue that Integrated Development Environments (IDEs) can provide direct, accurate and real-time cross-file information for repository-level code completion. We propose IDECoder, a practical framework that leverages IDE native static contexts for cross-context construction and diagnosis results for self-refinement. IDECoder utilizes the rich cross-context information available in IDEs to enhance the capabilities of LLMs of repository-level code completion. We conducted preliminary experiments to validate the performance of IDECoder and observed that this synergy represents a promising trend for future exploration.},
	booktitle = {Proceedings of the 1st {International} {Workshop} on {Large} {Language} {Models} for {Code}},
	publisher = {Association for Computing Machinery},
	author = {Li, Yichen and Peng, Yun and Huo, Yintong and Lyu, Michael R.},
	year = {2024},
	note = {event-place: Lisbon, Portugal},
	keywords = {code generation, large language model},
	pages = {70--74},
}

@inproceedings{saha_roy_evidence_2025,
	address = {New York, NY, USA},
	series = {{WSDM} '25},
	title = {Evidence {Contextualization} and {Counterfactual} {Attribution} for {Conversational} {QA} over {Heterogeneous} {Data} with {RAG} {Systems}},
	isbn = {979-8-4007-1329-3},
	url = {https://doi.org/10.1145/3701551.3704126},
	doi = {10.1145/3701551.3704126},
	abstract = {Retrieval Augmented Generation (RAG) works as a backbone for interacting with an enterprise's own data via Conversational Question Answering (ConvQA). In a RAG system, a retriever fetches passages from a collection in response to a question, which are then included in the prompt of a large language model (LLM) for generating a natural language (NL) answer. However, several RAG systems today suffer from two shortcomings: (i) retrieved passages usually contain their raw text and lack appropriate document context, negatively impacting both retrieval and answering quality; and (ii) attribution strategies that explain answer generation typically rely only on similarity between the answer and the retrieved passages, thereby only generating plausible but not causal explanations. In this work, we demonstrate RAGonite, a RAG system that remedies the above concerns by: (i) contextualizing evidence with source metadata and surrounding text; and (ii) computing counterfactual attribution, a causal explanation approach where the contribution of an evidence to an answer is determined by the similarity of the original response to the answer obtained by removing that evidence. To evaluate our proposals, we release a new benchmark ConfQuestions: it has 300 hand-created conversational questions, each in English and German, coupled with ground truth URLs, completed questions, and answers from 215 public Confluence pages. These documents are typical of enterprise wiki spaces with heterogeneous elements. Experiments with RAGonite on ConfQuestions show the viability of our ideas: contextualization improves RAG performance, and counterfactual explanations outperform standard attribution.},
	booktitle = {Proceedings of the {Eighteenth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Saha Roy, Rishiraj and Schlotthauer, Joel and Hinze, Chris and Foltyn, Andreas and Hahn, Luzian and Kuech, Fabian},
	year = {2025},
	note = {event-place: Hannover, Germany},
	keywords = {conversations, large language models, question answering},
	pages = {1040--1043},
}

@inproceedings{wu_clear_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{CLEAR}: {Climate} {Policy} {Retrieval} and {Summarization} {Using} {LLMs}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715170},
	doi = {10.1145/3701716.3715170},
	abstract = {Web platforms play a critical role in climate change communication. However, despite facing increasing climate issues, residents especially those living in rural areas still struggle to access and interpret climate policies, while local governments lack structured feedback on policy effectiveness and community needs. To bridge this dual communication challenge, we present CLEAR (Climate PoLicy rEtrieval and summA Rization), a system powered by Large Language Models (LLMs) which can analyze resident queries and provide customized responses addressing their climate concerns based on relevant local government policy documents. Our system leverages a fine-tuned Llama-3.2-3B to decompose natural queries into structured components to enable precise information retrieval and summarization. The workflow of the CLEAR system consists of: (1) semantic query analysis to identify resident location and climate concerns, (2) intelligent retrieval from a curated dataset of authoritative policy documents, and (3) multi-modal policy summarization with geospatial context. When there is no corresponding policy for the specific climate concern, the CLEAR system can help to generate contextualized feedback to relevant local governments. In this paper, through real-world implementation and demonstration, we show how CLEAR can effectively bridge the information gap between Australian rural communities and local governments through LLM-based policy retrieval and summarization. Our source code is available at https://github.com/wuyoscar/CLEAR.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Wu, Yutao and Ran, Kun and Liu, Ming and Cardilini, Adam P. A. and Nurwidyantoro, Arif and Liu, Xiao},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {actionable climate insights, large language model, natural language processing, report generation},
	pages = {2927--2930},
}

@inproceedings{felemban_exaggeration-based_2025,
	address = {New York, NY, USA},
	series = {{3D}-{Sec} '25},
	title = {Exaggeration-based {Fake} {Cybersecurity} {News} {Detection}},
	isbn = {979-8-4007-1902-8},
	url = {https://doi.org/10.1145/3733813.3764365},
	doi = {10.1145/3733813.3764365},
	abstract = {We address the challenge of detecting exaggeration in cybersecurity tweets on X, where misinformation spreads rapidly. Our novel framework uses local Large Language Models (LLMs) and Retrieval Augmented Generation (RAG) to gather evidence and assess tweets’ rhetorical intensity, offering graded exaggeration scores. Validated through a human study and a pilot that matches LLM results with human labels, this work lays the groundwork for improved misinformation detection tools.},
	booktitle = {Proceedings of the 1st {ACM} {Workshop} on {Deepfake}, {Deception}, and {Disinformation} {Security}},
	publisher = {Association for Computing Machinery},
	author = {Felemban, Abdullah and Ghaleb, Mustafa and Felemban, Muhamad},
	year = {2025},
	keywords = {Cybersecurity, Fake news, LLM, Misinformation detection},
	pages = {1--4},
}

@inproceedings{buzzi_towards_2025,
	address = {New York, NY, USA},
	series = {{PETRA} '25},
	title = {Towards {Empowering} {Teachers} with {AI} for {Dynamic} {Evaluation} and {Assessment} for {Students} with {Special} {Needs}},
	isbn = {979-8-4007-1402-3},
	url = {https://doi.org/10.1145/3733155.3736797},
	doi = {10.1145/3733155.3736797},
	abstract = {Supporting students with special needs requires adaptive, personalized, and continuously updated educational strategies. Traditional static approaches often fail to capture the complexity and evolution of students’ learning trajectories. In this paper, we propose a dynamic-context AI-based digital platform designed to empower teachers by monitoring student progress, suggesting tailored strategies, and adapting learning materials based on real-time observations and assessments. The system also assists in the compilation and iterative refinement of the IEP (Individualised Educational Plan), offering continuous feedback through a digital co-teacher (chatbot). By providing the AI with an evolving context, the platform aims to enable more accurate and responsive educational support. A theoretical use case illustrates how the system can help teachers adjust objectives and expectations when students encounter unforeseen difficulties, fostering more inclusive and effective learning experiences.},
	booktitle = {Proceedings of the 18th {ACM} {International} {Conference} on {PErvasive} {Technologies} {Related} to {Assistive} {Environments}},
	publisher = {Association for Computing Machinery},
	author = {Buzzi, Marina and Leporini, Barbara and Lo Duca, Angelica and Punzo, Veronica and Rotelli, Daniela},
	year = {2025},
	keywords = {Accessibility, Education, Generative AI, Special needs, STEM},
	pages = {212--215},
}

@inproceedings{biancini_multiple-choice_2024,
	address = {New York, NY, USA},
	series = {{UMAP} {Adjunct} '24},
	title = {Multiple-{Choice} {Question} {Generation} {Using} {Large} {Language} {Models}: {Methodology} and {Educator} {Insights}},
	isbn = {979-8-4007-0466-6},
	url = {https://doi.org/10.1145/3631700.3665233},
	doi = {10.1145/3631700.3665233},
	abstract = {Integrating Artificial Intelligence (AI) in educational settings has brought new learning approaches, transforming the practices of both students and educators. Among the various technologies driving this transformation, Large Language Models (LLMs) have emerged as powerful tools for creating educational materials and question answering, but there are still space for new applications. Educators commonly use Multiple-Choice Questions (MCQs) to assess student knowledge, but manually generating these questions is resource-intensive and requires significant time and cognitive effort. In our opinion, LLMs offer a promising solution to these challenges. This paper presents a novel comparative analysis of three widely known LLMs - Llama 2, Mistral, and GPT-3.5 - to explore their potential for creating informative and challenging MCQs. In our approach, we do not rely on the knowledge of the LLM, but we inject the knowledge into the prompt to contrast the hallucinations, giving the educators control over the test’s source text, too. Our experiment involving 21 educators shows that GPT-3.5 generates the most effective MCQs across several known metrics. Additionally, it shows that there is still some reluctance to adopt AI in the educational field. This study sheds light on the potential of LLMs to generate MCQs and improve the educational experience, providing valuable insights for the future.},
	booktitle = {Adjunct {Proceedings} of the 32nd {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {Association for Computing Machinery},
	author = {Biancini, Giorgio and Ferrato, Alessio and Limongelli, Carla},
	year = {2024},
	note = {event-place: Cagliari, Italy},
	keywords = {Generative AI, LLMs, Multiple Choice Question},
	pages = {584--590},
}

@inproceedings{varga_inquiry_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Inquiry {Assistant} {Using} {LLM}-{Generated} {Knowledge} {Graphs}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3731956},
	doi = {10.1145/3726302.3731956},
	abstract = {Businesses are increasingly overwhelmed by inquiries related to their services or products. Relying on human agents to handle inquiries via email results in higher costs and delayed responses, contributing to customer dissatisfaction. In response to these challenges, this pilot study leverages advancements in Large Language Models (LLMs) by proposing a fully automated method for generating a knowledge graph from unstructured data in help pages, which is then utilized to power a fully automated dialogue management system. By transitioning to a chat-based approach, our method aims to handle ambiguous, incomplete, or nonspecific inquiries more effectively and enhance customer satisfaction with tailored, natural responses. We also implement explicit safeguards to improve intent identification and prevent response hallucinations. We validate our proposal in the hotel industry, demonstrating that our knowledge graph based AI agent outperforms the baseline Retrieval-Augmented Generation (RAG) model in accuracy while facilitating more natural and coherent dialogues.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Varga, István and Yamashita, Yuta},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {automated customer support, automated dialogue management, conversational agent, knowledge graph generation},
	pages = {4319--4323},
}

@inproceedings{zhu_bridging_2025,
	address = {New York, NY, USA},
	series = {{LAK} '25},
	title = {Bridging the {Gender} {Gap}: {The} {Role} of {AI}-{Powered} {Math} {Story} {Creation} in {Learning} {Outcomes}},
	isbn = {979-8-4007-0701-8},
	url = {https://doi.org/10.1145/3706468.3706539},
	doi = {10.1145/3706468.3706539},
	abstract = {Addressing the gender gap in K-12 math education is essential for providing equitable learning opportunities, as historical disparities in engagement, performance, and confidence between male and female students in mathematics are often linked to educational biases. Integrating Generative AI (GAI) into math education shows promise for bridging the gender gap in K12 math learning. This study proposes an innovative pedagogy and platform that enables students to create math stories powered by GAI, enhancing their conceptual understanding of key mathematical ideas. The platform was implemented in two K5 schools to evaluate its effectiveness and mechanism (N = 86). Pre- and post-intervention surveys and usage logs indicated significant improvements in students’ learning outcomes regarding Math Question (MQ) skills and Math Story (MS) skills. Bayes SEM further modeled the mechanism: students’ creating math stories powered by GAI significantly improves MS, which further improves MQ. We further found female students were significantly more engaged in creating stories on this platform and gained more improvement on MQ than male students. The results suggest that AI-powered math story creation can be an effective tool for deepening students’ mathematical learning outcomes and has the potential to mitigate the gender gap.},
	booktitle = {Proceedings of the 15th {International} {Learning} {Analytics} and {Knowledge} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Zhu, Wangda and Xing, Wanli and Lyu, Bailing and Li, Chenglu and Zhang, Fan and Li, Hai},
	year = {2025},
	keywords = {Gender gap, Generative AI, Learning outcomes, Math story},
	pages = {918--923},
}

@inproceedings{lai_graphyour_2025,
	address = {New York, NY, USA},
	series = {{SIGMOD}/{PODS} '25},
	title = {Graphy'our {Data}: {Towards} {End}-to-{End} {Modeling}, {Exploring} and {Generating} {Report} from {Raw} {Data}},
	isbn = {979-8-4007-1564-8},
	url = {https://doi.org/10.1145/3722212.3725106},
	doi = {10.1145/3722212.3725106},
	abstract = {While Large Language Models (LLMs) excel at single-document queries and conversational workflows, they struggle with progressively exploring, analyzing, and synthesizing large unstructured document sets, such as in literature surveys. We address this challenge – termed Progressive Document Investigation – by introducing Graphy, an end-to-end platform that automates data modeling, exploration and high-quality report generation in a user-friendly manner. Graphy comprises an offline Scrapper that transforms raw documents into a graph, and an online Surveyor that enables iterative exploration and LLM-driven report generation. We showcase a pre-scrapped graph of over 50,000 papers, demonstrating how Graphy facilitates the literature-survey scenario, with video available at https://youtu.be/uM4nzkAdGlM.},
	booktitle = {Companion of the 2025 {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {Lai, Longbin and Luo, Changwei and Lou, Yunkai and Ju, Mingchen and Yang, Zhengyi},
	year = {2025},
	note = {event-place: Berlin, Germany},
	keywords = {document analysis, graph model, large language model},
	pages = {147--150},
}

@inproceedings{huly_old_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Old {IR} {Methods} {Meet} {RAG}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657935},
	doi = {10.1145/3626772.3657935},
	abstract = {Retrieval augmented generation (RAG) is an important approach to provide large language models (LLMs) with context pertaining to the text generation task: given a prompt, passages are retrieved from external corpora to ground the generation with more relevant and/or fresher data. Most previous studies used dense retrieval methods for applying RAG in question answering scenarios. However, recent work showed that traditional information retrieval methods (a.k.a. sparse methods) can do as well as or even better than dense retrieval ones. In particular, it was shown that Okapi BM25 outperforms dense retrieval methods, in terms of perplexity, for the fundamental text completion task in LLMs. We extend this study and show, using two popular LLMs, that a broad set of sparse retrieval methods achieve better results than all the dense retrieval methods we experimented with, for varying lengths of queries induced from the prompt. Furthermore, we found that Okapi BM25 is substantially outperformed by a term-proximity retrieval method (MRF), which is in turn outperformed by a pseudo-feedback-based bag-of-terms approach (relevance model). Additional exploration sheds some light on the effectiveness of lexical retrieval methods for RAG. Our findings call for further study of classical retrieval methods for RAG.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Huly, Oz and Pogrebinsky, Idan and Carmel, David and Kurland, Oren and Maarek, Yoelle},
	year = {2024},
	note = {event-place: Washington DC, USA},
	pages = {2559--2563},
}

@inproceedings{chan_dont_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Don't {Do} {RAG}: {When} {Cache}-{Augmented} {Generation} is {All} {You} {Need} for {Knowledge} {Tasks}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715490},
	doi = {10.1145/3701716.3715490},
	abstract = {Retrieval-augmented generation (RAG) has gained traction as a powerful approach for enhancing language models by integrating external knowledge sources. However, RAG introduces challenges such as retrieval latency, potential errors in document selection, and increased system complexity. With the advent of large language models (LLMs) featuring significantly extended context windows, this paper proposes an alternative paradigm, cache-augmented generation (CAG) that bypasses real-time retrieval. Our method involves preloading all relevant resources, especially when the documents or knowledge for retrieval are of a limited and manageable size, into the LLM's extended context and caching its runtime parameters. During inference, the model utilizes these preloaded parameters to answer queries without additional retrieval steps. Comparative analyses reveal that CAG eliminates retrieval latency and minimizes retrieval errors while maintaining context relevance. Performance evaluations across multiple benchmarks highlight scenarios where long-context LLMs either outperform or complement traditional RAG pipelines. These findings suggest that, for certain applications, particularly those with a constrained knowledge base, CAG provide a streamlined and efficient alternative to RAG, achieving comparable or superior results with reduced complexity.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Chan, Brian J. and Chen, Chao-Ting and Cheng, Jui-Hung and Huang, Hen-Hsen},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	pages = {893--897},
}

@inproceedings{niu_part_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{PaRT}: {Enhancing} {Proactive} {Social} {Chatbots} with {Personalized} {Real}-{Time} {Retrieval}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3731946},
	doi = {10.1145/3726302.3731946},
	abstract = {Social chatbots have become essential companions in daily scenarios ranging from emotional support to personal interaction. However, conventional chatbots with passive response mechanisms usually rely on users to initiate or sustain dialogues by bringing up new topics, resulting in diminished engagement and shortened dialogue duration. In this paper, we present PaRT, a novel framework enabling context-aware proactive dialogues for social chatbots through personalized real-time retrieval and generation. Specifically, PaRT first integrates user profiles and dialogue context into a large language model (LLM), which is initially prompted to refine user queries and recognize underlying intents for the upcoming conversation. Guided by refined intents, the LLM generates personalized dialogue topics as targeted queries to retrieve relevant passages from RedNote. Finally, we prompt LLMs with summarized passages to generate knowledge-grounded and engagement-optimized responses. Our approach has been running stably in a real-world production environment for more than 30 days, achieving a 21.77\% improvement in the average duration of dialogues.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Niu, Zihan and Xie, Zheyong and Cao, Shaosheng and Lu, Chonggang and Ye, Zheyu and Xu, Tong and Liu, Zuozhu and Gao, Yan and Chen, Jia and Xu, Zhe and Wu, Yi and Hu, Yao},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {llm, rag, social chatbot},
	pages = {4269--4274},
}

@inproceedings{wang_storyverse_2024,
	address = {New York, NY, USA},
	series = {{FDG} '24},
	title = {{StoryVerse}: {Towards} {Co}-authoring {Dynamic} {Plot} with {LLM}-based {Character} {Simulation} via {Narrative} {Planning}},
	isbn = {979-8-4007-0955-5},
	url = {https://doi.org/10.1145/3649921.3656987},
	doi = {10.1145/3649921.3656987},
	abstract = {Automated plot generation for games enhances the player’s experience by providing rich and immersive narrative experience. Recent advancements use Large Language Models (LLMs) to drive the behavior of virtual characters, allowing plots to emerge from interactions between characters and their environments. However, the emergent nature of such decentralized plot generation makes it difficult for authors to direct plot progression. We propose a novel plot creation workflow that mediates between a writer’s authorial intent and the emergent behaviors from LLM-driven character simulations, through a novel authorial structure called “abstract acts”. Writers create high-level plot outlines which are transformed into character actions via an LLM-based narrative planning process, based on the game world state. This results in narratives co-created by the author, the simulated characters, and the player. We present StoryVerse as a proof-of-concept system to demonstrate the workflow, and showcase its versatility across various stories and game environments.},
	booktitle = {Proceedings of the 19th {International} {Conference} on the {Foundations} of {Digital} {Games}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Yi and Zhou, Qian and Ledo, David},
	year = {2024},
	note = {event-place: Worcester, MA, USA},
	keywords = {Character Simulation, Generative AI, Large Language Models, Narrative Planning, Video games},
}

@inproceedings{rome_ask_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {"{Ask} {Me} {Anything}": {How} {Comcast} {Uses} {LLMs} to {Assist} {Agents} in {Real} {Time}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3661345},
	doi = {10.1145/3626772.3661345},
	abstract = {Customer service is how companies interface with their customers. It can contribute heavily towards the overall customer satisfaction. However, high-quality service can become expensive, creating an incentive to make it as cost efficient as possible and prompting most companies to utilize AI-powered assistants, or "chat bots". On the other hand, human-to-human interaction is still desired by customers, especially when it comes to complex scenarios such as disputes and sensitive topics like bill payment. This raises the bar for customer service agents. They need to accurately understand the customer's question or concern, identify a solution that is acceptable yet feasible (and within the company's policy), all while handling multiple conversations at once.In this work, we introduce "Ask Me Anything" (AMA) as an add-on feature to an agent-facing customer service interface. AMA allows agents to ask questions to a large language model (LLM) on demand, as they are handling customer conversations—the LLM provides accurate responses in real-time, reducing the amount of context switching the agent needs. In our internal experiments, we find that agents using AMA versus a traditional search experience spend approximately 10\% fewer seconds per conversation containing a search, translating to millions of dollars of savings annually. Agents that used the AMA feature provided positive feedback nearly 80\% of the time, demonstrating its usefulness as an AI-assisted feature for customer care.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Rome, Scott and Chen, Tianwen and Tang, Raphael and Zhou, Luwei and Ture, Ferhan},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {assistive ai, customer care, llm, rag, reranking, vector db},
	pages = {2827--2831},
}

@inproceedings{juan_co-trained_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Co-{Trained} {Retriever}-{Generator} {Framework} for {Question} {Generation} in {Earnings} {Calls}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715524},
	doi = {10.1145/3701716.3715524},
	abstract = {In diverse professional environments, ranging from academic conferences to corporate earnings calls, the ability to anticipate audience questions stands paramount. Traditional methods, which rely on manual assessment of an audience's background, interests, and subject knowledge, often fall short-particularly when facing large or heterogeneous groups, leading to imprecision and inefficiency. While NLP has made strides in text-based question generation, its primary focus remains on academic settings, leaving the intricate challenges of professional domains, especially earnings call conferences, underserved. Addressing this gap, our paper pioneers the multi-question generation (MQG) task specifically designed for earnings call contexts. Our methodology involves an exhaustive collection of earnings call transcripts and a novel annotation technique to classify potential questions. Furthermore, we introduce a retriever-enhanced strategy to extract relevant information. With a core aim of generating a spectrum of potential questions that analysts might pose, we derive these directly from earnings call content. Empirical evaluations underscore our approach's edge, revealing notable excellence in the accuracy, consistency, and perplexity of the questions generated.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Juan, Yining and Chen, Chung-Chi and Huang, Hen-Hsen and Chen, Hsin-Hsi},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {earnings calls, presentation preparation, question generation, retrieval-augmented generation},
	pages = {1048--1052},
}

@inproceedings{he_low-cost_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Low-{Cost} {Document} {Retrieval} with {Dense} {Pseudo}-{Query} {Encoding}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730227},
	doi = {10.1145/3726302.3730227},
	abstract = {Low-cost retrieval is crucial for document search on resource-limited computing platforms. This paper presents a staged sparse-to-dense retrieval framework that substitutes expensive dense query encoding with a dense pseudo-query (DPQ), an approximation derived solely from sparse retrieval results. DPQ scheme employs a simple, rank-aware weighting to combine corresponding dense representations of top sparse results, providing an opportunity to efficiently leverage an expensive but expressive LLM or BERT-based dense model without requiring GPUs. The evaluation demonstrates that DPQ-based retrieval runs fast on an affordable platform and outperforms several low-cost baselines in zero-shot retrieval.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {He, Shanxiu and Xie, Wentai and Qiao, Yifan and Carlson, Parker and Yang, Tao},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {efficiency, hybrid search, large language model},
	pages = {2987--2993},
}

@inproceedings{zhang_knowledge-based_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {Knowledge-{Based} {Multi}-{Agent} {Framework} for {Automated} {Software} {Architecture} {Design}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3728493},
	doi = {10.1145/3696630.3728493},
	abstract = {Architecture design is a critical step in software development. However, creating a high-quality architecture is often costly due to the significant need for human expertise and manual effort. Recently, agents built upon Large Language Models (LLMs) have achieved remarkable success in various software engineering tasks. Despite this progress, the use of agents to automate the architecture design process remains largely unexplored. To address this gap, we envision a Knowledge-based Multi-Agent Architecture Design (MAAD) framework. MAAD uses agents to simulate human roles in the traditional software architecture design process, thereby automating the design process. To empower these agents, MAAD incorporates knowledge extracted from three key sources: 1) existing system designs, 2) authoritative literature, and 3) architecture experts. By envisioning the MAAD framework, we aim to advance the full automation of application-level system development.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Yiran and Li, Ruiyin and Liang, Peng and Sun, Weisong and Liu, Yang},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {large language model, multi-agent system, software architecture},
	pages = {530--534},
}

@inproceedings{bai_insight_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Insight {Agents}: {An} {LLM}-{Based} {Multi}-{Agent} {System} for {Data} {Insights}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3731959},
	doi = {10.1145/3726302.3731959},
	abstract = {Today, E-commerce sellers face several key challenges, including difficulties in discovering and effectively utilizing available programs and tools, and struggling to understand and utilize rich data from various tools. We therefore aim to develop Insight Agents (IA), a conversational multi-agent Data Insight system, to provide E-commerce sellers with personalized data and business insights through automated information retrieval. Our hypothesis is that IA will serve as a force multiplier for sellers, thereby driving incremental seller adoption by reducing the effort required and increase speed at which sellers make good business decisions. In this paper, we introduce this new LLM-backed end-to-end agentic workflow designed for comprehensive coverage, high accuracy, and low latency. It features a hierarchical multi-agent structure, consisting of manager agent and two worker agents: data presentation and insight generation, for efficient information retrieval and problem-solving. We design a simple yet effective ML solution for manager agent that combines Out-of-Domain (OOD) detection using a lightweight encoder-decoder model and agent routing through a BERT-based classifier, optimizing both accuracy and latency. Within the two worker agents, a strategic planning is designed for API-based data model that breaks down queries into granular components to generate more accurate responses, and domain knowledge is dynamically injected to to enhance the insight generator. IA has been launched for Amazon sellers in US, which has achieved high accuracy of 89.5\% based on human evaluation, with latency of P90 below 15s.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Bai, Jincheng and Zhang, Zhenyu and Zhang, Jennifer and Zhu, Jason},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {agentic workflow, information retrieval, llm, rag},
	pages = {4335--4339},
}

@inproceedings{sarmah_towards_2024,
	address = {New York, NY, USA},
	series = {{AIMLSystems} '23},
	title = {Towards reducing hallucination in extracting information from financial reports using {Large} {Language} {Models}},
	isbn = {979-8-4007-1649-2},
	url = {https://doi.org/10.1145/3639856.3639895},
	doi = {10.1145/3639856.3639895},
	abstract = {For a financial analyst, the question and answer (Q\&amp;A) segment of the company financial report is a crucial piece of information for various analysis and investment decisions. However, extracting valuable insights from the Q\&amp;A section has posed considerable challenges as the conventional methods such as detailed reading and note-taking lack scalability and are susceptible to human errors, and Optical Character Recognition (OCR) and similar techniques encounter difficulties in accurately processing unstructured transcript text, often missing subtle linguistic nuances that drive investor decisions. Here, we demonstrate the utilization of Large Language Models (LLMs) to efficiently and rapidly extract information from earnings report transcripts while ensuring high accuracy—transforming the extraction process as well as reducing hallucination by combining retrieval-augmented generation technique as well as metadata. We evaluate the outcomes of various LLMs with and without using our proposed approach based on various objective metrics for evaluating Q\&amp;A systems, and empirically demonstrate superiority of our method.},
	booktitle = {Proceedings of the {Third} {International} {Conference} on {AI}-{ML} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Sarmah, Bhaskarjit and Mehta, Dhagash and Pasquali, Stefano and Zhu, Tianjie},
	year = {2024},
	note = {event-place: Bangalore, India},
	keywords = {Earning Call Transcripts, Financial Markets, Large Language Models, Natural Language Processing},
}

@inproceedings{sun_docs2kg_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{Docs2KG}: {A} {Human}-{LLM} {Collaborative} {Approach} to {Unified} {Knowledge} {Graph} {Construction} from {Heterogeneous} {Documents}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715309},
	doi = {10.1145/3701716.3715309},
	abstract = {Enterprises generate vast amounts of unstructured documents, posing challenges for knowledge extraction and representation. Large language models (LLMs) offer strong potential for processing such data but struggle with factual accuracy and provenance. Knowledge graphs (KGs) provide a structured framework to address these limitations [6], yet constructing high-quality KGs from heterogeneous data remains a challenge. To address this issue, we present Docs2KG, a modular framework to build high-quality KGs from diverse unstructured documents. We first employs state-of-the-art document processing techniques to extract textual content, tabular data, and figures. The extracted information is then unified into a multifaceted KG with three aspects: (1) a Layout KG capturing document structural hierarchies, (2) a Metadata KG preserving document properties, and (3) a Semantic KG representing domain-specific entities and relationships. Docs2KG supports multiple construction paradigms for Semantic KG: ontology-based approaches, hybrid NLP pipelines with LLM verification, LLM-guided ontology generation, and specialized models for named entity recognition, event extraction, and causal relationship identification to enhance semantic coverage and accuracy. A key feature of Docs2KG is its human-in-the-loop verification interface, enabling iterative quality assessment and refinement of the resulting KGs. Docs2KG is openly available at https://docs2kg.ai4wa.com, with the aim of advancing knowledge graph construction research and accelerating enterprise applications through high-quality knowledge graph construction.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Sun, Qiang and Luo, Yuanyi and Zhang, Wenxiao and Li, Sirui and Li, Jichunyang and Niu, Kai and Kong, Xiangrui and Liu, Wei},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {heterogeneous data, knowledge graph, unstructured data},
	pages = {801--804},
}

@inproceedings{ugarte_astral_2025,
	address = {New York, NY, USA},
	series = {{ISSTA} {Companion} '25},
	title = {{ASTRAL}: {A} {Tool} for the {Automated} {Safety} {Testing} of {Large} {Language} {Models}},
	isbn = {979-8-4007-1474-0},
	url = {https://doi.org/10.1145/3713081.3731733},
	doi = {10.1145/3713081.3731733},
	abstract = {In this paper, we present ASTRAL, a tool that automates the generation and execution of test inputs (i.e., prompts) to evaluate the safety of Large Language Models (LLMs). ASTRAL consists of three microservice modules. The first is a test generator, which employs a novel black-box coverage criterion to create balanced and diverse unsafe test inputs across a wide range of safety categories and linguistic characteristics (e.g., different writing styles and persuasion techniques). Additionally, the test generator incorporates an LLM-based approach that leverages Retrieval-Augmented Generation (RAG), few-shot prompting strategies, and web browsing to produce up-to-date test inputs. The second module is the test executor, which runs the generated test inputs on the LLM under test. Finally, the test evaluator acts an oracle to assess the execution outputs to identify unsafe responses, enabling a fully automated LLM testing process.},
	booktitle = {Proceedings of the 34th {ACM} {SIGSOFT} {International} {Symposium} on {Software} {Testing} and {Analysis}},
	publisher = {Association for Computing Machinery},
	author = {Ugarte, Miriam and Valle, Pablo and Parejo, José Antonio and Segura, Sergio and Arrieta, Aitor},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {automated testing, LLMs, safety},
	pages = {31--35},
}

@inproceedings{ma_fine-tuning_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Fine-{Tuning} {LLaMA} for {Multi}-{Stage} {Text} {Retrieval}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657951},
	doi = {10.1145/3626772.3657951},
	abstract = {While large language models (LLMs) have shown impressive NLP capabilities, existing IR applications mainly focus on prompting LLMs to generate query expansions or generating permutations for listwise reranking. In this study, we leverage LLMs directly to serve as components in the widely used multi-stage text ranking pipeline. Specifically, we fine-tune the open-source LLaMA-2 model as a dense retriever (repLLaMA) and a pointwise reranker (rankLLaMA). This is performed for both passage and document retrieval tasks using the MS MARCO training data. Our study shows that finetuned LLM retrieval models outperform smaller models. They are more effective and exhibit greater generalizability, requiring only a straightforward training strategy. Moreover, our pipeline allows for the fine-tuning of LLMs at each stage of a multi-stage retrieval pipeline. This demonstrates the strong potential for optimizing LLMs to enhance a variety of retrieval tasks. Furthermore, as LLMs are naturally pre-trained with longer contexts, they can directly represent longer documents. This eliminates the need for heuristic segmenting and pooling strategies to rank long documents. On the MS MARCO and BEIR datasets, our repLLaMA-rankLLaMA pipeline demonstrates a high level of effectiveness.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Ma, Xueguang and Wang, Liang and Yang, Nan and Wei, Furu and Lin, Jimmy},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {dense retrieval, large language model, reranker},
	pages = {2421--2425},
}

@inproceedings{shen_retrieval-augmented_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Retrieval-{Augmented} {Image} {Captioning} and {Generation} with {Entity} {Concepts} {Enhancement} for {Baidu} {Multimodal} {Advertising}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3731957},
	doi = {10.1145/3726302.3731957},
	abstract = {Recent advancements in generative artificial intelligence are driving a significant transformation in information retrieval and content generation, creating substantial opportunities for online advertising. Text-to-image generation technology has become increasingly prevalent in advertising content production, demonstrating promising performance improvements in terms of semantic relevance and visual appeal. However, existing models often suffer from inadequate representation of entity concepts, such as prominent product brands and recognizable landmarks. This inherent limitation subsequently leads to notable deficiencies in brand tonality, industry-specific relevance, and market adaptability of the generated advertising content. To address this challenge, we propose a multimodal ad content generation framework specifically engineered for online advertising system, particularly focused on resolving the deficiency in entity concepts. Our framework is comprised of two phases: first, an image captioning module with entity-aware learning based on multimodal large language model, leveraging retrieval-augmented techniques to incorporate entity concepts into image descriptions; second, a text-to-image diffusion model refined on image-text pairs enriched with entity concepts to facilitate entity-grounded image generation. Extensive experiments validate the effectiveness of our framework, demonstrating superior performance in both image captioning and image generation compared to existing methods, particularly in the accuracy of depiction of relevant entities in advertising images. Moreover, the deployment of the framework in the system primary traffic of Baidu Search Ads, has brought significant enhancements to advertisement revenue for both advertisers and the platform.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Shen, Lei and Zhao, Kang and Jin, Zhipeng and Tao, Wen and Yang, Yi and Han, Cong and Li, Shuanglong and Cai, Zhongmin and Liu, Lin},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {image captioning, multimodal large language model, search advertising, text-to-image generation},
	pages = {4324--4328},
}

@inproceedings{zhang_modelgalaxy_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {{ModelGalaxy}: {A} {Versatile} {Model} {Retrieval} {Platform}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657676},
	doi = {10.1145/3626772.3657676},
	abstract = {With the growing number of available machine learning models and the emergence of model-sharing platforms, model reuse has become a significant approach to harnessing the power of artificial intelligence. One of the key issues to realizing model reuse resides in efficiently and accurately finding the target models that meet user needs from a model repository. However, the existing popular model-sharing platforms (e.g., Hugging Face) mainly support model retrieval based on model name matching and task filtering. If not familiar with the platform or specific models, users may suffer from low retrieval efficiency and a less user-friendly interaction experience. To address these issues, we have developed ModelGalaxy, a versatile model retrieval platform supporting multiple model retrieval methods, including keyword-based search, dataset-based search, and user-task-centric search. Moreover, ModelGalaxy leverages the power of large language models to provide users with easily retrieving and using models. Our source code is available at https://github.com/zwl906711886/ModelGalaxy.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Wenling and Li, Yixiao and Li, Zhaotian and Sun, Hailong and Gao, Xiang and Liu, Xudong},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {large language model, meta-learning, model retrieval},
	pages = {2771--2775},
}

@inproceedings{ngom_mallet_2024,
	address = {New York, NY, USA},
	series = {{aiDM} '24},
	title = {Mallet: {SQL} {Dialect} {Translation} with {LLM} {Rule} {Generation}},
	isbn = {979-8-4007-0680-6},
	url = {https://doi.org/10.1145/3663742.3663973},
	doi = {10.1145/3663742.3663973},
	abstract = {Translating between the SQL dialects of different systems is important for migration and federated query processing. Existing approaches rely on hand-crafted translation rules, which tend to be incomplete and hard to maintain, especially as the number of dialects to translate increases. Thus, dialect translation remains a largely unsolved problem.To address this issue, we introduce Mallet, a system that leverages Large Language Models (LLMs) to automate the generation of SQL-to-SQL translation rules, namely schema conversion, automated UDF generation, extension selection, and expression composition. Once the rules are generated, they are infinitely reusable on new workloads without putting the LLM on the critical path of query execution. Mallet enhances the accuracy of the LLMs by (1) performing retrieval augmented generation (RAG) over system documentation and human expertise, (2) subjecting the rules to empirical validation using the actual SQL systems to detect hallucinations, and (3) automatically creating accurate few-shot learning instances. Contributors, without knowing the system's code, can improve Mallet by providing natural-language expertise for RAG.},
	booktitle = {Proceedings of the {Seventh} {International} {Workshop} on {Exploiting} {Artificial} {Intelligence} {Techniques} for {Data} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Ngom, Amadou Latyr and Kraska, Tim},
	year = {2024},
	note = {event-place: Santiago, AA, Chile},
}

@inproceedings{frey_pots_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{POTS} - {A} {Polyparadigmatic} {Ontology} {Term} {Search} with {Fine}-{Grained} {Context} {Steering} using {Hyper}-{Level} {Vector} {Spaces}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715194},
	doi = {10.1145/3701716.3715194},
	abstract = {We present a novel microservice-based system, that facilitates a polyparadigmatic ontology term search (leveraging semantic search via vector embeddings, keyword search, and attribute filters). The search index strategy intends to preserve important semantic aspects of the ontological context of a term (selected attributes and term relationships) using structured search fields and multilevel vector spaces assembling hyper-level vector spaces. The flexible, yet simple query API allows fine-grained search requests based on a combination of fuzzy and exact filters. The architecture is based on a highly automatable and flexible Docker Compose setup strategy. While deploying the system for a local ontology is only one command away, the setup also allows ingesting a configurable subset of over 1,800 published ontologies in over 12,000 versions via DBpedia Archivo.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Frey, Johannes and Ferraz, Lucas and Hofer, Marvin},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {graph retrieval augmented generation, llms, ontology, ontology retrieval, ontology terms embedding, owl, semantic search, terminology lookup service},
	pages = {2831--2834},
}

@inproceedings{van_schaik_field_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {A {Field} {Guide} to {Automatic} {Evaluation} of {LLM}-{Generated} {Summaries}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3661346},
	doi = {10.1145/3626772.3661346},
	abstract = {Large Language models (LLMs) are rapidly being adopted for tasks such as text summarization, in a wide range of industries. This has driven the need for scalable, automatic, reliable, and cost-effective methods to evaluate the quality of LLM-generated text. What is meant by evaluating an LLM is not yet well defined and there are widely different expectations about what kind of information evaluation will produce. Evaluation methods that were developed for traditional Natural Language Processing (NLP) tasks (before the rise of LLMs) remain applicable but are not sufficient for capturing high-level semantic qualities of summaries. Emerging evaluation methods that use LLMs to evaluate LLM-output, appear to be powerful but lacking in reliability. New elements of LLM generated text that were not an element of previous NLP tasks, such as the artifacts of hallucination, need to be considered. We outline the different types of LLM evaluation currently used in the literature but focus on offline, system-level evaluation of the text generated by LLMs. Evaluating LLM-generated summaries is a complex and fast-evolving area, and we propose strategies for applying evaluation methods to avoid common pitfalls. Despite having promising strategies for evaluating LLM summaries, we highlight some open challenges that remain.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {van Schaik, Tempest A. and Pugh, Brittany},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {evaluation metrics, llms, offline evaluation, summarization},
	pages = {2832--2836},
}

@inproceedings{buchmann_white-box_2024,
	address = {New York, NY, USA},
	series = {{MODELS} {Companion} '24},
	title = {White-box {LLM}-supported {Low}-code {Engineering}: {A} {Vision} and {First} {Insights}},
	isbn = {979-8-4007-0622-6},
	url = {https://doi.org/10.1145/3652620.3687803},
	doi = {10.1145/3652620.3687803},
	abstract = {Low-code development (LCD) platforms promise to empower citizen developers to define core domain models and rules for business applications. However, as domain rules grow complex, LCD platforms may fail to do so effectively. Generative AI, driven by large language models (LLMs), offers source code generation from natural language but suffers from its non-deterministic black-box nature and limited explainability. Therefore, rather than having LLMs generate entire applications from single prompts, we advocate for a white-box approach allowing citizen developers to specify domain models semi-formally, attaching constraints and operations as natural language annotations. These annotations are fed incrementally into an LLM contextualized with the generated application stub. This results in deterministic and better explainable generation of static application components, while offering citizen developers an appropriate level of abstraction. We report on a case study in manufacturing execution systems, where the implementation of the approach provides first insights.},
	booktitle = {Proceedings of the {ACM}/{IEEE} 27th {International} {Conference} on {Model} {Driven} {Engineering} {Languages} and {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Buchmann, Thomas and Peinl, René and Schwägerl, Felix},
	year = {2024},
	note = {event-place: Linz, Austria},
	keywords = {artificial intelligence, large language models, low-code, model-driven engineering, semiformal},
	pages = {556--560},
}

@inproceedings{venkatakrishnan_semantic_2024,
	address = {New York, NY, USA},
	series = {{WWW} '24},
	title = {Semantic interlinking of {Immigration} {Data} using {LLMs} for {Knowledge} {Graph} {Construction}},
	isbn = {979-8-4007-0172-6},
	url = {https://doi.org/10.1145/3589335.3651557},
	doi = {10.1145/3589335.3651557},
	abstract = {The challenge of managing immigration data is exacerbated by its reliance on paper-based, evidence-driven records maintained by legal professionals, creating obstacles for efficient processing and analysis due to inherent trust issues with AI-based systems. This paper introduces a cutting-edge framework to surmount these hurdles by synergizing Large Language Models (LLMs) with Knowledge Graphs (KGs), revolutionizing traditional data handling methods. Our method transforms archaic, paper-based immigration records into a structured, interconnected knowledge network that intricately mirrors the legal and procedural nuances of immigration, ensuring a dynamic and trustworthy platform for data analysis. Utilizing LLMs, we extract vital entities and relationships from diverse legal documents to forge a comprehensive knowledge graph, encapsulating the complex legalities and procedural disparities in immigration processes and mapping the multifaceted interactions among stakeholders like applicants, sponsors, and legal experts. This graph not only facilitates a deep dive into the legal stipulations but also incorporates them, significantly boosting the system's reliability and precision. With the integration of Retrieval Augmented Generation (RAG) for exact, context-aware data retrieval and Augmented Knowledge Creation for developing a conversational interface via LLMs, our framework offers a scalable, adaptable solution to immigration data management. This innovative amalgamation of LLMs, KGs, and RAG techniques marks a paradigm shift towards more informed, efficient, and trustworthy decision-making in the sphere of global migration, setting a new benchmark for legal technology and data source management.},
	booktitle = {Companion {Proceedings} of the {ACM} {Web} {Conference} 2024},
	publisher = {Association for Computing Machinery},
	author = {Venkatakrishnan, Radhakrishnan and Tanyildizi, Emrah and Canbaz, M. Abdullah},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	keywords = {data restructuring, document processing, information retrieval, knowledge graphs, large language models, legal tech},
	pages = {605--608},
}

@inproceedings{tian_template-based_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Template-{Based} {Financial} {Report} {Generation} in {Agentic} and {Decomposed} {Information} {Retrieval}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730253},
	doi = {10.1145/3726302.3730253},
	abstract = {Tailoring structured financial reports from companies' earnings releases is crucial for understanding financial performance and has been widely adopted in real-world analytics. However, existing summarization methods often generate broad, high-level summaries, which may lack the precision and detail required for financial reports that typically focus on specific, structured sections. While Large Language Models (LLMs) hold promise, generating reports adhering to predefined multi-section templates remains challenging. This paper investigates two LLM-based approaches popular in industry for generating templated financial reports: an agentic information retrieval (IR) framework and a decomposed IR approach, namely AgenticIR and DecomposedIR. The AgenticIR utilizes collaborative agents prompted with the full template. In contrast, the DecomposedIR approach applies a prompt chaining workflow to break down the template and reframe each section as a query answered by the LLM using the earnings release. To quantitatively assess the generated reports, we evaluated both methods in two scenarios: one using a financial dataset without direct human references, and another with a weather-domain dataset featuring expert-written reports. Experimental results show that while AgenticIR may excel in orchestrating tasks and generating concise reports through agent collaboration, DecomposedIR statistically significantly outperforms AgenticIR approach in providing broader and more detailed coverage in both scenarios, offering reflection on the utilization of the agentic framework in real-world applications.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Tian, Yong-En and Tang, Yu-Chien and Wang, Kuang-Da and Yen, An-Zi and Peng, Wen-Chih},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {agentic framework, decomposed prompting, large language model, template-based financial report generation},
	pages = {2706--2710},
}

@inproceedings{wang_paperping_2025,
	address = {New York, NY, USA},
	series = {{CSCW} {Companion} '25},
	title = {{PaperPing}: {A} {Socially}-aware {AI} {Agent} that {Recommends} {Academic} {Papers} to {Research} {Group} {Chats} with {Contextualized} {Explanations}},
	isbn = {979-8-4007-1480-1},
	url = {https://doi.org/10.1145/3715070.3757230},
	doi = {10.1145/3715070.3757230},
	abstract = {AI agents are entering group spaces to facilitate or contribute to conversations. However, without an understanding of group context, these contributions can be irrelevant or even intrusive. In this demo, we introduce a socially-aware AI agent that proactively contributes to research group chats by posting context-aware messages that contain paper recommendations and contextualized explanations. To achieve this, PaperPing instantiates Social-RAG\&nbsp;[14]. It retrieves relevant interactions in the group context, builds a social knowledge base, and extracts social signals to contextualize the generated messages. PaperPing has been deployed in 18 channels as part of a user study for at least 3 months, reaching 500+ researchers. As part of the demo, we will demonstrate PaperPing in a Slack workspace open to all CSCW attendees during and after the conference, allowing researchers to explore the interactions in real settings with the side benefits of fostering collaborative learning within the community.},
	booktitle = {Companion {Publication} of the 2025 {Conference} on {Computer}-{Supported} {Cooperative} {Work} and {Social} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Ruotong and Zhou, Xinyi and Qiu, Lin and Chang, Joseph Chee and Bragg, Jonathan and Zhang, Amy X.},
	year = {2025},
	keywords = {AI agent, group communication, large language models, recommender systems, retrieval augmented generation},
	pages = {532--535},
}

@inproceedings{zhao_ontology-guided_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Ontology-{Guided} {Knowledge} {Graph} {Retrieval} for {Multi}-{Hop} and {Cross}-{Granularity} {Store} {Fulfillment} {Queries}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3731964},
	doi = {10.1145/3726302.3731964},
	abstract = {Answering complex queries in store fulfillment, such as ”What percentage of employee-assigned actions remain unresolved?” or ”How many worklists for a specific product type were completed within a timeframe at each location?” requires precise, multi-hop reasoning across datasets with varying granularities. This paper introduces an ontology-based knowledge graph (KG) approach integrated with a structured text-to-Cypher generation pipeline, enabling accurate retrieval for such queries. Benchmarking against a robust hybrid search baseline combining BM25 and semantic search, our method demonstrates superior performance in addressing multi-hop and cross-granularity questions. Leveraging a KG schema designed to capture intricate relationships (e.g. (OrderLineItem)-[:INVOLVES\_ACTION]-\&gt;(Action)-[:INVOLVES]-\&gt;(BatchProcess)-[:IS\_COMPLETED\_AT]-\&gt;(Location)), we reveal universal patterns for constructing and querying highly relational data. This work highlights the transformative potential of ontology-driven KGs to improve reasoning, data aggregation, and decision-making, with broader implications for any domain requiring structured, multi-relational data analysis.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zhao, Mengyue and Nokleby, Matthew and Shen, Bo and Dong, Wenbo and Pachauri, Deepti and Yang, Andrew},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {hybrid search, knowledge graph, large language model, multi-hop reasoning, natural language processing, ontology-driven retrieval, store fulfillment., text-to-cypher},
	pages = {4360--4364},
}

@inproceedings{zhang_automating_2024,
	address = {New York, NY, USA},
	series = {{SIGSPATIAL} '24},
	title = {Automating {Geospatial} {Analysis} {Workflows} {Using} {ChatGPT}-4},
	isbn = {979-8-4007-1107-7},
	url = {https://doi.org/10.1145/3678717.3695760},
	doi = {10.1145/3678717.3695760},
	abstract = {The field of Geospatial Artificial Intelligence (GeoAI) has significantly impacted domain applications such as urban analytics, environmental monitoring, and disaster management. While powerful geoprocessing tools in geographic information systems (GIS) like ArcGIS Pro are available, automating these workflows with Python scripting using AI chatbots remains a challenge, especially for non-expert users. This study investigates whether ChatGPT-4 can automate GIS workflows by generating ArcPy functions based on structured instructions. We tested prompt engineering's ability on helping large language models (LLMs) understand spatial data and GIS workflows. The overall task success rate reaches 80.5\%. It is a valid and easy to implement approach for domain scientists who want to use ArcPy to automate their workflows.},
	booktitle = {Proceedings of the 32nd {ACM} {International} {Conference} on {Advances} in {Geographic} {Information} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Qianheng and Gao, Song},
	year = {2024},
	note = {event-place: Atlanta, GA, USA},
	keywords = {automate workflow, GeoAI, GIS, LLM, Prompt engineering},
	pages = {715--716},
}

@inproceedings{zhou_dataset_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Dataset for {Industrial} {Question} {Answering} with {Explanation} and {Scalable} {Ensemble} {Generation}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715310},
	doi = {10.1145/3701716.3715310},
	abstract = {The digital and green transition under Industry 4.0 has accelerated the adoption of AI in industries such as manufacturing, energy, and mining. Question Answering with Explanation (QAE), as a way of human interaction with AI, is crucial for enhancing transparency and trust in high-stakes industrial applications. However, industrial QAE remains underexplored due to the lack of publicly available, high-quality datasets, hindered by the need for expert effort and corporate restrictions. To this end, we introduce PANDAX ( https://doi.org/10.5281/zenodo.14510798 ), the first open-source industrial QAE dataset, and SEG, a scalable method for generating high-quality QAE datasets using LLMs. PANDAX focuses on three key topics of industrial system information: partonomy, functionality, and parameters, across critical domains such as green technology and cooling systems. SEG ensures scalability and quality through ensemble generation, majority voting, expert ranking, etc. The human evaluation validates PANDAX's high quality, positioning it as a valuable resource for advancing QAE techniques, benchmarking language technologies, and supporting research in explainable AI for industrial systems.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Zhou, Yan and Zhou, Baifan and Li, Huajian and Lyu, Qianhang and Qu, Yuanwei and Waaler, Arild and Yu, Ingrid C.},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {dataset generation, industrial dataset resource, question answering with explanation, system information},
	pages = {825--828},
}

@inproceedings{diaz-de-arcaya_towards_2024,
	address = {New York, NY, USA},
	series = {{APR} '24},
	title = {Towards the self-healing of {Infrastructure} as {Code} projects using constrained {LLM} technologies},
	isbn = {979-8-4007-0577-9},
	url = {https://doi.org/10.1145/3643788.3648014},
	doi = {10.1145/3643788.3648014},
	abstract = {The generalization of the use of cloud computing and edge computing solutions in industry requires innovative techniques to keep up with the complexity of these scenarios. In particular, the large heterogeneity of the infrastructural devices and the myriad of services offered by the various private and cloud providers represent a challenge. Infrastructure as Code (IaC) technologies have been adopted to reduce the complexity of these scenarios, but even IaC technologies have their drawbacks, as the errors resulting from their use often combine the complexities of the underlying layers and require a high level of expertise. In this regard, the recent upsurge of Large Language Models represents an opportunity as they are able to tackle different problems. In this article, we aspire to shed light on the automated patching of IaC projects with the help of LLMs. We evaluate the suitability of this hypothesis by using a well-known LLM that is able to solve all the scenarios we envisioned and assess the possibility of doing the same with smaller, offline LLMs, which could lead to the use of these technologies in resource-constrained environments, such as edge computing.},
	booktitle = {Proceedings of the 5th {ACM}/{IEEE} {International} {Workshop} on {Automated} {Program} {Repair}},
	publisher = {Association for Computing Machinery},
	author = {Diaz-De-Arcaya, Josu and López-De-Armentia, Juan and Zárate, Gorka and Torre-Bastida, Ana I.},
	year = {2024},
	note = {event-place: Lisbon, Portugal},
	keywords = {automated patching, IaC, infrastructure as code, large language models, LLMs, self-healing},
	pages = {22--25},
}

@inproceedings{zhao_best_2025,
	address = {New York, NY, USA},
	series = {{ISSTA} {Companion} '25},
	title = {Best practice for supply chain in {LLM}-assisted medical applications},
	isbn = {979-8-4007-1474-0},
	url = {https://doi.org/10.1145/3713081.3731748},
	doi = {10.1145/3713081.3731748},
	abstract = {The application of large language models in medical applications is crucial for enhancing diagnostic accuracy, improving patient communication, and boosting healthcare efficiency. Their ability to process vast amounts of data, generate concise information, and automate tasks positions LLM applications as transformative tools. Recent studies and real-world examples underscore the importance of delivering secure and responsible LLM-assisted applications. In this manuscript, we outline our intention of uncovering best software practices in the supply chain of LLM medical applications.},
	booktitle = {Proceedings of the 34th {ACM} {SIGSOFT} {International} {Symposium} on {Software} {Testing} and {Analysis}},
	publisher = {Association for Computing Machinery},
	author = {Zhao, Shengming and Wang, Jiawei},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {large language models, medical system, software best practice, software supply chain},
	pages = {174--177},
}

@inproceedings{galitsky_truth-o-meter_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Truth-{O}-{Meter}: {Handling} {Multiple} {Inconsistent} {Sources} {Repairing} {LLM} {Hallucinations}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657679},
	doi = {10.1145/3626772.3657679},
	abstract = {Large Language Models (LLM) often produce text with incorrect facts and hallucinations. To address this issue, we developed a fact-checking system Truth-O-Meter12 which verifies LLM results on the Internet and other sources of information to detect wrong claims/facts and proposes corrections for them. NLP and reasoning techniques such as Abstract Meaning Representation and syntactic alignment are applied to match hallucinating sentences with truthful ones. To handle inconsistent sources while fact-checking, we rely on argumentation analysis in the form of defeasible logic programming, selecting the most authoritative source. Our evaluation shows that LLM content can be substantially improved for factual correctness and meaningfulness on an industrial scale.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Galitsky, Boris and Chernyavskiy, Anton and Ilvovsky, Dmitry},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {evidence retrieval, fact-checking, hallucinations detection, llms},
	pages = {2817--2821},
}

@inproceedings{zinjad_resumeflow_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {{ResumeFlow}: {An} {LLM}-facilitated {Pipeline} for {Personalized} {Resume} {Generation} and {Refinement}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657680},
	doi = {10.1145/3626772.3657680},
	abstract = {Crafting the ideal, job-specific resume is a challenging task for many job applicants, especially for early-career applicants. While it is highly recommended that applicants tailor their resume to the specific role they are applying for, manually tailoring resumes to job descriptions and role-specific requirements is often (1) extremely time-consuming, and (2) prone to human errors. Furthermore, performing such a tailoring step at scale while applying to several roles may result in a lack of quality of the edited resumes. To tackle this problem, in this demo paper, we propose ResumeFlow: a Large Language Model (LLM) aided tool that enables an end user to simply provide their detailed resume and the desired job posting, and obtain a personalized resume specifically tailored to that specific job posting in the matter of a few seconds. Our proposed pipeline leverages the language understanding and information extraction capabilities of state-of-the-art LLMs such as OpenAI's GPT-4 and Google's Gemini, in order to (1) extract details from a job description, (2) extract role-specific details from the user-provided resume, and then (3) use these to refine and generate a role-specific resume for the user. Our easy-to-use tool leverages the user-chosen LLM in a completely off-the-shelf manner, thus requiring no fine-tuning. We demonstrate the effectiveness of our tool via a https://www.youtube.com/watch?v=Agl7ugyu1N4 and propose novel task-specific evaluation metrics to control for alignment and hallucination. Our tool is available at https://job-aligned-resume.streamlit.app.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zinjad, Saurabh Bhausaheb and Bhattacharjee, Amrita and Bhilegaonkar, Amey and Liu, Huan},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {ai persona, automated resume generation, information extraction, large language models, personalization, prompt engineering},
	pages = {2781--2785},
}

@inproceedings{bayer_towards_2025,
	address = {New York, NY, USA},
	series = {{TDIS} '25},
	title = {Towards {A} {Modular} {End}-{To}-{End} {Machine} {Learning} {Benchmarking} {Framework}},
	isbn = {979-8-4007-1526-6},
	url = {https://doi.org/10.1145/3719159.3721223},
	doi = {10.1145/3719159.3721223},
	abstract = {Machine learning (ML) benchmarks are crucial for evaluating the performance, efficiency, and scalability of ML systems, especially as the adoption of complex ML pipelines, such as retrieval-augmented generation (RAG), continues to grow. These pipelines introduce intricate execution graphs that require more advanced benchmarking approaches. Additionally, collocating workloads can improve resource efficiency but may introduce contention challenges that must be carefully managed. Detailed insights into resource utilization are necessary for effective collocation and optimized edge deployments. However, existing benchmarking frameworks often fail to capture these critical aspects.We introduce a modular end-to-end ML benchmarking framework designed to address these gaps. Our framework emphasizes modularity and reusability by enabling reusable pipeline stages, facilitating flexible benchmarking across diverse ML workflows. It supports complex workloads and measures their end-to-end performance. The workloads can be collocated, with the framework providing insights into resource utilization and contention between the concurrent workloads.},
	booktitle = {Proceedings of the 3rd {International} {Workshop} on {Testing} {Distributed} {Internet} of {Things} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Bayer, Robert and Robroek, Ties and Tözün, Pinar},
	year = {2025},
	note = {event-place: Rotterdam, Netherlands},
	keywords = {Benchmarking, Deep Learning, Edge Computing},
	pages = {23--26},
}

@inproceedings{yu_biasnavi_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{BiasNavi}: {LLM}-{Empowered} {Data} {Bias} {Management}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715169},
	doi = {10.1145/3701716.3715169},
	abstract = {Bias in datasets undermines the fairness, transparency, and reliability of AI systems, presenting critical challenges across applications. Existing tools for managing data bias often remain inaccessible to non-experts or struggle with the complexities of domain-specific datasets. In this work, we introduce BiasNavi, an large language models (LLM)-empowered toolkit for data bias management. BiasNavi features an autonomous agent that seamlessly integrates with modules for bias identification, measurement, surfacing, and adaptation, reasoning over data and interactions to adaptively guide users through the bias management pipeline. With intuitive and personalized interfaces, BiasNavi empowers users to customize their workflows and address data bias effectively. A case study with the COMPAS dataset demonstrates how BiasNavi, by leveraging the advanced reasoning capabilities of LLMs, democratizes responsible AI practices, making bias management both accessible and effective for users with varying levels of expertise. BiasNavi is available at: https://github.com/CIRES-Hub/BiasNavi.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Yu, Junliang and Huynh, Jay Thai Duong and Fan, Shaoyang and Demartini, Gianluca and Chen, Tong and Yin, Hongzhi and Sadiq, Shazia},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {agent, bias management, data management, large language models},
	pages = {2939--2942},
}

@inproceedings{zhao_checkguard_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {{CheckGuard}: {Advancing} {Stolen} {Check} {Detection} with a {Cross}-{Modal} {Image}-{Text} {Benchmark} {Dataset}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3679155},
	doi = {10.1145/3627673.3679155},
	abstract = {The prevalence of check fraud, particularly with stolen checks sold on platforms such as Telegram, creates significant challenges for both individuals and financial institutions. This underscores the urgent need for innovative solutions to detecting and preventing such fraud on social media platforms. While deep learning techniques show great promise in detecting objects and extracting information from images, their effectiveness in addressing check fraud is hindered by the lack of comprehensive, open-source, large training datasets specifically for check information extraction. To bridge this gap, this paper introduces "CheckGuard," a large labeled image-to-text cross-modal dataset designed for check information extraction. CheckGuard comprises over 7,000 real-world stolen check image segments from more than 15 financial institutions, featuring a variety of check styles and layouts. These segments have been manually labeled, resulting in over 50,000 samples across seven key elements: Drawer, Payee, Amount, Date, Drawee, Routing Number, and Check Number. This dataset supports various tasks such as visual question answering (VQA) on checks and check image captioning. Our paper details the rigorous data collecting, cleaning, and annotation processes that make CheckGuard a valuable resource for researchers in check fraud detection, machine learning, and multimodal large language models (MLLMs). We not only benchmark state-of-the-art (SOTA) methods on this dataset to assess their performance but also explore potential enhancements. Our application of parameter-efficient fine-tuning (PEFT) techniques on the SOTA MLLMs demonstrates significant performance improvements, providing valuable insights and practical approaches for enhancing model efficacy on this task. As an evolving project, CheckGuard will continue to be updated with new data, enhancing its utility and driving further advancements in the field. Our PEFT-based MLLM code is available at: https://github.com/feizhao19/CheckGuard. For data access, researchers are required to contact the authors directly.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Zhao, Fei and Chen, Jiawen and Huang, Bin and Zhang, Chengcui and Warner, Gary},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {check fraud detection, cross-modal generation, machine learning, multi-modal large language model, stolen check},
	pages = {5425--5429},
}

@inproceedings{lyu_towards_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {Towards {Advancing} {Text}-{Based} {User} and {Item} {Representation} in {Personalized} {Recommendation}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3680270},
	doi = {10.1145/3627673.3680270},
	abstract = {In the realm of personalized recommendation systems, accurately capturing user preferences and item characteristics is important for delivering relevant and satisfying recommendations. This study introduces innovative approaches using Large Language Models (LLMs) to generate detailed textual descriptions that enhance both user and item representations. We propose a dual strategy: for user representation, we employ supervised fine-tuning coupled with Retrieval-Augmented Generation (RAG) to keep the model current with dynamic user preferences; for item representation, we leverage the extensive knowledge base of LLMs to enrich item descriptions and infer traits from user interactions. These methods promise a deeper, more nuanced understanding of both users and items, potentially leading to superior recommendation accuracy. We adopt a rigorous evaluation methodology, ensuring the reliability of our results and the effectiveness of our proposed system. This paper discusses these methodologies, presents our preliminary findings, and highlights the potential of text-augmented profiles in advancing recommendation systems.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Lyu, Hanjia},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {content understanding, personalization, recommendation, representation learning, user understanding},
	pages = {5459--5462},
}

@inproceedings{urban_demonstrating_2024,
	address = {New York, NY, USA},
	series = {{SIGMOD} '24},
	title = {Demonstrating {CAESURA}: {Language} {Models} as {Multi}-{Modal} {Query} {Planners}},
	isbn = {979-8-4007-0422-2},
	url = {https://doi.org/10.1145/3626246.3654732},
	doi = {10.1145/3626246.3654732},
	abstract = {In many domains, multi-modal data takes an important role and modern question-answering systems based on LLMs allow users to query this data using simple natural language queries. Retrieval Augmented Generation (RAG) is a recent approach that extends Large Language Models (LLM) with database technology to enable such multi-modal QA systems. In RAG, relevant data is first retrieved from a vector database and then fed into an LLM that computes the query result. However, RAG-based approaches have severe issues, such as regarding efficiency and scalability, since LLMs have high inference costs and can only process limited amounts of data. Therefore, in this demo paper, we propose CAESURA, a database-first approach that extends databases with LLMs. The main idea is that CAESURA utilizes the reasoning capabilities of LLMs to translate natural language queries into execution plans. Using such execution plans allows CAESURA to process multi-modal data outside the LLM using query operators and optimization strategies that are footed in scalable query execution strategies of databases. Our demo allows users to experience CAESURA on two example datasets containing tables, texts, and images1.},
	booktitle = {Companion of the 2024 {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {Urban, Matthias and Binnig, Carsten},
	year = {2024},
	note = {event-place: Santiago AA, Chile},
	keywords = {large language models, multi-modal, query planning},
	pages = {472--475},
}

@inproceedings{nadel_enabling_2024,
	address = {New York, NY, USA},
	series = {{PEARC} '24},
	title = {Enabling access to large-language models ({LLMs}) at scale for higher education},
	isbn = {979-8-4007-0419-2},
	url = {https://doi.org/10.1145/3626203.3670577},
	doi = {10.1145/3626203.3670577},
	abstract = {The use of language models, particularly large-language models (LLMs), have been increasingly popular and can be transformative in higher education, by both enabling novel research approaches and providing instructional opportunities for skills needed in data science and engineering. However, running these LLMs traditionally requires access to advanced hardware resources and technical knowledge. To better provide a platform for experimenting with LLMs for users of all skill levels, we developed the Tufts Technology Services (TTS) LLM-Hub, a series of example Jupyter notebooks served through Tufts Open OnDemand (OOD) to setup, configure, and run LLMs automatically. The TTS LLM-Hub enabled quick access to running LLMs, while reducing barriers to compute and enabling users to chat with an LLM in just four clicks. We have used these platforms for support of advanced data science courses, and to enable research computing at Tufts.},
	booktitle = {Practice and {Experience} in {Advanced} {Research} {Computing} 2024: {Human} {Powered} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Nadel, Peter and Maloney, Delilah and Monahan, Kyle},
	year = {2024},
	note = {event-place: Providence, RI, USA},
	keywords = {High-Performance Computing (HPC), Large-Language Models (LLMs), Open OnDemand (OOD)},
}

@inproceedings{colombo_leveraging_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {Leveraging {Knowledge} {Graphs} and {LLMs} to {Support} and {Monitor} {Legislative} {Systems}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3680268},
	doi = {10.1145/3627673.3680268},
	abstract = {Knowledge Graphs (KGs) have been used to organize large datasets into structured, interconnected information, enhancing data analytics across various fields. In the legislative context, one potential natural application of KGs is modeling the intricate set of interconnections that link laws and their articles with each other and the broader legislative context.At the same time, the rise of large language models (LLMs) such as GPT has opened new opportunities in legal applications, such as text generation and document drafting. Despite their potential, the use of LLMs in legislative contexts is critical since it requires the absence of hallucinations and reliance on up-to-date information, as new laws are published on a daily basis.This work investigates how Legislative Knowledge Graphs and LLMs can synergize and support legislative processes. We address three key questions: the benefits of using KGs for legislative systems, how LLM can support legislative activities by ensuring an accurate output, and how we can allow non-technical users to use such technologies in their activities. To this aim, we develop Legis AI Platform, an interactive platform focused on Italian legislation that enhances the possibility of conducting legislative analysis and that aims to support lawmaking activities.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Colombo, Andrea},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {graphrag, knowledge graph, large language models, laws, legislative systems},
	pages = {5443--5446},
}

@inproceedings{kuchenbuch_smart_2025,
	address = {New York, NY, USA},
	series = {E-{Energy} '25},
	title = {Smart {Grid} {Assistive} {AI} in {Requirement} {Engineering}: {Improving} the {Modeling} of {Use} {Cases} and {Architecture} {Models} with {LLMs}},
	isbn = {979-8-4007-1125-1},
	url = {https://doi.org/10.1145/3679240.3734601},
	doi = {10.1145/3679240.3734601},
	abstract = {The IEC 62559 Use Case Methodology and Smart Grid Architecture Model (SGAM) Framework are crucial for fostering a shared understanding in the development of ICT-based power systems and their components within energy-related Requirements Engineering. However, discrepancies in interpretation among diverse stakeholders often diminish the quality of IEC 62559 Use Cases and SGAM Models, potentially leading to errors and costly setbacks in later project stages. This paper introduces the Smart Grid Assistive AI in Requirements Engineering (SGAAIRE), an intelligent system that leverages Large Language Models to enhance the quality of IEC 62559 Use Case descriptions and SGAM Models. Through a demonstration scenario featuring built-in quality defects, SGAAIRE is shown to effectively address common issues as an extension to a Use Case Management Repository. The proposed system supports the improvement of IEC 62559 Use Cases and SGAM Models, enabling the development of third-party tools aimed at advancing research in AI for energy-related requirements management.},
	booktitle = {Proceedings of the 16th {ACM} {International} {Conference} on {Future} and {Sustainable} {Energy} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kuchenbuch, René and Lehnhoff, Sebastian and Sauer, Jürgen},
	year = {2025},
	keywords = {Artificial Intelligence, IEC 62559 Use Cases, Natural Language Processing, Requirement Engineering, Smart Grid Architecture Model},
	pages = {495--504},
}

@inproceedings{kim_cyberally_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{CyberAlly}: {Leveraging} {LLMs} and {Knowledge} {Graphs} to {Empower} {Cyber} {Defenders}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715171},
	doi = {10.1145/3701716.3715171},
	abstract = {The increasing frequency and sophistication of cyberattacks demand innovative approaches to strengthen defense capabilities. Training on live infrastructure poses significant risks to organizations, making secure, isolated cyber ranges an essential tool for conducting Red vs. Blue Team training events. These events enable security teams to refine their skills without impacting operational environments. While such training provides a strong foundation, the ever-evolving nature of cyber threats necessitates additional support for effective defense. To address this challenge, we introduce CyberAlly, a knowledge graph-enhanced AI assistant designed to enhance the efficiency and effectiveness of Blue Teams during incident response. Integrated into our cyber range alongside an open-source SIEM platform, CyberAlly monitors alerts, tracks Blue Team actions, and suggests tailored mitigation recommendations based on insights from prior Red vs. Blue Team exercises. This demonstration highlights the feasibility and impact of CyberAlly in augmenting incident response and equipping defenders to tackle evolving threats with greater precision and confidence.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Kim, Minjune and Wang, Jeff and Moore, Kristen and Goel, Diksha and Wang, Derui and Mohsin, Ahmad and Ibrahim, Ahmed and Doss, Robin and Camtepe, Seyit and Janicke, Helge},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {augmenting cyber defence, cyber incident response, human ai teaming},
	pages = {2851--2854},
}

@inproceedings{khatua_evaluating_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Evaluating {LLMs}' ({In})ability to {Follow} {Prompts} in {QA} {Tasks}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730190},
	doi = {10.1145/3726302.3730190},
	abstract = {While LLMs have achieved impressive performance across various tasks, one under-explored area is evaluating their ability to follow instructions provided in the prompt when generating responses. In the context of question-answering (QA) tasks, a crucial research gap is whether LLMs prioritize their own parametric knowledge or the context provided in the prompt when generating an answer. Ignoring prompts, even when explicitly instructed to follow them, may adversely affect performance and potentially lead to unintended consequences. Additionally, LLMs should be self-reflective (i.e., LLMs should recognize when their knowledge is inadequate) and avoid hallucinations in such scenarios. To address our research question, we propose Oedipus, an evaluation framework to evaluate LLMs' ability to follow prompts. We further note that such abilities could also be influenced by contamination (i.e., exposure to datasets during training) and parametric knowledge. Consequently, we develop a novel QA dataset with four types of contexts- correct, masked, noisy, and absurd contexts with recent questions that LLMs are unlikely to have encountered in pre-training data or corpus and cannot be answered from parametric knowledge. We evaluate eight LLMs through our proposed evaluation framework and observe that LLMs often fail to follow instructions correctly and are not self-reflective.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Khatua, Aparup and Kalmbach, Tobias and Mitra, Prasenjit and Sikdar, Sandipan},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {instruction-following, large language models, question answering},
	pages = {2941--2945},
}

@inproceedings{dieing_traditional_2025,
	address = {New York, NY, USA},
	series = {{MuC} '25},
	title = {Traditional and {Deep} {Learning} {Methods} for {Trustworthy} {Intent} {Classification} in {Conversational} {Agent} {Voting} {Advice} {Applications} ({CAVAAs})},
	isbn = {979-8-4007-1582-2},
	url = {https://doi.org/10.1145/3743049.3748572},
	doi = {10.1145/3743049.3748572},
	abstract = {To enhance interactive political education, chatbots like Conversational Agent Voting Advice Applications (CAVAAs) are beginning to be powered by LLMs. While these systems offer open-domain conversational capabilities, they also pose risks when handling critical prompts involving toxic language or sensitive topics. This paper proposes intent classification as a method to safeguard political chatbots by distinguishing between safe and unsafe prompts. Using data from four international CAVAA studies and AI-generated inputs, four models — Random Forest, SVM, a DNN, and a CNN — were trained on fastText embeddings. The SVM achieved the highest F1 Macro of 0.955, outperforming all others. An explainability analysis confirmed that models learned meaningful indicators of critical intent. The findings support intent classification as a viable safety mechanism for political chatbots, while emphasizing the need for larger, real-world datasets, ethical considerations, and the need for scholars to further discuss what should be considered unsafe in this context.},
	booktitle = {Proceedings of the {Mensch} {Und} {Computer} 2025},
	publisher = {Association for Computing Machinery},
	author = {Dieing, Thilo Ignaz},
	year = {2025},
	keywords = {CAVAA, deep learning, Intent Classification, machine learning, NLP, safeguarding chatbots},
	pages = {749--754},
}

@inproceedings{ranaut_text_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Text {Obsoleteness} {Detection} using {Large} {Language} {Models}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730254},
	doi = {10.1145/3726302.3730254},
	abstract = {Maintaining accurate and up-to-date information is a persistent challenge for large-scale knowledge repositories, where outdated content can compromise their value. In this paper, we present a Multitask learning framework that uses Large Language Models (LLMs) for two tasks: semantic update detection and semantic update necessity prediction. The update detection task identifies obsoleteness by comparing older and newer text versions, while the update necessity prediction task determines whether an update is required based on a given context. To support these tasks, we curate a specialized dataset from Wikipedia called SEMUPDATES, focusing on frequently updated articles. Our experiments with five LLMs across four datasets in zero-shot, few-shot, and fine-tuned settings demonstrate that fine-tuning significantly enhances performance. In the multitask learning setup, Qwen delivers the best overall performance, while Mistral achieves the highest accuracy on individual tasks when fine-tuned separately. However, the performance differences across models are not substantial, suggesting that multiple LLMs can be effectively adapted for content update automation. These findings highlight the potential of LLMs in detecting and predicting obsolescence, providing a scalable solution for maintaining the timeliness of digital knowledge repositories.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Ranaut, Rishav and Saha, Sriparna and Jatowt, Adam and Gupta, Manish},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {llm, multitask learning, text obsoleteness},
	pages = {2827--2831},
}

@inproceedings{dewan_llm-driven_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{LLM}-{Driven} {Usefulness} {Labeling} for {IR} {Evaluation}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730223},
	doi = {10.1145/3726302.3730223},
	abstract = {In the information retrieval (IR) domain, evaluation plays a crucial role in optimizing search experiences and supporting diverse user intents. In the recent LLM era, research has been conducted to automate document relevance labels. These labels have traditionally been assigned by crowd-sourced workers, a process that is both time consuming and costly. This study focuses on LLM-generated usefulness labels, a crucial evaluation metric that considers the user's search intents and task objectives, an aspect where relevance falls short. Our experiment utilizes task-level, query-level, and document-level features along with user search behavior signals, which are essential in defining the usefulness of a document. Our research finds that (i) pre-trained LLMs can generate moderate usefulness labels by understanding the comprehensive search task session, and (ii) pre-trained LLMs perform better judgment in short search sessions when provided with search session contexts. Furthermore, we investigate whether LLMs can capture the unique divergence between relevance and usefulness, along with conducting an ablation study to identify the most critical metrics for accurate usefulness label generation. In conclusion, this work explores LLM-generated usefulness labels by evaluating critical metrics and optimizing for practicality in real-world settings.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Dewan, Mouly and Liu, Jiqun and Shah, Chirag},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {information retrieval, llm evaluation, usefulness judgment},
	pages = {3055--3059},
}

@inproceedings{capari_sciencedirect_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {{ScienceDirect} {Topic} {Pages}: {A} {Knowledge} {Base} of {Scientific} {Concepts} {Across} {Various} {Science} {Domains}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3661353},
	doi = {10.1145/3626772.3661353},
	abstract = {From undergraduate students to renowned scholars, everyone occasionally encounters unknown concepts within their field of interest, especially when reading scientific articles. ScienceDirectTopic Pages (TP) are intended to facilitate learning and to provide users with a structured overview of sources to deepen their knowledge about such unfamiliar topics. Our free service provides insight into a vast set of technical topics across 20 different scientific domains. Designed to emulate the natural flow of learning, TPs are embedded within millions of articles so that users can click on unfamiliar concepts they come across whilst reading an article. This redirects the user to a TP, consisting of a definition of the concept, which provides the user with a basic understanding of the concept. The TP further presents a collection of relevant snippets extracted from books and review articles published by ScienceDirect for users interested in references and more detailed explanations and applications of the concept. Finally, a set of related topics is provided to extend the user's knowledge even further. To build TPs, we utilize various information retrieval methods across our product. We retrieve the most relevant snippets for each topic/concept using a semantic search model fine-tuned on our scientific database. We further leverage the power of Retrieval Augmented Generation to generate reliable definitions on the topics sourced from ScienceDirect's content. To retrieve a list of relevant concepts for each topic, we use the co-occurrence statistics of concepts within books and articles.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Capari, Artemis and Azarbonyad, Hosein and Tsatsaronis, Georgios and Afzal, Zubair and Dunham, Judson},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {knowledge acquisition information retrieval, passage retrieval, scientific document processing},
	pages = {2976--2980},
}

@inproceedings{isahagian_publish-subscribe_2023,
	address = {New York, NY, USA},
	series = {Middleware '23},
	title = {Publish-subscribe with large language models: {Improving} expressiveness with natural language and generated custom notifications: {Poster} {Abstract}},
	isbn = {979-8-4007-0429-1},
	url = {https://doi.org/10.1145/3626564.3629099},
	doi = {10.1145/3626564.3629099},
	abstract = {Large Language Models (LLMs) have raised the expectations of users to be able to use natural language (NL) to interact with computer systems such as publish/subscribe systems. We introduce a design that extends existing pub/sub paradigms by adding support for NL queries to subscribe to publications of unstructured text messages. To make the system easier for users our system can also customize the notifications, using LLMs to generate targeted NL answers from the matching publications.},
	booktitle = {Proceedings of the 24th {International} {Middleware} {Conference}: {Demos}, {Posters} and {Doctoral} {Symposium}},
	publisher = {Association for Computing Machinery},
	author = {Isahagian, Vatche and Muthusamy, Vinod and Slominski, Aleksander},
	year = {2023},
	note = {event-place: Bologna, Italy},
	keywords = {large language models, LLM, publish-subscribe},
	pages = {29--30},
}

@inproceedings{abrami_vr-parlexplorer_2025,
	address = {New York, NY, USA},
	series = {{HT} '25},
	title = {{VR}-{ParlExplorer}: {A} {Hypertext} {System} for the {Collaborative} {Interaction} in {Parliamentary} {Debate} {Spaces}},
	isbn = {979-8-4007-1534-1},
	url = {https://doi.org/10.1145/3720553.3746672},
	doi = {10.1145/3720553.3746672},
	abstract = {The enhanced visualization and interaction with information in collaborative VR environments enabled by chatbots is currently rather limited. To fill this gap and create a concrete application that combines spatial and virtual concepts of hypertext systems based on the use of LLMs, we present VR-ParlExplorer as a system for virtualizing plenary debates that allows users to interact with virtual members of parliament through chatbots. VR-ParlExplorer is implemented as a Plugin for Va.Si.Li-Lab to enable immersion in the dynamics of communication in parliamentary debates. The paper describes the functionality of VR-ParlExplorer and discusses specifics of the use case it addresses.},
	booktitle = {Proceedings of the 36th {ACM} {Conference} on {Hypertext} and {Social} {Media}},
	publisher = {Association for Computing Machinery},
	author = {Abrami, Giuseppe and Bundan, Daniel and Manolis, Chrisowaladis and Mehler, Alexander},
	year = {2025},
	keywords = {Chatbot, Hypertext, Parliamentary Speeches, RAG, VR-Interaction},
	pages = {177--183},
}

@inproceedings{jiang_bridging_2024,
	address = {New York, NY, USA},
	series = {{CSCW} {Companion} '24},
	title = {Bridging {Dictionary}: {AI}-{Generated} {Dictionary} of {Partisan} {Language} {Use}},
	isbn = {979-8-4007-1114-5},
	url = {https://doi.org/10.1145/3678884.3681820},
	doi = {10.1145/3678884.3681820},
	abstract = {Words often carry different meanings for people from diverse backgrounds. Today's era of social polarization demands that we choose words carefully to prevent miscommunication, especially in political communication and journalism. To address this issue, we introduce the Bridging Dictionary, an interactive tool designed to illuminate how words are perceived by people with different political views. The Bridging Dictionary includes a static, printable document featuring 796 terms with summaries generated by a large language model. These summaries highlight how the terms are used distinctively by Republicans and Democrats. Additionally, the Bridging Dictionary offers an interactive interface that lets users explore selected words, visualizing their frequency, sentiment, summaries, and examples across political divides. We present a use case for journalists and emphasize the importance of human agency and trust in further enhancing this tool. The deployed version of Bridging Dictionary is available at https://dictionary.ccc-mit.org/.},
	booktitle = {Companion {Publication} of the 2024 {Conference} on {Computer}-{Supported} {Cooperative} {Work} and {Social} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Jiang, Hang and Beeferman, Doug and Brannon, William and Heyward, Andrew and Roy, Deb},
	year = {2024},
	note = {event-place: San Jose, Costa Rica},
	keywords = {civic media, computational journalism, natural language processing, social polarization, text analysis, trust and human agency},
	pages = {79--82},
}

@inproceedings{parikh_echoguide_2024,
	address = {New York, NY, USA},
	series = {{ISWC} '24},
	title = {{EchoGuide}: {Active} {Acoustic} {Guidance} for {LLM}-{Based} {Eating} {Event} {Analysis} from {Egocentric} {Videos}},
	isbn = {979-8-4007-1059-9},
	url = {https://doi.org/10.1145/3675095.3676611},
	doi = {10.1145/3675095.3676611},
	abstract = {Self-recording eating behaviors is a step towards a healthy lifestyle recommended by many health professionals. However, the current practice of manually recording eating activities using paper records or smartphone apps is often unsustainable and inaccurate. Smart glasses have emerged as a promising wearable form factor for tracking eating behaviors, but existing systems primarily identify when eating occurs without capturing details of the eating activities (E.g., what is being eaten). In this paper, we present EchoGuide, an application and system pipeline that leverages low-power active acoustic sensing to guide head-mounted cameras to capture egocentric videos, enabling efficient and detailed analysis of eating activities. By combining active acoustic sensing for eating detection with video captioning models and large-scale language models for retrieval augmentation, EchoGuide intelligently clips and analyzes videos to create concise, relevant activity records on eating. We evaluated EchoGuide with 9 participants in naturalistic settings involving eating activities, demonstrating high-quality summarization and significant reductions in video data needed, paving the way for practical, scalable eating activity tracking.},
	booktitle = {Proceedings of the 2024 {ACM} {International} {Symposium} on {Wearable} {Computers}},
	publisher = {Association for Computing Machinery},
	author = {Parikh, Vineet and Mahmud, Saif and Agarwal, Devansh and Li, Ke and Guimbretière, François and Zhang, Cheng},
	year = {2024},
	note = {event-place: Melbourne VIC, Australia},
	keywords = {acoustic sensing, activity recognition, eating detection, foundation models},
	pages = {40--47},
}

@inproceedings{jia_agentir_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{AgentIR}: 2nd {Workshop} on {Agent}-based {Information} {Retrieval}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730365},
	doi = {10.1145/3726302.3730365},
	abstract = {Information retrieval (IR) systems are essential in modern society, aiding users to efficiently locate relevant information through query expansion, document retrieval, ranking, and re-ranking. User feedback from ranked outputs forms a dynamic interaction loop with IR systems, which can be modeled as either one-time or sequential decision-making problems. Over the past decade, deep reinforcement learning (DRL) has emerged as a promising approach to decision-making, leveraging the high model capacity of deep learning for complex tasks. While significant research has explored the application of DRL to IR tasks, several fundamental challenges remain underexplored, including the underlying information theory in DRL settings, the limitations of reinforcement learning methods for industrial IR applications, and the simulation of DRL-based IR systems. Concurrently, the advent of large language models (LLMs) has introduced new opportunities for optimizing and simulating IR systems. Building on the success of the Agent-based IR Workshop at SIGIR 2024, we propose hosting the second Agent-based IR Workshop at SIGIR 2025. This workshop will continue to provide a platform for researchers and practitioners from academia and industry to present cutting-edge advances in DRL-based and LLM-based IR systems from an agent-based perspective. By building on the foundation laid in the first workshop, the 2025 edition aims to delve deeper into emerging research challenges, foster collaborations, and explore innovative applications. Through engaging discussions and insightful presentations, the workshop seeks to further expand the boundaries of IR research and solidify its role as a premier venue for advancing agent-based IR systems.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Jia, Pengyue and Cai, Qingpeng and Zhao, Xiangyu and Pan, Ling and Xin, Xin and Huang, Jin and Zhang, Weinan and Zhao, Li and Yin, Dawei and Yang, Grace Hui},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {agent-based information retrieval, drl, llm},
	pages = {4180--4183},
}

@inproceedings{cheng_sqlord_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{SQLord}: {A} {Robust} {Enterprise} {Text}-to-{SQL} {Solution} via {Reverse} {Data} {Generation} and {Workflow} {Decomposition}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715541},
	doi = {10.1145/3701716.3715541},
	abstract = {Transforming natural language into SQL queries (NL2SQL) is crucial for data-driven business applications. Existing frameworks, trained on open-source datasets, struggle with complex business logic and lack domain-specific data for fine-tuning. Additionally, evaluation methods often require annotated data and executable database environments, which are scarce in real-world scenarios. To address these challenges, we propose SQLord, an enterprise-level NL2SQL framework. First, SQLord introduces a data reverse generation approach to convert raw SQL statements into annotated data for supervised fine-tuning (SFT). Second, it proposes a decomposition method for complex queries using an automated workflow generator. Additionally, SQLord features a comprehensive GPT-Judge evaluation framework, including Execution Evaluation (EXE), Query-SQL Evaluation (QSE), and SQL-SQL Evaluation (SSE), tailored to diverse scenarios. Offline tests significantly outperform state-of-the-art baselines, and online accuracy consistently exceeds 90, highlighting SQLord's advantages and effectiveness in complex real-world scenarios. SQLord has been successfully applied across multiple scenarios on the world's largest B2B e-commerce platform.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Cheng, Song and Cheng, Qiannan and Jin, Linbo and Yi, Lei and Zhang, Guannan},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {llm, text to sql, workflow generation},
	pages = {919--923},
}

@inproceedings{fleshman_re-adaptir_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{RE}-{AdaptIR}: {Improving} {Information} {Retrieval} through {Reverse} {Engineered} {Adaptation}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730240},
	doi = {10.1145/3726302.3730240},
	abstract = {Large language models (LLMs) fine-tuned for text-retrieval have demonstrated state-of-the-art results across several information retrieval (IR) benchmarks. However, supervised training for improving these models requires numerous labeled examples, which are generally unavailable or expensive to acquire. In this work, we explore the effectiveness of extending reverse engineered adaptation to the context of information retrieval (RE-AdaptIR). We use RE-AdaptIR to improve LLM-based IR models using only unlabeled data. We demonstrate improved performance in both training domains and in zero-shot domains where the models have seen no queries. We analyze performance changes in various fine-tuning scenarios and offer findings of immediate use to IR practitioners.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Fleshman, William and Van Durme, Benjamin},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {adapter-tuning, fine-tuning, llm, lora, neural ir},
	pages = {2632--2636},
}

@inproceedings{arabzadeh_human-ai_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {A {Human}-{AI} {Comparative} {Analysis} of {Prompt} {Sensitivity} in {LLM}-{Based} {Relevance} {Judgment}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730159},
	doi = {10.1145/3726302.3730159},
	abstract = {Large Language Models (LLMs) are increasingly used to automate relevance judgments for information retrieval (IR) tasks, often demonstrating agreement with human labels that approaches inter-human agreement. To assess the robustness and reliability of LLM-based relevance judgments, we systematically investigate impact of prompt sensitivity on the task. We collected prompts for relevance assessment from 15 human experts and 15 LLMs across three tasks-binary, graded, and pairwise-yielding 90 prompts in total. We compare LLM-generated labels with TREC official human labels using Cohen's κ and pairwise agreement measures. In addition, we compare human- and LLM-generated prompts and analyze differences among different LLMs as judges. We release all data and prompts at https://github.com/Narabzad/prompt-sensitivity-relevance-judgements/.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Arabzadeh, Negar and Clarke, Charles L.A.},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {evaluation, large language models, relevance judgments},
	pages = {2784--2788},
}

@inproceedings{di_sipio_use_2024,
	address = {New York, NY, USA},
	series = {{MODELS} {Companion} '24},
	title = {On the use of {LLMs} to support the development of domain-specific modeling languages},
	isbn = {979-8-4007-0622-6},
	url = {https://doi.org/10.1145/3652620.3687808},
	doi = {10.1145/3652620.3687808},
	abstract = {In Model-Driven Engineering (MDE), domain-specific modeling languages (DSMLs) play a key role to model systems within specific application domains. Creating DSMLs is a complex, iterative process requiring input from both domain specialists and technical experts. This process often involves developing language artifacts, including syntax, semantics, and supporting environments, to gather feedback and achieve consensus among stakeholders.To facilitate the interaction between technical experts and domain specialists in the creation of new DSMLs, we propose using large language models for the specific task of supporting the requirement elicitation of language semantics. Our approach aims to reduce the time needed to develop proof-of-concept implementations, facilitating quicker agreement on the language's intended functions. Once consensus is reached, traditional technologies can be employed to develop the semantics of the agreed language. This method aims to mitigate potential misunderstandings that can arise during interactions between technical specialists and domain experts. As an initial investigation of this idea, we explore the model mutation problem as a case study. We developed a custom GPT model, named MuTaGENe, designed to support the definition of model mutations and tested it against the existing Wodel language.},
	booktitle = {Proceedings of the {ACM}/{IEEE} 27th {International} {Conference} on {Model} {Driven} {Engineering} {Languages} and {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Di Sipio, Claudio and Rubei, Riccardo and Di Rocco, Juri and Di Ruscio, Davide and Iovino, Ludovico},
	year = {2024},
	note = {event-place: Linz, Austria},
	keywords = {domain-specific languages, large language models, model driven engineering},
	pages = {596--601},
}

@inproceedings{ferrato_exploring_2025,
	address = {New York, NY, USA},
	series = {{UMAP} {Adjunct} '25},
	title = {Exploring the {Potential} of {Multimodal} {Large} {Language} {Models} for {Question} {Answering} on {Artworks}},
	isbn = {979-8-4007-1399-6},
	url = {https://doi.org/10.1145/3708319.3733648},
	doi = {10.1145/3708319.3733648},
	abstract = {This paper investigates the application of a Multimodal Large Language Model to enhance visitor experiences in cultural heritage settings through Visual Question Answering (VQA) and Contextual Question Answering (CQA). We evaluate the zero-shot capabilities of LLaVA-7b (Large Language and Vision Assistant) on QA using the AQUA dataset. We assess how effectively it can answer questions about artwork, visual content, and contextual information through three experimental approaches. Our findings reveal that LLaVA demonstrates promising performance on visual questions, outperforming previous baselines but facing challenges with questions requiring contextual understanding. The selective knowledge integration approach showed the best overall performance, suggesting an efficient knowledge retrieval systems could enhance performance. Moreover, we show how to exploit such models to provide correct personalized answers using a well-established visitor model.},
	booktitle = {Adjunct {Proceedings} of the 33rd {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {Association for Computing Machinery},
	author = {Ferrato, Alessio and Limongelli, Carla and Gasparetti, Fabio and Sansonetti, Giuseppe and Micarelli, Alessandro},
	year = {2025},
	keywords = {Cultural Heritage, Large Language Models, Personalization, Visual Question Answering},
	pages = {432--436},
}

@inproceedings{kemper_retrieval-augmented_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Retrieval-{Augmented} {Conversational} {Recommendation} with {Prompt}-based {Semi}-{Structured} {Natural} {Language} {State} {Tracking}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657670},
	doi = {10.1145/3626772.3657670},
	abstract = {Conversational recommendation (ConvRec) systems must understand rich and diverse natural language (NL) expressions of user preferences and intents, often communicated in an indirect manner (e.g., "I'm watching my weight”). Such complex utterances make retrieving relevant items challenging, especially if only using often incomplete or out-of-date metadata. Fortunately, many domains feature rich item reviews that cover standard metadata categories and offer complex opinions that might match a user's interests (e.g., "classy joint for a date”). However, only recently have large language models (LLMs) let us unlock the commonsense connections between user preference utterances and complex language in user-generated reviews. Further, LLMs enable novel paradigms for semi-structured dialogue state tracking, complex intent and preference understanding, and generating recommendations, explanations, and question answers. We thus introduce a novel technology RA-Rec, a Retrieval-Augmented, LLM-driven dialogue state tracking system for ConvRec, showcased with a video, open source GitHub repository, and interactive Google Colab notebook.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Kemper, Sara and Cui, Justin and Dicarlantonio, Kai and Lin, Kathy and Tang, Danjie and Korikov, Anton and Sanner, Scott},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {conversational recommendation, dialogue state tracking, llm},
	pages = {2786--2790},
}

@inproceedings{wheeler_procedural_2025,
	address = {New York, NY, USA},
	series = {{UMAP} {Adjunct} '25},
	title = {Procedural {Memory} {Is} {Not} {All} {You} {Need}: {Bridging} {Cognitive} {Gaps} in {LLM}-{Based} {Agents}},
	isbn = {979-8-4007-1399-6},
	url = {https://doi.org/10.1145/3708319.3734172},
	doi = {10.1145/3708319.3734172},
	abstract = {Large Language Models (LLMs) represent a landmark achievement in Artificial Intelligence (AI), demonstrating unprecedented proficiency in procedural tasks such as text generation, code completion, and conversational coherence. These capabilities stem from their architecture, which mirrors human procedural memory—the brain’s ability to automate repetitive, pattern-driven tasks through practice. However, as LLMs are increasingly deployed in real-world applications, it becomes impossible to ignore their limitations operating in complex, unpredictable environments. This paper argues that LLMs, while transformative, are fundamentally constrained by their reliance on procedural memory. To create agents capable of navigating “wicked” learning environments—where rules shift, feedback is ambiguous, and novelty is the norm—we must augment LLMs with semantic memory and associative learning systems. By adopting a modular architecture that decouples these cognitive functions, we can bridge the gap between narrow procedural expertise and the adaptive intelligence required for real-world problem-solving.},
	booktitle = {Adjunct {Proceedings} of the 33rd {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {Association for Computing Machinery},
	author = {Wheeler, Schaun and Jeunen, Olivier},
	year = {2025},
	pages = {360--364},
}

@inproceedings{zhang_ai_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {{AI} {Agent} for {Information} {Retrieval}: {Generating} and {Ranking}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3680120},
	doi = {10.1145/3627673.3680120},
	abstract = {The field of information retrieval has significantly transformed with the integration of AI technologies. AI agents, especially those leveraging LLMs and vast computational power, have revolutionized information retrieval, processing, and presentation. LLM agents, with advanced memory, reasoning, and planning capabilities, can perform complex tasks, engage in coherent conversations, and provide personalized responses. Despite these advancements, challenges such as ensuring relevance and accuracy, mitigating biases, providing real-time responses, and maintaining data security remain. This workshop aims to explore these challenges, share innovative solutions, and discuss future directions. It will provide a platform to bring together researchers, practitioners to discuss the latest theoretical advancements and practical implementations of AI agents in information retrieval. Topics include AI in search, recommendation, and personalization systems. By gathering a diverse group of experts, the workshop seeks to deepen the understanding of AI agents in information retrieval, advance the field, and enhance its societal impact. Participants will gain insights into cutting-edge research, emerging trends, and foster knowledge exchange and collaboration within the community.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Yongfeng and Liu, Zhiwei and Wen, Qingsong and Pang, Linsey and Liu, Wei and Yu, Philip S.},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {ai agent, information retrieval, large language models (llms), recommender systems},
	pages = {5605--5607},
}

@inproceedings{zhang_agentfm_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {{AgentFM}: {Role}-{Aware} {Failure} {Management} for {Distributed} {Databases} with {LLM}-{Driven} {Multi}-{Agents}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3728492},
	doi = {10.1145/3696630.3728492},
	abstract = {Distributed databases are critical infrastructures for today's large-scale software systems, making effective failure management essential to ensure software availability. However, existing approaches often overlook the role distinctions within distributed databases and rely on small-scale models with limited generalization capabilities. In this paper, we conduct a preliminary empirical study to emphasize the unique significance of different roles. Building on this insight, we propose AgentFM, a role-aware failure management framework for distributed databases powered by LLM-driven multi-agents. AgentFM addresses failure management by considering system roles, data roles, and task roles, with a meta-agent orchestrating these components. Preliminary evaluations using Apache IoTDB demonstrate the effectiveness of AgentFM and open new directions for further research.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Lingzhe and Zhai, Yunpeng and Jia, Tong and Huang, Xiaosong and Duan, Chiming and Li, Ying},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {distributed databases, failure management, multi agents},
	pages = {525--529},
}

@inproceedings{hillebrand_improving_2023,
	address = {New York, NY, USA},
	series = {{DocEng} '23},
	title = {Improving {Zero}-{Shot} {Text} {Matching} for {Financial} {Auditing} with {Large} {Language} {Models}},
	isbn = {979-8-4007-0027-9},
	url = {https://doi.org/10.1145/3573128.3609344},
	doi = {10.1145/3573128.3609344},
	abstract = {Auditing financial documents is a very tedious and time-consuming process. As of today, it can already be simplified by employing AI-based solutions to recommend relevant text passages from a report for each legal requirement of rigorous accounting standards. However, these methods need to be fine-tuned regularly, and they require abundant annotated data, which is often lacking in industrial environments. Hence, we present ZeroShotALI, a novel recommender system that leverages a state-of-the-art large language model (LLM) in conjunction with a domain-specifically optimized transformer-based text-matching solution. We find that a two-step approach of first retrieving a number of best matching document sections per legal requirement with a custom BERT-based model and second filtering these selections using an LLM yields significant performance improvements over existing approaches.},
	booktitle = {Proceedings of the {ACM} {Symposium} on {Document} {Engineering} 2023},
	publisher = {Association for Computing Machinery},
	author = {Hillebrand, Lars and Berger, Armin and Deußer, Tobias and Dilmaghani, Tim and Khaled, Mohamed and Kliem, Bernd and Loitz, Rüdiger and Pielka, Maren and Leonhard, David and Bauckhage, Christian and Sifa, Rafet},
	year = {2023},
	note = {event-place: Limerick, Ireland},
	keywords = {Large Language Models, Recommender System, Text Matching},
}

@inproceedings{kejriwal_commonsense_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Commonsense {AI} in the {History} of the {Web}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3716841},
	doi = {10.1145/3701716.3716841},
	abstract = {Machine common sense (MCS)-the challenge of enabling computers to grasp everyday human knowledge-has been a grand challenge in Artificial Intelligence (AI) since the 1950s. While recent advances in large language models have led to impressive progress, there is still no consensus on how much common sense today's AI actually possesses. In this brief review, we revisit the historical development of MCS in the context of the Web, examining how the Web's evolution-from early knowledge representation efforts to knowledge graphs, the Semantic Web, and crowdsourcing-has shaped MCS research. We argue that key breakthroughs in Web technologies were instrumental in addressing longstanding challenges of scale and coverage in commonsense reasoning. At the same time, MCS research has influenced the development of core Web applications, including intelligent agents, plausibility-based reasoning, and robust evaluation of black-box AI systems.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Kejriwal, Mayank and McGuinness, Deborah L. and Lieberman, Henry},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {conceptnet, cyc, llms, machine common sense},
	pages = {837--840},
}

@inproceedings{luo_oneke_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{OneKE}: {A} {Dockerized} {Schema}-{Guided} {LLM} {Agent}-based {Knowledge} {Extraction} {System}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715189},
	doi = {10.1145/3701716.3715189},
	abstract = {We introduce OneKE, a dockerized schema-guided knowledge extraction system, which can extract knowledge from the Web and raw PDF Books, and support various domains (science, news, etc.). Specifically, we design OneKE with multiple agents and a configure knowledge base. Different agents perform their respective roles, enabling support for various extraction scenarios. The configure knowledge base facilitates schema configuration, error case debugging and correction, further improving the performance. Empirical evaluations on benchmark datasets demonstrate OneKE's efficacy, while case studies further elucidate its adaptability to diverse tasks across multiple domains, highlighting its potential for broad applications. The code can be accessed on both GitHub1 and Zenodo2M, along with a video demonstration3.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Luo, Yujie and Ru, Xiangyuan and Liu, Kangwei and Yuan, Lin and Sun, Mengshu and Zhang, Ningyu and Liang, Lei and Zhang, Zhiqiang and Zhou, Jun and Wei, Lanning and Zheng, Da and Wang, Haofen and Chen, Huajun},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {information extraction, large language models, natural language processing},
	pages = {2871--2874},
}

@inproceedings{xu_geo-llava_2024,
	address = {New York, NY, USA},
	series = {{LGM3A} '24},
	title = {Geo-{LLaVA}: {A} {Large} {Multi}-{Modal} {Model} for {Solving} {Geometry} {Math} {Problems} with {Meta} {In}-{Context} {Learning}},
	isbn = {979-8-4007-1193-0},
	url = {https://doi.org/10.1145/3688866.3689124},
	doi = {10.1145/3688866.3689124},
	abstract = {Geometry mathematics problems pose significant challenges for large language models (LLMs) because they involve visual elements and spatial reasoning. Current methods primarily rely on symbolic character awareness to address these problems. Considering geometry problem solving is a relatively nascent field with limited suitable datasets and currently almost no work on solid geometry problem solving, we collect a geometry question-answer dataset by sourcing geometric data from Chinese high school education websites, referred to as GeoMath. It contains solid geometry questions and answers with accurate reasoning steps as compensation for existing plane geometry datasets. Additionally, we propose a Large Multi-modal Model (LMM) framework named Geo-LLaVA, which incorporates retrieval augmentation with supervised fine-tuning (SFT) in the training stage, called meta-training, and employs in-context learning (ICL) during inference to improve performance. Our fine-tuned model with ICL attains the state-of-the-art performance of 65.25\% and 42.36\% on selected questions of the GeoQA dataset and GeoMath dataset respectively with proper inference steps. Notably, our model initially endows the ability to solve solid geometry problems and supports the generation of reasonable solid geometry picture descriptions and problem-solving steps. Our research sets the stage for further exploration of LLMs in multi-modal math problem-solving, particularly in geometry math problems.},
	booktitle = {Proceedings of the 2nd {Workshop} on {Large} {Generative} {Models} {Meet} {Multimodal} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Xu, Shihao and Luo, Yiyang and Shi, Wei},
	year = {2024},
	note = {event-place: Melbourne VIC, Australia},
	keywords = {geometry problem solving, in-context learning, large multimodal model, rag},
	pages = {11--15},
}

@inproceedings{garcia_mesa_scalable_2025,
	address = {New York, NY, USA},
	series = {{PEARC} '25},
	title = {Scalable {Patent} {Analysis} {Using} {Function} {Calling} with {Local} {Large} {Language} {Models}},
	isbn = {979-8-4007-1398-9},
	url = {https://doi.org/10.1145/3708035.3736071},
	doi = {10.1145/3708035.3736071},
	abstract = {User requests often foment technological innovation, prompting transformative change across research and functional areas. At Arizona State University, a collaboration with their intellectual property management services led to the development of an automated tool that addresses the growing need for efficient patent classification and analysis. The system leverages large language models integrated with function calling to retrieve, clean, and analyze patent data from the US Patent and Trademark Office data portal. Key functionalities include extracting university-assigned patents, classifying them using a streamlined version of the official code hierarchy, and executing targeted queries such as retrieving detailed patent information or identifying patents related to specific subject matters. This work contributes to more efficient patent management processes and serves as a blueprint for applying similar methodologies to related problems. This approach combines conventional data analysis with dynamic function calling, mitigating common artificial intelligence challenges such as hallucinations and providing accurate outputs.},
	booktitle = {Practice and {Experience} in {Advanced} {Research} {Computing} 2025: {The} {Power} of {Collaboration}},
	publisher = {Association for Computing Machinery},
	author = {García Mesa, Juan José},
	year = {2025},
	keywords = {function calling, Large language models, patent classification},
}

@inproceedings{zeng_combining_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Combining {Large} {Language} {Models} and {Crowdsourcing} for {Hybrid} {Human}-{AI} {Misinformation} {Detection}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657965},
	doi = {10.1145/3626772.3657965},
	abstract = {Research on misinformation detection has primarily focused either on furthering Artificial Intelligence (AI) for automated detection or on studying humans' ability to deliver an effective crowdsourced solution. Each of these directions however shows different benefits. This motivates our work to study hybrid human-AI approaches jointly leveraging the potential of large language models and crowdsourcing, which is understudied to date. We propose novel combination strategies Model First, Worker First, and Meta Vote, which we evaluate along with baseline methods such as mean, median, hard- and soft-voting. Using 120 statements from the PolitiFact dataset, and a combination of state-of-the-art AI models and crowdsourced assessments, we evaluate the effectiveness of these combination strategies. Results suggest that the effectiveness varies with scales granularity, and that combining AI and human judgments enhances truthfulness assessments' effectiveness and robustness.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zeng, Xia and La Barbera, David and Roitero, Kevin and Zubiaga, Arkaitz and Mizzaro, Stefano},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {ai-crowdsourcing integration, llm, misinformation detection},
	pages = {2332--2336},
}

@inproceedings{wang_wildlifelookup_2025,
	address = {New York, NY, USA},
	series = {{WSDM} '25},
	title = {{WildlifeLookup}: {A} {Chatbot} {Facilitating} {Wildlife} {Management} with {Accessible} {Data} and {Insights}},
	isbn = {979-8-4007-1329-3},
	url = {https://doi.org/10.1145/3701551.3704121},
	doi = {10.1145/3701551.3704121},
	abstract = {Wildlife management is increasingly reliant on data-driven insights to address the impacts of climate change on species and ecosystems. However, the complexity of accessing and querying large, multimodal datasets often limits the ability of non-technical users, such as wildlife managers and conservationists, to make informed decisions. To address this challenge, we present WildlifeLookup, a public accessible, intelligent chatbot designed to facilitate natural language interaction with a novel knowledge graph (KN-Wildlife) that houses critical wildlife and environmental data. WildlifeLookup simplifies access to species distributions, habitat interactions, and climate-related events by converting user queries into precise graph queries, reducing the technical barriers for end users. The chatbot WildlifeLookup is available at https://oknbot.ngrok.dev/},
	booktitle = {Proceedings of the {Eighteenth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Xiangqi and Yang, Tianyu and Rohr, Jason and Scheffers, Brett and Chawla, Nitesh and Zhang, Xiangliang},
	year = {2025},
	note = {event-place: Hannover, Germany},
	keywords = {large language models (llms), retrieval-augment generation (rag), wildlife knowledge network},
	pages = {1064--1067},
}

@inproceedings{pathiyan_cherumanal_towards_2024,
	address = {New York, NY, USA},
	series = {{ICMI} '24 {Companion}},
	title = {Towards {Investigating} {Biases} in {Spoken} {Conversational} {Search}},
	isbn = {979-8-4007-0463-5},
	url = {https://doi.org/10.1145/3686215.3690156},
	doi = {10.1145/3686215.3690156},
	abstract = {Voice-based systems like Amazon Alexa, Google Assistant, and Apple Siri, along with the growing popularity of OpenAI’s ChatGPT and Microsoft’s Copilot, serve diverse populations, including visually impaired and low-literacy communities. This reflects a shift in user expectations from traditional search to more interactive question-answering models. However, presenting information effectively in voice-only channels remains challenging due to their linear nature. This limitation can impact the presentation of complex queries involving controversial topics with multiple perspectives. Failing to present diverse viewpoints may perpetuate or introduce biases and affect user attitudes. Balancing information load and addressing biases is crucial in designing a fair and effective voice-based system. To address this, we (i) review how biases and user attitude changes have been studied in screen-based web search, (ii) address challenges in studying these changes in voice-based settings like SCS, (iii) outline research questions, and (iv) propose an experimental setup with variables, data, and instruments to explore biases in a voice-based setting like Spoken Conversational Search.},
	booktitle = {Companion {Proceedings} of the 26th {International} {Conference} on {Multimodal} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Pathiyan Cherumanal, Sachin and Scholer, Falk and Trippas, Johanne R and Spina, Damiano},
	year = {2024},
	note = {event-place: San Jose, Costa Rica},
	keywords = {audio output, bias, conversational search, information retrieval},
	pages = {61--66},
}

@inproceedings{zhang_edu-values_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Edu-{Values}: {Towards} {Evaluating} the {Chinese} {Education} {Values} of {Large} {Language} {Models}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715518},
	doi = {10.1145/3701716.3715518},
	abstract = {In this paper, we present Edu-Values, the first Chinese education values evaluation benchmark that includes seven core values: professional philosophy, teachers' professional ethics, education laws and regulations, cultural literacy, educational knowledge and skills, basic competencies and subject knowledge. We meticulously design 1,418 questions, covering multiple-choice, multi-modal question answering, subjective analysis, adversarial prompts, and Chinese traditional culture (short answer) questions. We conduct human feedback based automatic evaluation over 21 state-of-the-art (SoTA) LLMs, and highlight three main findings: (1) due to differences in educational culture, Chinese LLMs outperform English LLMs, with Qwen 2 ranking the first with a score of 81.37; (2) LLMs often struggle with teachers' professional ethics and professional philosophy; (3) leveraging Edu-Values to build an external knowledge repository for RAG significantly improves LLMs' alignment. This demonstrates the effectiveness of the proposed benchmark.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Peiyi and Zhang, Yazhou and Wang, Bo and Rong, Lu and Tiwari, Prayag and Qin, Jing},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {educational benchmark, large language models, values alignment},
	pages = {1519--1523},
}

@inproceedings{liu_multimodal_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Multimodal {Intent} {Recognition} in {E}-{Commerce}: {Challenges}, {Innovations}, and {Lightweight} {Solutions}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3719642},
	doi = {10.1145/3701716.3719642},
	abstract = {The "Multimodal Dialogue System Intent Recognition Challenge", jointly organized by Alibaba Taobao and Tmall Group and the World Wide Web Conference (WWW), focuses on multimodal intent recognition in e-commerce scenarios, aiming to address technical challenges in joint understanding of images and text for customer service applications. During the preliminary round, over 1,500 teams participated, with 11 advancing to the semi-finals and 9 ultimately presenting in the final. Innovative approaches from participants centered on three key directions: multimodal data augmentation (e.g., synthetic sample generation, image-text co-augmentation), model optimization (discriminative fine-tuning, model soup fusion, etc.), and prompt engineering. Significantly, the top three teams elevated the weighted F1-score from a baseline of 0.78 to above 0.9. This improvement was achieved by incorporating a diverse set of techniques, including but not limited to vision-language models, structure-aware retrieval, and hierarchical label optimization. The competition outcomes validate the potential of lightweight models in data-scarce scenarios and provide open-source technical pathways for applying multimodal large language models to e-commerce customer service. These advancements drive progress in fine-grained semantic comprehension, domain adaptation, and efficient inference, offering valuable insights for the industrial deployment of intelligent customer service systems.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Liu, Junwen and Huang, Haikuan and Huang, Gang and Ge, Shuang and Hu, Jinlian},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {data augmentation, e-commerce customer service, model fusion, multimodal intent recognition, RAG, vision-language models},
	pages = {3008--3011},
}

@inproceedings{ni_reliable_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {Reliable {Knowledge} {Graph} {Reasoning} with {Uncertainty} {Quantification}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3680266},
	doi = {10.1145/3627673.3680266},
	abstract = {Recently, Knowledge Graphs (KGs) have been successfully coupled with Large Language Models (LLMs) to mitigate their hallucinations and enhance their reasoning capability, e.g., KG-based retrieval-augmented framework for question-answering. However, current KG-LLM frameworks lack rigorous uncertainty estimation, limiting their reliable deployment in high-stake applications where the cost of errors is significant. To address this crucial gap, we propose a new trustworthy KG-LLM framework, UaG(\&lt;u\&gt;U\&lt;/u\&gt;ncertainty \&lt;u\&gt;A\&lt;/u\&gt;ware \&lt;u\&gt;G\&lt;/u\&gt;raph Reasoning), which incorporates uncertainty quantification into the KG-LLM framework. We design an uncertainty-aware multi-step reasoning framework that leverages conformal prediction to provide a theoretical guarantee on the prediction set. To manage the error rate of the multi-step process, we additionally introduce an error rate control module to adjust the error rate within the individual components. Our preliminary results demonstrate that UaG can achieve the desired theoretical coverage while maintaining a reasonable prediction set size.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Ni, Bo},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {knowledge graph, question answering, trustworthy AI, uncertainty quantification},
	pages = {5463--5466},
}

@inproceedings{rashedul_hasan_muse_2025,
	address = {New York, NY, USA},
	series = {{ICMI} '25},
	title = {{MUSE}: {A} {Multimodal}, {Generative}, and {Symbolic} {Framework} for {Human} {Experience} {Modeling}},
	isbn = {979-8-4007-1499-3},
	url = {https://doi.org/10.1145/3716553.3750735},
	doi = {10.1145/3716553.3750735},
	abstract = {Realizing truly capable personal AI for health and education requires effectively modeling complex longitudinal experiential (LE) data. Unlike standard datasets, LE data from human experience is inherently multifaceted, dynamic, and contextual. Current AI approaches struggle with this complexity due to three critical gaps rooted in differences from human cognition: insufficient multimodal processing, lack of generative perception, and inadequate symbolic order contextualization. Drawing upon interdisciplinary insights, our blue sky vision, the MUSE (Multimodal, generative, and Symbolic framEwork), proposes to bridge these gaps. By integrating multimodal representations addressing LE data’s structure, generative simulation capturing “what-if” dynamics, and symbolic order grounding for context, MUSE aims for a profound, contextually aware understanding of individual experience, essential for robust inference and enabling advanced personal AI applications.},
	booktitle = {Proceedings of the 27th {International} {Conference} on {Multimodal} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Rashedul Hasan, Mohammad},
	year = {2025},
	keywords = {cognitive psychology, human experience modeling, longitudinal data, multimodal learning, neuroscience, psychoanalysis, vision-language model},
	pages = {699--705},
}

@inproceedings{vedula_question_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Question {Suggestion} for {Conversational} {Shopping} {Assistants} {Using} {Product} {Metadata}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3661371},
	doi = {10.1145/3626772.3661371},
	abstract = {Digital assistants have become ubiquitous in e-commerce applications, following the recent advancements in Information Retrieval (IR), Natural Language Processing (NLP) and Generative Artificial Intelligence (AI). However, customers are often unsure or unaware of how to effectively converse with these assistants to meet their shopping needs. In this work, we emphasize the importance of providing customers a fast, easy to use, and natural way to interact with conversational shopping assistants. We propose a framework that employs Large Language Models (LLMs) to automatically generate contextual, useful, answerable, fluent and diverse questions about products, via in-context learning and supervised fine-tuning. Recommending these questions to customers as helpful suggestions or hints to both start and continue a conversation can result in a smoother and faster shopping experience with reduced conversation overhead and friction. We perform extensive offline evaluations, and discuss in detail about potential customer impact, and the type, length and latency of our generated product questions if incorporated into a real-world shopping assistant.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Vedula, Nikhita and Rokhlenko, Oleg and Malmasi, Shervin},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {conversational shopping assistants, product question suggestion},
	pages = {2960--2964},
}

@inproceedings{petruzzelli_recommending_2024,
	address = {New York, NY, USA},
	series = {{RecSys} '24},
	title = {Recommending {Healthy} and {Sustainable} {Meals} exploiting {Food} {Retrieval} and {Large} {Language} {Models}},
	isbn = {979-8-4007-0505-2},
	url = {https://doi.org/10.1145/3640457.3688193},
	doi = {10.1145/3640457.3688193},
	abstract = {Given the rising global concerns about healthy nutrition and environmental sustainability, individuals need more and more support in making good choices concerning their daily meals. To this end, in this paper we introduce HeaSE, a framework for Healthy And Sustainable Eating. Given an input recipe, HeaSE identifies healthier and more sustainable meals by exploiting retrieval techniques and large language models. The framework works in two steps. First, it uses food retrieval strategies based on macro-nutrient information to identify candidate alternative meals. This ensures that the substitutions maintain a similar nutritional profile. Next, HeaSE employs large language models to re-rank these potential replacements while considering factors beyond just nutrition, such as the recipe’s environmental impact. In the experimental evaluation, we showed the capabilities of LLMs in identifying more sustainable and healthier alternatives within a set of candidate options. This highlights the potential of these models to guide users towards food choices that are both nutritious and environmentally responsible.},
	booktitle = {Proceedings of the 18th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Petruzzelli, Alessandro and Musto, Cataldo and Di Carlo, Michele Ciro and Tempesta, Giovanni and Semeraro, Giovanni},
	year = {2024},
	note = {event-place: Bari, Italy},
	keywords = {Food Recommendation, Health-aware Recommender Systems, Large Language Models, Sustainability},
	pages = {1057--1061},
}

@inproceedings{benedict_gen-ir_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Gen-{IR} @ {SIGIR} 2024: {The} {Second} {Workshop} on {Generative} {Information} {Retrieval}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657982},
	doi = {10.1145/3626772.3657982},
	abstract = {Generative information retrieval (Gen-IR) is a fast-growing interdisciplinary research area that investigates how to leverage advances in generative Artificial Intelligence (AI) to improve information retrieval systems. Gen-IR has attracted interest from the information retrieval, natural language processing, and machine learning communities, among others. Since the dawn of Gen-IR last year, there has been an explosion of Gen-IR systems that have launched and are now widely used. Interest in this area across academia and industry is only expected to continue to grow as new research challenges and application opportunities arise. The goal of this proposed workshop, The Second Workshop on Generative Information Retrieval (Gen-IR @ SIGIR 2024) is to provide an interactive venue for exploring a broad range of foundational and applied Gen-IR research. The workshop will focus on tasks such as generative document retrieval, grounded answer generation, generative recommendation, and generative knowledge graphs, all through the lens of model training, model behavior, and broader issues. The workshop will be highly interactive, favoring panel discussions, poster sessions, and roundtable discussions over one-sided keynotes and paper talks.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Bénédict, Gabriel and Zhang, Ruqing and Metzler, Donald and Yates, Andrew and Jiang, Ziyan},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {generative models, information retrieval, large language models},
	pages = {3029--3032},
}

@inproceedings{luo_evolutionagent_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{EvolutionAgent}: {A} {Large} {Model}-{Based} {Framework} for {User} {Behavior} {Modeling} and {Self}-{Evolving} {Intelligent} {Agents}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3719226},
	doi = {10.1145/3701716.3719226},
	abstract = {Large Language Models (LLMs) have demonstrated remarkable capabilities in simulating user behavior, offering significant potential for user modeling, behavior analysis, interest matching, and the extraction of unstructured features. However, the process of user simulation necessitates the identification of both unstructured and structured features, as well as the formulation of multi-stages workflow, which remains a challenging and labor-intensive task. To address this, we propose EvolutionAgent , a novel framework grounded in a discretized material repository, which employs self-reflective and evolutionary mechanisms to automate the search for unstructured features and the generation of simulation workflow. This framework establishes an efficient and robust simulation mechanism, achieving state-of-the-art performance across three distinct datasets. Notably, EvolutionAgent exhibits exceptional robustness, even in scenarios with limited historical data for users and products, underscoring its adaptability and reliability.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Luo, Junhui and Song, Li and Sun, Ranrun},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {closed-loop adaptation, llm agent, llm-based simulation, self-evolving framework},
	pages = {2973--2977},
}

@inproceedings{kapuriya_exploring_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Exploring the {Role} of {Diversity} in {Example} {Selection} for {In}-{Context} {Learning}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730194},
	doi = {10.1145/3726302.3730194},
	abstract = {In-Context Learning (ICL) has gained prominence due to its ability to perform tasks without requiring extensive training data and its robustness to noisy labels. A typical ICL workflow involves selecting localized examples relevant to a given input using sparse or dense embedding-based similarity functions. However, relying solely on similarity-based selection may introduce topical biases in the retrieved contexts, potentially leading to suboptimal downstream performance. We posit that reranking the retrieved context to enhance topical diversity can improve downstream task performance. To achieve this, we leverage maximum marginal relevance (MMR) which balances topical similarity with inter-example diversity. Our experimental results demonstrate that diversifying the selected examples leads to consistent improvements in downstream performance across various context sizes and similarity functions. The implementation of our approach is made available at https://github.com/janak11111/Diverse-ICL.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Kapuriya, Janak and Kaushik, Manit and Ganguly, Debasis and Bhatia, Sumit},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {diversity, in-context learning, large language models},
	pages = {2962--2966},
}

@inproceedings{wang_mememo_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {{MeMemo}: {On}-device {Retrieval} {Augmentation} for {Private} and {Personalized} {Text} {Generation}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657662},
	doi = {10.1145/3626772.3657662},
	abstract = {Retrieval-augmented text generation (RAG) addresses the common limitations of large language models (LLMs), such as hallucination, by retrieving information from an updatable external knowledge base. However, existing approaches often require dedicated backend servers for data storage and retrieval, thereby limiting their applicability in use cases that require strict data privacy, such as personal finance, education, and medicine. To address the pressing need for client-side dense retrieval, we introduce MeMemo, the first open-source JavaScript toolkit that adapts the state-of-the-art approximate nearest neighbor search technique HNSW to browser environments. Developed with modern and native Web technologies, such as IndexedDB and Web Workers, our toolkit leverages client-side hardware capabilities to enable researchers and developers to efficiently search through millions of high-dimensional vectors in the browser. MeMemo enables exciting new design and research opportunities, such as private and personalized content creation and interactive prototyping, as demonstrated in our example application RAG Playground. Reflecting on our work, we discuss the opportunities and challenges for on-device dense retrieval. MeMemo is available at https://github.com/poloclub/mememo.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Zijie J. and Chau, Duen Horng},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {large language models, neural information retrieval, on-device},
	pages = {2765--2770},
}

@inproceedings{li_graph-augmented_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Graph-{Augmented} {Retrieval} with {Memory}-{Driven} {Reasoning} and {Constraint}-{Aware} {Filtering} for {MultiHop} {QA}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730203},
	doi = {10.1145/3726302.3730203},
	abstract = {Addressing multi-hop reasoning of complex query effectively is a challenging task in information retrieval field. It demands the ability to retrieve and integrate dispersed knowledge across multiple documents dynamically while maintaining coherence in multi-step reasoning process. This study addresses these challenges with three primary contributions. It explores the integrating of large language models with graph-augmented retrieval methods for complex multihop reasoning. Moreover, the Memory-Driven Chain-of-Reasoning strategy is introduced, leveraging the memory of historical queries and results to optimize multi-step reasoning dynamically. Additionally, the Constraint-Aware Filtering in Chunked Window strategy is developed to improve retrieval precision by partitioning and filtering large retrieval windows based on query constraints. The experiments on public benchmarks indicate that our method substantially outperforms competitive approaches, achieving up to 13.8\% and 14.0\% improvements in EM and F1 on HotpotQA, 9.4\% and 12.8\% on MuSiQue, and 6.4\% and 3.2\% on 2WikiMultiHopQA, respectively.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Li, Siyuan and Du, Yongping and Li, Mingyang},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {constraint-aware filtering, graph-augmented retrieval, memory-driven reasoning, multihop question answering},
	pages = {2700--2705},
}

@inproceedings{kamran_vision_2024,
	address = {New York, NY, USA},
	series = {{ASEW} '24},
	title = {Vision {Paper}: {Proof}-{Carrying} {Code} {Completions}},
	isbn = {979-8-4007-1249-4},
	url = {https://doi.org/10.1145/3691621.3694932},
	doi = {10.1145/3691621.3694932},
	abstract = {Code completions produced by today's large language models (LLMs) offer no formal guarantees. We propose proof-carrying code completions (PC3). In this paradigm, a high-resourced entity (the LLM provided by the server) must provide a code completion together with a proof of a chosen safety property which can be independently checked by a low-resourced entity (the user). In order to provide safety proofs without requiring the user to write specifications in formal logic, we statically generate preconditions for all dangerous function calls (i.e., functions that may violate the safety property) which must be proved by the LLM.To demonstrate the main ideas, we provide a prototype implementation in the program verification language Dafny, and a case study focusing on file system vulnerabilities. Unlike Python code generated by GPT-4, Dafny code generated by PC3 provably avoids a common weakness related to path traversal (CWE-35), using a single generation attempt (k = 1) and a modest number of tokens (3, 350). Our tool is available as an open source repository at https://github.com/DavisPL/PCCC.},
	booktitle = {Proceedings of the 39th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering} {Workshops}},
	publisher = {Association for Computing Machinery},
	author = {Kamran, Parnian and Devanbu, Premkumar and Stanford, Caleb},
	year = {2024},
	note = {event-place: Sacramento, CA, USA},
	keywords = {dafny, formal verification, large language models, program synthesis, proof-carrying code},
	pages = {35--42},
}

@inproceedings{gawin_navigating_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Navigating {Semantic} {Relations}: {Challenges} for {Language} {Models} in {Abstract} {Common}-{Sense} {Reasoning}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715472},
	doi = {10.1145/3701716.3715472},
	abstract = {Large language models (LLMs) have achieved remarkable performance in generating human-like text and solving reasoning tasks of moderate complexity, such as question-answering and mathematical problem-solving. However, their capabilities in tasks requiring deeper cognitive skills, such as common-sense understanding and abstract reasoning, remain under-explored. In this paper, we systematically evaluate abstract common-sense reasoning in LLMs using the ConceptNet knowledge graph. We propose two prompting approaches: instruct prompting, where models predict plausible semantic relationships based on provided definitions, and few-shot prompting, where models identify relations using examples as guidance. Our experiments with the gpt-4o-mini model show that in instruct prompting, consistent performance is obtained when ranking multiple relations but with substantial decline when the model is restricted to predicting only one relation. In few-shot prompting, the model's accuracy improves significantly when selecting from five relations rather than the full set, although with notable bias toward certain relations. These results suggest significant gaps still, even in commercially used LLMs' abstract common-sense reasoning abilities, compared to human-level understanding. However, the findings also highlight the promise of careful prompt engineering, based on selective retrieval, for obtaining better performance.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Gawin, Cole and Sun, Yidan and Kejriwal, Mayank},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {abstract common sense, conceptnet, llm prompting},
	pages = {971--975},
}

@inproceedings{wang_international_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {International {Workshop} on {Online} and {Adaptive} {Recommender} {Systems} ({OARS} 2024)},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3679083},
	doi = {10.1145/3627673.3679083},
	abstract = {Recommender system (RecSys) plays important roles in helping users navigate, discover, and consume massive and highly-dynamic information. Today, many RecSys solutions deployed in the real world rely on categorical user-profiles and/or pre-calculated recommendation actions that stay static during a user session. However, recent trends suggest that RecSys need to model user intent in real time and constantly adapt to meet user needs at the moment or change user behavior in situ. There are three primary drivers for this emerging need of online adaptation. First, in order to meet the increasing demand for a better personalized experience, the personalization dimensions and space will grow larger and larger. It would not be feasible to pre-compute recommended actions for all personalization scenarios beyond a certain scale. Second, in many settings the system does not have user prior history to leverage. Estimating user intent in real time is the only feasible way to personalize. As various consumer privacy laws tighten, it is foreseeable that many businesses will reduce their reliance on static user profiles. Therefore, it makes the modeling of user intent in real time an important research topic. Third, a user's intent often changes within a session and between sessions, and user behavior could shift significantly during dramatic events. Therefore, it is important to investigate more on online and adaptive recommender system (OARS) that can adapt in real time to meet user needs and be robust against distribution shifts. Every year, the organizers survey the most important topics for OARS and propose a new workshop program. In light of the recent advancement of LLMs and foundation models in RecSys, in this new edition, we decide to formally add the new topic of foundation and LLM models in OARS. We will invite experts and papers in the field to facilitate its further advancement. Our workshop offers a focused discussion of the new study and application of OARS, and will bring together an interdisciplinary community of researchers and practitioners from both industry and academia to discuss on new topics in the area, grow a community, and push the direction forward.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Shuai and Zhuang, Shengyao and Koopman, Bevan and Zuccon, Guido and Cui, Xiquan and Dave, Vachik and Su, Yi and Al Jadda, Khalifeh and Kumar, Srijan and McAuley, Julian and Ye, Tao and Guo, Stephen and Huyen, Chip},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {artificial intelligence, foundation model, gen ai, llm, recommender system},
	pages = {5580--5583},
}

@inproceedings{alzahrani_accessible_2025,
	address = {New York, NY, USA},
	series = {{PEARC} '25},
	title = {Accessible {AI} and {HPC} {Education} for {All}},
	isbn = {979-8-4007-1398-9},
	url = {https://doi.org/10.1145/3708035.3736048},
	doi = {10.1145/3708035.3736048},
	abstract = {High-performance computing (HPC) and artificial intelligence (AI) are increasingly critical in research and industry, yet opportunities to learn these skills remain limited for many students and educators. This paper introduces a modular curriculum comprising 14 free and open interactive workshops designed to train learners at all levels – from K-12 and community colleges to vocational programs, colleges, and universities – in essential HPC and AI concepts. The workshops are hosted on GitHub and delivered through web-based Jupyter notebooks, accessible on any device (including smartphones) via platforms like Google Colaboratory (Colab) with no software installation required. The curriculum is fully compatible with the Advanced Cyberinfrastructure Coordination Ecosystem: Services \&amp; Support (ACCESS), a U.S. National Science Foundation (NSF)-funded initiative that provides free access to advanced computing systems, such as HPC. Each workshop integrates surveys and interactive exercises to measure engagement and learning outcomes, including before-and-after knowledge checks to assess knowledge gains. A complete list of workshops and their associated learning outcomes is provided to support clarity and replicability. The curriculum has been pilot-tested with student research assistants at California State University, San Bernardino (CSUSB), yielding overwhelmingly positive feedback on its accessibility and effectiveness. Survey data collected from a broader group of 84 learners further demonstrates strong engagement, learning gains, and perceived inclusivity. The material is designed to be engaging, accessible, and easily integrated into existing courses, learning management systems, or online education platforms. By democratizing access to HPC and AI education, this work aims to broaden participation and prepare a diverse workforce with computational and analytical skills.},
	booktitle = {Practice and {Experience} in {Advanced} {Research} {Computing} 2025: {The} {Power} of {Collaboration}},
	publisher = {Association for Computing Machinery},
	author = {Alzahrani, Nabeel},
	year = {2025},
	keywords = {AI, Cyberinfrastructure, HPC, Training and Education},
}

@inproceedings{barzanji_expectations_2025,
	address = {New York, NY, USA},
	series = {{MuC} '25},
	title = {Expectations and {Needs} of {Female} {STEM} {Students} for {Academic} {Chatbots}},
	isbn = {979-8-4007-1582-2},
	url = {https://doi.org/10.1145/3743049.3748564},
	doi = {10.1145/3743049.3748564},
	abstract = {Digital tools in higher education often promise support but rarely reflect the everyday realities of their users. This paper presents insights into what female STEM students expect from a supportive academic chatbot, aiming to better understand their needs and how such tools can be meaningfully integrated into their educational routines. As part of a broader context analysis, unstructured interviews were conducted with 30 female STEM students regarding their wishes and needs. Through thematic analysis, 71 wishes were extracted and organized into four broader themes, which we discuss and form into guidelines for designing academic chatbots. By conducting the first female-only study asking their specific question, we aim to include an underrepresented user group in the design of future academic chatbot applications.},
	booktitle = {Proceedings of the {Mensch} {Und} {Computer} 2025},
	publisher = {Association for Computing Machinery},
	author = {Barzanji, Chrakhan and Rosteck, Niclas and Lau, Annika and Rottmann, Sebastian and Loitsch, Claudia},
	year = {2025},
	keywords = {AI-based Chatbot, Chatbot Design, Conversational Agents, Female STEM Students Needs, Trust And Acceptance, User Expectations, User Needs, User-Centered Design},
	pages = {565--570},
}

@inproceedings{gong_cosearchagent_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {{CoSearchAgent}: {A} {Lightweight} {Collaborative} {Search} {Agent} with {Large} {Language} {Models}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657672},
	doi = {10.1145/3626772.3657672},
	abstract = {Collaborative search supports multiple users working together to accomplish a specific search task. Research has found that designing lightweight collaborative search plugins within instant messaging platforms aligns better with users' collaborative habits. However, due to the complexity of multi-user interaction scenarios, it is challenging to implement a fully functioning lightweight collaborative search system. Therefore, previous studies on lightweight collaborative search had to rely on the Wizard of Oz paradigm. In recent years, large language models (LLMs) have been demonstrated to interact naturally with users and achieve complex information-seeking tasks through LLM-based agents. Hence, to better support the research in collaborative search, in this demo, we propose CoSearchAgent, a lightweight collaborative search agent powered by LLMs. CoSearchAgent is designed as a Slack plugin that can support collaborative search during multi-party conversations on this platform. Equipped with the capacity to understand the queries and context in multi-user conversations and the ability to search the Web for relevant information via APIs, CoSearchAgent can respond to user queries with answers grounded on the relevant search results. It can also ask clarifying questions when the information needs are unclear. The proposed CoSearchAgent is highly flexible and would be useful for supporting further research on collaborative search. The code and demo are accessible at https://github.com/pygongnlp/CoSearchAgent},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Gong, Peiyuan and Li, Jiamian and Mao, Jiaxin},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {agents, collaborative search, large language models},
	pages = {2729--2733},
}

@inproceedings{piazza_which_2025,
	address = {New York, NY, USA},
	series = {{UMAP} {Adjunct} '25},
	title = {“{Which} vocational training program is best for me?” – {Design} of a recommender system for school students using large language models},
	isbn = {979-8-4007-1399-6},
	url = {https://doi.org/10.1145/3708319.3733809},
	doi = {10.1145/3708319.3733809},
	abstract = {School students need to make decisions about their career paths after graduating. In Germany, students can choose between more than 300 vocational training programs, which can be overwhelming. Frequently, the students hesitate to talk with career counselors. The objective of this research is, therefore, to provide a recommendation system for school students to support their decision-making, which is based on their interests and provides recommendations with explanations based on a LLM. This system was developed with a social robot as the user interface to make it easy to use and appeal to the young target group. Based on user observations, preliminary findings indicate that the system is a valuable and engaging approach to support career counseling activities.},
	booktitle = {Adjunct {Proceedings} of the 33rd {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {Association for Computing Machinery},
	author = {Piazza, Alexander and Schacht, Sigurd and Herzog, Michael},
	year = {2025},
	keywords = {Explainable Recommender Systems, Large Language Models, Social Robots, Vocational Training Programs},
	pages = {425--428},
}

@inproceedings{gosmar_insight_2024,
	address = {New York, NY, USA},
	series = {{EASE} '24},
	title = {Insight {AI} {Risk} {Detection} {Model} - {Vulnerable} {People} {Emotional} {Situation} {Support}},
	isbn = {979-8-4007-1701-7},
	url = {https://doi.org/10.1145/3661167.3661235},
	doi = {10.1145/3661167.3661235},
	abstract = {This paper presents an AI-based risk detection model (architectural framework) for real-time emotional support and risk assessment, addressing the rise in mental health issues among youth. The model leverages Insight AI (Sentiment and Emotional Analysis) to analyze synthetic utterance interactions. To design the initial version of the model, the Fundació Ajuda I Esperança customer experience has been considered: the analyzed service concerns the initial customer service (phase one) where particular focus has been paid to vulnerable youth and young adults from 14 to 25 years old. In particular, the emotional support chat that has managed - at the time of writing - more than 7,000 chat interactions, dealing with mental health problems such as depression anxiety, relationship. The findings emphasize ethical AI use in mental health services, promoting responsible deployment. Fundació Ajuda I Esperança is a no-profit organization providing help for people with emotional situations and in needs for psychological support like loneliness issues, self-harm and suicidal instincts.},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Evaluation} and {Assessment} in {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Gosmar, Diego and Peretto, Elena and Coleman, Oita},
	year = {2024},
	note = {event-place: Salerno, Italy},
	keywords = {Artificial intelligence, Conversational ai, ethicalai, insightai, mentalhealth},
	pages = {437--441},
}

@inproceedings{zhang_training_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {Training {Large} {Language} {Models} to {Comprehend} {LLVM} {IR} via {Feedback}-{Driven} {Optimization}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3731662},
	doi = {10.1145/3696630.3731662},
	abstract = {LLVM Intermediate Representation (LLVM IR) serves as a crucial bridge between source code and machine code, yet its complexity presents challenges for both human developers and AI-driven analysis tools. We propose an approach to train Large Language Models (LLMs) to better comprehend and optimize LLVM IR by leveraging diverse optimization feedback. Instead of relying on a single optimization strategy like -Oz, our framework incorporates multiple types of optimizations, combining (1) static supervision from various compiler-defined passes with (2) interactive, feedback-driven refinement learning based on preferences (potentially using reinforcement learning). This dual-feedback mechanism is designed to enable LLMs to process and analyze LLVM IR more effectively, thereby facilitating downstream software engineering tasks such as code summarization, optimization recommendation, and vulnerability detection.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Yifan and Leach, Kevin},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {compiler optimization, large language models},
	pages = {1477--1478},
}

@inproceedings{xu_towards_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {Towards {Seamless} {User} {Query} to {REST} {API} {Conversion}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3680275},
	doi = {10.1145/3627673.3680275},
	abstract = {Integrating Large Language Models (LLMs) with external tools and APIs is essential for fields such as information retrieval and knowledge management. While LLMs have made significant strides, their effective integration with external APIs-essential for real-world applications-remains challenging. This paper introduces RESTful-Llama, a novel method designed to empower open-source LLMs to accurately convert natural language instructions into well-formed RESTful API calls. Moreover, RESTful-Llama utilizes DOC-Prompt, a newly proposed technique for generating fine-tuning datasets from publicly available API documentation. Initial experiments demonstrate that RESTful-Llama significantly enhances the accuracy of generated REST API requests.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Xu, Han},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {information retrieval, natural language processing},
	pages = {5495--5498},
}

@inproceedings{zhang_intelligent_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Intelligent {Interaction} {Platform} for {Personalized} {Digital} {Tutor}: {Advancing} {Empathetic} and {Adaptive} {Learning} {Experiences}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715182},
	doi = {10.1145/3701716.3715182},
	abstract = {The rapid advancement of artificial intelligence and virtual digital human technologies is ushering in transformative changes in education. Virtual digital humans, empowered by multimodal information fusion and natural language processing capabilities, offer a more engaging and humanized interaction experience for online learning. However, general-purpose AI models for digital teaching often face notable challenges: 1) They often lack deep understanding of users, overlooking personalized learning needs; 2) they may struggle with knowledge reasoning, leading to unreliable and outdated content; 3) their human-machine interactions can feel unnatural, lacking emotional resonance and empathetic support.To address these challenges, we developed an interaction platform focused on delivering personalized digital human services. This platform optimizes learner profiling, domain-specific data integration, and service frameworks to enhance the intelligence, personalization, and quality of digital teaching agents, effectively tackling issues related to shallow user understanding and unreliable reasoning. Through the integration of realistic digital human avatars and personalized interactive technology, the platform enables more natural and seamless human-machine interactions. Additionally, emotional speech synthesis and synchronized facial expression technology allow virtual teachers' facial expressions to dynamically align with their speech, enhancing expressiveness, vitality, and empathy, which together heighten users' sense of immersion and interaction quality. This development marks a significant step toward smarter, more personalized education.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Kai and Gong, Weiyin and Liu, Qi and Lu, Junyu and Bao, Meikai and Liu, Xukai and Zhu, Linbo and Chen, Enhong},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {empathetic interaction, interactive platform, online education, virtual digital human},
	pages = {2947--2950},
}

@inproceedings{mulayim_large_2024,
	address = {New York, NY, USA},
	series = {{BuildSys} '24},
	title = {Large {Language} {Models} for the {Creation} and {Use} of {Semantic} {Ontologies} in {Buildings}: {Requirements} and {Challenges}},
	isbn = {979-8-4007-0706-3},
	url = {https://doi.org/10.1145/3671127.3698792},
	doi = {10.1145/3671127.3698792},
	abstract = {Semantic ontologies offer a formalized, machine-readable framework for representing knowledge, enabling the structured description of complex systems. In the building domain, the adoption of ontologies like the Brick schema has transformed how buildings and their systems are modeled by providing a standardized, interoperable language. However, the complexity and the steep learning curve involved in developing and querying semantic models present substantial challenges, often requiring a workforce with specialized expertise. This paper builds on our experience in investigating how Large Language Models (LLMs) can help address these challenges, focusing on their role in constructing and querying of semantic models, particularly using the Brick Schema. Our study outlines the requirements and metrics for evaluating the scalability and effectiveness of LLM-based tools, while also discussing the current challenges and limitations in developing such tools. Ultimately, this paper aims to orient research efforts as various groups experiment with diverse techniques, while enabling more effective comparison of emerging solutions and fostering collaboration across the field.},
	booktitle = {Proceedings of the 11th {ACM} {International} {Conference} on {Systems} for {Energy}-{Efficient} {Buildings}, {Cities}, and {Transportation}},
	publisher = {Association for Computing Machinery},
	author = {Mulayim, Ozan Baris and Paul, Lazlo and Pritoni, Marco and Prakash, Anand Krishnan and Sudarshan, Malavikha and Fierro, Gabe},
	year = {2024},
	note = {event-place: Hangzhou, China},
	keywords = {Knowledge Graphs, Large Language Models, Semantic Ontology},
	pages = {312--317},
}

@inproceedings{borg_creating_2024,
	address = {New York, NY, USA},
	series = {{HRI} '24},
	title = {Creating {Virtual} {Patients} using {Robots} and {Large} {Language} {Models}: {A} {Preliminary} {Study} with {Medical} {Students}},
	isbn = {979-8-4007-0323-2},
	url = {https://doi.org/10.1145/3610978.3640592},
	doi = {10.1145/3610978.3640592},
	abstract = {This paper presents a virtual patient (VP) platform for medical education, combining a social robot, Furhat, with large language models (LLMs). Aimed at enhancing clinical reasoning (CR) training, particularly in rheumatology, this approach introduces more interactive and realistic patient simulations. The use of LLMs both for driving the dialogue, but also for the expression of emotions in the robot's face, as well as automatic analysis and generation of feedback to the student, is discussed. The platform's effectiveness was tested in a pilot study with 15 medical students, comparing it against a traditional semi-linear VP platform. The evaluation indicates a preference for the robot platform in terms of authenticity and learning effect. We conclude that this novel integration of a social robot and LLMs in VP simulations shows potential in medical education, offering a more engaging learning experience.},
	booktitle = {Companion of the 2024 {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Borg, Alexander and Parodis, Ioannis and Skantze, Gabriel},
	year = {2024},
	note = {event-place: Boulder, CO, USA},
	keywords = {human-robot interaction, large language models, robots in education, virtual patients},
	pages = {273--277},
}

@inproceedings{parthasarathy_polymer_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {Polymer: {Development} {Workflows} as {Software}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3728494},
	doi = {10.1145/3696630.3728494},
	abstract = {Software development builds digital tools to automate processes, yet its initial phases, up to deployment, remain largely manual. There are two reasons: Development tasks are often under-specified and transitions between tasks usually require a translator. These reasons are mutually reinforcing: it makes little sense to specify tasks when you cannot connect them and writing a translator requires a specification. LLMs change this cost equation: they can handle under-specified systems and they excel at translation. Thus, they can act as skeleton keys that unlock the automation of tasks and transitions that were previously too expensive to automatically interlink. We introduce a recipe for writing development workflows as software (polymer) to further automate the initial phases of development. We show how adopting polymer at Volvo, a large automotive manufacturer, to automate testing saved 2–3 FTEs at the cost of two months to develop and deploy. We close with open challenges when polymerizing development workflows.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Parthasarathy, Dhasarathy and Yu, Yinan and Barr, Earl T.},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {large language models, software development automation},
	pages = {535--539},
}

@inproceedings{frobe_reneuir_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {{ReNeuIR} at {SIGIR} 2024: {The} {Third} {Workshop} on {Reaching} {Efficiency} in {Neural} {Information} {Retrieval}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657994},
	doi = {10.1145/3626772.3657994},
	abstract = {The Information Retrieval (IR) community has a rich history of empirically measuring novel retrieval methods in terms of effectiveness and efficiency. However, as the search ecosystem is developing rapidly, comparatively little attention has been paid to evaluating efficiency in recent years, which raises the question of the cost-benefit ratio between effectiveness and efficiency. In this regard, it has become difficult to compare and contrast systems in an empirically fair way. Factors including hardware configurations, software versioning, experimental settings, and measurement methods all contribute to the difficulty of meaningfully comparing search systems, especially where efficiency is a key component of the evaluation. Furthermore, efficiency is no longer limited to time and space but has found new, challenging dimensions that stretch to resource, sample, and energy efficiency and have implications for users, researchers, and the environment. Examining algorithms and models through the lens of efficiency and its trade-off with effectiveness requires revisiting and establishing new standards and principles, from defining relevant concepts, to designing measures, to creating guidelines for making sense of the significance of findings. The third iteration of ReNeuIR aims to bring the community together to debate these questions and collaboratively test and improve a benchmarking framework for efficiency derived from the discussions of the first two iterations of this workshop. We provide a first prototype of this framework by organizing a shared task track focused on comparability and reproducibility at the workshop.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Fröbe, Maik and Mackenzie, Joel and Mitra, Bhaskar and Nardini, Franco Maria and Potthast, Martin},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {algorithms, efficiency, neural ir, ranking, retrieval, sustainable ir},
	pages = {3051--3054},
}

@inproceedings{shen_iotcoder_2024,
	address = {New York, NY, USA},
	series = {{ACM} {MobiCom} '24},
	title = {{IoTCoder}: {A} {Copilot} for {IoT} {Application} {Development}},
	isbn = {979-8-4007-0489-5},
	url = {https://doi.org/10.1145/3636534.3697447},
	doi = {10.1145/3636534.3697447},
	abstract = {Existing code Large Language Models are primarily designed for generating simple and general algorithms but are not dedicated to IoT applications. To fill this gap, we present IoTCoder, a coding copilot specifically designed to synthesize programs for IoT application development. IoTCoder features three locally deployed small language models (SLMs): a Task Decomposition SLM that decomposes a complex IoT application into multiple tasks with detailed descriptions, a Requirement Transformation SLM that converts the decomposed tasks described in natural language to well-structured specifications, and a Modularized Code Generation SLM that generates modularized code based on the task specifications. Experiment results show that IoTCoder can synthesize programs adopting more IoT-specific algorithms and outperform state-of-the-art code LLMs in terms of both task accuracy (by more than 24.2\% on average) and memory usage (by less than 358.4 MB on average).},
	booktitle = {Proceedings of the 30th {Annual} {International} {Conference} on {Mobile} {Computing} and {Networking}},
	publisher = {Association for Computing Machinery},
	author = {Shen, Leming and Zheng, Yuanqing},
	year = {2024},
	note = {event-place: Washington D.C., DC, USA},
	keywords = {IoT applications, large language models},
	pages = {1647--1649},
}

@inproceedings{oliveira_improving_2024,
	address = {New York, NY, USA},
	series = {{SVR} '24},
	title = {Improving {VR} {Accessibility} {Through} {Automatic} 360 {Scene} {Description} {Using} {Multimodal} {Large} {Language} {Models}},
	isbn = {979-8-4007-0979-1},
	url = {https://doi.org/10.1145/3691573.3691619},
	doi = {10.1145/3691573.3691619},
	abstract = {Advancements in Virtual Reality (VR) technology hold immense promise for enriching immersive experiences. Despite the advancements in VR technology, there remains a significant gap in addressing accessibility concerns, particularly in automatically providing descriptive information for VR scenes. This paper combines the potential of leveraging Multimodal Large Language Models (MLLMs) to automatically generate text descriptions for 360 VR scenes according to Speech-to-Text (STT) prompts. As a case study, we conduct experiments on educational settings in VR museums, improving dynamic experiences across various contexts. Despite minor challenges in adapting MLLMs to VR Scenes, the experiments demonstrate that they can generate descriptions with high quality. Our findings provide insights for enhancing VR experiences and ensuring accessibility to individuals with disabilities or diverse needs.},
	booktitle = {Proceedings of the 26th {Symposium} on {Virtual} and {Augmented} {Reality}},
	publisher = {Association for Computing Machinery},
	author = {Oliveira, Elisa Ayumi Masasi de and Silva, Diogo Fernandes Costa and Filho, Arlindo Rodrigues Galvão},
	year = {2024},
	note = {event-place: Manaus, Brazil},
	keywords = {3D Scene, Accessibility, Multimodal Large Language Models (MLLMs), Virtual Reality (VR)},
	pages = {289--293},
}

@inproceedings{young_gaqr_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {{GaQR}: {An} {Efficient} {Generation}-augmented {Question} {Rewriter}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3679930},
	doi = {10.1145/3627673.3679930},
	abstract = {Query understanding is an essential part in search systems to improve the recall. Unlike prior works focusing on word expansions, in this paper, we leverage the comprehension ability of LLM to generate detailed queries from a global semantic perspective. To this end, we introduce an efficient GaQR to reformulate a question into several queries using Chain of Thought (CoT) and make it more efficient through knowledge distillation. Specifically, we first prompt a teacher model to generate indicative queries by considering answer generation one step ahead. Then, we filter out low-quality queries by validating the effectiveness of all generated queries in retrieving useful passages. Finally, we distill a student rewriter based on the verified results to improve efficiency. Our experimental results demonstrate that the rewriter improves the retrieval performance by 3\% to 15\% on the Miracl and NFCorpus datasets and shows good generalisation ability across different retrieval methods. Moreover, the efficiency of the rewriter after knowledge distillation is improved by as much as 5 times. Code is available at https://github.com/youngbeauty250/GaQR.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Young, Oliver and Fan, Yixing and Zhang, Ruqing and Guo, Jiafeng and de Rijke, Maarten and Cheng, Xueqi},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {generation-augmented retrieval, knowledge distillation, question rewriting},
	pages = {4228--4232},
}

@inproceedings{sun_integrated_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {An {Integrated} {Data} {Processing} {Framework} for {Pretraining} {Foundation} {Models}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657671},
	doi = {10.1145/3626772.3657671},
	abstract = {The ability of the foundation models heavily relies on large-scale, diverse, and high-quality pretraining data. In order to improve data quality, researchers and practitioners often have to manually curate datasets from difference sources and develop dedicated data cleansing pipeline for each data repository. Lacking a unified data processing framework, this process is repetitive and cumbersome. To mitigate this issue, we propose a data processing framework that integrates a Processing Module which consists of a series of operators at different granularity levels, and an Analyzing Module which supports probing and evaluation of the refined data. The proposed framework is easy to use and highly flexible. In this demo paper, we first introduce how to use this framework with some example use cases and then demonstrate its effectiveness in improving the data quality with an automated evaluation with ChatGPT and an end-to-end evaluation in pretraining the GPT-2 model. The code and demonstration video are accessible on GitHub.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Sun, Yiding and Wang, Feng and Zhu, Yutao and Zhao, Wayne Xin and Mao, Jiaxin},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {data processing, data quality, large language models},
	pages = {2713--2718},
}

@inproceedings{chen_retrieving_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Retrieving the {Right} {Law}: {Enhancing} {Legal} {Search} with {Style} {Translation}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730246},
	doi = {10.1145/3726302.3730246},
	abstract = {Legal question answering requires accurate retrieval of relevant laws, yet the significant writing style gap between user queries and legal provisions poses a major challenge. Existing datasets and retrieval methods often struggle to capture the complexity of legal language, limiting retrieval effectiveness. In this study, we introduce the Legal Query-to-Provision Retrieval (LQPR) task and construct Query2Provision (Q2P), a dataset designed to enhance law retrieval by incorporating diverse case scenarios and linguistic structures representative of real-world legal inquiries. To address the style disparity, we propose a style translation approach that transforms informal user queries into a more formal legal tone and simplifies complex legal provisions for better alignment. Our experiments demonstrate that integrating writing style transformation significantly improves retrieval performance. The dataset is available at https://github.com/ntunlplab/Query2Provision},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Szu-Ju and Jin, Jing and Wei, Sheng-Lun and Chen, Chien-Hung and Chen, Hsin-Hsi},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {information systems document filtering, information systems question answering},
	pages = {2951--2955},
}

@inproceedings{zhao_ai_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {{AI} {Model} {Genome}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3730571},
	doi = {10.1145/3696630.3730571},
	abstract = {Artificial intelligence models, particularly large language models (LLMs), have become increasingly important and prevalent in modern computational systems. Their rapid development has created a need for more intuitive frameworks to understand their structure, function, and evolution. This paper introduces the "AI Model Genome" framework, a novel biological analogy that maps AI model components to their genomic counterparts. By drawing parallels between model architectures and species classification, training data and genetic material, and model parameters and gene sequences, we establish a comprehensive framework for conceptualizing model development. This biological perspective offers researchers and practitioners new insights into model design, modification strategies, and evolutionary pathways, potentially accelerating innovation in the field while providing a more accessible mental model for understanding complex AI systems.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Zhao, Yanjie and Wang, Haoyu},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {AI models, biological analogy, conceptual frameworks, large language models, machine learning, model architecture},
	pages = {1768--1773},
}

@inproceedings{jia_vqlens_2025,
	address = {New York, NY, USA},
	series = {{SIGMOD}/{PODS} '25},
	title = {{VQLens}: {A} {Demonstration} of {Vector} {Query} {Execution} {Analysis}},
	isbn = {979-8-4007-1564-8},
	url = {https://doi.org/10.1145/3722212.3725142},
	doi = {10.1145/3722212.3725142},
	abstract = {With the increasing demand for high-speed similarity search over massive datasets, vector databases have become essential in modern data-intensive applications, particularly in LLMs and other AI-driven workloads. The growing complexity and scale of vector database operations demand more comprehensive evaluation methodologies. However, existing evaluation methodologies primarily rely on high-level information retrieval metrics (e.g., recall, accuracy) and system performance indicators (e.g., query latency, throughput), which fail to provide fine-grained insights. This limitation hinders the diagnosis of unexpected query results and the optimization of system performance. To bridge this gap, we present VQLens, an interactive visual analytics system for in-depth exploration of query execution traces and large-scale vector distributions. Specifically, VQLens (1) computes the overall data distribution and overlays query traces to reveal retrieval patterns, (2) visualizes query execution trace using multiple representations to enhance interpretability, and (3) enables interactive multi-view exploration, supporting both global pattern discovery and case-specific analysis. VQLens is open-source at https://github.com/DBGroup-SUSTech/VQLens.},
	booktitle = {Companion of the 2025 {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {Jia, Yansha and You, Zhengxin and Wang, Yujie and Shen, Qiaomu and Tang, Bo},
	year = {2025},
	note = {event-place: Berlin, Germany},
	keywords = {query execution, vector database, visual analytics system},
	pages = {267--270},
}

@inproceedings{wang_i-guide_2025,
	address = {New York, NY, USA},
	series = {{PEARC} '25},
	title = {I-{GUIDE} {Platform} for {Geospatial} {Data}-intensive {Convergence} {Research} and {Education}},
	isbn = {979-8-4007-1398-9},
	url = {https://doi.org/10.1145/3708035.3736108},
	doi = {10.1145/3708035.3736108},
	abstract = {The I-GUIDE Platform is a pioneering cyberinfrastructure environment designed to advance geospatial data-intensive convergence science and knowledge discovery across various domains. By integrating geospatial data, domain-specific knowledge elements, and open educational resources, the platform empowers researchers and practitioners to tackle complex scientific challenges cutting across multiple disciplines. This paper provides an overview of the motivation, architecture, principles, and applications and impacts of the platform, demonstrating how it fosters interdisciplinary collaboration and enables geospatial data-intensive convergence research and education.},
	booktitle = {Practice and {Experience} in {Advanced} {Research} {Computing} 2025: {The} {Power} of {Collaboration}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Shaowen and Baig, Furqan and Kang, Yunfan and Li, Erick and Michels, Alexander and Jaroenchai, Nattapon and Padmanabhan, Anand and Kumar, Arunesh and Kalyanam, Rajesh and S. Oller Smith, Noah and Song, X. Carol and Zhao, Lan and Manson, Steven and Ramamurthy, Mohan and Taghavikish, Sina and Tarboton, David},
	year = {2025},
	keywords = {cyberinfrastructure, geospatial artificial intelligence (AI), science gateway},
}

@inproceedings{xie_neighborhood-based_2024,
	address = {New York, NY, USA},
	series = {{RecSys} '24},
	title = {Neighborhood-{Based} {Collaborative} {Filtering} for {Conversational} {Recommendation}},
	isbn = {979-8-4007-0505-2},
	url = {https://doi.org/10.1145/3640457.3688191},
	doi = {10.1145/3640457.3688191},
	abstract = {Conversational recommender systems (CRS) should understand users’ expressed interests, which are frequently semantically rich and knowledge-intensive. Prior works attempt to address this challenge by using external knowledge bases or parametric knowledge in large language models (LLMs). In this paper, we study a complementary solution, exploiting item knowledge in the training data. We hypothesize that many inference-time user requests can be answered by reusing popular crowd-written answers associated with similar training queries. Following this intuition, we define a class of neighborhood-based CRS that makes recommendations by identifying items commonly associated with similar training dialogue contexts. Experiments on Inspired, Redial, and Reddit-Movie benchmarks show our method outperforms state-of-the-art LLMs with 2 billion parameters, and offers on-par performance to 7 billion parameter models while using over 170 times less GPU memory. We also show neighborhood and model-based predictions can be combined to achieve further performance improvements1.},
	booktitle = {Proceedings of the 18th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Xie, Zhouhang and Wu, Junda and Jeon, Hyunsik and He, Zhankui and Steck, Harald and Jha, Rahul and Liang, Dawen and Kallus, Nathan and Mcauley, Julian},
	year = {2024},
	note = {event-place: Bari, Italy},
	pages = {1045--1050},
}

@inproceedings{khatua_policies_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Policies for {Refugee} {Mental} {Health} {Using} {Generative} {Agents}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715580},
	doi = {10.1145/3701716.3715580},
	abstract = {In recent times, mental health has attracted the attention of researchers, and the extant literature has explored digital platforms to identify and analyze individuals' expressions of distress on social media platforms, such as depressive tweets, to probe various aspects of users' mental health. This unidirectional perspective often overlooks the societal context that may impact mental health. In the context of refugees' mental health, we propose a novel dual-perspective approach by examining both self-reflective tweets expressing emotional distress and hostile tweets from host country citizens. We employ large language models to extract and summarize crucial concerns from vast unstructured user-generated data, using them as input for our agent-based simulations for policy intervention. The proposed simulation-based approach suggests comprehensive policies to address displacement-related trauma and societal hostility faced by refugees in host countries.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Khatua, Aparup},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {generative agents, mental health, policy simulations, refugees},
	pages = {1062--1066},
}

@inproceedings{kim_conversational_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Conversational {Argument} {Search} {Under} {Selective} {Exposure}: {Strategies} for {Balanced} {Perspective} {Access}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730175},
	doi = {10.1145/3726302.3730175},
	abstract = {Conversational argument search systems influence how users access diverse perspectives but are prone to selective exposure. To address this, we propose two strategies: an interface-level multi-agent framework that structures perspective presentation and an interaction-level questioning strategy that encourages deeper engagement. We evaluate these strategies through a 2 x 2 factorial user study, examining their impact on selective exposure. Results show that the multi-agent setup facilitates broader perspective comparison, while agent-initiated questioning fosters deeper reflection; together, they promote more balanced argument access. Based on these findings, we discuss conversational search systems to mitigate selective exposure by implementing multi-agent interactions and questioning mechanisms.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Kim, Kyusik and Ryu, Jeongwoo and Heo, Dongseok and Song, Hyungwoo and Oh, Changhoon and Suh, Bongwon},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {argument search, conversational search, selective exposure},
	pages = {2837--2842},
}

@inproceedings{sun_timelinekgqa_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{TimelineKGQA}: {A} {Comprehensive} {Question}-{Answer} {Pair} {Generator} for {Temporal} {Knowledge} {Graphs}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715308},
	doi = {10.1145/3701716.3715308},
	abstract = {Question answering over temporal knowledge graphs (TKGs) is crucial for understanding evolving facts and relationships, yet its development is hindered by limited datasets and difficulties in generating custom QA pairs. We propose a novel categorization framework based on timeline-context relationships, along with TimelineKGQA, a universal temporal QA generator applicable to any TKGs. The code is available at: https://github.com/PascalSun/TimelineKGQA as an open source Python package.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Sun, Qiang and Li, Sirui and Huynh, Du and Reynolds, Mark and Liu, Wei},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {knowledge graph, question answering, temporal knowledge graph},
	pages = {797--800},
}

@inproceedings{zhu_ospc_2024,
	address = {New York, NY, USA},
	series = {{WWW} '24},
	title = {{OSPC}: {OCR}-{Assisted} {VLM} for {Zero}-{Shot} {Harmful} {Meme} {Detection}},
	isbn = {979-8-4007-0172-6},
	url = {https://doi.org/10.1145/3589335.3665994},
	doi = {10.1145/3589335.3665994},
	abstract = {Harmful memes refer to the memes which contain social bias towards a certain group, such as gender, race, disabilities and so on. Detecting these harmful memes requires the model to have both visual and linguistic understanding of memes and some external knowledge about the culture and morality. This technical report summarises the fourth place solution of the Online Safety Prize Challenge, which enhances a visual language model (VLM) by integrating external Optical Character Recognition (OCR) tools, employs prompt engineering and manual resource management to optimize performance within limited resource constraints. This strategy achieved a score of 0.723/0.643(AUROC/ACC) in this challenge with one single submission},
	booktitle = {Companion {Proceedings} of the {ACM} {Web} {Conference} 2024},
	publisher = {Association for Computing Machinery},
	author = {Zhu, Chenxi and Gao, Haotian and Duan, Yuxiao and Hao, Guo and Luo, Minnan and Zhao, Xiang},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	keywords = {meme, multi-modal, vision language models, zero-shot},
	pages = {1904--1907},
}

@inproceedings{shi_scalable_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Scalable {Overload}-{Aware} {Graph}-{Based} {Index} {Construction} for 10-{Billion}-{Scale} {Vector} {Similarity} {Search}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715576},
	doi = {10.1145/3701716.3715576},
	abstract = {Approximate Nearest Neighbor Search (ANNS) is essential for modern data-driven applications that require efficient retrieval of top-k results from massive vector databases. Although existing graph-based ANNS algorithms achieve a high recall rate on billion-scale datasets, their slow construction speed and limited scalability hinder their applicability to large-scale industrial scenarios. In this paper, we introduce SOGAIC, the first Scalable Overload-Aware Graph-Based ANNS Index Construction system tailored for ultra-large-scale vector databases: 1) We propose a dynamic data partitioning algorithm with overload constraints that adaptively introduces overlaps among subsets; 2) To enable efficient distributed subgraph construction, we employ an a load-balancing task scheduling framework combined with an agglomerative merging strategy; 3) Extensive experiments on various datasets demonstrate a reduction of 47.3\% in average construction time compared to existing methods. The proposed method has also been successfully deployed in a real-world industrial search engine, managing over 10 billion daily updated vectors and serving hundreds of millions of users.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Shi, Yang and Sun, Yiping and Du, Jiaolong and Zhong, Xiaocheng and Wang, Zhiyong and Hu, Yao},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {anns graph indexing, approximate nearest neighborhood search, data partitioning for distributed computing system, system and resource scalability},
	pages = {1303--1307},
}

@inproceedings{zhu_retrieval-augmented_2024,
	address = {New York, NY, USA},
	series = {{WWW} '24},
	title = {Retrieval-augmented {Query} {Reformulation} for {Heterogeneous} {Research} {Asset} {Retrieval} in {Virtual} {Research} {Environment}},
	isbn = {979-8-4007-0172-6},
	url = {https://doi.org/10.1145/3589335.3651553},
	doi = {10.1145/3589335.3651553},
	abstract = {Discovering and reusing research assets such as datasets and computational notebooks is crucial for building research workflows in data-centric studies. The rapid growth of research assets in scientific communities provides scientists with great opportunities to enhance research efficacy but also poses significant challenges in finding suitable materials for specific tasks. Scientists, especially those focusing on cross-disciplinary research, often find it difficult to formulate effective queries to retrieve desired resources. Previous work has proposed query reformulation methods to increase the efficiency of research asset search. However, it relies on existent knowledge graphs and is constrained to computational notebooks only. As research assets utilized by data analytic workflows are in essence heterogeneous, i.e., of distinct kinds and from diversified sources, query reformulation methods in this regard should consider the relationship between different types of research assets. To address the above challenges, we propose a retrieval-augmented query reformulation method for heterogeneous research asset retrieval. It is developed in the context of a Notebook-based virtual research environment (VRE) and offers query reformulation services to other VRE components. We demonstrate the effectiveness of the proposed query reformulation service with experiments on dataset and notebook retrieval. Up till now, we have indexed 8,954 datasets and 18,158 notebooks. The experimental results show that the proposed service can create useful query suggestions.},
	booktitle = {Companion {Proceedings} of the {ACM} {Web} {Conference} 2024},
	publisher = {Association for Computing Machinery},
	author = {Zhu, Peide and Li, Na and Zhao, Zhiming},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	keywords = {heterogeneous research asset retrieval, large language models, query reformulation},
	pages = {907--910},
}

@inproceedings{semenkin_context_2024,
	address = {New York, NY, USA},
	series = {{IDE} '24},
	title = {Context {Composing} for {Full} {Line} {Code} {Completion}},
	isbn = {979-8-4007-0580-9},
	url = {https://doi.org/10.1145/3643796.3648446},
	doi = {10.1145/3643796.3648446},
	abstract = {Code Completion is one of the most used Integrated Development Environment (IDE) features, which affects the everyday life of a software developer. Modern code completion approaches moved from the composition of several static analysis-based contributors to pipelines that involve neural networks. This change allows the proposal of longer code suggestions while maintaining the relatively short time spent on generation itself. At JetBrains, we put a lot of effort into perfecting the code completion workflow so it can be both helpful and non-distracting for a programmer. We managed to ship the Full Line Code Completion feature to PyCharm Pro IDE and proved its usefulness in A/B testing on hundreds of real Python users. The paper describes our approach to context composing for the Transformer model that is a core of the feature's implementation. In addition to that, we share our next steps to improve the feature and emphasize the importance of several research aspects in the area.},
	booktitle = {Proceedings of the 1st {ACM}/{IEEE} {Workshop} on {Integrated} {Development} {Environments}},
	publisher = {Association for Computing Machinery},
	author = {Semenkin, Anton and Sokolov, Yaroslav and Vu, Evgeniia},
	year = {2024},
	note = {event-place: Lisbon, Portugal},
	keywords = {artificial intelligence, code completion, context composing, integrated development environment, programming, prompt engineering, transformers},
	pages = {15--17},
}

@inproceedings{tsukuda_eliciting_2025,
	address = {New York, NY, USA},
	series = {{CHIIR} '25},
	title = {Eliciting {Implicit} {Information} {Needs} in {E}-{Commerce} {Search} by {Using} the {Think}-{Aloud} {Method}},
	isbn = {979-8-4007-1290-6},
	url = {https://doi.org/10.1145/3698204.3716461},
	doi = {10.1145/3698204.3716461},
	abstract = {In this paper, we elicit implicit information needs that arise during the process of deciding which products to purchase on e-commerce (EC) sites. We designed product purchase tasks to capture implicit information needs, and we conducted a user study to collect utterance data using a think-aloud method. By analyzing the utterances of participants during the tasks, we developed a taxonomy comprising five categories where people express preferences for products and 11 categories where people want to understand products. Our taxonomy includes implicit information needs that have not been captured in existing EC-related taxonomies (e.g., Preference for Subjective Attributes and Understanding Product Differences). We revealed the characteristics of each category of information need in terms of timing during the tasks: e.g., the information need of Understanding Product Range occurred very frequently in the early stage of a task. We also revealed the occurrence frequencies for different task types: e.g., the information needs of Preference for Objective Attributes, Understanding Product Range, and Understanding Terminology had a higher occurrence when purchasing products less frequently and at a higher cost than when purchasing products frequently at a relatively low cost. Our taxonomy could be used to further improve users’ purchasing processes on EC sites.},
	booktitle = {Proceedings of the 2025 {ACM} {SIGIR} {Conference} on {Human} {Information} {Interaction} and {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Tsukuda, Kosetsu and Maruta, Atsuki and Kato, Makoto P. and Joho, Hideo},
	year = {2025},
	keywords = {E-commerce, information needs, taxonomy, think-aloud method},
	pages = {292--297},
}

@inproceedings{jiang_gats_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {{GATS}: {Generative} {Audience} {Targeting} {System} for {Online} {Advertising}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3661372},
	doi = {10.1145/3626772.3661372},
	abstract = {This paper presents GATS (\&lt;u\&gt;G\&lt;/u\&gt;enerative \&lt;u\&gt;A\&lt;/u\&gt;udience \&lt;u\&gt;T\&lt;/u\&gt;argeting \&lt;u\&gt;S\&lt;/u\&gt; ystem for Online Advertising), a new framework using large language models (LLMs) to improve audience targeting in online advertising. GATS overcomes the shortcomings of rule-based, look-alike, and graph-based methods by facilitating flexible and interpretable audience criteria expression. The framework integrates intent recognition, knowledge mining, and Data Management Platform (DMP) mapping to translate advertiser demands into actionable user tags and correlate them within a DMP. A small, white-box model called LightGATS (base on QWen-14B), fine-tuned with a high-quality LLM corpus, ensures the framework's safety and efficiency, operating within a scalable hybrid online-offline architecture. GATS's effectiveness is validated through extensive experiments, marking a significant advancement in audience targeting technology.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Jiang, Cong and Chen, Zhongde and Zhang, Bo and Ren, Yankun and Dong, Xin and Cheng, Lei and Yang, Xinxing and Li, Longfei and Zhou, Jun and Mo, Linjian},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {audience targeting, large language models, multi-task fine-tuning, online advertising},
	pages = {2920--2924},
}

@inproceedings{carlson_dynamic_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Dynamic {Superblock} {Pruning} for {Fast} {Learned} {Sparse} {Retrieval}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730183},
	doi = {10.1145/3726302.3730183},
	abstract = {This paper proposes superblock pruning (SP) during top-k online document retrieval for learned sparse representations. SP structures the sparse index as a set of superblocks on a sequence of document blocks and conducts a superblock-level selection to decide if some superblocks can be pruned before visiting their child blocks. SP generalizes the previous flat block or cluster-based pruning, allowing the early detection of groups of documents that cannot or are less likely to appear in the final top-k list. SP can accelerate sparse retrieval in a rank-safe or approximate manner under a high-relevance competitiveness constraint. Our experiments show that the proposed scheme significantly outperforms state-of-the-art baselines on MS MARCO passages on a single-threaded CPU.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Carlson, Parker and Xie, Wentai and He, Shanxiu and Yang, Tao},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {dynamic pruning, efficiency, learned sparse retrieval},
	pages = {3004--3009},
}

@inproceedings{zhong_doctopus_2025,
	address = {New York, NY, USA},
	series = {{SIGMOD}/{PODS} '25},
	title = {Doctopus: {A} {System} for {Budget}-aware {Structural} {Data} {Extraction} from {Unstructured} {Documents}},
	isbn = {979-8-4007-1564-8},
	url = {https://doi.org/10.1145/3722212.3725103},
	doi = {10.1145/3722212.3725103},
	abstract = {Extracting structured data from unstructured documents is essential for applications like analytical SQL queries and decision-making. Strategies such as pre-trained language models (PLMs) can be employed, but they often fall short in quality. Large language models (LLMs) have shown effectiveness in attribute extraction but are costly, making them impractical for large-scale document sets. To best trade off quality and cost, we present Doctopus, a system designed for accurate and cost-effective attribute extraction. Overall, Doctopus combines LLMs with non-LLM strategies to achieve an optimal quality-cost balance. First, the system employs an index-based approach to efficiently identify and process only relevant chunks. Afterwards, it further estimates the quality of multiple strategies for each attribute. Finally, based on the cost and estimated quality, Doctopus dynamically selects the optimal strategies through budget-aware optimization. With a real-life scenario, we demonstrate that Doctopus allows users to extract attributes accurately and affordably. The corresponding video is available at https://youtu.be/Cxl\_PfvZY10?si=NYoHt2SyD9KHqd6V.},
	booktitle = {Companion of the 2025 {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {Zhong, Yuanhao and Deng, Yuhao and Chai, Chengliang and Gu, Ruixin and Yuan, Ye and Wang, Guoren and Cao, Lei},
	year = {2025},
	note = {event-place: Berlin, Germany},
	keywords = {cost optimization, information extraction, query enhancement},
	pages = {275--278},
}

@inproceedings{liu_robust-ir_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Robust-{IR} @ {SIGIR} 2025: {The} {First} {Workshop} on {Robust} {Information} {Retrieval}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730355},
	doi = {10.1145/3726302.3730355},
	abstract = {With the advancement of information retrieval (IR) technologies, robustness is increasingly attracting attention. When deploying technology into practice, we consider not only its average performance under normal conditions but, more importantly, its ability to maintain functionality across a variety of exceptional situations. In recent years, the research on IR robustness covers theory, evaluation, methodology, and application, and all of them show a growing trend. The purpose of this workshop is to systematize the latest results of each research aspect, to foster comprehensive communication within this niche domain while also bridging robust IR research with the broader community, and to promote further future development of robust IR. To avoid the one-sided talk of mini-conferences, this workshop adopts a highly interactive format, including round-table and panel discussion sessions, to encourage active participation and meaningful exchange among attendees.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Yu-An and Nachimovsky, Haya and Zhang, Ruqing and Kurland, Oren and Guo, Jiafeng and Tennenholtz, Moshe},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {competitive search, information retrieval, robustness},
	pages = {4142--4145},
}

@inproceedings{su_parametric_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Parametric {Retrieval} {Augmented} {Generation}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3729957},
	doi = {10.1145/3726302.3729957},
	abstract = {Retrieval-augmented generation (RAG) has emerged as a promising solution to enhance the reliability of large language models (LLMs) with external knowledge. Existing RAG methods share a common strategy for knowledge injection: they place the retrieved documents into the input context of the LLM, which we refer to as the in-context knowledge injection method. While this approach is simple and often effective, it has inherent limitations. Firstly, increasing the context length and number of relevant documents can lead to higher computational overhead and degraded performance, especially in complex reasoning tasks. More importantly, in-context knowledge injection operates primarily at the input level, but LLMs store their internal knowledge in their parameters. This gap fundamentally limits the capacity of in-context methods. To this end, we introduce Parametric RAG, a new RAG paradigm that integrates external knowledge directly into the feed-forward networks of an LLM through document parameterization. This approach not only reduces online computational costs by shortening the input context length, but also deepens the integration of external knowledge by enabling LLMs to utilize it in the same way as internal parametric knowledge. Experimental results demonstrate that Parametric RAG substantially enhances the effectiveness and efficiency of knowledge augmentation in LLMs. Also, it can be combined with in-context RAG methods to achieve even better performance. We have open-sourced all the code, data, and models in the following GitHub link: https://github.com/oneal2000/PRAG},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Su, Weihang and Tang, Yichen and Ai, Qingyao and Yan, Junxi and Wang, Changyue and Wang, Hongning and Ye, Ziyi and Zhou, Yujia and Liu, Yiqun},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {large language model, retrieval augmented generation},
	pages = {1240--1250},
}

@inproceedings{afzal_towards_2025,
	address = {New York, NY, USA},
	series = {{NLPIR} '24},
	title = {Towards {Optimizing} a {Retrieval} {Augmented} {Generation} using {Large} {Language} {Model} on {Academic} {Data}},
	isbn = {979-8-4007-1738-3},
	url = {https://doi.org/10.1145/3711542.3711575},
	doi = {10.1145/3711542.3711575},
	abstract = {Given the growing trend of many organizations integrating Retrieval Augmented Generation (RAG) into their operations, we assess RAG on domain-specific data and test state-of-the-art models across various optimization techniques. We incorporate four optimizations; Multi-Query, Child-Parent-Retriever, Ensemble Retriever, and In-Context-Learning, to enhance the functionality and performance in the academic domain. We focus on data retrieval, specifically targeting various study programs at a large technical university. We additionally introduce a novel evaluation approach, the RAG Confusion Matrix designed to assess the effectiveness of various configurations within the RAG framework. By exploring the integration of both open-source (e.g., Llama2, Mistral) and closed-source (GPT-3.5 and GPT-4) Large Language Models, we offer valuable insights into the application and optimization of RAG frameworks in domain-specific contexts. Our experiments show a significant performance increase when including multi-query in the retrieval phase.},
	booktitle = {Proceedings of the 2024 8th {International} {Conference} on {Natural} {Language} {Processing} and {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Afzal, Anum and Vladika, Juraj and Fazlija, Gentrit and Staradubets, Andrei and Matthes, Florian},
	year = {2025},
	keywords = {Benchmark, Large Language Models, Retrieval Augmented Generation},
	pages = {250--257},
}

@inproceedings{wallat_correctness_2025,
	address = {New York, NY, USA},
	series = {{ICTIR} '25},
	title = {Correctness is not {Faithfulness} in {Retrieval} {Augmented} {Generation} {Attributions}},
	isbn = {979-8-4007-1861-8},
	url = {https://doi.org/10.1145/3731120.3744592},
	doi = {10.1145/3731120.3744592},
	abstract = {Large language models (LLMs) have transformed information retrieval through chat interfaces, but their hallucination tendencies pose significant risks. While Retrieval Augmented Generation (RAG) with citations has emerged as a solution by allowing users to verify responses through source attribution, current evaluation approaches focus primarily on citation correctness - whether cited documents support the corresponding statements. This is insufficient and we introduce citation faithfulness - whether the model's reliance on cited documents is genuine rather than post-rationalized to fit pre-existing knowledge. Our contributions are threefold: (i) we introduce coherent notions of attribution and introduce the concept of citation faithfulness; (ii) we propose desiderata for citations beyond correctness and accuracy needed for trustworthy systems; and (iii) we emphasize evaluating citation faithfulness by studying post-rationalization. Through experimentation, we reveal prevalent post-rationalization issues, finding that up to 57\% of citations lack faithfulness. This undermines reliable attribution and may result in misplaced trust, highlighting a critical gap in current LLM-based IR systems. We demonstrate why both citation correctness and faithfulness must be considered when deploying LLMs in IR applications, contributing to a broader discussion of building more reliable and transparent information access systems.},
	booktitle = {Proceedings of the 2025 {International} {ACM} {SIGIR} {Conference} on {Innovative} {Concepts} and {Theories} in {Information} {Retrieval} ({ICTIR})},
	publisher = {Association for Computing Machinery},
	author = {Wallat, Jonas and Heuss, Maria and Rijke, Maarten de and Anand, Avishek},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {attributions, faithfulness, interpretability, large language models, retrieval-augmented generation, self-explanations},
	pages = {22--32},
}

@inproceedings{merker_axioms_2025,
	address = {New York, NY, USA},
	series = {{ICTIR} '25},
	title = {Axioms for {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-1861-8},
	url = {https://doi.org/10.1145/3731120.3744601},
	doi = {10.1145/3731120.3744601},
	abstract = {Information retrieval axioms are formalized constraints that good retrieval models should fulfill, e.g., to rank documents higher that contain the query terms more often. Over the last decades, more than 25 such axioms have been proposed and used to analyze, to improve, or to explain retrieval models. However, those axioms were meant for document ranking scenarios and thus do not directly fit the new scenario of retrieval-augmented generation systems (RAG). To close this gap, we rethink retrieval axioms for RAG. First, we transfer the underlying ideas of as many of the traditional axioms as possible to the new RAG setting (18 axioms can be transferred), and second, we suggest and formalize 11 new axioms to capture utility aspects of RAG answers. In experiments on the TREC 2024 RAG track data and on the Webis-CrowdRAG-25 corpus, we show that the new axioms more accurately capture automated and human RAG preferences than the transferred traditional axioms. Furthermore, we illustrate practical applications for inspecting preferences of language models and for aiding human preference judgments.},
	booktitle = {Proceedings of the 2025 {International} {ACM} {SIGIR} {Conference} on {Innovative} {Concepts} and {Theories} in {Information} {Retrieval} ({ICTIR})},
	publisher = {Association for Computing Machinery},
	author = {Merker, Jan Heinrich and Fröbe, Maik and Stein, Benno and Potthast, Martin and Hagen, Matthias},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {preferences, retrieval axioms, retrieval-augmented generation},
	pages = {67--77},
}

@inproceedings{dong_understand_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Understand {What} {LLM} {Needs}: {Dual} {Preference} {Alignment} for {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714717},
	doi = {10.1145/3696410.3714717},
	abstract = {Retrieval-augmented generation (RAG) has effectively mitigated the hallucination problem of large language models (LLMs). However, the difficulty of aligning the retriever with the LLMs' diverse knowledge preferences inevitably poses a challenge in developing a reliable RAG system. To address this issue, we propose DPA-RAG, a universal framework designed to align diverse knowledge preferences within RAG systems. Specifically, we initially introduce a preference knowledge construction pipeline and incorporate five novel query augmentation strategies to alleviate preference data scarcity. Based on preference data, DPA-RAG accomplishes both external and internal preference alignment: 1) It jointly integrates pairwise, pointwise, and contrastive preference alignment abilities into the reranker, achieving external preference alignment among RAG components. 2) It further introduces a pre-aligned stage before vanilla Supervised Fine-tuning (SFT), enabling LLMs to implicitly capture knowledge aligned with their reasoning preferences, achieving LLMs' internal alignment. Experimental results across four knowledge-intensive QA datasets demonstrate that DPA-RAG outperforms all baselines and seamlessly integrates both black-box and open-sourced LLM readers. Further qualitative analysis and discussions provide empirical guidance for achieving reliable RAG systems. Our code and example dataset are available at https://github.com/dongguanting/DPA-RAG.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Dong, Guanting and Zhu, Yutao and Zhang, Chenghao and Wang, Zechen and Wen, Ji-Rong and Dou, Zhicheng},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {large language model, retrieval-augmented generation},
	pages = {4206--4225},
}

@inproceedings{jiang_rago_2025,
	address = {New York, NY, USA},
	series = {{ISCA} '25},
	title = {{RAGO}: {Systematic} {Performance} {Optimization} for {Retrieval}-{Augmented} {Generation} {Serving}},
	isbn = {979-8-4007-1261-6},
	url = {https://doi.org/10.1145/3695053.3731093},
	doi = {10.1145/3695053.3731093},
	abstract = {Retrieval-augmented generation (RAG) is emerging as a popular approach for reliable LLM serving. However, efficient RAG serving remains an open challenge due to the rapid emergence of many RAG variants and the substantial differences in workload characteristics across them. This paper makes three fundamental contributions to advancing RAG serving. First, we introduce RAGSchema, a structured abstraction that captures the wide range of RAG algorithms, serving as a foundation for performance optimization. Second, we analyze several representative RAG workloads with distinct RAGSchema, revealing significant performance variability across these workloads. Third, to address this variability and meet diverse performance requirements, we propose RAGO (Retrieval-Augmented Generation Optimizer), a system optimization framework for efficient RAG serving. RAGO achieves up to a 2 × increase in QPS per chip and a 55\% reduction in time-to-first-token latency compared to RAG systems built on LLM-system extensions.},
	booktitle = {Proceedings of the 52nd {Annual} {International} {Symposium} on {Computer} {Architecture}},
	publisher = {Association for Computing Machinery},
	author = {Jiang, Wenqi and Subramanian, Suvinay and Graves, Cat and Alonso, Gustavo and Yazdanbakhsh, Amir and Dadu, Vidushi},
	year = {2025},
	keywords = {Computer Architecture, Computer System, Large Language Model, Performance Optimization, Retrieval-Augmented Generation},
	pages = {974--989},
}

@inproceedings{song_urag_2025,
	address = {New York, NY, USA},
	series = {{ICCIP} '24},
	title = {{URAG}: {Unified} {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-1744-4},
	url = {https://doi.org/10.1145/3708657.3708763},
	doi = {10.1145/3708657.3708763},
	abstract = {To address the issues of insufficient retrieval capabilities and "hallucinations" in responses generated by large models, this paper proposes a knowledge question-answering framework based on Unified Retrieval-Augmented Generation (URAG). The framework integrates three retrieval mechanisms—keyword retrieval, vector retrieval, and graph retrieval—enabling efficient and high-quality utilization of massive, multi-source, and heterogeneous data. It effectively overcomes the limitations of a single retrieval pathway. Experimental results demonstrate that the URAG framework excels across various task scenarios, enhancing the accuracy and comprehensiveness of knowledge retrieval. Its advantage is particularly evident when dealing with multi-dimensional and multi-layered information. In conclusion, the Unified Retrieval-Augmented Generation technique offers a new method for improving the performance of intelligent question-answering systems, with broad application prospects and research value. This study provides valuable insights into understanding RAG (Retrieval-Augmented Generation) technology and its application in large language models.},
	booktitle = {Proceedings of the 2024 10th {International} {Conference} on {Communication} and {Information} {Processing}},
	publisher = {Association for Computing Machinery},
	author = {Song, Yulun and Yan, Long and Qin, Lina and Wang, Gongju and Huang, Xingru and Hu, Luzhe and Liu, Weixin},
	year = {2025},
	keywords = {Accuracy and comprehensiveness in knowledge retrieval, Multi-source heterogeneous data, Unified Retrieval-Augmented Generation (URAG)},
	pages = {660--667},
}

@inproceedings{wu_retrieval_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Retrieval {Augmented} {Generation} for {Dynamic} {Graph} {Modeling}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3729958},
	doi = {10.1145/3726302.3729958},
	abstract = {Modeling dynamic graphs, such as those found in social networks, recommendation systems, and e-commerce platforms, is crucial for capturing evolving relationships and delivering relevant insights over time. Traditional approaches primarily rely on graph neural networks with temporal components or sequence generation models, which often focus narrowly on the historical context of target nodes. This limitation restricts the ability to adapt to new and emerging patterns in dynamic graphs. To address this challenge, we propose a novel framework, Retrieval-Augmented Generation for Dy namic Graph modeling (RAG4DyG ), which enhances dynamic graph predictions by incorporating contextually and temporally relevant examples from broader graph structures. Our approach includes a time- and context-aware contrastive learning module to identify high-quality demonstrations and a graph fusion strategy to effectively integrate these examples with historical contexts. The proposed framework is designed to be effective in both transductive and inductive scenarios, ensuring adaptability to previously unseen nodes and evolving graph structures. Extensive experiments across multiple real-world datasets demonstrate the effectiveness of RAG4DyG in improving predictive accuracy and adaptability for dynamic graph modeling. The code and datasets are publicly available at https://github.com/YuxiaWu/RAG4DyG.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Wu, Yuxia and Liao, Lizi and Fang, Yuan},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {dynamic graph modeling, graph neural networks, retrieval-augmented generation},
	pages = {1434--1443},
}

@inproceedings{liu_dragon_2025,
	address = {New York, NY, USA},
	series = {{MobiHoc} '25},
	title = {{DRAGON}: {Enhancing} {On}-{Device} {Model} {Performance} with {Distributed} {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-1353-8},
	url = {https://doi.org/10.1145/3704413.3764419},
	doi = {10.1145/3704413.3764419},
	abstract = {Small language models (SLMs) support efficient deployments on resource-constrained edge devices, but their limited capacity compromises inference performance. Retrieval-augmented generation (RAG) is a promising solution to enhance model performance by integrating external databases, without requiring intensive on-device model retraining. However, large-scale public databases and user-specific private contextual documents are typically located on the cloud and the device, respectively, while existing RAG implementations are primarily centralized. To bridge this gap, we propose DRAGON, a distributed RAG framework to enhance on-device SLMs through both general and personal knowledge without the risk of leaking document privacy. Specifically, DRAGON decomposes multi-document RAG into multiple parallel token generation processes performed independently and locally on the cloud and the device, and employs a newly designed Speculative Aggregation, a dual-side speculative algorithm to avoid frequent output synchronization between the cloud and device. A new scheduling algorithm is further introduced to identify the optimal aggregation side based on real-time network conditions. Evaluations on real-world hardware testbed demonstrate a significant performance improvement of DRAGON—up to 1.9X greater gains over standalone SLM compared to the centralized RAG, substantial reduction in per-token latency, and negligible Time to First Token (TTFT) overhead.},
	booktitle = {Proceedings of the {Twenty}-{Sixth} {International} {Symposium} on {Theory}, {Algorithmic} {Foundations}, and {Protocol} {Design} for {Mobile} {Networks} and {Mobile} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Shangyu and Zheng, Zhenzhe and Huang, Xiaoyao and Wu, Fan and Chen, Guihai and Wu, Jie},
	year = {2025},
	note = {event-place: Rice University, Houston, TX, USA},
	keywords = {device-cloud collaborative inference, large language model, retrieval-augmented generation, speculative aggregation},
	pages = {221--230},
}

@inproceedings{wang_instructrag_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{InstructRAG}: {Leveraging} {Retrieval}-{Augmented} {Generation} on {Instruction} {Graphs} for {LLM}-{Based} {Task} {Planning}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730009},
	doi = {10.1145/3726302.3730009},
	abstract = {Recent advancements in large language models (LLMs) have enabled their use as agents for planning complex tasks. Existing methods typically rely on a thought-action-observation (TAO) process to enhance LLM performance, but these approaches are often constrained by the LLMs' limited knowledge of complex tasks. Retrieval-augmented generation (RAG) offers new opportunities by leveraging external databases to ground generation in retrieved information. In this paper, we identify two key challenges (enlargability and transferability) in applying RAG to task planning. We propose InstructRAG, a novel solution within a multi-agent meta-reinforcement learning framework, to address these challenges. InstructRAG includes a graph to organize past instruction paths (sequences of correct actions), an RL-Agent with Reinforcement Learning to expand graph coverage for enlargability, and an ML-Agent with Meta-Learning to improve task generalization for transferability. The two agents are trained end-to-end to optimize overall planning performance. Our experiments on four widely used task planning datasets demonstrate that InstructRAG significantly enhances performance and adapts efficiently to new tasks, achieving up to a 19.2\% improvement over the best existing approach.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Zheng and Teo, Shu Xian and Chew, Jun Jie and Shi, Wei},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {agent planning, large language model, retrieval-augmented generation},
	pages = {1413--1422},
}

@inproceedings{zhang_traceback_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Traceback of {Poisoning} {Attacks} to {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714756},
	doi = {10.1145/3696410.3714756},
	abstract = {Large language models (LLMs) integrated with retrieval-augmented generation (RAG) systems improve accuracy by leveraging external knowledge sources. However, recent research has revealed RAG's susceptibility to poisoning attacks, where the attacker injects poisoned texts into the knowledge database, leading to attacker-desired responses. Existing defenses, which predominantly focus on inference-time mitigation, have proven insufficient against sophisticated attacks. In this paper, we introduce RAGForensics, the first traceback system for RAG, designed to identify poisoned texts within the knowledge database that are responsible for the attacks. RAGForensics operates iteratively, first retrieving a subset of texts from the database and then utilizing a specially crafted prompt to guide an LLM in detecting potential poisoning texts. Empirical evaluations across multiple datasets demonstrate the effectiveness of RAGForensics against state-of-the-art poisoning attacks. This work pioneers the traceback of poisoned texts in RAG systems, providing a practical and promising defense mechanism to enhance their security.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Baolei and Xin, Haoran and Fang, Minghong and Liu, Zhuqing and Yi, Biao and Li, Tong and Liu, Zheli},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {poisoning attacks, retrieval-augmented generation, traceback},
	pages = {2085--2097},
}

@inproceedings{wang_unveiling_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Unveiling {Knowledge} {Utilization} {Mechanisms} in {LLM}-based {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730112},
	doi = {10.1145/3726302.3730112},
	abstract = {Considering the inherent limitations of parametric knowledge in large language models (LLMs), retrieval-augmented generation (RAG) is widely employed to expand their knowledge scope. Since RAG has shown promise in knowledge-intensive tasks like open-domain question answering, its broader application to complex tasks and intelligent assistants has further advanced its utility. Despite this progress, the underlying knowledge utilization mechanisms of LLM-based RAG remain underexplored. In this paper, we present a systematic investigation of the intrinsic mechanisms by which LLMs integrate internal (parametric) and external (retrieved) knowledge in RAG scenarios. Specially, we employ knowledge stream analysis at the macroscopic level, and investigate the function of individual modules at the microscopic level. Drawing on knowledge streaming analyses, we decompose the knowledge utilization process into four distinct stages within LLM layers: knowledge refinement, knowledge elicitation, knowledge expression, and knowledge contestation. We further demonstrate that the relevance of passages guides the streaming of knowledge through these stages. At the module level, we introduce a new method, knowledge activation probability entropy (KAPE) for neuron identification associated with either internal or external knowledge. By selectively deactivating these neurons, we achieve targeted shifts in the LLM's reliance on one knowledge source over the other. Moreover, we discern complementary roles for multi-head attention and multi-layer perceptron layers during knowledge formation. These insights offer a foundation for improving interpretability and reliability in retrieval-augmented LLMs, paving the way for more robust and transparent generative solutions in knowledge-intensive domains.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Yuhao and Ren, Ruiyang and Wang, Yucheng and Zhao, Wayne Xin and Liu, Jing and Wu, Hua and Wang, Haifeng},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {knowledge utilization, large language models, retrieval-augmented generation},
	pages = {1262--1271},
}

@inproceedings{wu_time-sensitve_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {Time-{Sensitve} {Retrieval}-{Augmented} {Generation} for {Question} {Answering}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3679800},
	doi = {10.1145/3627673.3679800},
	abstract = {Retrieval-augmented generation (RAG) enhances large language models (LLMs) by accessing external data sources, offering a promising way to improve accuracy and reliability. Despite its potential, conventional retrievers encounter bias and flaws with time-sensitive queries. In this paper, a benchmark query dataset is constructed to retrieve documents containing time-evolving facts, and the results show that current embedding-based similarity-matching methods struggle to handle queries with explicit temporal constraints. Therefore, we propose a novel approach that integrates supervised contrastive learning with tailored negative sample pairs for temporal constraints to train the retriever of an RAG system, along with query-side fine-tuning and routing techniques. Experimental results show that our approach significantly enhances the retriever performance of time-sensitive queries while ensuring the effectiveness of general queries. We will make the code and dataset publicly available at https://github.com/suzhou-22/TS-Retriever.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Wu, Feifan and Liu, Lingyuan and He, Wentao and Liu, Ziqi and Zhang, Zhiqiang and Wang, Haofen and Wang, Meng},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {large language model, retrieval-augmented generation, retriever, supervised contrastive learning},
	pages = {2544--2553},
}

@inproceedings{guerraoui_efficient_2025,
	address = {New York, NY, USA},
	series = {{EuroMLSys} '25},
	title = {Efficient {Federated} {Search} for {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-1538-9},
	url = {https://doi.org/10.1145/3721146.3721942},
	doi = {10.1145/3721146.3721942},
	abstract = {Large language models (LLMs) have demonstrated remarkable capabilities across various domains but remain susceptible to hallucinations and inconsistencies, limiting their reliability. Retrieval-augmented generation (RAG) mitigates these issues by grounding model responses in external knowledge sources. Existing RAG workflows often leverage a single vector database, which is impractical in the common setting where information is distributed across multiple repositories. We introduce RAGRoute, a novel mechanism for federated RAG search. RAGRoute dynamically selects relevant data sources at query time using a lightweight neural network classifier. By not querying every data source, this approach significantly reduces query overhead, improves retrieval efficiency, and minimizes the retrieval of irrelevant information. We evaluate RAGRoute using the MIRAGE and MMLU benchmarks and demonstrate its effectiveness in retrieving relevant documents while reducing the number of queries. RAGRoute reduces the total number of queries up to 77.5\% and communication volume up to 76.2\%.},
	booktitle = {Proceedings of the 5th {Workshop} on {Machine} {Learning} and {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Guerraoui, Rachid and Kermarrec, Anne-Marie and Petrescu, Diana and Pires, Rafael and Randl, Mathis and de Vos, Martijn},
	year = {2025},
	note = {event-place: World Trade Center, Rotterdam, Netherlands},
	keywords = {federated search, large language models, resource selection, retrieval-augmented generation, routing},
	pages = {74--81},
}

@inproceedings{cheng_ragtrace_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {{RAGTrace}: {Understanding} and {Refining} {Retrieval}-{Generation} {Dynamics} in {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747741},
	doi = {10.1145/3746059.3747741},
	abstract = {Retrieval-Augmented Generation (RAG) systems have emerged as a promising solution to enhance large language models (LLMs) by integrating external knowledge retrieval with generative capabilities. While significant advancements have been made in improving retrieval accuracy and response quality, a critical challenge remains that the internal knowledge integration and retrieval-generation interactions in RAG workflows are largely opaque. This paper introduces RAGTrace, an interactive evaluation system designed to analyze retrieval and generation dynamics in RAG-based workflows. Informed by a comprehensive literature review and expert interviews, the system supports a multi-level analysis approach, ranging from high-level performance evaluation to fine-grained examination of retrieval relevance, generation fidelity, and cross-component interactions. Unlike conventional evaluation practices that focus on isolated retrieval or generation quality assessments, RAGTrace enables an integrated exploration of retrieval-generation relationships, allowing users to trace knowledge sources and identify potential failure cases. The system’s workflow allows users to build, evaluate, and iterate on retrieval processes tailored to their specific domains of interest. The effectiveness of the system is demonstrated through case studies and expert evaluations on real-world RAG applications.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Cheng, Sizhe and Li, Jiaping and Wang, Huanchen and Ma, Yuxin},
	year = {2025},
	keywords = {Evaluation, Knowledge Tracking, Retrieval-Augmented Generation},
}

@inproceedings{jiang_piperag_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{PipeRAG}: {Fast} {Retrieval}-{Augmented} {Generation} via {Adaptive} {Pipeline} {Parallelism}},
	isbn = {979-8-4007-1245-6},
	url = {https://doi.org/10.1145/3690624.3709194},
	doi = {10.1145/3690624.3709194},
	abstract = {Retrieval-augmented generation (RAG) can enhance the generation quality of large language models (LLMs) by incorporating external token databases. However, retrievals from large databases can constitute a substantial portion of the overall generation time, particularly when retrievals are periodically performed to align the retrieved content with the latest states of generation. In this paper, we introduce PipeRAG, a novel algorithm-system co-design approach to reduce generation latency and enhance generation quality. PipeRAG integrates (1) pipeline parallelism to enable concurrent retrieval and generation processes, (2) flexible retrieval intervals to maximize the efficiency of pipeline parallelism, and (3) a performance model to automatically balance retrieval quality and latency based on the generation states and underlying hardware. Our evaluation shows that, by combining the three aforementioned methods, PipeRAG achieves up to 2.6× speedup in end-to-end generation latency while improving generation quality. These promising results showcase the effectiveness of co-designing algorithms with underlying systems, paving the way for the adoption of PipeRAG in future RAG systems.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.1},
	publisher = {Association for Computing Machinery},
	author = {Jiang, Wenqi and Zhang, Shuai and Han, Boran and Wang, Jie and Wang, Bernie and Kraska, Tim},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {computer systems, retrieval-augmented generation, vector search},
	pages = {589--600},
}

@inproceedings{li_knowtrace_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{KnowTrace}: {Bootstrapping} {Iterative} {Retrieval}-{Augmented} {Generation} with {Structured} {Knowledge} {Tracing}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737015},
	doi = {10.1145/3711896.3737015},
	abstract = {Recent advances in retrieval-augmented generation (RAG) furnish large language models (LLMs) with iterative retrievals of relevant information to handle complex multi-hop questions. These methods typically alternate between LLM reasoning and retrieval to accumulate external information into the LLM's context. However, the ever-growing context inherently imposes an increasing burden on the LLM to perceive connections among critical information pieces, with futile reasoning steps further exacerbating this overload issue. In this paper, we present KnowTrace, an elegant RAG framework to (1) mitigate the context overload and (2) bootstrap higher-quality multi-step reasoning. Instead of simply piling the retrieved contents, KnowTrace autonomously traces out desired knowledge triplets to organize a specific knowledge graph relevant to the input question. Such a structured workflow not only empowers the LLM with an intelligible context for inference, but also naturally inspires a reflective mechanism of knowledge backtracing to identify contributive LLM generations as process supervision data for self-bootstrapping. Extensive experiments show that KnowTrace consistently surpasses existing methods across three multi-hop question answering benchmarks, and the bootstrapped version further amplifies the gains.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Li, Rui and Dai, Quanyu and Zhang, Zeyu and Chen, Xu and Dong, Zhenhua and Wen, Ji-Rong},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {large language models, retrieval-augmented generation},
	pages = {1470--1480},
}

@inproceedings{pinna_integration_2025,
	address = {New York, NY, USA},
	series = {{PETRA} '25},
	title = {Integration of {Retrieval}-{Augmented} {Generation} {Technique} for {LLM}-based {Differential} {Diagnosis} {Assistant}},
	isbn = {979-8-4007-1402-3},
	url = {https://doi.org/10.1145/3733155.3733192},
	doi = {10.1145/3733155.3733192},
	abstract = {Artificial Intelligence (AI) is increasingly transforming the medical field, offering significant potential for diagnosis, treatment, and patient care. However, its successful integration relies on healthcare professionals, such as doctors, psychologists, and nurses, trusting the technology’s reliability and accuracy. For Large Language Models (LLMs), this trust requires transparent, verifiable, and rigorously reviewed information sources. This paper presents an AI-powered tool for differential diagnosis and disease comparison, utilizing an LLM enhanced by Retrieval-Augmented Generation (RAG). RAG overcomes traditional LLM limitations by enabling access to external, domain-specific knowledge, ensuring accurate and contextually relevant responses. The system leverages PubMed, a biomedical article aggregator, to extract symptom-related information from scientific literature on various disorders. Evaluations involving psychologist-administered questionnaires demonstrate that combining a similarity score with detailed symptom descriptions provides a clear understanding of relationships between disorders. This approach may enhance diagnostic precision and build trust in AI-driven tools, encouraging their broader adoption in clinical practice.},
	booktitle = {Proceedings of the 18th {ACM} {International} {Conference} on {PErvasive} {Technologies} {Related} to {Assistive} {Environments}},
	publisher = {Association for Computing Machinery},
	author = {Pinna, Simone and Massa, Silvia Maria and Fenu, Matteo and Casti, Giulio and Riboni, Daniele},
	year = {2025},
	keywords = {Differential diagnosis, e-Health, Large Language Models, Retrieval-Augmented Generation},
	pages = {277--284},
}

@inproceedings{jang_au-rag_2024,
	address = {New York, NY, USA},
	series = {{SIGIR}-{AP} 2024},
	title = {{AU}-{RAG}: {Agent}-based {Universal} {Retrieval} {Augmented} {Generation}},
	isbn = {979-8-4007-0724-7},
	url = {https://doi.org/10.1145/3673791.3698416},
	doi = {10.1145/3673791.3698416},
	abstract = {Retrieval Augmented Generation (RAG) has been effectively used to improve the accuracy of question-answering (Q\&amp;A) systems powered by Large Language Models (LLMs) by integrating local knowledge and more up-to-date content. However, traditional RAG methods, including those with re-ranking mechanisms, face challenges when dealing with large, frequently updated data sources or when accessing sources exclusively via APIs, as they require pre-encoding all content into embedding vectors. To address these limitations, we introduce Agent-based Universal RAG (AU-RAG), a novel approach that augments data sources with descriptive metadata, allowing an agent to dynamically search through diverse data pools. This agent-driven system can learn from examples to retrieve and consolidate data from various sources on the fly, functioning as a more flexible and adaptive RAG. We demonstrate AU-RAG's functionality with a financial analysis example and evaluate its performance using a multi-source QA dataset. The results show that AU-RAG performs comparably to RAG with re-ranking in data retrieval tasks while also demonstrating an enhanced ability to intelligently learn and access new data sources from examples, making it a robust solution for dynamic and complex information environments.},
	booktitle = {Proceedings of the 2024 {Annual} {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval} in the {Asia} {Pacific} {Region}},
	publisher = {Association for Computing Machinery},
	author = {Jang, Jisoo and Li, Wen-Syan},
	year = {2024},
	note = {event-place: Tokyo, Japan},
	keywords = {agent, large language models, mediation, retrieval augmented generation},
	pages = {2--11},
}

@inproceedings{bergman_leveraging_2025,
	address = {New York, NY, USA},
	series = {{EuroMLSys} '25},
	title = {Leveraging {Approximate} {Caching} for {Faster} {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-1538-9},
	url = {https://doi.org/10.1145/3721146.3721941},
	doi = {10.1145/3721146.3721941},
	abstract = {Retrieval-augmented generation (RAG) enhances the reliability of large language model (LLM) answers by integrating external knowledge. However, RAG increases the end-to-end inference time since looking for relevant documents from large vector databases is computationally expensive. To address this, we introduce Proximity, an approximate key-value cache that optimizes the RAG workflow by leveraging similarities in user queries. Instead of treating each query independently, Proximity reuses previously retrieved documents when similar queries appear, reducing reliance on expensive vector database lookups. We evaluate Proximity on the MMLU and MedRAG benchmarks, demonstrating that it significantly improves retrieval efficiency while maintaining response accuracy. Proximity reduces retrieval latency by up to 59\% while maintaining accuracy and lowers the computational burden on the vector database. We also experiment with different similarity thresholds and quantify the trade-off between speed and recall. Our work shows that approximate caching is a viable and effective strategy for optimizing RAG-based systems.},
	booktitle = {Proceedings of the 5th {Workshop} on {Machine} {Learning} and {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Bergman, Shai Aviram and Ji, Zhang and Kermarrec, Anne-Marie and Petrescu, Diana and Pires, Rafael and Randl, Mathis and de Vos, Martijn},
	year = {2025},
	note = {event-place: World Trade Center, Rotterdam, Netherlands},
	keywords = {approximate caching, large language models, latency reduction, machine learning systems, neural information retrieval, query optimization, retrieval-augmented generation, vector databases},
	pages = {66--73},
}

@inproceedings{mahapatra_-storage_2025,
	address = {New York, NY, USA},
	series = {{ISCA} '25},
	title = {In-{Storage} {Acceleration} of {Retrieval} {Augmented} {Generation} as a {Service}},
	isbn = {979-8-4007-1261-6},
	url = {https://doi.org/10.1145/3695053.3731032},
	doi = {10.1145/3695053.3731032},
	abstract = {Retrieval-augmented generation (RAG) services are rapidly gaining adoption in enterprise settings as they combine information retrieval systems (e.g., databases) with large language models (LLMs) to enhance response generation and reduce hallucinations. By augmenting an LLM’s fixed pre-trained knowledge with real-time information retrieval, RAG enables models to effectively extend their context to large knowledge bases by selectively retrieving only the most relevant information. As a result, RAG provides the effect of dynamic updates to the LLM’s knowledge without requiring expensive and time-consuming retraining. While some deployments keep the entire database in memory, RAG services are increasingly shifting toward persistent storage to accommodate ever-growing knowledge bases, enhance utility, and improve cost-efficiency. However, this transition fundamentally reshapes the system’s performance profile: empirical analysis reveals that the Search \&amp; Retrieval phase emerges as the dominant contributor to end-to-end latency. This phase typically involves (1) running a smaller language model to generate query embeddings, (2) executing similarity and relevance checks over varying data structures, and (3) performing frequent, long-latency accesses to persistent storage. To address this triad of challenges, we propose a metamorphic in-storage accelerator architecture that provides the necessary programmability to support diverse RAG algorithms, dynamic data structures, and varying computational patterns. The architecture also supports in-storage execution of smaller language models for query embedding generation while final LLM generation is executed on DGX A100 systems. Experimental results show up to 4.3 × and 1.5 × improvement in end-to-end throughput compared to conventional retrieval pipelines using Xeon CPUs with NVMe storage and A100 GPUs with DRAM, respectively.},
	booktitle = {Proceedings of the 52nd {Annual} {International} {Symposium} on {Computer} {Architecture}},
	publisher = {Association for Computing Machinery},
	author = {Mahapatra, Rohan and Santhanam, Harsha and Priebe, Christopher and Xu, Hanyang and Esmaeilzadeh, Hadi},
	year = {2025},
	keywords = {In-Storage Acceleration, Large Language Models, LLM, RAG, Retrieval-Augmented Generation, Specialized Accelerators},
	pages = {450--466},
}

@inproceedings{simoni_morse_2025,
	address = {New York, NY, USA},
	series = {{SAC} '25},
	title = {{MoRSE}: {Bridging} the {Gap} in {Cybersecurity} {Expertise} with {Retrieval} {Augmented} {Generation}},
	isbn = {979-8-4007-0629-5},
	url = {https://doi.org/10.1145/3672608.3707898},
	doi = {10.1145/3672608.3707898},
	abstract = {In this paper, we introduce MoRSE (Mixture of RAGs Security Experts), the first specialised AI chatbot for cybersecurity. MoRSE aims to provide comprehensive and complete knowledge about cybersecurity. MoRSE uses two RAG (Retrieval Augmented Generation) systems designed to retrieve and organize information from multidimensional cybersecurity contexts. MoRSE differs from traditional RAGs by using parallel retrievers that work together to retrieve semantically related information in different formats and structures. Unlike traditional Large Language Models (LLMs) that rely on Parametric Knowledge Bases, MoRSE retrieves relevant documents from Non-Parametric Knowledge Bases in response to user queries. Subsequently, MoRSE uses this information to generate accurate answers. In addition, MoRSE benefits from real-time updates to its knowledge bases, enabling continuous knowledge enrichment without retraining. We have evaluated the effectiveness of MoRSE against other state-of-the-art LLMs, evaluating the system on 600 cybersecurity specific questions. The experimental evaluation has shown that the improvement in terms of relevance and correctness of the answer is more than 10\% compared to known solutions such as GPT-4 and Mixtral 7x8.},
	booktitle = {Proceedings of the 40th {ACM}/{SIGAPP} {Symposium} on {Applied} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Simoni, Marco and Saracino, Andrea and P, Vinod and Conti, Mauro},
	year = {2025},
	note = {event-place: Catania International Airport, Catania, Italy},
	keywords = {cyber threat intelligence, cybersecurity, large language model, retrieval augmented generation},
	pages = {1213--1222},
}

@inproceedings{tu_robust_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Robust {Fine}-tuning for {Retrieval} {Augmented} {Generation} against {Retrieval} {Defects}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730078},
	doi = {10.1145/3726302.3730078},
	abstract = {Retrieval-augmented generation (RAG) enhances large language models (LLMs) by integrating external knowledge retrieved from a knowledge base. However, its effectiveness is fundamentally constrained by the reliability of both the retriever and the knowledge base (i.e., the retrieval system). In real-world scenarios, imperfections in these components often lead to the retrieval of noisy, irrelevant, or misleading counterfactual information, ultimately undermining the trustworthiness of RAG systems. To address this challenge, we propose Robust Fine-Tuning (RbFT), a method designed to enhance the resilience of LLMs against retrieval defects through two targeted fine-tuning tasks. Experimental results demonstrate that RbFT significantly improves the robustness of RAG systems across diverse retrieval conditions, surpassing existing methods while maintaining high inference efficiency and compatibility with other robustness techniques.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Tu, Yiteng and Su, Weihang and Zhou, Yujia and Liu, Yiqun and Ai, Qingyao},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {fine-tuning, retrieval augmented generation, robust},
	pages = {1272--1282},
}

@inproceedings{gokdemir_hiperrag_2025,
	address = {New York, NY, USA},
	series = {{PASC} '25},
	title = {{HiPerRAG}: {High}-{Performance} {Retrieval} {Augmented} {Generation} for {Scientific} {Insights}},
	isbn = {979-8-4007-1886-1},
	url = {https://doi.org/10.1145/3732775.3733586},
	doi = {10.1145/3732775.3733586},
	abstract = {The volume of scientific literature is growing exponentially, leading to underutilized discoveries, duplicated efforts, and limited cross-disciplinary collaboration. Retrieval-Augmented Generation (RAG) offers a way to assist scientists by improving the factuality of Large Language Models (LLMs) in processing this influx of information. However, scaling RAG to handle millions of articles introduces significant challenges, including the high computational costs associated with parsing documents and embedding scientific knowledge, as well as the algorithmic complexity of aligning these representations with the nuanced semantics of scientific content. To address these issues, we introduce HiPerRAG, a RAG workflow powered by high performance computing (HPC) to index and retrieve knowledge from more than 3.6 million scientific articles. At its core are Oreo, a high-throughput model for multimodal document parsing, and ColTrast, a query-aware encoder fine-tuning algorithm that enhances retrieval accuracy by using contrastive learning and late-interaction techniques. HiPerRAG delivers robust performance on existing scientific question answering (Q/A) benchmarks and two new benchmarks introduced in this work, achieving 90\% accuracy on SciQ and 76\% on PubMedQA—outperforming both domain-specific models like PubMedGPT and commercial LLMs such as GPT-4. Scaling to thousands of GPUs on the Polaris, Sunspot, and Frontier supercomputers, HiPerRAG delivers million document-scale RAG workflows for unifying scientific knowledge and fostering interdisciplinary innovation.},
	booktitle = {Proceedings of the {Platform} for {Advanced} {Scientific} {Computing} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Gokdemir, Ozan and Siebenschuh, Carlo and Brace, Alexander and Wells, Azton and Hsu, Brian and Hippe, Kyle and Setty, Priyanka and Ajith, Aswathy and Pauloski, J. Gregory and Sastry, Varuni and Foreman, Sam and Zheng, Huihuo and Ma, Heng and Kale, Bharat and Chia, Nicholas and Gibbs, Thomas and Papka, Michael and Brettin, Thomas and Alexander, Francis and Anandkumar, Anima and Foster, Ian and Stevens, Rick and Vishwanath, Venkatram and Ramanathan, Arvind},
	year = {2025},
	note = {event-place: FHNW University of Applied Sciences and Arts Northwestern Switzerland, Brugg-Windisch, Switzerland},
	keywords = {AI, HPC, large language models, metric learning, neural information retrieval, retrieval-augmented generation},
	pages = {1--13},
}

@inproceedings{liu_mask-based_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Mask-based {Membership} {Inference} {Attacks} for {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714771},
	doi = {10.1145/3696410.3714771},
	abstract = {Retrieval-Augmented Generation (RAG) has been an effective approach to mitigate hallucinations in large language models (LLMs) by incorporating up-to-date and domain-specific knowledge. Recently, there has been a trend of storing up-to-date or copyrighted data in RAG knowledge databases instead of using it for LLM training. This practice has raised concerns about Membership Inference Attacks (MIAs), which aim to detect if a specific target document is stored in the RAG system's knowledge database so as to protect the rights of data producers. While research has focused on enhancing the trustworthiness of RAG systems, existing MIAs for RAG systems remain largely insufficient. Previous work either relies solely on the RAG system's judgment or is easily influenced by other documents or the LLM's internal knowledge, which is unreliable and lacks explainability. To address these limitations, we propose a \&lt;u\&gt;M\&lt;/u\&gt;ask-\&lt;u\&gt;B\&lt;/u\&gt;ased Membership Inference \&lt;u\&gt;A\&lt;/u\&gt;ttacks (MBA) framework. Our framework first employs a masking algorithm that effectively masks a certain number of words in the target document. The masked text is then used to prompt the RAG system, and the RAG system is required to predict the mask values. If the target document appears in the knowledge database, the masked text will retrieve the complete target document as context, allowing for accurate mask prediction. Finally, we adopt a simple yet effective threshold-based method to infer the membership of target document by analyzing the accuracy of mask prediction. Our mask-based approach is more document-specific, making the RAG system's generation less susceptible to distractions from other documents or the LLM's internal knowledge. Extensive experiments demonstrate the effectiveness of our approach compared to existing baseline models.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Liu, Mingrui and Zhang, Sixiao and Long, Cheng},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {membership inference attacks, retrieval-augmented generation},
	pages = {2894--2907},
}

@inproceedings{xu_p-rag_2024,
	address = {New York, NY, USA},
	series = {{MM} '24},
	title = {P-{RAG}: {Progressive} {Retrieval} {Augmented} {Generation} {For} {Planning} on {Embodied} {Everyday} {Task}},
	isbn = {979-8-4007-0686-8},
	url = {https://doi.org/10.1145/3664647.3680661},
	doi = {10.1145/3664647.3680661},
	abstract = {Embodied Everyday Task is a popular task in the embodied AI community, requiring agents to make a sequence of actions based on natural language instructions and visual observations. Traditional learning-based approaches face two challenges. Firstly, natural language instructions often lack explicit task planning. Secondly, extensive training is required to equip models with knowledge of the task environment. Previous works based on Large Language Model (LLM) either suffer from poor performance due to the lack of task-specific knowledge or rely on ground truth as few-shot samples. To address the above limitations, we propose a novel approach called Progressive Retrieval Augmented Generation (P-RAG), which not only effectively leverages the powerful language processing capabilities of LLMs but also progressively accumulates task-specific knowledge without ground-truth. Compared to the conventional RAG methods, which retrieve relevant information from the database in a one-shot manner to assist generation, P-RAG introduces an iterative approach to progressively update the database. In each iteration, P-RAG retrieves the latest database and obtains historical information from the previous interaction as experiential references for the current interaction. Moreover, we also introduce a more granular retrieval scheme that not only retrieves similar tasks but also incorporates retrieval of similar situations to provide more valuable reference experiences. Extensive experiments reveal that P-RAG achieves competitive results without utilizing ground truth and can even further improve performance through self-iterations.},
	booktitle = {Proceedings of the 32nd {ACM} {International} {Conference} on {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Xu, Weiye and Wang, Min and Zhou, Wengang and Li, Houqiang},
	year = {2024},
	note = {event-place: Melbourne VIC, Australia},
	keywords = {embodied ai, large language model, progressive method, retrieval augmented generation},
	pages = {6969--6978},
}

@inproceedings{tang_boosting_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Boosting {Retrieval}-{Augmented} {Generation} with {Generation}-{Augmented} {Retrieval}: {A} {Co}-{Training} {Approach}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3729907},
	doi = {10.1145/3726302.3729907},
	abstract = {Large language models (LLMs) have shown success in knowledge-intensive tasks, including closed-book question answering and entity linking. However, their susceptibility to hallucination undermines their reliability. Retrieval-augmented generation (RAG) partially addresses this issue by combining a retriever to locate relevant documents and a generator to produce responses grounded in the retrieved evidence. Despite its advantages, RAG faces challenges: (i) the structural gap between traditional dense retrievers and autoregressive generators, and (ii) limited generation performance due to insufficient contextual guidance returned by the retriever. To tackle these limitations, we propose MINT, a novel framework that enhances RAG by co-training Retrieval-augMented generatIon and geNeration-augmented reTrieval (GAR). MINT (i) bridges the gap between the retriever and generator using a unified encoder-decoder structure (ii) incorporates an iterative co-training strategy between RAG and GAR, enabling mutual enhancement through pseudo-samples generation, and (iii) introduces three heuristic inference strategies to generate relevant document identifiers and answers. We conduct an empirical study on the KILT benchmark, and MINT is found to yield significant improvements in both retrieval and generation tasks compared with prevailing baselines.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Tang, Yubao and Zhang, Ruqing and Guo, Jiafeng and de Rijke, Maarten and Fan, Yixing and Cheng, Xueqi},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {generative retrieval, retrieval-augmented generation},
	pages = {2441--2451},
}

@inproceedings{li_oreo_2025,
	address = {New York, NY, USA},
	series = {{ICTIR} '25},
	title = {Oreo: {A} {Plug}-in {Context} {Reconstructor} to {Enhance} {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-1861-8},
	url = {https://doi.org/10.1145/3731120.3744590},
	doi = {10.1145/3731120.3744590},
	abstract = {Retrieval-Augmented Generation (RAG) aims to augment the capabilities of Large Language Models (LLMs) by retrieving and incorporating external documents or chunks prior to generation. However, even improved retriever relevance can bring erroneous or contextually distracting information, undermining the effectiveness of RAG in downstream tasks. We introduce a compact, efficient, and pluggable module designed to refine retrieved chunks before using them for generation. The module aims to extract and reorganize the most relevant and supportive information into a concise, query-specific, format. Through a three-stage training paradigm–comprising supervised fine-tuning, contrastive multi-task learning, and reinforcement learning-based alignment–it prioritizes critical knowledge and aligns it with the generator's preferences. This approach enables LLMs to produce outputs that are more accurate, reliable, and contextually appropriate.},
	booktitle = {Proceedings of the 2025 {International} {ACM} {SIGIR} {Conference} on {Innovative} {Concepts} and {Theories} in {Information} {Retrieval} ({ICTIR})},
	publisher = {Association for Computing Machinery},
	author = {Li, Sha and Ramakrishnan, Naren},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {contrastive learning, prompt optimization, retrieval augmented generation},
	pages = {238--253},
}

@inproceedings{pogrebinsky_enhancing_2025,
	address = {New York, NY, USA},
	series = {{ICTIR} '25},
	title = {Enhancing {Retrieval}-{Augmented} {Generation} for {Text} {Completion} {Through} {Query} {Selection}},
	isbn = {979-8-4007-1861-8},
	url = {https://doi.org/10.1145/3731120.3744610},
	doi = {10.1145/3731120.3744610},
	abstract = {In a Retrieval-Augmented Generation (RAG) system designed for the fundamental task of text completion, a query is derived from the prompt of a large language model (LLM) and is issued to an external resource. The retrieved content is then incorporated into the prompt to enhance text completion. Since prompts can be considerably long, it is common practice to use a short suffix of the prompt as the query. We empirically show, using a suite of oracle experiments, that this approach is often suboptimal with respect to other choices of a query from the prompt. This finding gives rise to a novel research challenge: identifying the optimal query for RAG in this setting. As an initial study, we propose a few query selection methods, some of which yield statistically significant improvements over using the prompt's suffix as a query.},
	booktitle = {Proceedings of the 2025 {International} {ACM} {SIGIR} {Conference} on {Innovative} {Concepts} and {Theories} in {Information} {Retrieval} ({ICTIR})},
	publisher = {Association for Computing Machinery},
	author = {Pogrebinsky, Idan and Carmel, David and Kurland, Oren},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {llm, query selection, rag, text completion},
	pages = {410--415},
}

@inproceedings{rau_context_2025,
	address = {New York, NY, USA},
	series = {{WSDM} '25},
	title = {Context {Embeddings} for {Efficient} {Answer} {Generation} in {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-1329-3},
	url = {https://doi.org/10.1145/3701551.3703527},
	doi = {10.1145/3701551.3703527},
	abstract = {Retrieval-Augmented Generation (RAG) allows overcoming the limited knowledge of LLMs by extending the input with external information. As a consequence, the contextual inputs to the model become much longer slowing down decoding time affecting the time a user has to wait for an answer. We address this challenge by presenting COCOM, an effective context compression method, reducing long contexts to only a handful of Context Embeddings, speeding up the generation time by a large margin. Our method allows for different compression rates, trading off decoding time for answer quality. Compared to earlier methods, COCOM allows for handling multiple contexts more effectively, significantly reducing decoding time for long inputs. Our method demonstrates an inference speed-up of up to 5.69 times while achieving higher performance compared to existing efficient context compression methods},
	booktitle = {Proceedings of the {Eighteenth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Rau, David and Wang, Shuai and Déjean, Hervé and Clinchant, Stéphane and Kamps, Jaap},
	year = {2025},
	note = {event-place: Hannover, Germany},
	keywords = {context compression, llm, question-answering, retrieval-augmented generation},
	pages = {493--502},
}

@inproceedings{li_lexrag_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{LexRAG}: {Benchmarking} {Retrieval}-{Augmented} {Generation} in {Multi}-{Turn} {Legal} {Consultation} {Conversation}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730340},
	doi = {10.1145/3726302.3730340},
	abstract = {Retrieval-augmented generation (RAG) has proven highly effective in improving large language models (LLMs) across various domains. However, there is no benchmark specifically designed to assess the effectiveness of RAG in the legal domain, which restricts progress in this area. To fill this gap, we propose LexRAG, the first benchmark to evaluate RAG systems for multi-turn legal consultations. LexRAG consists of 1,013 multi-turn dialogue samples and 17,228 candidate legal articles. Each sample is annotated by legal experts and consists of five rounds of progressive questioning. LexRAG includes two key tasks: (1) Conversational knowledge retrieval, requiring accurate retrieval of relevant legal articles based on multi-turn context. (2) Response generation, focusing on producing legally sound answers. To ensure reliable reproducibility, we develop LexiT, a legal RAG toolkit that provides a comprehensive implementation of RAG system components tailored for the legal domain. Additionally, we introduce an LLM-as-a-judge evaluation pipeline to enable detailed and effective assessment. Through experimental analysis of various LLMs and retrieval methods, we reveal the key limitations of existing RAG systems in handling legal consultation conversations. LexRAG establishes a new benchmark for the practical application of RAG systems in the legal domain, with its code and data available at https://github.com/CSHaitao/LexRAG.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Li, Haitao and Chen, Yifan and YiRan, Hu and Ai, Qingyao and Chen, Junjie and Yang, Xiaoyu and Yang, Jianhui and Wu, Yueyue and Liu, Zeyang and Liu, Yiqun},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {legal consultation conversation, multi-turn, retrieval-augmented generation},
	pages = {3606--3615},
}

@inproceedings{fuchs_lissa_2025,
	address = {Ottawa, Ontario, Canada},
	series = {{ICSE} '25},
	title = {{LiSSA}: {Toward} {Generic} {Traceability} {Link} {Recovery} through {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-3315-0569-1},
	url = {https://doi.org/10.1109/ICSE55347.2025.00186},
	doi = {10.1109/ICSE55347.2025.00186},
	abstract = {There are a multitude of software artifacts which need to be handled during the development and maintenance of a software system. These artifacts interrelate in multiple, complex ways. Therefore, many software engineering tasks are enabled — and even empowered — by a clear understanding of artifact interrelationships and also by the continued advancement of techniques for automated artifact linking.However, current approaches in automatic Traceability Link Recovery (TLR) target mostly the links between specific sets of artifacts, such as those between requirements and code. Fortunately, recent advancements in Large Language Models (LLMs) can enable TLR approaches to achieve broad applicability. Still, it is a nontrivial problem how to provide the LLMs with the specific information needed to perform TLR.In this paper, we present LiSSA, a framework that harnesses LLM performance and enhances them through Retrieval-Augmented Generation (RAG). We empirically evaluate LiSSA on three different TLR tasks, requirements to code, documentation to code, and architecture documentation to architecture models, and we compare our approach to state-of-the-art approaches.Our results show that the RAG-based approach can significantly outperform the state-of-the-art on the code-related tasks. However, further research is required to improve the performance of RAG-based approaches to be applicable in practice.},
	booktitle = {Proceedings of the {IEEE}/{ACM} 47th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Fuchß, Dominik and Hey, Tobias and Keim, Jan and Liu, Haoyu and Ewald, Niklas and Thirolf, Tobias and Koziolek, Anne},
	year = {2025},
	keywords = {large language models, retrieval-augmented generation, traceability link recovery},
	pages = {1396--1408},
}

@inproceedings{agrawal_scmrag_2025,
	address = {Richland, SC},
	series = {{AAMAS} '25},
	title = {{SCMRAG}: {Self}-{Corrective} {Multihop} {Retrieval} {Augmented} {Generation} {System} for {LLM} {Agents}},
	isbn = {979-8-4007-1426-9},
	abstract = {Existing Retrieval-Augmented Generation (RAG) systems primarily depend on static knowledge vectorstores which combine semantic similarity algorithms with reranking. This often leads to outdated information and retrieval errors. In this paper, we propose SCMRAG, a Self-Corrective Multihop Retrieval Augmented Generation system for LLM agents. We introduce an LLM-assisted dynamic knowledge graph creation step to enhance information retrieval and mitigate hallucinations. Unlike traditional RAG systems, SCMRAG includes a self-corrective agent driven mechanism that autonomously identifies and retrieves missing information from external web sources. Furthermore, SCMRAG's internal reasoning agent determines whether the knowledge graph provides sufficient information or if a corrective step is needed. It further improves retrieval accuracy and efficiency. We benchmark the effectiveness of SCMRAG on five datasets - MultiHop-RAG, ARC AI2, PopQA, PubHealth, and WikiBio; showing significant improvements in retrieval precision and hallucination reduction across diverse tasks. Our results highlight SCMRAG's potential to redefine how LLM agents interact with knowledge bases, offering a more adaptable and reliable solution for a wide range of applications.},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Autonomous} {Agents} and {Multiagent} {Systems}},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Agrawal, Rishabh and Asrani, Murtaza and Youssef, Hadi and Narayan, Apurva},
	year = {2025},
	note = {event-place: Detroit, MI, USA},
	keywords = {agents, knowledge graph, LLM, RAG, vectorstore},
	pages = {50--58},
}

@inproceedings{liu_heterrag_2025,
	address = {New York, NY, USA},
	series = {{ISCA} '25},
	title = {{HeterRAG}: {Heterogeneous} {Processing}-in-{Memory} {Acceleration} for {Retrieval}-augmented {Generation}},
	isbn = {979-8-4007-1261-6},
	url = {https://doi.org/10.1145/3695053.3731089},
	doi = {10.1145/3695053.3731089},
	abstract = {By integrating external knowledge bases, Retrieval-augmented Generation (RAG) enhances natural language generation for knowledge-intensive scenarios and specialized domains, producing content that is both more informative and personalized. RAG systems typically consist of two fundamental stages: retrieval and generation. The retrieval stage experiences low bandwidth utilization due to its random and irregular memory access patterns. Meanwhile, the generation stage is also constrained by memory bandwidth limitations, which arise from involving a significant number of General Matrix-Vector Multiplications (GEMV) operations. These two stages collectively lead to memory bottlenecks within RAG systems. Recent efforts leverage HBM-based Processing-in-Memory (PIM) to accelerate conventional Large Language Models (LLMs). However, the retrieval stage incurs substantial storage overhead due to the need to maintain large-scale knowledge bases, resulting in a capacity bottleneck. Solely relying on HBM-based PIM in RAG is both costly and insufficient to meet the capacity demands. Fortunately, DIMM-based PIM provides a low-cost, high-capacity alternative that complements HBM. In this work, we propose HeterRAG, a novel heterogeneous PIM acceleration system for RAG. It combines HBM-based PIM and DIMM-based PIM to achieve high performance, energy efficiency, and low hardware cost. HeterRAG uses HBM-based PIM for the generation stage to meet bandwidth needs and DIMM-based PIM for the retrieval stage to satisfy memory capacity requirements. To further improve performance, HeterRAG incorporates three software–hardware co-optimization techniques: locality-aware retrieval, locality-aware generation, and fine-grained parallel pipelining. Experimental results demonstrate that, compared to RAG systems deployed on Intel Xeon CPUs and NVIDIA GPUs, HeterRAG achieves up to 26.5 × higher throughput, up to 27.6 × lower latency, and up to 2.8 × greater energy efficiency.},
	booktitle = {Proceedings of the 52nd {Annual} {International} {Symposium} on {Computer} {Architecture}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Chaoqiang and Liu, Haifeng and Chen, Dan and Huang, Yu and Zhang, Yi and Xiao, Wenjing and Liao, Xiaofei and Jin, Hai},
	year = {2025},
	keywords = {Approximate nearest neighbor search, DIMM, HBM, Large language models, Processing-in-memory, Retrieval-augmented generation},
	pages = {884--898},
}

@inproceedings{ruamsuk_enhancing_2025,
	address = {New York, NY, USA},
	series = {{NLPIR} '24},
	title = {Enhancing {Retrieval}-{Augmented} {Generation} {Systems} by {Text}-{Representing} {Centroid}},
	isbn = {979-8-4007-1738-3},
	url = {https://doi.org/10.1145/3711542.3711558},
	doi = {10.1145/3711542.3711558},
	abstract = {This paper introduces a novel approach to enhance Retrieval-Augmented Generation (RAG) systems by integrating Text-Representing Centroid (TRC) methodology. Addressing the limitations of traditional vector databases, this method preserves structural relationships and adapts to content complexity, improving information retrieval efficiency and accuracy. Key contributions include advanced graph construction, relevance scoring algorithms, and extensive validation, with discussions on potential applications and future research. Empirical evidence demonstrates that TRC methods achieve a 75 percent success rate on 100 questions, outperforming traditional vector methods.},
	booktitle = {Proceedings of the 2024 8th {International} {Conference} on {Natural} {Language} {Processing} and {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Ruamsuk, Yanakorn and Mingkhwan, Anirach and Unger, Herwig},
	year = {2025},
	keywords = {Co-Occurrence Graph, Information Retrieval, Retrieval-Augmented Generation, Text-Representing Centroid, Vector Database},
	pages = {265--271},
}

@inproceedings{zhang_exploring_2025,
	address = {New York, NY, USA},
	series = {{JCDL} '24},
	title = {Exploring {Efficient} {Optimization} {Techniques} in {Online} {Retrieval}-{Augmented} {Generation} {Application}},
	isbn = {979-8-4007-1093-3},
	url = {https://doi.org/10.1145/3677389.3702522},
	doi = {10.1145/3677389.3702522},
	abstract = {Recent advances in large language models (LLM) have brought an explosive growth to chat-bot applications. Among them, retrieval-augmented generation, which provides extra context to make LLM capable of answering out-of-domain questions is becoming a popular method. However, naive implementation of RAG usually cannot reach ideal answer quality in complicated real-world scenarios. Researchers have proposed a number of methods to improve RAG, but many of them involves extra LLM calls which is too time-consuming for online application. In this paper, we explored practical techniques and designs in RAG that improve answers to user-satisfying quality while keeping the response latency at a moderate level in the scenario of a research data QA application in university. Our main findings include introducing a relevance judge with small-scale LLM for retrieved documents can effectively filter out less relevant ones, which can otherwise disrupt the generated answer greatly, and decomposing the generation task into multiple independent sub-tasks can reduce the chance of hallucination and also accelerates the generation. As for model performance, prompt engineering and fine-tuning (through learning from strong LLM) are effective yet simple ways to enhance answer quality. Our results and experience provide insights for building future real-world LLM applications.},
	booktitle = {Proceedings of the 24th {ACM}/{IEEE} {Joint} {Conference} on {Digital} {Libraries}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Yining and Peng, Yinan and Tu, Chengying and Zhang, Zherui and Yan, Hongfei and Chen, Chong and Ma, Hao and Yang, Jia and Zhang, Yan and Liao, Rikun},
	year = {2025},
	note = {event-place: Hong Kong, China},
	keywords = {document relevance, fine-tuning, research data, retrieval-augmented generation},
}

@inproceedings{hu_prompt_2024,
	address = {New York, NY, USA},
	series = {{KDD} '24},
	title = {Prompt {Perturbation} in {Retrieval}-{Augmented} {Generation} based {Large} {Language} {Models}},
	isbn = {979-8-4007-0490-1},
	url = {https://doi.org/10.1145/3637528.3671932},
	doi = {10.1145/3637528.3671932},
	abstract = {The robustness of large language models (LLMs) becomes increasingly important as their use rapidly grows in a wide range of domains. Retrieval-Augmented Generation (RAG) is considered as a means to improve the trustworthiness of text generation from LLMs. However, how the outputs from RAG-based LLMs are affected by slightly different inputs is not well studied. In this work, we find that the insertion of even a short prefix to the prompt leads to the generation of outputs far away from factually correct answers. We systematically evaluate the effect of such prefixes on RAG by introducing a novel optimization technique called Gradient Guided Prompt Perturbation (GGPP). GGPP achieves a high success rate in steering outputs of RAG-based LLMs to targeted wrong answers. It can also cope with instructions in the prompts requesting to ignore irrelevant context. We also exploit LLMs' neuron activation difference between prompts with and without GGPP perturbations to give a method that improves the robustness of RAG-based LLMs through a highly effective detector trained on neuron activation triggered by GGPP generated prompts. Our evaluation on open-sourced LLMs demonstrates the effectiveness of our methods.},
	booktitle = {Proceedings of the 30th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Hu, Zhibo and Wang, Chen and Shu, Yanfeng and Paik, Hye-Young and Zhu, Liming},
	year = {2024},
	note = {event-place: Barcelona, Spain},
	keywords = {LLM, prompt attack, retrieval-augmented generation, robustness},
	pages = {1119--1130},
}

@inproceedings{packowski_optimizing_2025,
	address = {New York, NY, USA},
	series = {{ICAAI} '24},
	title = {Optimizing and {Evaluating} {Enterprise} {Retrieval}-{Augmented} {Generation} ({RAG}): {A} {Content} {Design} {Perspective}},
	isbn = {979-8-4007-1801-4},
	url = {https://doi.org/10.1145/3704137.3704181},
	doi = {10.1145/3704137.3704181},
	abstract = {Retrieval-augmented generation (RAG) is a popular technique for using large language models (LLMs) to build customer-support, question-answering solutions. In this paper, we share our team’s practical experience building and maintaining enterprise-scale RAG solutions that answer users’ questions about our software based on product documentation. Our experience has not always matched the most common patterns in the RAG literature. This paper focuses on solution strategies that are modular and model-agnostic. For example, our experience over the past few years - using different search methods and LLMs, and many knowledge base collections - has been that simple changes to the way we create knowledge base content can have a huge impact on our RAG solutions’ success. In this paper, we also discuss how we monitor and evaluate results. Common RAG benchmark evaluation techniques have not been useful for evaluating responses to novel user questions, so we have found a flexible, "human in the lead" approach is required.},
	booktitle = {Proceedings of the 2024 8th {International} {Conference} on {Advances} in {Artificial} {Intelligence}},
	publisher = {Association for Computing Machinery},
	author = {Packowski, Sarah and Halilovic, Inge and Schlotfeldt, Jenifer and Smith, Trish},
	year = {2025},
	keywords = {Large language models, RAG, Retrieval-augmented generation},
	pages = {162--167},
}

@inproceedings{tan_pear_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{PEAR}: {Position}-{Embedding}-{Agnostic} {Attention} {Re}-weighting {Enhances} {Retrieval}-{Augmented} {Generation} with {Zero} {Inference} {Overhead}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714795},
	doi = {10.1145/3696410.3714795},
	abstract = {Large language models (LLMs) enhanced with retrieval-augmented generation (RAG) have introduced a new paradigm for web search. However, the limited context awareness of LLMs degrades their performance on RAG tasks. Existing methods to enhance context awareness are often inefficient, incurring time or memory overhead during inference, and many are tailored to specific position embeddings. In this paper, we propose Position-Embedding-Agnostic attention Re-weighting (PEAR), which enhances the context awareness of LLMs with zero inference overhead. Specifically, on a proxy task focused on context copying, we first detect heads which suppress the models' context awareness, thereby diminishing RAG performance. To weaken the impact of these heads, we re-weight their outputs with learnable coefficients. The LLM (with frozen parameters) is optimized by adjusting these coefficients to minimize loss on the proxy task. During inference, the optimized coefficients are fixed to re-weight these heads, regardless of the specific task at hand. Our proposed PEAR offers two major advantages over previous approaches: (1) It introduces zero additional inference overhead in terms of memory usage or inference time, while outperforming competitive baselines in accuracy and efficiency across various RAG tasks. (2) It is independent of position embedding algorithms, ensuring broader applicability. Our code is available at https://github.com/TTArch/PEAR-RAG.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Tan, Tao and Qian, Yining and Lv, Ang and Lin, Hongzhan and Wu, Songhao and Wang, Yongbo and Wang, Feng and Wu, Jingtong and Lu, Xin and Yan, Rui},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {context awareness, large language model, re-weighting attention heads, retrieval-augmented generation},
	pages = {1693--1702},
}

@inproceedings{wu_lighter_2025,
	address = {New York, NY, USA},
	series = {{WSDM} '25},
	title = {Lighter {And} {Better}: {Towards} {Flexible} {Context} {Adaptation} {For} {Retrieval} {Augmented} {Generation}},
	isbn = {979-8-4007-1329-3},
	url = {https://doi.org/10.1145/3701551.3703580},
	doi = {10.1145/3701551.3703580},
	abstract = {The existing Retrieval-Augmented Generation (RAG) systems face significant challenges in terms of cost and effectiveness. On one hand, they need to encode the lengthy retrieved contexts before responding to the input tasks, which imposes substantial computational overhead. On the other hand, directly using generic Large Language Models (LLMs) often leads to sub-optimal answers, while task-specific fine-tuning may compromise the LLMs' general capabilities. To address these challenges, we introduce a novel approach called FlexRAG (\&lt;u\&gt;Flex\&lt;/u\&gt;ible Context Adaptation for \&lt;u\&gt;RAG\&lt;/u\&gt;). In this approach, the retrieved contexts are compressed into compact embeddings before being encoded by the LLMs. Simultaneously, these compressed embeddings are optimized to enhance downstream RAG performance. A key feature of FlexRAG is its flexibility, which enables effective support for diverse compression ratios and selective preservation of important contexts. With these designs, FlexRAG achieves superior generation quality while significantly reducing running costs. The experiments across multiple QA datasets validate our approach as a cost-effective and flexible solution for RAG systems (codebase: https://github.com/wcyno23/FlexRAG).},
	booktitle = {Proceedings of the {Eighteenth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Wu, Chenyuan and Shao, Ninglu and Liu, Zheng and Xiao, Shitao and Li, Chaozhuo and Zhang, Chen and Wang, Senzhang and Lian, Defu},
	year = {2025},
	note = {event-place: Hannover, Germany},
	keywords = {large language models, retrieval augmented generation},
	pages = {271--280},
}

@inproceedings{zhu_emerge_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {{EMERGE}: {Enhancing} {Multimodal} {Electronic} {Health} {Records} {Predictive} {Modeling} with {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3679582},
	doi = {10.1145/3627673.3679582},
	abstract = {The integration of multimodal Electronic Health Records (EHR) data has significantly advanced clinical predictive capabilities. Existing models, which utilize clinical notes and multivariate time-series EHR data, often fall short of incorporating the necessary medical context for accurate clinical tasks, while previous approaches with knowledge graphs (KGs) primarily focus on structured knowledge extraction. In response, we propose EMERGE, a Retrieval-Augmented Generation (RAG) driven framework to enhance multimodal EHR predictive modeling. We extract entities from both time-series data and clinical notes by prompting Large Language Models (LLMs) and align them with professional PrimeKG, ensuring consistency. In addition to triplet relationships, we incorporate entities' definitions and descriptions for richer semantics. The extracted knowledge is then used to generate task-relevant summaries of patients' health statuses. Finally, we fuse the summary with other modalities using an adaptive multimodal fusion network with cross-attention. Extensive experiments on the MIMIC-III and MIMIC-IV datasets' in-hospital mortality and 30-day readmission tasks demonstrate the superior performance of the EMERGE framework over baseline models. Comprehensive ablation studies and analysis highlight the efficacy of each designed module and robustness to data sparsity. EMERGE contributes to refining the utilization of multimodal EHR data in healthcare, bridging the gap with nuanced medical contexts essential for informed clinical predictions. We have publicly released the code at https://github.com/yhzhu99/EMERGE.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Zhu, Yinghao and Ren, Changyu and Wang, Zixiang and Zheng, Xiaochen and Xie, Shiyun and Feng, Junlan and Zhu, Xi and Li, Zhoujun and Ma, Liantao and Pan, Chengwei},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {electronic health record, large language model, multimodal learning, retrieval-augmented generation},
	pages = {3549--3559},
}

@inproceedings{liang_efficient_2025,
	address = {New York, NY, USA},
	series = {{AIMLSystems} '24},
	title = {Efficient and verifiable responses using {Retrieval} {Augmented} {Generation} ({RAG})},
	isbn = {979-8-4007-1161-9},
	url = {https://doi.org/10.1145/3703412.3703431},
	doi = {10.1145/3703412.3703431},
	abstract = {The rise of large language models (LLMs) like ChatGPT has greatly enhanced the efficiency of everyday tasks through automation. However, the deployment of LLMs for tasks such as responding to Request-for-Proposals (RFPs) is hindered by deficiencies like hallucinations and lack of response provenance. For such tasks, the aim of an automated response is to generate precise answers that can still be quickly reviewed and corrected by a human; therefore it is critical to optimize the system such that relevant source document sections are identified for as many questions as possible, and all relevant contexts are attributed correctly; this makes LLMs alone insufficient for this task. We present an improved Retrieval Augmented Generation (RAG) architecture for automated RFP completion that enhances relevant content generation and significantly reduces manual effort in drafting responses. The proposed improvements are two-fold: we present a novel text embedding scheme that combines a dense contextual embedding with a sparse statistical embedding for document retrieval, and we improve on the provenance of the generated response by presenting an algorithm that accurately provides the document page numbers as references when generating the answers. The practical deployment of this solution highlights its potential for automatic RFP completion, as well as its ability to act as an architecture for applications in various domains with differing complexity levels, especially when efficiency, accuracy, and verifiable responses are paramount.},
	booktitle = {Proceedings of the 4th {International} {Conference} on {AI}-{ML} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Liang, Henry and Zhou, Yu and Gurbani, Vijay K},
	year = {2025},
	keywords = {hybrid embedding, hybrid retrieval, LLM, RAG, RFP},
}

@inproceedings{barnett_seven_2024,
	address = {New York, NY, USA},
	series = {{CAIN} '24},
	title = {Seven {Failure} {Points} {When} {Engineering} a {Retrieval} {Augmented} {Generation} {System}},
	isbn = {979-8-4007-0591-5},
	url = {https://doi.org/10.1145/3644815.3644945},
	doi = {10.1145/3644815.3644945},
	abstract = {Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.},
	booktitle = {Proceedings of the {IEEE}/{ACM} 3rd {International} {Conference} on {AI} {Engineering} - {Software} {Engineering} for {AI}},
	publisher = {Association for Computing Machinery},
	author = {Barnett, Scott and Kurniawan, Stefanus and Thudumu, Srikanth and Brannelly, Zach and Abdelrazek, Mohamed},
	year = {2024},
	note = {event-place: Lisbon, Portugal},
	keywords = {case study, RAG, retrieval augmented generation, SE4AI},
	pages = {194--199},
}

@inproceedings{difallah_wikirag_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{WikiRAG}: {Revisiting} {Wikidata} {KGC} {Datasets} with {Community} {Updates} and {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737444},
	doi = {10.1145/3711896.3737444},
	abstract = {Link prediction is an important task for knowledge graph completion and curation, and it has received significant attention from the research community. However, researchers often train and evaluate new models on small or outdated datasets that do not reflect the current state of knowledge, thereby disregarding new information and the rich textual content often linked to knowledge graphs. As a result, many opportunities to leverage these dimensions are missed. We introduce WikiRAG, a framework for knowledge completion and evaluation derived from Wikidata and Wikipedia, which enables research integrating retrieval techniques and large language models. Our framework combines the following contributions: (i) We revisit the Wikidata5M dataset by updating it to reflect the current state of Wikidata and providing automated tools for its periodic maintenance. (ii) We enrich the dataset with long-form textual content sourced from Wikipedia, enabling research that goes beyond traditional graph structures and shallow text methods toward dense retrieval techniques. (iii) We propose a simple yet effective baseline that leverages retrieval-augmented generation, demonstrating the utility of the dataset and integrating language model capabilities for link prediction. The revised dataset, coined Wikidata5M-RE, shows that the original graph grew by roughly 50\% in the number of edges, while 10\% of the edges have been removed. A comparative analysis of classic methods demonstrates that these changes can impact downstream task evaluation. Finally, our evaluation of WikiRAG's KGC method shows an improvement of up to 9\% in link prediction accuracy over state-of-the-art baselines, setting the stage for a new avenue in knowledge completion that uses deep information extraction. The source code, data, and other artifacts have been made available on the project website: https://github.com/colab-nyuad/WikiRAG},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Difallah, Djellel},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {benchmarking, knowledge graph completion, large language models, retrieval augmented generation, wikidata},
	pages = {5391--5401},
}

@inproceedings{zhao_medrag_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{MedRAG}: {Enhancing} {Retrieval}-augmented {Generation} with {Knowledge} {Graph}-{Elicited} {Reasoning} for {Healthcare} {Copilot}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714782},
	doi = {10.1145/3696410.3714782},
	abstract = {Retrieval-augmented generation (RAG) is a well-suited technique for retrieving privacy-sensitive Electronic Health Records (EHR). It can serve as a key module of the healthcare copilot, helping reduce misdiagnosis for healthcare practitioners and patients. However, the diagnostic accuracy and specificity of existing heuristic-based RAG models used in the medical domain are inadequate, particularly for diseases with similar manifestations. This paper proposes MedRAG, a RAG model enhanced by knowledge graph (KG)-elicited reasoning for the medical domain that retrieves diagnosis and treatment recommendations based on manifestations. MedRAG systematically constructs a comprehensive four-tier hierarchical diagnostic KG encompassing critical diagnostic differences of various diseases. These differences are dynamically integrated with similar EHRs retrieved from an EHR database, and reasoned within a large language model. This process enables more accurate and specific decision support, while also proactively providing follow-up questions to enhance personalized medical decision-making. MedRAG is evaluated on both a public dataset DDXPlus and a private chronic pain diagnostic dataset (CPDD) collected from Tan Tock Seng Hospital, and its performance is compared against various existing RAG methods. Experimental results show that, leveraging the information integration and relational abilities of the KG, our MedRAG provides more specific diagnostic insights and outperforms state-of-the-art models in reducing misdiagnosis rates. Our code will be available at https://github.com/SNOWTEAM2023/MedRAG},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Zhao, Xuejiao and Liu, Siyan and Yang, Su-Yin and Miao, Chunyan},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {decision support, healthcare copilot, knowledge graph, large language models, retrieval-augmented generation},
	pages = {4442--4457},
}

@inproceedings{soudani_fine_2024,
	address = {New York, NY, USA},
	series = {{SIGIR}-{AP} 2024},
	title = {Fine {Tuning} vs. {Retrieval} {Augmented} {Generation} for {Less} {Popular} {Knowledge}},
	isbn = {979-8-4007-0724-7},
	url = {https://doi.org/10.1145/3673791.3698415},
	doi = {10.1145/3673791.3698415},
	abstract = {Language Models (LMs) memorize a vast amount of factual knowledge, exhibiting strong performance across diverse tasks and domains. However, it has been observed that the performance diminishes when dealing with less-popular or low-frequency concepts and entities, for example in domain specific applications. The two prominent approaches to enhance the performance of LMs on low-frequent topics are: Retrieval Augmented Generation (RAG) and fine-tuning (FT) over synthetic data. This paper explores and evaluates the impact of RAG and FT on customizing LMs in handling low-frequency entities on question answering tasks. We conduct extensive experiments on twelve LMs of varying size and type and different FT methods, data augmentation, and retrieval models. Our findings indicate that while FT boosts the performance across entities of varying popularity, RAG surpasses FT by a large margin particularly for least popular factual knowledge. Additionally, the success of both RAG and FT approaches is amplified by improving retrieval and data augmentation techniques. Fine tuning, while beneficial for small LMs, requires extensive resources. To address this issue, we propose the new Stimulus RAG approach that surpasses the effectiveness of fine tuning based approaches, thereby eliminating the need for the costly data augmentation and fine tuning step for enriching LMs with less popular factual knowledge.},
	booktitle = {Proceedings of the 2024 {Annual} {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval} in the {Asia} {Pacific} {Region}},
	publisher = {Association for Computing Machinery},
	author = {Soudani, Heydar and Kanoulas, Evangelos and Hasibi, Faegheh},
	year = {2024},
	note = {event-place: Tokyo, Japan},
	keywords = {data augmentation, fine tuning, retrieval augmented generation},
	pages = {12--22},
}

@inproceedings{wang_quantitative_2025,
	address = {New York, NY, USA},
	series = {{SIGCSETS} 2025},
	title = {Quantitative {Evaluation} of {Using} {Large} {Language} {Models} and {Retrieval}-{Augmented} {Generation} in {Computer} {Science} {Education}},
	isbn = {979-8-4007-0531-1},
	url = {https://doi.org/10.1145/3641554.3701917},
	doi = {10.1145/3641554.3701917},
	abstract = {Generative artificial intelligence (GenAI) is transforming Computer Science education, and every instructor is reflecting on how AI will impact their courses. Instructors must determine how students may use AI for course activities and what AI systems they will support and encourage students to use. This task is challenging with the proliferation of large language models (LLMs) and related AI systems. The contribution of this work is an experimental evaluation of the performance of multiple open-source and commercial LLMs utilizing retrieval-augmented generation in answering questions for computer science courses and a cost-benefit analysis for instructors when determining what systems to use. A key factor is the time an instructor has to maintain their supported AI systems and the most effective activities for improving their performance. The paper offers recommendations for deploying, using, and enhancing AI in educational settings.},
	booktitle = {Proceedings of the 56th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education} {V}. 1},
	publisher = {Association for Computing Machinery},
	author = {Wang, Kevin Shukang and Lawrence, Ramon},
	year = {2025},
	note = {event-place: Pittsburgh, PA, USA},
	keywords = {artificial intelligence, human-in-the-loop, large language model, question answering, retrieval-augmented generation},
	pages = {1183--1189},
}

@inproceedings{dai_next-search_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{NExT}-{Search}: {Rebuilding} {User} {Feedback} {Ecosystem} for {Generative} {AI} {Search}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730353},
	doi = {10.1145/3726302.3730353},
	abstract = {Generative AI search driven by large language models (LLMs) is reshaping information retrieval by offering end-to-end answers to complex queries, reducing users' reliance on manually browsing and summarizing multiple web pages. However, while this paradigm enhances convenience, it disrupts the feedback-driven improvement loop that has historically powered the evolution of traditional Web search. Web search can continuously improve their ranking models by collecting large-scale, fine-grained user feedback (e.g., clicks, dwell time) at the document level. In contrast, generative AI search operates through a much longer search pipeline-spanning query decomposition, document retrieval, and answer generation-yet typically receives only coarse-grained feedback on the final answer. This introduces a feedback loop disconnect, where user feedback for the final output cannot be effectively mapped back to specific system components, making it difficult to improve each intermediate stage and sustain the feedback loop.To address this limitation, we envision NExT-Search, a next-generation paradigm designed to reintroduce fine-grained, process-level feedback into generative AI search. NExT-Search integrates two complementary modes: User Debug Mode, which allows engaged users to intervene at key stages-such as refining query decomposition, rating retrieved documents, and editing initial generated responses-and Shadow User Mode, where a personalized user agent simulates user preferences and provides AI-assisted feedback for less interactive users. As these feedback signals serve as valuable resources for refining the whole search pipeline, we also introduce a feedback store mechanism that encourages users to share and monetize their debugging efforts, further incentivizing participation. Furthermore, we envision how these feedback signals can be leveraged through online adaptation, which refines current search outputs in real-time, and offline update, which aggregates interaction logs to periodically fine-tune query decomposition, retrieval, and generation models. By restoring human control over key stages of the generative AI search pipeline, we believe NExT-Search offers a promising direction for building feedback-rich AI search systems that can evolve continuously alongside human feedback.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Dai, Sunhao and Wang, Wenjie and Pang, Liang and Xu, Jun and Ng, See-Kiong and Wen, Ji-Rong and Chua, Tat-Seng},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {generative ai search, large language model, user feedback},
	pages = {3922--3931},
}

@inproceedings{nandy_balancing_2025,
	address = {New York, NY, USA},
	series = {{UMAP} {Adjunct} '25},
	title = {Balancing {Health} {Information}-{Seeking} through {Retrieval}-{Augmented} {Generation}-{Based} {LLM} {Chatbot}},
	isbn = {979-8-4007-1399-6},
	url = {https://doi.org/10.1145/3708319.3733709},
	doi = {10.1145/3708319.3733709},
	abstract = {Family caregivers play a vital role in supporting children with chronic health conditions, such as neonates diagnosed with hypoxic-ischemic encephalopathy (HIE). However, navigating complex medical information can be overwhelming due to the quantity and quality of available literature. This study leverages Retrieval-Augmented Generation (RAG)-based Large Language Models (LLMs) to develop a chatbot that integrates peer-reviewed scientific literature and provides personalized, simplified summaries for caregivers. A user study involving six caregivers and five healthcare providers demonstrated the chatbot’s ability to enhance clarity, improve comprehension, and deliver essential medical information concisely. Our findings highlight the potential of RAG-based LLMs to enhance caregivers’ health literacy and support their information-seeking behavior, while also underscoring the importance of thoughtfully navigating the differing expectations of caregivers and healthcare providers regarding the type, depth, and presentation of medical information.},
	booktitle = {Adjunct {Proceedings} of the 33rd {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {Association for Computing Machinery},
	author = {Nandy, Gargi and Gupta, Srishti and Mohammad Afzali, Farhad and Peeples, Eric and Pilon, Betsy and Tsai, Chun-Hua},
	year = {2025},
	keywords = {chatbot, healthcare, HIE, large language models},
	pages = {249--254},
}

@inproceedings{dela_rosa_video-enriched_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Video-{Enriched} {Retrieval} {Augmented} {Generation} {Using} {Aligned} {Video} {Captions}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3716890},
	doi = {10.1145/3701716.3716890},
	abstract = {In this work, we propose the use of ”aligned video captions” as an intelligent mechanism for integrating video content into retrieval augmented generation (RAG) based AI assistant systems. These captions serve as an efficient representation layer between videos and large language models (LLMs), describing both visual and audio content while requiring significantly less context window space compared to traditional frame sampling approaches. We demonstrate how this representation enables more effective agent-based retrieval and generation capabilities, with captions that can be dynamically adapted through targeted prompting or fine-tuning of the underlying models. Our empirical evaluation across multiple LLM configurations shows that this approach achieves comparable performance to direct video processing while being more computationally efficient and easier to reason about in downstream tasks. Notably, the approach shows particular strength in procedural content like How-To videos, where aligned captions significantly outperform speech-only baselines.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Dela Rosa, Kevin},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {agentic information retrieval, chatbots, multimodal retrieval},
	pages = {1663--1667},
}

@inproceedings{yu_droidcoder_2024,
	address = {New York, NY, USA},
	series = {{ASE} '24},
	title = {{DroidCoder}: {Enhanced} {Android} {Code} {Completion} with {Context}-{Enriched} {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-1248-7},
	url = {https://doi.org/10.1145/3691620.3695063},
	doi = {10.1145/3691620.3695063},
	abstract = {Android is the most popular mobile operating system. However, Android development requires extensive coding, especially for unique features such as lifecycle callbacks and UI widgets. Existing code completion methods typically utilize Retrieval-Augmented Generation (RAG) to provide contextual information for pre-trained code large language models (Code LLMs) to perform completion. Despite considerable progress in these methods, their effectiveness in Android development remains limited. This is because the features of Android development make it challenging for existing retrieval mechanisms to extract sufficient context effectively. In response, we propose DroidCoder, a novel Android code completion framework that employs Android development features and contextual information of code snippets to enrich RAG. It also incorporates a specifically designed loss function to fine-tune the model, enabling it to better utilize context-enhanced RAG for Android code completion. We evaluated our method on three base models and different types of applications, comparing it with two state-of-the-art code completion methods. The experimental results demonstrate that our method significantly outperforms the baselines at line-level and multi-line-level code completion and improves the quality of the completed code.},
	booktitle = {Proceedings of the 39th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Yu, Xinran and Li, Chun and Pan, Minxue and Li, Xuandong},
	year = {2024},
	note = {event-place: Sacramento, CA, USA},
	keywords = {Android, code completion, retrieval-augmented generation},
	pages = {681--693},
}

@inproceedings{xu_face4rag_2024,
	address = {New York, NY, USA},
	series = {{KDD} '24},
	title = {{Face4Rag}: {Factual} {Consistency} {Evaluation} for {Retrieval} {Augmented} {Generation} in {Chinese}},
	isbn = {979-8-4007-0490-1},
	url = {https://doi.org/10.1145/3637528.3671656},
	doi = {10.1145/3637528.3671656},
	abstract = {The prevailing issue of factual inconsistency errors in conventional Retrieval Augmented Generation (RAG) motivates the study of Factual Consistency Evaluation (FCE). Despite the various FCE methods proposed earlier, these methods are evaluated on datasets generated by specific Large Language Models (LLMs). Without a comprehensive benchmark, it remains unexplored how these FCE methods perform on other LLMs with different error distributions or even unseen error types, as these methods may fail to detect the error types generated by other LLMs. To fill this gap, in this paper, we propose the first comprehensive FCE benchmark Face4RAG for RAG independent of the underlying LLM. Our benchmark consists of a synthetic dataset built upon a carefully designed typology for factuality inconsistency error and a real-world dataset constructed from six commonly used LLMs, enabling evaluation of FCE methods on specific error types or real-world error distributions. On the proposed benchmark, we discover the failure of existing FCE methods to detect the logical fallacy, which refers to a mismatch of logic structures between the answer and the retrieved reference. To fix this issue, we further propose a new method called L-Face4RAG with two novel designs of logic-preserving answer decomposition and fact-logic FCE. Extensive experiments show L-Face4RAG substantially outperforms previous methods for factual inconsistency detection on a wide range of tasks, notably beyond the RAG task from which it is originally motivated. Both the benchmark and our proposed method are publicly available. https://huggingface.co/datasets/yq27/Face4RAG},
	booktitle = {Proceedings of the 30th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Xu, Yunqi and Cai, Tianchi and Jiang, Jiyan and Song, Xierui},
	year = {2024},
	note = {event-place: Barcelona, Spain},
	keywords = {factual consistency evaluation, large language model},
	pages = {6083--6094},
}

@inproceedings{jiao_pr-attack_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{PR}-{Attack}: {Coordinated} {Prompt}-{RAG} {Attacks} on {Retrieval}-{Augmented} {Generation} in {Large} {Language} {Models} via {Bilevel} {Optimization}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730058},
	doi = {10.1145/3726302.3730058},
	abstract = {Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of applications, e.g., medical question-answering, mathematical sciences, and code generation. However, they also exhibit inherent limitations, such as outdated knowledge and susceptibility to hallucinations. Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to address these issues, but it also introduces new vulnerabilities. Recent efforts have focused on the security of RAG-based LLMs, yet existing attack methods face three critical challenges: (1) their effectiveness declines sharply when only a limited number of poisoned texts can be injected into the knowledge database (2) they lack sufficient stealth, as the attacks are often detectable by anomaly detection systems, which compromises their effectiveness, and (3) they rely on heuristic approaches to generate poisoned texts, lacking formal optimization frameworks and theoretic guarantees, which limits their effectiveness and applicability. To address these issues, we propose coordinated Prompt-RAG attack (PR-attack), a novel optimization-driven attack that introduces a small number of poisoned texts into the knowledge database while embedding a backdoor trigger within the prompt. When activated, the trigger causes the LLM to generate pre-designed responses to targeted queries, while maintaining normal behavior in other contexts. This ensures both high effectiveness and stealth. We formulate the attack generation process as a bilevel optimization problem leveraging a principled optimization framework to develop optimal poisoned texts and triggers. Extensive experiments across diverse LLMs and datasets demonstrate the effectiveness of PR-Attack, achieving a high attack success rate even with a limited number of poisoned texts and significantly improved stealth compared to existing methods. These results highlight the potential risks posed by PR-Attack and emphasize the importance of securing RAG-based LLMs against such threats.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Jiao, Yang and Wang, Xiaodong and Yang, Kai},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {bilevel optimization, large language models, retrieval-augmented generation},
	pages = {656--667},
}

@inproceedings{zhang_large-language_2025,
	address = {New York, NY, USA},
	series = {{IC}-{BIS} '25},
	title = {A large-language model-driven approach to chronic disease follow-up},
	isbn = {979-8-4007-1439-9},
	url = {https://doi.org/10.1145/3745034.3745043},
	doi = {10.1145/3745034.3745043},
	abstract = {Chronic disease follow-up is essential for adjusting treatment plans and improving patient outcomes, yet traditional methods often face challenges such as resource inefficiency, insufficient coverage, and poor personalization. Leveraging advancements in artificial intelligence, this study proposes a chronic disease follow-up approach driven by a large language model (LLM). The methodology includes fine-tuning a pre-trained LLM using chronic disease-specific datasets to enhance task-specific capabilities. Integration with Graph-based\&nbsp;Retrieval Augmented Generation (GraphRAG)technology enables structured and non-structed data utilization, improving retrieval and response accuracy. The system design incorporates personalized patient interaction, semantic similarity methods, and real-time knowledge updates to enhance compliance and efficiency. However, limitations such as the lack of comprehensive structured data and domain-specific constraints are noted, with future work aimed at refining knowledge graphs and optimizing workflows for vertical field applications. This study provides a novel framework for intelligent chronic disease management in the era of large models.},
	booktitle = {Proceedings of the 4th {International} {Conference} on {Biomedical} and {Intelligent} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Yang and Feng, Sidu and Zhai, Tianzhang and Pan, Rumo and Li, Jian},
	year = {2025},
	keywords = {Artificial Intelligence, Chronic Disease Management, Large Language Model, Personalized Follow-Up, Retrieval Augmented Generation},
	pages = {50--55},
}

@inproceedings{shi_retrieval_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Retrieval {Augmented} {Generation} with {Collaborative} {Filtering} for {Personalized} {Text} {Generation}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730075},
	doi = {10.1145/3726302.3730075},
	abstract = {Recently, the personalization of Large Language Models (LLMs) to generate content that aligns with individual user preferences has garnered widespread attention. Personalized Retrieval-Augmented Generation (RAG), which retrieves relevant documents from the user's history to reflect their preferences and enhance LLM generation, is one commonly used approach for personalization. However, existing personalized RAG methods do not consider that the histories of similar users can also assist in personalized generation for the current user, meaning that collaborative information between users can also benefit personalized generation. Inspired by the application of collaborative filtering in recommender systems, we propose a method called CFRAG, which adapts Collaborative Filtering to RAG for personalized text generation. However, this presents two challenges: (1) how to incorporate collaborative information without explicit user similarity labels? (2) how to retrieve documents that support personalized LLM generation? For Challenge 1, we use contrastive learning to train user embeddings to retrieve similar users and introduce collaborative information. For Challenge 2, we design a personalized retriever and reranker to retrieve the top-k documents from these users' histories. We take into account the user's preference during retrieval and reranking. Then we leverage feedback from the LLM to fine-tune the personalized retriever and reranker, enabling them to retrieve documents that meet the personalized generation needs of the LLM. Experimental results on the Language Model Personalization (LaMP) benchmark validate the effectiveness of CFRAG. Further analysis confirms the importance of incorporating collaborative information.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Shi, Teng and Xu, Jun and Zhang, Xiao and Zang, Xiaoxue and Zheng, Kai and Song, Yang and Li, Han},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {han li, jun xu, kai zheng, teng shi, xiao zhang, xiaoxue zang, yang song},
	pages = {1294--1304},
}

@inproceedings{shawon_retrieval_2025,
	address = {New York, NY, USA},
	series = {{ICPE} '25},
	title = {Retrieval {Augmented} {Generation} {Fine}-{Tuned} {LLM} {Model} for {Code} {Recommendations} to {Mitigate} {Lock} {Contention}},
	isbn = {979-8-4007-1130-5},
	url = {https://doi.org/10.1145/3680256.3721324},
	doi = {10.1145/3680256.3721324},
	abstract = {Lock contention performance faults can lead to degradation in the performance of software applications. Unlike software bugs, per- formance faults do not lead to failures and application crashes but surface as a degradation in the response and execution of an ap- plication and can surface fairly late in the deployment life of an application. Tools exist for the identification and detection of lock performance faults but there is a lack of effective code refactor- ing recommendations for a developer to mitigate the performance degradation caused by lock-contention. Recent advances in Large Language Models (LLMs) have demonstrated positive results in code refactoring for fixing software bugs and mitigating run time faults. However, traditional LLM-based approaches often suffer from hal- lucination errors, where the generated code may not accurately reflect the context of the project or existing codebase. This thesis presents a novel approach that combines Retrieval Augmented Gen- eration (RAG) with a fine-tuned LLM model for refactored code recommendation aimed at reducing lock-contention performance faults in Java applications. The RAG fine-tuned model combines the strengths of contextual understanding from LLMs with the preci- sion of retrieval-based systems, thereby ensuring that the generated recommendations are relevant, accurate, and hallucination-free. Se- mantic and syntactic metrics of the recommendations generated by the combined RAG and LLM model show an accuracy of approxi- mately 90\% compared to an accuracy of approximately 25\% when a baseline LLM model is used.},
	booktitle = {Companion of the 16th {ACM}/{SPEC} {International} {Conference} on {Performance} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Shawon, Ashadullah and Liscano, Ramiro and Azim, Akramul and Sundaresan, Vijay and Chang, Yee-Kang},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {code smell, fine-tuning, large language model, lock contention, rag, refactored code recommendation},
	pages = {95--102},
}

@inproceedings{yang_im-rag_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {{IM}-{RAG}: {Multi}-{Round} {Retrieval}-{Augmented} {Generation} {Through} {Learning} {Inner} {Monologues}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657760},
	doi = {10.1145/3626772.3657760},
	abstract = {Although the Retrieval-Augmented Generation (RAG) paradigms can use external knowledge to enhance and ground the outputs of Large Language Models (LLMs) to mitigate generative hallucinations and static knowledge base problems, they still suffer from limited flexibility in adopting Information Retrieval (IR) systems with varying capabilities, constrained interpretability during the multi-round retrieval process, and a lack of end-to-end optimization. To address these challenges, we propose a novel LLM-centric approach, IM-RAG, that integrates IR systems with LLMs to support multi-round RAG through learning Inner Monologues (IM, i.e., the human inner voice that narrates one's thoughts). During the IM process, the LLM serves as the core reasoning model (i.e., Reasoner ) to either propose queries to collect more information via the Retriever or to provide a final answer based on the conversational context. We also introduce a Refiner that improves the outputs from the Retriever, effectively bridging the gap between the Reasoner and IR modules with varying capabilities and fostering multi-round communications. The entire IM process is optimized via Reinforcement Learning (RL) where a Progress Tracker is incorporated to provide mid-step rewards, and the answer prediction is further separately optimized via Supervised Fine-Tuning (SFT). We conduct extensive experiments with the HotPotQA dataset, a popular benchmark for retrieval-based, multi-step question-answering. The results show that our approach achieves state-of-the-art (SOTA) performance while providing high flexibility in integrating IR modules as well as strong interpretability exhibited in the learned inner monologue.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Yang, Diji and Rao, Jinmeng and Chen, Kezhen and Guo, Xiaoyuan and Zhang, Yawen and Yang, Jie and Zhang, Yi},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {inner monologue, large language models, multi-round retrieval, question answering, retrieval augmented generation},
	pages = {730--740},
}

@inproceedings{garetto_information_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Information {Retrieval} in the {Age} of {Generative} {AI}: {The} {RGB} {Model}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730008},
	doi = {10.1145/3726302.3730008},
	abstract = {The advent of Large Language Models (LLMs) and generative AI is fundamentally transforming information retrieval and processing on the Internet, bringing both great potential and significant concerns regarding content authenticity and reliability. This paper presents a novel quantitative approach to shed light on the complex information dynamics arising from the growing use of generative AI tools. Despite their significant impact on the digital ecosystem, these dynamics remain largely uncharted and poorly understood. We propose a stochastic model to characterize the generation, indexing, and dissemination of information in response to new topics. This scenario particularly challenges current LLMs, which often rely on real-time Retrieval-Augmented Generation (RAG) techniques to overcome their static knowledge limitations. Our findings suggest that the rapid pace of generative AI adoption, combined with increasing user reliance, can outpace human verification, escalating the risk of inaccurate information proliferation across digital resources. An in-depth analysis of Stack Exchange data confirms that high-quality answers inevitably require substantial time and human effort to emerge. This underscores the considerable risks associated with generating persuasive text in response to new questions and highlights the critical need for responsible development and deployment of future generative AI tools.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Garetto, Michele and Cornacchia, Alessandro and Galante, Franco and Leonardi, Emilio and Nordio, Alessandro and Tarable, Alberto},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {automation bias, information quality, large language models, retrieval-augmented generation, stack exchange, web answering},
	pages = {602--612},
}

@inproceedings{wang_evaluating_2025,
	address = {New York, NY, USA},
	series = {{ICCIP} '24},
	title = {Evaluating {Sparse} and {Dense} {Retrieval} in {Retrieval}-{Augmented} {Generation} {Systems}: {A} {Study}},
	isbn = {979-8-4007-1744-4},
	url = {https://doi.org/10.1145/3708657.3708747},
	doi = {10.1145/3708657.3708747},
	abstract = {With the rapid advancement of large-scale pre-trained models, their capabilities have found widespread applications across various fields, leading to increasing demand from individual users. However, personal users often face challenges such as concerns over data security and limitations in hardware resources, making the development and deployment of these models a complex task. Retrieval-Augmented Generation (RAG) systems offer a promising solution by enhancing a model’s ability to acquire knowledge through the integration of external knowledge bases, without the need for extensive training. Nevertheless, RAG systems employ a variety of retrieval algorithms, and different configurations can significantly impact both resource consumption and performance. As a result, choosing the right retrieval algorithm has become a critical area of research. This study evaluates and compares sparse and dense retrieval algorithms, aiming to identify how RAG system performance can be optimized under varying resource constraints and user requirements. The experimental results demonstrate that a well-matched combination of Large-scale Language Model and retrieval algorithm can maximize system performance under specific hardware conditions, offering new strategies for individual users to efficiently leverage large models.},
	booktitle = {Proceedings of the 2024 10th {International} {Conference} on {Communication} and {Information} {Processing}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Yang and Dai, Guanlin and Ke, Song and Zheng, Chao},
	year = {2025},
	keywords = {evaluation, large-scale language model, retrieval-augmented generation},
	pages = {548--554},
}

@inproceedings{dong_decoupling_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Decoupling {Knowledge} and {Context}: {An} {Efficient} and {Effective} {Retrieval} {Augmented} {Generation} {Framework} via {Cross} {Attention}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714608},
	doi = {10.1145/3696410.3714608},
	abstract = {Retrieval-Augmented Generation (RAG) systems have become a crucial tool to augment large language models (LLMs) with external knowledge for better task performance. However, existing traditional RAG methods inject knowledge directly into the context, resulting in several limitations. First, these methods highly rely on the in-context learning capability of LLMs, which often leads to excessively long contexts. This is inefficient due to the quadratic complexity of self-attention, leading to significant increase in inference time. Second, the extended context and the nature of self-attention can cause the LLMs to lose important information in the context, thereby degrading the original capabilities of LLMs. Third, the effectiveness of knowledge injection is perturbed by the permutation of knowledge within the extended context, reducing the robustness of existing RAG methods. To tackle the above problems, we propose DecoupledRAG, a method that decouples external knowledge from the context within the RAG framework. Specifically, we introduce a cross-attention based method that injects retrieved knowledge directly into the inference process of LLM on the fly, without modifying its parameters or the input context, so that the external knowledge can be utilized robustly in a permutation-independent manner. To the best of our knowledge, this is the first work that explore how to utilize cross-attention to inject knowledge with low training cost in decoder-only LLM era. By leveraging cross-attention operation, DecoupledRAG enables seamless knowledge aggregation without creating extended context. Experimental results demonstrate that our method could achieve high efficiency while maintaining strong performance, which indicates that RAG frameworks have the potential to benefit further from more knowledge.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Dong, Qian and Ai, Qingyao and Wang, Hongning and Liu, Yiding and Li, Haitao and Su, Weihang and Liu, Yiqun and Chua, Tat-Seng and Ma, Shaoping},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {knowledge injection, language model, retrieval augmented generation},
	pages = {4386--4395},
}

@inproceedings{zhang_domain-specific_2025,
	address = {New York, NY, USA},
	series = {{ICBAR} '24},
	title = {A {Domain}-specific {Retrieval}-{Augmented} {Generation} {System} for {Civil} {Aviation} {Safety}},
	isbn = {979-8-4007-0975-3},
	url = {https://doi.org/10.1145/3718751.3718860},
	doi = {10.1145/3718751.3718860},
	abstract = {This paper presents a domain-specific Retrieval Enhanced Generation (RAG) system designed for civil aviation security, to improve the quality of domain-specific query answers. Based on advanced Natural Language Processing (NLP) technology, this system combines large language models, embedding models and similarity search strategy, to optimize the accuracy, relevance and reliability of the generation. We evaluated the impact of different parameters (large language model, embedding model, and Top-k values) on the performance of the RAG system by adjusting them separately. In each set of experiments, we changed only one variable individually, while the others were kept fixed. This ensures that we can clearly observe the independent impact of each parameter change on the performance of the system. The results show that choosing an right large language model and top-k values will significantly improve the output quality, balancing between the accuracy of the answers and the comprehensiveness of the search. Though there's some limitations, such as too much reliance on vector similarity and the limitations of LLMs, the system still provides a tool to provide civil aviation practitioners with timely and accurate information. Future work will explore some improvements such as the use of graphical databases and the use of larger language models. This RAG system shows a step-forward in intelligent, data-driven decision-making in civil aviation safety, has great potential to improve response and safety management in emergency scenarios.},
	booktitle = {Proceedings of the 2024 4th {International} {Conference} on {Big} {Data}, {Artificial} {Intelligence} and {Risk} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Zhonghao and Yang, Xiaochen and Zeng, Changchang},
	year = {2025},
	keywords = {Civil Aviation Safety, Large Language Models (LLMs), Retrieval Augmented Generation (RAG)},
	pages = {682--687},
}

@inproceedings{wang_feb4rag_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {{FeB4RAG}: {Evaluating} {Federated} {Search} in the {Context} of {Retrieval} {Augmented} {Generation}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657853},
	doi = {10.1145/3626772.3657853},
	abstract = {Federated search systems aggregate results from multiple search engines, selecting appropriate sources to enhance result quality and align with user intent. With the increasing uptake of Retrieval-Augmented Generation (RAG) pipelines, federated search can play a pivotal role in sourcing relevant information across heterogeneous data sources to generate informed responses. However, existing datasets, such as those developed in the past TREC FedWeb tracks, predate the RAG paradigm shift and lack representation of modern information retrieval challenges.To bridge this gap, we present FeB4RAG, a novel dataset specifically designed for federated search within RAG frameworks. This dataset, derived from 16 sub-collections of the widely used BEIR benchmarking collection, includes 790 information requests (akin to conversational queries) tailored for chatbot applications, along with top results returned by each resource and associated LLM-derived relevance judgements. Additionally, to support the need for this collection, we demonstrate the impact on response generation of a high quality federated search system for RAG compared to a naive approach to federated search. We do so by comparing answers generated by the RAG pipeline with a qualitative side-by-side comparison. Our collection fosters and supports the development and evaluation of new federated search methods, especially in the context of RAG pipelines. The resource is publicly available at https://github.com/ielab/FeB4RAG.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Shuai and Khramtsova, Ekaterina and Zhuang, Shengyao and Zuccon, Guido},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {federated search, large language models (llms), retrieval augmented generation (rag), test collection.},
	pages = {763--773},
}

@inproceedings{cahoon_optimizing_2025,
	address = {New York, NY, USA},
	series = {{MIDAS} '25},
	title = {Optimizing open-domain question answering with graph-based retrieval augmented generation},
	isbn = {979-8-4007-1960-8},
	url = {https://doi.org/10.1145/3737412.3743489},
	doi = {10.1145/3737412.3743489},
	abstract = {In this work, we benchmark various graph-based retrieval-augmented generation (RAG) systems across a broad spectrum of query types, including OLTP-style (fact-based) and OLAP-style (thematic) queries, to address the complex demands of open-domain question answering (QA). Traditional RAG methods often fall short in handling nuanced, multi-document synthesis tasks. By structuring knowledge as graphs, we can facilitate the retrieval of context that captures greater semantic depth and enhances language model operations. We explore graph-based RAG methodologies and introduce TREX, a novel, cost-effective alternative that combines graph-based indexing and vector-based retrieval techniques. Our benchmarking across four diverse datasets highlights the strengths of different RAG methodologies, demonstrates TREX’s ability to handle multiple open-domain QA types, and reveals the limitations of current evaluation methods. We publicly release these datasets to facilitate further research and benchmarking at https://github.com/microsoft/graphrag-benchmarking-datasets. Our findings underscore the potential of augmenting large language models with advanced retrieval capabilities and scalable graph-based AI solutions.},
	booktitle = {Proceedings of the 1st {Workshop} {Connecting} {Academia} and {Industry} on {Modern} {Integrated} {Database} and {AI} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Cahoon, Joyce and Singh, Prerna and Litombe, Nick and Larson, Jonathan and Trinh, Ha and Zhu, Yiwen and Mueller, Andreas and Psallidas, Fotis and Curino, Carlo},
	year = {2025},
	pages = {1--11},
}

@inproceedings{pu_customized_2025,
	address = {New York, NY, USA},
	series = {{ICCAD} '24},
	title = {Customized {Retrieval} {Augmented} {Generation} and {Benchmarking} for {EDA} {Tool} {Documentation} {QA}},
	isbn = {979-8-4007-1077-3},
	url = {https://doi.org/10.1145/3676536.3676730},
	doi = {10.1145/3676536.3676730},
	abstract = {Retrieval augmented generation (RAG) enhances the accuracy and reliability of generative AI models by sourcing factual information from external databases, which is extensively employed in document-grounded question-answering (QA) tasks. Off-the-shelf RAG flows are well pretrained on general-purpose documents, yet they encounter significant challenges when being applied to knowledge-intensive vertical domains, such as electronic design automation (EDA). This paper addresses such issue by proposing a customized RAG framework along with three domain-specific techniques for EDA tool documentation QA, including a contrastive learning scheme for text embedding model fine-tuning, a reranker distilled from proprietary LLM, and a generative LLM fine-tuned with high-quality domain corpus. Furthermore, we have developed and released a documentation QA evaluation benchmark, ORD-QA, for OpenROAD, an advanced RTL-to-GDSII design platform. Experimental results demonstrate that our proposed RAG flow and techniques have achieved superior performance on ORD-QA as well as on a commercial tool, compared with state-of-the-arts. The ORD-QA benchmark and the training dataset for our customized RAG flow are open-source at https://github.com/lesliepy99/RAG-EDA.},
	booktitle = {Proceedings of the 43rd {IEEE}/{ACM} {International} {Conference} on {Computer}-{Aided} {Design}},
	publisher = {Association for Computing Machinery},
	author = {Pu, Yuan and He, Zhuolun and Qiu, Tairu and Wu, Haoyuan and Yu, Bei},
	year = {2025},
	note = {event-place: Newark Liberty International Airport Marriott, New York, NY, USA},
}

@inproceedings{zhu_collaborative_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Collaborative {Retrieval} for {Large} {Language} {Model}-based {Conversational} {Recommender} {Systems}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714908},
	doi = {10.1145/3696410.3714908},
	abstract = {Conversational recommender systems (CRS) aim to provide personalized recommendations via interactive dialogues with users. While large language models (LLMs) enhance CRS with their superior understanding of context-aware user preferences, they typically struggle to leverage behavioral data, which have proven to be important for classical collaborative filtering (CF)-based approaches. For this reason, we propose CRAG-Collaborative Retrieval Augmented Generation for LLM-based CRS. To the best of our knowledge, CRAG is the first approach that combines state-of-the-art LLMs with CF for conversational recommendations. Our experiments on two publicly available movie conversational recommendation datasets, i.e., a refined Reddit dataset (which we name Reddit-v2) as well as the Redial dataset, demonstrate the superior item coverage and recommendation performance of CRAG, compared to several CRS baselines. Moreover, we observe that the improvements are mainly due to better recommendation accuracy on recently released movies. The code and data are available at https://github.com/yaochenzhu/CRAG.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Zhu, Yaochen and Wan, Chao and Steck, Harald and Liang, Dawen and Feng, Yesu and Kallus, Nathan and Li, Jundong},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {collaborative filtering, conversational recommender systems, large language models, llm, retrieval augmented generation},
	pages = {3323--3334},
}

@inproceedings{gao_optimized_2025,
	address = {New York, NY, USA},
	series = {{ISBDAI} '24},
	title = {Optimized {Individual} {Modules} in {Retrieval} {Augmented} {Generation} in {Concrete} {Scenarios}},
	isbn = {979-8-4007-1829-8},
	url = {https://doi.org/10.1145/3723366.3723380},
	doi = {10.1145/3723366.3723380},
	abstract = {As the era of big data arrives, enterprises have accumulated an increasing amount of data. How to effectively utilize cutting-edge artificial intelligence technologies to digitize massive amounts of information has become a significant challenge. Due to the exorbitant costs of training large language models (LLMs) from scratch, along with limitations such as the context window length of these models, user data privacy concerns, and model hallucinations, Retrieval-Augmented Generation (RAG) is increasingly being adopted in reality applications. In recent years, the development of large language models has led to their widespread application across industries. However, the inconsistency between the training objectives of large models and the retrieval tasks often results in severe hallucinations, particularly in very professional and personal domains, and then leads to incorrect responses. To solve this problem, RAG has been widely implemented. This paper delves into several aspects, including query augmentation, encoding combination, hybrid re-ranking, and filtering of final candidate documents, which presents a practical and effective RAG system. Extensive experiments were conducted on plant and resume datasets, with ablation studies performed for each module. Comparative analyses revealed significant improvements over existing methods, achieving an average enhancement of 4\% or more in real-world applications, and a notable 6\% improvement specifically in the resume dataset. The final experimental analysis substantiates the efficacy of this approach.},
	booktitle = {Proceedings of the 2024 4th {International} {Symposium} on {Big} {Data} and {Artificial} {Intelligence}},
	publisher = {Association for Computing Machinery},
	author = {Gao, Yue},
	year = {2025},
	keywords = {artificial intelligence, big data, encode combination, model hallucinations, query augment},
	pages = {80--84},
}

@inproceedings{tupayachi_conversational_2025,
	address = {New York, NY, USA},
	series = {{IWCTS}'24},
	title = {Conversational {Geographic} {Question} {Answering} for {Route} {Optimization}: {An} {LLM} and {Continuous} {Retrieval}-{Augmented} {Generation} {Approach}},
	isbn = {979-8-4007-1151-0},
	url = {https://doi.org/10.1145/3681772.3698217},
	doi = {10.1145/3681772.3698217},
	abstract = {We present a pilot study exploring the potential of Large Language Models (LLMs) to interface with application programming interfaces through logical instructions, specifically within the domain of Geographic Question Answering for route optimization. This study employs a Continuous Retrieval-Augmented Generation approach combined with fine-tuned LLMs, featuring customized node-based storage and vector search retrieval. We also provide a comparative analysis of the method's effectiveness and adaptability in handling diverse textual queries.},
	booktitle = {Proceedings of the 17th {ACM} {SIGSPATIAL} {International} {Workshop} on {Computational} {Transportation} {Science} {GenAI} and {Smart} {Mobility} {Session}},
	publisher = {Association for Computing Machinery},
	author = {Tupayachi, Jose and Li, Xueping},
	year = {2025},
	note = {event-place: Atlanta, GA, USA},
	keywords = {Geographical Information, Large Language Models, Question Answering, Retrieval Augmented Generation},
	pages = {56--59},
}

@inproceedings{ehsan_explainable_2024,
	address = {New York, NY, USA},
	series = {{HttF} '24},
	title = {Explainable {AI} {Reloaded}: {Challenging} the {XAI} {Status} {Quo} in the {Era} of {Large} {Language} {Models}},
	isbn = {979-8-4007-1042-1},
	url = {https://doi.org/10.1145/3686169.3686185},
	doi = {10.1145/3686169.3686185},
	abstract = {When the initial vision of Explainable (XAI) was articulated, the most popular framing was to open the (proverbial) “black-box” of AI so that we could understand the inner workings. With the advent of Large Language Models (LLMs), the very ability to open the black-box is increasingly limited. Especially when it comes to non-technical end-users. In this paper, we challenge the assumption of “opening” the black-box in the LLM era and argue for a shift in our XAI expectations. Highlighting the epistemic blind spots of an algorithm-centered XAI view, we argue that a human-centered perspective can be a path forward. We operationalize the argument by synthesizing XAI research along three dimensions: explainability outside the black-box, explainability around the edges of the black box, and explainability that leverages infrastructural seams. We conclude with takeaways that reflexively inform XAI as a domain.},
	booktitle = {Proceedings of the {Halfway} to the {Future} {Symposium}},
	publisher = {Association for Computing Machinery},
	author = {Ehsan, Upol and Riedl, Mark},
	year = {2024},
	note = {event-place: Santa Cruz, CA, USA},
	keywords = {Explainable AI, Generative AI, Large Language Models},
}

@inproceedings{yu_integrating_2025,
	address = {New York, NY, USA},
	series = {{SIGCSETS} 2025},
	title = {Integrating {Small} {Language} {Models} with {Retrieval}-{Augmented} {Generation} in {Computing} {Education}: {Key} {Takeaways}, {Setup}, and {Practical} {Insights}},
	isbn = {979-8-4007-0531-1},
	url = {https://doi.org/10.1145/3641554.3701844},
	doi = {10.1145/3641554.3701844},
	abstract = {Leveraging a Large Language Model (LLM) for personalized learning in computing education is promising, yet cloud-based LLMs pose risks around data security and privacy. To address these concerns, we developed and deployed a locally stored Small Language Model (SLM) utilizing Retrieval-Augmented Generation (RAG) methods to support computing students' learning. Previous work has demonstrated that SLMs can match or surpass popular LLMs (gpt-3.5-turbo and gpt-4-32k) in handling conversational data from a CS1 course. We deployed SLMs with RAG (SLM + RAG) in a large course with more than 250 active students, fielding nearly 2,000 student questions, while evaluating data privacy, scalability, and feasibility of local deployments. This paper provides a comprehensive guide for deploying SLM + RAG systems, detailing model selection, vector database choice, embedding methods, and pipeline frameworks. We share practical insights from our deployment, including scalability concerns, accuracy versus context length trade-offs, guardrails and hallucination reduction, as well as data privacy maintenance. We address the "Impossible Triangle" in RAG systems, which states that achieving high accuracy, short context length, and low time consumption simultaneously is not feasible. Furthermore, our novel RAG framework, Intelligence Concentration (IC), categorizes information into multiple layers of abstraction within Milvus collections mitigating trade-offs and enabling educational assistants to deliver more relevant and personalized responses to students quickly.},
	booktitle = {Proceedings of the 56th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education} {V}. 1},
	publisher = {Association for Computing Machinery},
	author = {Yu, Zezhu and Liu, Suqing and Denny, Paul and Bergen, Andreas and Liut, Michael},
	year = {2025},
	note = {event-place: Pittsburgh, PA, USA},
	keywords = {computer science education, computing education, conversational agent, intelligence concentration, intelligent tutoring system, large language models, milvus, personalized ai agent, retrieval-augmented generation, small language models},
	pages = {1302--1308},
}

@inproceedings{yang_knowledge-enhanced_2025,
	address = {New York, NY, USA},
	series = {{ICAICE} '24},
	title = {Knowledge-{Enhanced} {Large} {Language} {Model}-{Based} {Assistance} {Training} {System} for {Subway} {Maintenance} {Personnel}},
	isbn = {979-8-4007-1800-7},
	url = {https://doi.org/10.1145/3716895.3716900},
	doi = {10.1145/3716895.3716900},
	abstract = {To address the various challenges faced in training urban rail transit system maintenance personnel, this paper proposes a solution for developing a training system for subway maintenance personnel using knowledge graphs and a Retrieval-Augmented Generation (RAG)-enhanced large language model. The approach involves first creating a fine-tuning dataset from subway maintenance technical documents to fine-tune the large language model. This fine-tuned model then assists in constructing a subway maintenance knowledge graph. Concurrently, a vector database of subway maintenance knowledge is established. Finally, a question-answering system leveraging both the knowledge graph and the vector database as external knowledge sources is developed to support the training of subway maintenance personnel. Results demonstrate that this system can effectively enhance the learning efficiency of maintenance staff.},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Artificial} {Intelligence} and {Computer} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Yang, Da and Wang, Hongbo and Shao, Shanzhong and Liu, Shutian},
	year = {2025},
	keywords = {knowledge graph (KG), large language model (LLM), Retrieval-Augmented Generation (RAG), subway maintenance},
	pages = {25--29},
}

@inproceedings{wynn-williams_can_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {Can {Generative} {AI} {Produce} {Test} {Cases}? {An} {Experience} from the {Automotive} {Domain}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3728568},
	doi = {10.1145/3696630.3728568},
	abstract = {Engineers need automated support for software testing. Generative AI is a novel technology for generating new content; however, its applicability for test case generation is still unclear. This work considers the following question: Can generative AI produce test cases in industrial software applications? We framed our question in the automotive domain. We performed our evaluation in collaboration with a large automotive manufacturer to assess to what extent generative AI can produce test cases (a.k.a. test scripts) from informal test case specifications. We considered 1) informal test case specifications defined in Rational Quality Manager, an industrial test management tool from IBM, and 2) executable test scripts specified as ecu.test packages supported by the ecu.test tool from Tracetronic. We used generative AI to produce the test scripts from the informal test case descriptions. Our results show that generative AI can produce correct or near-correct test scripts in a reasonable number of cases. We also analyzed the effects of prompt design, choice of generative AI model, and context accuracy on the effectiveness of our solution and reflected on our results.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Wynn-Williams, Stephen and Tyrrell, Ryan and Pantelic, Vera and Lawford, Mark and Menghi, Claudio and Nalla, Phaneendra and Artail, Hassan},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {automotive software, generative AI, LLM, software testing},
	pages = {456--467},
}

@inproceedings{yao_cacheblend_2025,
	address = {New York, NY, USA},
	series = {{EuroSys} '25},
	title = {{CacheBlend}: {Fast} {Large} {Language} {Model} {Serving} for {RAG} with {Cached} {Knowledge} {Fusion}},
	isbn = {979-8-4007-1196-1},
	url = {https://doi.org/10.1145/3689031.3696098},
	doi = {10.1145/3689031.3696098},
	abstract = {Large language models (LLMs) often incorporate multiple text chunks in their inputs to provide the necessary contexts. To speed up the prefill of the long LLM inputs, one can pre-compute the KV cache of a text and re-use the KV cache when the context is reused as the prefix of another LLM input. However, the reused text chunks are not always the input prefix, which makes precomputed KV caches not directly usable since they ignore the text's cross-attention with the preceding texts. Thus, the benefits of reusing KV caches remain largely unrealized.This paper tackles just one challenge: when an LLM input contains multiple text chunks, how to quickly combine their precomputed KV caches in order to achieve the same generation quality as the expensive full prefill (i.e., without reusing KV cache)? This challenge naturally arises in retrieval-augmented generation (RAG) where the input is supplemented with multiple retrieved texts as the context. We present CacheBlend, a scheme that reuses the precomputed KV caches, regardless prefix or not, and selectively recomputes the KV values of a small subset of tokens to partially update each reused KV cache. In the meantime, the small extra delay for recomputing some tokens can be pipelined with the retrieval of KV caches within the same job, allowing CacheBlend to store KV caches in slower devices with more storage capacity while retrieving them without increasing the inference delay. By comparing CacheBlend with the state-of-the-art KV cache reusing schemes on three open-source LLMs of various sizes and four popular benchmark datasets of different tasks, we show that CacheBlend reduces time-to-first-token (TTFT) by 2.2-3.3× and increases the inference throughput by 2.8-5× from full KV recompute without compromising generation quality. The code is available at https://github.com/LMCache/LMCache.},
	booktitle = {Proceedings of the {Twentieth} {European} {Conference} on {Computer} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Yao, Jiayi and Li, Hanchen and Liu, Yuhan and Ray, Siddhant and Cheng, Yihua and Zhang, Qizheng and Du, Kuntai and Lu, Shan and Jiang, Junchen},
	year = {2025},
	note = {event-place: Rotterdam, Netherlands},
	keywords = {KV Cache, Large Language Models, Retrieval-Augmented-Generation},
	pages = {94--109},
}

@inproceedings{guo_efragembedding-finetuning_2024,
	address = {New York, NY, USA},
	series = {{PRIS} '24},
	title = {{EFRAG}:{Embedding}-{FineTuning} {Retrieval} {Augmented} {Generation} for {QA} in power projects},
	isbn = {979-8-4007-1825-0},
	url = {https://doi.org/10.1145/3689218.3689225},
	doi = {10.1145/3689218.3689225},
	abstract = {This paper introduces an innovative method called EFRAG (Embedding-FineTuning Retrieval Augmented Generation for QA in power projects), which incorporates an external knowledge base as an additional information source to precisely answer questions related to power projects. The core of EFRAG lies in Embedding-FineTuning to enhance the model’s comprehension of user queries and project documents, thereby improving matching capability in power-related QA tasks and assisting the LLM in deriving accurate answers. This paper details the fundamental principles and implementation process of EFRAG and validates its effectiveness through a series of experiments. The experimental results indicate that EFRAG significantly improves the accuracy of QA results. The research findings not only provide a solution for enhancing power-related QA but also offer new insights into empowering the power industry through large language models.},
	booktitle = {Proceedings of the 2024 6th {International} {Conference} on {Pattern} {Recognition} and {Intelligent} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Guo, Jun and Huang, Jianye and Zhao, Zhichao and Chen, Jinming and Weng, Yuyou and Lin, Guoqing},
	year = {2024},
	note = {event-place: Hong Kong, Hong Kong},
	keywords = {Embedding-FineTuning, Power project, RAG},
	pages = {21--27},
}

@inproceedings{yamanishi_tourmllm_2025,
	address = {New York, NY, USA},
	series = {{ICMR} '25},
	title = {{TourMLLM}: {A} {Retrieval}-{Augmented} {Multimodal} {Large} {Language} {Model} for {Multitask} {Learning} in the {Tourism} {Domain}},
	isbn = {979-8-4007-1877-9},
	url = {https://doi.org/10.1145/3731715.3733450},
	doi = {10.1145/3731715.3733450},
	abstract = {Artificial Intelligence (AI) has shown significant potential in tourism, particularly in personalized recommendations, information provision, and user experience sharing. Recent advancements in multimodal large language models (MLLMs) have further enhanced AI-driven solutions. Although some MLLMs for tourism are proposed, existing models are constrained to a narrow range of tasks, limiting their effectiveness in providing information and personalization. Additionally, while some instruction tuning methods are proposed, effective learning methods that facilitate scaling for multi-task learning are still lacking in this domain. This paper proposes TourMLLM, a multimodal large language model designed to expand task coverage while improving training efficiency and accuracy. TourMLLM supports six key tasks, broadening its applications: landmark recognition, general review generation, conditional review generation, tourism recommendation, tourism image captioning with and without landmark names. To enhance adaptability and performance, we introduce task-adaptive retrieval-augmented instruction tuning and preference optimization strategies, allowing the model to handle diverse tourism-related tasks more effectively. Evaluation across six tasks demonstrates that TourMLLM outperforms GPT-4o in accuracy. The dataset and code are available online at https://github.com/HiromasaYamanishi/TourMLLM.},
	booktitle = {Proceedings of the 2025 {International} {Conference} on {Multimedia} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Yamanishi, Hiromasa and Xiao, Ling and Yamasaki, Toshihiko},
	year = {2025},
	note = {event-place: Chicago, IL, USA},
	keywords = {multimodal large language model, retrieval augmented generation, tourism},
	pages = {1654--1663},
}

@inproceedings{cai_forag_2024,
	address = {New York, NY, USA},
	series = {{KDD} '24},
	title = {{FoRAG}: {Factuality}-optimized {Retrieval} {Augmented} {Generation} for {Web}-enhanced {Long}-form {Question} {Answering}},
	isbn = {979-8-4007-0490-1},
	url = {https://doi.org/10.1145/3637528.3672065},
	doi = {10.1145/3637528.3672065},
	abstract = {Retrieval Augmented Generation (RAG) has become prevalent in question-answering (QA) tasks due to its ability of utilizing search engine to enhance the quality of long-form question-answering (LFQA). Despite the emergence of various open source methods and web-enhanced commercial systems such as Bing Chat, two critical problems remain unsolved, i.e., the lack of factuality and clear logic in the generated long-form answers. In this paper, we remedy these issues via a systematic study on answer generation in web-enhanced LFQA. Specifically, we first propose a novel outline-enhanced generator to achieve clear logic in the generation of multifaceted answers and construct two datasets accordingly. Then we propose a factuality optimization method based on a carefully designed doubly fine-grained RLHF framework, which contains automatic evaluation and reward modeling in different levels of granularity. Our generic framework comprises conventional fine-grained RLHF methods as special cases. Extensive experiments verify the superiority of our proposed Factuality-optimized RAG (FoRAG) method on both English and Chinese benchmarks. In particular, when applying our method to Llama2-7B-chat, the derived model FoRAG-L-7B outperforms WebGPT-175B in terms of three commonly used metrics (i.e., coherence, helpfulness, and factuality), while the number of parameters is much smaller (only 1/24 of that of WebGPT-175B). Our datasets and models are made publicly available for better reproducibility.https://huggingface.co/forag łabelfootnote\_dataset\_url},
	booktitle = {Proceedings of the 30th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Cai, Tianchi and Tan, Zhiwen and Song, Xierui and Sun, Tao and Jiang, Jiyan and Xu, Yunqi and Zhang, Yinger and Gu, Jinjie},
	year = {2024},
	note = {event-place: Barcelona, Spain},
	keywords = {fine-grained rlhf, rag},
	pages = {199--210},
}

@inproceedings{maity_leveraging_2025,
	address = {New York, NY, USA},
	series = {{FIRE} '24},
	title = {Leveraging {In}-{Context} {Learning} and {Retrieval}-{Augmented} {Generation} for {Automatic} {Question} {Generation} in {Educational} {Domains}},
	isbn = {979-8-4007-1318-7},
	url = {https://doi.org/10.1145/3734947.3734949},
	doi = {10.1145/3734947.3734949},
	abstract = {Question generation in education is a time-consuming and cognitively demanding task, as it requires creating questions that are both contextually relevant and pedagogically sound. Current automated question generation methods often generate questions that are out of context. In this work, we explore advanced techniques for automated question generation in educational contexts, focusing on In-Context Learning (ICL), Retrieval-Augmented Generation (RAG), and a novel Hybrid Model that merges both methods. We implement GPT-4 for ICL using few-shot examples and BART with a retrieval module for RAG. The Hybrid Model combines RAG and ICL to address these issues and improve question quality. Evaluation is conducted using automated metrics, followed by human evaluation metrics. Our results show that both the ICL approach and the Hybrid Model consistently outperform other methods, including baseline models, by generating more contextually accurate and relevant questions.},
	booktitle = {Proceedings of the 16th {Annual} {Meeting} of the {Forum} for {Information} {Retrieval} {Evaluation}},
	publisher = {Association for Computing Machinery},
	author = {Maity, Subhankar and Deroy, Aniket and Sarkar, Sudeshna},
	year = {2025},
	keywords = {Automatic Question Generation (AQG), In-Context Learning (ICL), Large Language Models (LLMs), Retrieval-Augmented Generation (RAG)},
	pages = {40--47},
}

@inproceedings{huang_foodpuzzle_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{FoodPuzzle}: {Toward} {Developing} {Large} {Language} {Model} {Agents} as {Autonomous} {Flavor} {Scientists}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737384},
	doi = {10.1145/3711896.3737384},
	abstract = {Flavor development in the food industry is increasingly challenged by the need for rapid innovation and precise flavor profile creation. Traditional flavor research methods typically rely on iterative, subjective testing, which lacks the efficiency and scalability required for modern demands. This paper presents three contributions to address these challenges. Firstly, we define a new problem domain for scientific agents in flavor science, conceptualized as the generation of hypotheses for flavor profile sourcing and understanding. By leveraging their capacity to identify relevant evidence and reason within large context spaces, language model-backed agents can perform the labor-intensive tasks of flavor sourcing and understanding with enhanced efficiency and precision. To facilitate research in this area, we introduce the FoodPuzzle dataset, a challenging benchmark consisting of 978 food items and 1,766 flavor molecule profiles. We propose a novel Scientific Agent approach, integrating in-context learning and retrieval augmented techniques to generate grounded hypotheses in the domain of food science. Experimental results indicate that our model significantly surpasses traditional methods in flavor profile prediction tasks, demonstrating its potential to transform flavor development practices.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Huang, Tenghao and Lee, Dong Hee and Sweeney, John and Shi, Jiatong and Steliotes, Emily and Lange, Matthew and May, Jonathan and Chen, Muhao},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {agent, flavor science, in-context learning, large language models, retrieval-augmented generation},
	pages = {5493--5504},
}

@inproceedings{lu_retrieval-augmented_2025,
	address = {New York, NY, USA},
	series = {{CECCT} '24},
	title = {A {Retrieval}-{Augmented} {Generation} {Framework} for {Electric} {Power} {Industry} {Question} {Answering}},
	isbn = {979-8-4007-1019-3},
	url = {https://doi.org/10.1145/3705754.3705771},
	doi = {10.1145/3705754.3705771},
	abstract = {Retrieval-augmented Generation has achieved significant success in improving the performance of large language models by utilizing external knowledge sources. However, despite its advancements, it still faces challenges in domain-specific structured documents such as the electric power industry, exhibiting low recall rates and response inaccuracies. To solve these issues, this paper designs a question-answering framework specifically for the electric power industry using the large language model. This study first analyzes the characteristics of documents in the electric power industry and proposes the Hierarchical Adaptive Semantic Segmentation(HASS) method, which improves the accuracy of responses and the precision of queries by subdividing knowledge points and integrating metadata. In the retrieval strategy, a Hybrid Search(HS) method is designed, combining the advantages of sparse and dense retrieval to improve the recall rate. To enable large language models to focus on relevant documents when generating responses, we propose the Irrelevant Document Filtering(IDF) method for minimizing the noise impact from irrelevant documents. Additionally, the model is designed with prompts and fine-tuned to further enhance its ability to utilize context and the accuracy of answer generation. Finally, due to the lack of publicly available datasets for document question-answering in the electricity sector, this work constructs a dataset manually for training and evaluation, comprising 1300 QA items covering several types of questions. Experimental results demonstrate that the methods proposed in this paper effectively improve the accuracy of LLMs in the electric power industry, with our method showing a 9\% improvement in accuracy over the traditional RAG approach.},
	booktitle = {Proceedings of the 2024 2nd {International} {Conference} on {Electronics}, {Computers} and {Communication} {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Lu, Yanyan and Peng, Jiao and Xu, Xing and He, Yue and Li, Tao and Wei, Jie and Jing, Hongyu and Wang, Heqing and Xu, Bo and Song, Hui},
	year = {2025},
	keywords = {hybrid search, language model, semantic screening, semantic segmentation},
	pages = {95--100},
}

@inproceedings{tan_paths-over-graph_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Paths-over-{Graph}: {Knowledge} {Graph} {Empowered} {Large} {Language} {Model} {Reasoning}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714892},
	doi = {10.1145/3696410.3714892},
	abstract = {Large Language Models (LLMs) have achieved impressive results in various tasks but struggle with hallucination problems and lack of relevant knowledge, especially in deep complex reasoning and knowledge-intensive tasks. Knowledge Graphs (KGs), which capture vast amounts of facts in a structured format, offer a reliable source of knowledge for reasoning. However, existing KG-based LLM reasoning methods face challenges like handling multi-hop reasoning, multi-entity questions, and effectively utilizing graph structures. To address these issues, we propose Paths-over-Graph (PoG), a novel method that enhances LLM reasoning by integrating knowledge reasoning paths from KGs, improving the interpretability and faithfulness of LLM outputs. PoG tackles multi-hop and multi-entity questions through a three-phase dynamic multi-hop path exploration, which combines the inherent knowledge of LLMs with factual knowledge from KGs. In order to improve the efficiency, PoG prunes irrelevant information from the graph exploration first and introduces efficient three-step pruning techniques that incorporate graph structures, LLM prompting, and a pre-trained language model (e.g., SBERT) to effectively narrow down the explored candidate paths. This ensures all reasoning paths contain highly relevant information captured from KGs, making the reasoning faithful and interpretable in problem-solving. PoG innovatively utilizes graph structure to prune the irrelevant noise and represents the first method to implement multi-entity deep path detection on KGs for LLM reasoning tasks. Comprehensive experiments on five benchmark KGQA datasets demonstrate PoG outperforms the state-of-the-art method ToG across GPT-3.5-Turbo and GPT-4, achieving an average accuracy improvement of 18.9\%. Notably, PoG with GPT-3.5-Turbo surpasses ToG with GPT-4 by up to 23.9\%.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Tan, Xingyu and Wang, Xiaoyang and Liu, Qing and Xu, Xiwei and Yuan, Xin and Zhang, Wenjie},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {knowledge graph, knowledge graph question answering, large language models, retrieval-augmented generation},
	pages = {3505--3522},
}

@inproceedings{he_designminds_2025,
	address = {New York, NY, USA},
	series = {{CUI} '25},
	title = {{DesignMinds}: {Enhancing} {Video}-{Based} {Design} {Ideation} with a {Vision}-{Language} {Model} and a {Context}-{Injected} {Large} {Language} {Model}},
	isbn = {979-8-4007-1527-3},
	url = {https://doi.org/10.1145/3719160.3736633},
	doi = {10.1145/3719160.3736633},
	abstract = {Ideation is a critical component of video-based design (VBD), where videos serve as the primary medium for design exploration and inspiration. The emergence of generative AI offers considerable potential to enhance this process by streamlining video analysis and facilitating idea generation. In this paper, we present DesignMinds, a prototype that integrates a state-of-the-art Vision-Language Model (VLM) with a context-enhanced Large Language Model (LLM) to support ideation in VBD. To evaluate DesignMinds, we conducted a between-subject study with 35 design practitioners, comparing its performance to a baseline condition. Our results demonstrate that DesignMinds significantly enhances the flexibility and originality of ideation, while also increasing task engagement. Importantly, the introduction of this technology did not negatively impact user experience, technology acceptance, or usability.},
	booktitle = {Proceedings of the 7th {ACM} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {He, Tianhao and Stanković, Andrija and Niforatos, Evangelos and Kortuem, Gerd},
	year = {2025},
	keywords = {Design Ideation, Designer-AI Collaboration, Eye-tracking, Generative AI, Large Language Model, Video-based Design, Vision Language Model},
}

@inproceedings{wei_large_2025,
	address = {New York, NY, USA},
	series = {{ANRW} '25},
	title = {Large {Language} {Model} {Driven} {Automated} {Network} {Protocol} {Testing}},
	isbn = {979-8-4007-2009-3},
	url = {https://doi.org/10.1145/3744200.3744763},
	doi = {10.1145/3744200.3744763},
	abstract = {Traditional network protocol testing methods face significant challenges in adapting to rapid protocol evolution. The challenges stem primarily from protocol specification analysis and customized code development for testing. To address this, we propose NeTestLLM, a Large Language Model (LLM)-powered framework that automates protocol testing through two key components: (1) a hybrid test case generator that extracts protocol specifications and produces high-coverage test cases, and (2) a retrieval-feedback-enhanced engine that translates natural language descriptions into executable code. Preliminary evaluations demonstrate that NeTestLLM achieves 94.1\% coverage on protocol specification understanding. A case study with commercial network equipment validates the practical effectiveness of our approach. Our work presents the first LLM-powered framework for automated network protocol testing to keep pace with the rapid evolution of network protocols and standards.},
	booktitle = {Proceedings of the 2025 {Applied} {Networking} {Research} {Workshop}},
	publisher = {Association for Computing Machinery},
	author = {Wei, Yunze and Chi, Kaiwen and Du, Shibo and Xie, Xiaohui and Geng, Ziyu and Han, Yuwei and Li, Zhen and Li, Zhanyou and Cui, Yong},
	year = {2025},
	note = {event-place: Madrid, Spain},
	pages = {32--38},
}

@inproceedings{yang_retrieval-augmented_2024,
	address = {New York, NY, USA},
	series = {{IoTAAI} '23},
	title = {Retrieval-{Augmented} {Generation} with {Quantized} {Large} {Language} {Models}: {A} {Comparative} {Analysis}},
	isbn = {979-8-4007-1648-5},
	url = {https://doi.org/10.1145/3653081.3653102},
	doi = {10.1145/3653081.3653102},
	abstract = {Large language models have demonstrated emergent intelligence and ability to handle a wide array of tasks. However, the reliability of these models in terms of factual accuracy and timely knowledge acquisition remains a challenge. Researchers explore the implementation of retrieval-augmented generation methods, aiming to enhance the authenticity and specificity in knowledge-intensive tasks. This paper discusses the practical application in industrial settings, particularly in assisting design personnel with navigating complex standards and quality manuals. Utilizing an open-source model with 6 billion parameters, the study employs quantization technology for local deployment, addressing computational challenges. The retrieval-augmented generation framework is analyzed, emphasizing the integration of document parsing, vector databases, and text embedding models. Experimental results compare models at different quantization levels, revealing trade-offs between response time, model size, and performance metrics. The findings suggest that 4-bit integer quantization is optimal for standard document retrieval and question-answering tasks, highlighting practical considerations for CPU inference. The paper concludes with insights into hyper-parameter tuning, model comparisons, and future optimizations for enhanced performance in edge device deployments of large language models.},
	booktitle = {Proceedings of the 2023 5th {International} {Conference} on {Internet} of {Things}, {Automation} and {Artificial} {Intelligence}},
	publisher = {Association for Computing Machinery},
	author = {Yang, Shanglin and Zhu, Jialin and Wang, Jialin and Xu, Xiaohan and Shao, Zihang and Yao, Liwei and Zheng, Benchang and Huang, Hu},
	year = {2024},
	note = {event-place: Nanchang, China},
	pages = {120--124},
}

@inproceedings{li_g-refer_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {G-{Refer}: {Graph} {Retrieval}-{Augmented} {Large} {Language} {Model} for {Explainable} {Recommendation}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714727},
	doi = {10.1145/3696410.3714727},
	abstract = {Explainable recommendation has demonstrated significant advantages in informing users about the logic behind recommendations, thereby increasing system transparency, effectiveness, and trustworthiness. To provide personalized and interpretable explanations, existing works often combine the generation capabilities of large language models (LLMs) with collaborative filtering (CF) information. CF information extracted from the user-item interaction graph captures the user behaviors and preferences, which is crucial for providing informative explanations. However, due to the complexity of graph structure, effectively extracting the CF information from graphs still remains a challenge. Moreover, existing methods often struggle with the integration of extracted CF information with LLMs due to its implicit representation and the modality gap between graph structures and natural language explanations. To address these challenges, we propose G-Refer, a framework using Graph Retrieval-augmented large language models (LLMs) for explainable recommendation. Specifically, we first employ a hybrid graph retrieval mechanism to retrieve explicit CF signals from both structural and semantic perspectives. The retrieved CF information is explicitly formulated as human-understandable text by the proposed graph translation and accounts for the explanations generated by LLMs. To bridge the modality gap, we introduce knowledge pruning and retrieval-augmented fine-tuning to enhance the ability of LLMs to process and utilize the retrieved CF information to generate explanations. Extensive experiments show that G-Refer achieves superior performance compared with existing methods in both explainability and stability. Codes and data are available at https://github.com/Yuhan1i/G-Refer.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Li, Yuhan and Zhang, Xinni and Luo, Linhao and Chang, Heng and Ren, Yuxiang and King, Irwin and Li, Jia},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {explainable recommendation, graphrag, large language model},
	pages = {240--251},
}

@inproceedings{yang_addrllm_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{AddrLLM}: {Address} {Rewriting} via {Large} {Language} {Model} on {Nationwide} {Logistics} {Data}},
	isbn = {979-8-4007-1245-6},
	url = {https://doi.org/10.1145/3690624.3709425},
	doi = {10.1145/3690624.3709425},
	abstract = {Textual description of a physical location, commonly known as an address, plays an important role in location-based services(LBS) such as on-demand delivery and navigation. However, the prevalence of abnormal addresses, those containing inaccuracies that fail to pinpoint a location, have led to significant costs. Address rewriting has emerged as a solution to rectify these abnormal addresses. Despite the critical need, existing address rewriting methods are limited, typically tailored to correct specific error types, or frequently require retraining to process new address data effectively. In this study, we introduce AddrLLM, an innovative framework for address rewriting that is built upon a retrieval augmented large language model. AddrLLM overcomes aforementioned limitations through a meticulously designed Supervised Fine-Tuning module, an Address-centric Retrieval Augmented Generation module and a Bias-free Objective Alignment module. To the best of our knowledge, this study pioneers the application of LLM-based address rewriting approach to solve the issue of abnormal addresses. Through comprehensive offline testing with real-world data on a national scale and subsequent online deployment, AddrLLM has demonstrated superior performance in integration with existing logistics system. It has significantly decreased the rate of parcel re-routing by approximately 43\%, underscoring its exceptional efficacy in real-world applications.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.1},
	publisher = {Association for Computing Machinery},
	author = {Yang, Qinchen and Hong, Zhiqing and Cao, Dongjiang and Wang, Haotian and Xie, Zejun and He, Tian and Liu, Yunhuai and Yang, Yu and Zhang, Desheng},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {address rewriting, large language models, query reformulation},
	pages = {2756--2767},
}

@inproceedings{sarmah_hybridrag_2024,
	address = {New York, NY, USA},
	series = {{ICAIF} '24},
	title = {{HybridRAG}: {Integrating} {Knowledge} {Graphs} and {Vector} {Retrieval} {Augmented} {Generation} for {Efficient} {Information} {Extraction}},
	isbn = {979-8-4007-1081-0},
	url = {https://doi.org/10.1145/3677052.3698671},
	doi = {10.1145/3677052.3698671},
	abstract = {Extraction and interpretation of intricate information from unstructured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Retrieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents. We introduce a novel approach based on a combination, called HybridRAG, of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q\&amp;A) systems for information extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers. Using experiments on a set of financial earning call transcripts documents which come in the form of Q\&amp;A format, and hence provide a natural set of pairs of ground-truth Q\&amp;As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG individually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation. The proposed technique has applications beyond the financial domain.},
	booktitle = {Proceedings of the 5th {ACM} {International} {Conference} on {AI} in {Finance}},
	publisher = {Association for Computing Machinery},
	author = {Sarmah, Bhaskarjit and Mehta, Dhagash and Hall, Benika and Rao, Rohan and Patel, Sunil and Pasquali, Stefano},
	year = {2024},
	note = {event-place: Brooklyn, NY, USA},
	pages = {608--616},
}

@inproceedings{chen_i-card_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {I-{Card}: {A} {Generative} {AI}-{Supported} {Intelligent} {Design} {Method} {Card} {Deck}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713934},
	doi = {10.1145/3706598.3713934},
	abstract = {A design method card deck helps designers understand and provoke thinking by presenting each method in a simple format and allow designers to switch between methods seamlessly by maintaining the same simple format across the deck. However, recent observations have shown designers hesitate to use a card deck due to the lack of support, while other tools have provided identified support with generative AI. Through a formative study, we identified the specific support designers need when applying the design method cards and intentions in integrating generative AI. Accordingly, we developed the intelligent design method card deck, I-Card, which integrates generative AI to provide applicable design methods, design knowledge and data support, and interactive and dynamic support. A user study demonstrates that I-Card improved the design efficiency and applicability by offering personalized guidance, enhanced decision-making with comprehensive data generation and provided more design inspiration via interactive support.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Liuqing and Cheang, Wengteng and Jiang, Zhaojun and Xu, Yuan and Cai, Zebin and Sun, Lingyun and Childs, Peter and Han, Ji and Hansen, Preben and Zuo, Haoyu},
	year = {2025},
	keywords = {design cards, Design method, design method cards, design support tool, generative AI},
}

@inproceedings{liu_aggregated_2025,
	address = {New York, NY, USA},
	series = {{AIMLSystems} '24},
	title = {Aggregated {Knowledge} {Model}: {Enhancing} {Domain}-{Specific} {QA} with {Fine}-{Tuned} and {Retrieval}-{Augmented} {Generation} {Models}},
	isbn = {979-8-4007-1161-9},
	url = {https://doi.org/10.1145/3703412.3703434},
	doi = {10.1145/3703412.3703434},
	abstract = {This paper introduces a novel approach to enhancing closed-domain Question Answering (QA) systems, focusing on the specific needs of the Lawrence Berkeley National Laboratory (LBL) Science Information Technology (ScienceIT) domain. Utilizing a rich dataset derived from the ScienceIT documentation, our study embarks on a detailed comparison of two fine-tuned large language models and five retrieval-augmented generation (RAG) models. Through data processing techniques, we transform the documentation into structured context-question-answer triples, leveraging the latest Large Language Models (AWS Bedrock, GCP PaLM2, Meta LLaMA2, OpenAI GPT-4, Google Gemini-Pro) for data-driven insights. Additionally, we introduce the Aggregated Knowledge Model (AKM), which synthesizes responses from the seven models mentioned above using K-means clustering to select the most representative answers. The evaluation of these models across multiple metrics offers a comprehensive look into their effectiveness and suitability for the LBL ScienceIT environment. The results demonstrate the potential benefits of integrating fine-tuning and retrieval-augmented strategies, highlighting significant performance improvements achieved with the AKM. The insights gained from this study can be applied to develop specialized QA systems tailored to specific domains.},
	booktitle = {Proceedings of the 4th {International} {Conference} on {AI}-{ML} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Fengchen and Jung, Jordan and Feinstein, Wei and D'Ambrogia, Jeff and Jung, Gary},
	year = {2025},
	keywords = {AWS Bedrock, Closed-Domain Question Answering, Domain-Specific Information Retrieval, Fine-tuning Language Models, GCP PaLM, Google Gemini-Pro, High Performance Computing, Large Language Models, Meta LLaMA, OpenAI GPT, Retrieval-Augmented Generation},
}

@inproceedings{ordoumpozanis_generative_2025,
	address = {New York, NY, USA},
	series = {{CHIGreece} '25},
	title = {Generative {AI}: {A} {Systematic} {Review} of {Related} {Interfaces} and {Interactions}},
	isbn = {979-8-4007-1561-7},
	url = {https://doi.org/10.1145/3749012.3749052},
	doi = {10.1145/3749012.3749052},
	abstract = {As artificial intelligence becomes an everyday presence across education, arts and creative technologies, and cultural heritage, the interaction between users and intelligent systems deserves critical examination. This submission presents a systematic review of 95 case studies, 64 in education, 14 in arts, and 17 in heritage — selected via a PRISMA-guided search and expert screening — to map how generative artificial intelligence is embedded at both the interface and interaction levels. We identify nine interface archetypes (e.g., conversational, adaptive dashboards, immersive environments interfaces), eight interaction patterns (e.g., conversing, collaborating, manipulating),and eight main user experience dimensions as observed in case studies. Our analysis further categorizes six modality-usage patterns—from text, image, audio, and video up to fully multi-modal workflows and distillsfour main categories of end-to-end application pipelines. Notably, only two studies were found to articulate design-phase guidelines, and limitations cluster around output quality, ethical risks, and a lack of longitudinal evaluations. We conclude with limitations observed and future research focused on explainability, participatory design, and sustained field deployments. This synthesis provides a foundation for researchers and practitioners seeking to harness generative artificial intelligence as a responsive, human-centered collaborator.},
	booktitle = {Proceedings of the 3rd {International} {Conference} of the {ACM} {Greek} {SIGCHI} {Chapter}},
	publisher = {Association for Computing Machinery},
	author = {Ordoumpozanis, Kostas and Konstantakis, Markos and Zoi, Stavroula and Caridakis, George},
	year = {2025},
	keywords = {AI, Artificial Intelligence, Gen AI, Generative AI, UI, User Experience, User Interaction, User Interface, UX},
	pages = {39--47},
}

@inproceedings{cao_ecc_2024,
	address = {New York, NY, USA},
	series = {{ICAIF} '24},
	title = {{ECC} {Analyzer}: {Extracting} {Trading} {Signal} from {Earnings} {Conference} {Calls} using {Large} {Language} {Model} for {Stock} {Volatility} {Prediction}},
	isbn = {979-8-4007-1081-0},
	url = {https://doi.org/10.1145/3677052.3698689},
	doi = {10.1145/3677052.3698689},
	abstract = {In the realm of financial analytics, leveraging unstructured data, such as earnings conference calls (ECCs), to forecast stock volatility is a critical challenge that has attracted both academics and investors. While previous studies have used multimodal deep learning-based models to obtain a general view of ECCs for volatility predicting, they often fail to capture detailed, complex information. Our research introduces a novel framework: ECC Analyzer, which utilizes large language models (LLMs) to extract richer, more predictive content from ECCs to aid the model’s prediction performance. We use the pre-trained large models to extract textual and audio features from ECCs and implement a hierarchical information extraction strategy to extract more fine-grained information. This strategy first extracts paragraph-level general information by summarizing the text and then extracts fine-grained focus sentences using Retrieval-Augmented Generation (RAG). These features are then fused through multimodal feature fusion to perform volatility prediction. Experimental results demonstrate that our model outperforms traditional analytical benchmarks, confirming the effectiveness of advanced LLM techniques in financial analysis.},
	booktitle = {Proceedings of the 5th {ACM} {International} {Conference} on {AI} in {Finance}},
	publisher = {Association for Computing Machinery},
	author = {Cao, Yupeng and Chen, Zhi and Pei, Qingyun and Lee, Nathan and Subbalakshmi, K. P. and Ndiaye, Papa Momar},
	year = {2024},
	note = {event-place: Brooklyn, NY, USA},
	keywords = {Earnings Conference Call Analysis, Large Language Model, Retrieval-Augmented Generation, Volatility forecasting},
	pages = {257--265},
}

@inproceedings{hellas_experiences_2024,
	address = {New York, NY, USA},
	series = {{SIGCSE} {Virtual} 2024},
	title = {Experiences from {Integrating} {Large} {Language} {Model} {Chatbots} into the {Classroom}},
	isbn = {979-8-4007-0598-4},
	url = {https://doi.org/10.1145/3649165.3690101},
	doi = {10.1145/3649165.3690101},
	abstract = {We provided students access to a state-of-the-art large language model (LLM) chatbot through the online materials of three university-level courses. One of the courses focused on software engineering with LLMs, while the two other courses were not directly related to LLMs. The chatbot used OpenAI GPT-4 without additional filters or system prompts. Our results suggest that only a minority of students engage with the chatbot in the courses that do not relate to LLMs. At the same time, unsurprisingly, nearly all students in the LLM-focused course leveraged the chatbot. In all courses, the majority of the chatbot usage came from a few superusers, whereas the majority of the students did not heavily use the chatbot even though it effectively provided free access to OpenAI's GPT-4 model (which would have otherwise required a paid subscription at the time of the study). We observe that in addition to students using the chatbot for course-specific purposes, many use the chatbot for their own purposes. Overall, our results suggest that the worst fears of educators – all students overrelying on chatbots – did not materialize. Finally, we discuss potential reasons for low usage, including the need for more tailored and scaffolded chatbot experiences targeted for specific types of use cases.},
	booktitle = {Proceedings of the 2024 on {ACM} {Virtual} {Global} {Computing} {Education} {Conference} {V}. 1},
	publisher = {Association for Computing Machinery},
	author = {Hellas, Arto and Leinonen, Juho and Leppänen, Leo},
	year = {2024},
	note = {event-place: Virtual Event, NC, USA},
	keywords = {chatbots, classroom experiences, experience report, generative ai, large language models, usage analysis},
	pages = {46--52},
}

@inproceedings{wang_colacare_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{ColaCare}: {Enhancing} {Electronic} {Health} {Record} {Modeling} through {Large} {Language} {Model}-{Driven} {Multi}-{Agent} {Collaboration}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714877},
	doi = {10.1145/3696410.3714877},
	abstract = {We introduce ColaCare, a framework that enhances Electronic Health Record (EHR) modeling through multi-agent collaboration driven by Large Language Models (LLMs). Our approach seamlessly integrates domain-specific expert models with LLMs to bridge the gap between structured EHR data and text-based reasoning. Inspired by the Multidisciplinary Team (MDT) approach used in clinical settings, ColaCare employs two types of agents: DoctorAgents and a MetaAgent, which collaboratively analyze patient data. Expert models process and generate predictions from numerical EHR data, while LLM agents produce reasoning references and decision-making reports within the MDT-driven collaborative consultation framework. The MetaAgent orchestrates the discussion, facilitating consultations and evidence-based debates among DoctorAgents, simulating diverse expertise in clinical decision-making. We additionally incorporate the Merck Manual of Diagnosis and Therapy (MSD) medical guideline within a retrieval-augmented generation (RAG) module for medical evidence support, addressing the challenge of knowledge currency. Extensive experiments conducted on three EHR datasets demonstrate ColaCare's superior performance in clinical mortality outcome and readmission prediction tasks, underscoring its potential to revolutionize clinical decision support systems and advance personalized precision medicine. All code, case studies and a questionnaire are available at the project website: https://colacare.netlify.app.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Wang, Zixiang and Zhu, Yinghao and Zhao, Huiya and Zheng, Xiaochen and Sui, Dehao and Wang, Tianlong and Tang, Wen and Wang, Yasha and Harrison, Ewen and Pan, Chengwei and Gao, Junyi and Ma, Liantao},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {electronic health record, large language model, multi-agent},
	pages = {2250--2261},
}

@inproceedings{qin_robust_2025,
	address = {New York, NY, USA},
	series = {{ICCAD} '24},
	title = {Robust {Implementation} of {Retrieval}-{Augmented} {Generation} on {Edge}-based {Computing}-in-{Memory} {Architectures}},
	isbn = {979-8-4007-1077-3},
	url = {https://doi.org/10.1145/3676536.3676674},
	doi = {10.1145/3676536.3676674},
	abstract = {Large Language Models (LLMs) deployed on edge devices learn through fine-tuning and updating a certain portion of their parameters. Although such learning methods can be optimized to reduce resource utilization, the overall required resources remain a heavy burden on edge devices. Instead, Retrieval-Augmented Generation (RAG), a resource-efficient LLM learning method, can improve the quality of the LLM-generated content without updating model parameters. However, the RAG-based LLM may involve repetitive searches on the profile data in every user-LLM interaction. This search can lead to significant latency along with the accumulation of user data. Conventional efforts to decrease latency result in restricting the size of saved user data, thus reducing the scalability of RAG as user data continuously grows. It remains an open question: how to free RAG from the constraints of latency and scalability on edge devices? In this paper, we propose a novel framework to accelerate RAG via Computing-in-Memory (CiM) architectures. It accelerates matrix multiplications by performing in-situ computation inside the memory while avoiding the expensive data transfer between the computing unit and memory. Our framework, Robust CiM-backed RAG (RoCR), utilizing a novel contrastive learning-based training method and noise-aware training, can enable RAG to efficiently search profile data with CiM. To the best of our knowledge, this is the first work utilizing CiM to accelerate RAG.},
	booktitle = {Proceedings of the 43rd {IEEE}/{ACM} {International} {Conference} on {Computer}-{Aided} {Design}},
	publisher = {Association for Computing Machinery},
	author = {Qin, Ruiyang and Yan, Zheyu and Zeng, Dewen and Jia, Zhenge and Liu, Dancheng and Liu, Jianbo and Abbasi, Ahmed and Zheng, Zhi and Cao, Ningyuan and Ni, Kai and Xiong, Jinjun and Shi, Yiyu},
	year = {2025},
	note = {event-place: Newark Liberty International Airport Marriott, New York, NY, USA},
}

@inproceedings{saketos_large_2024,
	address = {New York, NY, USA},
	series = {{SETN} '24},
	title = {The {Large} {Language} {Model} {GreekLegalRoBERTa}},
	isbn = {979-8-4007-0982-1},
	url = {https://doi.org/10.1145/3688671.3688770},
	doi = {10.1145/3688671.3688770},
	abstract = {We develop four versions of GreekLegalRoBERTa, which are four large language models trained on Greek legal and nonlegal text. We show that our models surpass the performance of GreekLegalBERT, Greek- LegalBERT-v2, and GreekBERT in two tasks involving Greek legal documents: named entity recognition and multi-class legal topic classification. We view our work as a contribution to the study of domain-specific NLP tasks in low-resource languages, like Greek, using modern NLP techniques and methodologies.},
	booktitle = {Proceedings of the 13th {Hellenic} {Conference} on {Artificial} {Intelligence}},
	publisher = {Association for Computing Machinery},
	author = {Saketos, Vasileios and Pantazi, Despina-Athanasia and Koubarakis, Manolis},
	year = {2024},
	keywords = {Classification, Greek Legislation, Greek NLP Resources, Named Entity Recognition, Natural Language Processing, Pre-trained Language Models},
}

@inproceedings{yu_stateful_2025,
	address = {New York, NY, USA},
	series = {{EuroSys} '25},
	title = {Stateful {Large} {Language} {Model} {Serving} with {Pensieve}},
	isbn = {979-8-4007-1196-1},
	url = {https://doi.org/10.1145/3689031.3696086},
	doi = {10.1145/3689031.3696086},
	abstract = {Large Language Models (LLMs) are wildly popular today and it is important to serve them efficiently. Existing LLM serving systems are stateless across requests. Consequently, when LLMs are used in the common setting of multi-turn conversations, a growing log of the conversation history must be processed alongside any request by the serving system at each turn, resulting in repeated processing.In this paper, we design Pensieve, a system optimized for multi-turn conversation LLM serving. Pensieve maintains the conversation state across requests by caching previously processed history to avoid duplicate processing. Pensieve's multi-tier caching strategy can utilize both GPU and CPU memory to efficiently store and retrieve cached data. Pensieve also generalizes the recent PagedAttention kernel to support attention between multiple input tokens with a GPU cache spread over non-contiguous memory. Our evaluation shows that Pensieve can achieve 1.14-3.0× the throughput of vLLM and TensorRT-LLM and significantly reduce latency.},
	booktitle = {Proceedings of the {Twentieth} {European} {Conference} on {Computer} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Yu, Lingfan and Lin, Jinkun and Li, Jinyang},
	year = {2025},
	note = {event-place: Rotterdam, Netherlands},
	keywords = {Cache, LLM Serving, Multi-turn Conversations},
	pages = {144--158},
}

@inproceedings{xu_automating_2024,
	address = {New York, NY, USA},
	series = {{UrbanAI} '24},
	title = {Automating {Bibliometric} {Analysis} with {Sentence} {Transformers} and {Retrieval}-{Augmented} {Generation} ({RAG}): {A} {Pilot} {Study} in {Semantic} and {Contextual} {Search} for {Customized} {Literature} {Characterization} for {High}-{Impact} {Urban} {Research}},
	isbn = {979-8-4007-1156-5},
	url = {https://doi.org/10.1145/3681780.3697252},
	doi = {10.1145/3681780.3697252},
	abstract = {Bibliometric analysis is essential for understanding research trends, scope, and impact in urban science, especially in high-impact journals, such Nature Portfolios. However, traditional methods, relying on keyword searches and basic NLP techniques, often fail to uncover valuable insights not explicitly stated in article titles or keywords. These approaches are unable to perform semantic searches and contextual understanding, limiting their effectiveness in classifying topics and characterizing studies. In this paper, we address these limitations by leveraging Generative AI models, specifically transformers and Retrieval-Augmented Generation (RAG), to automate and enhance bibliometric analysis. We developed a technical workflow that integrates a vector database, Sentence Transformers, a Gaussian Mixture Model (GMM), Retrieval Agent, and Large Language Models (LLMs) to enable contextual search, topic ranking, and characterization of research using customized prompt templates. A pilot study analyzing 223 urban science-related articles published in Nature Communications over the past decade highlights the effectiveness of our approach in generating insightful summary statistics on the quality, scope, and characteristics of papers in high-impact journals. This study introduces a new paradigm for enhancing bibliometric analysis and knowledge retrieval in urban research, positioning an AI agent as a powerful tool for advancing research evaluation and understanding.},
	booktitle = {Proceedings of the 2nd {ACM} {SIGSPATIAL} {International} {Workshop} on {Advances} in {Urban}-{AI}},
	publisher = {Association for Computing Machinery},
	author = {Xu, Haowen and Li, Xueping and Tupayachi, Jose and Lian, Jianming Jamie and Omitaomu, Olufemi A.},
	year = {2024},
	note = {event-place: Atlanta, GA, USA},
	keywords = {Bibliometrics Analysis, Large Language Models, Retrieval-Augmented Generation, Transformers},
	pages = {43--49},
}

@inproceedings{kocyigit_deceptilens_2025,
	address = {New York, NY, USA},
	series = {{FAccT} '25},
	title = {{DeceptiLens}: an {Approach} supporting {Transparency} in {Deceptive} {Pattern} {Detection} based on a {Multimodal} {Large} {Language} {Model}},
	isbn = {979-8-4007-1482-5},
	url = {https://doi.org/10.1145/3715275.3732129},
	doi = {10.1145/3715275.3732129},
	abstract = {To detect deceptive design patterns on UIs, traditional artificial intelligence models, such as machine learning, have limited coverage and a lack of multimodality. In contrast, the capabilities of Multimodal Large Language Model (MM-LLM) can achieve wider coverage with superior performance in the detection, while providing reasoning behind each decision. We propose and implement an MM-LLM-based approach (DeceptiLens) that analyzes UIs and assesses the presence of deceptive design patterns. We utilize Retrieval Augmented Generation (RAG) process in our design and task the model with capturing the deceptive patterns, classifying its category, e.g., false hierarchy, confirmshaming, etc., and explaining the reasoning behind the classifications by employing recent prompt engineering techniques, such as Chain-of-Thought (CoT). We first create a dataset by collecting UI screenshots from the literature and web sources and quantify the agreement between the model’s outputs and a few experts’ opinions. We additionally ask experts to gauge the transparency of the system’s explanations for its classifications in terms of recognized metrics of clarity, correctness, completeness, and verifiability. The results indicate that our approach is capable of capturing the deceptive patterns in UIs with high accuracy while providing clear, correct, complete, and verifiable justifications for its decisions. We additionally release two curated datasets, one with expert-labeled UIs with deceptive design patterns, and one with AI-based generated explanations. Lastly, we propose recommendations for future improvement of the approach in various contexts of use.},
	booktitle = {Proceedings of the 2025 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Kocyigit, Emre and Rossi, Arianna and Sergeeva, Anastasia and Negri Ribalta, Claudia and Farjami, Ali and Lenzini, Gabriele},
	year = {2025},
	keywords = {dark patterns, deceptive design patterns, LLMs, multimodal LLMs},
	pages = {1942--1959},
}

@inproceedings{hou_applied_2025,
	address = {New York, NY, USA},
	series = {{ISCCN} '25},
	title = {Applied {Research} on an {Aircraft} {Maintenance} {Assistant} {Based} on a {Large} {Language} {Model}},
	isbn = {979-8-4007-1520-4},
	url = {https://doi.org/10.1145/3732945.3732946},
	doi = {10.1145/3732945.3732946},
	abstract = {In recent years, significant progress has been made in the application of LLMs in various specialized fields. However, in the field of aircraft maintenance, intelligent systems face significant challenges due to the high complexity and private data involved. This paper describes the Zhihang Aircraft Maintenance Assistant, an LLM-based intelligent system designed to assist in aircraft maintenance tasks. The system integrates domain-specific knowledge on various aspects of aircraft maintenance and builds a vectorized knowledge base through advanced semantic understanding. Using RAG (Retrieval Augmented Generation) technology, it extracts relevant knowledge from the database based on user input and generates accurate responses to assist maintenance personnel with tasks such as fault diagnosis and troubleshooting. By using a specialized maintenance knowledge base, the system solves the problem of hallucination and ensures greater reliability in generating responses. Zhihang Assistant also provides one-click generation of maintenance record orders and concise summaries of policies and regulations. These features improve compliance with standard operating procedures, streamline workflow efficiency and minimize errors caused by inaccurate information retrieval. Test results show that Zhihang Assistant's average scores for answer relevance, content fidelity and contextual relevance were 0.973, 0.807 and 0.917 respectively, demonstrating its ability to provide highly accurate, relevant and contextually appropriate answers based on real-world maintenance needs.},
	booktitle = {Proceedings of the 2025 4th {International} {Conference} on {Intelligent} {Systems}, {Communications} and {Computer} {Networks}},
	publisher = {Association for Computing Machinery},
	author = {Hou, Lei and Jia, Beixi and Xing, Chenguang and Chen, Zhaojiang and Du, Ziliang},
	year = {2025},
	keywords = {Aviation Maintenance Automation, Knowledge Base Question Answering System, Large Language Models, Retrieval-Augmented Generation},
	pages = {1--7},
}

@inproceedings{martinez_enhancing_2025,
	address = {Orlando, Florida, USA},
	series = {{WSC} '24},
	title = {Enhancing {GPT}-3.5's {Proficiency} in {Netlogo} through {Few}-{Shot} {Prompting} and {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-3315-3420-2},
	abstract = {Recognizing the limited research on Large Language Models (LLMs) capabilities with low-resource languages, this study evaluates and increases the proficiency of the LLM GPT-3.5 in generating interface and procedural code elements for NetLogo, a multi-agent programming language and modeling environment. To achieve this, we employed "few-shot" prompting and Retrieval-Augmented Generation (RAG) methodologies using two manually created datasets, NetLogoEvalCode and NetLogoEvalInterface. The results demonstrate that GPT-3.5 can generate NetLogo elements and code procedures more effectively when provided with additional examples to learn from, highlighting the potential of LLMs in aiding the development of agent-based models (ABMs). On the other hand, the RAG model obtained a poor performance. We listed possible reasons for this result, which were aligned with RAG's common challenges identified by the state-of-the-art. We propose future research directions for leveraging LLMs for simulation development and instructional purposes in the context of ABMs.},
	booktitle = {Proceedings of the {Winter} {Simulation} {Conference}},
	publisher = {IEEE Press},
	author = {Martínez, Joseph and Llinas, Brian and Botello, Jhon G. and Padilla, Jose J. and Frydenlund, Erika},
	year = {2025},
	pages = {666--677},
}

@inproceedings{michelon_large_2025,
	address = {New York, NY, USA},
	series = {E-{Energy} '25},
	title = {Large {Language} {Model} {Interface} for {Home} {Energy} {Management} {Systems}},
	isbn = {979-8-4007-1125-1},
	url = {https://doi.org/10.1145/3679240.3734586},
	doi = {10.1145/3679240.3734586},
	abstract = {Home Energy Management Systems (HEMSs) help households tailor their electricity usage based on power system signals such as energy prices. This technology helps to reduce energy bills and offers greater demand-side flexibility that supports the power system stability. However, residents who lack a technical background may find it difficult to use HEMSs effectively, because HEMSs require well-formatted parameterization that reflects the characteristics of the energy resources, houses, and users’ needs. Recently, Large-Language Models (LLMs) have demonstrated an outstanding ability in language understanding. Motivated by this, we propose an LLM-based interface that interacts with users to understand and parameterize their “badly-formatted answers”, and then outputs well-formatted parameters to implement an HEMS. We further use Reason and Act method (ReAct) and few-shot prompting to enhance the LLM performance. Evaluating the interface performance requires multiple user–LLM interactions. To avoid the efforts in finding volunteer users and reduce the evaluation time, we additionally propose a method that uses another LLM to simulate users with varying expertise, ranging from knowledgeable to non-technical. By comprehensive evaluation, the proposed LLM-based HEMS interface achieves an average parameter retrieval accuracy of 88\%, outperforming benchmark models without ReAct and/or few-shot prompting.},
	booktitle = {Proceedings of the 16th {ACM} {International} {Conference} on {Future} and {Sustainable} {Energy} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Michelon, François and Zhou, Yihong and Morstyn, Thomas},
	year = {2025},
	keywords = {Demand-side Flexibility, Home Energy Management System, LLM, Parametrization, ReAct},
	pages = {590--602},
}

@inproceedings{liu_can_2024,
	address = {New York, NY, USA},
	series = {{ITiCSE} 2024},
	title = {Can {Small} {Language} {Models} {With} {Retrieval}-{Augmented} {Generation} {Replace} {Large} {Language} {Models} {When} {Learning} {Computer} {Science}?},
	isbn = {979-8-4007-0600-4},
	url = {https://doi.org/10.1145/3649217.3653554},
	doi = {10.1145/3649217.3653554},
	abstract = {Leveraging Large Language Models (LLMs) for personalized learning and support is becoming a promising tool in computing education. AI Assistants can help students with programming, problem-solving, converse with them to clarify course content, explain error messages to help with debugging, and much more. However, using cloud-based LLMs poses risks around data security, privacy, but also control of the overarching system.To address these concerns, we created a locally-stored Small Language Model (SLM) that leverages different Retrieval-Augmented Generation (RAG) methods to support computing students' learning. We compare one SLM (neural-chat-7b-v3 - fine-tuned version of Mistral-7B-v0.1) against two popular LLMs (gpt-3.5-turbo and gpt-4-32k) to see the viability for computing educators to use in their course(s).We use conversations from a CS1 course (N = 1,260), providing students with an AI Assistant (using gpt-3.5-turbo) to help them learn content and support problem-solving while completing their Python programming assignment. In total, we had 269 students use the AI Assistant, with a total of 1,988 questions asked. Using this real conversational data, we re-ran student questions using our novel SLM (neural-chat-7b-v3 testing nine different RAG methods) and gpt-4-32k, then compared those results against the original gpt-3.5-turbo responses. Our findings indicate that using an SLM with RAG can perform similarly, if not better, than LLMs. This shows that it is possible for computing educators to use SLMs (with RAG) in their course(s) as a tool for scalable learning, supporting content understanding and problem-solving needs, while employing their own policies on data privacy and security.},
	booktitle = {Proceedings of the 2024 on {Innovation} and {Technology} in {Computer} {Science} {Education} {V}. 1},
	publisher = {Association for Computing Machinery},
	author = {Liu, Suqing and Yu, Zezhu and Huang, Feiran and Bulbulia, Yousef and Bergen, Andreas and Liut, Michael},
	year = {2024},
	note = {event-place: Milan, Italy},
	keywords = {computing education, conversational agent, cs1, intelligence concentration, intelligent teaching assistant, intelligent tutoring system, large language models, locally deployable ai, personalized ai agent, retrieval augmented generation, small language models},
	pages = {388--393},
}

@inproceedings{xu_list-aware_2024,
	address = {New York, NY, USA},
	series = {{WWW} '24},
	title = {List-aware {Reranking}-{Truncation} {Joint} {Model} for {Search} and {Retrieval}-augmented {Generation}},
	isbn = {979-8-4007-0171-9},
	url = {https://doi.org/10.1145/3589334.3645336},
	doi = {10.1145/3589334.3645336},
	abstract = {The results of information retrieval (IR) are usually presented in the form of a ranking list of candidate documents, such as web search for humans and retrieval-augmented generation for large language models (LLMs). List-aware retrieval aims to capture the list-level contextual features to return a better list, mainly including reranking and truncation. Reranking finely re-scores the documents in the list. Truncation dynamically determines the cut-off point of the ranked list to achieve the trade-off between overall relevance and avoiding misinformation from irrelevant documents. Previous studies treat them as two separate tasks and model them separately. However, the separation is not optimal. First, it is hard to share the contextual information of the ranking list between the two tasks. Second, the separate pipeline usually meets the error accumulation problem, where the small error from the reranking stage can largely affect the truncation stage. To solve these problems, we propose a Reranking-Truncation joint model (GenRT) that can perform the two tasks concurrently. GenRT integrates reranking and truncation via a generative paradigm based on an encoder-decoder architecture with novel loss functions for joint optimization to learn both tasks. Sharing parameters by the joint model is conducive to making full use of the common modeling information of the two tasks. Besides, the two tasks are performed concurrently and co-optimized to solve the error accumulation problem between separate stages. Experiments on public learning-to-rank benchmarks and open-domain Q\&amp;A tasks show that our method achieves SOTA performance on both reranking and truncation tasks for web search and retrieval-augmented LLMs.},
	booktitle = {Proceedings of the {ACM} {Web} {Conference} 2024},
	publisher = {Association for Computing Machinery},
	author = {Xu, Shicheng and Pang, Liang and Xu, Jun and Shen, Huawei and Cheng, Xueqi},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	keywords = {reranking, retrieval-augmented LLMs, truncation},
	pages = {1330--1340},
}

@inproceedings{yu_ic-cache_2025,
	address = {New York, NY, USA},
	series = {{SOSP} '25},
	title = {{IC}-{Cache}: {Efficient} {Large} {Language} {Model} {Serving} via {In}-context {Caching}},
	isbn = {979-8-4007-1870-0},
	url = {https://doi.org/10.1145/3731569.3764829},
	doi = {10.1145/3731569.3764829},
	abstract = {Large language models (LLMs) have excelled in various applications, yet serving them at scale is challenging due to their substantial resource demands and high latency. Our real-world studies reveal that over 70\% of user requests to LLMs have semantically similar counterparts, suggesting the potential for knowledge transfer among requests. However, naively caching and reusing past responses leads to a big quality drop.In this paper, we introduce IC-Cache, a caching system that enables live LLM capability augmentation to improve serving efficiency: by leveraging historical request-response pairs from larger models as in-context examples, IC-Cache empowers small LLMs to imitate and even exceed the compositional abilities (e.g., reasoning) of their larger counterparts, enabling selective offloading of requests to reduce cost and latency. Achieving this live augmentation at scale introduces intricate trade-offs between response quality, latency, and system throughput. For a new request, IC-Cache efficiently selects similar, high-utility examples to prepend them to the new request's input. At scale, it adaptively routes requests across LLMs of varying capabilities, accounting for response quality and serving loads. IC-Cache employs a cost-aware cache replay mechanism that refines example quality offline to maximize online cache utility and efficiency. Evaluations on millions of realistic requests demonstrate that IC-Cache improves LLM serving throughput by 1.4–5.9x and reduces latency by 28–71\% without hurting response quality.},
	booktitle = {Proceedings of the {ACM} {SIGOPS} 31st {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {Association for Computing Machinery},
	author = {Yu, Yifan and Gan, Yu and Sarda, Nikhil and Tsai, Lillian and Shen, Jiaming and Zhou, Yanqi and Krishnamurthy, Arvind and Lai, Fan and Levy, Hank and Culler, David},
	year = {2025},
	note = {event-place: Lotte Hotel World, Seoul, Republic of Korea},
	keywords = {cloud computing, large language models (LLMs), LLM serving, load balancing, quality-efficiency tradeoff, request routing, semantic caching},
	pages = {375--398},
}

@inproceedings{wen_usb-rec_2025,
	address = {New York, NY, USA},
	series = {{RecSys} '25},
	title = {{USB}-{Rec}: {An} {Effective} {Framework} for {Improving} {Conversational} {Recommendation} {Capability} of {Large} {Language} {Model}},
	isbn = {979-8-4007-1364-4},
	url = {https://doi.org/10.1145/3705328.3748089},
	doi = {10.1145/3705328.3748089},
	abstract = {Recently, Large Language Models (LLMs) have been widely employed in Conversational Recommender Systems (CRSs). Unlike traditional language model approaches that focus on training, all existing LLMs-based approaches are mainly centered around how to leverage the summarization and analysis capabilities of LLMs while ignoring the issue of training. Therefore, in this work, we propose an integrated training-inference framework, User-Simulator-Based framework (USB-Rec), for improving the performance of LLMs in conversational recommendation at the model level. Firstly, we design a LLM-based Preference Optimization (PO) dataset construction strategy for RL training, which helps the LLMs understand the strategies and methods in conversational recommendation. Secondly, we propose a Self-Enhancement Strategy (SES) at the inference stage to further exploit the conversational recommendation potential obtained from RL training. Extensive experiments on various datasets demonstrate that our method consistently outperforms previous state-of-the-art methods. Codes are available at .},
	booktitle = {Proceedings of the {Nineteenth} {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wen, Jianyu and Wang, Jingyun and Yan, Cilin and Cai, Jiayin and Jiang, Xiaolong and Zhang, Ying},
	year = {2025},
	keywords = {Conversational Recommendation, Large Language Model, Reinforcement Learning},
	pages = {472--481},
}

@inproceedings{ashaduzzaman_leveraging_2025,
	address = {New York, NY, USA},
	series = {{UMAP} {Adjunct} '25},
	title = {Leveraging {Generative} {AI} to {Improve} {Comprehensibility} in {Social} {Recommender} {Systems}},
	isbn = {979-8-4007-1399-6},
	url = {https://doi.org/10.1145/3708319.3733696},
	doi = {10.1145/3708319.3733696},
	abstract = {Generative AI, particularly Large Language Models (LLMs), has revolutionized human-computer interaction by enabling the generation of nuanced, human-like text. This presents new opportunities, especially in enhancing explainability for AI systems like recommender systems, a crucial factor for fostering user trust and engagement. LLM-powered AI-Chatbots can be leveraged to provide personalized explanations for recommendations. Although users often find these chatbot explanations helpful, they may not fully comprehend the content. Our research focuses on assessing how well users comprehend these explanations and identifying gaps in understanding. We also explore the key behavioral differences between users who effectively understand AI-generated explanations and those who do not. We designed a three-phase user study with 17 participants to explore these dynamics. The findings indicate that the clarity and usefulness of the explanations are contingent on the user asking relevant follow-up questions and having a motivation to learn. Comprehension also varies significantly based on users’ educational backgrounds.},
	booktitle = {Adjunct {Proceedings} of the 33rd {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {Association for Computing Machinery},
	author = {Ashaduzzaman, Md and Tsai, Chun-Hua},
	year = {2025},
	keywords = {AI-Chatbots, Follow-up questions., Large Language Models, Personalized recommendation explanations, User comprehension},
	pages = {192--201},
}

@inproceedings{dou_design_2024,
	address = {New York, NY, USA},
	series = {{EKI} '24},
	title = {Design and {Application} of {Online} {Teaching} {Resource} {Platform} for {College} {English} {Based} on {Retrieval}-{Augmented} {Generation}},
	isbn = {979-8-4007-1023-0},
	url = {https://doi.org/10.1145/3691720.3691739},
	doi = {10.1145/3691720.3691739},
	abstract = {Aiming at the problems of inconvenient retrieval of teaching resources, untimely feedback, inaccurate questioning rate, and lack of learner privacy and security that exist in various online teaching resource platforms, it is proposed to construct a new college English teaching resource platform by utilizing the technology of Large Language Mode(LLM) and Retrieval-Augmented Generation(RAG). The platform builds a local large language model and a teaching resource repository for college English, which can intelligently identify learners' questions and queries, provide learners with real-time personalized interaction and accurate Q\&amp;A services, reduce teachers' workload in delivering resources and answering questions in real time, greatly improve the efficiency of using the resource repository, and create an intelligent resource environment for teaching quality improvement.},
	booktitle = {Proceedings of the 2nd {International} {Conference} on {Educational} {Knowledge} and {Informatization}},
	publisher = {Association for Computing Machinery},
	author = {Dou, Juhua and Zhao, Xuhua},
	year = {2024},
	note = {event-place: Shanghai, China},
	pages = {111--115},
}

@inproceedings{kim_pimba_2025,
	address = {New York, NY, USA},
	series = {{MICRO} '25},
	title = {Pimba: {A} {Processing}-in-{Memory} {Acceleration} for {Post}-{Transformer} {Large} {Language} {Model} {Serving}},
	isbn = {979-8-4007-1573-0},
	url = {https://doi.org/10.1145/3725843.3756121},
	doi = {10.1145/3725843.3756121},
	abstract = {Transformers are the driving force behind today’s Large Language Models (LLMs), serving as the foundation for their performance and versatility. Yet, their compute and memory costs grow with sequence length, posing scalability challenges for long-context inferencing. In response, the algorithm community is exploring alternative architectures—such as state space models (SSMs) (e.g., Mamba-2), linear attention, and recurrent neural networks (RNNs)—which we refer to as post-transformers. This shift presents a key challenge: building a serving system that efficiently supports not only emerging post-transformer LLMs but also existing transformer models within a unified framework. To address this challenge, we analyze the performance characteristics of transformer and post-transformer LLMs. Despite their algorithmic differences, both are largely bounded by memory bandwidth under batched inference—due to attention in transformers and state updates in post-transformers. Inspired by this finding, we propose Pimba, an accelerator solution that aims to address the memory bottleneck by jointly leveraging (1) Processing-in-Memory (PIM) paradigm and (2) LLM quantization. Further analyses suggest two additional insights: (1) state update operations, unlike attention, incur high hardware cost, making per-bank PIM acceleration inefficient, and (2) different low-precision arithmetic methods offer varying accuracy-area tradeoffs, while we identify Microsoft’s MX as a Pareto-optimal choice. Building on these insights, we design the architecture of Pimba as an array of State-update Processing Units (SPUs), each shared between two banks to enable interleaved access. Each SPU includes a State-update Processing Engine (SPE) that comprises element-wise multipliers and adders using MX-based quantized arithmetic, enabling efficient execution of state update and attention operations. Our evaluation shows that, compared to LLM-optimized GPU and GPU+PIM systems, Pimba achieves up to 4.1 × and 2.1 × higher generation throughput, respectively.},
	booktitle = {Proceedings of the 58th {IEEE}/{ACM} {International} {Symposium} on {Microarchitecture}},
	publisher = {Association for Computing Machinery},
	author = {Kim, Wonung and Lee, Yubin and Kim, Yoonsung and Hwang, Jinwoo and Oh, Seongryong and Jung, Jiyong and Huseynov, Aziz and Park, Woong Gyu and Park, Chang Hyun and Mahajan, Divya and Park, Jongse},
	year = {2025},
	keywords = {Heterogeneous system, Large Language Model (LLM), Linear Attention, Post-Transformer LLM, Processing-in-Memory (PIM), Recurrent Neural Network (RNN), State Space Model (SSM)},
	pages = {292--307},
}

@inproceedings{shah_-ta-da_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {From {To}-{Do} to {Ta}-{Da}: {Transforming} {Task}-{Focused} {IR} with {Generative} {AI}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730352},
	doi = {10.1145/3726302.3730352},
	abstract = {For decades, scholars have emphasized that tasks should be the central focus in Information Retrieval (IR). This point of view holds even more significance with the advent of Generative Artificial Intelligence (GenAI) models, which can, among other capabilities, understand natural language, engage in dialog with users, generate bespoke user interfaces, and power agents to help complete tasks. GenAI presents an unprecedented opportunity to finally realize the potential of tasks in IR, enhance task-focused retrieval and interaction, and create ”magical” task completion moments for users. In this paper, we explore the rationale and methodology behind this argument. Traditional IR systems support mostly simple tasks. The emergence of GenAI creates an opportunity for IR systems to help users achieve complex tasks and for the IR community to rekindle its interest and demonstrate leadership in this sizable and significant problem space. We underscore the pivotal role of tasks in IR and introduce new evidence supporting the notion that task-centric approaches, abstracted from specific modalities, represent the future of IR. Building on this foundation, we envision the development, utilization, and evaluation of next-generation IR systems. We propose a promising future where IR agents prioritize users, their tasks, and their situations. However, despite their potential to address task-focused and modality-independent IR, agents alone are insufficient. We propose a robust ecosystem around these agents that transcends traditional queries, questions, prompts, and modalities to address users' fundamental needs, tasks, and goals.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Shah, Chirag and White, Ryen W.},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {agents, generative ai, modalities, tasks},
	pages = {3911--3921},
}

@inproceedings{sun_largepig_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{LargePiG} for {Hallucination}-{Free} {Query} {Generation}: {Your} {Large} {Language} {Model} is {Secretly} a {Pointer} {Generator}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714800},
	doi = {10.1145/3696410.3714800},
	abstract = {Recent research on query generation has focused on using Large Language Models (LLMs), which, despite achieving state-of-the-art performance, also introduce hallucination issues in generated queries. In this work, we categorize these issues into relevance hallucination and factuality hallucination, proposing a new typology for hallucinations arising from LLM-based query generation. We present an effective approach to decouple content from form in LLM-generated queries, preserving the factual knowledge extracted and integrated from inputs while leveraging the LLM's linguistic capabilities to construct syntactic structures, including function words. Specifically, we introduce a model-agnostic and training-free method that transforms the Large Language Model into a Pointer-Generator (LargePiG), where the pointer attention distribution utilizes the LLM's inherent attention weights, and the copy probability is derived from the difference between the vocabulary distribution in the model's high layers and the last layer. To validate the effectiveness of LargePiG, we constructed two datasets for assessing hallucination issues in query generation, covering both document and video scenarios. Empirical studies on various LLMs demonstrated LargePiG's superiority across both datasets. Additional experiments further verified that LargePiG reduces hallucination in large vision-language models and enhances the accuracy of document-based question-answering and factuality evaluation tasks. The source code and dataset are available at https://github.com/Jeryi-Sun/LargePiG.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Sun, Zhongxiang and Si, Zihua and Zang, Xiaoxue and Zheng, Kai and Song, Yang and Zhang, Xiao and Xu, Jun},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {hallucination, pointer generator, query generation},
	pages = {4766--4779},
}

@inproceedings{baughman_large_2024,
	address = {New York, NY, USA},
	series = {{KDD} '24},
	title = {Large {Scale} {Generative} {AI} {Text} {Applied} to {Sports} and {Music}},
	isbn = {979-8-4007-0490-1},
	url = {https://doi.org/10.1145/3637528.3671542},
	doi = {10.1145/3637528.3671542},
	abstract = {We address the problem of scaling up the production of media content, including commentary and personalized news stories, for large-scale sports and music events worldwide. Our approach relies on generative AI models to transform a large volume of multimodal data (e.g., videos, articles, real-time scoring feeds, statistics, and fact sheets) into coherent and fluent text. Based on this approach, we introduce, for the first time, an AI commentary system, which was deployed to produce automated narrations for highlight packages at the 2023 US Open, Wimbledon, and Masters tournaments. In the same vein, our solution was extended to create personalized content for ESPN Fantasy Football and stories about music artists for the GRAMMY awards. These applications were built using a common software architecture achieved a 15x speed improvement with an average Rouge-L of 82.00 and perplexity of 6.6. Our work was successfully deployed at the aforementioned events, supporting 90 million fans around the world with 8 billion page views, continuously pushing the bounds on what is possible at the intersection of sports, entertainment, and AI.},
	booktitle = {Proceedings of the 30th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Baughman, Aaron and Morales, Eduardo and Agarwal, Rahul and Akay, Gozde and Feris, Rogerio and Johnson, Tony and Hammer, Stephen and Karlinsky, Leonid},
	year = {2024},
	note = {event-place: Barcelona, Spain},
	keywords = {applied computing, generative ai, large scale computing, neural networks, sports and entertainment},
	pages = {4784--4792},
}

@inproceedings{jayawardena_improving_2024,
	address = {New York, NY, USA},
	series = {{ICCAI} '24},
	title = {Improving {Quality} and {Domain}-{Relevancy} of {Paraphrase} {Generation} with {Graph}-{Based} {Retrieval} {Augmented} {Generation}},
	isbn = {979-8-4007-1705-5},
	url = {https://doi.org/10.1145/3669754.3669784},
	doi = {10.1145/3669754.3669784},
	abstract = {Paraphrase generation is a fundamental area of research in Natural Language Processing (NLP) and Natural Language Generation (NLG), due to its sequence-to-sequence (Seq2Seq) nature. Paraphrasing, spanning across various domains, poses challenges for simpler model architectures due to the extensive knowledge required to generate paraphrases. The added constraint of generating diverse paraphrases further complicates the task for models trained on existing datasets. We present a methodology that leverages Graph-Based Retrieval Augmented Generation (G-RAG), capable of utilizing both entity and phrasal knowledge to address this issue. We demonstrate through experiments that this approach enables both complex models like Large Language models (LLMs) and smaller Seq2Seq models to generate more diverse paraphrases without compromising semantic similarity. Furthermore, this approach’s capacity to integrate domain-specific knowledge makes it particularly effective across different domains, enhancing its applicability in varied contexts. The results are further corroborated by human evaluation and extensive quantitative analysis focusing on semantic similarity, lexical diversity, syntactic diversity, and grammatical correctness to gauge high-quality paraphrases.},
	booktitle = {Proceedings of the 2024 10th {International} {Conference} on {Computing} and {Artificial} {Intelligence}},
	publisher = {Association for Computing Machinery},
	author = {Jayawardena, Lasal and Yapa, Prasan},
	year = {2024},
	note = {event-place: Bali Island, Indonesia},
	keywords = {Graph-based Knowledge, Large Language Models, Natural Language Processing, Paraphrase Generation, Sequence-to-Sequence Models},
	pages = {196--208},
}

@inproceedings{dolata_development_2024,
	address = {New York, NY, USA},
	series = {{ICSE} '24},
	title = {Development in times of hype: {How} freelancers explore {Generative} {AI}?},
	isbn = {979-8-4007-0217-4},
	url = {https://doi.org/10.1145/3597503.3639111},
	doi = {10.1145/3597503.3639111},
	abstract = {The rise of generative AI has led many companies to hire freelancers to harness its potential. However, this technology presents unique challenges to developers who have not previously engaged with it. Freelancers may find these challenges daunting due to the absence of organizational support and their reliance on positive client feedback. In a study involving 52 freelance developers, we identified multiple challenges associated with developing solutions based on generative AI. Freelancers often struggle with aspects they perceive as unique to generative AI such as unpredictability of its output, the occurrence of hallucinations, and the inconsistent effort required due to trial-and-error prompting cycles. Further, the limitations of specific frameworks, such as token limits and long response times, add to the complexity. Hype-related issues, such as inflated client expectations and a rapidly evolving technological ecosystem, further exacerbate the difficulties. To address these issues, we propose Software Engineering for Generative AI (SE4GenAI) and Hype-Induced Software Engineering (HypeSE) as areas where the software engineering community can provide effective guidance. This support is essential for freelancers working with generative AI and other emerging technologies.},
	booktitle = {Proceedings of the {IEEE}/{ACM} 46th {International} {Conference} on {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Dolata, Mateusz and Lange, Norbert and Schwabe, Gerhard},
	year = {2024},
	note = {event-place: Lisbon, Portugal},
	keywords = {AI-based systems, challenges, fashion, freelancers, generative AI, hype, hype-induced SE, hype-SE, novelty, paradigm, product, qualitative research, SE for generative AI, SE4GenAI},
}

@inproceedings{luz_enhancing_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {Enhancing {Emotional} {Realism} in {Games}: {An} {Optimized} {Generative} {AI} {Framework} for {Dynamic} {3D} {Facial} {Animation}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3730554},
	doi = {10.1145/3696630.3730554},
	abstract = {Facial expressiveness is essential for immersive gaming, yet generating emotionally responsive 3D characters remains challenging. This paper presents an optimized generative AI framework that integrates OpenAI's LLMs with OpenFace to improve the mapping between blendshapes (or morph targets) and facial action units (standardized facial muscle movements defined by Facial Action Coding System) for dynamic facial expressions. The system, embedded in an original game scene, generates facial expressions based on interactive player dialogues. From a software engineering perspective, it features modular, scalable AI-driven animation pipelines that support adaptive emotion modeling and game engine integration. User evaluations demonstrate high realism, clear emotion recognition, and strong engagement, confirming the system's potential to enhance player interaction. Further refinements in blendshape mappings and real-time adjustments can enhance the differentiation of subtle emotions like Disgust and Contempt, improving the system's overall expressiveness.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Luz, Jonas de Araújo, Jr and Pessoa, Rafael Fonseca and Ribeiro, Guadalupe Prado Saldanha and Lira, João Vitor Vieira and Rodrigues, Maria Andréia Formico},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {artificial intelligence, facial expressions, game characters, LLMs, RAG},
	pages = {1461--1468},
}

@inproceedings{crista_chat4elderly_2025,
	address = {Richland, SC},
	series = {{AAMAS} '25},
	title = {{Chat4Elderly}: {A} {Multi}-{Agent} {System} for {Personalized} {Wellness} {Using} {Generative} {AI} and {Wearable} {Technology}},
	isbn = {979-8-4007-1426-9},
	abstract = {This demo presents Chat4Elderly, a Multi-Agent System (MAS) designed to support the well-being of elderly users through personalized and proactive interactions. The system combines Large Language Models (LLMs) with smartwatch sensor data to provide real-time, context-aware responses that address both mental and physical health needs. By analyzing conversational patterns and physical activity levels, it adapts to user preferences, offering personalized assistance and engagement. Over time, the system improves its interactions using stored knowledge, increasing personalization and supporting long-term well-being. This approach helps reduce loneliness and enhance quality of life (QoL), creating a more supportive and engaging experience for elderly users.},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Autonomous} {Agents} and {Multiagent} {Systems}},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Crista, Vítor and Martinho, Diogo and Marreiros, Goreti},
	year = {2025},
	note = {event-place: Detroit, MI, USA},
	keywords = {conversation system, generative ai, multi-agent systems, wearable technology},
	pages = {3041--3043},
}

@inproceedings{amri_approach_2024,
	address = {New York, NY, USA},
	series = {{NISS} '24},
	title = {An {Approach} to the {Analysis} of {Financial} {Documents} {Using} {Generative} {AI}},
	isbn = {979-8-4007-0929-6},
	url = {https://doi.org/10.1145/3659677.3659736},
	doi = {10.1145/3659677.3659736},
	abstract = {This project tackles the challenge of advancing document analysis with generative AI techniques. It explores two main approaches:• Fine-Tuning and Retrieval Augmented Generation (RAG).• Fine-Tuning: This approach utilizes the BART model in conjunction with a specialized vector database. The Fine-Tuning phase involves a comprehensive process of data acquisition, cleaning, and processing. This phase provides valuable insights into the challenges and considerations involved in document analysis using Fine-Tuning.Retrieval Augmented Generation (RAG): This novel method leverages generative AI for contextual understanding and response generation. The RAG section delves into the objectives, methodology, and results achieved with this cutting-edge approach.A comparative analysis is then conducted to shed light on the distinct contributions of Fine-Tuning and RAG to document analysis. Furthermore, the project extends beyond AI models by developing an interactive User Interface (UI). This UI utilizes various technologies to ensure a seamless user experience. Key features include functionalities for file upload, error handling, responsive design, and smooth integration with the backend system.},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Networking}, {Intelligent} {Systems} and {Security}},
	publisher = {Association for Computing Machinery},
	author = {Amri, Samir and Bani, Rkia and Bani, Saida},
	year = {2024},
	note = {event-place: Meknes, AA, Morocco},
}

@inproceedings{shin_planfitting_2025,
	address = {New York, NY, USA},
	series = {{CUI} '25},
	title = {{PlanFitting}: {Personalized} {Exercise} {Planning} with {Large} {Language} {Model}-driven {Conversational} {Agent}},
	isbn = {979-8-4007-1527-3},
	url = {https://doi.org/10.1145/3719160.3736607},
	doi = {10.1145/3719160.3736607},
	abstract = {Creating personalized and actionable exercise plans often requires iteration with experts, which can be costly and inaccessible to many individuals. This work explores the capabilities of Large Language Models (LLMs) in addressing these challenges. We present PlanFitting, an LLM-driven conversational agent that assists users in creating and refining personalized weekly exercise plans. By engaging users in free-form conversations, PlanFitting helps elicit users’ goals, availabilities, and potential obstacles, and enables individuals to generate personalized exercise plans aligned with established exercise guidelines. Our study—involving a user study, intrinsic evaluation, and expert evaluation—demonstrated PlanFitting’s ability to guide users to create tailored, actionable, and evidence-based plans. We discuss future design opportunities for LLM-driven conversational agents to create plans that better comply with exercise principles and accommodate personal constraints.},
	booktitle = {Proceedings of the 7th {ACM} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Shin, Donghoon and Hsieh, Gary and Kim, Young-Ho},
	year = {2025},
}

@inproceedings{tsai_rtlfixer_2024,
	address = {New York, NY, USA},
	series = {{DAC} '24},
	title = {{RTLFixer}: {Automatically} {Fixing} {RTL} {Syntax} {Errors} with {Large} {Language} {Model}},
	isbn = {979-8-4007-0601-1},
	url = {https://doi.org/10.1145/3649329.3657353},
	doi = {10.1145/3649329.3657353},
	abstract = {This paper presents RTLFixer, a novel framework enabling automatic syntax errors fixing for Verilog code with Large Language Models (LLMs). Despite LLM's promising capabilities, our analysis indicates that approximately 55\% of errors in LLM-generated Verilog are syntax-related, leading to compilation failures. To tackle this issue, we introduce a novel debugging framework that employs Retrieval-Augmented Generation (RAG) and ReAct prompting, enabling LLMs to act as autonomous agents in interactively debugging the code with feedback. This framework demonstrates exceptional proficiency in resolving syntax errors, successfully correcting about 98.5\% of compilation errors in our debugging dataset, comprising 212 erroneous implementations derived from the VerilogEval benchmark. Our method leads to 32.3\% and 10.1\% increase in pass@1 success rates in the VerilogEval-Machine and VerilogEval-Human benchmarks, respectively. The source code and benchmark are available at https://github.com/NVlabs/RTLFixer.},
	booktitle = {Proceedings of the 61st {ACM}/{IEEE} {Design} {Automation} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Tsai, Yunda and Liu, Mingjie and Ren, Haoxing},
	year = {2024},
	note = {event-place: San Francisco, CA, USA},
}

@inproceedings{tsutsui_case_2024,
	address = {New York, NY, USA},
	series = {{ICAIF} '24},
	title = {A {Case} {Study} on {Enhancing} {Inquiry} {Response} in a {Non}-{Life} {Insurance} {Company} {Using} {Generative} {AI}.},
	isbn = {979-8-4007-1081-0},
	url = {https://doi.org/10.1145/3677052.3698626},
	doi = {10.1145/3677052.3698626},
	abstract = {In Japan, non-life insurance companies deliver products through agencies. Major insurance companies provide support through phone calls, emails, etc., at locations nationwide to ensure that their tens of thousands of agents can accurately handle customers, taking into account the characteristics and underwriting rules of a wide variety of insurance products. The documents to be referred to cover a vast amount array of complex rules, and as financial products, precise and courteous responses are always needed in accordance with individual cases are vital. In this study, we developed an inquiry response support system using the retrieval-augmented generation (RAG) architecture of large language models (LLMs) with the aim of improving the inquiry response operations of non-life insurance companies. In addition, we conducted evaluation experiments on the optimal combinations of conditions related to response performance, such as the chunk division units of the target manuals for searching and the number of tokens input into the LLM. Our findings showed that the accuracy improved with an appropriate number of input tokens and item-based division units with meaningful content. In the end, the inquiry response system developed with the proposed architecture is in practical use, with 14,000 users utilizing it in their daily operations.},
	booktitle = {Proceedings of the 5th {ACM} {International} {Conference} on {AI} in {Finance}},
	publisher = {Association for Computing Machinery},
	author = {Tsutsui, Shojiro and Karino, Michihiro and Kuroki, Kenichi and Fukumoto, Aya and Hamano, Yusuke and Sobata, Kenji and Saito, Temma and Kawamoto, Tatsunori and Odashima, Taku and Kato, Tsuyoshi and Motohashi, Yosuke},
	year = {2024},
	note = {event-place: Brooklyn, NY, USA},
	keywords = {Inquiry response support system, Large Language Models (LLMs), Non-life insurance company, Retrieval-Augmented Generation (RAG)},
	pages = {108--116},
}

@inproceedings{geyer_case_2025,
	address = {New York, NY, USA},
	series = {{CHIWORK} '25},
	title = {A {Case} {Study} {Investigating} the {Role} of {Generative} {AI} in {Quality} {Evaluations} of {Epics} in {Agile} {Software} {Development}},
	isbn = {979-8-4007-1384-2},
	url = {https://doi.org/10.1145/3729176.3729200},
	doi = {10.1145/3729176.3729200},
	abstract = {The broad availability of generative AI offers new opportunities to support various work domains, including agile software development. Agile epics are a key artifact for product managers to communicate requirements to stakeholders. However, in practice, they are often poorly defined, leading to churn, delivery delays, and cost overruns. In this industry case study, we investigate opportunities for large language models (LLMs) to evaluate agile epic quality in a global company. Results from a user study with 17 product managers indicate how LLM evaluations could be integrated into their work practices, including perceived values and usage in improving their epics. High levels of satisfaction indicate that agile epics are a new, viable application of AI evaluations. However, our findings also outline challenges, limitations, and adoption barriers that can inform both practitioners and researchers on the integration of such evaluations into future agile work practices.},
	booktitle = {Proceedings of the 4th {Annual} {Symposium} on {Human}-{Computer} {Interaction} for {Work}},
	publisher = {Association for Computing Machinery},
	author = {Geyer, Werner and He, Jessica and Sarkar, Daita and Brachman, Michelle and Hammond, Chris and Heins, Jennifer and Ashktorab, Zahra and Rosemberg, Carlos and Hill, Charlie},
	year = {2025},
	keywords = {Agile Epics Quality, Agile Software Development, Evaluation, Generative AI, Large Language Models, Software Requirements},
}

@inproceedings{liu_innovative_2024,
	address = {New York, NY, USA},
	series = {{MM} '24},
	title = {An {Innovative} {Industry} {Program} in {A} {New} {Era} of {Multimedia} with {Generative} {AI}},
	isbn = {979-8-4007-0686-8},
	url = {https://doi.org/10.1145/3664647.3689702},
	doi = {10.1145/3664647.3689702},
	abstract = {The ACM Multimedia 2024 industry program offers a unique platform for fostering collaboration between academia and industry. This year's program features a diverse range of industry keynotes, expert talks, seminars, and demonstrations, showcasing the latest advancements in multimedia technology. Renowned experts from industry and academia will share their insights on topics such as generative AI, automotive design, computer vision, spatial experience, healthcare, and more. Attendees will have the opportunity to network with industry leaders, learn about cutting-edge technologies, and explore potential collaborations. The industry program highlights the growing importance of multimedia technology in various domains and demonstrates the innovative ways in which AI and other emerging technologies are transforming industries. By participating in this program, attendees can gain valuable knowledge, expand their professional networks, and contribute to the advancement of the field.},
	booktitle = {Proceedings of the 32nd {ACM} {International} {Conference} on {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Jianquan and Adsumilli, Balu and Yanagawa, Yukiko and Dong, Haiwei},
	year = {2024},
	note = {event-place: Melbourne VIC, Australia},
	keywords = {automotive design, computer vision, generative ai, healthcare, spatial experience},
	pages = {11125--11126},
}

@inproceedings{toslali_agrabot_2024,
	address = {New York, NY, USA},
	series = {{FSE} 2024},
	title = {{AgraBOT}: {Accelerating} {Third}-{Party} {Security} {Risk} {Management} in {Enterprise} {Setting} through {Generative} {AI}},
	isbn = {979-8-4007-0658-5},
	url = {https://doi.org/10.1145/3663529.3663829},
	doi = {10.1145/3663529.3663829},
	abstract = {In the contemporary business landscape, organizations often rely on third-party services for many functions, including IT services, cloud computing, and business processes. To identify potential security risks, organizations conduct rigorous assessments before engaging with third-party vendors, referred to as Third-Party Security Risk Management (TPSRM). Traditionally, TPSRM assessments are executed manually by human experts and involve scrutinizing various third-party documents such as System and Organization Controls Type 2 (SOC 2) reports and reviewing comprehensive questionnaires along with the security policy and procedures of vendors—a process that is time-intensive and inherently lacks scalability. AgraBOT, a Retrieval Augmented Generation (RAG) framework, can assist TPSRM assessors by expediting TPSRM assessments and reducing the time required from days to mere minutes. AgraBOT utilizes cutting-edge AI techniques, including information retrieval (IR), large language models (LLMs), multi-stage ranking, prompt engineering, and in-context learning to accurately generate relevant answers from third-party documents to conduct assessments. We evaluate AgraBOT on seven real TPSRM assessments, consisting of 373 question-answer pairs, and attain an F1 score of 0.85.},
	booktitle = {Companion {Proceedings} of the 32nd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Toslali, Mert and Snible, Edward and Chen, Jing and Cha, Alan and Singh, Sandeep and Kalantar, Michael and Parthasarathy, Srinivasan},
	year = {2024},
	note = {event-place: Porto de Galinhas, Brazil},
	keywords = {AI, Document Understanding, LLM, RAG, TPSRM},
	pages = {74--79},
}

@inproceedings{du_prefillonly_2025,
	address = {New York, NY, USA},
	series = {{SOSP} '25},
	title = {{PrefillOnly}: {An} {Inference} {Engine} for {Prefill}-only {Workloads} in {Large} {Language} {Model} {Applications}},
	isbn = {979-8-4007-1870-0},
	url = {https://doi.org/10.1145/3731569.3764834},
	doi = {10.1145/3731569.3764834},
	abstract = {Besides typical generative applications, like ChatGPT, GitHub Copilot, and Cursor, we observe an emerging trend that LLMs are increasingly used in traditional discriminative tasks, such as recommendation, credit verification, and data labeling. The key characteristic of these emerging use cases is that the LLM generates only a single output token, rather than an arbitrarily long sequence of tokens. We refer to this as a prefill-only workload. However, since existing LLM engines assume arbitrary output lengths, they fail to leverage the unique properties of prefill-only workloads. In this paper, we present PrefillOnly, the first LLM inference engine that improves the inference throughput and latency by fully embracing the properties of prefill-only workloads. First, since it generates only one token, PrefillOnly only needs to store the KV cache of only the last computed layer, rather than of all layers. This drastically reduces the GPU memory footprint of LLM inference and allows handling long inputs without using solutions that reduce throughput, such as cross-GPU KV cache parallelization. Second, because the output length is fixed, rather than arbitrary, PrefillOnly can precisely determine the job completion time (JCT) of each prefill-only request before it starts. This enables efficient JCT-aware scheduling policies such as shortest prefill first. PrefillOnly can process up to 4× larger queries per second without inflating the average and P99 latency.},
	booktitle = {Proceedings of the {ACM} {SIGOPS} 31st {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {Association for Computing Machinery},
	author = {Du, Kuntai and Wang, Bowen and Zhang, Chen and Cheng, Yiming and Lan, Qing and Sang, Hejian and Cheng, Yihua and Yao, Jiayi and Liu, Xiaoxuan and Qiao, Yifan and Stoica, Ion and Jiang, Junchen},
	year = {2025},
	note = {event-place: Lotte Hotel World, Seoul, Republic of Korea},
	keywords = {continuous prefill time estimation, hybrid prefilling, large language models, prefill-only, shortest prefill first},
	pages = {399--414},
}

@inproceedings{naik_workshop_2024,
	address = {New York, NY, USA},
	series = {{ISEC} '24},
	title = {Workshop {Report} on {Generative} {AI}-based {Software} {Engineering}},
	isbn = {979-8-4007-1767-3},
	url = {https://doi.org/10.1145/3641399.3641437},
	doi = {10.1145/3641399.3641437},
	abstract = {The co-authors have organized and conducting the Generative AI-based Software Engineering workshop, co-located with the 17th Innovations in Software Engineering Conference (ISEC) at Bangalore, India on 22nd Feb. 2024. This report briefly describes the objectives and brief contents of the workshop, and hoping that the execution of the planned contents during the workshop will meet the set objectives.},
	booktitle = {Proceedings of the 17th {Innovations} in {Software} {Engineering} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Naik, Ravindra and Rajbhoj, Asha and Patwardhan, Manasi and Medicherla, Raveendra Kumar},
	year = {2024},
	note = {event-place: Bangalore, India},
}

@inproceedings{tao_housing_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {"{Housing} {Diversity} {Means} {Diverse} {Housing}": {Blending} {Generative} {AI} into {Speculative} {Design} in {Rural} {Co}-{Housing} {Communities}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713906},
	doi = {10.1145/3706598.3713906},
	abstract = {In response to various environmental and societal challenges, co-housing has emerged to support social cohesion, grassroots innovation and ecological regeneration. Co-housing communities typically have smaller personal spaces, closer neighbourly relationships, and engage in more mutually supportive sustainable practices. To understand such communities’ motivations and visions, we developed a speculative design tool that harnesses Generative Artificial Intelligence (GenAI) to facilitate the envisioning of alternative future scenarios that challenge prevailing values, beliefs, lifestyles, and ways of knowing in contemporary society. Within the context of co-housing communities, we conducted a participatory design study with participants in co-creating their future communities. This paper unpacks implications and also reflects on the co-design approach employing GenAI. Our main findings highlight that GenAI, as a catalyst for imagination, empowers individuals to create visualisations that pose questions through a plural and situated speculative discourse.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Tao, Hongyi and Vyas, Dhaval},
	year = {2025},
	keywords = {co-housing, Generative AI, speculative design, sustainability},
}

@inproceedings{cheng_relic_2024,
	address = {New York, NY, USA},
	series = {{CHI} '24},
	title = {{RELIC}: {Investigating} {Large} {Language} {Model} {Responses} using {Self}-{Consistency}},
	isbn = {979-8-4007-0330-0},
	url = {https://doi.org/10.1145/3613904.3641904},
	doi = {10.1145/3613904.3641904},
	abstract = {Large Language Models (LLMs) are notorious for blending fact with fiction and generating non-factual content, known as hallucinations. To address this challenge, we propose an interactive system that helps users gain insight into the reliability of the generated text. Our approach is based on the idea that the self-consistency of multiple samples generated by the same LLM relates to its confidence in individual claims in the generated texts. Using this idea, we design RELIC, an interactive system that enables users to investigate and verify semantic-level variations in multiple long-form responses. This allows users to recognize potentially inaccurate information in the generated text and make necessary corrections. From a user study with ten participants, we demonstrate that our approach helps users better verify the reliability of the generated text. We further summarize the design implications and lessons learned from this research for future studies of reliable human-LLM interactions.},
	booktitle = {Proceedings of the 2024 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Cheng, Furui and Zouhar, Vilém and Arora, Simran and Sachan, Mrinmaya and Strobelt, Hendrik and El-Assady, Mennatallah},
	year = {2024},
	note = {event-place: Honolulu, HI, USA},
	keywords = {hallucination detection, human-AI interaction, natural language processing},
}

@inproceedings{yun_generative_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Generative {AI} in {Knowledge} {Work}: {Design} {Implications} for {Data} {Navigation} and {Decision}-{Making}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713337},
	doi = {10.1145/3706598.3713337},
	abstract = {Our study of 20 knowledge workers revealed a common challenge: the difficulty of synthesizing unstructured information scattered across multiple platforms to make informed decisions. Drawing on their vision of an ideal knowledge synthesis tool, we developed Yodeai, an AI-enabled system, to explore both the opportunities and limitations of AI in knowledge work. Through a user study with 16 product managers, we identified three key requirements for Generative AI in knowledge work: adaptable user control, transparent collaboration mechanisms, and the ability to integrate background knowledge with external information. However, we also found significant limitations, including overreliance on AI, user isolation, and contextual factors outside the AI’s reach. As AI tools become increasingly prevalent in professional settings, we propose design principles that emphasize adaptability to diverse workflows, accountability in personal and collaborative contexts, and context-aware interoperability to guide the development of human-centered AI systems for product managers and knowledge workers.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Yun, Bhada and Feng, Dana and Chen, Ace S. and Nikzad, Afshin and Salehi, Niloufar},
	year = {2025},
	keywords = {Human-AI Interaction, Information Visualization, Interaction Design, Knowledge Synthesis, Large Language Models},
}

@inproceedings{shin_what_2025,
	address = {New York, NY, USA},
	series = {{DIS} '25},
	title = {What {About} {My} {Design} {Context}?: {Exploring} the {Use} of {Generative} {AI} to {Support} {Customization} of {Translational} {Research} {Artifacts}},
	isbn = {979-8-4007-1485-6},
	url = {https://doi.org/10.1145/3715336.3735686},
	doi = {10.1145/3715336.3735686},
	abstract = {Despite the wealth of knowledge in research papers, practitioners struggle to apply research results to their work due to significant research-practice gaps. This study addresses the rigor-relevance paradox, where academic rigor can undermine the practical relevance of research for designers. Specifically, we explore the potential of large language models (LLMs) to customize translational research artifacts (i.e., design cards) and improve relevance to specific designers’ needs. In our preliminary study (N = 15), designers defined relevance as alignment between the content of the translational artifact and their design context—including target users, modalities/domains, and design stages. Based on these findings, we implemented an LLM-powered pipeline that allows designers to customize research papers into design cards tailored to their contexts. Our evaluation (N = 20) demonstrated that designers perceived customized artifacts as more relevant, actionable, valid, generative, and inspiring than those without customization—even for less topically related papers—indicating LLM-powered customization can be used to support research translation.},
	booktitle = {Proceedings of the 2025 {ACM} {Designing} {Interactive} {Systems} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Shin, Donghoon and Chen, Tze-Yu and Hsieh, Gary and Wang, Lucy Lu},
	year = {2025},
	keywords = {customization, generative AI, rigor-relevance paradox, translational science},
	pages = {1210--1227},
}

@inproceedings{zhao_lookahead_2024,
	address = {New York, NY, USA},
	series = {{KDD} '24},
	title = {Lookahead: {An} {Inference} {Acceleration} {Framework} for {Large} {Language} {Model} with {Lossless} {Generation} {Accuracy}},
	isbn = {979-8-4007-0490-1},
	url = {https://doi.org/10.1145/3637528.3671614},
	doi = {10.1145/3637528.3671614},
	abstract = {As Large Language Models (LLMs) have made significant advancements across various tasks, such as question answering, translation, text summarization, and dialogue systems, the need for accuracy in information becomes crucial, especially for serious financial products serving billions of users like Alipay. However, for a real-world product serving millions of users, the inference speed of LLMs becomes a critical factor compared to a mere experimental model.Hence, this paper presents a generic framework for accelerating the inference process, resulting in a substantial increase in speed and cost reduction for our LLM-based scenarios, with lossless generation accuracy. In the traditional inference process, each token is generated sequentially by the LLM, leading to a time consumption proportional to the number of generated tokens. To enhance this process, our framework, named lookahead, introduces a multi-branch strategy. Instead of generating a single token at a time, we propose a Trie-based retrieval and verification mechanism to be able to accept several tokens at a forward step. Our strategy offers two distinct advantages: (1) it guarantees absolute correctness of the output, avoiding any approximation algorithms, and (2) the worst-case performance of our approach could be comparable with the performance of the conventional process. We conduct extensive experiments to demonstrate the significant improvements achieved by applying our inference acceleration framework. Our framework has been widely deployed in Alipay since April 2023, and obtained remarkable 2.66x to 6.26x speedup. Our code is available at https://github.com/alipay/PainlessInferenceAcceleration.},
	booktitle = {Proceedings of the 30th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Zhao, Yao and Xie, Zhitian and Liang, Chen and Zhuang, Chenyi and Gu, Jinjie},
	year = {2024},
	note = {event-place: Barcelona, Spain},
	keywords = {inference framework, large language model, lossless generation accuracy, multi-branch draft, single-branch draft, trie tree},
	pages = {6344--6355},
}

@inproceedings{prather_beyond_2025,
	address = {New York, NY, USA},
	series = {{ITiCSE} 2024},
	title = {Beyond the {Hype}: {A} {Comprehensive} {Review} of {Current} {Trends} in {Generative} {AI} {Research}, {Teaching} {Practices}, and {Tools}},
	isbn = {979-8-4007-1208-1},
	url = {https://doi.org/10.1145/3689187.3709614},
	doi = {10.1145/3689187.3709614},
	abstract = {Generative AI (GenAI) is advancing rapidly, and the literature in computing education is expanding almost as quickly. Initial responses to GenAI tools were mixed between panic and utopian optimism. Many were fast to point out the opportunities and challenges of GenAI. Researchers reported that these new tools are capable of solving most introductory programming tasks and are causing disruptions throughout the curriculum. These tools can write and explain code, enhance error messages, create resources for instructors, and even provide feedback and help for students like a traditional teaching assistant. In 2024, new research started to emerge on the effects of GenAI usage in the computing classroom. These new data involve the use of GenAI to support classroom instruction at scale and to teach students how to code with GenAI. In support of the former, a new class of tools is emerging that can provide personalized feedback to students on their programming assignments or teach both programming and prompting skills at the same time. With the literature expanding so rapidly, this report aims to summarize and explain what is happening on the ground in computing classrooms. We provide a systematic literature review; a survey of educators and industry professionals; and interviews with educators using GenAI in their courses, educators studying GenAI, and researchers who create GenAI tools to support computing education. The triangulation of these methods and data sources expands the understanding of GenAI usage and perceptions at this critical moment for our community.},
	booktitle = {2024 {Working} {Group} {Reports} on {Innovation} and {Technology} in {Computer} {Science} {Education}},
	publisher = {Association for Computing Machinery},
	author = {Prather, James and Leinonen, Juho and Kiesler, Natalie and Gorson Benario, Jamie and Lau, Sam and MacNeil, Stephen and Norouzi, Narges and Opel, Simone and Pettit, Vee and Porter, Leo and Reeves, Brent N. and Savelka, Jaromir and Smith, David H., IV and Strickroth, Sven and Zingaro, Daniel},
	year = {2025},
	note = {event-place: Milan, Italy},
	keywords = {artificial intelligence, computing education, genai, generative ai, large language models, pedagogical practices, teaching computing},
	pages = {300--338},
}

@inproceedings{jin_chatting_2025,
	address = {New York, NY, USA},
	series = {{LAK} '25},
	title = {Chatting with a {Learning} {Analytics} {Dashboard}: {The} {Role} of {Generative} {AI} {Literacy} on {Learner} {Interaction} with {Conventional} and {Scaffolding} {Chatbots}},
	isbn = {979-8-4007-0701-8},
	url = {https://doi.org/10.1145/3706468.3706545},
	doi = {10.1145/3706468.3706545},
	abstract = {Learning analytics dashboards (LADs) simplify complex learner data into accessible visualisations, providing actionable insights for educators and students. However, their educational effectiveness has not always matched the sophistication of the technology behind them. Explanatory and interactive LADs, enhanced by generative AI (GenAI) chatbots, hold promise by enabling dynamic, dialogue-based interactions with data visualisations and offering personalised feedback through text. Yet, the effectiveness of these tools may be limited by learners’ varying levels of GenAI literacy, a factor that remains underexplored in current research. This study investigates the role of GenAI literacy in learner interactions with conventional (reactive) versus scaffolding (proactive) chatbot-assisted LADs. Through a comparative analysis of 81 participants, we examine how GenAI literacy is associated with learners’ ability to interpret complex visualisations and their cognitive processes during interactions with chatbot-assisted LADs. Results show that while both chatbots significantly improved learner comprehension, those with higher GenAI literacy benefited the most, particularly with conventional chatbots, demonstrating diverse prompting strategies. Findings highlight the importance of considering learners’ GenAI literacy when integrating GenAI chatbots in LADs and educational technologies. Incorporating scaffolding techniques within GenAI chatbots can be an effective strategy, offering a more guided experience that reduces reliance on learners’ GenAI literacy.},
	booktitle = {Proceedings of the 15th {International} {Learning} {Analytics} and {Knowledge} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Jin, Yueqiao and Yang, Kaixun and Yan, Lixiang and Echeverria, Vanessa and Zhao, Linxuan and Alfredo, Riordan and Milesi, Mikaela and Fan, Jie Xiang and Li, Xinyu and Gasevic, Dragan and Martinez-Maldonado, Roberto},
	year = {2025},
	keywords = {data visualisation, generative AI chatbots, generative AI literacy, learning analytics dashboard},
	pages = {579--590},
}

@inproceedings{inie_how_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {How {CO2STLY} {Is} {CHI}? {The} {Carbon} {Footprint} of {Generative} {AI} in {HCI} {Research} and {What} {We} {Should} {Do} {About} {It}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3714227},
	doi = {10.1145/3706598.3714227},
	abstract = {The energy cost of developing and deploying Generative AI (GenAI) models has exploded with their mass adoption, as has the ensuing carbon emissions. The climate impact of this is currently unknown. In Human-Computer Interaction, GenAI models are rarely trained but often used. Based on detailed review of 282 papers, we estimate this footprint from energy consumption of the total use of GenAI for CHI 2024 research as between 10,769.63 and 10,925.12 kg CO2e — equal to driving a car for more than 100,000 km. We show that in CHI research, GenAI is most often used for Prototyping, Evaluation \&amp; User studies, and that Data Collection and Fine-tuning models incurs the highest CO2st.1 We find that CHI submissions are unlikely to report GenAI use transparently, which makes precise calculations difficult. By measuring the usage of a subset of the papers on local hardware, we obtain estimations of the energy consumption and carbon footprint. Based on this evidence, we discuss and demonstrate ways to mitigate the issues of GenAI carbon footprint and lack of transparency.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Inie, Nanna and Falk, Jeanette and Selvan, Raghavendra},
	year = {2025},
	keywords = {AI Hype, carbon footprint, energy consumption, Environmental Sustainability, Generative AI},
}

@inproceedings{he_study_2024,
	address = {New York, NY, USA},
	series = {{ICBDDM} '24},
	title = {A {Study} on {Large} {Language} {Model}-{Based} {Approach} for {Construction} {Contract} {Risk} {Detection}},
	isbn = {979-8-4007-1027-8},
	url = {https://doi.org/10.1145/3696500.3696523},
	doi = {10.1145/3696500.3696523},
	abstract = {Construction projects typically involve large-scale operations and are subject to complex external conditions, making it essential to safeguard the interests of contractor enterprises through well-crafted contract clauses. However, the current reliance on expert judgment for identifying contract risks presents several challenges, including lengthy processing times, heavy workloads, and inconsistent results. To address these issues, this study introduces a Large Language Model (LLM)-based approach for automating the identification of risks in construction contracts. The proposed method was rigorously validated on 26 actual contracts, achieving an average accuracy of 76.7\% across four state-of-the-art LLMs. This research advances the application of LLMs in construction contract management, providing practical solutions to existing challenges and setting the stage for further exploration in LLM-driven contract analysis.},
	booktitle = {Proceedings of the 2024 {International} {Conference} on {Big} {Data} and {Digital} {Management}},
	publisher = {Association for Computing Machinery},
	author = {He, Yudong and Tang, Yinqiu and Chen, Tianhong},
	year = {2024},
	note = {event-place: Shanghai, China},
	pages = {136--141},
}

@inproceedings{shen_large_2025,
	address = {New York, NY, USA},
	series = {{ICCSIE} '25},
	title = {A large language model algorithm for green finance innovation for digital technology innovation of heavily polluting enterprises},
	isbn = {979-8-4007-1863-2},
	url = {https://doi.org/10.1145/3759179.3760456},
	doi = {10.1145/3759179.3760456},
	abstract = {Green financial innovation, by providing targeted credit and incentive mechanisms, alleviates the financing constraints of heavily polluting enterprises and intensifies the pressure of environmental regulations, thereby promoting their digital technology innovation to achieve emission reduction, efficiency improvement and green transformation. At present, there are many problems in the digital technology innovation of heavily polluting enterprises. Therefore, this study aims to construct a green finance innovation technology system to enhance the impact of digital technologies on heavily polluting enterprises. This paper utilizes green finance innovation technologies to design and implement a digital technology innovation system based on heavily polluting enterprises. Its performance was verified through experiments. The experimental results show that this method is simple to operate and has a profound impact on research. The results show that the large language model algorithm has significant advantages in the digital technology innovation of heavily polluting enterprises and can effectively solve the technical bottlenecks.},
	booktitle = {Proceedings of the 10th {International} {Conference} on {Cyber} {Security} and {Information} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Shen, Yuxin and Lu, Wei},
	year = {2025},
	keywords = {digital technology, Green finance, heavily polluting enterprises, impact, innovation},
	pages = {344--352},
}

@inproceedings{borghoff_generative_2025,
	address = {New York, NY, USA},
	series = {{ECSEE} '25},
	title = {Generative {AI} in {Student} {Software} {Development} {Projects}: {A} {User} {Study} on {Experiences} and {Self}-{Assessment}},
	isbn = {979-8-4007-1282-1},
	url = {https://doi.org/10.1145/3723010.3723012},
	doi = {10.1145/3723010.3723012},
	abstract = {The way software is developed is changing rapidly due to the general availability of generative AI tools. As a result, the software engineering education that is part of every computer science program needs to change. Especially in software engineering courses, such AI tools need to be used and practiced in a meaningful and useful way. The programming project is one such course at our university, and the curriculum will be expanded accordingly in the future. In this paper we describe our approach and a user study among the participants of the last programming project, in which we collected experiences with the use of current AI tools, in particular highlighting their usefulness and limitations. Our study focuses on identifying which aspects of the course students used AI tools for, evaluating successful applications, and uncovering remaining challenges.},
	booktitle = {Proceedings of the 6th {European} {Conference} on {Software} {Engineering} {Education}},
	publisher = {Association for Computing Machinery},
	author = {Borghoff, Uwe M. and Minas, Mark and Schopp, Jannis},
	year = {2025},
	keywords = {AI support, AI-based tutoring, experiments, software development project course, software engineering education},
	pages = {161--170},
}

@inproceedings{feng_complicated_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {Complicated {Semantic} {Alignment} for {Long}-{Tail} {Query} {Rewriting} in {Taobao} {Search} {Based} on {Large} {Language} {Model}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737204},
	doi = {10.1145/3711896.3737204},
	abstract = {In the realm of e-commerce search, semantic matching has consistently been a core issue, as it directly affects user experience and company revenue. However, users' queries often fail to effectively retrieve relevant products due to discrepancies between the user's expression habits and product names written by merchants. Even existing large language model (LLM) based query rewriting methods can bridge the semantic gap for most queries, they are still ineffective for long-tail queries with complicated semantic. In this paper, we propose Complicated Semantic Alignment Query Rewrite(CSA-QR) framework, which mitigates the semantic differences in long-tail queries with complicated semantics. CSA-QR comprises three stages: high-quality supervised fine-tuning (SFT) dataset generation, multi-dimensional alignment dataset generation, and binary feedback Proximal Policy Optimization (PPO) for reinforcement alignment. Initially, we utilize general large language models to generate rewrite candidates, followed by manual annotation to discriminate the candidates, then use the retrieval augmentation generation (RAG) based on existing annotations to produce a higher quality SFT dataset. Subsequently, we decouple the feedback data into user semantic consistency and merchant expression consistency dimensions to collect multi-dimensional alignment data. Finally, we introduce a binary feedback method to train the reward model, enabling it to better guide alignment training within our context. We also identify a set of more appropriate reward model evaluation metrics to guide our iterations. Offline experiments demonstrate the effectiveness of this method in improving retrieval performance. Online A/B tests reveal that our method significantly boosts critical metrics such as product click-through rate (CTR), gross merchandise volume (GMV) and number of transaction (\#Trans) for long-tail complicated queries. CSA-QR has been deployed on Taobao, one of China's most popular online shopping platforms, since September 2024.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Feng, Yunling and Ling, Gui and Jiang, Yue and Huang, Jianfeng and Ou, Dan and Liu, Qingwen and Lv, Fuyu and Xu, Yajing},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {large language models, query reformulation, semantic matching},
	pages = {4435--4446},
}

@inproceedings{yao_news_2024,
	address = {New York, NY, USA},
	series = {{RAIIE} '24},
	title = {News {GPT}: {A} {Large} {Language} {Model} for {Reliable} and {Hallucination}-{Controlled} {News} {Generation}},
	isbn = {979-8-4007-1831-1},
	url = {https://doi.org/10.1145/3689299.3689320},
	doi = {10.1145/3689299.3689320},
	abstract = {With the continuous development of natural language processing (NLP) technology, large models have become essential tools for handling natural language tasks. In the news domain, large models can be used for automating news generation, thereby enhancing the productivity and quality of news production. As a result, we introduce a new large model—News GPT—which utilizes an external knowledge retrieval module to inject real information, providing authentic and reliable news generation services. By combining Chinese and English news data with general domain data, we have constructed a high-quality, multi-domain news dataset consisting of 1.4B tokens. In the pre-training phase, we expand the Chinese vocabulary for the Llama2-70B model, and in the fine-tuning phase, we design expert prompts to help the model understand downstream tasks better. We have tested News GPT in various aspects, and the experimental results show that News GPT, as an intelligent news assistant, can effectively complete tasks using retrieval tools in different application scenarios. It possesses excellent natural language understanding, knowledge, and logical reasoning abilities, and effectively controls the hallucinations in the generation process. News GPT demonstrates high accuracy and reliability in news generation and can provide substantial support for the news industry.},
	booktitle = {Proceedings of the 2024 3rd {International} {Symposium} on {Robotics}, {Artificial} {Intelligence} and {Information} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Yao, Shunyu and Ke, Qingqing and Li, Kangtong and Wang, Qiwei and Hu, Jie},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	pages = {113--119},
}

@inproceedings{gao_humanizing_2024,
	address = {New York, NY, USA},
	series = {{CHI} {PLAY} {Companion} '24},
	title = {Humanizing {Artifacts}: {An} {Educational} {Game} {For} {Cultural} {Heritage} {Artifacts} and {History} {Using} {Generative} {AI}},
	isbn = {979-8-4007-0692-9},
	url = {https://doi.org/10.1145/3665463.3678792},
	doi = {10.1145/3665463.3678792},
	abstract = {Artifacts are vivid carriers of history and culture. Current applications of cultural heritage (CH) education present knowledge from a third-person perspective, potentially overlooking the emotional connection between users and artifacts. This paper introduces the concept of "Knowledge Actor", which humanizes artifacts, making them natural first-person narrators of knowledge. For instance, in the game, the glazed porcelain artifact is humanized as a boy. Players evoke his memories and advance the game using key information. To gather key information, players talk with ores to solve the creation puzzle or to the map to get location details, simultaneously deducing, acquiring, and memorizing knowledge. The humanized design and generative AI capabilities seamlessly integrate puzzle-solving gameplay with educational objectives. Experimental results indicate this game design fosters emotional connections between users and artifacts, enhances learning outcomes, and improves the game experience. This paper explores new directions of humanized design and generative AI in CH education.},
	booktitle = {Companion {Proceedings} of the 2024 {Annual} {Symposium} on {Computer}-{Human} {Interaction} in {Play}},
	publisher = {Association for Computing Machinery},
	author = {Gao, Fengsen and Fang, Ke and Chan, Wai Kin (Victor)},
	year = {2024},
	note = {event-place: Tampere, Finland},
	keywords = {artifact, cultural heritage, education, game design, humanized design},
	pages = {91--96},
}

@inproceedings{sharma_openroad-assistant_2024,
	address = {New York, NY, USA},
	series = {{MLCAD} '24},
	title = {{OpenROAD}-{Assistant}: {An} {Open}-{Source} {Large} {Language} {Model} for {Physical} {Design} {Tasks}},
	isbn = {979-8-4007-0699-8},
	url = {https://doi.org/10.1145/3670474.3685960},
	doi = {10.1145/3670474.3685960},
	abstract = {Large language models (LLMs) have shown significant potential in serving as domain-specific chatbots. Recently, these models have emerged as powerful tools for chip design, providing both natural language responses and script generation for domain-specific inquiries. Previous work has demonstrated the effectiveness of LLMs in assisting with physical design automation; however, these approaches often rely on proprietary tools, APIs, technologies, and designs. As a result, access to these models is extremely limited, particularly for new chip designers who could greatly benefit from a design assistant. This paper introduces OpenROAD-Assistant, an open-source chatbot for OpenROAD that relies only on public data and responds to queries in either prose or Python script using the OpenROAD APIs. OpenROAD-Assistant leverages the Llama3-8B foundation model and employs retrieval-aware fine-tuning (RAFT) to respond to physical design-specific questions for OpenROAD. Notably, OpenROAD-Assistant outperforms other foundational models such as ChatGPT3.5, ChatGPT4, Code Llama, Claude3, and other ablation study baselines on the measured metrics (pass@k for scripting and BERTScore/BARTScore for question-answering). OpenROAD-Assistant achieves a 77\% pass@1 score, 80\% pass@3 score for scripting, and it achieves a 98\% BERTScore and 96\% BARTScore on question-answering.},
	booktitle = {Proceedings of the 2024 {ACM}/{IEEE} {International} {Symposium} on {Machine} {Learning} for {CAD}},
	publisher = {Association for Computing Machinery},
	author = {Sharma, Utsav and Wu, Bing-Yue and Kankipati, Sai Rahul Dhanvi and Chhabria, Vidya A. and Rovinski, Austin},
	year = {2024},
	note = {event-place: Salt Lake City, UT, USA},
}

@inproceedings{das_swain_teacher_2024,
	address = {New York, NY, USA},
	series = {{CHIWORK} '24},
	title = {Teacher, {Trainer}, {Counsel}, {Spy}: {How} {Generative} {AI} can {Bridge} or {Widen} the {Gaps} in {Worker}-{Centric} {Digital} {Phenotyping} of {Wellbeing}},
	isbn = {979-8-4007-1017-9},
	url = {https://doi.org/10.1145/3663384.3663401},
	doi = {10.1145/3663384.3663401},
	abstract = {The increasing integration of computing technologies in the workplace has also seen the conceptualization and development of data-driven and algorithmic tools that aim to improve workers’ wellbeing and performance. However, both research and practice have revealed several gaps in the effectiveness and deployment of these tools. Meanwhile, the recent advances in generative AI have highlighted the tremendous capabilities of large language models (LLMs) in processing large volumes of data in producing human-interactive natural language content. This paper explores the opportunities for LLMs in facilitating worker-centered design for Wellbeing Assessment Tools (WATs). In particular, we map features of LLMs against known challenges of WAT. We highlight how the LLMs can bridge or even widen the gaps in worker-centeric WAT. This paper aims to inspire new research directions focused on empowering workers and anticipating harms in integrating LLMs with workplace technologies.},
	booktitle = {Proceedings of the 3rd {Annual} {Meeting} of the {Symposium} on {Human}-{Computer} {Interaction} for {Work}},
	publisher = {Association for Computing Machinery},
	author = {Das Swain, Vedant and Saha, Koustuv},
	year = {2024},
	note = {event-place: Newcastle upon Tyne, United Kingdom},
	keywords = {generative AI, large language models, LLMs, worker performance, worker wellbeing, workplace},
}

@inproceedings{yen_search_2025,
	address = {New York, NY, USA},
	series = {{DIS} '25},
	title = {To {Search} or {To} {Gen}? {Design} {Dimensions} {Integrating} {Web} {Search} and {Generative} {AI} in {Programmers}' {Information}-{Seeking} {Process}},
	isbn = {979-8-4007-1485-6},
	url = {https://doi.org/10.1145/3715336.3735752},
	doi = {10.1145/3715336.3735752},
	abstract = {Programmers now use both generative AI (GenAI) and traditional web search for information-seeking, yet how these tools are used individually or in combination remains unclear. To answer this, we conducted a multi-phase investigation, including retrospective interviews to identify foraging behaviours and challenges and an observational study with a technology probe to analyze how contextual information flows across tools. Our findings reveal that effective information-seeking requires adaptable strategies and varying levels of contextual detail. Building on these insights, we propose five design dimensions for developing tools that integrate web search, GenAI, and code editors. We further demonstrated the generative power of these design dimensions with a proof-of-concept prototype, validated through a user study, offering actionable design implications for enhancing integrated information-seeking workflows across web search and GenAI in programming.},
	booktitle = {Proceedings of the 2025 {ACM} {Designing} {Interactive} {Systems} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Yen, Ryan and Xie, Yimeng and Sultanum, Nicole and Zhao, Jian},
	year = {2025},
	keywords = {Code Generation, Human-AI Interaction, Information Seeking, Information-Foraging},
	pages = {1084--1106},
}

@inproceedings{liu_cachegen_2024,
	address = {New York, NY, USA},
	series = {{ACM} {SIGCOMM} '24},
	title = {{CacheGen}: {KV} {Cache} {Compression} and {Streaming} for {Fast} {Large} {Language} {Model} {Serving}},
	isbn = {979-8-4007-0614-1},
	url = {https://doi.org/10.1145/3651890.3672274},
	doi = {10.1145/3651890.3672274},
	abstract = {As large language models (LLMs) take on complex tasks, their inputs are supplemented with longer contexts that incorporate domain knowledge. Yet using long contexts is challenging as nothing can be generated until the whole context is processed by the LLM. While the context-processing delay can be reduced by reusing the KV cache of a context across different inputs, fetching the KV cache, which contains large tensors, over the network can cause high extra network delays.CacheGen is a fast context-loading module for LLM systems. First, CacheGen uses a custom tensor encoder, leveraging KV cache's distributional properties to encode a KV cache into more compact bitstream representations with negligible decoding overhead, to save bandwidth usage. Second, CacheGen adapts the compression level of different parts of a KV cache to cope with changes in available bandwidth, in order to maintain low context-loading delay and high generation quality. We test CacheGen on popular LLMs and datasets. Compared to the recent systems that reuse the KV cache, CacheGen reduces the KV cache size by 3.5–4.3x and the total delay in fetching and processing contexts by 3.2–3.7x with negligible impact on the LLM response quality. Our code is at: https://github.com/UChi-JCL/CacheGen.},
	booktitle = {Proceedings of the {ACM} {SIGCOMM} 2024 {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Yuhan and Li, Hanchen and Cheng, Yihua and Ray, Siddhant and Huang, Yuyang and Zhang, Qizheng and Du, Kuntai and Yao, Jiayi and Lu, Shan and Ananthanarayanan, Ganesh and Maire, Michael and Hoffmann, Henry and Holtzman, Ari and Jiang, Junchen},
	year = {2024},
	note = {event-place: Sydney, NSW, Australia},
	keywords = {compression, KV cache, large language models},
	pages = {38--56},
}

@inproceedings{haroon_twips_2024,
	address = {New York, NY, USA},
	series = {{ASSETS} '24},
	title = {{TwIPS}: {A} {Large} {Language} {Model} {Powered} {Texting} {Application} to {Simplify} {Conversational} {Nuances} for {Autistic} {Users}},
	isbn = {979-8-4007-0677-6},
	url = {https://doi.org/10.1145/3663548.3675633},
	doi = {10.1145/3663548.3675633},
	abstract = {Autistic individuals often experience difficulties in conveying and interpreting emotional tone and non-literal nuances. Many also mask1 their communication style to avoid being misconstrued by others, spending considerable time and mental effort in the process. To address these challenges in text-based communication, we present TwIPS2, a prototype texting application powered by a large language model (LLM), which can assist users with: a) deciphering tone and meaning of incoming messages, b) ensuring the emotional tone of their message is in line with their intent, and c) coming up with alternate phrasing for messages that could be misconstrued and received negatively by others. We leverage an AI-based simulation and a conversational script to evaluate TwIPS with 8 autistic participants in an in-lab setting. Our findings show TwIPS enables a convenient way for participants to seek clarifications, provides a better alternative to tone indicators, and facilitates constructive reflection on writing technique and style. We also examine how autistic users utilize language for self-expression and interpretation in instant messaging, and gather feedback for enhancing our prototype. We conclude with a discussion around balancing user-autonomy with AI-mediation, establishing appropriate trust levels in AI systems, and autistic users’ customization needs in the context of AI-assisted communication.},
	booktitle = {Proceedings of the 26th {International} {ACM} {SIGACCESS} {Conference} on {Computers} and {Accessibility}},
	publisher = {Association for Computing Machinery},
	author = {Haroon, Rukhshan and Dogar, Fahad},
	year = {2024},
	note = {event-place: St. John's, NL, Canada},
}

@inproceedings{yao_lawyer_2024,
	address = {New York, NY, USA},
	series = {{RAIIE} '24},
	title = {Lawyer {GPT}: {A} {Legal} {Large} {Language} {Model} with {Enhanced} {Domain} {Knowledge} and {Reasoning} {Capabilities}},
	isbn = {979-8-4007-1831-1},
	url = {https://doi.org/10.1145/3689299.3689319},
	doi = {10.1145/3689299.3689319},
	abstract = {The emergence of large language models has brought about revolutionary changes in the field of natural language processing and has shown extraordinary potential in general tasks and various specific domain tasks, especially in the legal field. However, there are still many factors that constrain the application of large language models in the legal field, with the main problems being the lack of domain knowledge and the ability to apply knowledge to solve problems. Therefore, we propose Lawyer GPT, a legal large model that incorporates domain knowledge by using an external knowledge retrieval module to combine an external knowledge base and possesses legal reasoning capabilities. We have collected a large amount of legal domain data and combined it with general domain data, using GPT-4 Turbo to build a high-quality legal dataset. To make Lawyer GPT's legal reasoning capabilities more reliable, we have performed supervised fine-tuning on this dataset, providing it with a good ability to apply domain knowledge to solve problems and enabling it to independently handle various legal professional issues. In addition, we have constructed a legal knowledge base and used retrieval enhancement techniques to provide Lawyer GPT with tools to retrieve external domain knowledge, thereby improving the factual and rationality of the generated content. Experimental results show that Lawyer GPT has demonstrated good performance in both subjective and objective legal domain tests, showing a strong ability to handle legal issues.},
	booktitle = {Proceedings of the 2024 3rd {International} {Symposium} on {Robotics}, {Artificial} {Intelligence} and {Information} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Yao, Shunyu and Ke, Qingqing and Wang, Qiwei and Li, Kangtong and Hu, Jie},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	pages = {108--112},
}

@inproceedings{leong_putting_2024,
	address = {New York, NY, USA},
	series = {{CHI} '24},
	title = {Putting {Things} into {Context}: {Generative} {AI}-{Enabled} {Context} {Personalization} for {Vocabulary} {Learning} {Improves} {Learning} {Motivation}},
	isbn = {979-8-4007-0330-0},
	url = {https://doi.org/10.1145/3613904.3642393},
	doi = {10.1145/3613904.3642393},
	abstract = {Fostering students’ interests in learning is considered to have many positive downstream effects. Large language models have opened up new horizons for generating content tuned to one’s interests, yet it is unclear in what ways and to what extent this customization could have positive effects on learning. To explore this novel dimension, we conducted a between-subjects online study (n=272) featuring different variations of a generative AI vocabulary learning app that enables users to personalize their learning examples. Participants were randomly assigned to control (sentence sourced from pre-existing text) or experimental conditions (generated sentence or short story based on users’ text input). While we did not observe a difference in learning performance between the conditions, the analysis revealed that generative AI-driven context personalization positively affected learning motivation. We discuss how these results relate to previous findings and underscore their significance for the emerging field of using generative AI for personalized\&nbsp;learning.},
	booktitle = {Proceedings of the 2024 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Leong, Joanne and Pataranutaporn, Pat and Danry, Valdemar and Perteneder, Florian and Mao, Yaoli and Maes, Pattie},
	year = {2024},
	note = {event-place: Honolulu, HI, USA},
	keywords = {education, generative artificial intelligence, learning, vocabulary},
}

@inproceedings{lee_altcanvas_2024,
	address = {New York, NY, USA},
	series = {{ASSETS} '24},
	title = {{AltCanvas}: {A} {Tile}-{Based} {Editor} for {Visual} {Content} {Creation} with {Generative} {AI} for {Blind} or {Visually} {Impaired} {People}},
	isbn = {979-8-4007-0677-6},
	url = {https://doi.org/10.1145/3663548.3675600},
	doi = {10.1145/3663548.3675600},
	abstract = {People with visual impairments often struggle to create content that relies heavily on visual elements, particularly when conveying spatial and structural information. Existing accessible drawing tools, which construct images line by line, are suitable for simple tasks like math but not for more expressive artwork. On the other hand, emerging generative AI-based text-to-image tools can produce expressive illustrations from descriptions in natural language, but they lack precise control over image composition and properties. To address this gap, our work integrates generative AI with a constructive approach that provides users with enhanced control and editing capabilities. Our system, AltCanvas, features a tile-based interface enabling users to construct visual scenes incrementally, with each tile representing an object within the scene. Users can add, edit, move, and arrange objects while receiving speech and audio feedback. Once completed, the scene can be rendered as a color illustration or as a vector for tactile graphic generation. Involving 14 blind or low-vision users in design and evaluation, we found that participants effectively used the AltCanvas’s workflow to create illustrations.},
	booktitle = {Proceedings of the 26th {International} {ACM} {SIGACCESS} {Conference} on {Computers} and {Accessibility}},
	publisher = {Association for Computing Machinery},
	author = {Lee, Seonghee and Kohga, Maho and Landau, Steve and O'Modhrain, Sile and Subramonyam, Hari},
	year = {2024},
	note = {event-place: St. John's, NL, Canada},
}

@inproceedings{drosos_its_2024,
	address = {New York, NY, USA},
	series = {{CHIWORK} '24},
	title = {"{It}'s like a rubber duck that talks back": {Understanding} {Generative} {AI}-{Assisted} {Data} {Analysis} {Workflows} through a {Participatory} {Prompting} {Study}},
	isbn = {979-8-4007-1017-9},
	url = {https://doi.org/10.1145/3663384.3663389},
	doi = {10.1145/3663384.3663389},
	abstract = {Generative AI tools can help users with many tasks. One such task is data analysis, which is notoriously challenging for non-expert end-users due to its expertise requirements, and where AI holds much potential, such as finding relevant data sources, proposing analysis strategies, and writing analysis code. To understand how data analysis workflows can be assisted or impaired by generative AI, we conducted a study (n=15) using Bing Chat via participatory prompting. Participatory prompting is a recently developed methodology in which users and researchers reflect together on tasks through co-engagement with generative AI. In this paper we demonstrate the value of the participatory prompting method. We found that generative AI benefits the information foraging and sensemaking loops of data analysis in specific ways, but also introduces its own barriers and challenges, arising from the difficulties of query formulation, specifying context, and verifying results.},
	booktitle = {Proceedings of the 3rd {Annual} {Meeting} of the {Symposium} on {Human}-{Computer} {Interaction} for {Work}},
	publisher = {Association for Computing Machinery},
	author = {Drosos, Ian and Sarkar, Advait and Xu, Xiaotong and Negreanu, Carina and Rintel, Sean and Tankelevitch, Lev},
	year = {2024},
	note = {event-place: Newcastle upon Tyne, United Kingdom},
}

@inproceedings{esposito_beyond_2024,
	address = {New York, NY, USA},
	series = {{ESEM} '24},
	title = {Beyond {Words}: {On} {Large} {Language} {Models} {Actionability} in {Mission}-{Critical} {Risk} {Analysis}},
	isbn = {979-8-4007-1047-6},
	url = {https://doi.org/10.1145/3674805.3695401},
	doi = {10.1145/3674805.3695401},
	abstract = {Context. Risk analysis assesses potential risks in specific scenarios. Risk analysis principles are context-less; the same methodology can be applied to a risk connected to health and information technology security. Risk analysis requires a vast knowledge of national and international regulations and standards and is time and effort-intensive. A large language model can quickly summarize information in less time than a human and can be fine-tuned to specific tasks. Aim. Our empirical study aims to investigate the effectiveness of Retrieval-Augmented Generation and fine-tuned LLM in Risk analysis. To our knowledge, no prior study has explored its capabilities in risk analysis. Method. We manually curated 193 unique scenarios leading to 1283 representative samples from over 50 mission-critical analyses archived by the industrial context team in the last five years. We compared the base GPT-3.5 and GPT-4 models versus their Retrieval-Augmented Generation and fine-tuned counterparts. We employ two human experts as competitors of the models and three other three human experts to review the models and the former human expert’s analysis. The reviewers analyzed 5,000 scenario analyses. Results and Conclusions. HEs demonstrated higher accuracy, but LLMs are quicker and more actionable. Moreover, our findings show that RAG-assisted LLMs have the lowest hallucination rates, effectively uncovering hidden risks and complementing human expertise. Thus, the choice of model depends on specific needs, with FTMs for accuracy, RAG for hidden risks discovery, and base models for comprehensiveness and actionability. Therefore, experts can leverage LLMs for an effective complementing companion in risk analysis within a condensed timeframe. They can also save costs by averting unnecessary expenses associated with implementing unwarranted countermeasures.},
	booktitle = {Proceedings of the 18th {ACM}/{IEEE} {International} {Symposium} on {Empirical} {Software} {Engineering} and {Measurement}},
	publisher = {Association for Computing Machinery},
	author = {Esposito, Matteo and Palagiano, Francesco and Lenarduzzi, Valentina and Taibi, Davide},
	year = {2024},
	note = {event-place: Barcelona, Spain},
	keywords = {Actionability, Analysis, Explainability, Fine-Tuning, Generative AI, Human Experts, Large Language Model, Management, Retrieval Augmented Generation, Risk, Security, Standards, XAI},
	pages = {517--527},
}

@inproceedings{hu_cg-rag_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{CG}-{RAG}: {Research} {Question} {Answering} by {Citation} {Graph} {Retrieval}-{Augmented} {LLMs}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3729920},
	doi = {10.1145/3726302.3729920},
	abstract = {Research question answering requires accurate retrieval and contextual understanding of scientific literature. However, current Retrieval-Augmented Generation (RAG) methods often struggle to balance complex document relationships with precise information retrieval. In this paper, we introduce Contextualized Graph Retrieval-Augmented Generation (CG-RAG), a novel framework that integrates sparse and dense retrieval signals within graph structures to enhance retrieval efficiency and subsequently improve generation quality for research question answering. First, we propose a contextual graph representation for citation graphs, effectively capturing both explicit and implicit connections within and across documents. Next, we introduce Lexical-Semantic Graph Retrieval (LeSeGR), which seamlessly integrates sparse and dense retrieval signals with graph encoding. It bridges the gap between lexical precision and semantic understanding in citation graph retrieval, demonstrating generalizability to existing graph retrieval and hybrid retrieval methods. Finally, we present a context-aware generation strategy that utilizes the retrieved graph-structured information to generate precise and contextually enriched responses using large language models (LLMs). Extensive experiments on research question answering benchmarks across multiple domains demonstrate that our CG-RAG framework significantly outperforms RAG methods combined with various state-of-the-art retrieval approaches, delivering superior retrieval accuracy and generation quality.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Hu, Yuntong and Lei, Zhihan and Dai, Zhongjie and Zhang, Allen and Angirekula, Abhinav and Zhang, Zheng and Zhao, Liang},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {citation graphs, graph learning, graph retrieval-augmented generation, hybrid retrieval, research question answering},
	pages = {678--687},
}

@inproceedings{tan_htmlrag_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{HtmlRAG}: {HTML} is {Better} {Than} {Plain} {Text} for {Modeling} {Retrieved} {Knowledge} in {RAG} {Systems}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714546},
	doi = {10.1145/3696410.3714546},
	abstract = {Retrieval-Augmented Generation (RAG) has been shown to improve knowledge capabilities and alleviate the hallucination problem of LLMs. The Web is a major source of external knowledge used in RAG systems, and many commercial RAG systems have used Web search engines as their major retrieval systems. Typically, such RAG systems retrieve search results, download HTML sources of the results, and then extract plain texts from the HTML sources. Plain text documents or chunks are fed into the LLMs to augment the generation. However, much of the structural and semantic information inherent in HTML, such as headings and table structures, is lost during this plain-text-based RAG process. To alleviate this problem, we propose HtmlRAG, which uses HTML instead of plain text as the format of retrieved knowledge in RAG. We believe HTML is better than plain text in modeling knowledge in external documents, and most LLMs possess robust capacities to understand HTML. However, utilizing HTML presents new challenges. HTML contains additional content such as tags, JavaScript, and CSS specifications, which bring extra input tokens and noise to the RAG system. To address this issue, we propose HTML cleaning, compression, and a two-step block-tree-based pruning strategy, to shorten the HTML while minimizing the loss of information. Experiments on six QA datasets confirm the superiority of using HTML in RAG systems. Our code and datasets are available at https://github.com/plageon/HtmlRAG.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Tan, Jiejun and Dou, Zhicheng and Wang, Wen and Wang, Mang and Chen, Weipeng and Wen, Ji-Rong},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {HTML, large language model, retrieval-augmented generation},
	pages = {1733--1746},
}

@inproceedings{sequeda_benchmark_2024,
	address = {New York, NY, USA},
	series = {{GRADES}-{NDA} '24},
	title = {A {Benchmark} to {Understand} the {Role} of {Knowledge} {Graphs} on {Large} {Language} {Model}'s {Accuracy} for {Question} {Answering} on {Enterprise} {SQL} {Databases}},
	isbn = {979-8-4007-0653-0},
	url = {https://doi.org/10.1145/3661304.3661901},
	doi = {10.1145/3661304.3661901},
	abstract = {Enterprise applications of Large Language Models (LLMs) hold promise for question answering on enterprise SQL databases. However, the extent to which LLMs can accurately respond to enterprise questions in such databases remains unclear, given the absence of suitable Text-to-SQL benchmarks tailored to enterprise settings. Additionally, the potential of Knowledge Graphs (KGs) to enhance LLM-based question answering by providing business context is not well understood. This study aims to evaluate the accuracy of LLM-powered question answering systems in the context of enterprise questions and SQL databases, while also exploring the role of knowledge graphs in improving accuracy. To achieve this, we introduce a benchmark comprising an enterprise SQL schema in the insurance domain, a range of enterprise queries encompassing reporting to metrics, and a contextual layer incorporating an ontology and mappings that define a knowledge graph. Our primary finding reveals that question answering using GPT-4, with zero-shot prompts directly on SQL databases, achieves an accuracy of 16\%. Notably, this accuracy increases to 54\% when questions are posed over a Knowledge Graph representation of the enterprise SQL database. Therefore, investing in Knowledge Graph provides higher accuracy for LLM powered question answering systems.},
	booktitle = {Proceedings of the 7th {Joint} {Workshop} on {Graph} {Data} {Management} {Experiences} \&amp; {Systems} ({GRADES}) and {Network} {Data} {Analytics} ({NDA})},
	publisher = {Association for Computing Machinery},
	author = {Sequeda, Juan and Allemang, Dean and Jacob, Bryon},
	year = {2024},
	note = {event-place: Santiago, AA, Chile},
}

@inproceedings{ardimento_rag-based_2024,
	address = {New York, NY, USA},
	series = {{MODELS} {Companion} '24},
	title = {A {RAG}-based {Feedback} {Tool} to {Augment} {UML} {Class} {Diagram} {Learning}},
	isbn = {979-8-4007-0622-6},
	url = {https://doi.org/10.1145/3652620.3687784},
	doi = {10.1145/3652620.3687784},
	abstract = {This paper introduces an advanced functionality designed to facilitate the learning of UML class diagram construction. Built upon an integrated Retrieval Augmented Generation Large Language Model, the functionality provides enriched feedback by leveraging accumulated knowledge. The functionality is implemented in an existing tool named UML Miner, a Visual Paradigm plugin that captures and analyzes student-generated UML diagrams by applying process mining techniques. By offering personalized feedback and continuous support during modeling, the tool aims to enhance learning outcomes and students' engagement.},
	booktitle = {Proceedings of the {ACM}/{IEEE} 27th {International} {Conference} on {Model} {Driven} {Engineering} {Languages} and {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ardimento, Pasquale and Bernardi, Mario Luca and Cimitile, Marta and Scalera, Michele},
	year = {2024},
	note = {event-place: Linz, Austria},
	keywords = {large language model, learning, retrieval augmented generation, software modeling, tool, UML},
	pages = {26--30},
}

@inproceedings{wu_research_2025,
	address = {New York, NY, USA},
	series = {{BDAIE} '25},
	title = {Research on {Intelligent} {Generation} {Method} of {Test} {Questions} in {Communication} {Operation} and {Maintenance} {Field} {Based} on {Knowledge} {Enhancement}},
	isbn = {979-8-4007-1601-0},
	url = {https://doi.org/10.1145/3767052.3767087},
	doi = {10.1145/3767052.3767087},
	abstract = {With the acceleration of technological iteration, the intelligent transformation of communication operation and maintenance urgently requires supporting talent assessment tools. Currently, traditional test question generation methods rely on static knowledge bases and manual writing. This article proposes an intelligent test question generation method based on knowledge enhancement to address the problems of knowledge update lag and insufficient scene generalization in traditional test question generation methods. By integrating technologies such as Large Language Model (LLM) and Retrieval-Augmented Generation (RAG), a professional vector knowledge base in the field of communication operation and maintenance is constructed. The RAG process is optimized to suppress the illusion of LLM and achieve intelligent generation of operation and maintenance test questions. This provides an efficient and customizable intelligent solution for evaluating the abilities of communication operation and maintenance talents.},
	booktitle = {Proceedings of the 2025 {International} {Conference} on {Big} {Data}, {Artificial} {Intelligence} and {Digital} {Economy}},
	publisher = {Association for Computing Machinery},
	author = {Wu, Wei and Liu, Zhiruo and Ma, Junfeng and Cao, Jiguang},
	year = {2025},
	keywords = {Intelligent generation of test questions, Large Language Model, Retrieval-Augmented Generation},
	pages = {227--233},
}

@inproceedings{sharma_enhancing_2025,
	address = {New York, NY, USA},
	series = {{IWSPA} '25},
	title = {Enhancing {Security} {Insights} with {KnowGen}-{RAG}: {Combining} {Knowledge} {Graphs}, {LLMs}, and {Multimodal} {Interpretability}},
	isbn = {979-8-4007-1501-3},
	url = {https://doi.org/10.1145/3716815.3729012},
	doi = {10.1145/3716815.3729012},
	abstract = {We present a hybrid Retrieval-Augmented Generation (RAG) framework KnowGen-RAG that integrates knowledge graphs comprising entities and relationships and LLM-based Natural Language Generation for application security, privacy, and compliance. The framework aims to enhance the accuracy and relevance of retrieved information to produce more context-aware and actionable security recommendations, identify potential privacy risks, and detect vulnerabilities by utilizing structured knowledge about entities (e.g., access control mechanisms, security policies, privacy-preserving algorithms, protocols, software vulnerabilities) and their inter-relationships in the security context. We also extend the multimodal-LLM interpretability paradigm by contextual explanation generation for equations and tables from unstructured and highly technical documents. KnowGen-RAG proves superior for security-related information retrieval and contextual reasoning. It significantly outperforms both the LLM's output without RAG and Baseline RAG in terms of preciseness and reliability. Specifically, KnowGen-RAG increases accuracy for the CyberMetric dataset, where the original approach struggled to perform consistently for lightweight LLMs, and Baseline RAG achieved only marginal improvements. Additionally, KnowGen-RAG enhances answer quality for our curated security dataset, SecMD, demonstrating its effectiveness and improved understanding of security-related techniques and digital artifacts when addressing complex questions. The system aims to strengthen the learning of security professionals by providing thorough insights into the security landscape, encouraging informed decision-making in the face of sophisticated challenges.},
	booktitle = {Proceedings of the 10th {ACM} {International} {Workshop} on {Security} and {Privacy} {Analytics}},
	publisher = {Association for Computing Machinery},
	author = {Sharma, Arnav Nishith and Akbar, Khandakar Ashrafi and Thuraisingham, Bhavani and Khan, Latifur},
	year = {2025},
	note = {event-place: Pittsburgh, PA, USA},
	keywords = {application security, knowledge graphs, multimodal llm interpretability, retrieval-augmented generation},
	pages = {2--12},
}

@inproceedings{meda_integrating_2025,
	address = {New York, NY, USA},
	series = {{ACMSE} 2025},
	title = {Integrating {Prompt} {Structures} {Using} {LLM} {Embeddings} for {Cybersecurity} {Threats}},
	isbn = {979-8-4007-1277-7},
	url = {https://doi.org/10.1145/3696673.3723069},
	doi = {10.1145/3696673.3723069},
	abstract = {This paper aims to develop a specialized Large Language Model (LLM) for cybersecurity training, designed to educate users on fundamental cybersecurity concepts. This paper focuses on creating an interactive system where users can ask questions about computer security and receive accurate, informative responses. By addressing cybersecurity as a critical national issue, the LLM empowers individuals and organizations to defend against malicious cyber threats. Our system was developed using Python, utilizing Google Sheets as a database, Gradio for the user interface, and Google Gemini's API for advanced language processing. The implementation followed a test-driven development approach, iterating between coding and testing to ensure functionality and reliability. Key technologies include Mistral's Large 2 model and embedding models for clustering related data. The Retrieval-Augmented Generation (RAG) framework was employed to integrate information retrieval with the LLM, enhancing its accuracy and relevance. Tools such as Google Suite, Colab, and Gradio contributed to creating a robust and user-friendly system. This paper highlights the potential of domain-specific LLMs, offering a practical solution to the growing need for accessible cybersecurity education and fostering awareness to mitigate the risks posed by malicious hackers.},
	booktitle = {Proceedings of the 2025 {ACM} {Southeast} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Meda, Kavya Nikhita and Nara, Pavan Subhash Chandrabose and Bozenka, Svoboda and Zormati, Tarek and Turner, Seth and Worley, Wayne and Mitra, Reshmi},
	year = {2025},
	note = {event-place: Southeast Missouri State University, Cape Girardeau, MO, USA},
	keywords = {cybersecurity education, embedding models, information retrieval, large language model (LLM), retrieval-augmented generation (RAG)},
	pages = {180--187},
}

@inproceedings{gienapp_viability_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {The {Viability} of {Crowdsourcing} for {RAG} {Evaluation}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730093},
	doi = {10.1145/3726302.3730093},
	abstract = {How good are humans at writing and judging responses in retrieval-augmented generation (RAG) scenarios? To answer this question, we investigate the efficacy of crowdsourcing for RAG through two complementary studies: response writing and response utility judgment. Our new Webis Crowd RAG Corpus 2025 (Webis-CrowdRAG-25) consists of 903 human-written and 903 LLM-generated responses for the 301 topics of the TREC 2024 RAG track, with each response composed according to one of the three discourse styles 'bullet list', 'essay', or 'news'. For a selection of 65 topics, the corpus further contains 47,320 pairwise human judgments and 10,556 pairwise LLM judgments across seven utility dimensions (e.g., coverage and coherence). Our analyses give insights into human writing behavior for RAG and the viability of crowdsourcing for RAG evaluation. We find that human pairwise judgments provide reliable and cost-effective results. This is much less the case for LLM-based pairwise and human/LLM-based pointwise judgments, nor for automated comparisons with human-written reference responses. All our data and tools are freely available.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Gienapp, Lukas and Hagen, Tim and Fröbe, Maik and Hagen, Matthias and Stein, Benno and Potthast, Martin and Scells, Harrisen},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {crowdsourcing, evaluation, retrieval-augmented generation},
	pages = {159--169},
}

@inproceedings{akewar_can_2025,
	address = {New York, NY, USA},
	series = {{HotStorage} '25},
	title = {Can {LLMs} {Model} the {Environmental} {Impact} on {SSD}?},
	isbn = {979-8-4007-1947-9},
	url = {https://doi.org/10.1145/3736548.3737835},
	doi = {10.1145/3736548.3737835},
	abstract = {Environmental stressors such as temperature, humidity, vibration, and radiation can severely impact the performance and reliability of SSDs, particularly in edge, automotive, aerospace, and datacenter deployments. Capturing sensor data in the field and conducting accelerated lab experiments are challenging, as they are time-consuming, resource-intensive, and often destructive to hardware. Specialized setups, such as thermal chambers or vibration rigs, are also required, which is why few studies explore this area, and current storage management techniques like RAID, tiering, and deduplication do not consider environmental factors. Models to capture these impacts would open new research opportunities across various fields. However, accurately modeling these effects remains challenging due to, (1) the limited availability of experimental data, (2) the complex, domino-like impact of historical exposure, (3) the interrelated nature of environmental factors, such as temperature and humidity, which exhibit correlation, (4) different response of each type of NAND flash memory TLC, MLC, and SLC to environmental factors, and (5) the difficulty that analytical and simple machine learning models face in generalizing across devices, environments, and unseen combinations of stressors. We believe that LLMs may offer a transformative alternative to this complex problem, with embedded domain knowledge and reasoning capabilities, to facilitate prompt-based natural language interaction. We propose a hybrid framework that combines Chain-of-Thought prompting and Retrieval-Augmented Generation to guide LLMs using physical principles and prior experiments. It enables interpretable "what-if" analysis of SSD behavior under environmental changes. Our results show that the LLM can effectively model the impact of temperature, humidity, and vibration on SSD performance, producing tail latency and bandwidth predictions with minimal error. The code and data are available on GitHub at https://github.com/Damrl-lab/SSD\_LLM.},
	booktitle = {Proceedings of the 17th {ACM} {Workshop} on {Hot} {Topics} in {Storage} and {File} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Akewar, Mayur and Quan, Gang and Madireddy, Sandeep and Bhimani, Janki},
	year = {2025},
	note = {event-place: Boston, MA, USA},
	keywords = {Large Language Model, Prompt Engineering, Retrieval Augmented Generation, Solid State Drive},
	pages = {100--106},
}

@inproceedings{yu_rag-guided_2024,
	address = {New York, NY, USA},
	series = {{MM} '24},
	title = {{RAG}-{Guided} {Large} {Language} {Models} for {Visual} {Spatial} {Description} with {Adaptive} {Hallucination} {Corrector}},
	isbn = {979-8-4007-0686-8},
	url = {https://doi.org/10.1145/3664647.3688990},
	doi = {10.1145/3664647.3688990},
	abstract = {Visual Spatial Description (VSD) is an emerging image-to-text task which aims at generating descriptions of the spatial relationships between given objects in an image. In this paper, we apply Retrieval-Augmented Generation (RAG) technology in guiding Multimodal Large Language Models (MLLMs) for the task of VSD, complemented by an Adaptive Hallucination Corrector, and further fine-tuning them to bolster semantic understanding and overall model efficacy. We found that our approach demonstrated higher accuracy and fewer hallucination errors in both spatial relationship classification and visual language description tasks within the VSD task, achieving state-of-the-art results.},
	booktitle = {Proceedings of the 32nd {ACM} {International} {Conference} on {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Yu, Jun and Zhang, Yunxiang and Zhang, Zerui and Yang, Zhao and Zhao, Gongpeng and Sun, Fengzhao and Zhang, Fanrui and Liu, Qingsong and Sun, Jianqing and Liang, Jiaen and Zhang, Yaohui},
	year = {2024},
	note = {event-place: Melbourne VIC, Australia},
	keywords = {hallucination, retrieval-augmented generation, visual spatial description},
	pages = {11407--11413},
}

@inproceedings{brachman_building_2025,
	address = {New York, NY, USA},
	series = {{IUI} '25},
	title = {Building {Appropriate} {Mental} {Models}: {What} {Users} {Know} and {Want} to {Know} about an {Agentic} {AI} {Chatbot}},
	isbn = {979-8-4007-1306-4},
	url = {https://doi.org/10.1145/3708359.3712071},
	doi = {10.1145/3708359.3712071},
	abstract = {Agentic systems aim to handle complex problems with increasing system autonomy using generative AI. These new agentic systems are becoming more feasible and easier to build. Yet we know little about what end-users need to know to use these systems appropriately. We study one such agentic system, “Gent,” which can break down complex problems into a set of actions, provide a rationale for each action, interact with external information, and cite its sources. Our goals were to understand users’ mental models of the agentic system, the information users leveraged to evaluate the accuracy of the system, and users’ information needs. In our study (N=24), participants interacted with Gent for four information seeking tasks where they could see Gent’s actions, rationale, and sources. Participants’ mental models centered around the search-like qualities of the system, with their confidence impacted by the website sources. Participants’ mental models often lacked insight into the workings of the generative AI model and agentic framework that impact the actions the system takes. Participants used the descriptions of the system’s actions to support their evaluation of the accuracy of the system and wanted to know more about how the system got to its answers. Participants also relied on their own personal knowledge and the style or length of Gent’s responses to evaluate the accuracy. Our results highlight the need for further transparency in agentic AI systems to support end-users in evaluating system outputs and help them build effective mental models.},
	booktitle = {Proceedings of the 30th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Brachman, Michelle and Kunde, Siya and Miller, Sarah and Fucs, Ana and Dempsey, Samantha and Jabbour, Jamie and Geyer, Werner},
	year = {2025},
	keywords = {Agentic AI, Conversational UI, Explainable AI, Generative AI, Information Seeking, Mental Models, Reliance, Transparency},
	pages = {247--264},
}

@inproceedings{su_mitigating_2024,
	address = {New York, NY, USA},
	series = {{SIGIR}-{AP} 2024},
	title = {Mitigating {Entity}-{Level} {Hallucination} in {Large} {Language} {Models}},
	isbn = {979-8-4007-0724-7},
	url = {https://doi.org/10.1145/3673791.3698403},
	doi = {10.1145/3673791.3698403},
	abstract = {The emergence of Large Language Models (LLMs) has revolutionized how users access information, shifting from traditional search engines to direct question-and-answer interactions with LLMs. However, the widespread adoption of LLMs has revealed a significant challenge known as hallucination, wherein LLMs generate coherent yet factually inaccurate responses. This hallucination phenomenon has led to users' distrust in information retrieval systems based on LLMs. To tackle this challenge, this paper proposes Dynamic Retrieval Augmentation based on hallucination Detection (DRAD) as a novel method to detect and mitigate hallucinations in LLMs. DRAD improves upon traditional retrieval augmentation by dynamically adapting the retrieval process based on real-time hallucination detection. It features two main components: Real-time Hallucination Detection (RHD) for identifying potential hallucinations without external models, and Self-correction based on External Knowledge (SEK) for correcting these errors using external knowledge. Experiment results show that DRAD demonstrates superior performance in both detecting and mitigating hallucinations in LLMs. All of our code and data are open-sourced at https://github.com/oneal2000/EntityHallucination.},
	booktitle = {Proceedings of the 2024 {Annual} {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval} in the {Asia} {Pacific} {Region}},
	publisher = {Association for Computing Machinery},
	author = {Su, Weihang and Tang, Yichen and Ai, Qingyao and Wang, Changyue and Wu, Zhijing and Liu, Yiqun},
	year = {2024},
	note = {event-place: Tokyo, Japan},
	keywords = {Hallucination, Large Language Model, Retrieval Augmented Generation},
	pages = {23--31},
}

@inproceedings{chen_towards_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {Towards {Mitigating} {API} {Hallucination} in {Code} {Generated} by {LLMs} with {Hierarchical} {Dependency} {Aware}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3728569},
	doi = {10.1145/3696630.3728569},
	abstract = {Application Programming Interfaces (APIs) are crucial in modern software development. Large Language Models (LLMs) assist in automated code generation but often struggle with API hallucination, including invoking non-existent APIs and misusing existing ones in practical development scenarios. Existing studies resort to Retrieval-Augmented Generation (RAG) methods for mitigating the hallucination issue, but tend to fail since they generally ignore the structural dependencies in practical projects and do not indeed validate whether the generated APIs are available or not. To address these limitations, we propose MARIN, a framework for mitigating API hallucination in code generated by LLMs with hierarchical dependency aware. MARIN consists of two phases: Hierarchical Dependency Mining, which analyzes local and global dependencies of the current function, aiming to supplement comprehensive project context in LLMs' input, and Dependency Constrained Decoding, which utilizes mined dependencies to adaptively constrain the generation process, aiming to ensure the generated APIs align with the project's specifications. To facilitate the evaluation of the degree of API hallucination, we introduce a new benchmark APIHul-Bench and two new metrics including Micro Hallucination Number (MiHN) and Macro Hallucination Rate (MaHR). Experiments on six state-of-the-art LLMs demonstrate that MARIN effectively reduces API hallucinations, achieving an average decrease of 67.52\% in MiHN and 73.56\% in MaHR compared to the RAG approach. Applied to Huawei's internal projects and two proprietary LLMs, MARIN achieves average decreases of 57.33\% in MiHN and 59.41\% in MaHR.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Yujia and Chen, Mingyu and Gao, Cuiyun and Jiang, Zhihan and Li, Zhongqi and Ma, Yuchi},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {code generation, large language model, LLM hallucination},
	pages = {468--479},
}

@inproceedings{qi_rag-optimized_2025,
	address = {New York, NY, USA},
	series = {{AIPR} '24},
	title = {{RAG}-{Optimized} {Tibetan} {Tourism} {LLMs}: {Enhancing} {Accuracy} and {Personalization}},
	isbn = {979-8-4007-1717-8},
	url = {https://doi.org/10.1145/3703935.3704112},
	doi = {10.1145/3703935.3704112},
	abstract = {With the development of the modern social economy, tourism has become an important way to meet people’s spiritual needs, bringing development opportunities to the tourism industry. However, existing large language models (LLMs) face challenges in personalized recommendation capabilities and the generation of content that can sometimes produce hallucinations. This study proposes an optimization scheme for Tibet tourism LLMs based on retrieval-augmented generation (RAG) technology. By constructing a database of tourist viewpoints and processing the data using vectorization techniques, we have significantly improved retrieval accuracy. The application of RAG technology effectively addresses the hallucination problem in content generation. The optimized model shows significant improvements in fluency, accuracy, and relevance of content generation. This research demonstrates the potential of RAG technology in the standardization of cultural tourism information and data analysis, providing theoretical and technical support for the development of intelligent cultural tourism service systems.},
	booktitle = {Proceedings of the 2024 7th {International} {Conference} on {Artificial} {Intelligence} and {Pattern} {Recognition}},
	publisher = {Association for Computing Machinery},
	author = {Qi, Jinhu and Yan, Shuai and Zhang, Yibo and Zhang, Wentao and Jin, Rong and Hu, Yuwei and Wang, Ke},
	year = {2025},
	keywords = {Hallucination Problem, Large Language Models, Retrieval-Augmented Generation, Vector Databases},
	pages = {1185--1192},
}

@inproceedings{feng_enabling_2024,
	address = {New York, NY, USA},
	series = {{ASE} '24},
	title = {Enabling {Cost}-{Effective} {UI} {Automation} {Testing} with {Retrieval}-{Based} {LLMs}: {A} {Case} {Study} in {WeChat}},
	isbn = {979-8-4007-1248-7},
	url = {https://doi.org/10.1145/3691620.3695260},
	doi = {10.1145/3691620.3695260},
	abstract = {UI automation tests play a crucial role in ensuring the quality of mobile applications. Despite the growing popularity of machine learning techniques to generate these tests, they still face several challenges, such as the mismatch of UI elements. The recent advances in Large Language Models (LLMs) have addressed these issues by leveraging their semantic understanding capabilities. However, a significant gap remains in applying these models to industrial-level app testing, particularly in terms of cost optimization and knowledge limitation. To address this, we introduce CAT to create cost-effective UI automation tests for industry apps by combining machine learning and LLMs with best practices. Given the task description, CAT employs Retrieval Augmented Generation (RAG) to source examples of industrial app usage as the few-shot learning context, assisting LLMs in generating the specific sequence of actions. CAT then employs machine learning techniques, with LLMs serving as a complementary optimizer, to map the target element on the UI screen. Our evaluations on the WeChat testing dataset demonstrate the CAT's performance and cost-effectiveness, achieving 90\% UI automation with \$0.34 cost, outperforming the state-of-the-art. We have also integrated our approach into the real-world WeChat testing platform, demonstrating its usefulness in detecting 141 bugs and enhancing the developers' testing process.},
	booktitle = {Proceedings of the 39th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Feng, Sidong and Lu, Haochuan and Jiang, Jianqin and Xiong, Ting and Huang, Likun and Liang, Yinglin and Li, Xiaoqin and Deng, Yuetang and Aleti, Aldeida},
	year = {2024},
	note = {event-place: Sacramento, CA, USA},
	keywords = {cost optimization, large language model, retrieval-augmented generation, UI automation test},
	pages = {1973--1978},
}

@inproceedings{lee_talkin_2024,
	address = {New York, NY, USA},
	series = {{CSLAW} '24},
	title = {Talkin' '{Bout} {AI} {Generation}: {Copyright} and the {Generative}-{AI} {Supply} {Chain} ({The} {Short} {Version})},
	isbn = {979-8-4007-0333-1},
	url = {https://doi.org/10.1145/3614407.3643696},
	doi = {10.1145/3614407.3643696},
	abstract = {"Does generative AI infringe copyright?" is an urgent question. It is also a difficult question, for two reasons. First, "generative AI" is not just one product from one company. It is a catch-all name for a massive ecosystem of loosely related technologies. These systems behave differently and raise different legal issues. Second, copyright law is notoriously complicated, and generative-AI systems manage to touch on a great many corners of it. They raise issues of authorship, similarity, direct and indirect liability, and fair use, among much else. These issues cannot be analyzed in isolation, because there are connections everywhere. We aim to bring order to the chaos. To do so, we introduce the generative-AI supply chain: an interconnected set of stages that transform training data into generations. The supply chain reveals all of the places at which companies and users make choices that have copyright consequences. It enables us to trace the effects of upstream technical designs on downstream uses, and to assess who in these complicated sociotechnical systems bears responsibility for infringement when it happens. Because we engage so closely with the technology of generative AI, we are able to shed more light on the copyright questions. We identify the key decisions that courts will need to make as they grapple with these issues, and point out the consequences that would likely flow from different liability regimes. This article is a much-abbreviated version of a forthcoming law review article at The Journal of the Copyright Society.},
	booktitle = {Proceedings of the 2024 {Symposium} on {Computer} {Science} and {Law}},
	publisher = {Association for Computing Machinery},
	author = {Lee, Katherine and Cooper, A. Feder and Grimmelmann, James},
	year = {2024},
	note = {event-place: Boston, MA, USA},
	pages = {48--63},
}

@inproceedings{yamane_chimera-vdb_2025,
	address = {New York, NY, USA},
	series = {{APSys} '25},
	title = {Chimera-{VDB}: {Mixed}-{Precision} {Vector} {Database} with {HNSW} {Index} for {RAG}-{LLM}},
	isbn = {979-8-4007-1572-3},
	url = {https://doi.org/10.1145/3725783.3764411},
	doi = {10.1145/3725783.3764411},
	abstract = {In recent years, vector databases have become a core component in Retrieval-Augmented Generation (RAG) systems for Large Language Models (LLM), enabling fast retrieval of documents similar to a given query. However, storing a large number of high-dimensional vectors requires substantial storage capacity. A common solution is to reduce vector precision through quantization, but this often degrades retrieval recall. To address this trade-off, we propose Chimera-VDB, which uses a mixture of high- and low-precision vectors to reduce data size while maintaining retrieval recall. Our approach leverages the graph structure of Hierarchical Navigable Small World (HNSW) networks, selectively preserving only the most search-critical vectors in high-precision, while quantizing the rest to lower precision. Experimental results show that our method reduces storage usage to 24\% compared to storing all vectors in FP32, while maintaining 93\% recall, demonstrating its effectiveness in balancing storage capacity and retrieval performance.},
	booktitle = {Proceedings of the 16th {ACM} {SIGOPS} {Asia}-{Pacific} {Workshop} on {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Yamane, Naoshi and Zielewski, Michael Ryan and Nakamura, Takaki and Suganuma, Takuo},
	year = {2025},
	note = {event-place: Lotte Hotel World, Emerald Hall, Seoul, Republic of Korea},
	keywords = {embedding vectors, hierarchical navigable small world, large language models, quantization, retrieval-augmented generation, storage usage, vector database},
	pages = {61--67},
}

@inproceedings{zhang_towards_2025,
	address = {New York, NY, USA},
	series = {{ICMR} '25},
	title = {Towards {Comprehensive} {Legal} {Document} {Analysis}: {A} {Multi}-{Round} {RAG} {Approach}},
	isbn = {979-8-4007-1877-9},
	url = {https://doi.org/10.1145/3731715.3733451},
	doi = {10.1145/3731715.3733451},
	abstract = {Legal document review is a time-consuming and highly specialized task, and the capabilities of intelligent legal review systems are limited and insufficient to complete detailed reviews. Traditional methods struggle with cross-references, dependencies, and context-dependent clauses. Our work introduces a multi-round RAG framework for legal document analysis, which iteratively refines queries and aggregates context to improve recall and understanding. Experiments on diverse contracts show a recall of 78.67\%, outperforming baseline (57.33\%) and single-round RAG (74.67\%). Our analysis shows that iterative refinement effectively filters irrelevant results despite reduced precision. The multi-round approach halves missed cross-clause dependencies but reveals limitations in numerical consistency and obligation scope detection. These insights advance RAG for legal applications and provide a foundation for future work on scalable and accurate contract review.},
	booktitle = {Proceedings of the 2025 {International} {Conference} on {Multimedia} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Wutong and Zhou, Hefeng and Zhou, Qiang and Li, Yunshen and Liu, Yuxin and Lou, Jiong and Wu, Chentao and Li, Jie},
	year = {2025},
	note = {event-place: Chicago, IL, USA},
	keywords = {contract review, document retrieval, large language model, multi-round retrieval, retrieval-augmented generation},
	pages = {1840--1848},
}

@inproceedings{vassos_now_2024,
	address = {New York, NY, USA},
	series = {{SETN} '24},
	title = {Now {I} know! {Empowering} {Voters} with {RAG}-enabled {LLMs} to {Eliminate} {Political} {Uncertainty}},
	isbn = {979-8-4007-0982-1},
	url = {https://doi.org/10.1145/3688671.3688784},
	doi = {10.1145/3688671.3688784},
	abstract = {Accurate political information is vital for voters to make informed decisions. However, due to the plethora of data and biased sources, accessing concise, factual information still remains a challenge. To tackle this problem, we present an open-access, deployed digital assistant powered by Large Language Models (LLMs), specifically tailored to answer voters’ questions and help them vote for the political party they mostly align with. The user can select up to 3 parties, input their question, and get short, summarized answers from the parties’ published political agendas, which contain hundreds of pages and, thus, are difficult to navigate for the typical citizen. Our NLP system architecture leverages OpenAI’s GPT-4 and incorporates Retrieval-Augmented Generation with Citations (RAG+C) to integrate custom data into LLMs effectively and build user trust. We also describe our database design, underlining the use of an open-source vector database, optimized for high-dimensional semantic search across multiple documents, and a semantic-rich LLM cache, reducing operational expenses and end-user latency time. Our open-access system supports Greek and English and has been deployed live at https://toraksero.gr/for the Greek 2023 Elections, which gathered 30K user sessions and 74\% user satisfaction.},
	booktitle = {Proceedings of the 13th {Hellenic} {Conference} on {Artificial} {Intelligence}},
	publisher = {Association for Computing Machinery},
	author = {Vassos, Stavros and Goudelis, Stratos and Balaouras, Dimi and Vitalis, Giannis and Nakos, Vasilis and Pigka, Glykeria and Tsagkli, Loukia and Hatzikou, Menia and Tsionas, Zachos and Chasanis, Alexandros and van de Burgt, Stan and Pors, Mark and Papadoudis, Stratos and Loukas, Lefteris},
	year = {2024},
	keywords = {Deployment, LLMs, NLP, Open-Access Software, Open-Book QA, OpenAI, RAG+C, Retrieval-Augmented Generation},
}

@inproceedings{su_judge_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{JuDGE}: {Benchmarking} {Judgment} {Document} {Generation} for {Chinese} {Legal} {System}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730295},
	doi = {10.1145/3726302.3730295},
	abstract = {This paper introduces JuDGE (Judgment Document Generation Evaluation), a novel benchmark for evaluating the performance of judgment document generation in the Chinese legal system. We define the task as generating a complete legal judgment document from the given factual description of the case. To facilitate this benchmark, we construct a comprehensive dataset consisting of factual descriptions from real legal cases, paired with their corresponding full judgment documents, which serve as the ground truth for evaluating the quality of generated documents. This dataset is further augmented by two external legal corpora that provide additional legal knowledge for the task: one comprising statutes and regulations, and the other consisting of a large collection of past judgment documents. In collaboration with legal professionals, we establish a comprehensive automated evaluation framework to assess the quality of generated judgment documents across various dimensions. We evaluate various baseline approaches, including few-shot in-context learning, fine-tuning, and a multi-source retrieval-augmented generation (RAG) approach, using both general and legal-domain LLMs. The experimental results demonstrate that, while RAG approaches can effectively improve performance in this task, there is still substantial room for further improvement. All the codes and datasets are available at: https://github.com/oneal2000/JuDGE},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Su, Weihang and Yue, Baoqing and Ai, Qingyao and Hu, Yiran and Li, Jiaqi and Wang, Changyue and Zhang, Kaiyuan and Wu, Yueyue and Liu, Yiqun},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {domain-specific evaluation, judgment document generation, large language model, retrieval augmented generation},
	pages = {3573--3583},
}

@inproceedings{signe_substring_2025,
	address = {New York, NY, USA},
	series = {{ICTIR} '25},
	title = {A {Substring} {Extraction}-{Based} {RAG} {Method} for {Minimising} {Hallucinations} in {Aircraft} {Maintenance} {Question} {Answering}},
	isbn = {979-8-4007-1861-8},
	url = {https://doi.org/10.1145/3731120.3744624},
	doi = {10.1145/3731120.3744624},
	abstract = {Hallucination occurs when a language model generates plausible yet nonfactual information. In particular, faithfulness hallucinations (inconsistency with a given context) cannot be tolerated in critical domains such as aircraft maintenance due to the potentially severe consequences. To mitigate this issue, Retrieval Augmented Generation (RAG) methods have been introduced. These approaches are relevant for reducing the risks of hallucination but do not eliminate them, as the generator may still produce content unfaithful to the retrieved context. This paper proposes a novel RAG approach that leverages a substring extraction tool from retrieved documents to minimise hallucinations. Experiments performed on real aircraft maintenance documentation revealed that, despite the lower accuracy of the answers compared to traditional RAG methods, the proposed approach demonstrates an improved control over hallucination risks. This highlights the potential of our method in highly technical use cases where accuracy and reliability are key.},
	booktitle = {Proceedings of the 2025 {International} {ACM} {SIGIR} {Conference} on {Innovative} {Concepts} and {Theories} in {Information} {Retrieval} ({ICTIR})},
	publisher = {Association for Computing Machinery},
	author = {Signé, Quentin and Boughanem, Mohand and Moreno, Jose G. and Belkacem, Thiziri},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {question answering, retrieval augmented generation, technical maintenance},
	pages = {513--521},
}

@inproceedings{huang_ket-rag_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{KET}-{RAG}: {A} {Cost}-{Efficient} {Multi}-{Granular} {Indexing} {Framework} for {Graph}-{RAG}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737012},
	doi = {10.1145/3711896.3737012},
	abstract = {Graph-RAG constructs a knowledge graph from text chunks to improve retrieval in Large Language Model (LLM)-based question answering. It is particularly useful in domains such as biomedicine, law, and political science, where retrieval often requires multi-hop reasoning over proprietary documents. Some existing Graph-RAG systems construct KNN graphs based on text chunk relevance, but this coarse-grained approach fails to capture entity relationships within texts, leading to sub-par retrieval and generation quality. To address this, recent solutions leverage LLMs to extract entities and relationships from text chunks, constructing triplet-based knowledge graphs. However, this approach incurs significant indexing costs, especially for large document collections. To ensure a good result accuracy while reducing the indexing cost, we propose KET-RAG, a multi-granular indexing framework. KET-RAG first identifies a small set of key text chunks and leverages an LLM to construct a knowledge graph skeleton. It then builds a text-keyword bipartite graph from all text chunks, serving as a lightweight alternative to a full knowledge graph. During retrieval, KET-RAG searches both structures: it follows the local search strategy of existing Graph-RAG systems on the skeleton while mimicking this search on the bipartite graph to improve retrieval quality. We evaluate 13 solutions on three real-world datasets, demonstrating that KET-RAG outperforms all competitors in indexing cost, retrieval effectiveness, and generation quality. Notably, it achieves comparable or superior retrieval quality to Microsoft's Graph-RAG while reducing indexing costs by over an order of magnitude. Additionally, it improves the generation quality by up to 32.4\% while lowering indexing costs by around 20\%.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Huang, Yiqian and Zhang, Shiqi and Xiao, Xiaokui},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {graphrag, indexing, retrieval-augmented generation},
	pages = {1003--1012},
}

@inproceedings{ngo_legal_2025,
	address = {New York, NY, USA},
	series = {{ICIIT} '25},
	title = {Legal {Documents} {Query} {Application} for {Vietnamese} {Law} {Using} {LLM} and {RAG} {Techniques}},
	isbn = {979-8-4007-1084-1},
	url = {https://doi.org/10.1145/3731763.3731802},
	doi = {10.1145/3731763.3731802},
	abstract = {This paper introduces the development of a Legal Documents Query Application for Vietnamese law, leveraging Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) techniques. It outlines the methodologies employed, addresses key challenges, and highlights the significance of the application in improving the accuracy and efficiency of legal document retrieval in specialized domains. By combining cutting-edge AI techniques with domain-specific optimizations, the proposed solution aims to enhance access to legal information for a wide range of users.},
	booktitle = {Proceedings of the 2025 10th {International} {Conference} on {Intelligent} {Information} {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Ngo, Anh Tuan and Doan, Trung Tung and Ngo, Tung Thanh and Nguyen, Viet Hoang},
	year = {2025},
	keywords = {Large Language Models, Legal AI, Legal Document Retrieval, Natural Language Processing, Retrieval-Augmented Generation, Semantic Search, Vietnamese Law},
	pages = {152--157},
}

@inproceedings{arefeen_irag_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {{iRAG}: {Advancing} {RAG} for {Videos} with an {Incremental} {Approach}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3680088},
	doi = {10.1145/3627673.3680088},
	abstract = {Retrieval-augmented generation (RAG) systems combine the strengths of language generation and information retrieval to power many real-world applications like chatbots. Use of RAG for understanding of videos is appealing but there are two critical limitations. One-time, upfront conversion of all content in large corpus of videos into text descriptions entails high processing times. Also, not all information in the rich video data is typically captured in the text descriptions. Since user queries are not known apriori, developing a system for video to text conversion and interactive querying of video data is challenging. To address these limitations, we propose an incremental RAG system called iRAG, which augments RAG with a novel incremental workflow to enable interactive querying of a large corpus of videos. Unlike traditional RAG, iRAG quickly indexes large repositories of videos, and in the incremental workflow, it uses the index to opportunistically extract more details from select portions of the videos to retrieve context relevant to an interactive user query. Such an incremental workflow avoids long video to text conversion times, and overcomes information loss issues due to conversion of video to text, by doing on-demand query-specific extraction of details in video data. This ensures high quality of responses to interactive user queries that are often not known apriori. To the best of our knowledge, iRAG is the first system to augment RAG with an incremental workflow to support efficient interactive querying of a large corpus of videos. Experimental results on real-world datasets demonstrate 23x to 25x faster video to text ingestion, while ensuring that latency and quality of responses to interactive user queries is comparable to responses from a traditional RAG where all video data is converted to text upfront before any user querying.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Arefeen, Md Adnan and Debnath, Biplob and Uddin, Md Yusuf Sarwar and Chakradhar, Srimat},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {generative ai, large language models (llms), retrieval augmented generation (rag), video analytics, vision language models (vlms)},
	pages = {4341--4348},
}

@inproceedings{yang_boosting_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {Boosting {E}-commerce {Content} {Diversity}: {A} {Graph}-based {RAG} {Approach} with {User} {Reviews}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3736864},
	doi = {10.1145/3711896.3736864},
	abstract = {In e-commerce, product descriptions and other forms of copywriting play a critical role in shaping consumer purchasing decisions. However, manually crafting such content is both time-consuming and costly, particularly given the vast and diverse item catalogs. Recent advances in large language models (LLMs) have transformed automated text generation, offering immense potential to streamline this process. Despite their capabilities, LLMs continue to face obstacles in e-commerce applications, including a lack of diversity and an inability to fully grasp the nuanced details of specific items. To address these limitations, we propose a novel framework that integrates graph-based knowledge into Retrieval-Augmented Generation (RAG) to enhance content generation. Our approach leverages user reviews to construct an item-feature graph, capturing both explicit and implicit connections between items and features. This structured representation enables the retrieval of diverse, contextually relevant, and factually grounded information, effectively addressing key deficiencies of existing methods. With the constructed graph, we design a graph traversal mechanism that explores a broader range of item-related features, augmenting the generation process with more varied and informative inputs. Extensive experiments demonstrate that our method significantly improves diversity while preserving fidelity, marking a major advancement in automated e-commerce content generation.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Yang, Jiaxi and Jia, Yiling and Yang, Carl and Liang, Yi and Lin, Lu},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {copywriting generation, e-commerce, graph traversal, large language models, retrieval-augmented generation},
	pages = {3495--3506},
}

@inproceedings{tran_rag_2025,
	address = {New York, NY, USA},
	series = {{ICMR} '25},
	title = {A {RAG} {Approach} for {Multi}-{Modal} {Open}-ended {Lifelog} {Question}-{Answering}},
	isbn = {979-8-4007-1877-9},
	url = {https://doi.org/10.1145/3731715.3733263},
	doi = {10.1145/3731715.3733263},
	abstract = {Lifelogging is the passive collection, storage and analysis of daily data through wearable sensors. Question Answering (QA) for lifelog data enables natural language interactions with personal daily life records, providing insights into individual routines and behaviours. While this task has great potential for personal analytics and memory augmentation, progress has been limited due to the challenges of lifelog management, since they can comprise of enormous multi-modal data sets spanning a lifetime. We introduce a Retrieval-Augmented Generation (RAG) approach for addressing the lifelog QA task. A RAG approach first includes a retrieval model finding the correct lifelog events containing answers and then a large language model (LLM) generating answers from the questions. In addition, we construct an open-ended lifelog QA benchmark with 14,187 QA pairs to examine the RAG approach to lifelog QA. Using an embedding-based retrieval approach, our lifelog context retriever achieves a performance of 77.67\% Recall@5 and 94.35\% Recall@20 using an embedding-based retrieval approach with the Stella 1.5B model. Combined with the Mistral 7B model, the model achieves scores of 39.54\% ROUGE-L and 3.475 Accuracy on a scale of 5 scored by GPT-4o. This approach potentially provides an effective approach to lifelog QA with high performance that does not require fine-tuning.},
	booktitle = {Proceedings of the 2025 {International} {Conference} on {Multimedia} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Tran, Quang-Linh and Pham, Ngo Ngoc Diep and Truong, Quoc Trung and Nguyen, Minh Hung and Le, Hong Cat and Vu, Dang Khoi and Nguyen, Van Minh Thien and Nguyen, Van Kinh and Nguyen, Luu Phuong Ngoc Lam and Le, Tan and Dang, Minh Phuc and Nguyen, Binh and Jones, Gareth J. F. and Gurrin, Cathal},
	year = {2025},
	note = {event-place: Chicago, IL, USA},
	keywords = {large language models, lifelog question answering, multi-modal question answering dataset, retrieval-augmented generation},
	pages = {1303--1312},
}

@inproceedings{chen_question_2025,
	address = {New York, NY, USA},
	series = {{ICEKIM} '25},
	title = {A {Question} {Answering} {System} for {Aerospace} {Large} {Language} {Models} {Based} on {Knowledge} {Graph} and {RAG} {Collaboration}},
	isbn = {979-8-4007-1562-4},
	url = {https://doi.org/10.1145/3756580.3756654},
	doi = {10.1145/3756580.3756654},
	abstract = {At present, the data in the aerospace science and technology is massive, heterogeneous, distributed and discrete, and lacks unified management, which seriously affects the quality and efficiency of retrieval. To solve this problem, a construction method of question answering system for aerospace large language models based on knowledge graph and retrieval enhanced generation (RAG) collaboration is proposed. Firstly, the aerospace science and technology information representation model is constructed, and then the aerospace science and technology information resource database is constructed based on the model. On this basis, the large language model in the aerospace field is trained by using the efficient fine-tuning technology; Create knowledge graph and vector database in the neo4j, and use entity attributes and vector indexes to integrate them; Finally, the langchain framework is used to link the knowledge graph, RAG and the large language model of the aerospace field to develop and construct the aerospace intelligent question answering system. The experimental results show that the system covers a wide range of knowledge in the aerospace science and technology field, and can effectively improve the accuracy of the answer and reduce the hallucination rate.},
	booktitle = {Proceedings of the 2025 6th {International} {Conference} on {Education}, {Knowledge} and {Information} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Fei and Wen, Zhonghua and Liu, Bo},
	year = {2025},
	keywords = {intelligent question answering, knowledge graph, large language model (LLM), retrieval augmented generation (RAG), the aerospace science and technology},
	pages = {446--455},
}

@inproceedings{xu_muarf_2025,
	address = {Ottawa, Ontario, Canada},
	series = {{ICSE} '25},
	title = {{MUARF}: {Leveraging} {Multi}-{Agent} {Workflows} for {Automated} {Code} {Refactoring}},
	isbn = {979-8-3315-3683-1},
	url = {https://doi.org/10.1109/ICSE-Companion66252.2025.00071},
	doi = {10.1109/ICSE-Companion66252.2025.00071},
	abstract = {Refactoring is crucial for maintaining a project, but it requires developers to understand code structure and system design principles well. Recent research on Large Language Models(LLMs) has shown their great capability for handling complex tasks, making them a possible solution for overcoming these challenges. In this paper, we propose MUARF, an LLM-based solution designed to automate method-level code refactoring, aiming to generate correct, high-quality, and human-like refactored code. MUARF leverages Contextual Retrieval-Augmented Generation to search for similar refactoring samples for few-shot learning, uses Multi-Agent Workflow to simulate the human refactoring process, and integrates advanced software engineering tools (e.g., RefactoringMiner, PurityChecker, StyleChecker) to assist refactoring. Evaluation results show that MUARF achieves a compilation pass rate of 86.5\% and a test success rate of 83.8\% for the refactored code it generates. Additionally, metrics such as CodeBLEU score and AST Diff accuracy—which compare human-refactored code with the output of MUARF —highlight the generated code is human-like. The ablation results show that RefactoringMiner and Agentware made the greatest contribution to MUARF.},
	booktitle = {Proceedings of the {IEEE}/{ACM} 47th {International} {Conference} on {Software} {Engineering}: {Companion} {Proceedings}},
	publisher = {IEEE Press},
	author = {Xu, Yisen},
	year = {2025},
	keywords = {code refactoring, contextual retrieval-augmented generation, large language model, multi-agent communication, prompt engineering},
	pages = {226--227},
}

@inproceedings{jiang_retrieve_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Retrieve, {Summarize}, {Plan}: {Advancing} {Multi}-hop {Question} {Answering} with an {Iterative} {Approach}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3716889},
	doi = {10.1145/3701716.3716889},
	abstract = {Multi-hop question answering is a challenging task with distinct industrial relevance, and Retrieval-Augmented Generation (RAG) methods based on large language models (LLMs) have become a popular approach to tackle this task. Owing to the potential inability to retrieve all necessary information in a single iteration, a series of iterative RAG methods has been recently developed, showing significant performance improvements. However, existing methods still face two critical challenges: context overload resulting from multiple rounds of retrieval, and over-planning and repetitive planning due to the lack of a recorded retrieval trajectory. In this paper, we propose a novel iterative RAG method called ReSP, equipped with a dual-function summarizer. This summarizer compresses information from retrieved documents, targeting both the overarching question and the current sub-question concurrently. Experimental results on the multi-hop question-answering datasets HotpotQA and 2WikiMultihopQA demonstrate that our method significantly outperforms the state-of-the-art, and exhibits excellent robustness concerning context length.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Jiang, Zhouyu and Sun, Mengshu and Liang, Lei and Zhang, Zhiqiang},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {llms, question answering, retrieval-augmented generation},
	pages = {1677--1686},
}

@inproceedings{song_assessing_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Assessing and {Post}-{Processing} {Black} {Box} {Large} {Language} {Models} for {Knowledge} {Editing}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714732},
	doi = {10.1145/3696410.3714732},
	abstract = {The rapid evolution of the Web as a key platform for information dissemination has led to the growing integration of large language models (LLMs) in Web-based applications. However, the swift changes in web content present challenges in maintaining these models' relevance and accuracy. The task of Knowledge Editing (KE) is aimed at efficiently and precisely adjusting the behavior of large language models (LLMs) to update specific knowledge while minimizing any adverse effects on other knowledge. Current research predominantly concentrates on editing white-box LLMs, neglecting a significant scenario: editing black-box LLMs, where access is limited to interfaces and only textual output is provided. In this paper, we initially officially introduce KE on black-box LLMs, followed by presenting a thorough evaluation framework. This framework operates without requiring logits and considers pre- and post-edit consistency, addressing the limitations of current evaluations that are inadequate for black-box LLMs editing and lack comprehensiveness. To address privacy leaks of editing data and style over-editing in existing approaches, we propose a new postEdit framework. postEdit incorporates a retrieval mechanism for editing knowledge and a purpose-trained editing plugin called post-editor, ensuring privacy through downstream processing and maintaining textual style consistency via fine-grained editing. Experiments and analysis conducted on two benchmarks show that postEdit surpasses all baselines and exhibits robust generalization, notably enhancing style retention by an average of +20.82\%. Our code is available on github https://github.com/songxiaoshuai/postEdit.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Song, Xiaoshuai and Wang, Zhengyang and He, Keqing and Dong, Guanting and Mou, Yutao and Zhao, Jinxu and Xu, Weiran},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {knowledge editing, large language model, retrieval-augmented generation},
	pages = {1716--1732},
}

@inproceedings{jia_structrag_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{StructRAG}: {Structure}-{Aware} {RAG} {Framework} with {Scholarly} {Knowledge} {Graph} for {Diverse} {Question} {Answering}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3717819},
	doi = {10.1145/3701716.3717819},
	abstract = {Recent advances in Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) have shown promise in academic question answering. However, existing approaches often fail to fully utilize document structural information and lack diversity in retrieved contexts. This paper presents StructRAG, a structure-aware RAG framework that leverages scholarly knowledge graphs for enhanced question answering. Our framework features three key innovations: (1) an automated knowledge graph construction pipeline based on Deep Document Model (DDM) that preserves document hierarchical structure, (2) a structure-aware retrieval mechanism that combines semantic relevance with source diversity, and (3) a context-enhanced generation approach that integrates structural metadata for improved answer synthesis. Experimental results on 329 computer science papers demonstrate that StructRAG significantly outperforms vanilla RAG baseline. While maintaining comparable semantic accuracy (91\% vs 90\%), our approach achieves substantially higher diversity in generated answers (Distinct-1: 62\% vs 52\%, Distinct-2: 89\% vs 78\%) and better answer quality across all metrics, with notable improvements in relevance (29\%) and readability (36.5\%). These results demonstrate that StructRAG effectively enhances both the diversity and quality of academic question answering.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Jia, Runsong and Zhang, Bowen and Méndez, Sergio José Rodríguez and Omran, Pouya G.},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {deep document model, knowledge graph, knowledge graph construction, large language models, retrieval-augmented generation},
	pages = {2567--2573},
}

@inproceedings{shen_pentestagent_2025,
	address = {New York, NY, USA},
	series = {{ASIA} {CCS} '25},
	title = {{PentestAgent}: {Incorporating} {LLM} {Agents} to {Automated} {Penetration} {Testing}},
	isbn = {979-8-4007-1410-8},
	url = {https://doi.org/10.1145/3708821.3733882},
	doi = {10.1145/3708821.3733882},
	abstract = {Penetration testing is a critical technique for identifying security vulnerabilities, traditionally performed manually by skilled security specialists. This complex process involves gathering information about the target system, identifying entry points, exploiting the system, and reporting findings. Despite its effectiveness, manual penetration testing is time-consuming and expensive, often requiring significant expertise and resources that many organizations cannot afford. While automated penetration testing methods have been proposed, they often fall short in real-world applications due to limitations in flexibility, adaptability, and implementation.Recent advancements in large language models offer new opportunities for enhancing penetration testing through increased intelligence and automation. However, current LLM-based approaches still face significant challenges, including limited penetration testing knowledge and a lack of comprehensive automation capabilities. To address these gaps, we propose PentestAgent, a novel LLM-based automated penetration testing framework that leverages the power of LLMs and various LLM-based techniques like retrieval augmented generation to enhance penetration testing knowledge and automate various tasks. Our framework leverages multi-agent collaboration to automate intelligence gathering, vulnerability analysis, and exploitation stages, reducing manual intervention. We evaluate PentestAgent using a comprehensive benchmark, demonstrating superior performance in task completion and overall efficiency.},
	booktitle = {Proceedings of the 20th {ACM} {Asia} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {Association for Computing Machinery},
	author = {Shen, Xiangmin and Wang, Lingzhi and Li, Zhenyuan and Chen, Yan and Zhao, Wencheng and Sun, Dawei and Wang, Jiashui and Ruan, Wei},
	year = {2025},
	keywords = {Agent, Large Language Model, Penetration Testing},
	pages = {375--391},
}

@inproceedings{szabo_applied_2025,
	address = {New York, NY, USA},
	series = {{IntRob} '25},
	title = {Applied {Domain} {Adaptation} of {LLM}-based {Document} {Embeddings} for {Engineering} {Knowledge} {Retrieval}},
	isbn = {979-8-4007-1589-1},
	url = {https://doi.org/10.1145/3759355.3759360},
	doi = {10.1145/3759355.3759360},
	abstract = {Technical documentation related to engineering and manufacturing is often stored in unstructured documents, rendering search and information retrieval processes time-consuming and inefficient. Recently, Retrieval-Augmented Generation (RAG) pipelines and AI agents leveraging dense retrieval capabilities of document embedding language models have emerged as promising solutions to address these challenges. However, these methods typically lack semantic understanding of industry-specific terminology, limiting their retrieval accuracy in specialized domains. In this paper, we identify the fine-tuning of dense retrieval models within RAG systems as an effective and cost-efficient approach for enhancing their industry- and enterprise-specific knowledge. We further investigate whether pretraining based on Masked Language Modeling is necessary for these scenarios. Through empirical evaluation, we show that automatic data preprocessing and synthetic data generation derived from human-labeled retrieval examples provide a cost-effective strategy for preparing fine-tuning data. By training and evaluating an embedding model on 21 281 engineering documents encompassing best practices and lessons learned, totaling 75 million whitespace delimited words, we achieve a significant increase of (23\%) in Recall@10 for domain-specific retrieval performance, while retaining generalization capabilities on general retrieval tasks as measured by the Massive Text Embedding Benchmark (MTEB). Additionally, we present ablation studies on the effects of loss function symmetry, masking ratio in MLM, and sequence packing strategies. Our results demonstrate that domain-specific fine-tuned embeddings consistently outperform both open-source and state-of-the-art proprietary general retrieval models, establishing this fine-tuning strategy as a viable solution even in computationally constrained, single-GPU training environments.},
	booktitle = {Proceedings of the {Intelligent} {Robotics} {FAIR} 2025},
	publisher = {Association for Computing Machinery},
	author = {Szabó, Barbara Noémi and Gyöngyössy, Natabara Máté and Dalos, Attila},
	year = {2025},
	keywords = {contrastive learning, embedding model, engineering knowledge management, fine-tuning, retrieval-augmented generation},
	pages = {29--37},
}

@inproceedings{nian_w-rag_2025,
	address = {New York, NY, USA},
	series = {{ICTIR} '25},
	title = {W-{RAG}: {Weakly} {Supervised} {Dense} {Retrieval} in {RAG} for {Open}-domain {Question} {Answering}},
	isbn = {979-8-4007-1861-8},
	url = {https://doi.org/10.1145/3731120.3744578},
	doi = {10.1145/3731120.3744578},
	abstract = {In knowledge-intensive tasks such as open-domain question answering (OpenQA), large language models (LLMs) often struggle to generate factual answers, relying solely on their internal (parametric) knowledge. To address this limitation, Retrieval-Augmented Generation (RAG) systems enhance LLMs by retrieving relevant information from external sources, thereby positioning the retriever as a pivotal component. Although dense retrieval demonstrates state-of-the-art performance, its training poses challenges due to the scarcity of ground-truth evidence, largely attributed to the high costs of human annotation. In this paper, we propose W-RAG, a method that draws weak training signals from the downstream task (such as OpenQA) of an LLM, and fine-tunes the retriever to prioritize passages that most benefit the task. Specifically, we rerank the top-k passages retrieved via BM25 by assessing the probability that the LLM will generate the correct answer for a question given each passage. The highest-ranking passages are then used as positive fine-tuning examples for dense retrieval. We conduct comprehensive experiments across four publicly available OpenQA datasets to demonstrate that our approach enhances both retrieval and OpenQA performance compared to baseline models, achieving results comparable to models fine-tuned with human-labeled data. Source code is published.},
	booktitle = {Proceedings of the 2025 {International} {ACM} {SIGIR} {Conference} on {Innovative} {Concepts} and {Theories} in {Information} {Retrieval} ({ICTIR})},
	publisher = {Association for Computing Machinery},
	author = {Nian, Jinming and Peng, Zhiyuan and Wang, Qifan and Fang, Yi},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {dense retrieval, open-domain question answering, retrieval augmented generation, weak supervised learning},
	pages = {136--146},
}

@inproceedings{huang_rd-p_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {{RD}-{P}: {A} {Trustworthy} {Retrieval}-{Augmented} {Prompter} with {Knowledge} {Graphs} for {LLMs}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3679659},
	doi = {10.1145/3627673.3679659},
	abstract = {Large Language Models (LLMs) face challenges due to hallucination issues. Current solutions use retrieval-augmented generation (RAG), integrating LLMs with external knowledge to enhance answer accuracy. However, the misuse of irrelevant external knowledge can be misleading. In this paper, we propose a novel method called Retrieve-and-Discriminate Prompter (RD-P), which leverages knowledge graphs (KGs) for trustworthy RAG by synchronizing knowledge retrieval and discrimination in a unified model. Specifically, we train a prompter based on a pre-trained language model with shared parameters. It has two key modules: the retriever and the discriminator. The retriever identifies relevant reasoning paths in the KG, while the discriminator evaluates their credibility through "logical coverage calculation" and in turn instructs the retrieval process. Prompts are then constructed to guide LLMs in reasoning and answering questions using both retrieved and implicit knowledge. Experiments on knowledge-intensive question answering (QA) tasks demonstrate that our method significantly improves answer coverage rate while reducing the retrieval scale, achieving superior performance in complex KGQA tasks compared with state-of-the-art RAG methods at a low cost.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Huang, Yubo and Zeng, Guosun},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {kgqa, large language models, prompter, retrieval-augmented generation},
	pages = {942--952},
}

@inproceedings{salemi_comparing_2025,
	address = {New York, NY, USA},
	series = {{ICTIR} '25},
	title = {Comparing {Retrieval}-{Augmentation} and {Parameter}-{Efficient} {Fine}-{Tuning} for {Privacy}-{Preserving} {Personalization} of {Large} {Language} {Models}},
	isbn = {979-8-4007-1861-8},
	url = {https://doi.org/10.1145/3731120.3744595},
	doi = {10.1145/3731120.3744595},
	abstract = {Despite its substantial impact on various search, recommendation, and question answering tasks, privacy-preserving methods for personalizing large language models (LLMs) have received relatively limited exploration. There is one primary approach in this area through retrieval-augmented generation (RAG), which generates personalized outputs by enriching the input prompt with information retrieved from the user's personal data. This paper studies an orthogonal approach to RAG that involves learning user-dependent LLM parameters through parameter-efficient fine-tuning (PEFT). This paper presents the first systematic study for exploration of PEFT for LLM personalization and provides an extensive comparisons between RAG- and PEFT-based solutions, across a broad set of seven diverse datasets from the LaMP benchmark. Our results demonstrate that, on average, both RAG- and PEFT-based personalization methods yield 14.92\% and 1.07\% improvements over non-personalized LLMs, respectively. When combining RAG with PEFT, we observe a further improvement of 15.98\%, highlighting the effectiveness of their integration in enhancing personalized text generation. Additionally, we identify a positive correlation between the amount of user data available and the effectiveness of PEFT. This finding suggests that RAG is particularly beneficial for cold-start users–users with limited personal data–while PEFT performs better when more user-specific data is available.},
	booktitle = {Proceedings of the 2025 {International} {ACM} {SIGIR} {Conference} on {Innovative} {Concepts} and {Theories} in {Information} {Retrieval} ({ICTIR})},
	publisher = {Association for Computing Machinery},
	author = {Salemi, Alireza and Zamani, Hamed},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {parameter-efficient fine-tuning, personalization, retrieval-augmented generation, text classification, text generation},
	pages = {286--296},
}

@inproceedings{bi_rbdq_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{RBDQ}: {A} {Reliable} {LLM}-based {Text}-to-{SQL} {System} for {Business} {Data} {Queries}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715257},
	doi = {10.1145/3701716.3715257},
	abstract = {Using large language models (LLMs) to convert natural language (NL) into SQL simplifies data access for users by allowing them to use everyday language. However, business departments often distrust LLM-based text-to-SQL systems due to the probabilistic nature of SQL generation, which can result in incorrect but executable SQL queries caused by model hallucinations. This leads to significant concerns regarding the accuracy and reliability of the queried data. In this paper, we present RBDQ, a novel LLM-based text-to-SQL system designed to address the unique challenges of business data queries. RBDQ innovatively introduces the Hierarchical Metrics Query Method and integrates advanced Retrieval-Augmented Generation (RAG) methods along with a self-reflection mechanism to tackle these challenges. RBDQ effectively meets the requirements of business metric queries in real-world scenarios. Currently implemented in the Quality Assurance department at ByteDance, RBDQ has significantly improved operational efficiency and query flexibility. Our experiments demonstrate the system's effectiveness, achieving an Execution Accuracy of 96.20\%.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Bi, Fenglin and Cao, Dongdong and Wang, Zhiyu and Chen, Yang and Zhao, Fangliang and Hu, Tao and Li, Zhi and Zhang, Yanbin and Wang, Wei},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {business data queries, large language models, retrieval-augmented generation, text-to-sql},
	pages = {95--103},
}

@inproceedings{wang_topology-aware_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {Topology-aware {Retrieval} {Augmentation} for {Text} {Generation}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3679746},
	doi = {10.1145/3627673.3679746},
	abstract = {Retrieval-augmented Generation has been used to augment Language Models by retrieving texts from external databases. Since real-world texts are often connected in the graph (e.g., papers in citation networks), we use these relations to guide the retrieval process of RAG. Concretely, we investigate proximity and role-based relations, where the former considers topologically close nodes and the latter considers structurally similar nodes. We empirically verify their correlation to text relations, which motivates us to propose the framework of Topology-aware Retrieval-augmented Generation for text generation, which consists of a retrieval module to retrieve texts by their topological relations and an aggregation module to compose retrieved texts into prompts triggering LLMs for text generation. Extensive experiments verify the effectiveness of this framework, signifying the potential of equipping RAG with topological awareness.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Yu and Lipka, Nedim and Zhang, Ruiyi and Siu, Alexa and Zhao, Yuying and Ni, Bo and Wang, Xin and Rossi, Ryan and Derr, Tyler},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {graph structural relations, retrieval-augmented generation},
	pages = {2442--2452},
}

@inproceedings{chen_generating_2025,
	address = {New York, NY, USA},
	series = {{ICEA} '24},
	title = {Generating {Spatially}-{Aware} {Dense} {Video} {Captions} for {Indoor} {Human} {Behavior} {Analysis} with {Position}-{Based} {Scene} {Knowledge}},
	isbn = {979-8-4007-1166-4},
	url = {https://doi.org/10.1145/3732437.3732768},
	doi = {10.1145/3732437.3732768},
	abstract = {Current dense video captioning methods do not effectively capture spatial information about the individual and the surrounding objects in the scene. This limitation can lead to ambiguous captions, making it difficult to detect abnormalities in human activities in the human-centric applications, such as security surveillance and remote indoor caregiving, where detecting abnormalities in human activities is crucial and these activities are closely intertwined with the spatial information of the objects in the scene.We propose a system that enhances dense video captioning of indoor human behavior by integrating two key sources of information: spatial context extracted by Retrieval-Augmented Generation (RAG) from a knowledge base that contains the positions and categories of all objects in the room, and spatial information from RGB-D pairs that includes the positions and categories of people and objects within the Field of View (FOV). By combining these elements, our approach reduces ambiguity and improves the accuracy of behavior descriptions.Our proposed baseline method is evaluated on the custom dataset, achieving scores of 15.7 for METEOR, 20.3 for ROUGE-L, 52.3 for Recall and 52.4 for Precision. These results demonstrates that our system effectively addresses the limitations of PDVC and GVL in collecting spatial information and provides improvements over SG-PDVC and SI-PDVC in this area. We propose a convenient and effective method for generating spatial information-enhanced captions to describe human behavior in untrimmed videos.},
	booktitle = {Proceedings of the 2024 {International} {Conference} on {Intelligent} {Computing} and {Its} {Emerging} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Bin and Nakamura, Yugo and Fukushima, Shogo and Arakawa, Yutaka},
	year = {2025},
	keywords = {3D reconstruction, Dense video caption, Human action recognition, Large language model, Retrieval-augmented generation},
	pages = {74--80},
}

@inproceedings{yu_mramg-bench_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{MRAMG}-{Bench}: {A} {Comprehensive} {Benchmark} for {Advancing} {Multimodal} {Retrieval}-{Augmented} {Multimodal} {Generation}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730288},
	doi = {10.1145/3726302.3730288},
	abstract = {Recent advances in Retrieval-Augmented Generation (RAG) have significantly improved response accuracy and relevance by incorporating external knowledge into Large Language Models (LLMs). However, existing RAG methods primarily focus on generating text-only answers, even in Multimodal Retrieval-Augmented Generation (MRAG) scenarios, where multimodal elements are retrieved to assist in generating text answers. To address this, we introduce the Multimodal Retrieval-Augmented Multimodal Generation (MRAMG) task, in which we aim to generate multimodal answers that combine both text and images, fully leveraging the multimodal data within a corpus. Despite growing attention to this challenging task, a notable lack of a comprehensive benchmark persists for effectively evaluating its performance. To bridge this gap, we provide MRAMG-Bench, a meticulously curated, human-annotated benchmark comprising 4,346 documents, 14,190 images, and 4,800 QA pairs, distributed across six distinct datasets and spanning three domains: Web, Academia, and Lifestyle. The datasets incorporate diverse difficulty levels and complex multi-image scenarios, providing a robust foundation for evaluating the MRAMG task. To facilitate rigorous evaluation, MRAMG-Bench incorporates a comprehensive suite of both statistical and LLM-based metrics, enabling a thorough analysis of the performance of generative models in the MRAMG task. Additionally, we propose an efficient and flexible multimodal answer generation framework that can leverage LLMs/MLLMs to generate multimodal responses. Our datasets and complete evaluation results for 11 popular generative models are available at https://github.com/MRAMG-Bench/MRAMG.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Yu, Qinhan and Xiao, Zhiyou and Li, Binghui and Wang, Zhengren and Chen, Chong and Zhang, Wentao},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {evaluation, large language model, multimodal large language model, multimodal retrieval-augmented multimodal generation},
	pages = {3616--3626},
}

@inproceedings{li_emails_2025,
	address = {New York, NY, USA},
	series = {Websci '25},
	title = {Emails by {LLMs}: {A} {Comparison} of {Language} in {AI}-{Generated} and {Human}-{Written} {Emails}},
	isbn = {979-8-4007-1483-2},
	url = {https://doi.org/10.1145/3717867.3717872},
	doi = {10.1145/3717867.3717872},
	abstract = {The growing excitement around generative AI (and LLMs) is fueling a heightened interest in the development of AI-assisted writing tools. One popular context is AI-assisted email writing, and this paper explores how AI-generated emails compare to human-written emails. We obtained human-written emails from the W3C corpus and generated analogous AI-generated emails using GPT-3.5, GPT-4, Llama-2, and Mistral-7B, and compared AI-generated and human-written emails using a suite of natural language analyses across syntactic, semantic, and psycholinguistic dimensions. AI-generated emails are generally consistent across different LLMs but differ significantly from human-written emails. Specifically, AI-generated emails tend to be more formal, verbose, and complex, whereas human-written emails are often more concise and personalized. While AI-generated emails are slightly more polite, both types exhibit a similar level of empathetic tone in language. Further, we qualitatively examined user perceptions of AI and human-written emails by conducting a small survey of 41 participants and interviewing a subset of them. This study highlights preliminary insights into generative AI’s distinct strengths and weaknesses in assisting email communication, and we discuss the theoretical and practical implications of the evolving landscape of AI-generated content.},
	booktitle = {Proceedings of the 17th {ACM} {Web} {Science} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Li, Weijiang and Lai, Yinmeng and Soni, Sandeep and Saha, Koustuv},
	year = {2025},
	keywords = {email, generative AI, language, linguistic analysis, LLMs},
	pages = {391--403},
}

@inproceedings{zhou_metacognitive_2024,
	address = {New York, NY, USA},
	series = {{WWW} '24},
	title = {Metacognitive {Retrieval}-{Augmented} {Large} {Language} {Models}},
	isbn = {979-8-4007-0171-9},
	url = {https://doi.org/10.1145/3589334.3645481},
	doi = {10.1145/3589334.3645481},
	abstract = {Retrieval-augmented generation have become central in natural language processing due to their efficacy in generating factual content. While traditional methods employ single-time retrieval, more recent approaches have shifted towards multi-time retrieval for multi-hop reasoning tasks. However, these strategies are bound by predefined reasoning steps, potentially leading to inaccuracies in response generation. This paper introduces MetaRAG, an approach that combines the retrieval-augmented generation process with metacognition. Drawing from cognitive psychology, metacognition allows an entity to self-reflect and critically evaluate its cognitive processes. By integrating this, MetaRAG enables the model to monitor, evaluate, and plan its response strategies, enhancing its introspective reasoning abilities. Through a three-step metacognitive regulation pipeline, the model can identify inadequacies in initial cognitive responses and fixes them. Empirical evaluations show that MetaRAG significantly outperforms existing methods.},
	booktitle = {Proceedings of the {ACM} {Web} {Conference} 2024},
	publisher = {Association for Computing Machinery},
	author = {Zhou, Yujia and Liu, Zheng and Jin, Jiajie and Nie, Jian-Yun and Dou, Zhicheng},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	keywords = {llms, metacognition, retrieval-augmented generation},
	pages = {1453--1463},
}

@inproceedings{salemi_learning_2025,
	address = {New York, NY, USA},
	series = {{ICTIR} '25},
	title = {Learning to {Rank} for {Multiple} {Retrieval}-{Augmented} {Models} through {Iterative} {Utility} {Maximization}},
	isbn = {979-8-4007-1861-8},
	url = {https://doi.org/10.1145/3731120.3744584},
	doi = {10.1145/3731120.3744584},
	abstract = {This paper investigates the design of a unified search engine to serve multiple retrieval-augmented generation (RAG) agents, each with a distinct task, backbone large language model (LLM), and RAG strategy. We introduce an iterative approach where the search engine generates retrieval results for the RAG agents and gathers feedback on the quality of the retrieved documents during an offline phase. This feedback is then used to iteratively optimize the search engine using an expectation-maximization algorithm, with the goal of maximizing each agent's utility function. Additionally, we adapt this to an online setting, allowing the search engine to refine its behavior based on real-time individual agents feedback to better serve the results for each of them. Experiments on datasets from the Knowledge-Intensive Language Tasks (KILT) benchmark demonstrates that our approach significantly on average outperforms baselines across 18 RAG models. We demonstrate that our method effectively ”personalizes” the retrieval for each RAG agent based on the collected feedback. Finally, we provide a comprehensive ablation study to explore various aspects of our method.},
	booktitle = {Proceedings of the 2025 {International} {ACM} {SIGIR} {Conference} on {Innovative} {Concepts} and {Theories} in {Information} {Retrieval} ({ICTIR})},
	publisher = {Association for Computing Machinery},
	author = {Salemi, Alireza and Zamani, Hamed},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {ranking optimization, retrieval-augmented generation, retrieval-enhanced machine learning, search engine for agents},
	pages = {183--193},
}

@inproceedings{peng_eloq_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{ELOQ}: {Resources} for {Enhancing} {LLM} {Detection} of {Out}-of-{Scope} {Questions}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730333},
	doi = {10.1145/3726302.3730333},
	abstract = {Retrieval-augmented generation (RAG) has become integral to large language models (LLMs), particularly for conversational AI systems where user questions may reference knowledge beyond the LLMs' training cutoff. However, many natural user questions lack well-defined answers, either due to limited domain knowledge or because the retrieval system returns documents that are relevant in appearance but uninformative in content. In such cases, LLMs often produce hallucinated answers without flagging them. While recent work has largely focused on questions with false premises, we study out-of-scope questions, where the retrieved document appears semantically similar to the question but lacks the necessary information to answer it. In this paper, we propose a guided hallucination-based approach ELOQ . https://github.com/zhiyuanpeng/ELOQ.git, for automatically generating a diverse set of out-of-scope questions from post-cutoff documents, followed by human verification to ensure quality. We use this dataset to evaluate several LLMs on their ability to detect out-of-scope questions and generate appropriate responses. Finally, we introduce an improved detection method that enhances the reliability of LLM-based question-answering systems in handling out-of-scope questions.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Peng, Zhiyuan and Nian, Jinming and Evfimievski, Alexandre and Fang, Yi},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {large language models, out-of-scope question, question answering, retrieval augmented generation},
	pages = {3509--3519},
}

@inproceedings{lin_scirgen_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{ScIRGen}: {Synthesize} {Realistic} and {Large}-{Scale} {RAG} {Dataset} for {Scientific} {Research}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737432},
	doi = {10.1145/3711896.3737432},
	abstract = {Scientific researchers need intensive information about datasets to effectively evaluate and develop theories and methodologies. The information needs regarding datasets are implicitly embedded in particular research tasks, rather than explicitly expressed in search queries. However, existing scientific retrieval and question-answering (QA) datasets typically address straightforward questions, which do not align with the distribution of real-world research inquiries. To bridge this gap, we developed ScIRGen, a dataset generation framework for scientific QA \&amp; retrieval that more accurately reflects the information needs of professional science researchers, and uses it to create a large-scale scientific retrieval-augmented generation (RAG) dataset with realistic queries, datasets and papers. Technically, we designed a dataset-oriented information extraction method that leverages academic papers to augment the dataset representation. We then proposed a question generation framework by employing cognitive taxonomy to ensure the quality of synthesized questions. We also design a method to automatically filter synthetic answers based on the perplexity shift of LLMs, which is highly aligned with human judgment of answers' validity. Collectively, these methodologies culminated in the creation of the 61k QA dataset, ScIRGen-Geo. We benchmarked representative methods on the ScIRGen-Geo dataset for their question-answering and retrieval capabilities, finding out that current methods still suffer from reasoning from complex questions. This work advances the development of more sophisticated tools to support the intricate information needs of the scientific community.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Lin, Junyong and Dai, Lu and Han, Ruiqian and Sui, Yijie and Wang, Ruilin and Sun, Xingliang and Wu, Qinglin and Feng, Min and Liu, Hao and Xiong, Hui},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {dataset generation, geoscience, information retrieval, large language models (LLMs), question answering, retrieval-augmented generation (RAG), scientific workflows, synthetic dataset},
	pages = {5619--5630},
}

@inproceedings{zhang_way_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {Way to {Specialist}: {Closing} {Loop} {Between} {Specialized} {LLM} and {Evolving} {Domain} {Knowledge} {Graph}},
	isbn = {979-8-4007-1245-6},
	url = {https://doi.org/10.1145/3690624.3709187},
	doi = {10.1145/3690624.3709187},
	abstract = {Large language models (LLMs) have demonstrated exceptional performance across a wide variety of domains. Nonetheless, generalist LLMs continue to fall short in reasoning tasks necessitating specialized knowledge, e.g., emotional sociology and medicine. Prior investigations into specialized LLMs focused on domain-specific training, which entails substantial efforts in domain data acquisition and model parameter fine-tuning. To address these challenges, this paper proposes the Way-to-Specialist (WTS) framework, which synergizes retrieval-augmented generation with knowledge graphs (KGs) to enhance the specialized capability of LLMs in the absence of specialized training. In distinction to existing paradigms that merely utilize external knowledge from general KGs or static domain KGs to prompt LLM for enhanced domain-specific reasoning, WTS proposes an innovative ”LLM↻KG” paradigm, which achieves bidirectional enhancement between specialized LLM and domain knowledge graph (DKG). The proposed paradigm encompasses two closely coupled components: the DKG-Augmented LLM and the LLM-Assisted DKG Evolution. The former retrieves question-relevant domain knowledge from DKG and uses it to prompt LLM to enhance the reasoning capability for domain-specific tasks; the latter leverages LLM to generate new domain knowledge from processed tasks and use it to evolve DKG. WTS closes the loop between DKG-Augmented LLM and LLM-Assisted DKG Evolution, enabling continuous improvement in the domain specialization as it progressively answers and learns from domain-specific questions. We validate the performance of WTS on 7 datasets (e.g., TweetQA, ChatDoctor5k) spanning 6 domains, e.g., emotional sociology, medical, ect. The experimental results show that WTS surpasses the previous SOTA in 5 specialized domains, and achieves a maximum performance improvement of 11.3\%.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.1},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Yutong and Chen, Lixing and Li, Shenghong and Cao, Nan and Shi, Yang and Ding, Jiaxin and Qu, Zhe and Zhou, Pan and Bai, Yang},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {domain knowledge graph, retrieval-augmented generation, social network., specialized large language models},
	pages = {1996--2007},
}

@inproceedings{chen_multi-agent_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {Multi-{Agent} {Proactive} {Information} {Seeking} with {Adaptive} {LLM} {Orchestration} for {Non}-{Factoid} {Question} {Answering}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737249},
	doi = {10.1145/3711896.3737249},
	abstract = {The proliferation of complex non-factoid questions in modern information seeking (IS) systems exposes critical limitations in conventional Retrieval-Augmented Generation (RAG) approaches, particularly their static search strategies and the lack of systematic multi-source information integration capabilities. Facing these limitations, we present PASS (Proactive Agent-driven Search System), a novel multi-agent framework that operationalizes human-like proactive search strategies through five specialized agents: Revealer for intent analysis, Navigator for search planning, Seeker/Reader for adaptive retrieval, and Writer for response synthesis, systematically expanding the search space through iterative query refinement and multi-perspective knowledge integration. Crucially, our framework demonstrates remarkable adaptability to mid-sized LLMs, demonstrating its scalability in resource-constrained environments. To comprehensively assess the effectiveness of the proposed framework, we carry out extensive experiments on both mid-sized and proprietary large-scale LLMs, evaluating response quality for complex non-factoid questions using a newly introduced nugget-based assessment. Experimental results from offline nugget-based evaluation and online A/B Tests confirm substantial improvements in answer quality, advancing proactive information seeking methodologies and offering practical pathways for democratizing complex reasoning capabilities to resource-constrained environments.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Chen, Xinran and Li, Yuchen and Cai, Hengyi and Ma, Zhuoran and Chen, Xuanang and Xiong, Haoyi and Wang, Shuaiqiang and He, Ben and Sun, Le and Yin, Dawei},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {information seeking, large language model, multi-agent system},
	pages = {4341--4352},
}

@inproceedings{cuconasu_power_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {The {Power} of {Noise}: {Redefining} {Retrieval} for {RAG} {Systems}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657834},
	doi = {10.1145/3626772.3657834},
	abstract = {Retrieval-Augmented Generation (RAG) has recently emerged as a method to extend beyond the pre-trained knowledge of Large Language Models by augmenting the original prompt with relevant passages or documents retrieved by an Information Retrieval (IR) system. RAG has become increasingly important for Generative AI solutions, especially in enterprise settings or in any domain in which knowledge is constantly refreshed and cannot be memorized in the LLM. We argue here that the retrieval component of RAG systems, be it dense or sparse, deserves increased attention from the research community, and accordingly, we conduct the first comprehensive and systematic examination of the retrieval strategy of RAG systems. We focus, in particular, on the type of passages IR systems within a RAG solution should retrieve. Our analysis considers multiple factors, such as the relevance of the passages included in the prompt context, their position, and their number. One counter-intuitive finding of this work is that the retriever's highest-scoring documents that are not directly relevant to the query (e.g., do not contain the answer) negatively impact the effectiveness of the LLM. Even more surprising, we discovered that adding random documents in the prompt improves the LLM accuracy by up to 35\%. These results highlight the need to investigate the appropriate strategies when integrating retrieval with LLMs, thereby laying the groundwork for future research in this area.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Cuconasu, Florin and Trappolini, Giovanni and Siciliano, Federico and Filice, Simone and Campagnano, Cesare and Maarek, Yoelle and Tonellotto, Nicola and Silvestri, Fabrizio},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {information retrieval, llm, rag},
	pages = {719--729},
}

@inproceedings{zhong_towards_2025,
	address = {New York, NY, USA},
	series = {{LMPL} '25},
	title = {Towards {Repository}-{Level} {Program} {Verification} with {Large} {Language} {Models}},
	isbn = {979-8-4007-2148-9},
	url = {https://doi.org/10.1145/3759425.3763382},
	doi = {10.1145/3759425.3763382},
	abstract = {Recent advancements in large language models (LLMs) suggest great promises in code and proof generations. However, scaling automated formal verification to real-world projects requires resolving cross-module dependencies and global contexts, which are crucial challenges overlooked by existing LLM-based methods with a special focus on targeting isolated, function-level verification tasks. To systematically explore and address the significant challenges of verifying entire software repositories, we introduce RVBench, the first verification benchmark explicitly designed for repository-level evaluation, constructed from four diverse and complex open-source Verus projects. We further introduce RagVerus, an extensible framework that synergizes retrieval-augmented generation with context-aware prompting to automate proof synthesis for multi-module repositories. RagVerus triples proof pass rates on existing benchmarks under constrained model inference budgets, and achieves a 27\% relative improvement on the more challenging RVBench benchmark, demonstrating a scalable and sample-efficient verification solution.},
	booktitle = {Proceedings of the 1st {ACM} {SIGPLAN} {International} {Workshop} on {Language} {Models} and {Programming} {Languages}},
	publisher = {Association for Computing Machinery},
	author = {Zhong, Si Cheng and Si, Xujie},
	year = {2025},
	note = {event-place: Singapore, Singapore},
	keywords = {Large Language Model, Trustworthy Code Generation},
	pages = {27--39},
}

@inproceedings{yang_knowing_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Knowing {You} {Don}'t {Know}: {Learning} {When} to {Continue} {Search} in {Multi}-round {RAG} through {Self}-{Practicing}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730018},
	doi = {10.1145/3726302.3730018},
	abstract = {Retrieval Augmented Generation (RAG) has shown strong capability in enhancing language models' knowledge and reducing AI generative hallucinations, driving its widespread use. However, complex tasks requiring multi-round retrieval remain challenging, and early attempts tend to be overly optimistic without a good sense of self-skepticism. Current multi-round RAG systems may continue searching even when enough information has already been retrieved, or they may provide incorrect answers without having sufficient information or knowledge. Existing solutions either require large amounts of expensive human-labeled process supervision data or lead to subpar performance. This paper aims to address these limitations by introducing a new framework, SIM-RAG, to explicitly enhance RAG systems' self-awareness and multi-round retrieval capabilities. To train SIM-RAG, we first let a RAG system self-practice multi-round retrieval, augmenting existing question-answer pairs with intermediate inner monologue reasoning steps to generate synthetic training data. For each pair, the system may explore multiple retrieval paths, which are labeled as successful if they reach the correct answer and unsuccessful otherwise. Using this data, we train a lightweight information sufficiency Critic. At inference time, the Critic evaluates whether the RAG system has retrieved sufficient information at each round, guiding retrieval decisions and improving system-level self-awareness through in-context reinforcement learning. Experiments across multiple prominent RAG benchmarks show that SIM-RAG is an effective multi-round RAG solution. Furthermore, this framework is system-efficient, adding a lightweight component to RAG without requiring modifications to existing LLMs or search engines, and data-efficient, eliminating the need for costly human-annotated mid-step retrieval process supervision data.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Yang, Diji and Zeng, Linda and Rao, Jinmeng and Zhang, Yi},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {inner monologue, large language models, multi-round retrieval, question answering, retrieval augmented generation},
	pages = {1305--1315},
}

@inproceedings{dakshit_faculty_2024,
	address = {New York, NY, USA},
	series = {{SIGITE} '24},
	title = {Faculty {Perspectives} on the {Potential} of {RAG} in {Computer} {Science} {Higher} {Education}},
	isbn = {979-8-4007-1106-0},
	url = {https://doi.org/10.1145/3686852.3686864},
	doi = {10.1145/3686852.3686864},
	abstract = {The emergence of Large Language Models (LLMs) has significantly impacted the field of Natural Language Processing and has transformed conversational tasks across various domains because of their widespread integration in applications and public access. The discussion surrounding the application of LLMs in education has raised ethical concerns, particularly concerning plagiarism and policy compliance. Despite the prowess of LLMs in conversational tasks, the limitations of reliability and hallucinations exacerbate the need to guardrail conversations, motivating our investigation of RAG in computer science higher education. We developed Retrieval Augmented Generation (RAG) applications for the two tasks of virtual teaching assistants and teaching aids. In our study, we collected the ratings and opinions of faculty members in undergraduate and graduate computer science university courses at various levels, using our personalized RAG systems for each course. This study is the first to gather faculty feedback on the application of LLM-based RAG in education. The investigation revealed that while faculty members acknowledge the potential of RAG systems as virtual teaching assistants and teaching aids, certain barriers and features are suggested for their full-scale deployment. These findings contribute to the ongoing discussion on the integration of advanced language models in educational settings, highlighting the need for careful consideration of ethical implications and the development of appropriate safeguards to ensure responsible and effective implementation.},
	booktitle = {Proceedings of the 25th {Annual} {Conference} on {Information} {Technology} {Education}},
	publisher = {Association for Computing Machinery},
	author = {Dakshit, Sagnik},
	year = {2024},
	note = {event-place: El Paso, TX, USA},
	keywords = {Education, Large Language Models, Learning, Neural Networks, Retrieval Augmented Generation},
	pages = {19--24},
}

@inproceedings{doyle_if_2025,
	address = {New York, NY, USA},
	series = {{CSLAW} '25},
	title = {If {You} {Give} an {LLM} a {Legal} {Practice} {Guide}},
	isbn = {979-8-4007-1421-4},
	url = {https://doi.org/10.1145/3709025.3712220},
	doi = {10.1145/3709025.3712220},
	abstract = {Large language models struggle to answer legal questions that require applying detailed, jurisdiction-specific legal rules. Lawyers also find these types of question difficult to answer. For help, lawyers turn to legal practice guides: expert-written how-to manuals for practicing a type of law in a particular jurisdiction. Might large language models also benefit from consulting these practice guides? This article investigates whether providing LLMs with excerpts from these guides can improve their ability to answer legal questions. Our findings show that adding practice guide excerpts to LLMs' prompts tends to help LLMs answer legal questions. But even when a practice guide provides clear instructions on how to apply the law, LLMs often fail to correctly answer straightforward legal questions - questions that any lawyer would be expected to answer correctly if given the same information. Performance varies considerably and unpredictably across different language models and legal subject areas. Across our experiments' different legal domains, no single model consistently outperformed others. LLMs sometimes performed better when a legal question was broken down into separate subquestions for the model to answer over multiple prompts and responses. But sometimes breaking legal questions down resulted in much worse performance. These results suggest that retrieval augmented generation (RAG) will not be enough to overcome LLMs' shortcomings with applying detailed, jurisdiction-specific legal rules. Replicating our experiments on the recently released OpenAI o1 and o3-mini advanced reasoning models did not result in consistent performance improvements. These findings cast doubt on claims that LLMs will develop competency at legal reasoning tasks without dedicated effort directed toward this specific goal.},
	booktitle = {Proceedings of the 2025 {Symposium} on {Computer} {Science} and {Law}},
	publisher = {Association for Computing Machinery},
	author = {Doyle, Colin and Tucker, Aaron D.},
	year = {2025},
	note = {event-place: Munich, Germany},
	keywords = {Large Language Models, Law, Propositional Logic, Reasoning Models, Retrieval Augmented Generation},
	pages = {194--205},
}

@inproceedings{ram_gesturecoach_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {{GestureCoach}: {Rehearsing} for {Engaging} {Talks} with {LLM}-{Driven} {Gesture} {Recommendations}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747705},
	doi = {10.1145/3746059.3747705},
	abstract = {This paper introduces GestureCoach, a system designed to help speakers deliver more engaging talks by guiding them to gesture effectively during rehearsal. GestureCoach combines an LLM-driven gesture recommendation model with a rehearsal interface that proactively cues speakers to gesture appropriately. Trained on experts’ gesturing patterns from TED talks, the model consists of two modules: an emphasis proposal module, which predicts when to gesture by identifying gesture-worthy text segments in the presenter notes, and a gesture identification module, which determines what gesture to use by retrieving semantically appropriate gestures from a curated gesture database. Results of a model performance evaluation and user study (N=30) show that the emphasis proposal module outperforms off-the-shelf LLMs in identifying suitable gesture regions, and that participants rated the majority of these predicted regions and their corresponding gestures as highly appropriate. A subsequent user study (N=10) showed that rehearsing with GestureCoach encouraged speakers to gesture and significantly increased gesture diversity, resulting in more engaging talks. We conclude with design implications for future AI-driven rehearsal systems.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Ram, Ashwin and Suresh, Varsha and Saberpour Abadian, Artin and Demberg, Vera and Steimle, Jürgen},
	year = {2025},
	keywords = {Generative AI, Gesture, LLM, Presentation Talks},
}

@inproceedings{ross_rarr_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{RARR} {Unraveled}: {Component}-{Level} {Insights} into {Hallucination} {Detection} and {Mitigation}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730337},
	doi = {10.1145/3726302.3730337},
	abstract = {Large Language Models (LLMs) often exhibit hallucinations, which makes detecting and mitigating these errors a critical challenge. The Retrofit Attribution using Research and Revision (RARR) framework addresses this challenge by extracting key aspects of an LLM response, verifying them against retrieved evidence, and resolving errors through re-prompting. In this work, we critically examine RARR and adapt its framework to incorporate publicly available evidence retrieval systems and generative models, thereby operationalizing the approach. We focus on hallucination detection, analyzing how each pipeline component contributes to this task. We also conduct a sentence-level analysis of hallucinations to provide a more granular assessment of RARR's performance. A key finding is that while query generation and retrieval are effective, the agreement module emerges as the weakest link in the RARR pipeline. We offer deeper insights into RARR's strengths, limitations, and potential areas for improvement, thereby broadening our understanding of hallucination detection in LLMs.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Ross, Jonathan J and Khramtsova, Ekaterina and van der Vegt, Anton and Koopman, Bevan and Zuccon, Guido},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {large language models (llms)., retrieval augmented generation (rag)},
	pages = {3286--3295},
}

@inproceedings{huly_predicting_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Predicting {RAG} {Performance} for {Text} {Completion}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730062},
	doi = {10.1145/3726302.3730062},
	abstract = {We address the challenge of predicting the performance of using retrieval augmented generation (RAG) in large language models (LLMs) for the task of text completion; specifically, we predict the perplexity gain attained by applying RAG. We present novel supervised post-retrieval prediction methods that utilize the specific characteristics of the text completion setting. Our predictors substantially outperform a wide variety of prediction methods originally proposed for ad hoc document retrieval. We then show that integrating our post-retrieval predictors with recently proposed post-generation predictors - i.e., those analyzing the next-token distribution - is of much merit: the resultant prediction quality is statistically significantly better than that of using the post-generation predictors alone. Finally, we show that our post-retrieval predictors are as effective as post-generation predictors for selective application of RAG. This finding is of utmost importance in terms of efficiency of selective RAG.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Huly, Oz and Carmel, David and Kurland, Oren},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {llm, performance prediction, rag, text completion},
	pages = {1283--1293},
}

@inproceedings{qian_memorag_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{MemoRAG}: {Boosting} {Long} {Context} {Processing} with {Global} {Memory}-{Enhanced} {Retrieval} {Augmentation}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714805},
	doi = {10.1145/3696410.3714805},
	abstract = {Processing long contexts presents a significant challenge for large language models (LLMs). While recent advancements allow LLMs to handle much longer contexts than before (e.g., 32K or 128K tokens), it is computationally expensive and can still be insufficient for many applications. Retrieval-Augmented Generation (RAG) is considered a promising strategy to address this problem. However, conventional RAG methods face inherent limitations because of two underlying requirements: 1) explicitly stated queries, and 2) well-structured knowledge. These conditions, however, do not hold in general long-context processing tasks.In this work, we propose MemoRAG, a novel RAG framework empowered by global memory-augmented retrieval. MemoRAG features a dual-system architecture. First, it employs a light but long-range system to create a global memory of the long context. Once a task is presented, it generates draft answers, providing useful clues for the retrieval tools to locate relevant information within the long context. Second, it leverages an expensive but expressive system, which generates the final answer based on the retrieved information. Building upon this fundamental framework, we realize the memory module in the form of KV compression, and reinforce its memorization and cluing capacity from the Generation quality's Feedback (a.k.a. RLGF). In our experiments, MemoRAG achieves superior performances across a variety of long-context evaluation tasks, not only complex scenarios where traditional RAG methods struggle, but also simpler ones where RAG is typically applied.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Qian, Hongjin and Liu, Zheng and Zhang, Peitian and Mao, Kelong and Lian, Defu and Dou, Zhicheng and Huang, Tiejun},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {long context processing, retrieval-augmented generation},
	pages = {2366--2377},
}

@inproceedings{boumber_llms_2024,
	address = {New York, NY, USA},
	series = {{IWSPA} '24},
	title = {{LLMs} for {Explainable} {Few}-shot {Deception} {Detection}},
	isbn = {979-8-4007-0556-4},
	url = {https://doi.org/10.1145/3643651.3659898},
	doi = {10.1145/3643651.3659898},
	abstract = {This study investigates the effectiveness of Large Language Models (LLMs) in detecting deception using a Retrieval Augmented Generation (RAG) framework for few-shot learning in domain-agnostic settings. Our approach combines the sophisticated reasoning capabilities and extensive knowledge base of LLMs to identify deceptive statements across various contexts, with a focus on the explainability of the detection process. This emphasis on explainability enables a detailed analysis of the model's methodologies in distinguishing between truthful and deceptive statements. Additionally, we examine the impact of different definitions of deception, from overt falsehoods to subtle misrepresentations, on the model's accuracy. Our main contributions include providing initial insights into the adaptability of LLMs for deception detection and highlighting the challenges faced in this endeavor, thereby encouraging further exploration in this area.},
	booktitle = {Proceedings of the 10th {ACM} {International} {Workshop} on {Security} and {Privacy} {Analytics}},
	publisher = {Association for Computing Machinery},
	author = {Boumber, Dainis and Tuck, Bryan E. and Verma, Rakesh M. and Qachfar, Fatima Zahra},
	year = {2024},
	note = {event-place: Porto, Portugal},
	keywords = {business email compromise, explainability, fake news, job scams, language models, opinion spam, phishing, reasoning, retrieval augmented generation, sms spam, social engineering attacks},
	pages = {37--47},
}

@inproceedings{liu_graphcoder_2024,
	address = {New York, NY, USA},
	series = {{ASE} '24},
	title = {{GraphCoder}: {Enhancing} {Repository}-{Level} {Code} {Completion} via {Coarse}-to-fine {Retrieval} {Based} on {Code} {Context} {Graph}},
	isbn = {979-8-4007-1248-7},
	url = {https://doi.org/10.1145/3691620.3695054},
	doi = {10.1145/3691620.3695054},
	abstract = {The performance of repository-level code completion depends upon the effective leverage of both general and repository-specific knowledge. Despite the impressive capability of code LLMs in general code completion tasks, they often exhibit less satisfactory performance on repository-level completion due to the lack of repository-specific knowledge in these LLMs. To address this problem, we propose GraphCoder, a retrieval-augmented code completion framework that leverages LLMs' general code knowledge and the repository-specific knowledge via a graph-based retrieval-generation process. In particular, GraphCoder captures the context of completion target more accurately through code context graph (CCG) that consists of control-flow, data- and control-dependence between code statements, a more structured way to capture the completion target context than the sequence-based context used in existing retrieval-augmented approaches; based on CCG, GraphCoder further employs a coarse-to-fine retrieval process to locate context-similar code snippets with the completion target from the current repository. Experimental results demonstrate both the effectiveness and efficiency of GraphCoder: Compared to baseline retrieval-augmented methods, GraphCoder achieves higher exact match (EM) on average, with increases of +6.06 in code match and +6.23 in identifier match, while using less time and space.},
	booktitle = {Proceedings of the 39th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Wei and Yu, Ailun and Zan, Daoguang and Shen, Bo and Zhang, Wei and Zhao, Haiyan and Jin, Zhi and Wang, Qianxiang},
	year = {2024},
	note = {event-place: Sacramento, CA, USA},
	keywords = {code completion, code graphs, large language model, retrieval augmented generation},
	pages = {570--581},
}

@inproceedings{dang_authoring_2025,
	address = {New York, NY, USA},
	series = {{IUI} '25},
	title = {Authoring {LLM}-{Based} {Assistance} for {Real}-{World} {Contexts} and {Tasks}},
	isbn = {979-8-4007-1306-4},
	url = {https://doi.org/10.1145/3708359.3712164},
	doi = {10.1145/3708359.3712164},
	abstract = {Advances in AI hold the possibility of assisting users with highly varied and individual needs, but the breadth of assistance that these systems could provide creates a challenge for how users specify their goals to the system. To support the authoring of AI assistance for real-world tasks, we propose the concept of Contextually-Driven Prompts (CDPs) that define how an AI assistant should respond to real-world context. We implemented a prototype system for authoring and executing CDPs, which provides suggestions to assist users with finding the right level of assistance for their goal. We also conducted a user study (N=10) to investigate how participants express and refine their goals for real-world tasks. Results revealed a number of strategies for initiating and refining CDPs with suggestions, and implications for the design of future authoring interfaces.},
	booktitle = {Proceedings of the 30th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Dang, Hai and Lafreniere, Ben and Grossman, Tovi and Todi, Kashyap and Li, Michelle},
	year = {2025},
	keywords = {generative AI, large language model, virtual assistants, vision language model, voice-based interaction},
	pages = {211--230},
}

@inproceedings{cui_cirag_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{CIRAG}: {Retrieval}-{Augmented} {Language} {Model} with {Collective} {Intelligence}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3729921},
	doi = {10.1145/3726302.3729921},
	abstract = {Retrieval-augmented generation (RAG) paradigms can integrate external knowledge to enhance and validate the output of Large Language Models (LLMs) thereby mitigating generative hallucinations and broadening the model's knowledge scope. Despite advancements, existing RAG methods still suffer from uncertainty of prediction during the multi-round retrieval-generation process, and a lack of the ability to balance the adequacy and redundancy of retrieved information. To address these challenges, we propose CIRAG, an approach that combines the RAG process with collective intelligence. Inspired by the crowd of wisdom, CIRAG simulates individual independent decision-making and information aggregation within a crowd. Specifically, CIRAG first enhances retrieval diversity by expanding queries based on extracted entities, then combines frequency-based and semantic-based reranking to form a multi granularity fusion reranking thereby assessing better relevance, and integrate multiple information sources for accurate content generation. By undertaking these steps in an integrated manner, CIRAG enables the model to acquire comprehensive and non-redundant information for generating responses. We conduct extensive experiments with HotPotQA and 2WikiMultihopQA datasets, popular benchmark for retrieval-based, multi-step question-answering. Experimental results show that our approach surpasses existing advanced RAG framework while providing high portability in query expansion as well as strong comprehensiveness exhibited in the collective intelligence.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Cui, Chenxu and Fan, Haihui and Zhang, Jinchao and Shen, Lin and Li, Bo and Wang, Weiping},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {information retrieval, natural language processing, query expansion, reranking, retrieval-augmented generation},
	pages = {1316--1326},
}

@inproceedings{xin_atomr_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{AtomR}: {Atomic} {Operator}-{Empowered} {Large} {Language} {Models} for {Heterogeneous} {Knowledge} {Reasoning}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3736849},
	doi = {10.1145/3711896.3736849},
	abstract = {Despite the outstanding capabilities of large language models (LLMs), knowledge-intensive reasoning still remains a challenging task due to LLMs' limitations in compositional reasoning and the hallucination problem. A prevalent solution is to employ chain-of-thought (CoT) with retrieval-augmented generation (RAG), which first formulates a reasoning plan by decomposing complex questions into simpler sub-questions, and then applies iterative RAG at each sub-question. However, prior works exhibit two crucial problems: inadequate reasoning planning and poor incorporation of heterogeneous knowledge. In this paper, we introduce AtomR, a framework for LLMs to conduct accurate heterogeneous knowledge reasoning at the atomic level. Inspired by how knowledge graph query languages model compositional reasoning through combining predefined operations, we propose three atomic knowledge operators, a unified set of operators for LLMs to retrieve and manipulate knowledge from heterogeneous sources. First, in the reasoning planning stage, AtomR decomposes a complex question into a reasoning tree where each leaf node corresponds to an atomic knowledge operator, achieving question decomposition that is highly fine-grained and orthogonal. Subsequently, in the reasoning execution stage, AtomR executes each atomic knowledge operator, which flexibly selects, retrieves, and operates atomic level knowledge from heterogeneous sources. We also introduce BlendQA, a challenging benchmark specially tailored for heterogeneous knowledge reasoning. Experiments on three single-source and two multi-source datasets show that AtomR outperforms state-of-the-art baselines by a large margin, with absolute F1 score improvements of 9.4\% on 2WikiMultihop and 9.5\% on BlendQA. We release our code and data https://github.com/THU-KEG/AtomR.git.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Xin, Amy and Liu, Jinxin and Yao, Zijun and Lee, Zhicheng and Cao, Shulin and Hou, Lei and Li, Juanzi},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {knowledge-intensive reasoning, large language models, multi-hop qa, retrieval-augmented generation},
	pages = {3344--3355},
}

@inproceedings{proma_personalizing_2025,
	address = {New York, NY, USA},
	series = {{UMAP} '25},
	title = {Personalizing {LLM} {Responses} to {Combat} {Political} {Misinformation}},
	isbn = {979-8-4007-1313-2},
	url = {https://doi.org/10.1145/3699682.3728349},
	doi = {10.1145/3699682.3728349},
	abstract = {Despite various efforts to tackle online misinformation, people inevitably encounter and engage with it, especially on social media platforms. Recent advances in LLMs present an opportunity to develop personalized interventions to address misinformed beliefs, and potentially offer more effective approaches than existing non-tailored methods. In this paper, we design and evaluate personalized LLM agent that can consider users’ demographics and personalities to tailor responses to mitigate misinformed beliefs. Our pipeline is grounded in facts through an external Retrieval Augmented Generation (RAG) knowledge base and is able to generate diverse output as a result of the personalization, with an average cosine similarity of 0.538. Our pipeline scores an average rating of 3.99 out of 5 when evaluated by a GPT-4o-mini LLM judge for response persuasiveness. Our methods can be adapted to design similar personalized agents in other domains.},
	booktitle = {Proceedings of the 33rd {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {Association for Computing Machinery},
	author = {Proma, Adiba and Pate, Neeley and Druckman, James and Ghoshal, Gourab and Hoque, Ehsan},
	year = {2025},
	keywords = {LLM Agents, Misinformation, Personalization, Persuasion, RAG systems},
	pages = {134--143},
}

@inproceedings{imasaka_effect_2024,
	address = {New York, NY, USA},
	series = {{SIGIR}-{AP} 2024},
	title = {Effect of {LLM}'s {Personality} {Traits} on {Query} {Generation}},
	isbn = {979-8-4007-0724-7},
	url = {https://doi.org/10.1145/3673791.3698433},
	doi = {10.1145/3673791.3698433},
	abstract = {Large language models (LLMs) have demonstrated strong performance across various natural language processing tasks and are increasingly integrated into daily life. Just as personality traits are crucial in human communication, they could also play a significant role in the behavior of LLMs, for instance, in the context of Retrieval Augmented Generation. Previous studies have shown that Big Five personality traits could be applied to LLMs, but their specific effects on information retrieval tasks have not been sufficiently explored. This study aims to examine how personality traits assigned to LLM agents affect their query formulation behavior and search performance. We propose a method to accurately assign personality traits to LLM agents based on the Big Five theory and verify its accuracy using the IPIP-NEO-120 scale. We then design a query generation experiment using the NTCIR Ad-Hoc test collections and evaluate the search performance of queries generated by different LLM agents. The results show that our method successfully assigns all five personality traits to LLM agents as intended. Additionally, the query generation experiment suggests that the assigned traits did influence the length and vocabulary choices of generated queries. Finally, the retrieval effectiveness of the traits varied across test collections, showing a relative improvement ranging from -7.7\% to +4.6\%, but these differences were not statistically significant.},
	booktitle = {Proceedings of the 2024 {Annual} {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval} in the {Asia} {Pacific} {Region}},
	publisher = {Association for Computing Machinery},
	author = {Imasaka, Yuta and Joho, Hideo},
	year = {2024},
	note = {event-place: Tokyo, Japan},
	keywords = {large language model, personality traits, query generation},
	pages = {249--258},
}

@inproceedings{hammoud_human_2024,
	address = {New York, NY, USA},
	series = {{MLCAD} '24},
	title = {Human {Language} to {Analog} {Layout} {Using} {GLayout} {Layout} {Automation} {Framework}},
	isbn = {979-8-4007-0699-8},
	url = {https://doi.org/10.1145/3670474.3685971},
	doi = {10.1145/3670474.3685971},
	abstract = {Current approaches to Analog Layout Automation apply ML techniques such as Graph Convolutional Neural Networks (GCN) to translate netlist to layout. While these ML approaches have proven to be effective, they lack the powerful reasoning capabilities, an intuitive human interface, and standard evaluation benchmarks that have been improving at a rapid development pace in Large Language Models (LLMs). The GLayout framework introduced in this work translates analog layout into an expressive, technology generic, compact text representation. Then, an LLM is taught to understand analog layout through fine-tuning and in-context learning using Retrieval Augmented Generation (RAG). The LLM is able to successfully layout unseen circuits based on new information provided in-context. We train 3.8, 7, and 22 Billion parameter quantized LLMs on a dataset of less than 50 unique circuits, and text documents providing layout knowledge. The 22B parameter model is tuned in 2 hours on a single NVIDIA A100 GPU. The open-source evaluation set is proposed as an automation benchmark for LLM layout automation tasks, and ranges from 2-transistor circuits to a ΔΣ ADC. The 22B model completes 70\% of the tasks in the evaluation set, and passes DRC and LVS verification on 44\% of evaluations with verified correct blocks up to 4 transistors in size.},
	booktitle = {Proceedings of the 2024 {ACM}/{IEEE} {International} {Symposium} on {Machine} {Learning} for {CAD}},
	publisher = {Association for Computing Machinery},
	author = {Hammoud, Ali and Goyal, Chetanya and Pathen, Sakib and Dai, Arlene and Li, Anhang and Kielian, Gregory and Saligane, Mehdi},
	year = {2024},
	note = {event-place: Salt Lake City, UT, USA},
	keywords = {Analog Layout Automation, GLayout, Large Language Model, Open Source, Parameter Efficient Fine Tuning, Quantized Low Rank Adaptation (QLORA), Retrieval Augmented Generation (RAG)},
}

@inproceedings{fuchs_practical_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Practical {Fact} {Checking} {System} for {LLMs}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3717849},
	doi = {10.1145/3701716.3717849},
	abstract = {The use of Large Language Models (LLM) like ChatGPT in real-world product solutions is significantly limited by the well-known issue of hallucinations. Various methods exist in order to overcome this issue automatically, such as using a different LLM to provide feedback on the accuracy of the generated text or by examining the output consistency given multiple sampled responses. However, these approaches do not guarantee factual accuracy, which is crucial in many specialized domains. In order to enhance the factual correctness of generated text by LLM models, a combination of manual annotations and supportive tools are required. We suggest a practical fact checking system tailored specifically for LLMs which combines a hybrid approach (human and machine) to evaluate the correctness of the generated text. This is particularly vital in fields where hallucinations present significant challenges. We use proprietary LLMs, both directly and through Retrieval-Augmented Generation (RAG), to offer users informed feedback on potential hallucinations via a user-friendly interface. We apply our methodology to the task of generating aspect values for video games in listings from an E-commerce marketplace, demonstrating the utility of our approach.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Fuchs, Gilad and Zinman, Oded and Ben-Shaul, Ido},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {fact-checking, hallucinations, large language models},
	pages = {2713--2716},
}

@inproceedings{barat_constructing_2025,
	address = {New York, NY, USA},
	series = {{ISEC} '25},
	title = {Constructing {Enterprise} {Digital} {Twins} by {Augmenting} {LLMs} with {MDE}},
	isbn = {979-8-4007-1424-5},
	url = {https://doi.org/10.1145/3717383.3717391},
	doi = {10.1145/3717383.3717391},
	abstract = {Over the past year, Large Language Models (LLMs) have proven their value across a diverse range of industrial applications starting from supporting software development to automating customer interactions and enhancing process automation. We harness their potential for constructing Enterprise Digital Twins (EDTs), an emerging decision-making aid for a wide range of business sectors. EDT offers an effective "in silico" business experimentation leading to evidence-based informed decision-making, but its construction requires deep domain expertise spanning multiple aspects of enterprises across multiple stakeholders. Moreover, constructing an effective EDT demands seamless coordination between domain experts and expert modelers. These critical dependencies make the EDT construction challenging. This paper investigates the role of LLMs as domain experts and expert modelers to reduce excessive dependencies on both specializations and their coordination to an extent. Our approach integrates meta-modelling and Model Driven Engineering (MDE) techniques to effectively utilize LLMs with increased precision to alleviate the cognitive burden on domain experts and provide a systematic metamodel guided method for constructing purposive digital twins. We illustrate the approach and demonstrate its efficacy using a real-life EDT use case.},
	booktitle = {Proceedings of the 18th {Innovations} in {Software} {Engineering} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Barat, Souvik and Mulpuru, Dushyanthi and Yadav, Abhishek and Korabu, Reshma and Thogaru, Himabindu and Kulkarni, Vinay},
	year = {2025},
	keywords = {ChatGPT, Digital Twin, Large Language Model, LLM, Model Driven Engineering},
}

@inproceedings{bradland_new_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {A {New} {HOPE}: {Domain}-agnostic {Automatic} {Evaluation} of {Text} {Chunking}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3729882},
	doi = {10.1145/3726302.3729882},
	abstract = {Document chunking fundamentally impacts Retrieval-Augmented Generation (RAG) by determining how source materials are segmented before indexing. Despite evidence that Large Language Models (LLMs) are sensitive to the layout and structure of retrieved data, there is currently no framework to analyze the impact of different chunking methods. In this paper, we introduce a novel methodology that defines essential characteristics of the chunking process at three levels: intrinsic passage properties, extrinsic passage properties, and passages-document coherence. We propose HOPE (Holistic Passage Evaluation), a domain-agnostic, automatic evaluation metric that quantifies and aggregates these characteristics. Our empirical evaluations across seven domains demonstrate that the HOPE metric correlates significantly (p \&gt; 0.13) with various RAG performance indicators, revealing contrasts between the importance of extrinsic and intrinsic properties of passages. Semantic independence between passages proves essential for system performance with a performance gain of up to 56.2\% in factual correctness and 21.1\% in answer correctness. On the contrary, traditional assumptions about maintaining concept unity within passages show minimal impact. These findings provide actionable insights for optimizing chunking strategies, thus improving RAG system design to produce more factually correct responses.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Brådland, Henrik and Goodwin, Morten and Andersen, Per-Arne and Nossum, Alexander S. and Gupta, Aditya},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {document chunking, natural language processing, passage evaluation, retrieval-augmented generation, text embedding},
	pages = {170--179},
}

@inproceedings{zhang_litfm_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{LitFM}: {A} {Retrieval} {Augmented} {Structure}-aware {Foundation} {Model} {For} {Citation} {Graphs}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737028},
	doi = {10.1145/3711896.3737028},
	abstract = {With the advent of large language models (LLMs), managing scientific literature via LLMs has become a promising direction of research. However, existing approaches often overlook the rich structural and semantic relevance among scientific literature, limiting their ability to discern the relationships between pieces of scientific knowledge, and suffer from various types of hallucinations. These methods also focus narrowly on individual downstream tasks, limiting their applicability across use cases. We propose LitFM, the first literature foundation model designed for a wide variety of practical downstream tasks on domain-specific literature, with a focus on citation information. At its core, LitFM contains a novel graph retriever that can provide accurate and diverse recommendations for LLM to integrate graph structure information and relevant literature. LitFM also leverages a knowledge-infused LLM, fine-tuned through a well-developed instruction paradigm. It enables LitFM to extract domain-specific knowledge from literature and reason relationships among them. By integrating citation graphs during both training and inference, LitFM can generalize to unseen papers and accurately assess their relevance within existing literature. Additionally, we introduce new large-scale literature citation benchmark datasets on three academic fields, featuring sentence-level citation information and local context. Extensive experiments validate the superiority of LitFM, achieving 28.1\% improvement on retrieval task in precision, and an average improvement of 7.52\% over state-of-the-art across six downstream literature-related tasks.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Jiasheng and Maatouk, Ali and Chen, Jialin and Bui, Ngoc and Xie, Qianqian and Tassiulas, Leandros and Xu, Hua and Shao, Jie and Ying, Rex},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {citation graph, foundation model, large language model},
	pages = {3728--3739},
}

@inproceedings{abbasiantaeb_conversational_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Conversational {Gold}: {Evaluating} {Personalized} {Conversational} {Search} {System} {Using} {Gold} {Nuggets}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730316},
	doi = {10.1145/3726302.3730316},
	abstract = {The rise of personalized conversational search systems has been driven by advancements in Large Language Models (LLMs), enabling these systems to retrieve and generate answers for complex information needs. However, the automatic evaluation of responses generated by Retrieval Augmented Generation (RAG) systems remains an understudied challenge. In this paper, we introduce a new resource for assessing the retrieval effectiveness and relevance of responses generated by RAG systems, using a nugget-based evaluation framework. Built upon the foundation of TREC iKAT 2023, our dataset extends to the TREC iKAT 2024 collection, which includes 17 conversations and 20,575 relevance passage assessments, together with 2,279 extracted gold nuggets and 62 manually written gold answers from NIST assessors. While maintaining the core structure of its predecessor, this new collection enables a deeper exploration of generation tasks in conversational settings. Key improvements in iKAT 2024 include: (1) ”gold nuggets” - concise, essential pieces of information extracted from relevant passages of the collection - which serve as a foundation for automatic response evaluation; (2) manually written answers to provide a gold standard for response evaluation; (3) expanded user personas, providing richer contextual grounding; and (4) a transition from Personal Text Knowledge Base (PTKB) ranking to PTKB classification and selection. Built on this resource, we provide a framework for long-form answer generation evaluation, involving nugget extraction and nugget matching, linked to retrieval. This establishes a solid resource for advancing research in personalized conversational search and long-form answer generation. Our resources are publicly available at https://github.com/irlabamsterdam/CONE-RAG.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Abbasiantaeb, Zahra and Lupart, Simon and Azzopardi, Leif and Dalton, Jeffrey and Aliannejadi, Mohammad},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {conversational information seeking, evaluation, information nuggets, retrieval-augmented generation, test collection},
	pages = {3455--3465},
}

@inproceedings{grimm_conversational_2024,
	address = {New York, NY, USA},
	series = {{HUMAN} '24},
	title = {Conversational {Data} {Stories}},
	isbn = {979-8-4007-1120-6},
	url = {https://doi.org/10.1145/3679058.3688631},
	doi = {10.1145/3679058.3688631},
	abstract = {Data stories are about revealing and communicating insights from complex data. In this paper, we propose conversational data stories, which support end users in understanding the key findings of the data analysis at hand by natural language conversation. Creating these stories manually means to put a lot of effort into understanding the data and crafting visuals. With increasingly powerful generative large language models (LLMs), natural language processing as well as automating the creation of data stories is a promising field. We present a concept for a conversational data storytelling system that integrates LLMs as well as explainable AI. We present the collected requirements for our system concept and how the requirements are addressed. To show the potential of our approach, we provide a use case scenario and a discussion in this paper. This is supposed to serve as a basis for future research that will aim at investigating the technical reliability and the user experience of such a system.},
	booktitle = {Proceedings of the 7th {Workshop} on {Human} {Factors} in {Hypertext}},
	publisher = {Association for Computing Machinery},
	author = {Grimm, Valentin and Rubart, Jessica and Söhlke, Patrick},
	year = {2024},
	note = {event-place: Poznan, Poland},
	keywords = {Conversational Assistant, Conversational Data Storytelling, Data Storytelling, Explainable AI},
}

@inproceedings{wu_xinyu_2024,
	address = {New York, NY, USA},
	series = {{KDD} '24},
	title = {Xinyu: {An} {Efficient} {LLM}-based {System} for {Commentary} {Generation}},
	isbn = {979-8-4007-0490-1},
	url = {https://doi.org/10.1145/3637528.3671537},
	doi = {10.1145/3637528.3671537},
	abstract = {Commentary provides readers with a deep understanding of events by presenting diverse arguments and evidence. However, creating commentary is a time-consuming task, even for skilled commentators. Large language models (LLMs) have simplified the process of natural language generation, but their direct application in commentary creation still faces challenges due to unique task requirements. These requirements can be categorized into two levels: 1) fundamental requirements, which include creating well-structured and logically consistent narratives, and 2) advanced requirements, which involve generating quality arguments and providing convincing evidence. In this paper, we introduce Xinyu, an efficient LLM-based system designed to assist commentators in generating Chinese commentaries. To meet the fundamental requirements, we deconstruct the generation process into sequential steps, proposing targeted strategies and supervised fine-tuning (SFT) for each step. To address the advanced requirements, we present an argument ranking model for arguments and establish a comprehensive evidence database that includes up-to-date events and classic books, thereby strengthening the substantiation of the evidence with retrieval augmented generation (RAG) technology. To evaluate the generated commentaries more fairly, corresponding to the two-level requirements, we introduce a comprehensive evaluation metric that considers five distinct perspectives in commentary generation. Our experiments confirm the effectiveness of our proposed system. We also observe a significant increase in the efficiency of commentators in real-world scenarios, with the average time spent on creating a commentary dropping from 4 hours to 20 minutes. Importantly, such an increase in efficiency does not compromise the quality of the commentaries.},
	booktitle = {Proceedings of the 30th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Wu, Yiquan and Tang, Bo and Xi, Chenyang and Yu, Yu and Wang, Pengyu and Liu, Yifei and Kuang, Kun and Deng, Haiying and Li, Zhiyu and Xiong, Feiyu and Hu, Jie and Cheng, Peng and Wang, Zhonghao and Wang, Yi and Luo, Yi and Yang, Mingchuan},
	year = {2024},
	note = {event-place: Barcelona, Spain},
	keywords = {commentary generation, llm-based system, retrieval augmented generation, supervised fine-tuning},
	pages = {6003--6014},
}

@inproceedings{mao_multi-agent_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {A {Multi}-{Agent} {Framework} for {Multi}-{Source} {Manufacturing} {Knowledge} {Integration} and {Question} {Answering}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3716884},
	doi = {10.1145/3701716.3716884},
	abstract = {The integration of next-generation information technologies in the manufacturing sector has resulted in the generation of extensive and complex knowledge data by organizations. Effectively managing and utilizing this dispersed knowledge presents a significant challenge. This paper proposes a Multi-Agent-based, Multi-Source, and Multimodal Retrieval-Augmented Generation (RAG) framework specifically designed for the manufacturing industry. By employing advanced methodologies such as multimodal document parsing, multi-source data integration, and intelligent agent-driven querying, the proposed framework aims to address the interconnected challenges of knowledge management and intelligent question answering in complex manufacturing environments. The principal contributions of this research include: (1) the advancement of sophisticated multimodal document parsing techniques, (2) the establishment of robust strategies for multi-source data integration, (3) the development of a comprehensive multi-agent intelligent question-answering system, and (4) the enhancement of the Thinking RAG model. This framework provides a holistic solution to the complexities associated with knowledge management and improves retrieval efficiency in the manufacturing sector.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Mao, Teng and Yang, Shuangtao and Fu, Bo},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {intelligent manufacturing, multi-agent systems, multi-source data, multimodal documents, thinking retrieval-augmented generation},
	pages = {1687--1695},
}

@inproceedings{zhai_information_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Information {Retrieval} for {Artificial} {General} {Intelligence}: {A} {New} {Perspective} of {Information} {Retrieval} {Research}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730349},
	doi = {10.1145/3726302.3730349},
	abstract = {Traditionally, the users of an information retrieval (IR) system have been human users. We present a new perspective on IR research in which the users of an IR system are intelligent agents instead of human users. Extending the current work on retrieval-augmented generation (RAG), we identify five novel IR tasks that an intelligent agent must be able to perform in order to achieve Human-Level Artificial Intelligence, or Artificial General Intelligence (AGI), including 1) External Information Retrieval (EIR) to access new information unseen by the agent, 2) Provenance Information Retrieval (PIR) to trace the provenance of information, 3) Curriculum Information Retrieval (CIR) to actively acquire the most useful new data and information for lifelong learning, 4) Rule Information Retrieval (RIR) to perform reasoning and problem solving, and 5) Scenario Information Retrieval (SIR) to leverage past scenarios for problem solving and decision making. We compare these new IR tasks with the traditional IR tasks performed by an IR system that serves human users and systematically examine the challenges involved in the five new IR tasks, providing a roadmap for new IR research within the broader context of AGI development.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zhai, ChengXiang},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {artificial general intelligence, neurosymbolic architecture, new retrieval tasks, retrieval for agent, retrieval-augmented generation},
	pages = {3876--3886},
}

@inproceedings{almuntashiri_using_2025,
	address = {New York, NY, USA},
	series = {{PW}' 25},
	title = {Using {LLMs} to infer provenance information},
	isbn = {979-8-4007-1941-7},
	url = {https://doi.org/10.1145/3736229.3736261},
	doi = {10.1145/3736229.3736261},
	abstract = {Having a provenance record facilitates data reuse and experimental reuse. However, provenance capture requires either: specific provenance-enabled systems to be used or human documentation. While there have been many examples of provenance-enabled systems for scientific usage, they are still the exception, not the norm. The one, standard place for provenance information of scientific experiments remains the scientific publication. Unfortunately, provenance buried in text is not immediately useful for computational purposes. Large Language Models (LLMs) have demonstrated exceptional capability across various tasks, particularly in information extraction. In this paper, we explore the potential of LLMs to infer a provenance record for scientific experiments from scientific papers. We develop an extractor, identify the most effective prompt for provenance extraction. Our results emphasise the capability of ChatGPT-4o in accessing and extracting provenance information from biomedical research papers. Additionally, we assess the scalability of the extractor for use in extracting provenance information across a set of biomedical research papers.},
	booktitle = {Proceedings of the {ProvenanceWeek} 2025},
	publisher = {Association for Computing Machinery},
	author = {Almuntashiri, Abdullah Hamed and Ibáñez, Luis-Daniel and Chapman, Adriane},
	year = {2025},
	keywords = {Dataset Search, Information Extraction, LLMs, Provenance},
	pages = {1--10},
}

@inproceedings{zhang_cream_2024,
	address = {New York, NY, USA},
	series = {{MM} '24},
	title = {{CREAM}: {Coarse}-to-{Fine} {Retrieval} and {Multi}-modal {Efficient} {Tuning} for {Document} {VQA}},
	isbn = {979-8-4007-0686-8},
	url = {https://doi.org/10.1145/3664647.3680750},
	doi = {10.1145/3664647.3680750},
	abstract = {Document Visual Question Answering (DVQA) involves responding to queries based on the contents of document images. Existing works are confined to locating information within a single page and lack support for cross-page question-and-answer interactions. Furthermore, the token length limitation on model inputs can lead to the truncation of answer-relevant segments. In this study, we present CREAM, an innovative methodology that focuses on high-performance retrieval and integrates relevant multimodal document information to effectively address this critical issue. To overcome the limitations of current text embedding similarity methods, we first employ a coarse-to-fine retrieval and ranking approach. The coarse phase calculates the similarity between the query and text chunk embeddings, while the fine phase involves multiple rounds of grouping and ordering with a large language model to identify the text chunks most relevant to the query. Subsequently, integrating an attention pooling mechanism for multi-page document images into the vision encoder allows us to effectively merge the visual information of multi-page documents, enabling the multimodal large language model (MLLM) to simultaneously process both single-page and multi-page documents. Finally, we apply various parameter-efficient tuning methods to enhance document visual question-answering performance. Experiments demonstrate that our approach secures state-of-the-art results across various document datasets.},
	booktitle = {Proceedings of the 32nd {ACM} {International} {Conference} on {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Jinxu and Yu, Yongqi and Zhang, Yu},
	year = {2024},
	note = {event-place: Melbourne VIC, Australia},
	keywords = {document vqa, large language model ranking, multi-page document representation, retrieval augmented generation},
	pages = {925--934},
}

@inproceedings{feng_forage_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{FoRAGe}: {High}-{CTR} {Food} {Image} {Synthesis} with {Retrieval}-{Augmented} {Diffusion} {Model}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737223},
	doi = {10.1145/3711896.3737223},
	abstract = {High Click-Through Rate (CTR) imagery has proven commercial value for food delivery platforms, driving a need for strategies to generate visually compelling images. Our investigations reveal a positive correlation between appropriate food backgrounds and subsequent user engagement. Despite advancements in diffusion models, inpainting new backgrounds does not guarantee high CTR, and fine-tuning diffusion models for this purpose is prohibitively expensive for the fast-paced online food delivery advertising sector. Consequently, there is a lack of cost-effective, transferable generation frameworks tailored to high-CTR food images. In this paper, we propose FoRAGe, a novel high-CTR Food image Retrieval-Augmented Generation pipeline leveraging ControlNet based on Stable Diffusion. Specifically, we construct a comprehensive food image database encompassing a diverse range of background environments. During image generation, FoRAGe retrieves high-quality background exemplars featuring analogous food subjects from the database and employs the retrieved backgrounds as conditions to guide image synthesis via the ControlNet model. Subsequently, a multimodal CTR prediction model is utilized to identify and select optimal images for deployment. Extensive online experiments demonstrate a significant increase in CTR for images generated by our proposed pipeline, and ablation studies further elucidate the impact of different strategies and configurations. Code is available at https://github.com/jiaxu-feng/FoRAGe.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Feng, Jiaxu and Gao, Xinyu and Huang, Muqi and Xu, Kanjun and Xiong, Yun and Zhou, Kun and Li, Chuan and Shi, Feng},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {click-through rate prediction, diffusion model, food delivery, retrieval-augmented generation},
	pages = {4414--4423},
}

@inproceedings{gu_adaptive_2024,
	address = {New York, NY, USA},
	series = {{ICAIF} '24},
	title = {Adaptive and {Explainable} {Margin} {Trading} via {Large} {Language} {Models} on {Portfolio} {Management}},
	isbn = {979-8-4007-1081-0},
	url = {https://doi.org/10.1145/3677052.3698681},
	doi = {10.1145/3677052.3698681},
	abstract = {Recent strategies for portfolio management often lack flexibility to adjust funds between long and short positions throughout trading periods. This prevents adapting portfolios to the market, which mitigates risks and seizes opportunities. To address these gaps, we propose an adaptive and explainable framework that integrates Large Language Models (LLMs) with Reinforcement Learning (RL) for dynamic long-short position adjustment in response to evolving market conditions. This approach leverages the recent advancements in LLMs for processing unstructured data and their capacity for explainable reasoning. The framework includes two stages: an Explainable Market Forecasting/Reasoning Pipeline, and a Position Reallocation stage. The Market Forecasting/Reasoning Pipeline allows various LLMs to learn market trends from diverse external data sources and determine optimal adjustment ratios with a clear reasoning path. The Portfolio Reallocation stage interacts with the sequential trading process from a pre-trained RL model to enhance decision-making and transparency. Our framework is flexible to accommodate various external data sources from microeconomics to macroeconomics data, diverse data types including time series and news text, along with multiple LLMs. Experiments demonstrate that our framework effectively achieves three times the return and doubles the Sharpe ratio compared to benchmarks. All the data and code are publicly available under NJIT FinTech Lab’s GitHub1.},
	booktitle = {Proceedings of the 5th {ACM} {International} {Conference} on {AI} in {Finance}},
	publisher = {Association for Computing Machinery},
	author = {Gu, Jingyi and Ye, Junyi and Wang, Guiling and Yin, Wenpeng},
	year = {2024},
	note = {event-place: Brooklyn, NY, USA},
	keywords = {Explainable AI, Large Language Model, Market Trend Forecasting, Portfolio Management, Reinforcement Learning},
	pages = {248--256},
}

@inproceedings{chukwu_may_2025,
	address = {New York, NY, USA},
	series = {{EuroMLSys} '25},
	title = {May the {Memory} {Be} {With} {You}: {Efficient} and {Infinitely} {Updatable} {State} for {Large} {Language} {Models}},
	isbn = {979-8-4007-1538-9},
	url = {https://doi.org/10.1145/3721146.3721951},
	doi = {10.1145/3721146.3721951},
	abstract = {Large language models (LLMs) excel at natural language tasks but lack persistent state management for personalized and adaptive interactions. We propose a framework that endows these models with stateful capabilities by combining retrieval-augmented generation (RAG) and low-rank adaptation (LoRA). Our approach recasts the LLM as an editable component that retains hierarchical knowledge, analogous to deferred merge operations in log-structured merge (LSM) trees. The system integrates short-term context with long-term memory by storing accumulated context in a retrieval system while periodically training and combining lightweight LoRA adapters. Preliminary evaluations demonstrate improved state retention and query performance compared to both standard LLMs and RAG-augmented models, supporting our vision for scalable, stateful AI systems.},
	booktitle = {Proceedings of the 5th {Workshop} on {Machine} {Learning} and {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Chukwu, Excel and Bindschaedler, Laurent},
	year = {2025},
	note = {event-place: World Trade Center, Rotterdam, Netherlands},
	keywords = {contextual knowledge management, hierarchical state management, large language models, log-structured merge trees, low-rank adaptation, persistent state retention, retrieval-augmented generation, stateful AI systems},
	pages = {200--207},
}

@inproceedings{deeksha_emu-llm_2025,
	address = {New York, NY, USA},
	series = {{ICPE} '25},
	title = {{EMU}-{LLM}: {Emulators} for {Performance} {Evaluation} of {LLM}-based {Applications}},
	isbn = {979-8-4007-1130-5},
	url = {https://doi.org/10.1145/3680256.3721312},
	doi = {10.1145/3680256.3721312},
	abstract = {With the advent of Large Language Models (LLMs) in modern web applications, rigorous performance testing has become essential to assess application's speed, stability, and resource usage under diverse workload conditions. While third-party APIs enable rapid integration and scaling in LLM-based applications, scalability testing with these APIs often incurs high costs and adds complexity throughout the development cycle. To address these challenges, we propose EMU-LLM, a framework that automatically selects and integrates emulators to replace third-party APIs while preserving LLM behavior. This emulator-centric approach offers a cost-effective solution for performance evaluation and system testing of LLM-based web applications. Our framework enhances the robustness and efficiency of applications and highlights promising directions for future research. This paper aims to guide researchers, developers, and testers on the significance of emulators in optimizing LLM performance and fostering growth.},
	booktitle = {Companion of the 16th {ACM}/{SPEC} {International} {Conference} on {Performance} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Deeksha, Deeksha and Krishnan, Ashwin and Nambiar, Manoj},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {emulators, large language model, performance testing, performance.},
	pages = {130--135},
}

@inproceedings{bui_cross-data_2024,
	address = {New York, NY, USA},
	series = {{AIQAM} '24},
	title = {Cross-{Data} {Knowledge} {Graph} {Construction} for {LLM}-enabled {Educational} {Question}-{Answering} {System}: {A} {Case} {Study} at {HCMUT}},
	isbn = {979-8-4007-0547-2},
	url = {https://doi.org/10.1145/3643479.3662055},
	doi = {10.1145/3643479.3662055},
	abstract = {In today's rapidly evolving landscape of Artificial Intelligence, large language models (LLMs) have emerged as a vibrant research topic. LLMs find applications in various fields and contribute significantly. Despite their powerful language capabilities, similar to pre-trained language models (PLMs), LLMs still face challenges in remembering events, incorporating new information, and addressing domain-specific issues or hallucinations. To overcome these limitations, researchers have proposed Retrieval-Augmented Generation (RAG) techniques, some others have proposed the integration of LLMs with Knowledge Graphs (KGs) to provide factual context, thereby improving performance and delivering more accurate feedback to user queries.Education plays a crucial role in human development and progress. With the technology transformation, traditional education is being replaced by digital or blended education. Therefore, educational data in the digital environment is increasing day by day. Data in higher education institutions are diverse, comprising various sources such as unstructured/structured text, relational databases, web/app-based API access, etc. Constructing a Knowledge Graph from these cross-data sources is not a simple task. This article proposes a method for automatically constructing a Knowledge Graph from multiple data sources and discusses some initial applications (experimental trials) of KG in conjunction with LLMs for question-answering tasks.},
	booktitle = {Proceedings of the 1st {ACM} {Workshop} on {AI}-{Powered} {Q}\&amp;{A} {Systems} for {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Bui, Tuan and Tran, Oanh and Nguyen, Phuong and Ho, Bao and Nguyen, Long and Bui, Thang and Quan, Tho},
	year = {2024},
	note = {event-place: Phuket, Thailand},
	keywords = {Education, Knowledge Graph, Large language model, Open Intent Discovery, Question-Answering System},
	pages = {36--43},
}

@inproceedings{zhao_explainable_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Explainable {LLM}-driven {Multi}-dimensional {Distillation} for {E}-{Commerce} {Relevance} {Learning}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715222},
	doi = {10.1145/3701716.3715222},
	abstract = {Effective query-item relevance modeling is pivotal for enhancing user experience and safeguarding user satisfaction in e-commerce search systems. Recently, benefiting from the vast inherent knowledge, Large Language Model (LLM) approach demonstrates strong performance and long-tail generalization ability compared with previous neural-based specialized relevance learning methods. Though promising, current LLM-based method encounters the following inadequacies in practice: Firstly, the relevance modeling process is a black box, making it difficult to clearly understand why LLM can provide the significant improvement or to analyze its relevance judgment errors. This opacity also hinders the reuse of the LLM's rich intrinsic knowledge. Secondly, the massive parameters and computational demands make it challenging to be deployed online. To improve the interpretability of LLM and boost the performance of online relevance models, we propose an Explainable LLM-driven Multi-dimensional Distillation framework for e-commerce relevance learning, which comprises two core components: (1) An Explainable LLM for relevance modeling (ELLM-rele), which decomposes the relevance learning into intermediate steps and models relevance learning as a Chain-of-Thought (CoT) reasoning, thereby enhancing both interpretability and performance of LLM. (2) A Multi-dimensional Knowledge Distillation (MKD) architecture that transfers the knowledge of ELLM-rele to current interaction-based and representation-based student models from both the relevance score distribution and CoT reasoning aspects. Through distilling the probabilistic and CoT reasoning knowledge, MKD improves both the semantic interaction and long-tail generalization abilities of student models. Extensive offline evaluations and online experiments conducted on Taobao search ad scene demonstrate that our proposed ELLM-MD framework significantly enhances e-commerce relevance learning performance and consumer experience.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Zhao, Gang and Zhang, Ximing and Lu, Chenji and Zhao, Hui and Wu, Tianshu and Wang, Pengjie and Xu, Jian and Zheng, Bo},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {e-commerce, knowledge distillation, large language model, semantic matching},
	pages = {631--640},
}

@inproceedings{wilk_fact-based_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Fact-based {Counter} {Narrative} {Generation} to {Combat} {Hate} {Speech}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714718},
	doi = {10.1145/3696410.3714718},
	abstract = {Online hatred has become an increasingly pervasive issue, affecting individuals and communities across various digital platforms. To combat hate speech in such platforms, counter narratives (CNs) are regarded as an effective method. In recent years, there has been growing interest in using generative AI tools to construct CNs. However, most of the generative models produce generic responses to hate speech and can hallucinate, reducing their effectiveness. To address the above limitations, we propose a counter narrative generation method that enhances CNs by providing non-aggressive, fact-based narratives with relevant background knowledge from two distinct sources, including a web search module. Furthermore, we conduct a comprehensive evaluation using multiple metrics, including LLM-based measures for persuasion, factuality, and informativeness, along with human and traditional NLP evaluations. Our method significantly outperforms baselines, achieving an average factuality score of 0.915, compared to 0.741, 0.701, and 0.69 for competitive baselines, and performs well in human evaluations.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Wilk, Brian and Shomee, Homaira Huda and Maity, Suman Kalyan and Medya, Sourav},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {counter narrative, fact-based narrative, hate speech, large language model},
	pages = {3354--3365},
}

@inproceedings{he_ai_2024,
	address = {New York, NY, USA},
	series = {{CHIWORK} '24},
	title = {{AI} and the {Future} of {Collaborative} {Work}: {Group} {Ideation} with an {LLM} in a {Virtual} {Canvas}},
	isbn = {979-8-4007-1017-9},
	url = {https://doi.org/10.1145/3663384.3663398},
	doi = {10.1145/3663384.3663398},
	abstract = {The introduction of generative AI into multi-user applications raises novel considerations for the future of collaborative work. How might collaborative work practices change? How might we incorporate generative AI into shared tools with users’ needs at the forefront? We examine these questions in the context of a remote team conducting ideation tasks – an example of collaborative work enabled by a shared digital workspace. We conducted a user study with 17 professionals experienced with virtual group ideation workshops. Our study examined their use of the Collaborative Canvas, a virtual canvas tool with integrated generative AI capabilities that we created as a probe. Participants saw value in using generative AI to assist with group facilitation and to augment perspectives and ideas. However, they worried about losing human perspectives and critical thinking, as well as reputational harms resulting from harmful AI outputs. Participants shared suggestions for appropriate ways to incorporate generative AI capabilities within multi-user applications and identified needs for transparency of content ownership, private digital spaces, and specialized AI capabilities. Based on participants’ insights, we share implications and opportunities for the incorporation of generative AI into collaborative work in ways that place user needs at the forefront.},
	booktitle = {Proceedings of the 3rd {Annual} {Meeting} of the {Symposium} on {Human}-{Computer} {Interaction} for {Work}},
	publisher = {Association for Computing Machinery},
	author = {He, Jessica and Houde, Stephanie and Gonzalez, Gabriel E. and Silva Moran, Darío Andrés and Ross, Steven I. and Muller, Michael and Weisz, Justin D.},
	year = {2024},
	note = {event-place: Newcastle upon Tyne, United Kingdom},
	keywords = {Brainstorming, Future of work, Generative AI, Group ideation, Mixed initiative, Shared virtual canvas},
}

@inproceedings{zhou_intermind_2025,
	address = {New York, NY, USA},
	series = {{MM} '25},
	title = {{InterMind}: {Doctor}-{Patient}-{Family} {Interactive} {Depression} {Assessment} {Empowered} by {Large} {Language} {Models}},
	isbn = {979-8-4007-2035-2},
	url = {https://doi.org/10.1145/3746027.3754755},
	doi = {10.1145/3746027.3754755},
	abstract = {Depression poses significant challenges to patients and healthcare organizations, necessitating efficient assessment methods. Existing paradigms typically focus on a patient-doctor way that overlooks multi-role interactions, such as family involvement in the evaluation and caregiving process. Moreover, current automatic depression detection (ADD) methods usually model depression detection as a classification or regression task, lacking interpretability for the decision-making process. To address these issues, we developed InterMind, a doctor-patient-family interactive depression assessment system empowered by large language models (LLMs). Our system enables patients and families to contribute descriptions, generates assistive diagnostic reports for doctors, and provides actionable insights, improving diagnostic precision and efficiency. To enhance LLMs' performance in psychological counseling and diagnostic interpretability, we integrate retrieval-augmented generation (RAG) and chain-of-thoughts (CoT) techniques for data augmentation, which mitigates the hallucination issue of LLMs in specific scenarios after instruction fine-tuning. Quantitative experiments and professional assessments by clinicians validate the effectiveness of our system.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Zhou, Zhiyuan and Liu, Jilong and Wang, Sanwang and Hao, Shijie and Guo, Yanrong and Hong, Richang},
	year = {2025},
	note = {event-place: Dublin, Ireland},
	keywords = {depression detection, large language model},
	pages = {5480--5489},
}

@inproceedings{zhang_characterizing_2025,
	address = {New York, NY, USA},
	series = {{MICRO} '25},
	title = {Characterizing and {Optimizing} {Realistic} {Workloads} on a {Commercial} {Compute}-in-{SRAM} {Device}},
	isbn = {979-8-4007-1573-0},
	url = {https://doi.org/10.1145/3725843.3756132},
	doi = {10.1145/3725843.3756132},
	abstract = {Compute-in-SRAM architectures offer a promising approach to achieving higher performance and energy efficiency across a range of data-intensive applications. However, prior evaluations have largely relied on simulators or small prototypes, limiting the understanding of their real-world potential. In this work, we present a comprehensive performance and energy characterization of a commercial compute-in-SRAM device, the GSI APU, under realistic workloads. We compare the GSI APU against established architectures, including CPUs and GPUs, to quantify its energy efficiency and performance potential. We introduce an analytical framework for general-purpose compute-in-SRAM devices that reveals fundamental optimization principles by modeling performance trade-offs, thereby guiding program optimizations. Exploiting the fine-grained parallelism of tightly integrated memory-compute architectures requires careful data management. We address this by proposing three optimizations: communication-aware reduction mapping, coalesced DMA, and broadcast-friendly data layouts. When applied to retrieval-augmented generation (RAG) over large corpora (10GB–200GB), these optimizations enable our compute-in-SRAM system to accelerate retrieval by 4.8 × –6.6 × over an optimized CPU baseline, improving end-to-end RAG latency by 1.1 × –1.8 ×. The shared off-chip memory bandwidth is modeled using a simulated HBM, while all other components are measured on the real compute-in-SRAM device. Critically, this system matches the performance of an NVIDIA A6000 GPU for RAG while being significantly more energy-efficient (54.4 × -117.9 × reduction). These findings validate the viability of compute-in-SRAM for complex, real-world applications and provide guidance for advancing the technology.},
	booktitle = {Proceedings of the 58th {IEEE}/{ACM} {International} {Symposium} on {Microarchitecture}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Niansong and Zhu, Wenbo and Golden, Courtney and Ilan, Dan and Chen, Hongzheng and Batten, Christopher and Zhang, Zhiru},
	year = {2025},
	keywords = {analytical modeling, Compute-in-SRAM, energy efficiency, retrieval-augmented generation (RAG)},
	pages = {1011--1025},
}

@inproceedings{sun_application_2024,
	address = {New York, NY, USA},
	series = {{ICISDM} '24},
	title = {The {Application} of {Constructing} {Knowledge} {Graph} of {Oral} {Historical} {Archives} {Resources} {Based} on {LLM}-{RAG}},
	isbn = {979-8-4007-1734-5},
	url = {https://doi.org/10.1145/3686397.3686420},
	doi = {10.1145/3686397.3686420},
	abstract = {Oral historical archive resources are an emerging archive resource with the rapid development of modern technology. Its "bottom-up" approach to historical research has received widespread attention in the fields of history, archives, and libraries. Under the common knowledge discovery mode, oral historical archives resources are showing a dispersed state. Information technology represented by knowledge graphs can break through the data solidification of oral historical archives, reshape the information stack of oral historical archives, and achieve knowledge association and aggregation of oral historical archive resources. The article attempts to construct a knowledge graph of the oral historical archives resources on the theme of "science and art" in the collection of T.D. Lee Library of Shanghai Jiao Tong University. It uses Large Language Model - Retrieval Augmented Generation (LLM-RAG) for knowledge extraction, and then uses a semantic model for knowledge organization and management. The article attempts to empower humanities with technology, exploring the possibility of combining "digital technology" and "humanities research", extending traditional humanities research methods, breaking down barriers between technology and humanities resources, and providing a new path reference for revealing resource content characteristics, semantic deep correlation, and multi-dimensional knowledge discovery.},
	booktitle = {Proceedings of the 2024 8th {International} {Conference} on {Information} {System} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Sun, Yi and Yang, Wanru and Liu, Yin},
	year = {2024},
	keywords = {Knowledge Graph, LLM-RAG, Oral History Archives},
	pages = {142--149},
}

@inproceedings{chen_react_2025,
	address = {New York, NY, USA},
	series = {{ISAIMS} '24},
	title = {React {Agent}-{Based} {Question} {Answering} {Method} for {Biology} in {National} {College} {Entrance} {Examination}},
	isbn = {979-8-4007-1782-6},
	url = {https://doi.org/10.1145/3706890.3707043},
	doi = {10.1145/3706890.3707043},
	abstract = {Recent advancements in large language models have led to significant improvements in various natural language processing tasks, including automated question answering. However, these models still struggle with providing accurate responses to complex biology questions, such as those found in the National College Entrance Examination. To address this issue, researchers have explored retrieval-augmented generation techniques, which incorporate external knowledge sources to enhance answer accuracy. While these methods have shown promise in improving efficiency, they often lack the ability to perform in-depth analysis of complex questions. In response to these limitations, the paper proposes a novel ReAct agent-based question answering method. This method combines biology textbook document libraries with Google search engine capabilities, leveraging the strengths of large language models. By integrating these components, this method can engage in autonomous decision-making and multi-step reasoning, allowing for a more thorough analysis of complex biology questions. Experimental results demonstrate the effectiveness of this new approach. When compared to responses generated directly by ChatGPT and GPT-4o models, the method showed significant improvements in accuracy for biology questions from the National College Entrance Examination. Specifically, the new method achieved accuracy increases of 11.1\% and 4.64\% over ChatGPT and GPT-4o, respectively.},
	booktitle = {Proceedings of the 2024 5th {International} {Symposium} on {Artificial} {Intelligence} for {Medicine} {Science}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Yulin and Luo, Jing and Tu, Xinhui},
	year = {2025},
	keywords = {Agent, Automated question answering, Large language models, Retrieval-augmented generation},
	pages = {892--897},
}

@inproceedings{datta_raging_2025,
	address = {New York, NY, USA},
	series = {{JCDL} '24},
	title = {{RAGing} {Against} the {Literature}: {LLM}-{Powered} {Dataset} {Mention} {Extraction}},
	isbn = {979-8-4007-1093-3},
	url = {https://doi.org/10.1145/3677389.3702523},
	doi = {10.1145/3677389.3702523},
	abstract = {Dataset Mention Extraction (DME) is a critical task in the field of scientific information extraction, aiming to identify references to datasets within research papers. In this paper, we explore two advanced methods for DME from research papers, utilizing the capabilities of Large Language Models (LLMs). The first method employs a language model with a prompt-based framework to extract dataset names from text chunks, utilizing patterns of dataset mentions as guidance. The second method integrates the Retrieval-Augmented Generation (RAG) framework, which enhances dataset extraction through a combination of keyword-based filtering, semantic retrieval, and iterative refinement. We observe that both of the proposed methods achieve more than a 25\% improvement in recall compared to the baselines. Further, the RAG-based model achieves an extensive 26\% improvement over the baselines. We also propose exData, a web-based tool for extracting dataset name mentions from a given article.},
	booktitle = {Proceedings of the 24th {ACM}/{IEEE} {Joint} {Conference} on {Digital} {Libraries}},
	publisher = {Association for Computing Machinery},
	author = {Datta, Priyangshu and Datta, Suchana and Roy, Dwaipayan},
	year = {2025},
	note = {event-place: Hong Kong, China},
	keywords = {bibliometrics, dataset mention extraction, LLM, RAG},
}

@inproceedings{li_repomincoder_2024,
	address = {New York, NY, USA},
	series = {Internetware '24},
	title = {{RepoMinCoder}: {Improving} {Repository}-{Level} {Code} {Generation} {Based} on {Information} {Loss} {Screening}},
	isbn = {979-8-4007-0705-6},
	url = {https://doi.org/10.1145/3671016.3674819},
	doi = {10.1145/3671016.3674819},
	abstract = {Repository-level code generation task involves generating code at a specified location based on unfinished code with repository context. Existing research mainly rely on retrieval-augmented generation methods to complete code. Existing work mainly investigates on improving retrieval results based on the unfinished code, but rarely pays attention to the information loss in the prompt encoding process. In this paper, we propose RepoMinCoder, a novel repository-level code generation framework that adds another round of screening and ranking based on information loss, building upon the canonical retrieval-augmented generation method. Extensive experimental results demonstrate that RepoMinCoder consistently outperforms state-of-the-art methods on public benchmark RepoEval, achieving 3.3\% EM and 2.1\% ES improvement over previous methods. Moreover, we conduct additional experiments to study the effect of various factors in the existing code generation pipeline, including the number of retrieval candidates, the slicing strategy of the retrieval database, and different prompting strategies.},
	booktitle = {Proceedings of the 15th {Asia}-{Pacific} {Symposium} on {Internetware}},
	publisher = {Association for Computing Machinery},
	author = {Li, Yifan and Shi, Ensheng and Zheng, Dewu and Duan, Kefeng and Chen, Jiachi and Wang, Yanlin},
	year = {2024},
	note = {event-place: Macau, China},
	keywords = {Code Generation, Large Language Model, Screening and Ranking},
	pages = {229--238},
}

@inproceedings{yan_understanding_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Understanding and {Detecting} {File} {Knowledge} {Leakage} in {GPT} {App} {Ecosystem}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714755},
	doi = {10.1145/3696410.3714755},
	abstract = {OpenAI has enabled third-party developers to build applications around ChatGPT, known as GPTs, to expand its capability to handle complex and specialized tasks. A key feature of GPTs is Retrieval-Augmented Generation (RAG), which allows developers to upload documents containing domain knowledge or application context, referred to as file knowledge. However, these documents often contain sensitive information, and the security mechanisms governing access control in GPTs remains an underexplored area.In this work, we present the first comprehensive study on file knowledge leakage within GPTs. We develop GPTs-Filtor, leveraging the unique characteristics of GPTs deployment, to perform an in-depth analysis and detection of file knowledge leakage at both user interaction (i.e., prompt) and network transmission levels. Applying GPTs-Filtor to 8,000 popular GPTs across eight different categories, we reveal widespread vulnerabilities in the current GPTs development and deployment model. We detect 618 cases of leakage among 1,331 GPTs that involve uploaded file knowledge, leading to the exfiltration of 3,645 file contents that contain highly-sensitive data such as internal bank audit transaction records. Our work underscores the pressing need for improved security practices in GPTs development and deployment, providing crucial insights for the secure development of this young but rapidly evolving ecosystem.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Yan, Chuan and Guan, Bowei and Li, Yazhi and Meng, Mark Huasong and Wan, Liuhuo and Bai, Guangdong},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {deployment, large language model, security, testing},
	pages = {3831--3839},
}

@inproceedings{bhowmick_raguru_2025,
	address = {New York, NY, USA},
	series = {{ICPE} '25},
	title = {{RAGuru}: {A} {Tool} to {Create} and {Automatically} {Deploy} {Workload} {Optimized} {RAG}},
	isbn = {979-8-4007-1130-5},
	url = {https://doi.org/10.1145/3680256.3721326},
	doi = {10.1145/3680256.3721326},
	abstract = {Retrieval Augmented Generation (RAG) architectures have emerged as a powerful solution to enhance the accuracy and relevance of large language models (LLMs) by integrating retrieval mechanisms with generative capabilities. However, the design of an effective RAG pipeline is inherently complex, involving multiple components such as chunking strategies, embedding models, retrieval systems, and choice of LLMs. Each of these components offers numerous configuration options and the selection of the optimal combination is often a daunting task. The challenge is compounded by the need to consider trade-offs between performance, accuracy, and cost, which are not always straightforward and can vary significantly depending on the workload. In this context, we present RAGuru, an innovative tool designed to automate the design and creation of cost and latency-optimized RAG architectures. RAGuru addresses the complexities of RAG design by intelligently selecting and configuring the optimal components based on the user's specific workload requirements and also ensuring higher quality responses from RAG. By using an inhouse dataset of cost and performance metrics, RAGuru ensures that the resulting architecture is cost and latency wise optimal for an use-case, while achieving high accuracy. The architecture design space choices can be fed to terraform[2] as a configuration file for automatic deployment of the cost-performance optimal RAG. We have tested RAGuru in real-world scenarios. In a particular case, the RAG generated by RAGuru, demonstrated comparable performance at approximately half the cost of a conventional RAG system, with only minimal accuracy1 loss.},
	booktitle = {Companion of the 16th {ACM}/{SPEC} {International} {Conference} on {Performance} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Bhowmick, Archisman and S, Rishikesh and Taksande, Ashay and Singh, Kuldeep and Mishra, Mayank and Singhal, Rekha},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {deployment, optimization, rag, terraform},
	pages = {109--113},
}

@inproceedings{zhang_lsrp_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{LSRP}: {A} {Leader}-{Subordinate} {Retrieval} {Framework} for {Privacy}-{Preserving} {Cloud}-{Device} {Collaboration}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737036},
	doi = {10.1145/3711896.3737036},
	abstract = {Cloud-device collaboration leverages on-cloud Large Language Models (LLMs) for handling public user queries and on-device Small Language Models (SLMs) for processing private user data, collectively forming a powerful and privacy-preserving solution. However, existing approaches often fail to fully leverage the scalable problem-solving capabilities of on-cloud LLMs while underutilizing the advantage of on-device SLMs in accessing and processing personalized data. This leads to two interconnected issues: 1) Limited utilization of the problem-solving capabilities of on-cloud LLMs, which fail to align with personalized user-task needs, and 2) Inadequate integration of user data into on-device SLM responses, resulting in mismatches in contextual user information. In this paper, we propose a Leader-Subordinate Retrieval framework for Privacy-preserving cloud-device collaboration (LSRP), a novel solution that bridges these gaps by: 1) enhancing on-cloud LLM guidance to on-device SLM through a dynamic selection of task-specific leader strategies named as user-to-user retrieval-augmented generation (U-U-RAG), and 2) integrating the data advantages of on-device SLMs through small model feedback Direct Preference Optimization (SMFB-DPO) for aligning the on-cloud LLM with the on-device SLM. Experiments on two datasets demonstrate that LSRP consistently outperforms state-of-the-art baselines, significantly improving question-answer relevance and personalization, while preserving user privacy through efficient on-device retrieval. Our code is available at: https://github.com/Applied-Machine-Learning-Lab/LSRP.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Yingyi and Jia, Pengyue and Li, Xianneng and Xu, Derong and Wang, Maolin and Wang, Yichao and Du, Zhaocheng and Guo, Huifeng and Liu, Yong and Tang, Ruiming and Zhao, Xiangyu},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {cloud-device framework, large language model, privacy-preserving},
	pages = {3889--3900},
}

@inproceedings{wang_intent-driven_2025,
	address = {New York, NY, USA},
	series = {{SIGCOMM} '25},
	title = {Intent-{Driven} {Network} {Management} with {Multi}-{Agent} {LLMs}: {The} {Confucius} {Framework}},
	isbn = {979-8-4007-1524-2},
	url = {https://doi.org/10.1145/3718958.3750537},
	doi = {10.1145/3718958.3750537},
	abstract = {Advancements in Large Language Models (LLMs) are significantly transforming network management practices. In this paper, we present our experience developing Confucius, a multi-agent framework for network management at Meta. We model network management workflows as directed acyclic graphs (DAGs) to aid planning. Our framework integrates LLMs with existing management tools to achieve seamless operational integration, employs retrieval-augmented generation (RAG) to improve long-term memory, and establishes a set of primitives to systematically support human/model interaction. To ensure the accuracy of critical network operations, Confucius closely integrates with existing network validation methods and incorporates its own validation framework to prevent regressions. Remarkably, Confucius is a production-ready LLM development framework that has been operational for two years, with over 60 applications onboarded. To our knowledge, this is the first report on employing multi-agent LLMs for hyper-scale networks.},
	booktitle = {Proceedings of the {ACM} {SIGCOMM} 2025 {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Zhaodong and Lin, Samuel and Yan, Guanqing and Ghorbani, Soudeh and Yu, Minlan and Zhou, Jiawei and Hu, Nathan and Baruah, Lopa and Peters, Sam and Kamath, Srikanth and Yang, Jerry and Zhang, Ying},
	year = {2025},
	note = {event-place: São Francisco Convent, Coimbra, Portugal},
	keywords = {large language models (LLMs), network planning, RAG},
	pages = {347--362},
}

@inproceedings{rejithkumar_probing_2024,
	address = {New York, NY, USA},
	series = {{MO2RE} 2024},
	title = {Probing with {Precision}: {Probing} {Question} {Generation} for {Architectural} {Information} {Elicitation}},
	isbn = {979-8-4007-0569-4},
	url = {https://doi.org/10.1145/3643666.3648577},
	doi = {10.1145/3643666.3648577},
	abstract = {Software Requirements Specifications (SRS) often lack the necessary level of specificity required by software architects to make well-informed architectural decisions. This deficiency compels software architects to probe business analysts to collect more details pertinent to architectural requirements from the clients. In our previous work, we introduced Probing Question-flows (PQ-flows) that can assist business analysts to probe stakeholders and gather architecturally significant information for the creation of a more comprehensive SRS. Key limitations of our previous work were the manually created templatized PQ-flows and the mapping of PQ-flows to the software requirements based on standard Vector Space Model. In this study, we propose a Retrieval Augmented Generation (RAG) prompting framework to address these limitations. We conducted experiments using ChatGPT and Mistral-7B models. We present our findings utilizing human and automated evaluation metrics on a subset of the publicly available PUblic REquirements (PURE) dataset.},
	booktitle = {Proceedings of the 1st {IEEE}/{ACM} {Workshop} on {Multi}-{Disciplinary}, {Open}, and {RElevant} {Requirements} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Rejithkumar, Gokul and Anish, Preethu Rose and Shukla, Jyoti and Ghaisas, Smita},
	year = {2024},
	note = {event-place: Lisbon, Portugal},
	keywords = {ChatGPT, large language models, mistral, probing questions, prompting, requirements engineering, retrieval augmented generation},
	pages = {8--14},
}

@inproceedings{li_leveraging_2024,
	address = {New York, NY, USA},
	series = {{RMEL} '24},
	title = {Leveraging {Prompt} {Tuning}-{Based} {Cognitive} {Attention} to {Enhance} {Logical} {Inference} in {Large} {Language} {Models}},
	isbn = {979-8-4007-1295-1},
	url = {https://doi.org/10.1145/3698383.3699622},
	doi = {10.1145/3698383.3699622},
	abstract = {Large language models (LLMs) have demonstrated remarkable problem-solving abilities, but the impact of attention on their logical reasoning capabilities remains underexplored. This study investigates the intersection of cognitive neuroscience and LLMs, focusing on prompt fine-tuning techniques to analyze how humanlike cognitive abilities and disabilities affect the problem-solving performance of these models. Two GPT-4 based models were developed using prompt fine-tuning and retrieval-augmented generation (RAG). The models were evaluated using the Criteria Cognitive Aptitude Test (CCAT) dataset, which assesses cognitive abilities such as problem-solving, critical thinking, and information processing. Results showed that the prompt-tuned GPT-4 model achieved the highest accuracy (81.2\%), while the model lacking attention performed poorly on questions requiring long-term inference. GPT-4's analysis highlighted the importance of attention in solving problems that demand long-term reference and identified the deficiencies in the attention-deficient model. This study sheds light on the mechanisms of problem-solving in the brain and the potential of AI to approximate human-like cognition, paving the way for future research at the intersection of cognitive neuroscience and artificial intelligence.},
	booktitle = {Proceedings of the {First} {ACM} {International} {Workshop} on {Resource}-{Efficient} {Mobile} and {Embedded} {LLM} {System} in {AIoT}},
	publisher = {Association for Computing Machinery},
	author = {Li, Xiaoyan and Jiang, Cuicui},
	year = {2024},
	note = {event-place: Hangzhou, China},
	keywords = {Attention ability, Cognitive function, Large language model, Logic Reasoning},
	pages = {6--12},
}

@inproceedings{kang_retrieval-augmented_2024,
	address = {New York, NY, USA},
	series = {{ICMR} '24},
	title = {Retrieval-{Augmented} {Audio} {Deepfake} {Detection}},
	isbn = {979-8-4007-0619-6},
	url = {https://doi.org/10.1145/3652583.3658086},
	doi = {10.1145/3652583.3658086},
	abstract = {With recent advances in speech synthesis including text-to-speech (TTS) and voice conversion (VC) systems enabling the generation of ultra-realistic audio deepfakes, there is growing concern about their potential misuse. However, most deepfake (DF) detection methods rely solely on the fuzzy knowledge learned by a single model, resulting in performance bottlenecks and transparency issues. Inspired by retrieval-augmented generation (RAG), we propose a retrieval-augmented detection (RAD) framework that augments test samples with similar retrieved samples for enhanced detection. We also extend the multi-fusion attentive classifier to integrate it with our proposed RAD framework. Extensive experiments show the superior performance of the proposed RAD framework over baseline methods, achieving state-of-the-art results on the ASVspoof 2021 DF set and competitive results on the 2019 and 2021 LA sets. Further sample analysis indicates that the retriever consistently retrieves samples mostly from the same speaker with acoustic characteristics highly consistent with the query audio, thereby improving detection performance.},
	booktitle = {Proceedings of the 2024 {International} {Conference} on {Multimedia} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Kang, Zuheng and He, Yayun and Zhao, Botao and Qu, Xiaoyang and Peng, Junqing and Xiao, Jing and Wang, Jianzong},
	year = {2024},
	note = {event-place: Phuket, Thailand},
	keywords = {audio deepfake, deepfake detection, llm, retrieval-augmented detection, retrieval-augmented generation, text-to-speech, voice conversion},
	pages = {376--384},
}

@inproceedings{hedi_personalized_2025,
	address = {Richland, SC},
	series = {{AAMAS} '25},
	title = {Personalized {Language} {Learning}: {A} {Multi}-{Agent} {System} {Leveraging} {LLMs} for {Teaching} {Luxembourgish}.},
	isbn = {979-8-4007-1426-9},
	abstract = {The integration of Artificial Intelligence (AI) into education is transforming language learning. Current chatbot-based tools primarily focus on vocabulary acquisition and conversation, overlooking the holistic needs of effective language learning, such as grammar, reading, and listening skills. These limitations are further compounded by the challenges of low-resource languages like Luxembourgish. This demonstration https://www.youtube.com/watch?v=5bxVHsuK-Hs presents a Multi-Agent System (MAS) powered by Large Language Models (LLMs), integrated with Retrieval-Augmented Generation (RAG) to address these challenges. Our system personalizes learning by employing specialized agents for specialized tasks, ensuring a comprehensive and adaptive experience. To mitigate inaccuracies, human-on-the-loop (here teacher) validation enhances content quality and aligns with pedagogical standards inspired by the National Institute of Languages of Luxembourg (INL). Attendees will experience interactive demonstrations showcasing how the system delivers tailored educational experiences through innovative agent workflows and user-centric design.},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Autonomous} {Agents} and {Multiagent} {Systems}},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Hedi, Tebourbi and Nouzri, Sana and Mualla, Yazan and Najjar, Amro},
	year = {2025},
	note = {event-place: Detroit, MI, USA},
	keywords = {language learning, llms, mas, personalized learning, rag},
	pages = {3032--3034},
}

@inproceedings{kasundra_adapting_2024,
	address = {New York, NY, USA},
	series = {{AIMLSystems} '23},
	title = {Adapting {Open}-{Source} {LLMs} for {Contract} {Drafting} and {Analyzing} {Multi}-{Role} vs. {Single}-{Role} {Behavior} of {ChatGPT} for {Synthetic} {Data} {Generation}},
	isbn = {979-8-4007-1649-2},
	url = {https://doi.org/10.1145/3639856.3639888},
	doi = {10.1145/3639856.3639888},
	abstract = {Large-scale language models, such as ChatGPT[3] and GPT-4[32], have demonstrated remarkable capabilities in generating human-like text for various applications. In this paper, we focus on two key aspects: (1) adapting open-source large language models (LLMs) for specific use cases like contract drafting using instruction tuning and parameter-efficient fine-tuning, and (2) analyzing the difference in ChatGPT’s behavior in single-role prompts compared to multi-role prompts for synthetic data generation tasks. We present a method for aligning open-source LLMs to follow instructions for customized contract drafting scenarios using parameter-efficient fine-tuning on synthetic data. Furthermore, we investigate the data quality of the synthetically generated instructions data by ChatGPT with single-role vs. multi-role prompts. Our findings reveal that the model performs better when given single-role prompts, highlighting the importance of strategically designing prompting strategy to generate better quality data using LLMs. By combining the insights from these two aspects, we explore potential implications and opportunities for enhancing generative AI solutions for practical implementations. The Contract Drafting model 1 and data 2 are released.},
	booktitle = {Proceedings of the {Third} {International} {Conference} on {AI}-{ML} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kasundra, Jaykumar and Dhankhar, Shreyans},
	year = {2024},
	note = {event-place: Bangalore, India},
	keywords = {Automated Evaluation, Generative AI, Large Language Models, Natural Language Generation},
}

@inproceedings{chen_qilin_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Qilin: {A} {Multimodal} {Information} {Retrieval} {Dataset} with {APP}-level {User} {Sessions}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730279},
	doi = {10.1145/3726302.3730279},
	abstract = {User-generated content (UGC) communities, especially those featuring multimodal content, improve user experiences by integrating visual and textual information into results (or items). The challenge of improving user experiences in complex systems with search and recommendation (S\&amp;R) services has drawn significant attention from both academia and industry these years. However, the lack of high-quality datasets has limited the research progress on multimodal S\&amp;R. To address the growing need for developing better S\&amp;R services, we present a novel multimodal information retrieval dataset in this paper, namely Qilin. The dataset is collected from Xiaohongshu, a popular social platform with over 300 million monthly active users and an average search penetration rate of over 70\%. In contrast to existing datasets, Qilin offers a comprehensive collection of user sessions with heterogeneous results like image-text notes, video notes, commercial notes, and direct answers, facilitating the development of advanced multimodal neural retrieval models across diverse task settings. To better model user satisfaction and support the analysis of heterogeneous user behaviors, we also collect extensive APP-level contextual signals and genuine user feedback. Notably, Qilin contains user-favored answers and their referred results for search requests triggering the Deep Query Answering (DQA) module. This allows not only the training \&amp; evaluation of a Retrieval-augmented Generation (RAG) pipeline, but also the exploration of how such a module would affect users' search behavior. Through comprehensive analysis and experiments, we provide interesting findings and insights for further improving S\&amp;R systems. We hope that Qilin will significantly contribute to the advancement of multimodal content platforms with S\&amp;R services in the future.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Jia and Dong, Qian and Li, Haitao and He, Xiaohui and Gao, Yan and Cao, Shaosheng and Wu, Yi and Yang, Ping and Xu, Chen and Hu, Yao and Ai, Qingyao and Liu, Yiqun},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {context-aware ranking, multimodal information retrieval, recommendation, retrieval-augmented generation, search, user behavior analysis},
	pages = {3670--3680},
}

@inproceedings{mamalis_can_2024,
	address = {New York, NY, USA},
	series = {{PCI} '23},
	title = {Can {Large} {Language} {Models} {Revolutionalize} {Open} {Government} {Data} {Portals}? {A} {Case} of {Using} {ChatGPT} in statistics.gov.scot},
	isbn = {979-8-4007-1626-3},
	url = {https://doi.org/10.1145/3635059.3635068},
	doi = {10.1145/3635059.3635068},
	abstract = {Large language models possess tremendous natural language understanding and generation abilities. However, they often lack the ability to discern between fact and fiction, leading to factually incorrect responses. Open Government Data are repositories of, often times linked, information that is freely available to everyone. By combining these two technologies in a proof of concept designed application utilizing the GPT3.5 OpenAI model and the Scottish open statistics portal, we show that not only is it possible to augment the large language model’s factuality of responses, but also propose a novel way to effectively access and retrieve statistical information from the data portal just through natural language querying. We anticipate that this paper will trigger a discussion regarding the transformation of Open Government Portals through large language models.},
	booktitle = {Proceedings of the 27th {Pan}-{Hellenic} {Conference} on {Progress} in {Computing} and {Informatics}},
	publisher = {Association for Computing Machinery},
	author = {Mamalis, Marios Evangelos and Kalampokis, Evangelos and Karamanou, Areti and Brimos, Petros and Tarabanis, Konstantinos},
	year = {2024},
	note = {event-place: Lamia, Greece},
	keywords = {chatgpt, large language model, linked data, natural language processing, open government data},
	pages = {53--59},
}

@inproceedings{joshi_reaper_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {{REAPER}: {Reasoning} based {Retrieval} {Planning} for {Complex} {RAG} {Systems}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3680087},
	doi = {10.1145/3627673.3680087},
	abstract = {Complex dialog systems often use retrieved evidence to facilitate factual responses. Such RAG (Retrieval Augmented Generation) systems retrieve from heterogeneous data stores that are architected as multiple indexes or APIs instead of a single monolithic source. For a given query, relevant evidence needs to be retrieved from one (or few) retrieval source. Complex queries can even require multi-step retrieval. For example, a conversational agent on a retail site answering customer questions about past orders need to retrieve the appropriate customer order first and then the evidence relevant to the customer's question in the context of the ordered product. Most RAG Agents handle such Chain-of-Thought (CoT) tasks by interleaving reasoning and retrieval steps. However, each reasoning step directly adds to the latency of the system. For large models this latency cost is significant – in the order of multiple seconds. Multi-agent systems may classify the query to a single Agent associated with a retrieval source, which means that a (small) classification model dictates the performance of a large language model. To address this problem, we present REAPER (REAsoning-based PlannER), an LLM-based retrieval planner that we evaluate on a conversational shopping assistant, which shows significant gains in latency over Agent-based systems and scalability to new and unseen use cases when compared to classification-based planning.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Joshi, Ashutosh and Sarwar, Sheikh Muhammad and Varshney, Samarth and Nag, Sreyashi and Agrawal, Shrivats and Naik, Juhi},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {chain-of-thought, multi-hop reasoning, rag},
	pages = {4621--4628},
}

@inproceedings{liu_optimizing_2025,
	address = {New York, NY, USA},
	series = {{AIIIP} '24},
	title = {Optimizing {RAG} {Techniques} for {Automotive} {Industry} {PDF} {Chatbots}: {A} {Case} {Study} with {Locally} {Deployed} {Ollama} {ModelsOptimizing} {RAG} {Techniques} {Based} on {Locally} {Deployed} {Ollama} {ModelsA} {Case} {Study} with {Locally} {Deployed} {Ollama} {Models}},
	isbn = {979-8-4007-0730-8},
	url = {https://doi.org/10.1145/3707292.3707358},
	doi = {10.1145/3707292.3707358},
	abstract = {With the growing demand for offline PDF chatbots in automotive industrial production environments, optimizing the deployment of large language models (LLMs) in local, low-performance settings has become increasingly important. This study focuses on enhancing Retrieval-Augmented Generation (RAG) techniques for processing complex automotive industry documents using locally deployed Ollama models.Based on the Langchain framework, we propose a multi-dimensional optimization approach for Ollama's local RAG implementation. Our method addresses key challenges in automotive document processing, including multi-column layouts and technical specifications. We introduce improvements in PDF processing, retrieval mechanisms, and context compression, tailored to the unique characteristics of automotive industry documents. Additionally, we design custom classes supporting embedding pipelines and an agent supporting self-RAG based on LangGraph best practices.To evaluate our approach, we constructed a proprietary dataset comprising typical automotive industry documents, including technical reports and corporate regulations. We compared our optimized RAG model and self-RAG agent against a naive RAG baseline across three datasets: our automotive industry dataset, QReCC, and CoQA. Results demonstrate significant improvements in context precision, context recall, answer relevancy, and faithfulness, with particularly notable performance on the automotive industry dataset.Our optimization scheme provides an effective solution for deploying local RAG systems in the automotive sector, addressing the specific needs of PDF chatbots in industrial production environments. This research has important implications for advancing information processing and intelligent production in the automotive industry.},
	booktitle = {Proceedings of the 2024 3rd {International} {Conference} on {Artificial} {Intelligence} and {Intelligent} {Information} {Processing}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Fei and Kang, Zejun and Han, Xing},
	year = {2025},
	keywords = {Automotive Industry, Langchain, Ollama, PDF Processing, RAG, self-rag},
	pages = {152--159},
}

@inproceedings{ranade_fabula_2024,
	address = {New York, NY, USA},
	series = {{ASONAM} '23},
	title = {{FABULA}: {Intelligence} {Report} {Generation} {Using} {Retrieval}-{Augmented} {Narrative} {Construction}},
	isbn = {979-8-4007-0409-3},
	url = {https://doi.org/10.1145/3625007.3627505},
	doi = {10.1145/3625007.3627505},
	abstract = {Narrative construction is the process of representing disparate event information into a logical plot structure that models an end to end story. Intelligence analysis is an example of a domain that can benefit tremendously from narrative construction techniques, particularly in aiding analysts during the largely manual and costly process of synthesizing event information into comprehensive intelligence reports. Manual intelligence report generation is often prone to challenges such as integrating dynamic event information, writing fine-grained queries, and closing information gaps. This motivates the development of a system that retrieves and represents critical aspects of events in a form that aids in automatic generation of intelligence reports.We introduce a Retrieval Augmented Generation (RAG) approach to augment prompting of an autoregressive decoder by retrieving structured information asserted in a knowledge graph to generate targeted information based on a narrative plot model. We apply our approach to the problem of neural intelligence report generation and introduce FABULA, framework to augment intelligence analysis workflows using RAG. An analyst can use FABULA to query an Event Plot Graph (EPG) to retrieve relevant event plot points, which can be used to augment prompting of a Large Language Model (LLM) during intelligence report generation. Our evaluation studies show that the plot points included in the generated intelligence reports have high semantic relevance, high coherency, and low data redundancy.},
	booktitle = {Proceedings of the 2023 {IEEE}/{ACM} {International} {Conference} on {Advances} in {Social} {Networks} {Analysis} and {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Ranade, Priyanka and Joshi, Anupam},
	year = {2024},
	note = {event-place: Kusadasi, Turkiye},
	keywords = {knowledge graphs, large language models, narratives, retrieval augmented generation},
	pages = {603--610},
}

@inproceedings{bhattacharya_show_2025,
	address = {New York, NY, USA},
	series = {{UMAP} '25},
	title = {"{Show} {Me} {How}": {Benefits} and {Challenges} of {Agent}-{Augmented} {Counterfactual} {Explanations} for {Non}-{Expert} {Users}},
	isbn = {979-8-4007-1313-2},
	url = {https://doi.org/10.1145/3699682.3728321},
	doi = {10.1145/3699682.3728321},
	abstract = {Counterfactual explanations offer actionable insights by illustrating how changes to inputs can lead to different outcomes. However, these explanations often suffer from ambiguity and impracticality, limiting their utility for non-expert users with limited AI knowledge. Augmenting counterfactual explanations with Large Language Models (LLMs) has been proposed as a solution, but little research has examined their benefits and challenges for non-experts. To address this gap, we developed a healthcare-focused system that leverages conversational AI agents to enhance counterfactual explanations, offering clear, actionable recommendations to help patients at high risk of cardiovascular disease (CVD) reduce their risk. Evaluated through a mixed-methods study with 34 participants, our findings highlight the effectiveness of agent-augmented counterfactuals in improving actionable recommendations. Results further indicate that users with prior experience using conversational AI demonstrated greater effectiveness in utilising these explanations compared to novices. Furthermore, this paper introduces a set of generic guidelines for creating augmented counterfactual explanations, incorporating safeguards to mitigate common LLM pitfalls, such as hallucinations, and ensuring the explanations are both actionable and contextually relevant for non-expert users.},
	booktitle = {Proceedings of the 33rd {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {Association for Computing Machinery},
	author = {Bhattacharya, Aditya and Vanherwegen, Tim and Verbert, Katrien},
	year = {2025},
	keywords = {AI Agents, Conversational XAI, Counterfactual Explanation, Explainable AI},
	pages = {174--184},
}

@inproceedings{wang_social-rag_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Social-{RAG}: {Retrieving} from {Group} {Interactions} to {Socially} {Ground} {AI} {Generation}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713749},
	doi = {10.1145/3706598.3713749},
	abstract = {AI agents are increasingly tasked with making proactive suggestions in online spaces where groups collaborate, yet risk being unhelpful or even annoying if they fail to match group preferences or behave in socially inappropriate ways. Fortunately, group spaces have a rich history of prior interactions and affordances for social feedback that can support grounding an agent’s generations to a group’s interests and norms. We present Social-RAG, a workflow for socially grounding agents that retrieves context from prior group interactions, selects relevant social signals, and feeds them into a language model to generate messages in a socially aligned manner. We implement this in PaperPing, a system for posting paper recommendations in group chat, leveraging social signals determined from formative studies with 39 researchers. From a three-month deployment in 18 channels reaching 500+ researchers, we observed PaperPing posted relevant messages in groups without disrupting their existing social practices, fostering group common ground.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Ruotong and Zhou, Xinyi and Qiu, Lin and Chang, Joseph Chee and Bragg, Jonathan and Zhang, Amy X.},
	year = {2025},
	keywords = {AI agent, group communication, large language models, recommender systems, retrieval augmented generation},
}

@inproceedings{ray_metis_2025,
	address = {New York, NY, USA},
	series = {{SOSP} '25},
	title = {{METIS}: {Fast} {Quality}-{Aware} {RAG} {Systems} with {Configuration} {Adaptation}},
	isbn = {979-8-4007-1870-0},
	url = {https://doi.org/10.1145/3731569.3764855},
	doi = {10.1145/3731569.3764855},
	abstract = {RAG (Retrieval Augmented Generation) allows LLMs (large language models) to generate better responses with external knowledge, but using more external knowledge causes higher response delay. Prior work focuses either on reducing the response delay (e.g., better scheduling of RAG queries) or on maximizing quality (e.g., tuning the RAG workflow), but they fall short in systematically balancing the tradeoff between the delay and quality of RAG responses. To balance both quality and response delay, this paper presents METIS, the first RAG system that jointly schedules queries and adapts the key RAG configurations of each query, such as the number of retrieved text chunks and synthesis methods. Using four popular RAG-QA datasets, we show that compared to the state-of-the-art RAG optimization schemes, METIS reduces the generation latency by 1.64 – 2.54× without sacrificing generation quality.},
	booktitle = {Proceedings of the {ACM} {SIGOPS} 31st {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {Association for Computing Machinery},
	author = {Ray, Siddhant and Pan, Rui and Gu, Zhuohan and Du, Kuntai and Feng, Shaoting and Ananthanarayanan, Ganesh and Netravali, Ravi and Jiang, Junchen},
	year = {2025},
	note = {event-place: Lotte Hotel World, Seoul, Republic of Korea},
	keywords = {LLM inference, RAG systems, scheduling},
	pages = {606--622},
}

@inproceedings{thiede_talking_2024,
	address = {New York, NY, USA},
	series = {Onward! '24},
	title = {Talking to {Objects} in {Natural} {Language}: {Toward} {Semantic} {Tools} for {Exploratory} {Programming}},
	isbn = {979-8-4007-1215-9},
	url = {https://doi.org/10.1145/3689492.3690049},
	doi = {10.1145/3689492.3690049},
	abstract = {In exploratory programming, programmers often face a semantic gap between their high-level understanding and the low-level interfaces available for interacting with objects in a system. That is, technical object structure and behavior need to be interpreted as abstract domain concepts, which then increases cognitive load and thus impedes exploration progress. We propose semantic object interfaces that bridge this gap by enabling contextual, natural-language conversations with objects. Our approach leverages an exploratory programming agent powered by a large language model (LLM) to translate natural-language questions into low-level experiments and provide high-level answers. We describe a framework for integrating semantic object interfaces into existing exploratory programming systems, including a prototype implementation in Squeak/Smalltalk using GPT-4o. We showcase the potential of semantic object interfaces through case studies and discuss their feasibility, limitations, and impact on the programming experience. While challenges remain, our approach promises to reduce mental effort and empower programmers to explore and understand systems at a higher level of abstraction for a better programming experience.},
	booktitle = {Proceedings of the 2024 {ACM} {SIGPLAN} {International} {Symposium} on {New} {Ideas}, {New} {Paradigms}, and {Reflections} on {Programming} and {Software}},
	publisher = {Association for Computing Machinery},
	author = {Thiede, Christoph and Taeumel, Marcel and Böhme, Lukas and Hirschfeld, Robert},
	year = {2024},
	note = {event-place: Pasadena, CA, USA},
	keywords = {ChatGPT, conversational agents, exploratory programming, generative AI, LLMs, natural-language programming, object-oriented programming, semantic tools, Smalltalk},
	pages = {68--84},
}

@inproceedings{chatterjee_towards_2025,
	address = {New York, NY, USA},
	series = {{DEEM} '25},
	title = {Towards {An} {Improved} {Video} {RAG} {Workflow} {With} {Orchestration} {Support} in {A} {Visual} {Data} {Management} {System}},
	isbn = {979-8-4007-1924-0},
	url = {https://doi.org/10.1145/3735654.3735945},
	doi = {10.1145/3735654.3735945},
	abstract = {Video Retrieval-Augmented Generation (RAG) Workflows augment user query contexts with stored video contexts to guide a Large Language Model (LLM) in providing more context-relevant answers. The challenge is to design a workflow where the video contexts can be generated with practical latency values. It is also important to ensure that the resources available to run the workflows are not under-utilized whenever possible. In this paper, we propose a video RAG workflow that utilizes the Visual Data Management System (VDMS) interfaced with the Kubernetes (K8s) orchestration framework to design an enhanced video RAG workflow (VRAG) for faster video context generation in the pre-processing phase and a faster response generation with no impact on response accuracy. Our experiments showcase that compared to Conventional RAG(CRAG) workflows, VRAG reduces the pre-processing latency by a minimum of 10\%, which decreases manifold with parallelization and the response latency by a minimum of 70\% to as high as 97\% with further parallelization.},
	booktitle = {Proceedings of the {Workshop} on {Data} {Management} for {End}-to-{End} {Machine} {Learning}},
	publisher = {Association for Computing Machinery},
	author = {Chatterjee, Sourish and Verma, Rohit and Kumar, Abhinav and Raghunath, Arun},
	year = {2025},
	note = {event-place: Berlin, Germany},
}

@inproceedings{shao_are_2025,
	address = {Ottawa, Ontario, Canada},
	series = {{ICSE} '25},
	title = {Are {LLMs} {Correctly} {Integrated} into {Software} {Systems}?},
	isbn = {979-8-3315-0569-1},
	url = {https://doi.org/10.1109/ICSE55347.2025.00204},
	doi = {10.1109/ICSE55347.2025.00204},
	abstract = {Large language models (LLMs) provide effective solutions in various application scenarios, with the support of retrieval-augmented generation (RAG). However, developers face challenges in integrating LLM and RAG into software systems, due to lacking interface specifications, various requirements from software context, and complicated system management. In this paper, we have conducted a comprehensive study of 100 open-source applications that incorporate LLMs with RAG support, and identified 18 defect patterns. Our study reveals that 77\% of these applications contain more than three types of integration defects that degrade software functionality, efficiency, and security. Guided by our study, we propose systematic guidelines for resolving these defects in software life cycle. We also construct an open-source defect library Hydrangea [1].},
	booktitle = {Proceedings of the {IEEE}/{ACM} 47th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Shao, Yuchen and Huang, Yuheng and Shen, Jiawei and Ma, Lei and Su, Ting and Wan, Chengcheng},
	year = {2025},
	keywords = {defects, empirical software engineering, LLM},
	pages = {1178--1190},
}

@inproceedings{hu_llm-generated_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{LLM}-{Generated} {Fake} {News} {Induces} {Truth} {Decay} in {News} {Ecosystem}: {A} {Case} {Study} on {Neural} {News} {Recommendation}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730027},
	doi = {10.1145/3726302.3730027},
	abstract = {Online fake news moderation now faces a new challenge brought by the malicious use of large language models (LLMs) in fake news production. Though existing works have shown LLM-generated fake news is hard to detect from an individual aspect, it remains underexplored how its large-scale release will impact the news ecosystem. In this study, we develop a simulation pipeline and a dataset with 56k generated news of diverse types to investigate the effects of LLM-generated fake news within neural news recommendation systems. Our findings expose a truth decay phenomenon, where real news is gradually losing its advantageous position in news ranking against fake news as LLM-generated news is involved in news recommendation. We further provide an explanation about why truth decay occurs from a familiarity perspective and show the positive correlation between perplexity and news ranking. Finally, we discuss the threats of LLM-generated fake news and provide possible countermeasures. We urge stakeholders to address this emerging challenge to preserve the integrity of news ecosystems.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Hu, Beizhe and Sheng, Qiang and Cao, Juan and Li, Yang and Wang, Danding},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {fake news, large language model, recommender system},
	pages = {435--445},
}

@inproceedings{mattis_examples_2024,
	address = {New York, NY, USA},
	series = {Programming '24},
	title = {Examples out of {Thin} {Air}: {AI}-{Generated} {Dynamic} {Context} to {Assist} {Program} {Comprehension} by {Example}},
	isbn = {979-8-4007-0634-9},
	url = {https://doi.org/10.1145/3660829.3660845},
	doi = {10.1145/3660829.3660845},
	abstract = {Programmers often benefit from the availability of concrete run-time data alongside abstract source code. However, programmers need to manually exercise the program to reach an interesting state or write code that reproducibly executes a functionality with concrete inputs to be able to observe concrete data. This work aims to automate this process by leveraging generative AI. We present a framework and a preliminary Smalltalk-based prototype allowing programmers to obtain and run examples for the currently viewed source code section from a large language model. Our approach demonstrates how locally hosted LLMs can be fine-tuned and used for such a task with reasonable computational effort while minimizing common problems like hallucinations and out-of-date knowledge. The framework has direct applications in example-based live programming, where it can suggest new examples, and in learning settings where novices need to know how to use certain functionality.},
	booktitle = {Companion {Proceedings} of the 8th {International} {Conference} on the {Art}, {Science}, and {Engineering} of {Programming}},
	publisher = {Association for Computing Machinery},
	author = {Mattis, Toni and Krebs, Eva and Rinard, Martin C. and Hirschfeld, Robert},
	year = {2024},
	note = {event-place: Lund, Sweden},
	keywords = {example-based programming, generative ai, large language models, live programming, smalltalk},
	pages = {99--107},
}

@inproceedings{srivastava_lending_2024,
	address = {New York, NY, USA},
	series = {{ICAIF} '24},
	title = {Lending an {Ear}: {How} {LLMs} {Hear} {Your} {Banking} {Intentions}},
	isbn = {979-8-4007-1081-0},
	url = {https://doi.org/10.1145/3677052.3698608},
	doi = {10.1145/3677052.3698608},
	abstract = {Traditional language models in NLP require a considerable amount of labeled examples, which is not always available in data-limited domains like banking. Large Language Models (LLMs) are known to perform effectively with few-shot learning in various domains with just 1-5 examples per class. However, the use of open-source instruction-tuned LLMs, and how they compare to closed-source LLMs and modern few-shot learning approaches like contrastive learning in data-constrained use-cases has been under-explored. Additionally, the understanding of performance-cost trade-offs of these methods, as well as the consideration of infrastructure resource-limited settings through optimal usage of smaller versions of LLMs (7B-9B parameters), a critical concern for budget-limited organizations, has not been studied comprehensively. Our work addresses these gaps by studying the aforementioned approaches over the Banking77 financial intent detection dataset, including the evaluation and comparison of cutting-edge LLMs by Meta, Google, Mistral-AI, OpenAI, and Anthropic in a comprehensive set of few-shot scenarios which include examples selected by a human-expert, as well as with a cost-effective querying method based on retrieval-augmented generation (RAG). We observed that smaller open-source LLMs are able to out-perform larger closed-source ones with effective prompts and RAG. Moreover, they offer a significantly better performance-cost ratio than their larger closed-source counterparts. We also experiment with data-augmentation by using LLMs to generate artificial labeled examples, which is able to improve performance slightly in a data-scarce scenario. Finally, we explored benefits of fine-tuning using three parameter efficient methods and propose BAI-Fintent, an LLM based on fine-tuned Mistral-7B, that out-performs all other approaches at customer banking intent identification.},
	booktitle = {Proceedings of the 5th {ACM} {International} {Conference} on {AI} in {Finance}},
	publisher = {Association for Computing Machinery},
	author = {Srivastava, Varad},
	year = {2024},
	note = {event-place: Brooklyn, NY, USA},
	keywords = {Claude, Few-Shot, Gemma, GPT, Llama, LLMs, Mistral, NLP, RAG},
	pages = {301--309},
}

@inproceedings{huang_penheal_2024,
	address = {New York, NY, USA},
	series = {{AutonomousCyber} '24},
	title = {{PenHeal}: {A} {Two}-{Stage} {LLM} {Framework} for {Automated} {Pentesting} and {Optimal} {Remediation}},
	isbn = {979-8-4007-1229-6},
	url = {https://doi.org/10.1145/3689933.3690831},
	doi = {10.1145/3689933.3690831},
	abstract = {Recent advances in Large Language Models (LLMs) have shown significant potential in enhancing cybersecurity defenses against sophisticated threats. LLM-based penetration testing is an essential step in automating system security evaluations by identifying vulnerabilities. Remediation, the subsequent crucial step, addresses these discovered vulnerabilities. Since details about vulnerabilities, exploitation methods, and software versions offer crucial insights into system weaknesses, integrating penetration testing with vulnerability remediation into a cohesive system has become both intuitive and necessary. This paper introduces PenHeal, a two-stage LLM-based framework designed to autonomously identify and mitigate security vulnerabilities. The framework integrates two LLM-enabled components: the Pentest Module, which detects multiple vulnerabilities within a system, and the Remediation Module, which recommends optimal remediation strategies. The integration is facilitated through Counterfactual Prompting and an Instructor module that guides the LLMs using external knowledge to explore multiple potential attack paths effectively. Our experimental results demonstrate that PenHeal not only automates the identification and remediation of vulnerabilities but also significantly improves vulnerability coverage by 31\%, increases the effectiveness of remediation strategies by 32\%, and reduces the associated costs by 46\% compared to baseline models. These outcomes highlight the transformative potential of LLMs in reshaping cybersecurity practices, offering an innovative solution to defend against cyber threats.},
	booktitle = {Proceedings of the {Workshop} on {Autonomous} {Cybersecurity}},
	publisher = {Association for Computing Machinery},
	author = {Huang, Junjie and Zhu, Quanyan},
	year = {2024},
	note = {event-place: Salt Lake City, UT, USA},
	keywords = {cybersecurity automation, llms, penetration testing, retrieval-augmented generation, vulnerability remediation},
	pages = {11--22},
}

@inproceedings{bhuvaji_retrieval-augmented_2025,
	address = {New York, NY, USA},
	series = {{SAC} '25},
	title = {A {Retrieval}-{Augmented} {Framework} {For} {Meeting} {Insight} {Extraction}},
	isbn = {979-8-4007-0629-5},
	url = {https://doi.org/10.1145/3672608.3707915},
	doi = {10.1145/3672608.3707915},
	abstract = {Meetings are vital for collaboration and decision-making in professional environments, yet recalling key details from past discussions can be challenging and this impacts productivity. In this paper, we address this issue by developing a solution that extracts crucial insights from historical meeting records using Retrieval Augmented Generation (RAG) techniques. Users can easily upload meeting records and query for relevant information. A core feature of our proposed system is grouping meetings based on abstractive summaries, using state-of-the-art clustering algorithms extensively trained for accuracy. Upon user inquiry, the system identifies the most relevant cluster and retrieves related conversations from the Pinecone vector store database. These conversations, paired with custom prompts, are processed through a Large Language Model (LLM) to generate precise responses. Our optimization efforts focus on exploring various encoders and LLMs, with fine-tuning to ensure seamless integration and high performance. This approach tackles challenges in meeting summarization, content discovery, and user-friendly information retrieval.},
	booktitle = {Proceedings of the 40th {ACM}/{SIGAPP} {Symposium} on {Applied} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Bhuvaji, Sartaj and Chouhan, Prachitee and Irukulla, Madhuroopa and Singhvi, Jay and Bae, Wan D. and Alkobaisi, Shayma},
	year = {2025},
	note = {event-place: Catania International Airport, Catania, Italy},
	keywords = {abstractive summarization, BART, LLM, meeting data retrieval, pinecone, speech to text conversion, text summarization},
	pages = {899--906},
}

@inproceedings{luo_integration_2024,
	address = {New York, NY, USA},
	series = {{ACM}-{TURC} '24},
	title = {Integration of {LLMs} and the {Physical} {World}: {Research} and {Application}},
	isbn = {979-8-4007-1011-7},
	url = {https://doi.org/10.1145/3674399.3674402},
	doi = {10.1145/3674399.3674402},
	abstract = {The emergence of large language models (LLMs) offers a new opportunity to build LLMs-based applications, such as smart home, as these models have demonstrated general-purpose language understanding by generating coherent and contextually relevant text. However, LLMs are trained on massive amounts of text data to predict tokens, so these models have limitations and it is difficult for them performing physical world tasks directly. To further exploit the potential of LLMs to solve the challenge of integrating them with the physical world, LLMs enhanced and augmented techniques should be addressed, especially reinforcement learning based techniques. In this paper, we study the issue of integrating LLMs with physical world. We first describe the large language models and limitations. Then, we revisit LLMs enhanced and augmented techniques. After that, we present methods of interaction LLMs with physical world, such as integration IoT sensing with LLMs, embodied agent post-training with LLMs, and robot task planning with LLMs. Finally, we provide a case study of smart home powered by LLMs to discuss future research directions of next-generation intelligent smart home, personal health assistant, and LLM-based household robot.},
	booktitle = {Proceedings of the {ACM} {Turing} {Award} {Celebration} {Conference} - {China} 2024},
	publisher = {Association for Computing Machinery},
	author = {Luo, Xiaoyu and Liu, Daping and Dang, Fan and Luo, Hanjiang},
	year = {2024},
	note = {event-place: Changsha, China},
	keywords = {Internet of Things, Large Language Model, LLM-based Agent, Smart Home},
	pages = {1--5},
}

@inproceedings{kaate_you_2025,
	address = {New York, NY, USA},
	series = {{IUI} '25},
	title = {“{You} {Always} {Get} an {Answer}”: {Analyzing} {Users}’ {Interaction} with {AI}-{Generated} {Personas} {Given} {Unanswerable} {Questions} and {Risk} of {Hallucination}},
	isbn = {979-8-4007-1306-4},
	url = {https://doi.org/10.1145/3708359.3712160},
	doi = {10.1145/3708359.3712160},
	abstract = {We investigated the presence and acceptance of hallucinations (i.e., accidental misinformation) of an AI-generated persona system that leverages large language models for persona creation from survey data in a 54-user within-subjects experiment. After interacting with the personas, users were given a task to ask the personas a series of questions, including an unanswerable question, meaning the personas lacked the data to answer the question. The AI-generated persona system provided a plausible but incorrect answer half (52\%) of the time, and more than half of the time (57\%), the users accepted the incorrect answer, and the rest of the time, users answered the unanswerable question correctly (no answer). We found that when the AI-generated persona hallucinated, the user was significantly more likely to answer the unanswerable question incorrectly. Also, for genders separately, when the AI-generated persona hallucinated, it was significantly more likely for the female user and the male users to answer the unanswerable question incorrectly. We identified four themes in the AI-generated persona's answers and found that users perceive AI-generated persona's answers as long and unclear for the unanswerable question. Findings imply that personas leveraging LLMs require guardrails to ensure that personas clearly state the possibility of data restrictions and hallucinations when asked unanswerable questions.},
	booktitle = {Proceedings of the 30th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Kaate, Ilkka and Salminen, Joni and Jung, Soon-Gyo and Xuan, Trang Thi Thu and Häyhänen, Essi and Azem, Jinan Y. and Jansen, Bernard J.},
	year = {2025},
	keywords = {AI-generated personas, generative AI, human-computer interaction, misinformation, user experience},
	pages = {1624--1638},
}

@inproceedings{zhu_autopbl_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{AutoPBL}: {An} {LLM}-powered {Platform} to {Guide} and {Support} {Individual} {Learners} {Through} {Self} {Project}-based {Learning}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3714261},
	doi = {10.1145/3706598.3714261},
	abstract = {Self project-based learning (SPBL) is a popular learning style where learners follow tutorials and build projects by themselves. SPBL combines project-based learning’s benefit of being engaging and effective with the flexibility of self-learning. However, insufficient guidance and support during SPBL may lead to unsatisfactory learning experiences and outcomes. While LLM chatbots (e.g., ChatGPT) could potentially serve as SPBL tutors, we have yet to see an SPBL platform with responsible and systematic LLM integration. To address this gap, we present AutoPBL, an interactive learning platform for SPBL learners. We examined human PBL tutors’ roles through formative interviews to inform our design. AutoPBL features an LLM-guided learning process with checkpoint questions and in-context Q\&amp;A. In a user study where 29 beginners learned machine learning through entry-level projects, we found that AutoPBL effectively improves learning outcomes and elicits better learning behavior and metacognition by clarifying current priorities and providing timely assistance.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhu, Yihao and Ye, Zhoutong and Yuan, Yichen and Tang, Wenxuan and Yu, Chun and Shi, Yuanchun},
	year = {2025},
	keywords = {AI for education, Large Language Model, Project-based Learning},
}

@inproceedings{pei_flow--action_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Flow-of-{Action}: {SOP} {Enhanced} {LLM}-{Based} {Multi}-{Agent} {System} for {Root} {Cause} {Analysis}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715225},
	doi = {10.1145/3701716.3715225},
	abstract = {In the realm of microservices architecture, the occurrence of frequent incidents necessitates the employment of Root Cause Analysis (RCA) for swift issue resolution. It is common that a serious incident can take several domain experts hours to identify the root cause. Consequently, a contemporary trend involves harnessing Large Language Models (LLMs) as automated agents for RCA. Though the recent ReAct framework aligns well with the Site Reliability Engineers (SREs) for its thought-action-observation paradigm, its hallucinations often lead to irrelevant actions and directly affect subsequent results. Additionally, the complex and variable clues of the incident can overwhelm the model one step further. To confront these challenges, we propose Flow-of-Action, a pioneering Standard Operation Procedure (SOP) enhanced LLM-based multi-agent system. By explicitly summarizing the diagnosis steps of SREs, SOP imposes constraints on LLMs at crucial junctures, guiding the RCA process towards the correct trajectory. To facilitate the rational and effective utilization of SOPs, we design an SOP-centric framework called SOP flow. SOP flow contains a series of tools, including one for finding relevant SOPs for incidents, another for automatically generating SOPs for incidents without relevant ones, and a tool for converting SOPs into code. This significantly alleviates the hallucination issues of ReAct in RCA tasks. We also design multiple auxiliary agents to assist the main agent by removing useless noise, narrowing the search space, and informing the main agent whether the RCA procedure can stop. Compared to the ReAct method's 35.50\% accuracy, our Flow-of-Action method achieves 64.01\%, meeting the accuracy requirements for RCA in real-world systems.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Pei, Changhua and Wang, Zexin and Liu, Fengrui and Li, Zeyan and Liu, Yang and He, Xiao and Kang, Rong and Zhang, Tieying and Chen, Jianjun and Li, Jianhui and Xie, Gaogang and Pei, Dan},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {large language model, multi-agent system, root cause analysis},
	pages = {422--431},
}

@inproceedings{xu_generative_2025,
	address = {New York, NY, USA},
	series = {{ICAIE} '24},
	title = {Generative {Artificial} {Intelligence} {Empowers} the {Research} of {Digital} {Textbooks} in {Vocational} {Education}},
	isbn = {979-8-4007-1269-2},
	url = {https://doi.org/10.1145/3722237.3722377},
	doi = {10.1145/3722237.3722377},
	abstract = {This research focuses on the application of AIGC in vocational education digital textbooks and how RAG technology can be used to further improve the interactivity and educational effectiveness of digital textbooks. The paper first analyzes the development of AIGC technology and its great potential in the field of education, especially the role of LLM in content generation. It then discusses the concept, risks, and construction strategies of vocational education digital textbooks, emphasizing the importance of digital textbooks in teaching and their differences compared with paper textbooks. The study also designs a knowledge retrieval question-answering system based on RAG, which combines school-based textbooks and cooperative enterprise manuals as a knowledge base to generate responses to student questions. While ensuring accuracy and completeness, the quality of the responses was improved by the merge of students' queries with relevant texts using RAG technology. Regarding implementation, RAG technology consists of knowledge base construction and knowledge retrieval. It includes segmenting the document, recognizing and vectorizing it in order to build a vector database. During user retrieval, queries are sorted through the vector database interface, and the matched knowledge fragments and query statements are merged to generate answers including specific domain knowledge. This framework of the RAG question-answering system can provide accurate answers to satisfy students of all levels in personalized teaching while maintaining explainability and timeliness of the content.},
	booktitle = {Proceedings of the 2024 3rd {International} {Conference} on {Artificial} {Intelligence} and {Education}},
	publisher = {Association for Computing Machinery},
	author = {Xu, Yao and Jian, Xiao},
	year = {2025},
	keywords = {Digital Textbooks, Retrieval-Augmented Generation, Vocational Education},
	pages = {802--806},
}

@inproceedings{pallucchini_self-explanatory_2025,
	address = {New York, NY, USA},
	series = {{SAC} '25},
	title = {Self-explanatory and {Retrieval}-augmented {LLMs} for {Financial} {Sentiment} {Analysis}},
	isbn = {979-8-4007-0629-5},
	url = {https://doi.org/10.1145/3672608.3707894},
	doi = {10.1145/3672608.3707894},
	abstract = {Enriching sentences with qualitative knowledge is crucial for enhancing sentiment prediction and making the most of the available labelled data for training models. This is particularly important in domains like the financial one, where texts are usually brief and contain much-implied information. In this article, we introduce FLEX (Financial Language Enhancement with Guided LLM Execution), an automated system capable of retrieving information from a Large Language Model (LLM) to enrich financial sentences, making them more knowledge-dense and explicit. FLEX generates multiple potentially enhanced sentences and uses a new logic to determine the most suitable one. To mitigate hallucinations in LLMs, we developed a new algorithm to select the most appropriate sentences. This approach ensures the original meaning is preserved, reduces excessive syntactic similarity between versions, and maintains the lowest possible perplexity. These enhanced sentences are more interpretable and directly useful for downstream tasks like financial sentiment analysis (FSA). Compared to state-of-the-art methods, FLEX shows improvements in the accuracy of processing FSA tasks.},
	booktitle = {Proceedings of the 40th {ACM}/{SIGAPP} {Symposium} on {Applied} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Pallucchini, Filippo and Zhang, Xulang and Mao, Rui and Cambria, Erik},
	year = {2025},
	note = {event-place: Catania International Airport, Catania, Italy},
	keywords = {financial sentiment analysis, interpretability, LLM, RAG, semantics},
	pages = {131--137},
}

@inproceedings{saha_ir_explain_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {ir\_explain: {A} {Python} {Library} of {Explainable} {IR} {Methods}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730343},
	doi = {10.1145/3726302.3730343},
	abstract = {While recent advancements in Neural Ranking Models have resulted in significant improvements over traditional statistical retrieval models, it is generally acknowledged that the use of large neural architectures and the application of complex language models in Information Retrieval (IR) have reduced the transparency of retrieval methods. Consequently, Explainability and Interpretability have emerged as important research topics in IR. Several axiomatic and post-hoc explanation methods, as well as approaches that attempt to be interpretable-by-design, have been proposed. We present ir\_explain, an open-source Python library that implements a variety of well-known techniques for Explainable IR (ExIR) within a common, extensible framework. It supports the three standard categories of post-hoc explanations, namely pointwise, pairwise, and listwise explanations. The library is designed to make it easy to reproduce state-of-the-art ExIR baselines on standard test collections, as well as to explore new approaches to explaining IR models and methods. To facilitate adoption, ir\_explain is well-integrated with widely-used toolkits such as Pyserini, PyTerrier (work in progress) and ir\_datasets. Downstream applications of ir\_explain include explaining the Retrieval-Augmented Generation (RAG) pipeline. The development version of the library is available on GitHub. We release the library as a pip package (https://pypi.org/project/ir-explain/); source code is available from https://github.com/souravsaha/ir\_explain.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Saha, Sourav and Agarwal, Harsh and V, Venktesh and Anand, Avishek and Mohanty, Swastik and Majumdar, Debapriyo and Mitra, Mandar},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {axiomatic ranking, explainable information retrieval, interpretable by design, post-hoc interpretability, probing},
	pages = {3563--3572},
}

@inproceedings{xiong_enhancing_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Enhancing the {Patent} {Matching} {Capability} of {Large} {Language} {Models} via the {Memory} {Graph}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3729970},
	doi = {10.1145/3726302.3729970},
	abstract = {Intellectual Property (IP) management involves strategically protecting and utilizing intellectual assets to enhance organizational innovation, competitiveness, and value creation. Patent matching is a crucial task in intellectual property management, which facilitates the organization and utilization of patents. Existing models often rely on the emergent capabilities of Large Language Models (LLMs) and leverage them to identify related patents directly. However, these methods usually depend on matching keywords and overlook the hierarchical classification and categorical relationships of patents. In this paper, we propose MemGraph, a method that augments the patent matching capabilities of LLMs by incorporating a memory graph derived from their parametric memory. Specifically, MemGraph prompts LLMs to traverse their memory to identify relevant entities within patents, followed by attributing these entities to corresponding ontologies. After traversing the memory graph, we utilize extracted entities and ontologies to improve the capability of LLM in comprehending the semantics of patents. Experimental results on the PatentMatch dataset demonstrate the effectiveness of MemGraph, achieving a 17.68\% performance improvement over baseline LLMs. The further analysis highlights the generalization ability of MemGraph across various LLMs, both in-domain and out-of-domain, and its capacity to enhance the internal reasoning processes of LLMs during patent matching. All data and codes are available at https://github.com/NEUIR/MemGraph.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Xiong, Qiushi and Xu, Zhipeng and Liu, Zhenghao and Wang, Mengjia and Chen, Zulong and Sun, Yue and Gu, Yu and Li, Xiaohua and Yu, Ge},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {large language models, memory graph, patent matching, retrieval-augmented generation},
	pages = {337--347},
}

@inproceedings{xu_aligning_2025,
	address = {Ottawa, Ontario, Canada},
	series = {{ICSE} '25},
	title = {Aligning the {Objective} of {LLM}-{Based} {Program} {Repair}},
	isbn = {979-8-3315-0569-1},
	url = {https://doi.org/10.1109/ICSE55347.2025.00169},
	doi = {10.1109/ICSE55347.2025.00169},
	abstract = {Large language models (LLMs) have achieved decent results on automated program repair (APR). However, the next token prediction training objective of decoder-only LLMs (e.g., GPT-4) is misaligned with the masked span prediction objective of current infilling-style methods, which impedes LLMs from fully leveraging pre-trained knowledge for program repair. In addition, while some LLMs can locate and repair bugs in certain functions using the related artifacts (e.g., test cases), existing methods still depend on statement-level fault localization methods to provide a list of buggy hunks for repair. This restriction hinders LLMs from exploring potential patches beyond the given locations.In this paper, we investigate a new approach to adapt LLMs to program repair. Our core insight is that LLM's APR capability can be greatly improved by simply aligning the output to their training objective and allowing them to refine the whole program without first identifying faulty statements. Based on this insight, we designed D4C, a straightforward prompting framework for APR. D4C can repair 180 bugs correctly in Defects4J, with each patch being sampled only 10 times. This surpasses the SOTA APR methods with perfect fault localization by 10\% and reduces the patch sampling number by 90\%. Our findings reveal that (1) objective alignment is crucial for fully exploiting LLM's pre-trained capability, and (2) replacing the traditional localize-buggy-hunks-then-repair workflow with direct debugging is more effective for LLM-based APR methods. Thus, we believe this paper introduces a new mindset for harnessing LLMs in APR.},
	booktitle = {Proceedings of the {IEEE}/{ACM} 47th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Xu, Junjielong and Fu, Ying and Tan, Shin Hwei and He, Pinjia},
	year = {2025},
	keywords = {automated program repair, large language model, objective alignment},
	pages = {2548--2560},
}

@inproceedings{salemi_towards_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Towards a {Search} {Engine} for {Machines}: {Unified} {Ranking} for {Multiple} {Retrieval}-{Augmented} {Large} {Language} {Models}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657733},
	doi = {10.1145/3626772.3657733},
	abstract = {This paper introduces uRAG-a framework with a unified retrieval engine that serves multiple downstream retrieval-augmented generation (RAG) systems. Each RAG system consumes the retrieval results for a unique purpose, such as open-domain question answering, fact verification, entity linking, and relation extraction. We introduce a generic training guideline that standardizes the communication between the search engine and the downstream RAG systems that engage in optimizing the retrieval model. This lays the groundwork for us to build a large-scale experimentation ecosystem consisting of 18 RAG systems that engage in training and 18 unknown RAG systems that use the uRAG as the new users of the search engine. Using this experimentation ecosystem, we answer a number of fundamental research questions that improve our understanding of promises and challenges in developing search engines for machines.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Salemi, Alireza and Zamani, Hamed},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {large language model, neural ranking model, retrieval augmentation, retrieval-enhanced machine learning, text generation},
	pages = {741--751},
}

@inproceedings{song_how_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {How {Much} {Do} {Prompting} {Methods} {Help} {LLMs} on {Quantitative} {Reasoning} with {Irrelevant} {Information}?},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3679840},
	doi = {10.1145/3627673.3679840},
	abstract = {Real-world quantitative reasoning problems are complex, often including extra information irrelevant to the question (or "IR noise" for short). State-of-the-art (SOTA) prompting methods have increased the Large Language Model's ability for quantitative reasoning on grade-school Math Word Problems (MWPs). To assess how well these SOTA methods handle IR noise, we constructed four new datasets with IR noise, each consisting of 300 problems from each of the four public datasets: MAWPS, ASDiv, SVAMP, and GSM8K, with added IR noise. We called the collection of these new datasets "MPN"–Math Word Problems with IR Noise. We evaluated SOTA prompting methods using MPN. We propose Noise Reduction Prompting (NRP) and its variant (NRP+) to reduce the impact of IR noise. Findings: Our IR noise significantly degrades the performance of Chain-of-Thought (CoT) Prompting on three different backend models: ChatGPT (gpt-3.5-turbo-0613), PaLM2, and Llama3-8B-instruct. Among them, ChatGPT offers the best accuracy on MPN with and without IR noise. With IR noise, performances of CoT, Least-To-Most Prompting, Progressive-Hint Prompting, and Program-aided Language Models with ChatGPT were significantly impacted, each with an average accuracy drop of above 12\%. NRP is least impacted by the noise, with a drop in average accuracy to only around 1.9\%. Our NRP+ and NRP perform comparably in the presence of IR noise.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Song, Seok Hwan and Tavanapong, Wallapak},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {large language model, math word problem, prompt engineering, quantitative reasoning, trustworthy information extraction},
	pages = {2128--2137},
}

@inproceedings{kanakaris_network-informed_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Network-informed {Prompt} {Engineering} against {Organized} {Astroturf} {Campaigns} under {Extreme} {Class} {Imbalance}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3717539},
	doi = {10.1145/3701716.3717539},
	abstract = {Detecting organized political campaigns, commonly known as astroturf campaigns, is of paramount importance in fighting against disinformation on social media. Existing approaches for the identification of such organized actions employ techniques mostly from network science, graph machine learning and natural language processing. Their ultimate goal is to analyze the relationships and interactions (e.g. re-posting) among users and the textual similarities of their posts. Despite their effectiveness in recognizing astroturf campaigns, these methods face significant challenges, notably the class imbalance in available training datasets. To mitigate this issue, recent methods usually resort to data augmentation or increasing the number of positive samples, which may not always be feasible or sufficient in real-world settings. Following a different path, in this paper, we propose a novel framework for identifying astroturf campaigns based solely on large language models (LLMs), introducing a Balanced Retrieval-Augmented Generation (Balanced RAG) component. Our approach first gives both textual information concerning the posts (in our case tweets) and the user interactions of the social network as input to a language model. Then, through prompt engineering and the proposed Balanced RAG method, it effectively detects coordinated disinformation campaigns on 𝕏 (Twitter). The proposed framework does not require any training or fine-tuning of the language model. Instead, by strategically harnessing the strengths of prompt engineering and Balanced RAG, it facilitates LLMs to overcome the effects of class imbalance and effectively identify coordinated political campaigns. The experimental results demonstrate that by incorporating the proposed prompt engineering and Balanced RAG methods, our framework outperforms the traditional graph-based baselines, achieving 2×-3× improvements in terms of precision, recall and F1 scores.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Kanakaris, Nikos and Ping, Heng and Xiao, Xiongye and Ahmed, Nesreen K. and Luceri, Luca and Ferrara, Emilio and Bogdan, Paul},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {class imbalance, disinformation spread, fake news detection, graph classification, graph-aware prompt engineering, large language models, organized disinformation campaign detection, prompt engineering, retrieval-augmented generation},
	pages = {2651--2660},
}

@inproceedings{zhu_study_2024,
	address = {New York, NY, USA},
	series = {{ISAIE} '24},
	title = {A {Study} of the {AIGC}-{Enabled} {BOPPPS} {Smart} {Teaching} {Model}},
	isbn = {979-8-4007-0710-0},
	url = {https://doi.org/10.1145/3700297.3700326},
	doi = {10.1145/3700297.3700326},
	abstract = {Smart teaching refers to the in-depth use of modern information technology to promote the process of education, which is characterized by using digital, network, intelligent and multimedia technologies. BOPPPS teaching model is a new type of student-centered teaching model. This teaching model is widely used around the world. The traditional BOPPPS teaching model makes it difficult to implement personalized teaching in the classroom. The new development of artificial intelligence technology provides new method for smart teaching, especially the AIGC Large Language Model represented by ChatGPT. This paper introduces AIGC technology into personalized teaching, and study the application of AIGC in various aspects of BOPPPS teaching model, by taking the design of smart teaching course of video surveillance as an example. In particular, AIGC is utilized for Pre-assessment. It is proposed to use an agent as a mediator between students and the AIGC large language model to test the students individually, and to design personalized test contents for personalized feedback. Comparatively better results were obtained in the actual teaching process, which can provide a reference for other smart teaching researchers.},
	booktitle = {Proceedings of the 2024 {International} {Symposium} on {Artificial} {Intelligence} for {Education}},
	publisher = {Association for Computing Machinery},
	author = {Zhu, Guibin and Zhao, Bo and Tang, Jianbo},
	year = {2024},
	keywords = {Artificial Intelligence, BOPPPS, Large Language Model, Personalized Teaching, Smart Teaching},
	pages = {166--170},
}

@inproceedings{jacobs_thats_2025,
	address = {New York, NY, USA},
	series = {{UKICER} '25},
	title = {That's {Not} the {Feedback} {I} {Need}! - {Student} {Engagement} with {GenAI} {Feedback} in the {Tutor} {Kai}},
	isbn = {979-8-4007-2078-9},
	url = {https://doi.org/10.1145/3754508.3754512},
	doi = {10.1145/3754508.3754512},
	abstract = {The potential of Generative AI (GenAI) for generating feedback in computing education has been the subject of numerous studies. However, there is still limited research on how computing students engage with this feedback and to what extent it supports their problem-solving. For this reason, we built a custom web application providing students with Python programming tasks, a code editor, GenAI feedback, and compiler feedback. Via a think-aloud protocol including eye-tracking and a post-interview with 11 undergraduate students, we investigate (1) how much attention the generated feedback received from learners and (2) to what extent the generated feedback is helpful (or not). In addition, students’ attention to GenAI feedback is compared with that towards the compiler feedback. We further investigate differences between students with and without prior programming experience. The findings indicate that GenAI feedback generally receives a lot of visual attention, with inexperienced students spending twice as much fixation time. More experienced students requested GenAI less frequently, and could utilize it better to solve the given problem. It was more challenging for inexperienced students to do so, as they could not always comprehend the GenAI feedback. They often relied solely on the GenAI feedback, while compiler feedback was not read. Understanding students’ attention and perception toward GenAI feedback is crucial for developing educational tools that support student learning.},
	booktitle = {Proceedings of the 2025 {Conference} on {UK} and {Ireland} {Computing} {Education} {Research}},
	publisher = {Association for Computing Machinery},
	author = {Jacobs, Sven and Kempf, Maurice and Kiesler, Natalie},
	year = {2025},
	keywords = {Feedback, GenAI, Generative AI, Large Language Models, Programming Education},
}

@inproceedings{wang_llm-powered_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{LLM}-powered {Multi}-agent {Framework} for {Goal}-oriented {Learning} in {Intelligent} {Tutoring} {System}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715244},
	doi = {10.1145/3701716.3715244},
	abstract = {Intelligent Tutoring Systems (ITSs) have revolutionized education by offering personalized learning experiences. However, as goal-oriented learning, which emphasizes efficiently achieving specific objectives, becomes increasingly important in professional contexts, existing ITSs often struggle to deliver this type of targeted learning experience. In this paper, we propose GenMentor, an LLM-powered multi-agent framework designed to deliver goal-oriented, personalized learning within ITS. GenMentor begins by accurately mapping learners' goals to required skills using a fine-tuned LLM trained on a custom goal-to-skill dataset. After identifying the skill gap, it schedules an efficient learning path using an evolving optimization approach, driven by a comprehensive and dynamic profile of learners' multifaceted status. Additionally, GenMentor tailors learning content with an exploration-drafting-integration mechanism to align with individual learner needs. Extensive automated and human evaluations demonstrate GenMentor's effectiveness in learning guidance and content quality. Furthermore, we have deployed it in practice and also implemented it as an application. Practical human study with professional learners further highlights its effectiveness in goal alignment and resource targeting, leading to enhanced personalization. Supplementary resources are available at ttps://github.com/GeminiLight/gen-mentor.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Wang, Tianfu and Zhan, Yi and Lian, Jianxun and Hu, Zhengyu and Yuan, Nicholas Jing and Zhang, Qi and Xie, Xing and Xiong, Hui},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {intelligent tutoring system, large language model, multi-agent},
	pages = {510--519},
}

@inproceedings{jin_i_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {"{I} {Don}'t {Know} {Why} {I} {Should} {Use} {This} {App}": {Holistic} {Analysis} on {User} {Engagement} {Challenges} in {Mobile} {Mental} {Health}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713732},
	doi = {10.1145/3706598.3713732},
	abstract = {Over the past decade, mobile apps have been widely adopted as a digital intervention method for mental health support, offering scalable and accessible solutions to address the growing global mental health challenges. However, sustaining user engagement in real-world settings remains a major challenge in the development of these applications. This study systematically examines factors that hinder user engagement in existing mobile mental health support systems through a scoping review of the literature. After an initial identification of 1,267 papers, we conducted a final analysis of 111 empirical studies using mobile app-based mental health support systems. The study investigates the main factors that negatively affect user engagement from user and system perspectives. Based on these findings, we propose guidelines for sustaining and enhancing user engagement and for structuring personalized emotional interaction design along three dimensions: adaptive, continuous, and multimodal interactions. Furthermore, we discuss the potential for integration with advanced AI methods (e.g., LLM-based generative AI agents) as a way to achieve these design implications and suggestions. Our results provide critical insights for enhancing long-term user engagement in the development of future mental health support systems.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Jin, Seungwan and Kim, Bogoan and Han, Kyungsik},
	year = {2025},
	keywords = {large language model, mental health apps, scoping review, user engagement},
}

@inproceedings{lubos_llm-generated_2024,
	address = {New York, NY, USA},
	series = {{UMAP} {Adjunct} '24},
	title = {{LLM}-generated {Explanations} for {Recommender} {Systems}},
	isbn = {979-8-4007-0466-6},
	url = {https://doi.org/10.1145/3631700.3665185},
	doi = {10.1145/3631700.3665185},
	abstract = {Users are often confronted with situations where they have to decide in favor or against an offered item, like a book, movie, or recipe. Those suggested items are commonly determined by a recommender system, which considers personal preferences to identify relevant items. However, those systems often lack transparency and comprehensibility in revealing why a specific item is recommended. For this purpose, explanations have been added as a powerful tool to help users with their final decisions. In this paper, we present and evaluate the capabilities of a Large Language Model (LLM) to come up with high-quality explanations to further improve the support of users for three different recommendation approaches, including feature-based recommendation, collaborative filtering, and knowledge-based recommendation. We explain how an LLM can be applied to generate personalized explanations and evaluate the explanation goals in an online user study. Our findings highlight that LLM-generated explanations are highly appreciated by users as they help in the evaluation of recommended items. Furthermore, we discuss which characteristics of the LLM-based explanations were perceived positively and how those findings can be used for future research.},
	booktitle = {Adjunct {Proceedings} of the 32nd {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {Association for Computing Machinery},
	author = {Lubos, Sebastian and Tran, Thi Ngoc Trang and Felfernig, Alexander and Polat Erdeniz, Seda and Le, Viet-Man},
	year = {2024},
	note = {event-place: Cagliari, Italy},
	keywords = {decision-making, explanation generation, explanations, feature-based explanations, item-based explanations, knowledge-based explanations, large language model, recommender systems},
	pages = {276--285},
}

@inproceedings{harvey_framework_2025,
	address = {New York, NY, USA},
	series = {{FAccT} '25},
	title = {A {Framework} for {Auditing} {Chatbots} for {Dialect}-{Based} {Quality}-of-{Service} {Harms}},
	isbn = {979-8-4007-1482-5},
	url = {https://doi.org/10.1145/3715275.3732137},
	doi = {10.1145/3715275.3732137},
	abstract = {Increasingly, individuals who engage in online activities are expected to interact with large language model (LLM)-based chatbots. Prior work has shown that LLMs can display dialect bias, which occurs when they produce harmful responses when prompted with text written in minoritized dialects. However, whether and how this bias propagates to systems built on top of LLMs, such as chatbots, is still unclear. We conduct a review of existing approaches for auditing LLMs for dialect bias and show that they cannot be straightforwardly adapted to audit LLM-based chatbots due to issues of substantive and ecological validity. To address this, we present a framework for auditing LLM-based chatbots for dialect bias by measuring the extent to which they produce quality-of-service harms, which occur when systems do not work equally well for different people. Our framework has three key characteristics that make it useful in practice. First, by leveraging dynamically generated instead of pre-existing text, our framework enables testing over any dialect, facilitates multi-turn conversations, and represents how users are likely to interact with chatbots in the real world. Second, by measuring quality-of-service harms, our framework aligns audit results with the real-world outcomes of chatbot use. Third, our framework requires only query access to an LLM-based chatbot, meaning that it can be leveraged equally effectively by internal auditors, external auditors, and even individual users in order to promote accountability. To demonstrate the efficacy of our framework, we conduct a case study audit of Amazon Rufus, a widely-used LLM-based chatbot in the customer service domain. Our results reveal that Rufus produces lower-quality responses to prompts written in minoritized English dialects, and that these quality-of-service harms are exacerbated by the presence of typos in prompts.},
	booktitle = {Proceedings of the 2025 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Harvey, Emma and Kizilcec, Rene F. and Koenecke, Allison},
	year = {2025},
	keywords = {audit, chatbot, dialect bias, large language model, quality-of-service harm},
	pages = {2025--2039},
}

@inproceedings{lee_mvprompt_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{MVPrompt}: {Building} {Music}-{Visual} {Prompts} for {AI} {Artists} to {Craft} {Music} {Video} {Mise}-en-scène},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713876},
	doi = {10.1145/3706598.3713876},
	abstract = {Music videos have traditionally been the domain of experts, but with text-to-video generative AI models, AI artists can now create them more easily. However, accurately reflecting the desired music-visual mise-en-scène remains challenging without specialized knowledge, highlighting the need for supportive tools. To address this, we conducted a design workshop with seven music video experts, identified design goals, and developed MVPrompt—a tool for generating music-visual mise-en-scène prompts. In a user study with 24 AI artists, MVPrompt outperformed the Baseline, effectively supporting the collaborative creative process. Specifically, the Visual Theme stage facilitated the exploration of tone and manner, while the Visual Scene \&amp; Grammar stage refined prompts with detailed mise-en-scène elements. By enabling AI artists to specify mise-en-scène creatively, MVPrompt enhances the experience of making music video scenes with text-to-video generative AI.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Lee, ChungHa and Lee, DaeHo and Hong, Jin-Hyuk},
	year = {2025},
	keywords = {AI Artists, Collaboration, Creativity Support Tools, Generative AI, Mise-en-scène, Music Video, Prompt Support, Text-to-Video},
}

@inproceedings{leitner_characterizing_2025,
	address = {New York, NY, USA},
	series = {Websci '25},
	title = {Characterizing {Network} {Structure} of {Anti}-{Trans} {Actors} on {TikTok}},
	isbn = {979-8-4007-1483-2},
	url = {https://doi.org/10.1145/3717867.3717926},
	doi = {10.1145/3717867.3717926},
	abstract = {Content Warning: Trans-antagonistic Rhetoric and Terminology The recent proliferation of short form video social media sites such as TikTok has been effectively utilized for increased visibility, communication, and community connection amongst trans/nonbinary creators online. However, these same platforms have also been exploited by right-wing actors targeting trans/nonbinary people, enabling such anti-trans actors to efficiently spread hate speech and propaganda. Given these divergent groups, what are the differences in network structure between anti-trans and pro-trans communities on TikTok, and to what extent do they amplify the effects of anti-trans content? In this paper, we collect a sample of TikTok videos containing pro and anti-trans content, and develop a taxonomy of trans related sentiment to enable the classification of content on TikTok, and ultimately analyze the reply network structures of pro-trans and anti-trans communities. In order to accomplish this, we worked with hired expert data annotators from the trans/nonbinary community in order to generate a sample of highly accurately labeled data. From this subset, we utilized a novel classification pipeline leveraging Retrieval-Augmented Generation (RAG) with annotated examples and taxonomy definitions to classify content into pro-trans, anti-trans, or neutral categories. We find that incorporating our taxonomy and its logics into our classification engine results in improved ability to differentiate trans related content, and that Results from network analysis indicate many interactions between posters of pro-trans and anti-trans content exist, further demonstrating targeting of trans individuals, and demonstrating the need for better content moderation tools.},
	booktitle = {Proceedings of the 17th {ACM} {Web} {Science} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Leitner, Maxyn Rose and Dorn, Rebecca and Morstatter, Fred and Lerman, Kristina},
	year = {2025},
	keywords = {Classification, Community Dynamics, Computational Social Science, Large language models (LLMs), Network analysis, Online Harassment, Retrieval-Augmented Generation (RAG)},
	pages = {472--483},
}

@inproceedings{fang_llm_2024,
	address = {New York, NY, USA},
	series = {{IVA} '24},
	title = {On {LLM} {Wizards}: {Identifying} {Large} {Language} {Models}' {Behaviors} for {Wizard} of {Oz} {Experiments}},
	isbn = {979-8-4007-0625-7},
	url = {https://doi.org/10.1145/3652988.3673967},
	doi = {10.1145/3652988.3673967},
	abstract = {The Wizard of Oz (WoZ) method is a widely adopted research approach where a human Wizard “role-plays” a not readily available technology and interacts with participants to elicit user behaviors and probe the design space. With the growing ability for modern large language models (LLMs) to role-play, one can apply LLMs as Wizards in WoZ experiments with better scalability and lower cost than the traditional approach. However, methodological guidance on responsibly applying LLMs in WoZ experiments and a systematic evaluation of LLMs’ role-playing ability are lacking. Through two LLM-powered WoZ studies, we take the first step towards identifying an experiment lifecycle for researchers to safely integrate LLMs into WoZ experiments and interpret data generated from settings that involve Wizards role-played by LLMs. We also contribute a heuristic-based evaluation framework that allows the estimation of LLMs’ role-playing ability in WoZ experiments and reveals LLMs’ behavior patterns at scale.},
	booktitle = {Proceedings of the 24th {ACM} {International} {Conference} on {Intelligent} {Virtual} {Agents}},
	publisher = {Association for Computing Machinery},
	author = {Fang, Jingchao and Arechiga, Nikos and Namikoshi, Keiichi and Bravo, Nayeli and Hogan, Candice and Shamma, David A.},
	year = {2024},
	note = {event-place: GLASGOW, United Kingdom},
	keywords = {large language model, LLM, methods, persuasive conversation, synthetic data, Wizard of Oz, WoZ},
}

@inproceedings{pradeep_great_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {The {Great} {Nugget} {Recall}: {Automating} {Fact} {Extraction} and {RAG} {Evaluation} with {Large} {Language} {Models}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730090},
	doi = {10.1145/3726302.3730090},
	abstract = {Large Language Models (LLMs) have significantly enhanced the capabilities of information access systems, especially with retrieval-augmented generation (RAG). Nevertheless, the evaluation of RAG systems remains a barrier to continued progress, a challenge we tackle in this work by proposing an automatic evaluation framework that is validated against human annotations. We believe that the nugget evaluation methodology provides a solid foundation for evaluating RAG systems. This approach, originally developed for the TREC Question Answering (QA) Track in 2003, evaluates systems based on atomic facts that should be present in good answers. Our efforts focus on ”refactoring” this methodology, where we describe the AutoNuggetizer framework that specifically applies LLMs to both automatically create nuggets and automatically assign nuggets to system answers. In the context of the TREC 2024 RAG Track, we calibrate a fully automatic approach against strategies where nuggets are created manually or semi-manually by human assessors and then assigned manually to system answers. Based on results from a community-wide evaluation, we observe strong agreement at the run level between scores derived from fully automatic nugget evaluation and human-based variants. The agreement is stronger when individual framework components such as nugget assignment are automated independently. This suggests that our evaluation framework provides tradeoffs between effort and quality that can be used to guide the development of future RAG systems. However, further research is necessary to refine our approach, particularly in establishing robust per-topic agreement to diagnose system failures effectively.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Pradeep, Ronak and Thakur, Nandan and Upadhyay, Shivani and Campos, Daniel and Craswell, Nick and Soboroff, Ian and Dang, Hoa Trang and Lin, Jimmy},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {atomic facts, automatic evaluation, nugget evaluation},
	pages = {180--190},
}

@inproceedings{liu_towards_2024,
	address = {New York, NY, USA},
	series = {{KDD} '24},
	title = {Towards {Automatic} {Evaluation} for {LLMs}' {Clinical} {Capabilities}: {Metric}, {Data}, and {Algorithm}},
	isbn = {979-8-4007-0490-1},
	url = {https://doi.org/10.1145/3637528.3671575},
	doi = {10.1145/3637528.3671575},
	abstract = {Large language models (LLMs) are gaining increasing interests to improve clinical efficiency, owing to their unprecedented performance in modelling natural language. Ensuring the reliable clinical applications, the evaluation of LLMs indeed becomes critical for better mitigating the potential risks, e.g., hallucinations. However, current evaluation methods heavily rely on labor-intensive human participation to achieve human-preferred judgements. To overcome this challenge, we propose an automatic evaluation paradigm tailored to assess the LLMs' capabilities in delivering clinical services, e.g., disease diagnosis and treatment. The evaluation paradigm contains three basic elements: metric, data, and algorithm. Specifically, inspired by professional clinical practice pathways, we formulate a LLM-specific clinical pathway (LCP) to define the clinical capabilities that a doctor agent should possess. Then, Standardized Patients (SPs) from the medical education are introduced as the guideline for collecting medical data for evaluation, which can well ensure the completeness of the evaluation procedure. Leveraging these steps, we develop a multi-agent framework to simulate the interactive environment between SPs and a doctor agent, which is equipped with a Retrieval-Augmented Evaluation (RAE) to determine whether the behaviors of a doctor agent are in accordance with LCP. The above paradigm can be extended to any similar clinical scenarios to automatically evaluate the LLMs' medical capabilities. Applying such paradigm, we construct an evaluation benchmark in the field of urology, including a LCP, a SPs dataset, and an automated RAE. Extensive experiments are conducted to demonstrate the effectiveness of the proposed approach, providing more insights for LLMs' safe and reliable deployments in clinical practice.},
	booktitle = {Proceedings of the 30th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Lei and Yang, Xiaoyan and Li, Fangzhou and Chi, Chenfei and Shen, Yue and Lyu, Shiwei and Zhang, Ming and Ma, Xiaowei and Lv, Xiangguo and Ma, Liya and Zhang, Zhiqiang and Xue, Wei and Huang, Yiran and Gu, Jinjie},
	year = {2024},
	note = {event-place: Barcelona, Spain},
	keywords = {evaluation benchmark, large language model, medical ai},
	pages = {5466--5475},
}

@inproceedings{barone_combining_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Combining {Evidence} and {Reasoning} for {Biomedical} {Fact}-{Checking}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3729931},
	doi = {10.1145/3726302.3729931},
	abstract = {Misinformation in healthcare, from vaccine hesitancy to unproven treatments, poses risks to public health and trust in medical systems. While machine learning and natural language processing have advanced automated fact-checking, validating biomedical claims remains uniquely challenging due to complex terminology, the need for domain expertise, and the critical importance of grounding in scientific evidence. We introduce CER (Combining Evidence and Reasoning), a novel framework for biomedical fact-checking that integrates scientific evidence retrieval, reasoning via large language models, and supervised veracity prediction. By integrating the text-generation capabilities of large language models with advanced retrieval techniques for high-quality biomedical scientific evidence, CER effectively mitigates the risk of hallucinations, ensuring that generated outputs are grounded in verifiable, evidence-based sources. Evaluations on expert-annotated datasets (HealthFC, BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising cross-dataset generalization. Code and data are released for transparency and reproducibility: https://github.com/PRAISELab-PicusLab/CER},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Barone, Mariano and Romano, Antonio and Riccio, Giuseppe and Postiglione, Marco and Moscato, Vincenzo},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {fact-checking, generative ai, healthcare, large language models},
	pages = {1087--1097},
}

@inproceedings{yen_memolet_2024,
	address = {New York, NY, USA},
	series = {{UIST} '24},
	title = {Memolet: {Reifying} the {Reuse} of {User}-{AI} {Conversational} {Memories}},
	isbn = {979-8-4007-0628-8},
	url = {https://doi.org/10.1145/3654777.3676388},
	doi = {10.1145/3654777.3676388},
	abstract = {As users engage more frequently with AI conversational agents, conversations may exceed their “memory” capacity, leading to failures in correctly leveraging certain memories for tailored responses. However, in finding past memories that can be reused or referenced, users need to retrieve relevant information in various conversations and articulate to the AI their intention to reuse these memories. To support this process, we introduce Memolet, an interactive object that reifies memory reuse. Users can directly manipulate Memolet to specify which memories to reuse and how to use them. We developed a system demonstrating Memolet’s interaction across various memory reuse stages, including memory extraction, organization, prompt articulation, and generation refinement. We examine the system’s usefulness with an N=12 within-subject study and provide design implications for future systems that support user-AI conversational memory reusing.},
	booktitle = {Proceedings of the 37th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Yen, Ryan and Zhao, Jian},
	year = {2024},
	note = {event-place: Pittsburgh, PA, USA},
	keywords = {Human-AI, Memory Reuse, Retrieval Augmented Generation},
}

@inproceedings{bose_prompts_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {From {Prompts} to {Properties}: {Rethinking} {LLM} {Code} {Generation} with {Property}-{Based} {Testing}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3728702},
	doi = {10.1145/3696630.3728702},
	abstract = {Large Language Models (LLMs) have shown promise in automated code generation, but ensuring correctness remains a significant challenge. Traditional unit testing evaluates functional correctness but often fails to capture deeper logical constraints. We apply Property-Based Testing (PBT) as an alternative evaluation strategy to StarCoder and CodeLlama on MBPP and HumanEval. Our results reveal that while pass@k evaluation shows moderate success, PBT exposes additional correctness gaps. A significant portion of generated solutions only partially adhere to correctness properties (30–32\%), while 18–23\% fail outright. Property extraction is also imperfect, with 9–13\% of constraints missing. These findings highlight that unit test-based evaluations may overestimate solution correctness by not capturing fundamental logical errors. Our study demonstrates that combining unit testing with PBT can offer a more comprehensive assessment of generated code correctness, revealing limitations that traditional verification approaches miss.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Bose, Dibyendu Brinto},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {code generation, large language model(LLM), property-based-testing},
	pages = {1660--1665},
}

@inproceedings{esmaelizadeh_integrating_2024,
	address = {New York, NY, USA},
	series = {{GUIDE}-{AI} '24},
	title = {On {Integrating} the {Data}-{Science} and {Machine}-{Learning} {Pipelines} for {Responsible} {AI}},
	isbn = {979-8-4007-0694-3},
	url = {https://doi.org/10.1145/3665601.3669849},
	doi = {10.1145/3665601.3669849},
	abstract = {Herein, we advocate for the integration of the pipelines for data science (e.g., extraction, cleaning, and exploration) and machine learning (e.g., training data collection, feature selection, model selection, and parameter tuning), toward responsible and trustworthy artificial intelligence. We argue that the metadata generated by the machine-learning pipeline, which includes model outputs and model accuracy scores, is best managed and analyzed using data-science tools, thereby obtaining actionable insights into model performance, interpretability, and bias. We illustrate via two examples from our recent work as proof of concept: data summarization for model performance diagnostics; and input and output exploration to understand retrieval-augmented language models.},
	booktitle = {Proceedings of the {Conference} on {Governance}, {Understanding} and {Integration} of {Data} for {Effective} and {Responsible} {AI}},
	publisher = {Association for Computing Machinery},
	author = {Esmaelizadeh, Armin and Rorseth, Joel and Yu, Andy and Godfrey, Parke and Golab, Lukasz and Srivastava, Divesh and Szlichta, Jaroslaw and Taghva, Kazem},
	year = {2024},
	note = {event-place: Santiago, AA, Chile},
	keywords = {Data Science, Explainable AI, Machine Learning Model Diagnostics},
	pages = {50--53},
}

@inproceedings{tayal_dynamic_2024,
	address = {New York, NY, USA},
	series = {{WWW} '24},
	title = {Dynamic {Contexts} for {Generating} {Suggestion} {Questions} in {RAG} {Based} {Conversational} {Systems}},
	isbn = {979-8-4007-0172-6},
	url = {https://doi.org/10.1145/3589335.3651905},
	doi = {10.1145/3589335.3651905},
	abstract = {When interacting with Retrieval-Augmented Generation (RAG)-based conversational agents, the users must carefully craft their queries to be understood correctly. Yet, understanding the system's capabilities can be challenging for the users, leading to ambiguous questions that necessitate further clarification. This work aims to bridge the gap by developing a suggestion question generator. To generate suggestion questions, our approach involves utilizing dynamic context, which includes both dynamic few-shot examples and dynamically retrieved contexts. Through experiments, we show that the dynamic contexts approach can generate better suggestion questions as compared to other prompting approaches.},
	booktitle = {Companion {Proceedings} of the {ACM} {Web} {Conference} 2024},
	publisher = {Association for Computing Machinery},
	author = {Tayal, Anuja and Tyagi, Aman},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	keywords = {conversational systems, few-shot, prompting, question generation, rag},
	pages = {1338--1341},
}

@inproceedings{xiang_civil_2025,
	address = {New York, NY, USA},
	series = {{ICAICE} '24},
	title = {Civil {Aviation} {Legal} {Retrieval} and {Analysis} {Based} on {RAG}},
	isbn = {979-8-4007-1800-7},
	url = {https://doi.org/10.1145/3716895.3716958},
	doi = {10.1145/3716895.3716958},
	abstract = {Efficient research on civil aviation laws using a large language model (LMM) is a hot issue in current research In this paper, we build a RAG-based model of civil aviation laws and regulations by analyzing civil aviation law-related documents. We obtain high-quality civil aviation data on civil aviation laws by combining manual and the LLM approaches, and carefully categorize the samples according to the frequency of changes in the answers to the assessment indicators, in order to observe the capability of the LLM more accurately We also evaluate and analyze mainstream and advanced Chinese LLM on our dataset. Extensive experiments and valuable insights show that the use of RAG for retrieval of civil aviation LLM is challenging and deserves further research!},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Artificial} {Intelligence} and {Computer} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Xiang, Ziyu and Luo, Yinhui and Fu, Qiang and Xu, Wenhao},
	year = {2025},
	keywords = {LLM, LLM valuation, RAG, text chunking, vector search},
	pages = {351--357},
}

@inproceedings{wang_towards_2025,
	address = {New York, NY, USA},
	series = {{SIGCOMM} '25},
	title = {Towards {LLM}-{Based} {Failure} {Localization} in {Production}-{Scale} {Networks}},
	isbn = {979-8-4007-1524-2},
	url = {https://doi.org/10.1145/3718958.3750505},
	doi = {10.1145/3718958.3750505},
	abstract = {Root causing and failure localization are critical to maintain reliability in cloud network operations. When an incident is reported, network operators must review massive volumes of monitoring data and identify the root cause (i.e., error device) as fast as possible, making it extremely challenging even for experienced operators. Large language models (LLMs) have shown great potential in text understanding and reasoning. In this paper, we present BiAn, an LLM-based framework designed to assist operators in efficient incident investigation. BiAn processes monitoring data and generates error device rankings with detailed explanations. To date, BiAn has been deployed in our network infrastructure for 10 months and it has successfully assisted operators in identifying error devices more quickly, reducing time to root causing by 20.5\% (55.2\% for high-risk incidents). Extensive performance evaluations based on 17 months of real cases further demonstrate that BiAn achieves accurate and fast failure localization. It improves accuracy by 9.2\% compared to the baseline approach.},
	booktitle = {Proceedings of the {ACM} {SIGCOMM} 2025 {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Chenxu and Zhang, Xumiao and Lu, Runwei and Lin, Xianshang and Zeng, Xuan and Zhang, Xinlei and An, Zhe and Wu, Gongwei and Gao, Jiaqi and Tian, Chen and Chen, Guihai and Liu, Guyue and Liao, Yuhong and Lin, Tao and Cai, Dennis and Zhai, Ennan},
	year = {2025},
	note = {event-place: São Francisco Convent, Coimbra, Portugal},
	keywords = {AIOps, data center networks, incident management, large language model, network troubleshooting, root cause analysis},
	pages = {496--511},
}

@inproceedings{gubanov_cancerkgorg_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {{CancerKG}.{ORG} - {A} {Web}-scale, {Interactive}, {Verifiable} {Knowledge} {Graph}-{LLM} {Hybrid} for {Assisting} with {Optimal} {Cancer} {Treatment} and {Care}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3680094},
	doi = {10.1145/3627673.3680094},
	abstract = {Here, we describe one of the first Web-scale hybrid Knowledge Graph (KG)-Large Language Model (LLM), populated with the latest peer-reviewed medical knowledge on colorectal Cancer. It is currently being evaluated to assist with both medical research and clinical information retrieval tasks at Moffitt Cancer Center and Research Institute, which is one of the top Cancer centers in the U.S. and in the world. Our hybrid is remarkable as it serves the user needs better than just an LLM, KG or a search-engine in isolation. LLMs as is are known to exhibit hallucinations and catastrophic forgetting as well as are trained on outdated corpora. The state of the art KGs, such as PrimeKG, cBioPortal, ChEMBL, NCBI, and other require manual curation, hence are quickly getting stale. CancerKG is unsupervised and is capable of automatically ingesting and organizing the latest medical findings. To alleviate the LLMs shortcomings, the verified KG serves as a Retrieval Augmented Generation (RAG) guardrail. CancerKG exhibits 5 different advanced user interfaces, each tailored to serve different data modalities better and more convenient for the user. We evaluated CancerKG on real user queries and report a high NDCG score on a large-scale corpora of approximately 44K publications.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Gubanov, Michael and Pyayt, Anna and Karolak, Aleksandra},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {artificial intelligence (AI), cancer, data management, LLM},
	pages = {4497--4505},
}

@inproceedings{hofstatter_fid-light_2023,
	address = {New York, NY, USA},
	series = {{SIGIR} '23},
	title = {{FiD}-{Light}: {Efficient} and {Effective} {Retrieval}-{Augmented} {Text} {Generation}},
	isbn = {978-1-4503-9408-6},
	url = {https://doi.org/10.1145/3539618.3591687},
	doi = {10.1145/3539618.3591687},
	abstract = {Retrieval-augmented generation models offer many benefits over standalone language models: besides a textual answer to a given query they provide provenance items retrieved from an updateable knowledge base. However, they are also more complex systems and need to handle long inputs. In this work, we introduce FiD-Light to strongly increase the efficiency of the state-of-the-art retrieval-augmented FiD model, while maintaining the same level of effectiveness. Our FiD-Light model constrains the information flow from the encoder (which encodes passages separately) to the decoder (using concatenated encoded representations). Furthermore, we adapt FiD-Light with re-ranking capabilities through textual source pointers, to improve the top-ranked provenance precision. Our experiments on a diverse set of seven knowledge intensive tasks (KILT) show FiD-Light consistently improves the Pareto frontier between query latency and effectiveness. FiD-Light with source pointing sets substantial new state-of-the-art results on six KILT tasks for combined text generation and provenance retrieval evaluation, while maintaining high efficiency.},
	booktitle = {Proceedings of the 46th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Hofstätter, Sebastian and Chen, Jiecao and Raman, Karthik and Zamani, Hamed},
	year = {2023},
	note = {event-place: Taipei, Taiwan},
	keywords = {fusion-in-decoder, kilt, retrieval augmented generation},
	pages = {1437--1447},
}

@inproceedings{chong_llm-net_2025,
	address = {New York, NY, USA},
	series = {{ICSCA} '25},
	title = {{LLM}-{Net}: {Democratizing} {LLMs}-as-a-{Service} through {Blockchain}-based {Expert} {Networks}},
	isbn = {979-8-4007-1012-4},
	url = {https://doi.org/10.1145/3731806.3731827},
	doi = {10.1145/3731806.3731827},
	abstract = {The centralization of Large Language Models (LLMs) development has created significant barriers to AI advancement, limiting the democratization of these powerful technologies. This centralization, coupled with the scarcity of high-quality training data and mounting complexity in maintaining comprehensive expertise across rapidly expanding knowledge domains, poses critical challenges to the continued growth of LLMs. While solutions like Retrieval-Augmented Generation (RAG) offer potential remedies, maintaining up-to-date expert knowledge across diverse domains remains a significant challenge, particularly given the exponential growth of specialized information. This paper introduces LLM Networks (LLM-Net), a blockchain-based framework that democratizes LLMs-as-a-Service through a decentralized network of specialized LLM providers. By leveraging collective computational resources and distributed domain expertise, LLM-Net incorporates fine-tuned expert models for various specific domains, ensuring sustained knowledge growth while maintaining service quality through collaborative prompting mechanisms. The framework’s robust design includes blockchain technology for transparent transaction and performance validation, establishing an immutable record of service delivery. Our simulation, built on top of state-of-the-art LLMs such as Claude 3.5 Sonnet, Llama 3.1, Grok-2, and GPT-4o, validates the effectiveness of the reputation-based mechanism in maintaining service quality by selecting high-performing respondents (LLM providers). Thereby, the results demonstrate the potential of LLM-Net to sustain AI advancement through the integration of decentralized expertise and blockchain-based accountability.},
	booktitle = {Proceedings of the 2025 14th {International} {Conference} on {Software} and {Computer} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Chong, Zan-Kai and Ohsaki, Hiroyuki and Ng, Bryan},
	year = {2025},
	pages = {313--320},
}

@inproceedings{fang_cross-cultural_2025,
	address = {New York, NY, USA},
	series = {{LAK} '25},
	title = {A {Cross}-{Cultural} {Confusion} {Model} for {Detecting} and {Evaluating} {Students}’ {Confusion} {In} a {Large} {Classroom}},
	isbn = {979-8-4007-0701-8},
	url = {https://doi.org/10.1145/3706468.3706528},
	doi = {10.1145/3706468.3706528},
	abstract = {In traditional lecture delivery setting, it is very challenging to identify which part of the lecture material that students are struggling with. One approach to identify difficult concepts is to capture students’ confusion during class time. However, most existing confusion detectors focus on an individual student rather than a classroom, and only on a single ethnicity group which could propagate bias when developing pedagogical technologies. In this paper, we leverage two existing ‘Confused’ facial expression datasets (DAiSEE and DevEmo) with an East Asian ‘Confused’ facial expression dataset that we collected. Through model performance and explainableAI, we address potential cultural biases in detecting emotions, particularly in confusion, and identified culturally-specific features that align with prior research. As a proof-of-concept, we deployed this cross-cultural confusion machine learning model in a live semester-long class. This work to integrate cross-cultural facial features highlights the importance of fostering inclusivity in educational technologies.},
	booktitle = {Proceedings of the 15th {International} {Learning} {Analytics} and {Knowledge} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Fang, Yu and Huang, Shihong and Ogan, Amy},
	year = {2025},
	keywords = {Affective computing, Confusion, Cross-cultural models, Retrieval-augmented generation},
	pages = {473--483},
}

@inproceedings{shailya_lext_2025,
	address = {New York, NY, USA},
	series = {{FAccT} '25},
	title = {{LExT}: {Towards} {Evaluating} {Trustworthiness} of {Natural} {Language} {Explanations}},
	isbn = {979-8-4007-1482-5},
	url = {https://doi.org/10.1145/3715275.3732104},
	doi = {10.1145/3715275.3732104},
	abstract = {As Large Language Models (LLMs) become increasingly integrated into high-stakes domains, there have been several approaches proposed toward generating natural language explanations. These explanations are crucial for enhancing the interpretability of a model, especially in sensitive domains like healthcare, where transparency and reliability are key. In light of such explanations being generated by LLMs and its known concerns, there is a growing need for robust evaluation frameworks to assess model-generated explanations. Natural Language Generation metrics like BLEU and ROUGE capture syntactic and semantic accuracies but overlook other crucial aspects such as factual accuracy, consistency, and faithfulness. To address this gap, we propose a general framework for quantifying trustworthiness of natural language explanations, balancing Plausibility and Faithfulness, to derive a comprehensive Language Explanation Trustworthiness Score (LExT). Applying our domain-agnostic framework to the healthcare domain using public medical datasets, we evaluate six models, including domain-specific and general-purpose models. Our findings demonstrate significant differences in their ability to generate trustworthy explanations. On comparing these explanations, we make interesting observations such as inconsistencies in Faithfulness demonstrated by general-purpose models and their tendency to outperform domain-specific fine-tuned models. This work further highlights the importance of using a tailored evaluation framework to assess natural language explanations in sensitive fields, providing a foundation for improving the trustworthiness and transparency of language models in healthcare and beyond.},
	booktitle = {Proceedings of the 2025 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Shailya, Krithi and Rajpal, Shreya and Krishnan, Gokul S and Ravindran, Balaraman},
	year = {2025},
	keywords = {Evaluation, Explanations, Faithfulness, Healthcare, Language Models, Plausibility, Trustworthiness},
	pages = {1565--1587},
}

@inproceedings{li_corpuslm_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {{CorpusLM}: {Towards} a {Unified} {Language} {Model} on {Corpus} for {Knowledge}-{Intensive} {Tasks}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657778},
	doi = {10.1145/3626772.3657778},
	abstract = {Large language models (LLMs) have gained significant attention in various fields but prone to hallucination, especially in knowledge-intensive (KI) tasks. To address this, retrieval-augmented generation (RAG) has emerged as a popular solution to enhance factual accuracy. However, traditional retrieval modules often rely on large document index and disconnect with generative tasks. With the advent of generative retrieval (GR), language models can retrieve by directly generating document identifiers (DocIDs), offering superior performance in retrieval tasks. However, the potential relationship between GR and downstream tasks remains unexplored. In this paper, we propose CorpusLM, a unified language model that leverages external corpus to tackle various knowledge-intensive tasks by integrating generative retrieval, closed-book generation, and RAG through a unified greedy decoding process. We design the following mechanisms to facilitate effective retrieval and generation, and improve the end-to-end effectiveness of KI tasks: (1) We develop a ranking-oriented DocID list generation strategy, which refines GR by directly learning from a DocID ranking list, to improve retrieval quality. (2) We design a continuous DocIDs-References-Answer generation strategy, which facilitates effective and efficient RAG. (3) We employ well-designed unsupervised DocID understanding tasks, to comprehend DocID semantics and their relevance to downstream tasks. We evaluate our approach on the widely used KILT benchmark with two variants of backbone models, i.e., T5 and Llama2. Experimental results demonstrate the superior performance of our models in both retrieval and downstream tasks.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Li, Xiaoxi and Dou, Zhicheng and Zhou, Yujia and Liu, Fangchao},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {generative retrieval, knowledge-intensive language tasks, rag},
	pages = {26--37},
}

@inproceedings{guo_bkrag_2024,
	address = {New York, NY, USA},
	series = {{PRIS} '24},
	title = {{BKRAG} : {A} {BGE} {Reranker} {RAG} for similarity analysis of power project requirements},
	isbn = {979-8-4007-1825-0},
	url = {https://doi.org/10.1145/3689218.3689224},
	doi = {10.1145/3689218.3689224},
	abstract = {This paper proposes an innovative method called BKRAG (A BGE Reranker Retrieval Augmented Generation for similarity analysis of power project requirements), which integrates information retrieval techniques and NLP to achieve automated analysis and similarity evaluation of power project requirements. The core of the BKRAG method lies in the utilization of a Rerank model to re-rank the initially retrieved candidate documents, improving their semantic matching degree with user queries, thereby optimizing the results of requirements similarity analysis. In this paper, we elaborate on the construction principles and workflow of the BKRAG method and verify its effectiveness through a series of experiments. Results demonstrate that the BKRAG can significantly improve the retrieval accuracy of power project requirement documents and the performance of requirements similarity analysis. The research findings of this paper not only provide a new solution for the field of power project requirements analysis, but also offer new insights into the cross-application of information retrieval and natural language processing technologies.},
	booktitle = {Proceedings of the 2024 6th {International} {Conference} on {Pattern} {Recognition} and {Intelligent} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Guo, Jun and Chen, Bojian and Zhao, Zhichao and He, Jindong and Chen, Shichun and Hu, Donglan and Pan, Hao},
	year = {2024},
	note = {event-place: Hong Kong, Hong Kong},
	keywords = {Power project, RAG, requirements similarity analysis, Rerank model},
	pages = {14--20},
}

@inproceedings{strubberg_ux_2025,
	address = {New York, NY, USA},
	series = {{SIGDOC} '25},
	title = {From {UX} to {AI} {Literacies}: {Evaluating} a {Custom} {Chatbot} in the {UX} {Classroom}},
	isbn = {979-8-4007-1444-3},
	url = {https://doi.org/10.1145/3711670.3764640},
	doi = {10.1145/3711670.3764640},
	abstract = {This experience report reflects on a collaborative effort to examine how generative artificial intelligence chatbots (gen AI chatbots) can support technical communication (TC) students in developing gen AI and user experience (UX) literacies aligned with emerging professional practices. Upper-division students in a UX research course investigated the usability and design of a custom-built chatbot that had been integrated into a general education TC course as a learning assistant. Students engaged with the chatbot both as users and evaluators, learning from the developer and analyzing its underlying architecture, training corpus, and decision-making processes. This report reviews both the chatbot's design and development, as well as the details of the UX course, and posits that giving students active roles in the design, testing, and critique of gen AI tools fosters durable skills that bridge the academic and professional spheres.},
	booktitle = {Proceedings of the 43rd {ACM} {International} {Conference} on {Design} of {Communication}},
	publisher = {Association for Computing Machinery},
	author = {Strubberg, Brandon C. and Blackburn, Hayley},
	year = {2025},
	keywords = {digital literacies, Generative artificial intelligence, retrieval augmented generation, technical communication, user experience},
	pages = {189--194},
}

@inproceedings{shi_retrieval-enhanced_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {Retrieval-enhanced {Knowledge} {Editing} in {Language} {Models} for {Multi}-{Hop} {Question} {Answering}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3679722},
	doi = {10.1145/3627673.3679722},
	abstract = {Large Language Models (LLMs) have shown proficiency in question-answering tasks but often struggle to integrate real-time knowledge, leading to potentially outdated or inaccurate responses. This problem becomes even more challenging when dealing with multi-hop questions, since they require LLMs to update and integrate multiple knowledge pieces relevant to the questions. To tackle the problem, we propose the Retrieval-Augmented model Editing (RAE) framework for multi-hop question answering. RAE first retrieves edited facts and then refines the language model through in-context learning. Specifically, our retrieval approach, based on mutual information maximization, leverages the reasoning abilities of LLMs to identify chain facts that traditional similarity-based searches might miss. In addition, our framework includes a pruning strategy to eliminate redundant information from the retrieved facts, which enhances the editing accuracy and mitigates the hallucination problem. Our framework is supported by theoretical justification for its fact retrieval efficacy. Finally, comprehensive evaluation across various LLMs validates RAE's ability in providing accurate answers with updated knowledge. Our code is available at: https://github.com/sycny/RAE.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Shi, Yucheng and Tan, Qiaoyu and Wu, Xuansheng and Zhong, Shaochen and Zhou, Kaixiong and Liu, Ninghao},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {model editing, question answering, retrieval-augmented generation},
	pages = {2056--2066},
}

@inproceedings{wang_how_2025,
	address = {New York, NY, USA},
	series = {{LEO}-{NET} '25},
	title = {How {LLM} {Saved} {Me} from {Struggling} with {Experiment} {Reproduction}: {LEO} {Networking} as {A} {Case} {Study}},
	isbn = {979-8-4007-2090-1},
	url = {https://doi.org/10.1145/3748749.3749084},
	doi = {10.1145/3748749.3749084},
	abstract = {Reproducing network experiments is critical to advancing the research in computer networks. However, in reality many researchers often struggle with experiment reproduction: not only because reading, understanding, and debugging prior work is time-consuming and labor-intensive, but also because not all papers publicly release their code, thereby forcing subsequent researchers to re-implement experiments from scratch.In this paper, we explore an intriguing question: can recent large language models (LLMs) assist in understanding research papers and generating code, thereby accelerating the reproduction of network experiments? Focusing on the rapidly evolving area of low-Earth-orbit (LEO) satellite networks (LSN), we present LASER1, a semi-automated, LLM-assisted tool designed to facilitate the reproduction of LSN experiments. LASER judiciously integrates the capabilities of LLM with LSN simulation to ease the burden of LSN experimentation. Our case studies provide preliminary evidence that LASER can efficiently reproduce experimental results consistent with those reported in the original papers, while substantially reducing the manual effort required by LSN researchers},
	booktitle = {Proceedings of the 2025 3rd {Workshop} on {LEO} {Networking} and {Communication}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Yibo and Hou, Yunan and Lai, Zeqi and Li, Hewu and Wu, Qian and Liu, Jun and Li, Yuanjie and Xie, Xin and Han, Zhifeng},
	year = {2025},
	note = {event-place: Coimbra, Portugal},
	keywords = {Large Language Model (LLM), LEO Satellite Network (LSN), Network Experiment Reproduction, Network Simulation},
	pages = {1--7},
}

@inproceedings{birillo_one_2024,
	address = {New York, NY, USA},
	series = {Koli {Calling} '24},
	title = {One {Step} at a {Time}: {Combining} {LLMs} and {Static} {Analysis} to {Generate} {Next}-{Step} {Hints} for {Programming} {Tasks}},
	isbn = {979-8-4007-1038-4},
	url = {https://doi.org/10.1145/3699538.3699556},
	doi = {10.1145/3699538.3699556},
	abstract = {Students often struggle with solving programming problems when learning to code, especially when they have to do it online, with one of the most common disadvantages of working online being the lack of personalized help. This help can be provided as next-step hint generation, i.e., showing a student what specific small step they need to do next to get to the correct solution. There are many ways to generate such hints, with large language models (LLMs) being among the most actively studied right now. While LLMs constitute a promising technology for providing personalized help, combining them with other techniques, such as static analysis, can significantly improve the output quality. In this work, we utilize this idea and propose a novel system to provide both textual and code hints for programming tasks. The pipeline of the proposed approach uses a chain-of-thought prompting technique and consists of three distinct steps: (1) generating subgoals — a list of actions to proceed with the task from the current student’s solution, (2) generating the code to achieve the next subgoal, and (3) generating the text to describe this needed action. During the second step, we apply static analysis to the generated code to control its size and quality. The tool is implemented as a modification to the open-source JetBrains Academy plugin, supporting students in their in-IDE courses. To evaluate our approach, we propose a list of criteria for all steps in our pipeline and conduct two rounds of expert validation. Finally, we evaluate the next-step hints in a classroom with 14 students from two universities. Our results show that both forms of the hints — textual and code — were helpful for the students, and the proposed system helped them to proceed with the coding tasks.},
	booktitle = {Proceedings of the 24th {Koli} {Calling} {International} {Conference} on {Computing} {Education} {Research}},
	publisher = {Association for Computing Machinery},
	author = {Birillo, Anastasiia and Artser, Elizaveta and Potriasaeva, Anna and Vlasov, Ilya and Dzialets, Katsiaryna and Golubev, Yaroslav and Gerasimov, Igor and Keuning, Hieke and Bryksin, Timofey},
	year = {2024},
	keywords = {Generative AI, in-IDE learning, LLMs, Next-Step Hints, Programming Education},
}

@inproceedings{liu_tigervector_2025,
	address = {New York, NY, USA},
	series = {{SIGMOD}/{PODS} '25},
	title = {{TigerVector}: {Supporting} {Vector} {Search} in {Graph} {Databases} for {Advanced} {RAGs}},
	isbn = {979-8-4007-1564-8},
	url = {https://doi.org/10.1145/3722212.3724456},
	doi = {10.1145/3722212.3724456},
	abstract = {In this paper, we introduce TigerVector, a system that integrates vector search and graph query within TigerGraph, a Massively Parallel Processing (MPP) native graph database. We extend the vertex attribute type with the embedding type. To support fast vector search, we devise an MPP index framework that interoperates efficiently with the graph engine. The graph query language GSQL is enhanced to support vector type expressions and enable query compositions between vector search results and graph query blocks. These advancements elevate the expressive power and analytical capabilities of graph databases, enabling seamless fusion of unstructured and structured data in ways previously unattainable. Through extensive experiments, we demonstrate TigerVector's hybrid search capability, scalability, and superior performance compared to other graph databases (including Neo4j and Amazon Neptune) and a highly optimized specialized vector database (Milvus). TigerVector was integrated into TigerGraph v4.2, the latest release of TigerGraph, in December 2024.},
	booktitle = {Companion of the 2025 {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Shige and Zeng, Zhifang and Chen, Li and Ainihaer, Adil and Ramasami, Arun and Chen, Songting and Xu, Yu and Wu, Mingxi and Wang, Jianguo},
	year = {2025},
	note = {event-place: Berlin, Germany},
	keywords = {graph database, retrieval-augmented generation, vector database},
	pages = {553--565},
}

@inproceedings{zhang_eclass_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {℡{EClass}: {Taxonomy} {Enrichment} and {LLM}-{Enhanced} {Hierarchical} {Text} {Classification} with {Minimal} {Supervision}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714940},
	doi = {10.1145/3696410.3714940},
	abstract = {Hierarchical text classification aims to categorize each document into a set of classes in a label taxonomy, which is a fundamental web text mining task with broad applications such as web content analysis and semantic indexing. Most earlier works focus on fully or semi-supervised methods that require a large amount of human annotated data which is costly and time-consuming to acquire. To alleviate human efforts, in this paper, we work on hierarchical text classification with a minimal amount of supervision: using the sole class name of each node as the only supervision. Recently, large language models (LLM) have shown competitive performance on various tasks through zero-shot prompting, but this method performs poorly in the hierarchical setting because it is ineffective to include the large and structured label space in a prompt. On the other hand, previous weakly-supervised hierarchical text classification methods only utilize the raw taxonomy skeleton and ignore the rich information hidden in the text corpus that can serve as additional class-indicative features. To tackle the above challenges, we propose ℡EClass, \&lt;u\&gt;T\&lt;/u\&gt;axonomy \&lt;u\&gt;E\&lt;/u\&gt;nrichment and \&lt;u\&gt;L\&lt;/u\&gt;LM-\&lt;u\&gt;E\&lt;/u\&gt;nhanced weakly-supervised hierarchical text \&lt;u\&gt;Class\&lt;/u\&gt;ification, which combines the general knowledge of LLMs and task-specific features mined from an unlabeled corpus. ℡EClass automatically enriches the raw taxonomy with class-indicative features for better label space understanding and utilizes novel LLM-based data annotation and generation methods specifically tailored for the hierarchical setting. Experiments show that ℡EClass can significantly outperform previous baselines while achieving comparable performance to zero-shot prompting of LLMs with drastically less inference cost.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Yunyi and Yang, Ruozhen and Xu, Xueqiang and Li, Rui and Xiao, Jinfeng and Shen, Jiaming and Han, Jiawei},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {hierarchical text classification, large language model, taxonomy enrichment, weakly-supervised text classification},
	pages = {2032--2042},
}

@inproceedings{haag_last_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {The {Last} {JITAI}? {Exploring} {Large} {Language} {Models} for {Issuing} {Just}-in-{Time} {Adaptive} {Interventions}: {Fostering} {Physical} {Activity} in a {Prospective} {Cardiac} {Rehabilitation} {Setting}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713307},
	doi = {10.1145/3706598.3713307},
	abstract = {We evaluated the viability of using Large Language Models (LLMs) to trigger and personalize content in Just-in-Time Adaptive Interventions (JITAIs) in digital health. As an interaction pattern representative of context-aware computing, JITAIs are being explored for their potential to support sustainable behavior change, adapting interventions to an individual's current context and needs. Challenging traditional JITAI implementation models, which face severe scalability and flexibility limitations, we tested GPT-4 for suggesting JITAIs in the use case of heart-healthy activity in cardiac rehabilitation. Using three personas representing patients affected by CVD with varying severeness and five context sets per persona, we generated 450 JITAI decisions and messages. These were systematically evaluated against those created by 10 laypersons (LayPs) and 10 healthcare professionals (HCPs). GPT-4-generated JITAIs surpassed human-generated intervention suggestions, outperforming both LayPs and HCPs across all metrics (i.e., appropriateness, engagement, effectiveness, and professionalism). These results highlight the potential of LLMs to enhance JITAI implementations in personalized health interventions, demonstrating how generative AI could revolutionize context-aware computing.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Haag, David and Kumar, Devender and Gruber, Sebastian and Hofer, Dominik P., MSc and Sareban, Mahdi and Treff, Gunnar and Niebauer, Josef and Bull, Christopher N and Schmidt, Albrecht and Smeddinck, Jan David},
	year = {2025},
	keywords = {adaptive interventions, context-aware computing, digital health, generative AI, healthcare AI, human-AI interaction, JITAIs, just-in-time adaptive interventions, large language models, LLMs},
}

@inproceedings{abedu_llm-based_2024,
	address = {New York, NY, USA},
	series = {{EASE} '24},
	title = {{LLM}-{Based} {Chatbots} for {Mining} {Software} {Repositories}: {Challenges} and {Opportunities}},
	isbn = {979-8-4007-1701-7},
	url = {https://doi.org/10.1145/3661167.3661218},
	doi = {10.1145/3661167.3661218},
	abstract = {Software repositories have a plethora of information about software development, encompassing details such as code contributions, bug reports and code reviews. This rich source of data can be harnessed to enhance not only software quality and development velocity but also to gain insights into team collaboration and inform strategic decision-making throughout the software development lifecycle. Previous studies show that many stakeholders cannot benefit from the project information due to the technical knowledge and expertise required to extract the project data. To lower the barrier to entry by automating the process of extracting and analyzing repository data, we explored the potential of using an LLM to develop a chatbot for answering questions related to software repositories. We evaluated the chatbot on 150 software repository-related questions. We found that the chatbot correctly answered one question. This result prompted us to shift our focus to investigate the challenges in adopting LLMs for the out-of-the-box development of software repository chatbots. We identified five main challenges related to retrieving data, structuring the data, and generating the answer to the user’s query. Among these challenges, the most frequent (83.3\%) is the inaccurate retrieval of data to answer questions. In this paper, we share our experience and challenges in developing an LLM-based chatbot to answer software repository-related questions within the SE community. We also provide recommendations on mitigating these challenges. Our findings will serve as a foundation to drive future research aimed at enhancing LLMs for adoption in extracting useful information from software repositories, fostering advancements in natural language understanding, data retrieval, and response generation within the context of software repository-related questions and analytics.},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Evaluation} and {Assessment} in {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Abedu, Samuel and Abdellatif, Ahmad and Shihab, Emad},
	year = {2024},
	note = {event-place: Salerno, Italy},
	keywords = {Conversational Development Assistant, Large Language Model, Software Chatbots},
	pages = {201--210},
}

@inproceedings{lajewska_explainability_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Explainability for {Transparent} {Conversational} {Information}-{Seeking}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657768},
	doi = {10.1145/3626772.3657768},
	abstract = {The increasing reliance on digital information necessitates advancements in conversational search systems, particularly in terms of information transparency. While prior research in conversational information-seeking has concentrated on improving retrieval techniques, the challenge remains in generating responses useful from a user perspective. This study explores different methods of explaining the responses, hypothesizing that transparency about the source of the information, system confidence, and limitations can enhance users' ability to objectively assess the response. By exploring transparency across explanation type, quality, and presentation mode, this research aims to bridge the gap between system-generated responses and responses verifiable by the user. We design a user study to answer questions concerning the impact of (1) the quality of explanations enhancing the response on its usefulness and (2) ways of presenting explanations to users. The analysis of the collected data reveals lower user ratings for noisy explanations, although these scores seem insensitive to the quality of the response. Inconclusive results on the explanations presentation format suggest that it may not be a critical factor in this setting.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Łajewska, Weronika and Spina, Damiano and Trippas, Johanne and Balog, Krisztian},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {conversational information-seeking, explainable ai},
	pages = {1040--1050},
}

@inproceedings{jin_intentiongpt_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{IntentionGPT}: {Boosting} {E}-commerce {User} {Intent} {Recognition} with {Self}-data {Augmentation} and {Structure}-aware {Retrieval}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3718370},
	doi = {10.1145/3701716.3718370},
	abstract = {In recent years, Vision Language Models (VLMs) have significantly advanced multi-modal reasoning and generation tasks, offering promising solutions for e-commerce applications like multi-modal user intent recognition. However, VLMs trained on open-domain datasets often struggle with understanding fine-grained e-commerce semantics. This limitation stems primarily from two key factors: the scarcity of labeled multi-modal data for training and the lack of domain-specific knowledge to effectively reason. To overcome the above problems, we introduce IntentionGPT, a novel framework for multi-modal user intent recognition in e-commerce with limited labeled data. Specifically, we first propose a self-data augmentation method to generate diverse synthetic samples from minimal seed labeled samples to tackle data scarcity challenge. Meanwhile, a new collaborative filtering mechanism is proposed to filter out noise samples to enhance data quality. Second, a structure-aware retrieval method is proposed for retrieving domain knowledge to enhance the model's multi-modal reasoning ability. Third, the model soups method are utilized to fuse models from different training stages, combining their strengths and mitigating potential biases for robust performance. This work systematically addresses both data scarcity and domain adaptation challenges, and achieves first place in the WWW2025 multi-modal dialogue system intent recognition challenge.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Jin, Yilun and Wu, Chunqi and Zhang, Ying and Shi, Chenlong and Li, Zhao and Yin, Wei and Pan, Xuming},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {intent classification, retrieval-augmented generation, vision language model},
	pages = {3053--3057},
}

@inproceedings{gao_fast_2025,
	address = {New York, NY, USA},
	series = {{EuroSys} '25},
	title = {Fast {State} {Restoration} in {LLM} {Serving} with {HCache}},
	isbn = {979-8-4007-1196-1},
	url = {https://doi.org/10.1145/3689031.3696072},
	doi = {10.1145/3689031.3696072},
	abstract = {The growing complexity of LLM usage today, e.g., multi-round conversation and retrieval-augmented generation (RAG), makes contextual states (i.e., KV cache) reusable across user requests. Given the capacity constraints of GPU memory, only a limited number of contexts can be cached on GPU for reusing. Existing inference systems typically evict part of the KV cache and restore it by recomputing it from the original tokens or offloading it to host storage for later retrieval, both of which introduce substantial computational or I/O overheads.We propose HCache, a novel LLM state restoration method. Its key idea is to restore LLM states from intermediate activations and thus utilize computational and I/O resources with low overhead. We enhance HCache with two techniques, including i) a bubble-free restoration scheduler that integrates resource-complementary methods to optimize the balance between computation and IO tasks; and ii) a chunk-based storage manager to address the layout mismatch issue (i.e., layer-before-token saving versus token-before-layer restoration). Our evaluations, conducted using real-world tasks, show that HCache reduces the TTFT by up to 1.93× compared to KV offload while consuming 1.92-2.40× less storage space; compared to token recomputation, HCache achieves up to 5.73× reduction in TTFT.},
	booktitle = {Proceedings of the {Twentieth} {European} {Conference} on {Computer} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Gao, Shiwei and Chen, Youmin and Shu, Jiwu},
	year = {2025},
	note = {event-place: Rotterdam, Netherlands},
	keywords = {LLM, machine learning system, state management},
	pages = {128--143},
}

@inproceedings{tian_towards_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Towards {Explainable} {Search} {Results} in {E}-commerce},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715264},
	doi = {10.1145/3701716.3715264},
	abstract = {Search result explanations are essential in E-commerce, helping users understand the relevance of the returned results. Existing methods primarily focus on explaining relevance based on either product content or behavioral data. However, we argue that combining both content and behavior data can provide more comprehensive and accurate explanations. In this paper, we propose a novel approach to generate relevance explanations. First, we utilize the content data to train a domain-specific large language model (LLM) that generates relevance labels and reasoning processes for queries and items. Then, we introduce the BehaviorRAG framework to retrieve behavioral data related to queries and items, allowing the model to generate explainable reasons for their relevance. Finally, the LLM integrates outputs from both the content- and behavior-based modules to produce a final explanation. To evaluate the effectiveness of our methods, we conduct extensive experiments on both our built dataset and publicly available datasets. The results demonstrate that our method outperforms current state-of-the-art baselines in predicting relevance and generating explainable reasons. Furthermore, online A/B testing on the Fliggy app demonstrates that incorporating explanations generated by our approach into the search results leads to a 2.30\% increase in the Unique Visitors List to Order. The codes are publicly available at https://github.com/tonnyaudio/explainable.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Tian, Xianyang and Xu, Xiang and Wang, Chao and Ruan, Tong and Wu, Baohua and Que, Maofei and Ni, Shenghua and Zhuang, Zhuoran and Liu, Jingping},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {explainable search, large language model, relevance analysis},
	pages = {476--484},
}

@inproceedings{wang_rcagent_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {{RCAgent}: {Cloud} {Root} {Cause} {Analysis} by {Autonomous} {Agents} with {Tool}-{Augmented} {Large} {Language} {Models}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3680016},
	doi = {10.1145/3627673.3680016},
	abstract = {Large language model (LLM) applications in cloud root cause analysis (RCA) have been actively explored recently. However, current methods are still reliant on manual workflow settings and do not unleash LLMs' decision-making and environment interaction capabilities. We present RCAgent, a tool-augmented LLM autonomous agent framework for practical and privacy-aware industrial RCA usage. Running on an internally deployed model rather than GPT families, RCAgent is capable of free-form data collection and comprehensive analysis with tools. Our framework combines a variety of enhancements, including a unique Self-Consistency for action trajectories, and a suite of methods for context management, stabilization, and importing domain knowledge. Our experiments show RCAgent's evident and consistent superiority over ReAct across all aspects of RCA–predicting root causes, solutions, evidence, and responsibilities–and tasks covered or uncovered by current rules, as validated by both automated metrics and human evaluations. Furthermore, RCAgent has already been integrated into the diagnosis and issue discovery workflow of the Real-time Compute Platform for Apache Flink of Alibaba Cloud.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Zefan and Liu, Zichuan and Zhang, Yingying and Zhong, Aoxiao and Wang, Jihong and Yin, Fengbin and Fan, Lunting and Wu, Lingfei and Wen, Qingsong},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {cloud systems, large language model, root cause analysis},
	pages = {4966--4974},
}

@inproceedings{liu_improving_2025,
	address = {New York, NY, USA},
	series = {{SIGCSETS} 2025},
	title = {Improving {AI} in {CS50}: {Leveraging} {Human} {Feedback} for {Better} {Learning}},
	isbn = {979-8-4007-0531-1},
	url = {https://doi.org/10.1145/3641554.3701945},
	doi = {10.1145/3641554.3701945},
	abstract = {In 2023, we developed and deployed AI-based tools in CS50 at Harvard University to provide students with 24/7 interactive assistance, approximating a 1:1 teacher-to-student ratio. These tools offer code explanations, style suggestions, and responses to course-related inquiries, emulating human educators to foster critical thinking. However, maintaining alignment with instructional goals is challenging, especially with frequent updates to the underlying large language models (LLMs). We thus propose a continuous improvement process for LLM-based systems using a collaborative human-in-the-loop approach. We introduce a systematic evaluation framework for assessing and refining the performance of AI-based tutors, combining human-graded and model-graded evaluations. Using few-shot prompting and fine-tuning, we aim to ensure our AI tools adopt pedagogically sound teaching styles. Fine-tuning with a small, high-quality dataset has shown significant improvements in aligning with teaching goals, as confirmed through multi-turn conversation evaluations. Additionally, our framework includes a model-evaluation backend that teaching assistants periodically review, ensuring the AI system remains effective and aligned with instructional objectives. This paper offers insights into our methods and the impact of these AI tools on CS50 and contributes to the discourse on AI in education, showcasing scalable, personalized learning enhancements.},
	booktitle = {Proceedings of the 56th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education} {V}. 1},
	publisher = {Association for Computing Machinery},
	author = {Liu, Rongxin and Zhao, Julianna and Xu, Benjamin and Perez, Christopher and Zhukovets, Yuliia and Malan, David J.},
	year = {2025},
	note = {event-place: Pittsburgh, PA, USA},
	keywords = {ai, artificial intelligence, generative ai, large language models, llms},
	pages = {715--721},
}

@inproceedings{liang_kag_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{KAG}: {Boosting} {LLMs} in {Professional} {Domains} via {Knowledge} {Augmented} {Generation}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715240},
	doi = {10.1145/3701716.3715240},
	abstract = {The recently developed Retrieval-Augmented Generation (RAG) technology has enabled the efficient construction of domain-specific applications. The key technologies of RAG are retrieval based on similarity and reasoning based on next-token prediction. However, this approach differs significantly from how humans solve problems. Humans typically follow certain analytical logic, reasoning while retrieving relevant information, and then connecting the clues to serve as references, ultimately generating an answer. In this process, the focus is on the semantic type and clear relationships between the keywords rather than similarity and co-occurrence. This difference in methodology results in the answers generated by RAG technology being insufficiently accurate or valuable.In this work, we concentrate on establishing semantic relationships between keywords to enable a more precise expression of knowledge and propose the Knowledge Augmented Generation(KAG) framework. KAG performs semantic parsing and reasoning on both documents and questions, involving three specific strategies: In the indexing phase, we complete the semantic information of keywords and the semantic relationships between them through information extraction and semantic reasoning; in the reasoning phase of question answering, we leverage semantic parsing to transform questions into Logical Forms with clear semantic types and relationships; in the retrieval phase, we predict the semantic relationships between Logical Form elements and structured index, thereby obtaining the required references.We compared KAG with existing RAG methods in three multi-hop QA datasets and the results show that KAG significantly outperforms existing methods, achieving a new state-of-the-art. We also applied KAG to real E-Government Q\&amp;A business scenario, and achieving significant improvements in professionalism compared to traditional RAG methods. Meanwhile, to help developers easily build accurate and efficient domain knowledge QA services, our KAG natively supports the open-source KG engine OpenSPG.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Liang, Lei and Bo, Zhongpu and Gui, Zhengke and Zhu, Zhongshu and Zhong, Ling and Zhao, Peilong and Sun, Mengshu and Zhang, Zhiqiang and Zhou, Jun and Chen, Wenguang and Zhang, Wen and Chen, Huajun},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {information retrieval, kbqa, knowledge graph, knowledge reasoning, rag},
	pages = {334--343},
}

@inproceedings{liu_dual_2025,
	address = {New York, NY, USA},
	series = {{WiseML} '25},
	title = {The {Dual} {Role} of {Large} {Language} {Models} in {Network} {Security}: {Survey} and {Research} {Trends}},
	isbn = {979-8-4007-1531-0},
	url = {https://doi.org/10.1145/3733965.3733972},
	doi = {10.1145/3733965.3733972},
	abstract = {Large language models (LLMs) have profoundly shaped various domains, including several types of network systems. With their powerful capabilities, LLMs have recently been proposed to enhance network security. However, the development of LLMs can introduce new risks due to their potential vulnerabilities and misuse. In this paper, we are motivated to review the dual role of LLMs in network security. Our goal is to explore how LLMs impact network security and ultimately shed light on how to evaluate LLMs from a network security perspective. We further discuss several future research directions regarding how to scientifically enable LLMs to assist with network security.},
	booktitle = {Proceedings of the 2025 {ACM} {Workshop} on {Wireless} {Security} and {Machine} {Learning}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Haiyun and Xue, Jiahao and Zhao, Shangqing and Liu, Yao and Lu, Zhuo},
	year = {2025},
	note = {event-place: USA},
	keywords = {adversarial attacks, large language model (llm), network security},
	pages = {20--25},
}

@inproceedings{li_accurate_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Accurate {Insights}, {Trustworthy} {Interactions}: {Designing} a {Collaborative} {AI}-{Human} {Multi}-{Agent} {System} with {Knowledge} {Graph} for {Diagnosis} {Prediction}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713526},
	doi = {10.1145/3706598.3713526},
	abstract = {Healthcare question-answering (QA) systems can assist physicians in making medical decisions. However, traditional medical QA systems struggle with multi-agents interaction and domain-specific knowledge processing, thereby reducing the accuracy and credibility of clinical decision-making. We thus develop a multi-agent decision-making system by combining a fine-tuned medical model, biomedical knowledge graphs, and PubMed data. By summarizing the symptoms described by users, our system can automatically convene clinical experts from various fields, retrieve domain knowledge, and provide clinical decision support for users. We have validated the system performance using both technical and user-centric approaches in terms of information accuracy, user satisfaction, user trust, ect. We thus provide an effective tool for healthcare professionals to make accurate and timely decisions. Furthermore, this study also reveals new design and research opportunities, including (1) optimizing multi-agent collaboration mechanisms for more complex medical decision-making, (2) improving interaction design to enhance system transparency and explainability, and (3) expanding the system to support a broader range of medical issues and multimodal data.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Li, Haoran and Cheng, Xusen and Zhang, Xiaoping},
	year = {2025},
	keywords = {Clinical Decision Support Systems, Graph-based Retrieval-Augmented Generation (Graph RAG), Human-Computer Interaction, Large Medical Language Models, Multi-Agent Systems},
}

@inproceedings{wei_garag_2024,
	address = {New York, NY, USA},
	series = {{ICCBD} '24},
	title = {{GARAG}: {A} {General} adaptive question-answering system based on {RAG}},
	isbn = {979-8-4007-1022-3},
	url = {https://doi.org/10.1145/3695080.3695156},
	doi = {10.1145/3695080.3695156},
	abstract = {Large language models (LLMs) possess exceptional capabilities, but their effectiveness is limited by their knowledge base. Retrieval-Augmented Generation (RAG) techniques integrate external knowledge to enhance performance in question-answering tasks. However, RAG techniques may encounter difficulties in dealing with irrelevant content, complex queries, as well as accurately evaluating the importance and relevance of information. To address these challenges, we developed an optimization question-answering system General Adaptive RAG (GARAG), specifically tailored for question-and-answer tasks. Our system utilizes a retrieval agent to identify relevant content and a generation agent to construct answers based on the question and retrieved information. Additionally, we incorporated modules for question complexity measurement, question correction, query transformation, query routing, and adaptive retrieval to improve intent recognition and document retrieval. We implemented an answer corrector and discriminator, as well as a self-reflection mechanism, to enhance output quality and factuality. Empirical experiments conducted on real-world questions validate the effectiveness of our question-and-answer system.},
	booktitle = {Proceedings of the 2024 {International} {Conference} on {Cloud} {Computing} and {Big} {Data}},
	publisher = {Association for Computing Machinery},
	author = {Wei, Zizhong and Huang, Dengrong and Zhang, Jichen and Song, Chen and Zhang, Sijia and Zhang, Jianing and Li, Zhaochuan and Jiang, Kai and Li, Rui and Duan, Qiang},
	year = {2024},
	note = {event-place: Dali, China},
	pages = {442--447},
}

@inproceedings{zheng_evaluating_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Evaluating {Non}-{AI} {Experts}' {Interaction} with {AI}: {A} {Case} {Study} {In} {Library} {Context}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3714219},
	doi = {10.1145/3706598.3714219},
	abstract = {Public libraries in the U.S. are increasingly facing labor shortages, tight budgets, and overworked staff, creating a pressing need for conversational agents to assist patrons. The democratization of generative AI has empowered public service professionals to develop AI agents by leveraging large language models. To understand the needs of non-AI library professionals in creating their own conversational agents, we conducted semi-structured interviews with library professionals (n=11) across the U.S. Insights from these interviews informed the design of AgentBuilder, a prototype tool that enables non-AI experts to create conversational agents without coding skills. We then conducted think-aloud sessions and follow-up interviews to evaluate the prototype experience and identify the key evaluation criteria emphasized by library professionals (n=12) when developing conversational agents. Our findings highlight how these professionals perceive the prototype experience and reveal five essential evaluation criteria: interpreting user intent, faithful paraphrasing, proper alignment with authoritative sources, tailoring the tone of voice, and handling unknown answers effectively. These insights provide valuable guidance for designing AI-supported "end-user creation tools" in public service domains beyond libraries.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zheng, Qingxiao and Chen, Minrui and Park, Hyanghee and Xu, Zhongwei and Huang, Yun},
	year = {2025},
	keywords = {End-User AI Creation Tool, Generative AI, Large language models, Public Service, User Experience},
}

@inproceedings{liu_teaching_2024,
	address = {New York, NY, USA},
	series = {{SIGCSE} 2024},
	title = {Teaching {CS50} with {AI}: {Leveraging} {Generative} {Artificial} {Intelligence} in {Computer} {Science} {Education}},
	isbn = {979-8-4007-0423-9},
	url = {https://doi.org/10.1145/3626252.3630938},
	doi = {10.1145/3626252.3630938},
	abstract = {In Summer 2023, we developed and integrated a suite of AI-based software tools into CS50 at Harvard University. These tools were initially available to approximately 70 summer students, then to thousands of students online, and finally to several hundred on campus during Fall 2023. Per the course's own policy, we encouraged students to use these course-specific tools and limited the use of commercial AI software such as ChatGPT, GitHub Copilot, and the new Bing. Our goal was to approximate a 1:1 teacher-to-student ratio through software, thereby equipping students with a pedagogically-minded subject-matter expert by their side at all times, designed to guide students toward solutions rather than offer them outright. The tools were received positively by students, who noted that they felt like they had "a personal tutor.” Our findings suggest that integrating AI thoughtfully into educational settings enhances the learning experience by providing continuous, customized support and enabling human educators to address more complex pedagogical issues. In this paper, we detail how AI tools have augmented teaching and learning in CS50, specifically in explaining code snippets, improving code style, and accurately responding to curricular and administrative queries on the course's discussion forum. Additionally, we present our methodological approach, implementation details, and guidance for those considering using these tools or AI generally in education.},
	booktitle = {Proceedings of the 55th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education} {V}. 1},
	publisher = {Association for Computing Machinery},
	author = {Liu, Rongxin and Zenke, Carter and Liu, Charlie and Holmes, Andrew and Thornton, Patrick and Malan, David J.},
	year = {2024},
	note = {event-place: Portland, OR, USA},
	keywords = {ai, artificial intelligence, generative ai, large language models, llms},
	pages = {750--756},
}

@inproceedings{ju_toward_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Toward {Affective} {Empathy} via {Personalized} {Analogy} {Generation}: {A} {Case} {Study} on {Microaggression}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3714122},
	doi = {10.1145/3706598.3714122},
	abstract = {The importance of empathy cannot be overstated in modern societies where people of diverse backgrounds increasingly interact together. The HCI community has strived to foster affective empathy through immersive technologies. Many previous techniques are built upon a premise that presenting the same experience as-is may help evoke the same emotion, which however faces limitations in matters where the emotional responses largely differ across individuals. In this paper, we present a novel concept of generating a personalized experience based on a large language model (LLM) to facilitate affective empathy between individuals despite their differences. As a case study to showcase its effectiveness, we developed EmoSync, an LLM-based agent that generates personalized analogical microaggression situations, facilitating users to personally resonate with a specific microaggression situation of another person. EmoSync is designed and evaluated along a 3-phased user study with 100+ participants. We comprehensively discuss implications, limitations, and possible applications.Disclaimer: Readers may find content of a discriminative or stereotypical nature, which is inevitable given this work’s theme.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ju, Hyojin and Lee, Jungeun and Yang, Seungwon and Ok, Jungseul and Hwang, Inseok},
	year = {2025},
	keywords = {Empathy, Large Language Model, Microaggression, Personalized Analogy Generation},
}

@inproceedings{zheng_revolutionizing_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {Revolutionizing {Database} {Q}\&amp;{A} with {Large} {Language} {Models}: {Comprehensive} {Benchmark} and {Evaluation}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737405},
	doi = {10.1145/3711896.3737405},
	abstract = {The development of Large Language Models (LLMs) has revolutionized QA across various industries, including the database domain. However, there lacks a thorough evaluation regarding the capabilities of different LLMs in database QA. To this end, we introduce DQABench, the first comprehensive database QA benchmark for LLMs. DQABench features an innovative LLM-based method to automate the generation, cleaning, and rewriting of evaluation dataset, resulting in over 200,000 QA pairs in English and Chinese. These QA pairs cover a wide range of database-specific knowledge extracted from manuals, online communities, and DB instances, allowing for assessment of LLMs' Retrieval-Augmented Generation (RAG) and Tool Invocation Generation (TIG) capabilities in the database QA task. Furthermore, we propose a highly modular and scalable testbed DQATestbed, with basic and advanced components such as Fine-tuning, Question Classification Routing (QCR), RAG, TIG, and Prompt Template Engineering (PTE). Finally, we provide an evaluation pipeline that computes various metrics throughout a standardized evaluation process to ensure the accuracy and fairness. Our evaluation reveals the strengths and limitations of nine open-source and commercial LLMs, and the impact of various service components (e.g., fine-tuning, QCR, RAG, TIG). The proposed benchmark dataset is available at https://github.com/XMUDM/DQABench.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Zheng, Yihang and Li, Bo and Lin, Zhenghao and Luo, Yi and Zhou, Xuanhe and Lin, Chen and Li, Guoliang and Su, Jinsong},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {ai4db, benchmark, database qa, llm},
	pages = {5960--5971},
}

@inproceedings{sun_multimodal_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {A {Multimodal} {Intelligent} {Change} {Assessment} {Framework} for {Microservice} {Systems} {Based} on {Large} {Language} {Models}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3728561},
	doi = {10.1145/3696630.3728561},
	abstract = {Frequent changes in large-scale online service systems often lead to failures, threatening system reliability. To overcome the limitations of existing techniques in erroneous change detection, failure triage, and root cause change analysis, this paper presents a multimodal intelligent change assessment framework based on large language models. Our framework integrates retrieval-augmented generation techniques and leverages unified representation of multimodal data, enhanced knowledge access, and domain-specific LLMs to automate the entire change management lifecycle. Experiments on two microservice system datasets show that our method outperforms state-of-the-arts in accuracy, efficiency, and minimizing manual intervention. Furthermore, SCELM has been operational for over 11 months in real world, reducing response and resolution times for erroneous changes by 90\%, significantly improving incident handling efficiency. This work provides a robust solution for change management and valuable insights into improving system stability and optimizing operational workflows.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Sun, Yongqian and Zheng, Tinghua and Wen, Xidao and Kuang, Weihua and Liu, Heng and Zhang, Shenglin and Shen, Chao and Wu, Bo and Pei, Dan},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {anomaly detection, failure triage, LLMs, RAG, root cause analysis, software change},
	pages = {378--388},
}

@inproceedings{wang_diagnosing_2025,
	address = {New York, NY, USA},
	series = {{EuroMLSys} '25},
	title = {Diagnosing and {Resolving} {Cloud} {Platform} {Instability} with {Multi}-modal {RAG} {LLMs}},
	isbn = {979-8-4007-1538-9},
	url = {https://doi.org/10.1145/3721146.3721958},
	doi = {10.1145/3721146.3721958},
	abstract = {Today's cloud-hosted applications and services are complex systems, and a performance or functional instability can have dozens or hundreds of potential root causes. Our hypothesis is that by combining the pattern matching capabilities of modern AI tools with a natural multi-modal RAG LLM interface, problem identification and resolution can be simplified. ARCA is a new multi-modal RAG LLM system that targets this domain. Step-wise evaluations show that ARCA outperforms state-of-the-art alternatives.},
	booktitle = {Proceedings of the 5th {Workshop} on {Machine} {Learning} and {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Yifan and Birman, Kenneth P.},
	year = {2025},
	note = {event-place: World Trade Center, Rotterdam, Netherlands},
	keywords = {AI-Ops, RAG LLM, root cause analysis},
	pages = {139--147},
}

@inproceedings{deldjoo_toward_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Toward {Holistic} {Evaluation} of {Recommender} {Systems} {Powered} by {Generative} {Models}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730354},
	doi = {10.1145/3726302.3730354},
	abstract = {Recommender systems powered by generative models (Gen-RecSys) extend beyond classical item-ranking by producing open-ended content, which simultaneously unlocks richer user experiences and introduces new risks. On one hand, these systems can enhance personalization and appeal through dynamic explanations and multi-turn dialogues. On the other hand, they might venture into unknown territory-hallucinating nonexistent items, amplifying bias, or leaking private information. Traditional accuracy metrics cannot fully capture these challenges, as they fail to measure factual correctness, content safety, or alignment with user intent.This paper makes two main contributions. First, we categorize the evaluation challenges of Gen-RecSys into two groups: (i) existing concerns that are exacerbated by generative outputs (e.g., bias, privacy) and (ii) entirely new risks (e.g., item hallucinations, contradictory explanations). Second, we propose a holistic evaluation approach that includes scenario-based assessments and multi-metric checks-incorporating relevance, factual grounding, bias detection, and policy compliance. Our goal is to provide a guiding framework so that researchers and practitioners can thoroughly assess Gen-RecSys, ensuring both effective personalization and responsible deployment.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Deldjoo, Yashar and Mehta, Nikhil and Sathiamoorthy, Maheswaran and Zhang, Shuai and Castells, Pablo and McAuley, Julian},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {bias amplification, factuality, fairness, generative recommender systems, hallucination, holistic evaluation framework, llm},
	pages = {3932--3942},
}

@inproceedings{huang_generating_2024,
	address = {New York, NY, USA},
	series = {{In2Writing} '24},
	title = {Generating {Educational} {Materials} with {Different} {Levels} of {Readability} using {LLMs}},
	isbn = {979-8-4007-1031-5},
	url = {https://doi.org/10.1145/3690712.3690718},
	doi = {10.1145/3690712.3690718},
	abstract = {This study introduces the leveled-text generation task, aiming to rewrite educational materials to specific readability levels while preserving meaning. We assess the capability of GPT-3.5, LLaMA-2 70B, and Mixtral 8x7B, to generate content at various readability levels through zero-shot and few-shot prompting. Evaluating 100 processed educational materials reveals that few-shot prompting significantly improves performance in readability manipulation and information preservation. LLaMA-2 70B performs better in achieving the desired difficulty range, while GPT-3.5 maintains original meaning. However, manual inspection highlights concerns such as misinformation introduction and inconsistent edit distribution. These findings emphasize the need for further research to ensure the quality of generated educational content.},
	booktitle = {Proceedings of the {Third} {Workshop} on {Intelligent} and {Interactive} {Writing} {Assistants}},
	publisher = {Association for Computing Machinery},
	author = {Huang, Chieh-Yang and Wei, Jing and Huang, Ting-Hao Kenneth},
	year = {2024},
	note = {event-place: Honolulu, HI, USA},
	keywords = {Educational Material Generation, Large Language Model, Text Generation, Text Readability},
	pages = {16--22},
}

@inproceedings{engelmann_reanimator_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{REANIMATOR}: {Reanimate} {Retrieval} {Test} {Collections} with {Extracted} and {Synthetic} {Resources}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730342},
	doi = {10.1145/3726302.3730342},
	abstract = {Retrieval test collections are essential for evaluating information retrieval systems, yet they often lack generalizability across tasks. To overcome this limitation, we introduce REANIMATOR, a versatile framework designed to enable the repurposing of existing test collections by enriching them with extracted and synthetic resources. REANIMATOR enhances test collections from PDF files by parsing full texts and machine-readable tables, as well as related contextual information. It then employs state-of-the-art large language models to produce synthetic relevance labels. Including an optional human-in-the-loop step can help validate the resources that have been extracted and generated. We demonstrate its potential with a revitalized version of the TREC-COVID test collection, showcasing the development of a retrieval-augmented generation system and evaluating the impact of tables on retrieval-augmented generation. REANIMATOR enables the reuse of test collections for new applications, lowering costs and broadening the utility of legacy resources.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Engelmann, Björn and Haak, Fabian and Schaer, Philipp and Erfanian Abdoust, Mani and Netze, Linus and Bittkowski, Meik},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {information retrieval, large language models, rag, scientific literature, table information extraction, table retrieval, test collection},
	pages = {3691--3701},
}

@inproceedings{yan_challenges_2025,
	address = {New York, NY, USA},
	series = {{LMPL} '25},
	title = {Challenges in {C}++ to {Rust} {Translation} with {Large} {Language} {Models}: {A} {Preliminary} {Empirical} {Study}},
	isbn = {979-8-4007-2148-9},
	url = {https://doi.org/10.1145/3759425.3763380},
	doi = {10.1145/3759425.3763380},
	abstract = {C++ programming language is one of the mainstream choices for developing various systems due to its efficiency and widespread application, particularly in fields with high-performance requirements. However, C++ programs may have many memory management and security issues, such as dangling pointers and memory leaks, which pose increasing challenges in modern software development. As a modern programming language designed to address memory safety issues, Rust has gained widespread attention for its ownership system and memory safety features, driving research and practice in migrating C++ code to Rust. However, the differences in syntax and features between C++ and Rust, as well as C++'s complex and object-oriented features, make it extremely difficult to directly convert C++ code into Rust code. With the development of large language models (LLMs), significant progress has been made in code translation and understanding. This paper aims to investigate the use of LLMs to convert C++ code into Rust code by decomposing the C++ code into independent features, such as classes, templates, and functions etc., and extracting the dependent global symbol definitions through program analysis. We selected GPT-4-turbo and Deepseek-v3 for experimentation, analyzed their performance of translation results, and investigated the root causes made by GPT-4-turbo and Deepseek-v3. By manually classifying errors, we identified the root causes of translation issues and provided findings and suggestions for future research on translating C++ code into Rust code.},
	booktitle = {Proceedings of the 1st {ACM} {SIGPLAN} {International} {Workshop} on {Language} {Models} and {Programming} {Languages}},
	publisher = {Association for Computing Machinery},
	author = {Yan, Yanyan and Feng, Yang and He, Qi and Zeng, Jun and Xu, Baowen},
	year = {2025},
	note = {event-place: Singapore, Singapore},
	keywords = {Large Language Model, Program Analysis, Program Generation, Program Translation},
	pages = {21--26},
}

@inproceedings{poudel_scalable_2025,
	address = {New York, NY, USA},
	series = {{PEARC} '25},
	title = {A {Scalable} {Framework} for {Heterogeneous} {Environmental} {Data} {Management} {Using} {Smart} {Data} {Pipeline}},
	isbn = {979-8-4007-1398-9},
	url = {https://doi.org/10.1145/3708035.3736017},
	doi = {10.1145/3708035.3736017},
	abstract = {Environmental data originates from diverse sources, posing challenges in management, processing, and visualization. This paper introduces a scalable, AI-driven data pipeline framework for environmental data management and discovery. The framework integrates workflow orchestration, automated data ingestion and processing, federated storage, and seamless geospatial visualization. It employs a Ceph-based storage system to handle large, heterogeneous datasets, leveraging its fault-tolerant, distributed architecture for high-performance storage across object, block, and file interfaces. To enhance data discoverability and interoperability, the framework incorporates Generative AI (GenAI) for automated metadata generation, reducing manual annotation overhead while improving real-time processing and cross-platform integration. Additionally, the system enables interdisciplinary collaboration through standardized metadata structures and scalable data federation. A case study using buoy data validates the framework’s capabilities, including data processing, cleaning, and visualization. By addressing critical data integration and accessibility challenges, the system fosters a scalable, efficient, and intelligent research data-sharing ecosystem for environmental science studies.},
	booktitle = {Practice and {Experience} in {Advanced} {Research} {Computing} 2025: {The} {Power} of {Collaboration}},
	publisher = {Association for Computing Machinery},
	author = {Poudel, Pratik and Guan, Boyuan and Sanchez, Nicole and Bahreini, Kiavash and Cui, Wencong and Lopez, Andres and Najafi, Hamed and Fu, Zhaohui and Bobadilla, Leonardo and Liu, Jason},
	year = {2025},
	keywords = {Ceph-based Storage System, Environmental Data Management, Generative AI (GenAI), Geospatial Visualization, Smart Data Pipeline},
}

@inproceedings{dou_construction_2025,
	address = {New York, NY, USA},
	series = {{CIBDA} '25},
	title = {Construction and {Innovative} {Application} of {Intelligent} {Agents} in {College} {EFL} {Teaching}},
	isbn = {979-8-4007-1316-3},
	url = {https://doi.org/10.1145/3746709.3746933},
	doi = {10.1145/3746709.3746933},
	abstract = {Artificial intelligence has brought unlimited possibilities to education. Based on the Deepseek large language model and the Dify agent platform, this paper uses RAG, TTS, NLP and other technologies to build multiple different types of college EFL teaching agents. While greatly reducing the teaching workload of teachers, it can also establish a one-to-one personal learning assistant for learners to help them learn flexibly and efficiently. Teaching practice shows that the college EFL teaching agent can better adapt to the teaching methods of the intelligent era. It is an innovative exploration of the digital transformation of college EFL course in higher educational institutions.},
	booktitle = {Proceedings of the 2025 6th {International} {Conference} on {Computer} {Information} and {Big} {Data} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Dou, Juhua and Zheng, Bo},
	year = {2025},
	keywords = {AI Agent, College EFL Teaching, Dify platform, Large Language Model},
	pages = {1324--1329},
}

@inproceedings{salemi_optimization_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Optimization {Methods} for {Personalizing} {Large} {Language} {Models} through {Retrieval} {Augmentation}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657783},
	doi = {10.1145/3626772.3657783},
	abstract = {This paper studies retrieval-augmented approaches for personalizing large language models (LLMs), which potentially have a substantial impact on various applications and domains. We propose the first attempt to optimize the retrieval models that deliver a limited number of personal documents to large language models for the purpose of personalized generation. We develop two optimization algorithms that solicit feedback from the downstream personalized generation tasks for retrieval optimization–one based on reinforcement learning whose reward function is defined using any arbitrary metric for personalized generation and another based on knowledge distillation from the downstream LLM to the retrieval model. This paper also introduces a pre- and post-generation retriever selection model that decides what retriever to choose for each LLM input. Extensive experiments on diverse tasks from the language model personalization (LaMP) benchmark reveal statistically significant improvements in six out of seven datasets.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Salemi, Alireza and Kallumadi, Surya and Zamani, Hamed},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {personalization, ranking optimization, retrieval-augmented generation, text generation},
	pages = {752--762},
}

@inproceedings{qian_tackling_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {Tackling the {Length} {Barrier}: {Dynamic} {Context} {Browsing} for {Knowledge}-{Intensive} {Task}},
	isbn = {979-8-4007-1245-6},
	url = {https://doi.org/10.1145/3690624.3709240},
	doi = {10.1145/3690624.3709240},
	abstract = {Knowledge-intensive tasks often require complex reasoning and contextual understanding over long contexts. However, the learning and deployment of long-LLMs remains a challenging problem despite recent progresses. In this work, we propose that the short LLMs have great potentiality for solving knowledge-intensive tasks that have long context, i.e. they can be solved by purely working with oracle short-contexts within the input long-context. On top of this argument, we propose a framework called DCISO DynamiC knowledge-Intensive task S\&gt;Olver), which enables a short-LLM to address the knowledge-intensive tasks with long context via dynamic context browsing. In our framework, the short-LLM prompts itself to reason for two critical decisions: 1) how to access to the appropriate part of context within the input, 2) how to make effective use of the accessed context. By adaptively accessing and utilizing the context based on the presented tasks, DCISO can serve as a general framework to handle diversified knowledge-intensive long-context problems. We comprehensively evaluate different types of tasks from popular long-context benchmarks, where DCISO is able to achieve a substantially improved performance. Our codes will be released at this repository.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.1},
	publisher = {Association for Computing Machinery},
	author = {Qian, Hongjin and Liu, Zheng and Zhang, Peitian and Mao, Kelong and Zhou, Yujia and Chen, Xu and Dou, Zhicheng},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {context length, knowledge-intensive task, large language model},
	pages = {1150--1160},
}

@inproceedings{alvarado_garcia_emerging_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Emerging {Data} {Practices}: {Data} {Work} in the {Era} of {Large} {Language} {Models}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3714069},
	doi = {10.1145/3706598.3714069},
	abstract = {Data is one of the foundational aspects of making Artificial Intelligence (AI) work as intended. As large language models (LLMs) become the epicenter of AI, it is crucial to understand better how the datasets that maintain such models are created. The emergent nature of LLMs makes it critical to understand the challenges practitioners developing Gen AI technologies face to design alternatives for better responding to Gen AI’s ethical issues. In this paper, we provide such understanding by reporting on 25 interviews with practitioners who handle data in three distinct development stages of different LLMs. Our contributions are (1) empirical evidence of how uncertainty, data practices, and reliance mechanisms change across LLMs’ development cycle; (2) how the unique qualities of LLMs impact data practices and their implications for the future of Gen AI technologies; and (3) provide three opportunities for HCI researchers interested in supporting practitioners developing Gen AI technologies.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Alvarado Garcia, Adriana and Candello, Heloisa and Badillo-Urquiola, Karla and Wong-Villacres, Marisol},
	year = {2025},
	keywords = {AI, AI practitioners, data governance, data practices, data work, GenAI, generative AI, LLMs, synthetic data},
}

@inproceedings{liu_detecting_2025,
	address = {New York, NY, USA},
	series = {{SIGCSETS} 2025},
	title = {Detecting {AI}-{Generated} {Pseudocode} in {High} {School} {Online} {Programming} {Courses} {Using} an {Explainable} {Approach}},
	isbn = {979-8-4007-0531-1},
	url = {https://doi.org/10.1145/3641554.3701942},
	doi = {10.1145/3641554.3701942},
	abstract = {Despite extensive research on code plagiarism detection in higher education and for programming languages like Java and Python, limited work has focused on K-12 settings, particularly for pseudocode. This study aims to address this gap by building explainable machine learning models for pseudocode plagiarism detection in online programming education. To achieve this, we construct a comprehensive dataset comprising 7,838 pseudocode submissions from 2,578 high school students enrolled in an online programming foundations course, along with 6,300 pseudocode samples generated by three versions of generative pre-trained transformer (GPT) models. Utilizing this dataset, we develop an explainable model to detect AI-generated pseudocode across various assessments. The model not only identifies AI-generated content but also provides insights into its predictions at both the student and problem levels, thus enhancing our understanding of AI-generated pseudocode in K-12 education. Furthermore, we analyzed SHAP values and key features of the model to pinpoint student submissions that closely resemble AI-generated pseudocode. This research offers implications for developing robust educational technologies and methodologies to uphold academic integrity in online programming courses.},
	booktitle = {Proceedings of the 56th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education} {V}. 1},
	publisher = {Association for Computing Machinery},
	author = {Liu, Zifeng and Jiao, Xinyue and Xing, Wanli and Zhu, Wangda},
	year = {2025},
	note = {event-place: Pittsburgh, PA, USA},
	keywords = {ai-generated content, explainable ai, gpt model, online programming education, plagiarism detection, pseudocode},
	pages = {701--707},
}

@inproceedings{pasquini_neural_2024,
	address = {New York, NY, USA},
	series = {{AISec} '24},
	title = {Neural {Exec}: {Learning} (and {Learning} from) {Execution} {Triggers} for {Prompt} {Injection} {Attacks}},
	isbn = {979-8-4007-1228-9},
	url = {https://doi.org/10.1145/3689932.3694764},
	doi = {10.1145/3689932.3694764},
	abstract = {We introduce a new family of prompt injection attacks, termed Neural Exec. Unlike known attacks that rely on handcrafted strings (e.g., "Ignore previous instructions and..."), we show that it is possible to conceptualize the creation of execution triggers as a differentiable search problem and use learning-based methods to autonomously generate them.Our results demonstrate that a motivated adversary can forge triggers that are not only drastically more effective than current handcrafted ones but also exhibit inherent flexibility in shape, properties, and functionality. In this direction, we show that an attacker can design and generate Neural Execs capable of persisting through multi-stage preprocessing pipelines, such as in the case of Retrieval-Augmented Generation (RAG)-based applications. More critically, our findings show that attackers can produce triggers that deviate markedly in form and shape from any known attack, sidestepping existing blacklist-based detection and sanitation approaches. Code available at https://github.com/pasquini-dario/LLM\_NeuralExec},
	booktitle = {Proceedings of the 2024 {Workshop} on {Artificial} {Intelligence} and {Security}},
	publisher = {Association for Computing Machinery},
	author = {Pasquini, Dario and Strohmeier, Martin and Troncoso, Carmela},
	year = {2024},
	note = {event-place: Salt Lake City, UT, USA},
	keywords = {adversarial inputs, ai readteam, llms, prompt injection, rag},
	pages = {89--100},
}

@inproceedings{albrecht-crane_thinking_2025,
	address = {New York, NY, USA},
	series = {{SIGDOC} '25},
	title = {Thinking {Smarter}, not {Harder}? {Google} {NotebookLM}'s {Misalignment} {Problem} in {Education}},
	isbn = {979-8-4007-1444-3},
	url = {https://doi.org/10.1145/3711670.3764628},
	doi = {10.1145/3711670.3764628},
	abstract = {This paper examines Google's NotebookLM as a case study of how consumer-facing generative AI technologies misalign with educational values and user needs. While marketed as an "AI-powered research assistant," NotebookLM exemplifies the disconnect between AI industry promises and actual capabilities. Through technical analysis of large language model mechanisms, this paper reveals how NotebookLM's statistical compression methods fundamentally differ from human cognitive processes of reading and analysis. The paper argues that despite claims of source-grounding, NotebookLM produces outputs that compress rather than comprehend texts, often missing crucial arguments and generating confabulated content. Drawing on examinations of "smart" technology rhetoric and extreme usability design, the analysis demonstrates how the tool's frictionless interface obscures computational limitations while potentially undermining cognitive development. The paper concludes by advocating for critical AI literacy in writing studies and technical communication, proposing pedagogical approaches that demystify AI hype and preserve the essential friction necessary for meaningful learning.},
	booktitle = {Proceedings of the 43rd {ACM} {International} {Conference} on {Design} of {Communication}},
	publisher = {Association for Computing Machinery},
	author = {Albrecht-Crane, Christa},
	year = {2025},
	keywords = {AI chatbot interface, AI summarization, cognitive offloading, critical AI literacy, education, extreme usability, large-language models, misalignment, NotebookLM, technical communication, usability},
	pages = {121--127},
}

@inproceedings{zha_mentigo_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Mentigo: {An} {Intelligent} {Agent} for {Mentoring} {Students} in the {Creative} {Problem} {Solving} {Process}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713952},
	doi = {10.1145/3706598.3713952},
	abstract = {Creative Problem-Solving (CPS) promotes creative and critical thinking while enhancing real-world problem-solving skills, making it essential for middle school education. However, providing personalized mentorship in CPS projects at scale is challenging due to resource constraints and diverse student needs. To address this, we developed Mentigo, an AI-driven mentor agent designed to guide middle school students through the CPS process. Using a dataset of real classroom interactions, we encoded CPS task stages, adaptive guidance strategies, and personalized feedback mechanisms to inform Mentigo‘s dynamic mentoring framework powered by large language models (LLMs). A comparative experiment with 12 students and evaluations from five expert educators demonstrated improved student engagement, creativity, and task performance. Our findings highlight design implications for using LLM-based AI mentors to enhance CPS learning in educational environments.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zha, Siyu and Liu, Yujia and Zheng, Chengbo and Xu, Jiaqi and Yu, Fuze and Gong, Jiangtao and Xu, Yingqing},
	year = {2025},
	keywords = {Agent, creative problem solving, Generative AI, mentor},
}

@inproceedings{yang_evaluation_2024,
	address = {New York, NY, USA},
	series = {{ASE} '24},
	title = {On the {Evaluation} of {Large} {Language} {Models} in {Unit} {Test} {Generation}},
	isbn = {979-8-4007-1248-7},
	url = {https://doi.org/10.1145/3691620.3695529},
	doi = {10.1145/3691620.3695529},
	abstract = {Unit testing is an essential activity in software development for verifying the correctness of software components. However, manually writing unit tests is challenging and time-consuming. The emergence of Large Language Models (LLMs) offers a new direction for automating unit test generation. Existing research primarily focuses on closed-source LLMs (e.g., ChatGPT and CodeX) with fixed prompting strategies, leaving the capabilities of advanced open-source LLMs with various prompting settings unexplored. Particularly, open-source LLMs offer advantages in data privacy protection and have demonstrated superior performance in some tasks. Moreover, effective prompting is crucial for maximizing LLMs' capabilities. In this paper, we conduct the first empirical study to fill this gap, based on 17 Java projects, five widely-used open-source LLMs with different structures and parameter sizes, and comprehensive evaluation metrics. Our findings highlight the significant influence of various prompt factors, show the performance of open-source LLMs compared to the commercial GPT-4 and the traditional Evosuite, and identify limitations in LLM-based unit test generation. We then derive a series of implications from our study to guide future research and practical use of LLM-based unit test generation.},
	booktitle = {Proceedings of the 39th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Yang, Lin and Yang, Chen and Gao, Shutao and Wang, Weijing and Wang, Bo and Zhu, Qihao and Chu, Xiao and Zhou, Jianyi and Liang, Guangtai and Wang, Qianxiang and Chen, Junjie},
	year = {2024},
	note = {event-place: Sacramento, CA, USA},
	keywords = {empirical study, large language model, unit test generation},
	pages = {1607--1619},
}

@inproceedings{ma_towards_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Towards {Human}-{AI} {Deliberation}: {Design} and {Evaluation} of {LLM}-{Empowered} {Deliberative} {AI} for {AI}-{Assisted} {Decision}-{Making}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713423},
	doi = {10.1145/3706598.3713423},
	abstract = {Traditional AI-assisted decision-making systems often provide fixed recommendations that users must either accept or reject entirely, limiting meaningful interaction—especially in cases of disagreement. To address this, we introduce Human-AI Deliberation, an approach inspired by human deliberation theories that enables dimension-level opinion elicitation, iterative decision updates, and structured discussions between humans and AI. At the core of this approach is Deliberative AI, an assistant powered by large language models (LLMs) that facilitates flexible, conversational interactions and precise information exchange with domain-specific models. Through a mixed-methods user study, we found that Deliberative AI outperforms traditional explainable AI (XAI) systems by fostering appropriate human reliance and improving task performance. By analyzing participant perceptions, user experience, and open-ended feedback, we highlight key findings, discuss potential concerns, and explore the broader applicability of this approach for future AI-assisted decision-making systems.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ma, Shuai and Chen, Qiaoyi and Wang, Xinru and Zheng, Chengbo and Peng, Zhenhui and Yin, Ming and Ma, Xiaojuan},
	year = {2025},
	keywords = {AI-Assisted Decision-making, Appropriate Reliance, Deliberation, Human-AI Collaboration, Large Language Models},
}

@inproceedings{peng_tilse_2024,
	address = {New York, NY, USA},
	series = {{ISAIE} '24},
	title = {“{TILSE}” {Framework} for {RAG}-{Based} {AIGC} {Feedback} {Prompts}: {A} {Modular} and {Personalized} {Intelligent} {Feedback} {Generation} {Method}},
	isbn = {979-8-4007-0710-0},
	url = {https://doi.org/10.1145/3700297.3700365},
	doi = {10.1145/3700297.3700365},
	abstract = {This paper introduces the TILSE grading prompt framework, integrating RAG (Retrieval-Augmented Generation) technology to address the challenge of generating accurate and personalized feedback in educational settings. The TILSE framework's modular design, comprising Task, Input, Logic, Style, and Example modules, allows for flexible and contextually relevant prompt generation. By dynamically retrieving pertinent knowledge, RAG technology enhances the precision and adaptability of feedback, making it more tailored to individual student needs. Experiments with ChatGPT 4.0 demonstrate that the TILSE framework significantly outperforms traditional methods, particularly in complex educational scenarios, by providing more accurate and personalized feedback. This research offers a novel solution to the limitations of existing feedback systems and contributes to the advancement of AI-driven educational tools.},
	booktitle = {Proceedings of the 2024 {International} {Symposium} on {Artificial} {Intelligence} for {Education}},
	publisher = {Association for Computing Machinery},
	author = {Peng, Beibei and Wang, Xindi and Xu, Lei},
	year = {2024},
	keywords = {Personalized Feedback, Prompt Generation, RAG Technology, TILSE Framework},
	pages = {398--403},
}

@inproceedings{joho_instruction-response_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {An {Instruction}-{Response} {Perspective} on {Large} {Language} {Models} in {Information} {Retrieval} {Tasks}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730346},
	doi = {10.1145/3726302.3730346},
	abstract = {The increasing use of retrieval-augmented applications, where large language models (LLMs) are instructed to generate queries, assess relevance, and synthesise responses, has introduced new challenges in Information Retrieval (IR). The lack of transparency in LLMs means that even subtle variations in instructions can significantly impact the quality, consistency, and reliability of their responses. To address this issue, we propose Instruction-Response Study, an experimental framework for systematically analysing how task instructions influence LLM-generated responses in IR tasks. This paper presents the core components of the framework and demonstrates its utility through four case studies, examining 1) the effect of IR tasks on query formulation, 2) the impact of topic information size on retrieval effectiveness, 3) the reproducibility of LLM-generated queries, and 4) the role of meta-instructions in diversifying instruction design. The findings highlight how the proposed framework enables controlled experimentation on instruction design and its effects, offering a foundation for optimising prompt engineering and enhancing retrieval-augmented applications.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Joho, Hideo and Jose, Joemon M},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {explainable ai, information retrieval tasks, instruction-response study, large language models},
	pages = {3843--3852},
}

@inproceedings{sharifymoghaddam_rankllm_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{RankLLM}: {A} {Python} {Package} for {Reranking} with {LLMs}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730331},
	doi = {10.1145/3726302.3730331},
	abstract = {The adoption of large language models (LLMs) as rerankers in multi-stage retrieval systems has gained significant traction in academia and industry. These models refine a candidate list of retrieved documents, often through carefully designed prompts, and are typically used in applications built on retrieval-augmented generation (RAG). This paper introduces RankLLM, an open-source Python package for reranking that is modular, highly configurable, and supports both proprietary and open-source LLMs in customized reranking workflows. To improve usability, RankLLM features optional integration with Pyserini for retrieval and provides integrated evaluation for multi-stage pipelines. Additionally, RankLLM includes a module for detailed analysis of input prompts and LLM responses, addressing reliability concerns with LLM APIs and non-deterministic behavior in Mixture-of-Experts (MoE) models. This paper presents the architecture of RankLLM, along with a detailed step-by-step guide and sample code. We reproduce results from RankGPT, LRL, RankVicuna, RankZephyr, and other recent models. RankLLM integrates with common inference frameworks and a wide range of LLMs. This compatibility allows for quick reproduction of reported results, helping to speed up both research and real-world applications. The complete repository is available at rankllm.ai, and the package can be installed via PyPI.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Sharifymoghaddam, Sahel and Pradeep, Ronak and Slavescu, Andre and Nguyen, Ryan and Xu, Andrew and Chen, Zijian and Zhang, Yilin and Chen, Yidi and Xian, Jasper and Lin, Jimmy},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {information retrieval, large language models, python, reranking},
	pages = {3681--3690},
}

@inproceedings{liu_gram_2024,
	address = {New York, NY, USA},
	series = {{KDD} '24},
	title = {{GRAM}: {Generative} {Retrieval} {Augmented} {Matching} of {Data} {Schemas} in the {Context} of {Data} {Security}},
	isbn = {979-8-4007-0490-1},
	url = {https://doi.org/10.1145/3637528.3671602},
	doi = {10.1145/3637528.3671602},
	abstract = {Schema matching constitutes a pivotal phase in the data ingestion process for contemporary database systems. Its objective is to discern pairwise similarities between two sets of attributes, each associated with a distinct data table. This challenge emerges at the initial stages of data analytics, such as when incorporating a third-party table into existing databases to inform business insights. Given its significance in the realm of database systems, schema matching has been under investigation since the 2000s. This study revisits this foundational problem within the context of large language models. Adhering to increasingly stringent data security policies, our focus lies on the zero-shot and few-shot scenarios: the model should analyze only a minimal amount of customer data to execute the matching task, contrasting with the conventional approach of scrutinizing the entire data table. We emphasize that the zero-shot or few-shot assumption is imperative to safeguard the identity and privacy of customer data, even at the potential cost of accuracy. The capability to accurately match attributes under such stringent requirements distinguishes our work from previous literature in this domain.},
	booktitle = {Proceedings of the 30th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Xuanqing and Wang, Runhui and Song, Yang and Kong, Luyang},
	year = {2024},
	note = {event-place: Barcelona, Spain},
	keywords = {generative modeling, retrieval augmented generation, schema matching},
	pages = {5476--5486},
}

@inproceedings{wang_jupybara_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Jupybara: {Operationalizing} a {Design} {Space} for {Actionable} {Data} {Analysis} and {Storytelling} with {LLMs}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713913},
	doi = {10.1145/3706598.3713913},
	abstract = {Mining and conveying actionable insights from complex data is a key challenge of exploratory data analysis (EDA) and storytelling. To address this challenge, we present a design space for actionable EDA and storytelling. Synthesizing theory and expert interviews, we highlight how semantic precision, rhetorical persuasion, and pragmatic relevance underpin effective EDA and storytelling. We also show how this design space subsumes common challenges in actionable EDA and storytelling, such as identifying appropriate analytical strategies and leveraging relevant domain knowledge. Building on the potential of LLMs to generate coherent narratives with commonsense reasoning, we contribute Jupybara, an AI-enabled assistant for actionable EDA and storytelling implemented as a Jupyter Notebook extension. Jupybara employs two strategies—design-space-aware prompting and multi-agent architectures—to operationalize our design space. An expert evaluation confirms Jupybara’s usability, steerability, explainability, and reparability, as well as the effectiveness of our strategies in operationalizing the design space framework with LLMs.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Huichen Will and Birnbaum, Larry and Setlur, Vidya},
	year = {2025},
	keywords = {Actionable Insights, Data Science, Data Storytelling, Exploratory Data Analysis, Human-AI Collaboration, Large Language Model, Multi-Agent System, Pragmatics., Rhetoric, Semantics},
}

@inproceedings{wen_6g-xsec_2024,
	address = {New York, NY, USA},
	series = {{HotNets} '24},
	title = {{6G}-{XSec}: {Explainable} {Edge} {Security} for {Emerging} {OpenRAN} {Architectures}},
	isbn = {979-8-4007-1272-2},
	url = {https://doi.org/10.1145/3696348.3696881},
	doi = {10.1145/3696348.3696881},
	abstract = {The evolution from 5G to 6G cellular networks signifies a crucial advancement towards enhanced robustness and automation driven by the promise of ubiquitous Artificial Intelligence (AI) to overhaul network operations, commonly referred to as AIOps. However, 6G network operators also need to deal with evolving threats at the edge to ensure data integrity and availability. We introduce 6G-XSEC, the first framework that seeks to automatically monitor, analyze, and explain anomalies and threats at the cellular network edge. Our framework enhances the emerging Open Radio Access Network (O-RAN) control plane with run-time analytic capabilities and explainability. A distinguishing aspect of our framework is the use of expert referencing, a coupling of lightweight unsupervised deep learning-based anomaly detection with large language models (LLMs) to first detect, analyze, and subsequently explain complicated real-world cellular threats and anomalies at run-time, based on enhanced security telemetry from the O-RAN data plane. We build a prototype 6G-XSEC framework and evaluate it against 5 end-to-end cellular attacks from the literature, achieving 100\% detection rate with our best model. We also propose effective LLM prompt templates for attack analysis and present qualitative results from 5 popular LLMs.},
	booktitle = {Proceedings of the 23rd {ACM} {Workshop} on {Hot} {Topics} in {Networks}},
	publisher = {Association for Computing Machinery},
	author = {Wen, Haohuang and Sharma, Prakhar and Yegneswaran, Vinod and Porras, Phillip and Gehani, Ashish and Lin, Zhiqiang},
	year = {2024},
	note = {event-place: Irvine, CA, USA},
	keywords = {6G, Anomaly Detection, Large Language Model, OpenRAN},
	pages = {77--85},
}

@inproceedings{chen_open_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Open {Local} {Knowledge} {Graph} {Construction} from {Academic} {Papers} {Using} {Generative} {Large} {Language} {Models}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3717820},
	doi = {10.1145/3701716.3717820},
	abstract = {This manuscript introduces paper2lkg, a novel Local Knowledge Graph Construction (KGC) pipeline designed to transform individual academic papers into their structured local Knowledge Graph (KG) representations. The pipeline harnesses Large Language Models (LLMs), particularly generative LLMs, to automate key Natural Language Processing (NLP) tasks in KGC. The constructed local KGs can potentially be used to enrich an existing academic KG that lacks detailed local representations of individual papers or further integrated into new academic KGs through Knowledge Graph Alignment (KGA).},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Chen, Haoting and Rodríguez Méndez, Sergio José and Omran, Pouya Ghiasnezhad},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {knowledge graph construction, large language model, natural language processing},
	pages = {2551--2559},
}

@inproceedings{prakash_integrating_2024,
	address = {New York, NY, USA},
	series = {{DataEd} '24},
	title = {Integrating {LLMs} into {Database} {Systems} {Education}},
	isbn = {979-8-4007-0678-3},
	url = {https://doi.org/10.1145/3663649.3664371},
	doi = {10.1145/3663649.3664371},
	abstract = {Large Language Models (LLMs) have sparked a drastic improvement in the ways computers can understand, process, and generate language. As LLM-based offerings become mainstream, we explore the incorporation of such LLMs into introductory or undergraduate database systems education. Students and instructors are both faced with the calculator dilemma: while the use of LLM-based tools may “solve” tasks such as assignments and exams, do they impede or accelerate the learning itself? We review deficiencies of using existing off-the-shelf tools for learning, and further articulate the differentiated needs of database systems students as opposed to trained data practitioners. Building on our exploration, we outline a vision that integrates LLMs into database education in a principled manner, keeping pedagogical best practices in mind. If implemented correctly, we posit that LLMs can drastically amplify the impact of existing instruction, minimizing costs and barriers towards learning database systems fundamentals.},
	booktitle = {Proceedings of the 3rd {International} {Workshop} on {Data} {Systems} {Education}: {Bridging} {Education} {Practice} with {Education} {Research}},
	publisher = {Association for Computing Machinery},
	author = {Prakash, Kishore and Rao, Shashwat and Hamza, Rayan and Lukich, Jack and Chaudhari, Vatsal and Nandi, Arnab},
	year = {2024},
	note = {event-place: Santiago, AA, Chile},
	keywords = {ChatGPT, database systems education, foundation models, intro to db, large language models, llm, undergrad databases},
	pages = {33--39},
}

@inproceedings{lin_fraudulent_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {A {Fraudulent} {Blind} {Shipment} {Detection} {Framework} in {Logistics}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737184},
	doi = {10.1145/3711896.3737184},
	abstract = {An emerging type of fraud involves malicious senders exploiting the blind shipment and cash-on-delivery (COD) mechanisms by dispatching large volumes of unsolicited, low-cost parcels. If unsuspecting receivers accept these parcels, they pay for both shipping and goods; otherwise, logistics providers bear the round-trip shipping costs. Existing detection techniques, which rely on extensive labeled cases, struggle with this emerging fraud because receivers' unawareness and low transaction values discourage complaints, resulting in few confirmed cases. Therefore, we propose leveraging receivers' complaints, though not initially collected for fraud detection, to uncover subtle indicators of fraud patterns, while addressing three challenges: (C1) noise-rich dialogues(C2) data privacy concerns, and (C3) ever-evolving fraud patterns. To address them, we design BLOFF, a Blind shipment detection Framework for LO gistics Fraud powered by large language models (LLMs). Specifically, BLOFF includes three components: i) Sensitivity Anonymization to protect sensitive user information; ii) Dialogue Profile Distillation to transform informal dialogues into structured representation, addressing C1, and distill knowledge from a teacher LLM (GPT-4o) to a lightweight student LLM (ChatGLM4-9B), addressing C2; ii) Multi-faceted Context Augmentation to enhance the interpretation of fraud signatures and adaptation of evolving patterns, addressing C3. We evaluate BLOFF on about 56,000 complaints records collected from JD Logistics between January and November 2024. Results show that BLOFF outperforms state-of-the-art methods, achieving a 10.19\% improvement in precision. Furthermore, during its real-world deployment in December 2024, BLOFF identified over 90 fraudulent parcels with a 91.4\% precision.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Lin, Hongyu and Zhong, Shuxin and Fang, Yan and Hong, Zhiqing and Lyu, Wenjun and Xie, Qipeng and Wang, Haotian and Wang, Lu and Wu, Kaishun},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {blind shipment detection, large language model, multi-modal data aggregation},
	pages = {4590--4598},
}

@inproceedings{shi_you_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {You {Are} {What} {You} {Bought}: {Generating} {Customer} {Personas} for {E}-commerce {Applications}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730118},
	doi = {10.1145/3726302.3730118},
	abstract = {In e-commerce, user representations are essential for various applications. Existing methods often use deep learning techniques to convert customer behaviors into implicit embeddings. However, these embeddings are difficult to understand and integrate with external knowledge, limiting the effectiveness of applications such as customer segmentation, search navigation, and product recommendations. To address this, our paper introduces the concept of the customer persona. Condensed from a customer's numerous purchasing histories, a customer persona provides a multi-faceted and human-readable characterization of specific purchase behaviors and preferences, such as Busy Parents or Bargain Hunters.This work then focuses on representing each customer by multiple personas from a predefined set, achieving readable and informative explicit user representations. To this end, we propose an effective and efficient solution GPLR. To ensure effectiveness, GPLR leverages pre-trained LLMs and few-shot learning to infer personas for customers. To reduce overhead, GPLR applies LLM-based labeling to only a fraction of users and utilizes a random walk technique to predict personas for the remaining customers. To further enhance efficiency, we propose an approximate solution called RevAff for this random walk-based computation. RevAff provides an absolute error ε guarantee while improving the time complexity of the exact solution by a factor of at least O( ε ⋅{\textbar}E{\textbar}N over {\textbar}E{\textbar} + N log N ), where N represents the number of customers and products, and E represents the interactions between them. We evaluate the performance of our persona-based representation in terms of accuracy and robustness for recommendation and customer segmentation tasks using three real-world e-commerce datasets. Most notably, we find that integrating customer persona representations improves the state-of-the-art graph convolution-based recommendation model by up to 12\% in terms of NDCG@K and F1-Score@K.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Shi, Yimin and Fei, Yang and Zhang, Shiqi and Wang, Haixun and Xiao, Xiaokui},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {large language model, persona, random walk, recommendation},
	pages = {1810--1819},
}

@inproceedings{mei-seung_navigating_2024,
	address = {New York, NY, USA},
	series = {{ICSLT} '24},
	title = {Navigating the “{Cooked}” {Data}: {A} {Framework} for {Understanding} {GenAI}'s {Impact} on {Academic} {Writing} and {Learning}},
	isbn = {979-8-4007-1679-9},
	url = {https://doi.org/10.1145/3678610.3678630},
	doi = {10.1145/3678610.3678630},
	abstract = {This article explores the integration of Generative AI (GenAI) technologies, such as ChatGPT, Bard, and LaMDA, in academic writing classrooms, examining both their potential to transform learning and the challenges they present. Building on Activity Theory, the study assesses the transformation of students' roles, the writing assistant tool, and the rules and division of labor within the academic community after technology integration. We argue that GenAI, while offering powerful potential for personalized feedback and learning, disrupts traditional educational dynamics. This raises critical questions about student roles, data integrity, and the evolving responsibilities of teachers. We propose eleven research questions to guide future investigations. These questions emphasize the need for a nuanced understanding of how GenAI impacts the learning experience and its implications for academic integrity. We also highlight the ethical considerations surrounding its use. This work aims to contribute to the ongoing conversation surrounding AI in education, promoting a more comprehensive understanding of the opportunities and challenges presented by this transformative technology.},
	booktitle = {Proceedings of the 2024 10th {International} {Conference} on {E}-{Society}, e-{Learning} and e-{Technologies} ({ICSLT})},
	publisher = {Association for Computing Machinery},
	author = {Mei-seung, Cheng},
	year = {2024},
	keywords = {Academic Integrity, Activity Theory, Generative AI in education, Technology in higher education},
	pages = {76--81},
}

@inproceedings{ma_ambigchat_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {{AmbigChat}: {Interactive} {Hierarchical} {Clarification} for {Ambiguous} {Open}-{Domain} {Question} {Answering}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747686},
	doi = {10.1145/3746059.3747686},
	abstract = {When conversing with large language models, it is common for users to ask an ambiguous open-domain question that could lead to multiple answers, especially when exploring new topics. For example, “Who won the US Open?” can result in different athletes according to the referenced events and years. We propose AmbigChat, an automatic approach that hierarchically disambiguates a factual question and guides users to navigate answers via UI widgets in a multi-turn conversational interface. Using the ambiguity taxonomy we generated from an analysis of 5,000 queries, AmbigChat identifies ambiguous facets of a question and constructs a disambiguation tree, where each level corresponds to a facet. Users can traverse the tree to explore answers via interactive disambiguation widgets and expand the conversation by referencing tree nodes through drag and drop. We iterated our interaction design with six design professionals and tested the effectiveness of the disambiguation tree generation algorithm on a variety of factual queries. Our evaluation with 16 participants shows that AmbigChat not only helps the participants find answers more easily and efficiently, but also facilitates structured explorations of the topic space.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Ma, Jiaju and Shi, Lei and Robertsen, Kenneth Aleksander and Chi, Peggy},
	year = {2025},
	keywords = {conversational interfaces, factual question answering, Language ambiguity, large language model},
}

@inproceedings{liu_enhancing_2025,
	address = {New York, NY, USA},
	series = {{ICADI} '24},
	title = {Enhancing {Automotive} {PDF} {Chatbots}: {A} {Graph} {RAG} {Approach} with {Custom} {Function} {Calling} for {Locally} {Deployed} {Ollama} {Models}},
	isbn = {979-8-4007-1284-5},
	url = {https://doi.org/10.1145/3726010.3726012},
	doi = {10.1145/3726010.3726012},
	abstract = {This research explores state-of-the-art retrieval augmented generation (RAG) methodologies utilizing a locally hosted Ollama model to address the rising demand for streamlined offline PDF chatbots in the automotive industry. In this paper we present a Langchain-based optimization of the a forementioned framework for modeling all input text from automotive documents. For example, using JoinChpy which use specialized finetuning to a base model where it is fine-tuned adding specialized modifications, the first on PDF and retrieval algorithms as well as context compression strictly for automotive literature We define embedding pipeline classes and graph RAG agents.To instantiate our methodology, we developed our own automotive industry document dataset and compared the enhanced graph RAG and self-RAG agents with the original RAG baseline on our automotive dataset as well as QuAC and CANARD. The results demonstrate a consistent increase along the dimensions, in correctness, swiftness, relevance, and fidelity, specifically for automotive domain specific content. Hence offering a guideline on how to implement a local RAG in automotive setting, thus serving as a significant contribution to the research in an industrial context to process information and make a step towards smart manufacturing.},
	booktitle = {Proceedings of the 2024 {International} {Conference} on {Artificial} {Intelligence}, {Digital} {Media} {Technology} and {Interaction} {Design}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Fei and Ren, Huanhuan and Guan, Yu and Li, Na},
	year = {2025},
	keywords = {Automotive Industry, Graph RAG, Langchain, Ollama, PDF Processing},
	pages = {6--13},
}

@inproceedings{weber_perses_2025,
	address = {New York, NY, USA},
	series = {{ASIA} {CCS} '25},
	title = {Perses: {Unlocking} {Privilege} {Escalation} for {Small} {LLMs} via {Extensible} {Heterogeneity}},
	isbn = {979-8-4007-1410-8},
	url = {https://doi.org/10.1145/3708821.3736189},
	doi = {10.1145/3708821.3736189},
	abstract = {Misconfiguration poses a ubiquitous security vulnerability for even modern hardened systems. Recent advances in Large Language Model (LLM)-based penetration testing have proven its efficacy in vulnerability detection. Prior research has predominantly focused on large, non-local models, evaluating them exclusively on Linux and Windows systems. We developed Perses, an extensible multi-LLM framework based on heterogeneity in model selection and task decomposition, designed to enable small local models to autonomously detect and exploit misconfiguration vulnerabilities. Perses is evaluated on a FreeBSD port of an existing privilege escalation benchmark, analyzing the effects of heterogeneity, the viability of automatic LLM assignment, the criticality of introduced LLM-roles, and the detriment incurred through evaluation on a system the models have little inherent knowledge on. Experimental results reveal that Perses, in its default configuration, enables Small Models to consistently exploit 87.5\% of the evaluated vulnerabilities, significantly improving upon the 12.5\% reported in prior work. We further find that SMAC-based automatic configuration is feasible, each role is essential for Perses’ performance, and that the models contain sufficient knowledge on FreeBSD. These results showcase the power of Small Models in privilege escalation, presenting a viable alternative to Large Models.},
	booktitle = {Proceedings of the 20th {ACM} {Asia} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {Association for Computing Machinery},
	author = {Weber, Dominik M. and Tzachristas, Ioannis and Sui, Aifen},
	year = {2025},
	keywords = {Automatic Algorithm Configuration, Cybersecurity Automation, LLMs, Penetration Testing, Vulnerability Detection},
	pages = {344--357},
}

@inproceedings{ehl_supporting_2025,
	address = {New York, NY, USA},
	series = {{SAC} '25},
	title = {Supporting {Software} {Engineers} in {IT} {Security} and {Privacy} through {Automated} {Knowledge} {Discovery}},
	isbn = {979-8-4007-0629-5},
	url = {https://doi.org/10.1145/3672608.3707798},
	doi = {10.1145/3672608.3707798},
	abstract = {Security and privacy are increasingly essential concepts in software engineering. New threats and corresponding countermeasures are continuously discovered. Concurrently, projects are becoming more complex and are exposed to a greater number of threats. This presents a significant challenge for software engineers. As a result, security and privacy are often neglected due to a lack of knowledge, limited time, and financial constraints. While systematic literature reviews exist to address the increasing volume of publications, software engineers still require up-to-date knowledge of current threats and measures. This paper presents an automated, time-efficient, and cost-effective method for discovering knowledge from state-of-the-art literature and project artifacts, such as design documents. The presented method utilizes Large Language Models (LLMs) for data extraction and is demonstrated through a prototypical implementation and evaluation. This evaluation involves security and privacy in open-access scientific publications and project documentation from European Union research and development projects. The extracted knowledge is used to populate a quality model that is specifically designed to provide software engineers with information that helps them apply the findings. This quality model offers software engineers valuable, up-to-date insights into security and privacy, bridging the gap between scientific research and practical applications.},
	booktitle = {Proceedings of the 40th {ACM}/{SIGAPP} {Symposium} on {Applied} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Ehl, Marco and Ahmadian, Amir Shayan and Großer, Katharina and Elsofi, Duaa Adel Ali and Herrmann, Marc and Specht, Alexander and Schneider, Kurt and Jürjens, Jan},
	year = {2025},
	note = {event-place: Catania International Airport, Catania, Italy},
	keywords = {knowledge discovery, large language model, privacy, quality model, security},
	pages = {1647--1656},
}

@inproceedings{tu_r-eval_2024,
	address = {New York, NY, USA},
	series = {{KDD} '24},
	title = {R-{Eval}: {A} {Unified} {Toolkit} for {Evaluating} {Domain} {Knowledge} of {Retrieval} {Augmented} {Large} {Language} {Models}},
	isbn = {979-8-4007-0490-1},
	url = {https://doi.org/10.1145/3637528.3671564},
	doi = {10.1145/3637528.3671564},
	abstract = {Large language models have achieved remarkable success on general NLP tasks, but they may fall short for domain-specific problems. Recently, various Retrieval-Augmented Large Language Models (RALLMs) are proposed to address this shortcoming. However, existing evaluation tools only provide a few baselines and evaluate them on various domains without mining the depth of domain knowledge. In this paper, we address the challenges of evaluating RALLMs by introducing the R-Eval toolkit, a Python toolkit designed to streamline the evaluation of different RAG workflows in conjunction with LLMs. Our toolkit, which supports popular built-in RAG workflows and allows for the incorporation of customized testing data on the specific domain, is designed to be user-friendly, modular, and extensible. We conduct an evaluation of 21 RALLMs across three task levels and two representative domains, revealing significant variations in the effectiveness of RALLMs across different tasks and domains. Our analysis emphasizes the importance of considering both task and domain requirements when choosing a RAG workflow and LLM combination. We are committed to continuously maintaining our platform at https://github.com/THU-KEG/R-Eval to facilitate both the industry and the researchers.},
	booktitle = {Proceedings of the 30th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Tu, Shangqing and Wang, Yuanchun and Yu, Jifan and Xie, Yuyang and Shi, Yaran and Wang, Xiaozhi and Zhang, Jing and Hou, Lei and Li, Juanzi},
	year = {2024},
	note = {event-place: Barcelona, Spain},
	keywords = {domain knowledge, evaluation, large language model},
	pages = {5813--5824},
}

@inproceedings{mi_empower_2025,
	address = {New York, NY, USA},
	series = {{EuroSys} '25},
	title = {Empower {Vision} {Applications} with {LoRA} {LMM}},
	isbn = {979-8-4007-1196-1},
	url = {https://doi.org/10.1145/3689031.3717472},
	doi = {10.1145/3689031.3717472},
	abstract = {Large Multimodal Models (LMMs) have shown significant progress in various complex vision tasks with the solid linguistic and reasoning capacity inherited from large language models (LMMs). Low-rank adaptation (LoRA) offers a promising method to integrate external knowledge into LMMs, compensating for their limitations on domain-specific tasks. However, the existing LoRA model serving is excessively computationally expensive and causes extremely high latency. In this paper, we present an end-to-end solution that empowers diverse vision tasks and enriches vision applications with LoRA LMMs. Our system, VaLoRA, enables accurate and efficient vision tasks by 1) an accuracy-aware LoRA adapter generation approach that generates LoRA adapters rich in domain-specific knowledge to meet application-specific accuracy requirements, 2) an adaptive-tiling LoRA adapters batching operator that efficiently computes concurrent heterogeneous LoRA adapters, and 3) a flexible LoRA adapter orchestration mechanism that manages application requests and LoRA adapters to achieve the lowest average response latency. We prototype VaLoRA on five popular vision tasks on three LMMs. Experiment results reveal that VaLoRA improves 24-62\% of the accuracy compared to the original LMMs and reduces 20-89\% of the latency compared to the state-of-the-art LoRA model serving systems.},
	booktitle = {Proceedings of the {Twentieth} {European} {Conference} on {Computer} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Mi, Liang and Wang, Weijun and Tu, Wenming and He, Qingfeng and Kong, Rui and Fang, Xinyu and Dong, Yazhu and Zhang, Yikang and Li, Yuanchun and Li, Meng and Dai, Haipeng and Chen, Guihai and Liu, Yunxin},
	year = {2025},
	note = {event-place: Rotterdam, Netherlands},
	keywords = {Large language model, Machine learning system},
	pages = {261--277},
}

@inproceedings{lo_noel_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Noel: {A} {Chatbot} {Persona} to {Support} {Children} {Designing} for {Others}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713836},
	doi = {10.1145/3706598.3713836},
	abstract = {Designing for others encourages children to empathize with and consider different perspectives and needs. A chatbot persona could allow children to design for stakeholder groups that are challenging to involve directly in educational activities, such as people with disabilities. In this paper, we explore how an artificial intelligence chatbot persona leveraging the GPT-4 large language model can support children’s design empathy while designing for others. We report the design, development process, and implementation of a chatbot persona representing a 12-year-old child with low vision named Noel. The exploratory case study consisted of three 90- to 120-minute workshop sessions with nineteen students (ages 11 to 13) in a grade 6/7 classroom. Results illustrate ways that Noel supported students throughout the design process, their expressions of design empathy, and their experiences. We present implications for developers and educators along with future directions for research.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Lo, Priscilla Y. and Veldhuis, Annemiek and Antle, Alissa N. and DiPaola, Steve},
	year = {2025},
	keywords = {artificial intelligence, chatbot, children, design thinking, education, empathy, large language model, persona, visual impairment},
}

@inproceedings{ding_diagram_2025,
	address = {New York, NY, USA},
	series = {C\&amp;{C} '25},
	title = {"{The} {Diagram} is like {Guardrails}": {Structuring} {GenAI}-assisted {Hypotheses} {Exploration} with an {Interactive} {Shared} {Representation}},
	isbn = {979-8-4007-1289-0},
	url = {https://doi.org/10.1145/3698061.3726935},
	doi = {10.1145/3698061.3726935},
	abstract = {Data analysis encompasses a spectrum of tasks, from high-level conceptual reasoning to lower-level execution. While AI-powered tools increasingly support execution tasks, there remains a need for intelligent assistance in conceptual tasks. This paper investigates the design of interactive tree diagrams as effective shared representations for AI-assisted hypothesis exploration. We developed a system with ordered node-link diagram augmented with AI-generated information hints and visualizations. Through a design probe (n=22), participants generated diagrams averaging 21.82 hypotheses. Our findings showed that the node-link diagram acts as “guardrails" for hypothesis exploration, facilitating structured workflows, providing overviews, and enabling backtracking. The AI-generated information hints, particularly visualizations, aided users in transforming abstract ideas into data-backed concepts while reducing cognitive load. We further discuss how node-link diagrams can support both parallel exploration and iterative refinement in hypothesis formulation, potentially enhancing the breadth and depth of human-AI collaborative data analysis.},
	booktitle = {Proceedings of the 2025 {Conference} on {Creativity} and {Cognition}},
	publisher = {Association for Computing Machinery},
	author = {Ding, Zijian and Brachman, Michelle and Chan, Joel and Geyer, Werner},
	year = {2025},
	keywords = {Generative AI, Hypothesis Exploration, Node-link Diagram, Shared Representation},
	pages = {606--625},
}

@inproceedings{zhang_human-imperceptible_2024,
	address = {New York, NY, USA},
	series = {{FSE} 2024},
	title = {Human-{Imperceptible} {Retrieval} {Poisoning} {Attacks} in {LLM}-{Powered} {Applications}},
	isbn = {979-8-4007-0658-5},
	url = {https://doi.org/10.1145/3663529.3663786},
	doi = {10.1145/3663529.3663786},
	abstract = {Presently, with the assistance of advanced LLM application development frameworks, more and more LLM-powered applications can effortlessly augment the LLMs' knowledge with external content using the retrieval augmented generation (RAG) technique. However, these frameworks' designs do not have sufficient consideration of the risk of external content, thereby allowing attackers to undermine the applications developed with these frameworks. In this paper, we reveal a new threat to LLM-powered applications, termed retrieval poisoning, where attackers can guide the application to yield malicious responses during the RAG process. Specifically, through the analysis of LLM application frameworks, attackers can craft documents visually indistinguishable from benign ones. Despite the documents providing correct information, once they are used as reference sources for RAG, the application is misled into generating incorrect responses. Our preliminary experiments indicate that attackers can mislead LLMs with an 88.33\% success rate, and achieve a 66.67\% success rate in the real-world application, demonstrating the potential impact of retrieval poisoning.},
	booktitle = {Companion {Proceedings} of the 32nd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Quan and Zeng, Binqi and Zhou, Chijin and Go, Gwihwan and Shi, Heyuan and Jiang, Yu},
	year = {2024},
	note = {event-place: Porto de Galinhas, Brazil},
	keywords = {Large Language Models, Retrieval Poisoning Attack},
	pages = {502--506},
}

@inproceedings{loukas_making_2023,
	address = {New York, NY, USA},
	series = {{ICAIF} '23},
	title = {Making {LLMs} {Worth} {Every} {Penny}: {Resource}-{Limited} {Text} {Classification} in {Banking}},
	isbn = {979-8-4007-0240-2},
	url = {https://doi.org/10.1145/3604237.3626891},
	doi = {10.1145/3604237.3626891},
	abstract = {Standard Full-Data classifiers in NLP demand thousands of labeled examples, which is impractical in data-limited domains. Few-shot methods offer an alternative, utilizing contrastive learning techniques that can be effective with as little as 20 examples per class. Similarly, Large Language Models (LLMs) like GPT-4 can perform effectively with just 1-5 examples per class. However, the performance-cost trade-offs of these methods remain underexplored, a critical concern for budget-limited organizations. Our work addresses this gap by studying the aforementioned approaches over the Banking77 financial intent detection dataset, including the evaluation of cutting-edge LLMs by OpenAI, Cohere, and Anthropic in a comprehensive set of few-shot scenarios. We complete the picture with two additional methods: first, a cost-effective querying method for LLMs based on retrieval-augmented generation (RAG), able to reduce operational costs multiple times compared to classic few-shot approaches, and second, a data augmentation method using GPT-4, able to improve performance in data-limited scenarios. Finally, to inspire future research, we provide a human expert’s curated subset of Banking77, along with extensive error analysis.},
	booktitle = {Proceedings of the {Fourth} {ACM} {International} {Conference} on {AI} in {Finance}},
	publisher = {Association for Computing Machinery},
	author = {Loukas, Lefteris and Stogiannidis, Ilias and Diamantopoulos, Odysseas and Malakasiotis, Prodromos and Vassos, Stavros},
	year = {2023},
	note = {event-place: Brooklyn, NY, USA},
	keywords = {Anthropic, Claude, Cohere, Few-shot, GPT, LLMs, NLP, OpenAI},
	pages = {392--400},
}

@inproceedings{huang_accessibility_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {Accessibility {Scout}: {Personalized} {Accessibility} {Scans} of {Built} {Environments}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747624},
	doi = {10.1145/3746059.3747624},
	abstract = {Assessing the accessibility of unfamiliar built environments is critical for people with disabilities. However, manual assessments, performed by users or their personal health professionals, are laborious and unscalable, while automatic machine learning methods often neglect an individual user’s unique needs. Recent advances in Large Language Models (LLMs) enable novel approaches to this problem, balancing personalization with scalability to enable more adaptive and context-aware assessments of accessibility. We present Accessibility Scout, an LLM-based accessibility scanning system that identifies accessibility concerns from photos of built environments. With use, Accessibility Scout becomes an increasingly capable "accessibility scout", tailoring accessibility scans to an individual’s mobility level, preferences, and specific environmental interests through collaborative Human-AI assessments. We present findings from three studies: a formative study with six participants to inform the design of Accessibility Scout, a technical evaluation of 500 images of built environments, and a user study with 10 participants of varying mobility. Results from our technical evaluation and user study show that Accessibility Scout can generate personalized accessibility scans that extend beyond traditional ADA considerations. Finally, we conclude with a discussion on the implications of our work and future steps for building more scalable and personalized accessibility assessments of the physical world.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Huang, William and Su, Xia and Froehlich, Jon E. and Zhang, Yang},
	year = {2025},
	keywords = {Accessibility, Accessibility Assessment, Computer Vision, Large Language Model, Personalization},
}

@inproceedings{xuan_assessing_2024,
	address = {New York, NY, USA},
	series = {{IOTMMIM} '24},
	title = {Assessing the {Potential} of {Large} {Language} {Models} for {Chemical} {Engineering} {Applications}},
	isbn = {979-8-4007-1297-5},
	url = {https://doi.org/10.1145/3698385.3699878},
	doi = {10.1145/3698385.3699878},
	abstract = {This study investigates the emerging potential of large language models in chemical engineering by evaluating GPT-4's performance on questions from general chemistry, physical chemistry, and reactor and process design. GPT-4 correctly answered 45\% of the problems without error, with overall accuracy increasing to 62\% when partially correct answers were included. These results highlight both the capabilities and limitations of LLMs in this field. We discuss the challenges and future prospects of integrating LLMs into chemical engineering, aiming to provide insights and direction for future interdisciplinary research. Additionally, a problem set is provided for further exploration.},
	booktitle = {Proceedings of the {First} {International} {Workshop} on {IoT} {Datasets} for {Multi}-{Modal} {Large} {Model}},
	publisher = {Association for Computing Machinery},
	author = {Xuan, Li and Haoxiang, Zhang and Baozheng, Jiang and You, Li},
	year = {2024},
	note = {event-place: Hangzhou, China},
	keywords = {artificial intelligence, chemical engineering, large language model, process design},
	pages = {57--82},
}

@inproceedings{aruleba_scoping_2025,
	address = {New York, NY, USA},
	series = {{UKICER} '25},
	title = {A {Scoping} {Review} of {Student} and {Educator} {Engagement} with {Large} {Language} {Models} in {Introductory} {Programming} {Education}},
	isbn = {979-8-4007-2078-9},
	url = {https://doi.org/10.1145/3754508.3754517},
	doi = {10.1145/3754508.3754517},
	abstract = {As Large Language Models (LLMs) like ChatGPT and GitHub Copilot gain traction in computing education, understanding their role in introductory programming (CS1) is essential. This scoping review synthesises 38 empirical studies published between 2022 and 2024, focusing on student and educator engagement with LLMs in CS1 contexts. Following Arksey and O’Malley’s five-stage framework and PRISMA-ScR guidelines, we identify four thematic areas: (1) varied student prompting behaviours, from surface-level code copying to iterative refinement; (2) evolving educator practices, from passive allowance to guided integration; (3) assessment-related tensions, notably the “assistance dilemma”; and (4) ethical concerns around bias, integrity, and access. While LLMs support debugging and code comprehension, their value depends on pedagogical framing and learner agency. Gaps remain in longitudinal research, diverse learner representation, and alignment with curriculum frameworks. We offer practical recommendations for scaffolded GenAI integration, prompt engineering strategies, and ethical classroom use. This review supports the development of CS1 curricula that foster critical AI literacy, inclusive participation, and thoughtful engagement with human–AI collaboration in programming education.},
	booktitle = {Proceedings of the 2025 {Conference} on {UK} and {Ireland} {Computing} {Education} {Research}},
	publisher = {Association for Computing Machinery},
	author = {Aruleba, Kehinde and Oyelere, Solomon Sunday and Obaido, George Rabeshi and Sanusi, Ismaila Temitayo},
	year = {2025},
	keywords = {Generative AI, Introductory Computer Science (CS1), Large Language Models (LLMs), Programming Education, Student Engagement},
}

@inproceedings{paduraru_enhancing_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {Enhancing {Game} {AI} {Behaviors} with {Large} {Language} {Models} and {Agentic} {AI}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3728553},
	doi = {10.1145/3696630.3728553},
	abstract = {Integrating advanced AI behaviors is central to creating immersive and dynamic video game experiences. This paper presents a novel approach to improving AI behaviors in games using Large Language Models (LLMs) and agent-based AI. By orchestrating various interconnected parts, we propose a framework that facilitates the creation of complex behavior trees (BTs) for non-player characters (NPCs). Our method bridges the gap between source code and visual tools in game engines and enables both technical and non-technical stakeholders to effectively contribute to the development process. We also aim to increase the diversity of observable behaviors and testability of games through the same methods. The proposed architecture is designed to be adaptable to different game engines to ensure scalability and flexibility. In a collaboration between industry and academia, we validate our approach and demonstrate its potential to improve game AI development and make it more accessible and efficient. To promote the adoption of the methods, we consider small-sized models that run on typical developer platforms without the need for external solutions or expensive computing resources.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Paduraru, Ciprian and Paduraru, Miruna and Stefanescu, Alin},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {agentic AI, behavior trees, game AI, generative AI, large language models, non-player characters (NPCs)},
	pages = {286--296},
}

@inproceedings{monteiro_imago_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {Imago {Obscura}: {An} {Image} {Privacy} {AI} {Co}-pilot to {Enable} {Identification} and {Mitigation} of {Risks}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747633},
	doi = {10.1145/3746059.3747633},
	abstract = {Users often struggle to navigate the privacy / publicity boundary in sharing images online: they may lack awareness of image privacy risks or the ability to apply effective mitigation strategies. To address this challenge, we introduce and evaluate Imago Obscura, an intent-aware AI-powered image-editing copilot that enables users to identify and mitigate privacy risks in images they intend to share. Driven by design requirements from a formative user study with 7 image-editing experts, Imago Obscura enables users to articulate their image-sharing intent and privacy concerns. The system uses these inputs to surface contextually pertinent privacy risks, and then recommends and facilitates application of a suite of obfuscation techniques found to be effective in prior literature — e.g., inpainting, blurring, and generative content replacement. We evaluated Imago Obscura with 15 end-users in a lab study and found that it improved users’ awareness of image privacy risks and their ability to address them, enabling more informed sharing decisions.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Monteiro, Kyzyl and Wu, Yuchen and Das, Sauvik},
	year = {2025},
	keywords = {generative AI, human-AI teaming, intent-aware tool, usable privacy},
}

@inproceedings{jennings_whats_2024,
	address = {New York, NY, USA},
	series = {{UIST} '24},
	title = {What's the {Game}, then? {Opportunities} and {Challenges} for {Runtime} {Behavior} {Generation}},
	isbn = {979-8-4007-0628-8},
	url = {https://doi.org/10.1145/3654777.3676358},
	doi = {10.1145/3654777.3676358},
	abstract = {Procedural content generation (PCG), the process of algorithmically creating game components instead of manually, has been a common tool of game development for decades. Recent advances in large language models (LLMs) enable the generation of game behaviors based on player input at runtime. Such code generation brings with it the possibility of entirely new gameplay interactions that may be difficult to integrate with typical game development workflows. We explore these implications through GROMIT, a novel LLM-based runtime behavior generation system for Unity. When triggered by a player action, GROMIT generates a relevant behavior which is compiled without developer intervention and incorporated into the game. We create three demonstration scenarios with GROMIT to investigate how such a technology might be used in game development. In a system evaluation we find that our implementation is able to produce behaviors that result in significant downstream impacts to gameplay. We then conduct an interview study with n=13 game developers using GROMIT as a probe to elicit their current opinion on runtime behavior generation tools, and enumerate the specific themes curtailing the wider use of such tools. We find that the main themes of concern are quality considerations, community expectations, and fit with developer workflows, and that several of the subthemes are unique to runtime behavior generation specifically. We outline a future work agenda to address these concerns, including the need for additional guardrail systems for behavior generation.},
	booktitle = {Proceedings of the 37th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Jennings, Nicholas and Wang, Han and Li, Isabel and Smith, James and Hartmann, Bjoern},
	year = {2024},
	note = {event-place: Pittsburgh, PA, USA},
	keywords = {Generative AI, Human-AI interaction, Procedural Content Generation},
}

@inproceedings{sharma_generative_2024,
	address = {New York, NY, USA},
	series = {{CHI} '24},
	title = {Generative {Echo} {Chamber}? {Effect} of {LLM}-{Powered} {Search} {Systems} on {Diverse} {Information} {Seeking}},
	isbn = {979-8-4007-0330-0},
	url = {https://doi.org/10.1145/3613904.3642459},
	doi = {10.1145/3613904.3642459},
	abstract = {Large language models (LLMs) powered conversational search systems have already been used by hundreds of millions of people, and are believed to bring many benefits over conventional search. However, while decades of research and public discourse interrogated the risk of search systems in increasing selective exposure and creating echo chambers—limiting exposure to diverse opinions and leading to opinion polarization, little is known about such a risk of LLM-powered conversational search. We conduct two experiments to investigate: 1) whether and how LLM-powered conversational search increases selective exposure compared to conventional search; 2) whether and how LLMs with opinion biases that either reinforce or challenge the user’s view change the effect. Overall, we found that participants engaged in more biased information querying with LLM-powered conversational search, and an opinionated LLM reinforcing their views exacerbated this bias. These results present critical implications for the development of LLMs and conversational search systems, and the policy governing these technologies.},
	booktitle = {Proceedings of the 2024 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Sharma, Nikhil and Liao, Q. Vera and Xiao, Ziang},
	year = {2024},
	note = {event-place: Honolulu, HI, USA},
	keywords = {Confirmation Bias, Conversational Search, Echo Chamber Effect, Generative AI, Information Diversity, Information Seeking, Large Language Models},
}

@inproceedings{tong_missteps_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {From {Missteps} to {Mastery}: {Enhancing} {Low}-{Resource} {Dense} {Retrieval} through {Adaptive} {Query} {Generation}},
	isbn = {979-8-4007-1245-6},
	url = {https://doi.org/10.1145/3690624.3709225},
	doi = {10.1145/3690624.3709225},
	abstract = {Document retrieval, designed to recall query-relevant documents from expansive collections, is essential for information-seeking tasks, such as web search and open-domain question-answering. Advances in representation learning and pretrained language models (PLMs) have driven a paradigm shift from traditional sparse retrieval methods to more effective dense retrieval approaches, forging enhanced semantic connections between queries and documents and establishing new performance benchmarks. However, reliance on extensive annotated document-query pairs limits their competitiveness in low-resource scenarios. Recent research efforts employing the few-shot capabilities of large language models (LLMs) and prompt engineering for synthetic data generation have emerged as a promising solution. Nonetheless, these approaches are hindered by the generation of lower-quality data within the conventional dense retrieval training process. To this end, in this paper, we introduce iGFT, a framework aimed at enhancing low-resource dense retrieval by integrating a three-phase process — Generation, Filtering, and Tuning — coupled with an iterative optimization strategy. Specifically, we first employ supervised fine-tuning on limited ground truth data, enabling an LLM to function as the generator capable of producing potential queries from given documents. Subsequently, we present a multi-stage filtering module to minimize noise in the generated data while retaining samples poised to significantly improve the dense retrieval model's performance in the follow-up fine-tuning process. Furthermore, we design a novel iterative optimization strategy that dynamically optimizes the query generator for producing more informative queries, thereby enhancing the efficacy of the entire framework. Finally, extensive experiments conducted on a series of publicly available retrieval benchmark datasets have demonstrated the effectiveness of the proposed iGFT.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.1},
	publisher = {Association for Computing Machinery},
	author = {Tong, Zhenyu and Qin, Chuan and Fang, Chuyu and Yao, Kaichun and Chen, Xi and Zhang, Jingshuai and Zhu, Chen and Zhu, Hengshu},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {dense retrieval, large language model, query generation},
	pages = {1373--1384},
}

@inproceedings{wang_lekube_2024,
	address = {New York, NY, USA},
	series = {{SIGIR}-{AP} 2024},
	title = {{LeKUBE}: {A} {Knowledge} {Update} {BEnchmark} for {Legal} {Domain}},
	isbn = {979-8-4007-0724-7},
	url = {https://doi.org/10.1145/3673791.3698407},
	doi = {10.1145/3673791.3698407},
	abstract = {Recent advances in Large Language Models (LLMs) have significantly shaped the applications of AI in multiple fields, including the studies of legal intelligence. Trained on extensive legal texts, including statutes and legal documents, the legal LLMs can capture important legal knowledge/concepts effectively and provide important support for downstream legal applications such as legal consultancy. Yet, the dynamic nature of legal statutes and interpretations also poses new challenges to the use of LLMs in legal applications. Particularly, how to update the legal knowledge of LLMs effectively and efficiently has become an important research problem in practice. Existing benchmarks for evaluating knowledge update methods are mostly designed for the open domain and cannot address the specific challenges of the legal domain, such as the nuanced application of new legal knowledge, the complexity and lengthiness of legal regulations, and the intricate nature of legal reasoning.To address this gap, we introduce the Legal Knowledge Update BEnchmark, i.e. LeKUBE, which evaluates knowledge update methods for legal LLMs across five dimensions. Specifically, we categorize the needs of knowledge updates in the legal domain with the help of legal professionals, and then hire annotators from law schools to create synthetic updates to the Chinese Criminal and Civil Code as well as sets of questions of which the answers would change after the updates. Through a comprehensive evaluation of state-of-the-art knowledge update methods, we reveal a notable gap between existing knowledge update methods and the unique needs of the legal domain, emphasizing the need for further research and development of knowledge update mechanisms tailored for legal LLMs.},
	booktitle = {Proceedings of the 2024 {Annual} {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval} in the {Asia} {Pacific} {Region}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Changyue and Su, Weihang and Hu, Yiran and Ai, Qingyao and Wu, Yueyue and Luo, Cheng and Liu, Yiqun and Zhang, Min and Ma, Shaoping},
	year = {2024},
	note = {event-place: Tokyo, Japan},
	keywords = {domain-specific evaluation, knowledge update, large language model},
	pages = {175--185},
}

@inproceedings{singh_bias-aware_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Bias-{Aware} {Agent}: {Enhancing} {Fairness} in {AI}-{Driven} {Knowledge} {Retrieval}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3716885},
	doi = {10.1145/3701716.3716885},
	abstract = {Advancements in retrieving accessible information have evolved faster in the last few years compared to the decades since the internet's creation. Search engines, like Google, have been the \#1 way to find relevant data. They have always relied on the user's abilities to find the best information in its billions of links and sources at everybody's fingertips. The advent of large language models (LLMs) has completely transformed the field of information retrieval. LLMs excel not only at retrieving relevant knowledge, but also in summarizing it effectively, making information more accessible and consumable for users. On top of it, the rise of AI Agents has introduced another aspect to information retrieval, i.e. dynamic information retrieval which enables the integration of real-time data such as weather forecasts and financial data with the knowledge base to curate context-aware knowledge. However, despite these advancements, agents remain susceptible to issues of bias and fairness deeply rooted in the knowledge base and training of LLMs. This study introduces a novel approach to bias-aware knowledge retrieval by leveraging agentic framework and the innovative use of bias detectors as tools to identify and highlight inherent biases in the retrieved content. By empowering users with transparency and awareness, this approach aims to foster more equitable information systems and promote the development of responsible AI.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Singh, Karanbir and Ngu, William},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {agents, bias, fairness, information retrieval, large language models, retrieval augmented generation},
	pages = {1705--1712},
}

@inproceedings{cima_contextualized_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Contextualized {Counterspeech}: {Strategies} for {Adaptation}, {Personalization}, and {Evaluation}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714507},
	doi = {10.1145/3696410.3714507},
	abstract = {AI-generated counterspeech offers a promising and scalable strategy to curb online toxicity through direct replies that promote civil discourse. However, current counterspeech is one-size-fits-all, lacking adaptation to the moderation context and the users involved. We propose and evaluate multiple strategies for generating tailored counterspeech that is adapted to the moderation context and personalized for the moderated user. We instruct a LLaMA2-13B model to generate counterspeech, experimenting with various configurations based on different contextual information and fine-tuning strategies. We identify the configurations that generate persuasive counterspeech through a combination of quantitative indicators and human evaluations collected via a pre-registered mixed-design crowdsourcing experiment. Results show that contextualized counterspeech can significantly outperform state-of-the-art generic counterspeech in adequacy and persuasiveness, without compromising other characteristics. Our findings also reveal a poor correlation between quantitative indicators and human evaluations, suggesting that these methods assess different aspects and highlighting the need for nuanced evaluation methodologies. The effectiveness of contextualized AI-generated counterspeech and the divergence between human and algorithmic evaluations underscore the importance of increased human-AI collaboration in content moderation.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Cima, Lorenzo and Miaschi, Alessio and Trujillo, Amaury and Avvenuti, Marco and Dell'Orletta, Felice and Cresci, Stefano},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {content moderation, counterspeech, generative ai, online toxicity, personalization},
	pages = {5022--5033},
}

@inproceedings{yu_preliminary_2025,
	address = {New York, NY, USA},
	series = {{ISSTA} {Companion} '25},
	title = {A {Preliminary} {Study} of {Large} {Language} {Models} for {Multilingual} {Vulnerability} {Detection}},
	isbn = {979-8-4007-1474-0},
	url = {https://doi.org/10.1145/3713081.3731746},
	doi = {10.1145/3713081.3731746},
	abstract = {Deep learning-based approaches, particularly those leveraging pre-trained language models (PLMs), have shown promise in automated software vulnerability detection. However, existing methods are predominantly limited to specific programming languages, restricting their applicability in multilingual settings. Recent advancements in large language models (LLMs) offer language-agnostic capabilities and enhanced semantic understanding, presenting a potential solution to this limitation. While existing studies have explored LLMs for vulnerability detection, their detection performance remains unknown for multilingual vulnerabilities. To address this gap, we conducted a preliminary study to evaluate the effectiveness of PLMs and state-of-the-art LLMs across seven popular programming languages. Our findings reveal that the PLM CodeT5P achieves the best performance in multilingual vulnerability detection, particularly in identifying the most critical vulnerabilities. Based on these results, we further discuss the potential of LLMs in advancing real-world multilingual vulnerability detection. This work represents an initial step toward exploring PLMs and LLMs for cross-language vulnerability detection, offering key insights for future research and practical deployment.},
	booktitle = {Proceedings of the 34th {ACM} {SIGSOFT} {International} {Symposium} on {Software} {Testing} and {Analysis}},
	publisher = {Association for Computing Machinery},
	author = {Yu, Junji and Shu, Honglin and Fu, Michael and Wang, Dong and Tantithamthavorn, Chakkrit and Kamei, Yasutaka and Chen, Junjie},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {large language model, multilingual vulnerability, vulnerability detection},
	pages = {161--168},
}

@inproceedings{ma_integrating_2024,
	address = {New York, NY, USA},
	series = {{SIGCSE} {Virtual} 2024},
	title = {Integrating {AI} {Tutors} in a {Programming} {Course}},
	isbn = {979-8-4007-0598-4},
	url = {https://doi.org/10.1145/3649165.3690094},
	doi = {10.1145/3649165.3690094},
	abstract = {RAGMan is an LLM-powered tutoring system that can support a variety of course-specific and homework-specific AI tutors. RAGMan leverages Retrieval Augmented Generation (RAG), as well as strict instructions, to ensure the alignment of the AI tutors' responses. By using RAGMan's AI tutors, students receive assistance with their specific homework assignments without directly obtaining solutions, while also having the ability to ask general programming-related questions. RAGMan was deployed as an optional resource in an introductory programming course with an enrollment of 455 students. It was configured as a set of five homework-specific AI tutors. This paper describes the interactions the students had with the AI tutors, the students' feedback, and a comparative grade analysis. Overall, about half of the students engaged with the AI tutors, and the vast majority of the interactions were legitimate homework questions. When students posed questions within the intended scope, the AI tutors delivered accurate responses 98\% of the time. Among the students who used AI tutors, 78\% reported that the tutors helped their learning. Beyond AI tutors' ability to provide valuable suggestions, students reported appreciating them for fostering a safe learning environment free from judgment.},
	booktitle = {Proceedings of the 2024 on {ACM} {Virtual} {Global} {Computing} {Education} {Conference} {V}. 1},
	publisher = {Association for Computing Machinery},
	author = {Ma, Iris and Krone-Martins, Alberto and Videira Lopes, Cristina},
	year = {2024},
	note = {event-place: Virtual Event, NC, USA},
	keywords = {education, large language models, llms, software engineering},
	pages = {130--136},
}

@inproceedings{ho_enhancing_2025,
	address = {New York, NY, USA},
	series = {{IUI} '25},
	title = {Enhancing {Visitor} {Engagement} in {Interactive} {Art} {Exhibitions} with {Visual}-{Enhanced} {Conversational} {Agents}},
	isbn = {979-8-4007-1306-4},
	url = {https://doi.org/10.1145/3708359.3712145},
	doi = {10.1145/3708359.3712145},
	abstract = {Conversational agents in art exhibitions can enhance user engagement and understanding of artworks by providing contextual information, especially through voice interactions. However, creating a deeper personal connection with art — which often requires direct aesthetic and visual experiences — remains a challenge. This paper examines how integrating visual perception into conversational agents can enhance alignment with visitors’ artistic interpretations, thereby fostering deeper engagement with interactive art exhibitions. We introduce a voice-based conversational agent enhanced with visual capabilities via a multimodal large language model (MLLM), allowing the agent to perceive, interpret and discuss artworks in real-time with visitors. The system utilizes a simplified Retrieval-Augmented Generation (RAG) architecture, which collects voice inputs, retrieves relevant information from a domain knowledge graph, and uses the LLM to generate conversational responses, which are then converted into voice outputs. A user study with 36 participants, divided into two groups, was conducted to compare the enhanced system with a baseline system that lacked visual input. Our results show that the visually enhanced system significantly improved visitor engagement and perception. Content analysis of the conversational transcripts further revealed a wider range of conversational topics, deeper visitor perceptions, and the agent’s ability to provide more nuanced, visually-related discussions.},
	booktitle = {Proceedings of the 30th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Ho, Hoang Phuoc and Ramesh, Vani and Zaloudek, Ivo and Rikhtehgar, Delaram Javdani and Wang, Shenghui},
	year = {2025},
	keywords = {Conversational Agents, Cultural Heritage, Human-Computer Interaction, Large Language Models, Multimodal Interaction, User Engagement, Voice User Interfaces},
	pages = {660--671},
}

@inproceedings{hu_hedrarag_2025,
	address = {New York, NY, USA},
	series = {{SOSP} '25},
	title = {{HedraRAG}: {Co}-{Optimizing} {Generation} and {Retrieval} for {Heterogeneous} {RAG} {Workflows}},
	isbn = {979-8-4007-1870-0},
	url = {https://doi.org/10.1145/3731569.3764806},
	doi = {10.1145/3731569.3764806},
	abstract = {In this paper, we identify and tackle emerging system-level challenges in serving heterogeneous RAG workflows, characterized by complex stages and diverse request patterns. We present HedraRAG, a new system built on RAGraph, a graph-based abstraction that exposes optimization opportunities across stage-level parallelism, intra-request similarity, and inter-request skewness. These opportunities are expressed through graph transformations, including node splitting, reordering, edge addition and rewiring. Transformations are dynamically applied to wavefronts of subgraphs across concurrent requests and scheduled onto the CPU-GPU pipeline. Experiments across a wide range of workflows demonstrate that HedraRAG achieves more that 1.5× and up to 5× speedup over existing frameworks, offering a comprehensive solution for heterogeneous RAG workload serving.},
	booktitle = {Proceedings of the {ACM} {SIGOPS} 31st {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {Association for Computing Machinery},
	author = {Hu, Zhengding and Murthy, Vibha and Pan, Zaifeng and Li, Wanlu and Fang, Xiaoyi and Ding, Yufei and Wang, Yuke},
	year = {2025},
	note = {event-place: Lotte Hotel World, Seoul, Republic of Korea},
	keywords = {heterogeneous RAG, LLM, vector search},
	pages = {623--638},
}

@inproceedings{azzopardi_simiir_2024,
	address = {New York, NY, USA},
	series = {{SIGIR}-{AP} 2024},
	title = {{SimIIR} 3: {A} {Framework} for the {Simulation} of {Interactive} and {Conversational} {Information} {Retrieval}},
	isbn = {979-8-4007-0724-7},
	url = {https://doi.org/10.1145/3673791.3698427},
	doi = {10.1145/3673791.3698427},
	abstract = {Evaluating the interactions between users and systems presents many challenges. Simulation offers a reliable, re-usable, and repeatable methodology to explore how different users, user behaviours and/or retrieval systems impact performance. With Large Language Models and Generative AI now widely available and accessible, new affordances are possible. These allow researchers to create more ”realistic” simulated users that can generate queries and judge items like humans, and to develop new retrieval systems where responses and interactions are conversational and based on retrieval augmented generation. This resource paper presents a community-led initiative to update the Simulation of Interactive Information Retrieval (SimIIR) Framework to enable the simulation of conversational search using LLMs. The largest update provides a conversational search workflow which involves a number of new possible interactions with a search system or agent – enabling a host of new development and evaluation opportunities. Other developments include the Markovian Users, Cognitive States, LLM-based components for assessing snippets/documents/responses, generating queries, deciding on when to stop/continue, and PyTerrier integration. This paper aims to mark the release of SimIIR 3.0 and invites the community to build, extend, and use the resource.},
	booktitle = {Proceedings of the 2024 {Annual} {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval} in the {Asia} {Pacific} {Region}},
	publisher = {Association for Computing Machinery},
	author = {Azzopardi, Leif and Breuer, Timo and Engelmann, Björn and Kreutz, Christin and MacAvaney, Sean and Maxwell, David and Parry, Andrew and Roegiest, Adam and Wang, Xi and Zerhoudi, Saber},
	year = {2024},
	note = {event-place: Tokyo, Japan},
	keywords = {conversational ir, interaction, interactive ir, open source framework, simulation},
	pages = {197--202},
}

@inproceedings{miroyan_analyzing_2025,
	address = {New York, NY, USA},
	series = {{SIGCSETS} 2025},
	title = {Analyzing {Pedagogical} {Quality} and {Efficiency} of {LLM} {Responses} with {TA} {Feedback} to {Live} {Student} {Questions}},
	isbn = {979-8-4007-0531-1},
	url = {https://doi.org/10.1145/3641554.3701965},
	doi = {10.1145/3641554.3701965},
	abstract = {While Large Language Models (LLMs) have emerged as promising methods for automated student question-answering, guaranteeing consistent instructional effectiveness of the response remains a key challenge. Therefore, there is a need for fine-grained analysis of State-Of-The-Art (SOTA) LLM-powered educational assistants. This work evaluates Edison: a Retrieval Augmented Generation (RAG) pipeline based on GPT-4. We determine the pedagogical effectiveness of Edison's responses through expert Teaching Assistant (TA) evaluation of the answers. After the TA edits and improves the response, we analyze the original LLM response, the TA-assigned ratings, and the TA's edits to ascertain the essential characteristics of a high-quality response. Some key insights of our evaluation are as follows: (1) Edison can give relevant and factual answers in an educational style for conceptual and assignment questions, (2) Most TA edits are deletions made to improve the style of the response, and finally (3) Our analysis indicates that Edison improves TAs' efficiency by reducing the effort required to respond to student questions.},
	booktitle = {Proceedings of the 56th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education} {V}. 1},
	publisher = {Association for Computing Machinery},
	author = {Miroyan, Mihran and Mitra, Chancharik and Jain, Rishi and Ranade, Gireeja and Norouzi, Narges},
	year = {2025},
	note = {event-place: Pittsburgh, PA, USA},
	keywords = {expert feedback, instructional technologies, language models, question answering},
	pages = {770--776},
}

@inproceedings{narayanan_venkit_search_2025,
	address = {New York, NY, USA},
	series = {{FAccT} '25},
	title = {Search {Engines} in the {AI} {Era}: {A} {Qualitative} {Understanding} to the {False} {Promise} of {Factual} and {Verifiable} {Source}-{Cited} {Responses} in {LLM}-based {Search}},
	isbn = {979-8-4007-1482-5},
	url = {https://doi.org/10.1145/3715275.3732089},
	doi = {10.1145/3715275.3732089},
	abstract = {As Large Language Model (LLM) applications transition from research to widespread sociotechnical products, they are fundamentally changing how people access and process information. Answer engines - LLM-powered search tools that generate source-cited summaries rather than just returning relevant links - represent a particularly significant shift from traditional search engines. Through a qualitative study of 21 expert users comparing answer engines to traditional search, we identified 16 ethical and societal limitations in current answer engine implementations. We showcase how current LLM-based search engine still lack the neccessary features to be treated as a safe sociotechnical system for public consumption. Based on these findings, we propose a framework of 16 corresponding design recommendations to guide the development of more trustworthy answer engine systems. We showcase of this application is still nascent and how we need to be more sensitive to their social ramifications, to create a better and safer experience for individuals.},
	booktitle = {Proceedings of the 2025 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Narayanan Venkit, Pranav and Laban, Philippe and Zhou, Yilun and Mao, Yixin and Wu, Chien-Sheng},
	year = {2025},
	keywords = {Answer Engines, Ethical Audit, Fairness and Ethics, Generative Search Engine, RAG systems},
	pages = {1325--1340},
}

@inproceedings{cao_javabench_2024,
	address = {New York, NY, USA},
	series = {{ASE} '24},
	title = {{JavaBench}: {A} {Benchmark} of {Object}-{Oriented} {Code} {Generation} for {Evaluating} {Large} {Language} {Models}},
	isbn = {979-8-4007-1248-7},
	url = {https://doi.org/10.1145/3691620.3695470},
	doi = {10.1145/3691620.3695470},
	abstract = {Code generation benchmarks such as HumanEval are widely adopted to evaluate LLMs' capabilities. However, after consolidating the latest 24 benchmarks, we noticed three significant imbalances. First, imbalanced programming language. 95.8\% of benchmarks involve Python, while only 5 benchmarks involve Java, resulting in an insufficient understanding of LLMs' capability to generate Java code. Second, imbalanced code granularity. Function-/statement-level benchmarks account for over 83.3\% of benchmarks. Only a mere handful extends to class-/project-levels, and all are limited to Python. Third, lacking advanced features. Existing benchmarks primarily assess basic coding skills (e.g., variables, operators, and control structures), while overlooking advanced Object-Oriented Programming (OOP) features (i.e., encapsulation, inheritance, and polymorphism). Considering the prevalence of these advanced features in real-world Java project development, constructing benchmarks to test LLMs on handling OOP features is necessary.To fill these gaps, we propose JavaBench, a project-level Java benchmark that exercises OOP features. It comprises four Java projects with 389 methods in 106 Java classes. The test coverage is up to 92\%, and JavaBench is attested by 282 undergraduate students, reaching a 90.93/100 average score (i.e., pass rate against the test suite), ensuring the quality of documentation, code skeleton, and tests. To better evaluate LLM's capability against JavaBench, we introduce a systematic evaluation design covering three context settings and five synthesis strategies at two granularities using three hierarchical metrics. Our extensive experiment yields several interesting findings. First, we noticed that regarding project-level Java programming, LLMs are far behind undergraduate students (no project can be correctly completed by any studied LLMs, and at most 48.24\% Pass@5 in a more relaxed evaluation). Second, using method signature as prompt context may strike an ideal balance for project-level code generation. JavaBench is publicly available at https://github.com/java-bench/JavaBench. We also release a leaderboard and invite model developers to participate and test their models against JavaBench at https://java-bench.github.io/leaderboard.html.},
	booktitle = {Proceedings of the 39th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Cao, Jialun and Chen, Zhiyong and Wu, Jiarong and Cheung, Shing-Chi and Xu, Chang},
	year = {2024},
	note = {event-place: Sacramento, CA, USA},
	keywords = {large language model, object-oriented programming, program synthesis},
	pages = {870--882},
}

@inproceedings{li_bridging_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Bridging the {Gap}: {Aligning} {Language} {Model} {Generation} with {Structured} {Information} {Extraction} via {Controllable} {State} {Transition}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714571},
	doi = {10.1145/3696410.3714571},
	abstract = {Large language models (LLMs) achieve superior performance in generative tasks. However, due to the natural gap between language model generation and structured information extraction in three dimensions: task type, output format, and modeling granularity, they often fall short in structured information extraction, a crucial capability for effective data utilization on the web. In this paper, we define the generation process of the language model as the controllable state transition, aligning the generation and extraction processes to ensure the integrity of the output structure and adapt to the goals of the information extraction task. Furthermore, we propose the Structure2Text decider to help the language model understand the fine-grained extraction information, which converts the structured output into natural language and makes state decisions, thereby focusing on the task-specific information kernels, and alleviating language model hallucinations and incorrect content generation. We conduct extensive experiments and detailed analyses on myriad information extraction tasks, including named entity recognition, relation extraction, and event argument extraction. Our method not only achieves significant performance improvements but also considerably enhances the model's capability to generate precise and relevant content, making the extracted content easy to parse.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Li, Hao and Ren, Yubing and Cao, Yanan and Li, Yingjie and Fang, Fang and Lin, Zheng and Wang, Shi},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {few-shot learning, information extraction, large language model, structure generation},
	pages = {1811--1821},
}

@inproceedings{guo_optimizing_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {Optimizing {Case}-{Based} {Reasoning} {System} for {Functional} {Test} {Script} {Generation} with {Large} {Language} {Models}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737254},
	doi = {10.1145/3711896.3737254},
	abstract = {In this work, we explore the potential of large language models (LLMs) for generating functional test scripts, which necessitates understanding the dynamically evolving code structure of the target software. To achieve this, we propose a case-based reasoning (CBR) system utilizing a 4R cycle (i.e., retrieve, reuse, revise, and retain), which maintains and leverages a case bank of test intent descriptions and corresponding test scripts to facilitate LLMs for test script generation. To improve user experience further, we introduce Re4, an optimization method for the CBR system, comprising reranking-based retrieval finetuning and reinforced reuse finetuning. Specifically, we first identify positive examples with high semantic and script similarity, providing reliable pseudo-labels for finetuning the retriever model without costly labeling. Then, we apply supervised finetuning, followed by a reinforcement learning finetuning stage, to align LLMs with our production scenarios, ensuring the faithful reuse of retrieved cases. Extensive experimental results on two product development units from Huawei Datacom demonstrate the superiority of the proposed CBR+Re4. Notably, we also show that the proposed Re4 method can help alleviate the repetitive generation issues with LLMs.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Guo, Siyuan and Liu, Huiwu and Chen, Xiaolong and Xie, Yuming and Zhang, Liang and Han, Tao and Chen, Hechang and Chang, Yi and Wang, Jun},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {case-based reasoning, functional testing, large language model, reinforcement learning, test script generation},
	pages = {4487--4498},
}

@inproceedings{dao_llm-powered_2024,
	address = {New York, NY, USA},
	series = {{AIQAM} '24},
	title = {{LLM}-{Powered} {Multimodal} {AI} {Conversations} for {Diabetes} {Prevention}},
	isbn = {979-8-4007-0547-2},
	url = {https://doi.org/10.1145/3643479.3662049},
	doi = {10.1145/3643479.3662049},
	abstract = {The global prevalence of diabetes remains high despite rising life expectancy with improved quality and access to healthcare services. The significant burden that diabetes imposes warrants efforts to improve existing interventions in diabetes care. Present research on diabetes management has shown that artificial intelligence (AI) and Large Language Models (LLM) play an important role in various aspects of the diabetes continuum but a distinct lack of studies in diabetes prevention is observed. Our research introduces a comprehensive digital solution, leveraging the capabilities of GPT-3.5 models maintained by OpenAI, focused specifically on the active prevention of diabetes. The system encompasses a user-friendly interface accessible via mobile and web applications, an AI-powered chatbot for instant Q\&amp;A and advice, personalized reminder systems, a data analysis module for tailored guidance, resource aggregators for health-related information, and an emotional support module to ensure a holistic approach to prevention. Furthermore, our experiments involved testing the quality of responses generated by a fine-tuned GPT-3.5 model, utilizing the Assistants API or a retrieval-augmented generation (RAG) system powered by FAISS for enhanced context awareness and personalized advice. The testing focused on a structured dataset of questions and answers related to diabetes prevention, with results highlighting the superiority of the GPT-3.5 model combined with the Assistants API in providing relevant, detailed, and personalized responses, thus demonstrating its potential as an invaluable tool in the proactive prevention of diabetes.},
	booktitle = {Proceedings of the 1st {ACM} {Workshop} on {AI}-{Powered} {Q}\&amp;{A} {Systems} for {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Dao, Dung and Teo, Jun Yi Claire and Wang, Wenru and Nguyen, Hoang D.},
	year = {2024},
	note = {event-place: Phuket, Thailand},
	keywords = {Conversational, Design, Diabetes, Diabetes Prevention, Dialogue, Fine-tuning, GPT-3.5, Multimodal},
	pages = {1--6},
}

@inproceedings{wang_metmap_2024,
	address = {New York, NY, USA},
	series = {{FORGE} '24},
	title = {{MeTMaP}: {Metamorphic} {Testing} for {Detecting} {False} {Vector} {Matching} {Problems} in {LLM} {Augmented} {Generation}},
	isbn = {979-8-4007-0609-7},
	url = {https://doi.org/10.1145/3650105.3652297},
	doi = {10.1145/3650105.3652297},
	abstract = {Augmented generation techniques such as Retrieval-Augmented Generation (RAG) and Cache-Augmented Generation (CAG) have revolutionized the field by enhancing large language model (LLM) outputs with external knowledge and cached information. However, the integration of vector databases, which serve as a backbone for these augmentations, introduces critical challenges, particularly in ensuring accurate vector matching. False vector matching in these databases can significantly compromise the integrity and reliability of LLM outputs, leading to misinformation or erroneous responses. Despite the crucial impact of these issues, there is a notable research gap in methods to effectively detect and address false vector matches in LLM-augmented generation.This paper presents MeTMaP, a metamorphic testing framework developed to identify false vector matching in LLM-augmented generation systems. We derive eight metamorphic relations (MRs) from six NLP datasets, which form our method's core, based on the idea that semantically similar texts should match and dissimilar ones should not. MeTMaP uses these MRs to create sentence triplets for testing, simulating real-world matching scenarios. Our evaluation of MeTMaP over 203 vector matching configurations, involving 29 embedding models and 7 distance metrics, uncovers significant inaccuracies. The results, showing a maximum accuracy of only 41.51\% on our tests compared to the original datasets, emphasize the widespread issue of false matches in vector matching methods and the critical need for effective detection and mitigation in LLM-augmented applications.},
	booktitle = {Proceedings of the 2024 {IEEE}/{ACM} {First} {International} {Conference} on {AI} {Foundation} {Models} and {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Guanyu and Li, Yuekang and Liu, Yi and Deng, Gelei and Li, Tianlin and Xu, Guosheng and Liu, Yang and Wang, Haoyu and Wang, Kailong},
	year = {2024},
	note = {event-place: Lisbon, Portugal},
	keywords = {augmented generation, metamorphic testing, vector matching},
	pages = {12--23},
}

@inproceedings{shi_flowxpert_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{FlowXpert}: {Expertizing} {Troubleshooting} {Workflow} {Orchestration} with {Knowledge} {Base} and {Multi}-{Agent} {Coevolution}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737221},
	doi = {10.1145/3711896.3737221},
	abstract = {Incident management remains a critical yet challenging task for large-scale cloud services. Most cloud service providers abstract troubleshooting into predefined workflows for different incidents, offering step-by-step guidance. However, manually crafting workflows is resource-consuming and knowledge-intensive, hindering large-scale deployment. Most automated techniques for workflow orchestration rely on large language models (LLMs) to handle complex tasks but overlook key aspects of troubleshooting, including complex expertise, domain requirements, and the reliability of AI feedback. These limitations undermine workflow quality. Therefore, we propose FlowXpert, a novel framework for troubleshooting workflow orchestration. Leveraging LLMs, it first builds a knowledge base centered on incident-aware nodes to precisely depict expertise. Then, fed into AI feedback and synthetic preference data, reinforcement learning is applied to refine the workflow generator and evaluator. To assess troubleshooting workflows, we introduce OpsFlowBench based on Huawei Cloud's datacenter switch operation documents. Benchmark tests under the tailored STEPScore metric validate its effectiveness. Furthermore, during a 10-week deployment in Huawei Cloud's datacenter network, FlowXpert provided valuable support to both on-call engineers and AI executors, as evidenced by empirical data and case study.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Shi, Binpeng and Luo, Yu and Wang, Jingya and Zhao, Yongxin and Zhang, Shenglin and Hao, Bowen and Zhao, Chenyu and Sun, Yongqian and Zhang, Zhi and Sun, Ronghua and Li, Haihua and Song, Wei and Chen, Xiaolong and Miao, Jingbo and Pei, Dan},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {incident management, large language model, troubleshooting, workflow orchestration},
	pages = {4839--4850},
}

@inproceedings{yang_design_2025,
	address = {New York, NY, USA},
	series = {{CUI} '25},
	title = {Design {Activity} {Simulation}: {Opportunities} and {Challenges} in {Using} {Multiple} {Communicative} {AI} {Agents} to {Tackle} {Design} {Problems}},
	isbn = {979-8-4007-1527-3},
	url = {https://doi.org/10.1145/3719160.3736609},
	doi = {10.1145/3719160.3736609},
	abstract = {Large Language Models (LLMs) can enhance structured design thinking, yet existing copilot approaches integrate them into human workflows rather than exploring their autonomous potential. This paper investigates how LLM-based communicative AI agents can independently tackle open-ended design problems and how their strengths and limitations inform human-AI collaboration. We iteratively design a system where AI agents play different roles and simulate human design activity through conversational turns. The agents investigate user needs, identify design constraints, and explore the design space, with useful insights emerging from their interactions. To assess reasoning quality, we conducted a human jury evaluation with five HCI researchers and explored potential applications through a contextual inquiry with seven professionals. Our findings demonstrate that integrating human design thinking techniques enhances AI reasoning. AI agents effectively tackle design problems, generating low-novelty yet well-grounded and practical solutions that meet key design requirements.},
	booktitle = {Proceedings of the 7th {ACM} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Yang, Boyin and Dudley, John J and Kristensson, Per Ola},
	year = {2025},
	keywords = {End-user interaction with LLMs and Multimodal models, Generative AI},
}

@inproceedings{battaglini-fischer_fails_2025,
	address = {New York, NY, USA},
	series = {{ICPE} '25},
	title = {{FAILS}: {A} {Framework} for {Automated} {Collection} and {Analysis} of {LLM} {Service} {Incidents}},
	isbn = {979-8-4007-1130-5},
	url = {https://doi.org/10.1145/3680256.3721320},
	doi = {10.1145/3680256.3721320},
	abstract = {Large Language Model (LLM) services such as ChatGPT, DALL·E, and Cursor have quickly become essential for society, businesses, and individuals, empowering applications such as chatbots, image generation, and code assistance. The complexity of LLM systems makes them prone to failures and affects their reliability and availability, yet their failure patterns are not fully understood, making it an emerging problem. However, there are limited datasets and studies in this area, particularly lacking an open-access tool for analyzing LLM service failures based on incident reports. Addressing these problems, in this work we propose FAILS, the first open-sourced framework for incident reports collection and analysis on different LLM services and providers. FAILS provides comprehensive data collection, analysis, and visualization capabilities, including: (1) It can automatically collect, clean, and update incident data through its data scraper and processing components;(2) It provides 17 types of failure analysis, allowing users to explore temporal trends of incidents, analyze service reliability metrics, such as Mean Time to Recovery (MTTR) and Mean Time Between Failures (MTBF);(3) It leverages advanced LLM tools to assist in data analysis and interpretation, enabling users to gain observations and insights efficiently. All functions are integrated in the backend, allowing users to easily access them through a web-based frontend interface. FAILS supports researchers, engineers, and general users to understand failure patterns and further mitigate operational incidents and outages in LLM services. The framework is publicly available on https://github.com/atlarge-research/FAILS.},
	booktitle = {Companion of the 16th {ACM}/{SPEC} {International} {Conference} on {Performance} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Battaglini-Fischer, Sándor and Srinivasan, Nishanthi and Szarvas, Bálint László and Chu, Xiaoyu and Iosup, Alexandru},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {failure characterization, failure recovery, incident report, llm, operational data analytics, reliability, system design},
	pages = {187--194},
}

@inproceedings{yuan_scx_2025,
	address = {New York, NY, USA},
	series = {{SIGCOMM} '25},
	title = {{SCX}: {Stateless} {KV}-{Cache} {Encoding} for {Cloud}-{Scale} {Confidential} {Transformer} {Serving}},
	isbn = {979-8-4007-1524-2},
	url = {https://doi.org/10.1145/3718958.3750509},
	doi = {10.1145/3718958.3750509},
	abstract = {Transformer models have revolutionized fields like natural language processing and computer vision but face privacy concerns in sensitive applications such as medical diagnostics. Existing confidential serving methods, including cryptography-based, memory isolation-based, and access control-based, offer trade-offs between privacy and efficiency but often struggle with high latency or hardware dependencies. This work proposes stateless KV-cache encoding (SCX), a novel framework that encodes the intermediate key-value cache during Transformer inference using user-controlled keys. SCX ensures that the cloud can neither recover the input nor independently complete the next token prediction, effectively preserving privacy. By introducing efficient encoding and decoding schemes, SCX addresses communication complexity and attack vulnerabilities while ensuring zero loss of inference quality. Experiments on large Transformer models demonstrate that SCX achieves lower latency (e.g., 36ms for LLaMA-7B), outperforming state-of-the-art cryptography and memory isolation methods by orders of magnitude. Moreover, SCX can complementarily work with advanced KV-cache management techniques to further enhance KV-cache communication efficiency by 85\%, marking a significant step toward practical, privacy-preserving large Transformer serving.},
	booktitle = {Proceedings of the {ACM} {SIGCOMM} 2025 {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Yuan, Mu and Zhang, Lan and Zeng, Liekang and Jiang, Siyang and Yang, Bufang and Duan, Di and Xing, Guoliang},
	year = {2025},
	note = {event-place: São Francisco Convent, Coimbra, Portugal},
	keywords = {confidential computing, device-cloud collaboration, KV-cache, large language model, model inference},
	pages = {39--54},
}

@inproceedings{tang_test_2024,
	address = {New York, NY, USA},
	series = {{MobiArch} '24},
	title = {Test {Large} {Language} {Models} on {Driving} {Theory} {Knowledge} and {Skills} for {Connected} {Autonomous} {Vehicles}},
	isbn = {979-8-4007-1247-0},
	url = {https://doi.org/10.1145/3691555.3696825},
	doi = {10.1145/3691555.3696825},
	abstract = {Handling long tail corner cases is a major challenge faced by autonomous vehicles (AVs). While large language models (LLMs) hold great potentials to handle the corner cases with excellent generalization and explanation capabilities and received increasing research interest on application to autonomous driving, there are still technical barriers to be tackled, such as strict model performance and huge computing resource requirements of LLMs, which are difficult to be met locally at AVs. In this paper, we investigate a new approach of applying remote or edge LLMs to support autonomous driving. With this approach connected autonomous vehicles (CAVs) send driving assistance requests to the LLMs. LLMs deployed at the edge of the networks or remote clouds process the requests and generate driving assistance instructions for the CAVs. A key issue for such LLM assisted driving system is the assessment of LLMs on their understanding of driving theory and skills, ensuring they are qualified to undertake safety critical driving assistance tasks for CAVs. As there is no published work on assessing LLM of driving theory and skills, we design and run driving theory tests for several proprietary LLM models (OpenAI GPT models, Baidu Ernie and Ali QWen) and open-source LLM models (Tsinghua MiniCPM-2B and MiniCPM-Llama3-V2.5) with more than 500 multiple-choices theory test questions. These questions are close to the official UK driving theory test ones. Model accuracy, cost and processing latency are measured from the experiments. Experiment results show that while model GPT-4 passes the test with improved domain knowledge and Ernie has an accuracy of 85\% (just below the 86\% passing threshold), other LLM models including GPT-3.5 fail the test. For the test questions with images, the multimodal model GPT4-o has an excellent accuracy result of 96\%, and the MiniCPM-Llama3-V2.5 achieves an accuracy of 76\%. While GPT-4 holds stronger potential for CAV driving assistance applications, the cost of using model GPT4 is much higher, almost 50 times of that of using GPT3.5. The results can help make decision on the use of the existing LLMs for CAV applications and balancing on the model performance and cost.},
	booktitle = {Proceedings of the 19th {Workshop} on {Mobility} in the {Evolving} {Internet} {Architecture}},
	publisher = {Association for Computing Machinery},
	author = {Tang, Zuoyin and He, Jianhua and Pe, Dashuai and Liu, Kezhong and Gao, Tao and Zheng, Jiawei},
	year = {2024},
	note = {event-place: Washington D.C., DC, USA},
	keywords = {Connected autonomous vehicles, driving theory test, large language model, mobile cloud computing, mobile edge computing, remote driving},
	pages = {1--6},
}

@inproceedings{zhang_enhancing_2023,
	address = {New York, NY, USA},
	series = {{ICAIF} '23},
	title = {Enhancing {Financial} {Sentiment} {Analysis} via {Retrieval} {Augmented} {Large} {Language} {Models}},
	isbn = {979-8-4007-0240-2},
	url = {https://doi.org/10.1145/3604237.3626866},
	doi = {10.1145/3604237.3626866},
	abstract = {Financial sentiment analysis is critical for valuation and investment decision-making. Traditional NLP models, however, are limited by their parameter size and the scope of their training datasets, which hampers their generalization capabilities and effectiveness in this field. Recently, Large Language Models (LLMs) pre-trained on extensive corpora have demonstrated superior performance across various NLP tasks due to their commendable zero-shot abilities. Yet, directly applying LLMs to financial sentiment analysis presents challenges: The discrepancy between the pre-training objective of LLMs and predicting the sentiment label can compromise their predictive performance. Furthermore, the succinct nature of financial news, often devoid of sufficient context, can significantly diminish the reliability of LLMs’ sentiment analysis. To address these challenges, we introduce a retrieval-augmented LLMs framework for financial sentiment analysis. This framework includes an instruction-tuned LLMs module, which ensures LLMs behave as predictors of sentiment labels, and a retrieval-augmentation module which retrieves additional context from reliable external sources. Benchmarked against traditional models and LLMs like ChatGPT and LLaMA, our approach achieves 15\% to 48\% performance gain in accuracy and F1 score.},
	booktitle = {Proceedings of the {Fourth} {ACM} {International} {Conference} on {AI} in {Finance}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Boyu and Yang, Hongyang and Zhou, Tianyu and Ali Babar, Muhammad and Liu, Xiao-Yang},
	year = {2023},
	note = {event-place: Brooklyn, NY, USA},
	keywords = {Instruction Tuning, Large Language Models, Retrieval Augmented Generation, Sentiment Analysis},
	pages = {349--356},
}

@inproceedings{aodeng_inreactable_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {{InReAcTable}: {LLM}-powered {Interactive} {Visual} {Data} {Story} {Construction} from {Tabular} {Data}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747719},
	doi = {10.1145/3746059.3747719},
	abstract = {Insights in tabular data capture valuable patterns that help analysts understand critical information. Organizing related insights into visual data stories is crucial for in-depth analysis. However, constructing such stories is challenging because of the complexity of the inherent relations between extracted insights. Users face difficulty sifting through a vast number of discrete insights to integrate specific ones into a unified narrative that meets their analytical goals. Existing methods either heavily rely on user expertise, making the process inefficient, or employ automated approaches that cannot fully capture their evolving goals. In this paper, we introduce InReAcTable, a framework that enhances visual data story construction by establishing both structural and semantic connections between data insights. Each user interaction triggers the Acting module, which utilizes an insight graph for structural filtering to narrow the search space, followed by the Reasoning module using the retrieval-augmented generation method based on large language models for semantic filtering, ultimately providing insight recommendations aligned with the user’s analytical intent. Based on the InReAcTable framework, we develop an interactive prototype system that guides users to construct visual data stories aligned with their analytical requirements. We conducted a case study and a user experiment to demonstrate the utility and effectiveness of the InReAcTable framework and the prototype system for interactively building visual data stories.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Aodeng, Gerile and Li, Guozheng and Feng, Yunshan and Chen, Qiyang and Zhang, Yu and Liu, Chi Harold},
	year = {2025},
	keywords = {exploratory data analysis, large language models., Tabular data, visual data story},
}

@inproceedings{valtolina_teacher-driven_2025,
	address = {New York, NY, USA},
	series = {{CHItaly} '25},
	title = {A {Teacher}-{Driven} {Framework} for {Reliable} and {Personalised} {AITutors}},
	isbn = {979-8-4007-2102-1},
	url = {https://doi.org/10.1145/3750069.3750121},
	doi = {10.1145/3750069.3750121},
	abstract = {This paper presents a software framework that enables teachers to design reliable, personalised conversational agents tailored to their pedagogical goals and student learning preferences. The system combines a Retrieval-Augmented Generation (RAG) architecture with a visual configuration environment, allowing educators to upload, validate, and organise domain-specific teaching materials into a teacher-curated content corpus. Educators can configure adaptive tutoring strategies based on the VARK model (Visual, Auditory, Reading/Writing, Kinesthetic), allowing the conversational agents to address diverse learning preferences and educational contexts. Unlike fully autonomous or black-box educational AI systems, this approach foregrounds teacher agency and pedagogical alignment, enabling intuitive control over content and interaction style. A preliminary evaluation with university educators assessed usability (SUS), perceived utility (UTAUT), cognitive load (NASA-TLX), and creative-technical capacity (CTS), revealing promising results and informing future design directions. The system supports the development of human-centred AI tutors that are transparent, configurable, and grounded in teacher expertise.},
	booktitle = {Proceedings of the 16th {Biannual} {Conference} of the {Italian} {SIGCHI} {Chapter}},
	publisher = {Association for Computing Machinery},
	author = {Valtolina, Stefano and Matamoros Aragon, Ricardo Anibal and Epifania, Francesco},
	year = {2025},
	keywords = {Acceptability and Usability, Conversational interface, End User Development objects, Machine learning for education},
}

@inproceedings{yang_optimization_2025,
	address = {New York, NY, USA},
	series = {{CNML} '25},
	title = {Optimization of {RAG} multi query rewrite generation strategy based on markov decision process},
	isbn = {979-8-4007-1323-1},
	url = {https://doi.org/10.1145/3728199.3728221},
	doi = {10.1145/3728199.3728221},
	abstract = {The Large Language Model (LLM) has some limitations in dealing with illusion problems, acquiring the latest knowledge, and dealing with complex tasks. Retrieval Enhanced Generation (RAG) combines retrieval based and generation based models, utilizing massive external data to assist the LLM in generating more informative, accurate, and contextually relevant responses. Query rewriting solves the above problem by generating new retrieval queries from the user's original queries to obtain external knowledge. The RAG framework MQRF-RAG, based on multiple query rewrites, constructs four different styles of query problems, enabling it to obtain more comprehensive and accurate retrieval documents. Based on Markov decision process optimization rewriter and lightweight prompt adaptive rewriting strategy selection, it better handles complex tasks. The test results show that MQRF-RAG outperforms existing rewriting methods in document retrieval, and the retrieved documents provide accurate external knowledge for the response model, significantly improving its response performance.},
	booktitle = {Proceedings of the 2025 3rd {International} {Conference} on {Communication} {Networks} and {Machine} {Learning}},
	publisher = {Association for Computing Machinery},
	author = {Yang, Junwen and Zhou, Yanci and Li, Yijin and Zhu, Guohua},
	year = {2025},
	pages = {142--148},
}

@inproceedings{dubey_auctions_2024,
	address = {New York, NY, USA},
	series = {{KDD} '24},
	title = {Auctions with {LLM} {Summaries}},
	isbn = {979-8-4007-0490-1},
	url = {https://doi.org/10.1145/3637528.3672022},
	doi = {10.1145/3637528.3672022},
	abstract = {We study an auction setting in which bidders bid for placement of their content within a summary generated by a large language model (LLM), e.g., an ad auction in which the display is a summary paragraph of multiple ads. This generalizes the classic ad settings such as position auctions to an LLM generated setting, which allows us to handle general display formats. We propose a novel factorized framework in which an auction module and an LLM module work together via a prediction model to provide welfare maximizing summary outputs in an incentive compatible manner. We provide a theoretical analysis of this framework and synthetic experiments to demonstrate the feasibility and validity of the system together with welfare comparisons.},
	booktitle = {Proceedings of the 30th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Dubey, Avinava and Feng, Zhe and Kidambi, Rahul and Mehta, Aranyak and Wang, Di},
	year = {2024},
	note = {event-place: Barcelona, Spain},
	keywords = {auction design, computational advertising},
	pages = {713--722},
}

@inproceedings{chen_knowledge_2025,
	address = {New York, NY, USA},
	series = {{SECA} '25},
	title = {Knowledge {Reasoning} {Chain}-of-{Thought} {Embedded} {Large} {Model} for {Power} {Text} {Writing}},
	isbn = {979-8-4007-1513-6},
	url = {https://doi.org/10.1145/3747912.3747923},
	doi = {10.1145/3747912.3747923},
	abstract = {Although the current large language models (LLM) have very strong general capabilities, they lack professional knowledge of power systems and also do not possess the reasoning ability required to solve complex problems in the field of power systems. Therefore, we introduced a two-stage training method. Specifically, we first constructed and cleaned the Q\&amp;A dataset of power professional knowledge. Based on these data, we fine-tuned the open-source large model to achieve the injection of power professional knowledge. Secondly, we constructed a power preference dataset based on the current most advanced closed-source LLM and expert experience, and used DPO to enable the open-source LLM to learn the expert thought chain in the field of power systems, improving the reasoning ability of the open-source LLM in the field of power systems.},
	booktitle = {Proceedings of the 2025 {International} {Conference} on {Software} {Engineering} and {Computer} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Yun and Shen, Hao and Xie, Bangpeng and Wang, Jiayu and Zhao, Wenkai and Pan, Zhijun and Fu, Chaoran and Wang, Xiaohui and Liang, Xiao and Zhang, Zhonghao and Cai, Changyu},
	year = {2025},
	keywords = {Direct Preference Optimization, Large Language Model, Power Industry},
	pages = {71--76},
}

@inproceedings{frazier_customizing_2024,
	address = {New York, NY, USA},
	series = {{ITiCSE} 2024},
	title = {Customizing {ChatGPT} to {Help} {Computer} {Science} {Principles} {Students} {Learn} {Through} {Conversation}},
	isbn = {979-8-4007-0600-4},
	url = {https://doi.org/10.1145/3649217.3653570},
	doi = {10.1145/3649217.3653570},
	abstract = {This paper explores leveraging conversational agents, specifically ChatGPT, to enhance the introduction of computing, focused on the Advanced Placement Computer Science Principles (CSP) course in secondary schools. Despite the potential benefits for diverse student audiences, little research has investigated their effectiveness and engagement in this context. We examine the customization of ChatGPT for secondary school CSP students, assessing its impact on exploratory searches for learning CSP concepts. Results from 20 high school students in grades 10-12 (ages 15-18) in a CSP course indicate that students preferred a customized ChatGPT, with its terminology more suitable to secondary school level, examples more understandable, and better connections to personal experiences compared to standard ChatGPT.},
	booktitle = {Proceedings of the 2024 on {Innovation} and {Technology} in {Computer} {Science} {Education} {V}. 1},
	publisher = {Association for Computing Machinery},
	author = {Frazier, Matthew and Damevski, Kostadin and Pollock, Lori},
	year = {2024},
	note = {event-place: Milan, Italy},
	keywords = {chatgpt, computer science principles, conversational agent, exploratory search},
	pages = {633--639},
}

@inproceedings{most_lost_2025,
	address = {New York, NY, USA},
	series = {{DocEng} '25},
	title = {Lost in {OCR} {Translation}? {Vision}-{Based} {Approaches} to {Robust} {Document} {Retrieval}},
	isbn = {979-8-4007-1351-4},
	url = {https://doi.org/10.1145/3704268.3742698},
	doi = {10.1145/3704268.3742698},
	abstract = {Retrieval-Augmented Generation (RAG) has become a popular technique for enhancing the reliability and utility of Large Language Models (LLMs) by grounding responses in external documents. Traditional RAG systems rely on Optical Character Recognition (OCR) to first process scanned documents into text. However, even state-of-the-art OCRs can introduce errors, especially in degraded or complex documents. Recent vision-language approaches, such as ColPali, propose direct visual embedding of documents, eliminating the need for OCR. This study presents a systematic comparison between a vision-based RAG system (ColPali) and more traditional OCR-based pipelines utilizing Llama 3.2 (90B) and Nougat OCR across varying document qualities. Beyond conventional retrieval accuracy metrics, we introduce a semantic answer evaluation benchmark to assess end-to-end question-answering performance. Our findings indicate that while vision-based RAG performs well on documents it has been fine-tuned on, OCR-based RAG is better able to generalize to unseen documents of varying quality. We highlight the key trade-offs between computational efficiency and semantic accuracy, offering practical guidance for RAG practitioners in selecting between OCR-dependent and vision-based document retrieval systems in production environments.},
	booktitle = {Proceedings of the 2025 {ACM} {Symposium} on {Document} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Most, Alexander and Winjum, Joseph and Bhattarai, Manish and Jones, Shawn and Ranasinghe, Nishath Rajiv and Biswas, Ayan and O'Malley, Dan},
	year = {2025},
	note = {event-place: Nottingham, United Kingdom},
}

@inproceedings{moayeri_worldbench_2024,
	address = {New York, NY, USA},
	series = {{FAccT} '24},
	title = {{WorldBench}: {Quantifying} {Geographic} {Disparities} in {LLM} {Factual} {Recall}},
	isbn = {979-8-4007-0450-5},
	url = {https://doi.org/10.1145/3630106.3658967},
	doi = {10.1145/3630106.3658967},
	abstract = {As large language models (LLMs) continue to improve and gain popularity, some may use the models to recall facts, despite well documented limitations with LLM factuality. Towards ensuring that models work reliably for all, we seek to uncover if geographic disparities emerge when asking an LLM the same question about different countries. To this end, we present WorldBench, a dynamic and flexible benchmark composed of per-country data from the World Bank. In extensive experiments on state of the art open and closed source models, including GPT-4, Gemini, Llama-2, and Vicuna, to name a few, we find significant biases based on region and income level. For example, error rates are 1.5 times higher for countries from Sub-Saharan Africa compared to North American countries. We observe these disparities to be consistent over 20 LLMs and 11 individual World Bank indicators (i.e. specific statistics, such as population or CO2 emissions). WorldBench also enables automatic detection of citation hallucination, where models cite the World Bank itself while providing false statistics, and a manner to assess when an LLM’s stored facts begin to go out of date. We hope our benchmark will draw attention to geographic disparities in existing LLMs and facilitate the remedying of these biases.},
	booktitle = {Proceedings of the 2024 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Moayeri, Mazda and Tabassi, Elham and Feizi, Soheil},
	year = {2024},
	note = {event-place: Rio de Janeiro, Brazil},
	keywords = {Bias, Factuality, Fairness, Geographic Disparity, Large Language Models},
	pages = {1211--1228},
}

@inproceedings{roy_exploring_2024,
	address = {New York, NY, USA},
	series = {{FSE} 2024},
	title = {Exploring {LLM}-{Based} {Agents} for {Root} {Cause} {Analysis}},
	isbn = {979-8-4007-0658-5},
	url = {https://doi.org/10.1145/3663529.3663841},
	doi = {10.1145/3663529.3663841},
	abstract = {The growing complexity of cloud based software systems has resulted in incident management becoming an integral part of the software development lifecycle. Root cause analysis (RCA), a critical part of the incident management process, is a demanding task for on-call engineers, requiring deep domain knowledge and extensive experience with a team’s specific services. Automation of RCA can result in significant savings of time, and ease the burden of incident management on on-call engineers. Recently, researchers have utilized Large Language Models (LLMs) to perform RCA, and have demonstrated promising results. However, these approaches are not able to dynamically collect additional diagnostic information such as incident related logs, metrics or databases, severely restricting their ability to diagnose root causes. In this work, we explore the use of LLM based agents for RCA to address this limitation. We present a thorough empirical evaluation of a ReAct agent equipped with retrieval tools, on an out-of-distribution dataset of production incidents collected at a large IT corporation. Results show that ReAct performs competitively with strong retrieval and reasoning baselines, but with highly increased factual accuracy. We then extend this evaluation by incorporating discussions associated with incident reports as additional inputs for the models, which surprisingly does not yield significant performance improvements. Lastly, we conduct a case study with a team at Microsoft to equip the ReAct agent with tools that give it access to external diagnostic services that are used by the team for manual RCA. Our results show how agents can overcome the limitations of prior work, and practical considerations for implementing such a system in practice.},
	booktitle = {Companion {Proceedings} of the 32nd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Roy, Devjeet and Zhang, Xuchao and Bhave, Rashi and Bansal, Chetan and Las-Casas, Pedro and Fonseca, Rodrigo and Rajmohan, Saravan},
	year = {2024},
	note = {event-place: Porto de Galinhas, Brazil},
	keywords = {AIOps, Cloud Computing, Incident Management, Root Cause Analysis},
	pages = {208--219},
}

@inproceedings{cheng_oak_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {Oak {Story}: {Improving} {Learner} {Outcomes} with {LLM}-{Mediated} {Interactive} {Narratives}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747698},
	doi = {10.1145/3746059.3747698},
	abstract = {Narrative-based education engages children in learning, but traditional approaches offer limited adaptability to individual preferences. Although large language models (LLMs) offer promising opportunities for interactive narratives, balancing their unpredictability with structured learning objectives remains challenging. To answer this challenge, we designed and built Oak Story, an educational mobile application for 4th–6th graders centered on local oak woodland ecosystems. Oak Story employs a learning-goal-directed LLM architecture that adapts the narrative, as well as multimodal real-world activities, to each individual student while ensuring that learning goals are met. In a between-participants study (N = 47), we find that Oak Story produces statistically significant increases in learning gains, engagement, and perceived agency compared to a control with static sequencing within and between scenes. These findings demonstrate an effective architectural approach for LLM-based educational systems that successfully balances learner agency with pedagogical structure.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Cheng, Alan Y. and Zou, Carolyn Q. and Xie, Anthony and Hsu, Matthew and Yan, Felicia and Huang, Felicity and Zhang, David K. and Sharma, Arjun and Poole, Rashon and Wan Rosli, Daniel and Cuadra, Andrea and Pea, Roy and Landay, James A.},
	year = {2025},
}

@inproceedings{kassaie_exploiting_2025,
	address = {New York, NY, USA},
	series = {{DocEng} '25},
	title = {Exploiting {Query} {Reformulation} and {Reciprocal} {Rank} {Fusion} in {Math}-{Aware} {Search} {Engines}},
	isbn = {979-8-4007-1351-4},
	url = {https://doi.org/10.1145/3704268.3742687},
	doi = {10.1145/3704268.3742687},
	abstract = {Mathematical formulas introduce complications to the standard approaches used in information retrieval. By studying how traditional (sparse) search systems perform in matching queries to documents, we hope to gain insights into which features in the formulas and in the accompanying natural language text signal likely relevance.In this paper, we focus on query rewriting for the ARQMath benchmarks recently developed as part of CLEF, the Conference and Labs of the Evaluation Forum. In particular, we improve mathematical community question answering applications by using responses from a large language model (LLM) to reformulate queries. Beyond simply replacing the query by the LLM response or concatenating the response to the query, we explore whether improvements accrue from the LLM selecting a subset of the query terms, augmenting the query with additional terms, or re-weighting the query terms. We also examine whether such query reformulation is equally advantageous for math features extracted from formulas and for keyword terms. As a final step, we use reciprocal rank fusion (RRF) to combine several component approaches in order to improve ranking results. In two experiments involving real-world mathematical questions, we show that combining four strategies for term selection, term augmentation, and term re-weighting improves nDCG'@1000 by 5\%, MAP'@1000 by 7\%, and P'@10 by more than 9\% over using the question as given.},
	booktitle = {Proceedings of the 2025 {ACM} {Symposium} on {Document} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Kassaie, Besat and Kane, Andrew and Tompa, Frank Wm.},
	year = {2025},
	note = {event-place: Nottingham, United Kingdom},
	keywords = {ARQMath Lab, large language model (LLM), math-aware search engine, mathematical community question answering (Math CQA), Mathematical information retrieval (MIR), query reformulation},
}

@inproceedings{hegde_self_2025,
	address = {New York, NY, USA},
	series = {{AIMLSystems} '24},
	title = {Self {Supervised} {LLM} {Customizer}({SSLC}): {Customizing} {LLMs} on {Unlabeled} {Data} to {Enhance} {Contextual} {Question} {Answering}},
	isbn = {979-8-4007-1161-9},
	url = {https://doi.org/10.1145/3703412.3703421},
	doi = {10.1145/3703412.3703421},
	abstract = {While we can customize large language models (LLMs) on specific domains by finetuning using the domain specific labeled data, performance of the customized models is highly dependent on the quality of the labeled data. Obtaining high-quality labeled data for custom domains often requires considerable human effort and associated costs. However, in many cases, unlabeled data is readily available at little or no cost. Existing methods either rely on continued pre-training or use general purpose models trained for synthesis. But, continued pre-training necessitates vast amounts of data and adversely affects instruction tuned models. On the other hand, general purpose synthesis models might not capture the nuances of custom data. We present a framework (SSLC) for customizing LLMs using unlabeled text to enhance contextual question answering on custom data. Our approach employs few-shot synthesis using an instruction-tuned model, curates the synthesized data using a LLM response scorer and finetunes the model on this synthesized data. We demonstrate that the approach significantly improves contextual question answering performance compared to the baselines. It outperforms baselines in 75\% (9/12) of the experiments as evidenced by both quantitative and qualitative metrics. On an average, it outperforms un-customized models by 19.3 percentage points and state-of-the-art approach by 4.4 percentage points in human evaluation(proxy) accuracy.},
	booktitle = {Proceedings of the 4th {International} {Conference} on {AI}-{ML} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Hegde, Raveendra R and Sharma, Saurabh},
	year = {2025},
	keywords = {Language generation, LLM, Self Supervised},
}

@inproceedings{di_enhancing_2025,
	address = {Ottawa, Ontario, Canada},
	series = {{ICSE} '25},
	title = {Enhancing {Code} {Generation} via {Bidirectional} {Comment}-{Level} {Mutual} {Grounding}},
	isbn = {979-8-3315-0569-1},
	url = {https://doi.org/10.1109/ICSE55347.2025.00165},
	doi = {10.1109/ICSE55347.2025.00165},
	abstract = {Large Language Models (LLMs) have demonstrated unprecedented capability in code generation. However, LLM-generated code is still plagued with a wide range of functional errors, especially for complex programming tasks that LLMs have not seen before. Recent studies have shown that developers often struggle with inspecting and fixing incorrect code generated by LLMs, diminishing their productivity and trust in LLM-based code generation. Inspired by the mutual grounding theory in communication, we propose an interactive approach that leverages code comments as a medium for developers and LLMs to establish a shared understanding. Our approach facilitates iterative grounding by interleaving code generation, inline comment generation, and contextualized user feedback through editable comments to align generated code with developer intent. We evaluated our approach on two popular benchmarks and demonstrated that our approach significantly improved multiple state-of-the-art LLMs, e.g., 17.1\% pass@1 improvement for code-davinci-002 on HumanEval. Furthermore, we conducted a user study with 12 participants in comparison to two baselines: (1) interacting with GitHub Copilot, and (2) interacting with a multi-step code generation paradigm called Multi-Turn Program Synthesis. Participants completed the given programming tasks 16.7\% faster and with 10.5\% improvement in task success rate when using our approach. Both results show that interactively refining code comments enables the collaborative establishment of mutual grounding, leading to more accurate code generation and higher developer confidence.},
	booktitle = {Proceedings of the {IEEE}/{ACM} 47th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Di, Yifeng and Zhang, Tianyi},
	year = {2025},
	keywords = {code generation, code refinement, LLM},
	pages = {1359--1371},
}

@inproceedings{liu_symagent_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{SymAgent}: {A} {Neural}-{Symbolic} {Self}-{Learning} {Agent} {Framework} for {Complex} {Reasoning} over {Knowledge} {Graphs}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714768},
	doi = {10.1145/3696410.3714768},
	abstract = {Recent advancements have highlighted that Large Language Models (LLMs) are prone to hallucinations when solving complex reasoning problems, leading to erroneous results. To tackle this issue, researchers incorporate Knowledge Graphs (KGs) to improve the reasoning ability of LLMs. However, existing methods face two limitations: 1) they typically assume that all answers to the questions are contained in KGs, neglecting the incompleteness issue of KGs, and 2) they treat the KG as a static repository and overlook the implicit logical reasoning structures inherent in KGs. In this paper, we introduce SymAgent, an innovative neural-symbolic agent framework that achieves collaborative augmentation between KGs and LLMs. We conceptualize KGs as dynamic environments and transform complex reasoning tasks into a multi-step interactive process, enabling KGs to participate deeply in the reasoning process. SymAgent consists of two modules: Agent-Planner and Agent-Executor. The Agent-Planner leverages LLM's inductive reasoning capability to extract symbolic rules from KGs, guiding efficient question decomposition. The Agent-Executor autonomously invokes predefined action tools to integrate information from KGs and external documents, addressing the issues of KG incompleteness. Furthermore, we design a self-learning framework comprising online exploration and offline iterative policy updating phases, enabling the agent to automatically synthesize reasoning trajectories and improve performance. Experimental results demonstrate that SymAgent with weak LLM backbones (i.e., 7B series) yields better or comparable performance compared to various strong baselines. Further analysis reveals that our agent can identify missing triples, facilitating automatic KG updates.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Liu, Ben and Zhang, Jihai and Lin, Fangquan and Yang, Cheng and Peng, Min and Yin, Wotao},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {knowledge graph, large language model agent, self-learning},
	pages = {98--108},
}

@inproceedings{hu_aptness_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {{APTNESS}: {Incorporating} {Appraisal} {Theory} and {Emotion} {Support} {Strategies} for {Empathetic} {Response} {Generation}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3679687},
	doi = {10.1145/3627673.3679687},
	abstract = {Empathetic response generation is designed to comprehend the emotions of others and select the most appropriate strategies to assist them in resolving emotional challenges. Empathy can be categorized into cognitive empathy and affective empathy. The former pertains to the ability to understand and discern the emotional issues and situations of others, while the latter involves the capacity to provide comfort. To enhance one's empathetic abilities, it is essential to develop both these aspects. Therefore, we develop an innovative framework that combines retrieval augmentation and emotional support strategy integration. Our framework starts with the introduction of a comprehensive emotional palette for empathy. We then apply appraisal theory to decompose this palette and create a database of empathetic responses. This database serves as an external resource and enhances the LLM's empathy by integrating semantic retrieval mechanisms. Moreover, our framework places a strong emphasis on the proper articulation of response strategies. By incorporating emotional support strategies, we aim to enrich the model's capabilities in both cognitive and affective empathy, leading to a more nuanced and comprehensive empathetic response. Finally, we extract datasets ED and ET from the empathetic dialogue dataset EmpatheticDialogues and ExTES based on dialogue length. Experiments demonstrate that our framework can enhance the empathy ability of LLMs from both cognitive and affective empathy perspectives. Our code is released at https://github.com/CAS-SIAT-XinHai/APTNESS.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Hu, Yuxuan and Tan, Minghuan and Zhang, Chenwei and Li, Zixuan and Liang, Xiaodan and Yang, Min and Li, Chengming and Hu, Xiping},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {appraisal theory, emotional support strategy, empathetic response generation, empathy, retrieval augmented generation},
	pages = {900--909},
}

@inproceedings{singh_rags_2025,
	address = {New York, NY, USA},
	series = {{ICPE} '25},
	title = {{RAGs} to {Riches}: {Cost}-efficient {Complex} {Query} {Orchestration}},
	isbn = {979-8-4007-1130-5},
	url = {https://doi.org/10.1145/3680256.3721327},
	doi = {10.1145/3680256.3721327},
	abstract = {Large Language Models (LLMs) have become integral to modern business operations, especially for tasks involving reasoning over large datasets. One prominent application of LLMs is in chatbot systems, where customers provide natural language queries, often complex in nature, requiring decomposition to retrieve relevant information from various data sources. These queries may span structured databases, unstructured data, or public information from the internet, making efficient data retrieval and reasoning vital for real-time, accurate responses. In this paper, we propose two cost-efficient ”Query Orchestration” approaches (Context Latent and Context Acute) to address these challenges. By leveraging graph-based retrieval-augmented generation (RAG) techniques for vector search, we optimize data retrieval while minimizing reliance on LLMs for reasoning to reduce costs. Our approach is validated through experiments on a banking use case, where we demonstrate its effectiveness in providing high-quality},
	booktitle = {Companion of the 16th {ACM}/{SPEC} {International} {Conference} on {Performance} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Singh, Ravi Kumar and Singh, Kuldeep and Kunde, Shruti and Mishra, Mayank and Singhal, Rekha and Nambiar, Manoj},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {complex query, cost-efficient rag, query orchestration},
	pages = {114--120},
}

@inproceedings{xu_large_2025,
	address = {New York, NY, USA},
	series = {{CCEAI} '25},
	title = {Large {Language} {Models} for {HeXie} {Management} {Theory}: {A} {Comparative} {Evaluation} of {RAG} and {Finetuning}},
	isbn = {979-8-4007-1164-0},
	url = {https://doi.org/10.1145/3722150.3722167},
	doi = {10.1145/3722150.3722167},
	abstract = {HeXie Management Theory (HXMT) is a modern management theory for organizations. It provides macro-level considerations for both the internal mechanisms of an organization and its overall operational patterns. It has been utilized in organizations such as healthcare, rural construction, university management, and large-scale engineering projects and has proved useful. There are press demands for its wider adoption. Large Language Models (LLMs) have been widely used in natural language processing and content generation. Re-training LLMs will help them possess HeXie management theory, which can be useful. However, there are two popular methods to achieve this goal: fine-tuning and RAG; each approach has pros and cons. This paper reports our efforts in a comparative study of the two approaches. Our research employs datasets from HXMT and chooses the open-source platforms LlaMA-2, LlaMA-3, and ERNIE-Speed for fine-tuning based on four metrics and manual evaluations, with RAG we used ERNIE models with five dimensions. Our results show that the RAG-trained ERNIE-speed-App performs better than the fine-tuning training ERNIE-speed-8k model under the same training data volume. this may shed some light on similar applications where new theory needs to be integrated into an LLM to make it specialized for particular applications. Our work is available at https://alex17swim.com/hxjun2.},
	booktitle = {Proceedings of the 2025 9th {International} {Conference} on {Control} {Engineering} and {Artificial} {Intelligence}},
	publisher = {Association for Computing Machinery},
	author = {Xu, Yulu and Chen, Shishuo and Tang, Lisirui and Yun, Jiya and Li, Gangmin and Wang, Chengyu},
	year = {2025},
	keywords = {Finetune, HeXie Management Theory, Large Language Models, RAG},
	pages = {35--39},
}

@inproceedings{maslych_mitigating_2025,
	address = {New York, NY, USA},
	series = {{CUI} '25},
	title = {Mitigating {Response} {Delays} in {Free}-{Form} {Conversations} with {LLM}-powered {Intelligent} {Virtual} {Agents}},
	isbn = {979-8-4007-1527-3},
	url = {https://doi.org/10.1145/3719160.3736636},
	doi = {10.1145/3719160.3736636},
	abstract = {We investigated the challenges of mitigating response delays in free-form conversations with virtual agents powered by Large Language Models (LLMs) within Virtual Reality (VR). For this, we used conversational fillers, such as gestures and verbal cues, to bridge delays between user input and system responses and evaluate their effectiveness across various latency levels and interaction scenarios. We found that latency above 4 seconds degrades quality of experience, while natural conversational fillers improve perceived response time, especially in high-delay conditions. Our findings provide insights for practitioners and researchers to optimize user engagement whenever conversational systems’ responses are delayed by network limitations or slow hardware. We also contribute an open-source pipeline that streamlines deploying conversational agents in virtual environments.},
	booktitle = {Proceedings of the 7th {ACM} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Maslych, Mykola and Katebi, Mohammadreza and Lee, Christopher and Hmaiti, Yahya and Ghasemaghaei, Amirpouya and Pumarada, Christian and Palmer, Janneese and Segarra Martinez, Esteban and Emporio, Marco and Snipes, Warren and McMahan, Ryan P. and LaViola Jr., Joseph J.},
	year = {2025},
	keywords = {Conversational interfaces, LLM, response latency., user study, VR},
}

@inproceedings{khurana_why_2024,
	address = {New York, NY, USA},
	series = {{IUI} '24},
	title = {Why and {When} {LLM}-{Based} {Assistants} {Can} {Go} {Wrong}: {Investigating} the {Effectiveness} of {Prompt}-{Based} {Interactions} for {Software} {Help}-{Seeking}},
	isbn = {979-8-4007-0508-3},
	url = {https://doi.org/10.1145/3640543.3645200},
	doi = {10.1145/3640543.3645200},
	abstract = {Large Language Model (LLM) assistants, such as ChatGPT, have emerged as potential alternatives to search methods for helping users navigate complex, feature-rich software. LLMs use vast training data from domain-specific texts, software manuals, and code repositories to mimic human-like interactions, offering tailored assistance, including step-by-step instructions. In this work, we investigated LLM-generated software guidance through a within-subject experiment with 16 participants and follow-up interviews. We compared a baseline LLM assistant with an LLM optimized for particular software contexts, SoftAIBot, which also offered guidelines for constructing appropriate prompts. We assessed task completion, perceived accuracy, relevance, and trust. Surprisingly, although SoftAIBot outperformed the baseline LLM, our results revealed no significant difference in LLM usage and user perceptions with or without prompt guidelines and the integration of domain context. Most users struggled to understand how the prompt’s text related to the LLM’s responses and often followed the LLM’s suggestions verbatim, even if they were incorrect. This resulted in difficulties when using the LLM’s advice for software tasks, leading to low task completion rates. Our detailed analysis also revealed that users remained unaware of inaccuracies in the LLM’s responses, indicating a gap between their lack of software expertise and their ability to evaluate the LLM’s assistance. With the growing push for designing domain-specific LLM assistants, we emphasize the importance of incorporating explainable, context-aware cues into LLMs to help users understand prompt-based interactions, identify biases, and maximize the utility of LLM assistants.},
	booktitle = {Proceedings of the 29th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Khurana, Anjali and Subramonyam, Hariharan and Chilana, Parmit K},
	year = {2024},
	note = {event-place: Greenville, SC, USA},
	keywords = {feature-rich software, help-seeking, large language models, prompt-based interactions},
	pages = {288--303},
}

@inproceedings{kazemitabaar_codeaid_2024,
	address = {New York, NY, USA},
	series = {{CHI} '24},
	title = {{CodeAid}: {Evaluating} a {Classroom} {Deployment} of an {LLM}-based {Programming} {Assistant} that {Balances} {Student} and {Educator} {Needs}},
	isbn = {979-8-4007-0330-0},
	url = {https://doi.org/10.1145/3613904.3642773},
	doi = {10.1145/3613904.3642773},
	abstract = {Timely, personalized feedback is essential for students learning programming. LLM-powered tools like ChatGPT offer instant support, but reveal direct answers with code, which may hinder deep conceptual engagement. We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions. CodeAid answers conceptual questions, generates pseudo-code with line-by-line explanations, and annotates student’s incorrect code with fix suggestions. We deployed CodeAid in a programming class of 700 students for a 12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed, further enriched by weekly surveys, and 22 student interviews. We then interviewed eight programming educators to gain further insights. Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI’s unique benefits; D2) simplifying query formulation while promoting cognitive engagement; D3) avoiding direct responses while encouraging motivated learning; and D4) maintaining transparency and control for students to asses and steer AI responses.},
	booktitle = {Proceedings of the 2024 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kazemitabaar, Majeed and Ye, Runlong and Wang, Xiaoning and Henley, Austin Zachary and Denny, Paul and Craig, Michelle and Grossman, Tovi},
	year = {2024},
	note = {event-place: Honolulu, HI, USA},
	keywords = {AI assistants, AI tutoring, class deployment, design guidelines, educational technology, generative AI, intelligent tutoring systems, large language models, programming education},
}

@inproceedings{wang_rap-gen_2023,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE} 2023},
	title = {{RAP}-{Gen}: {Retrieval}-{Augmented} {Patch} {Generation} with {CodeT5} for {Automatic} {Program} {Repair}},
	isbn = {979-8-4007-0327-0},
	url = {https://doi.org/10.1145/3611643.3616256},
	doi = {10.1145/3611643.3616256},
	abstract = {Automatic program repair (APR) is crucial to reduce manual debugging efforts for developers and improve software reliability. While conventional search-based techniques typically rely on heuristic rules or a redundancy assumption to mine fix patterns, recent years have witnessed the surge of deep learning (DL) based approaches to automate the program repair process in a data-driven manner. However, their performance is often limited by a fixed set of parameters to model the highly complex search space of APR. To ease such burden on the parametric models, in this work, we propose a novel Retrieval-Augmented Patch Generation framework (RAP-Gen) by explicitly leveraging relevant fix patterns retrieved from a codebase of previous bug-fix pairs. Specifically, we build a hybrid patch retriever to account for both lexical and semantic matching based on the raw source code in a language-agnostic manner, which does not rely on any code-specific features. In addition, we adapt a code-aware language model CodeT5 as our foundation model to facilitate both patch retrieval and generation tasks in a unified manner. We adopt a stage-wise approach where the patch retriever first retrieves a relevant external bug-fix pair to augment the buggy input for the CodeT5 patch generator, which synthesizes a ranked list of repair patch candidates. Notably, RAP-Gen is a generic APR framework that can flexibly integrate different patch retrievers and generators to repair various types of bugs. We thoroughly evaluate RAP-Gen on three benchmarks in two programming languages, including the TFix benchmark in JavaScript, and Code Refinement and Defects4J benchmarks in Java, where the bug localization information may or may not be provided. Experimental results show that RAP-Gen significantly outperforms previous state-of-the-art (SoTA) approaches on all benchmarks, e.g., boosting the accuracy of T5-large on TFix from 49.70\% to 54.15\% (repairing 478 more bugs) and repairing 15 more bugs on 818 Defects4J bugs. Further analysis reveals that our patch retriever can search for relevant fix patterns to guide the APR systems.},
	booktitle = {Proceedings of the 31st {ACM} {Joint} {European} {Software} {Engineering} {Conference} and {Symposium} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Weishi and Wang, Yue and Joty, Shafiq and Hoi, Steven C.H.},
	year = {2023},
	note = {event-place: San Francisco, CA, USA},
	keywords = {Automated program repair, Neural networks, Pretrained language models, Retrieval-augmented generation},
	pages = {146--158},
}

@inproceedings{li_mm-forecast_2024,
	address = {New York, NY, USA},
	series = {{MM} '24},
	title = {{MM}-{Forecast}: {A} {Multimodal} {Approach} to {Temporal} {Event} {Forecasting} with {Large} {Language} {Models}},
	isbn = {979-8-4007-0686-8},
	url = {https://doi.org/10.1145/3664647.3681593},
	doi = {10.1145/3664647.3681593},
	abstract = {We study an emerging and intriguing problem of multimodal temporal event forecasting with large language models. Compared to using text or graph modalities, the investigation of utilizing images for temporal event forecasting has not been fully explored, especially in the era of large language models (LLMs). To bridge this gap, we are particularly interested in two key questions of: 1) why images will help in temporal event forecasting, and 2) how to integrate images into the LLM-based forecasting framework. To answer these research questions, we propose to identify two essential functions that images play in the scenario of temporal event forecasting, i.e., highlighting and complementary. Then, we develop a novel framework, named MM-Forecast. It employs an Image Function Identification module to recognize these functions as verbal descriptions using multimodal large language models (MLLMs), and subsequently incorporates these function descriptions into LLM-based forecasting models. To evaluate our approach, we construct a new multimodal dataset, MidEast-TE-mm, by extending an existing event dataset MidEast-TE-mini with images. Empirical studies demonstrate that our MM-Forecast can correctly identify the image functions, and further more, incorporating these verbal function descriptions significantly improves the forecasting performance. The dataset, code, and prompts are available at https://github.com/LuminosityX/MM-Forecast.},
	booktitle = {Proceedings of the 32nd {ACM} {International} {Conference} on {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Li, Haoxuan and Yang, Zhengmao and Ma, Yunshan and Bin, Yi and Yang, Yang and Chua, Tat-Seng},
	year = {2024},
	note = {event-place: Melbourne VIC, Australia},
	keywords = {multimodal event forecasting, multimodal large language model, temporal event forecasting},
	pages = {2776--2785},
}

@inproceedings{zhou_instructpipe_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{InstructPipe}: {Generating} {Visual} {Blocks} {Pipelines} with {Human} {Instructions} and {LLMs}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713905},
	doi = {10.1145/3706598.3713905},
	abstract = {Visual programming has the potential of providing novice programmers with a low-code experience to build customized processing pipelines. Existing systems typically require users to build pipelines from scratch, implying that novice users are expected to set up and link appropriate nodes from a blank workspace. In this paper, we introduce InstructPipe, an AI assistant for prototyping machine learning (ML) pipelines with text instructions. We contribute two large language model (LLM) modules and a code interpreter as part of our framework. The LLM modules generate pseudocode for a target pipeline, and the interpreter renders the pipeline in the node-graph editor for further human-AI collaboration. Both technical and user evaluation (N=16) shows that InstructPipe empowers users to streamline their ML pipeline workflow, reduce their learning curve, and leverage open-ended commands to spark innovative ideas.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhou, Zhongyi and Jin, Jing and Phadnis, Vrushank and Yuan, Xiuxiu and Jiang, Jun and Qian, Xun and Wright, Kristen and Sherwood, Mark and Mayes, Jason and Zhou, Jingtao and Huang, Yiyi and Xu, Zheng and Zhang, Yinda and Lee, Johnny and Olwal, Alex and Kim, David and Iyengar, Ram and Li, Na and Du, Ruofei},
	year = {2025},
	keywords = {Deep Learning, Deep Neural Networks, Graph Compiler, Large Language Models, Low-code Development, Node-graph Editor, Visual Analytics, Visual Programming, Visual Prototyping},
}

@inproceedings{qian_shape-it_2024,
	address = {New York, NY, USA},
	series = {{UIST} '24},
	title = {{SHAPE}-{IT}: {Exploring} {Text}-to-{Shape}-{Display} for {Generative} {Shape}-{Changing} {Behaviors} with {LLMs}},
	isbn = {979-8-4007-0628-8},
	url = {https://doi.org/10.1145/3654777.3676348},
	doi = {10.1145/3654777.3676348},
	abstract = {This paper introduces text-to-shape-display, a novel approach to generating dynamic shape changes in pin-based shape displays through natural language commands. By leveraging large language models (LLMs) and AI-chaining, our approach allows users to author shape-changing behaviors on demand through text prompts without programming. We describe the foundational aspects necessary for such a system, including the identification of key generative elements (primitive, animation, and interaction) and design requirements to enhance user interaction, based on formative exploration and iterative design processes. Based on these insights, we develop SHAPE-IT, an LLM-based authoring tool for a 24 x 24 shape display, which translates the user’s textual command into executable code and allows for quick exploration through a web-based control interface. We evaluate the effectiveness of SHAPE-IT in two ways: 1) performance evaluation and 2) user evaluation (N= 10). The study conclusions highlight the ability to facilitate rapid ideation of a wide range of shape-changing behaviors with AI. However, the findings also expose accuracy-related challenges and limitations, prompting further exploration into refining the framework for leveraging AI to better suit the unique requirements of shape-changing systems.},
	booktitle = {Proceedings of the 37th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Qian, Wanli and Gao, Chenfeng and Sathya, Anup and Suzuki, Ryo and Nakagaki, Ken},
	year = {2024},
	note = {event-place: Pittsburgh, PA, USA},
	keywords = {Code-Generation, LLMs, Shape Display, Text-based Authoring},
}

@inproceedings{djeffal_reflexive_2025,
	address = {New York, NY, USA},
	series = {{FAccT} '25},
	title = {Reflexive {Prompt} {Engineering}: {A} {Framework} for {Responsible} {Prompt} {Engineering} and {AI} {Interaction} {Design}},
	isbn = {979-8-4007-1482-5},
	url = {https://doi.org/10.1145/3715275.3732118},
	doi = {10.1145/3715275.3732118},
	abstract = {Responsible prompt engineering has emerged as a critical pracitce for ensuring that generative artificial intelligence (AI) systems are aligned with ethical, legal, and social principles. As generative AI applications become increasingly powerful and ubiquitous, the way we instruct and interact with them through prompts has profound implications for fairness, accountability, and transparency. It is, therefore, necessary to examine how strategic prompt engineering can embed ethical and legal considerations and societal values directly into AI interactions, moving beyond mere technical optimization for functionality. This article proposes “Reflexive Prompt Engineering”, a comprehensive framework for responsible prompt engineering that encompasses five interconnected components: prompt design, system selection, system configuration, performance evaluation, and prompt management. Drawing from empirical evidence, the paper demonstrates how each component can be leveraged to promote improved societal outcomes while mitigating potential risks. The analysis reveals that effective prompt engineering requires a delicate balance between technical precision and ethical consciousness, combining the systematic rigor and focus on functionality with the nuanced understanding of social impact. Through examination of emerging practices, this article illustrates how responsible prompt engineering serves as a crucial connection between AI development and deployment, enabling organizations to align AI outputs without modifying underlying model architectures. This approach links with broader “Responsibility by Design” principles, embedding ethical considerations directly into the implementation process rather than treating them as post-hoc additions. The article concludes by identifying key research directions and practical guidelines for advancing the field of responsible prompt engineering as an essential component of AI literacy.},
	booktitle = {Proceedings of the 2025 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Djeffal, Christian},
	year = {2025},
	keywords = {Accountability, AI alignment, AI Ethics, AI Governance, Human-AI Interaction, Prompt Engineering, Responsible AI},
	pages = {1757--1768},
}

@inproceedings{malaborbor_enhancing_2024,
	address = {New York, NY, USA},
	series = {{ICDTE} '24},
	title = {Enhancing {Data} {Privacy} {Literacy} through {Conversational} {AI}: {A} {QandA}-{Based} {Approach} to {Educating} {Users} on the {Provisions} of the {Data} {Privacy} {Act} of 2012},
	isbn = {979-8-4007-1757-4},
	url = {https://doi.org/10.1145/3696230.3696247},
	doi = {10.1145/3696230.3696247},
	abstract = {With the advent of the digital age, data privacy has become increasingly relevant, provoking widespread concern and attention. As technology facilitates increased communication and automation in various aspects of life, companies and organizations must protect personal information. The National Privacy Commission (NPC) enforces the Data Privacy Act of 2012, which protects individuals' privacy rights. Despite legislative efforts, public awareness of data privacy remains low, leaving individuals vulnerable to cybercrime. To address this gap, this study proposes the development of a Question Answering (Q\&amp;A) system leveraging LangChain technology and llama cpp Large Language Models (LLMs) to educate individuals about the Data Privacy Act of 2012. It proposes a methodology that utilizes document embeddings, vector storage, and semantic search techniques to facilitate efficient Q\&amp;A processing. As part of the performance evaluation, BLEU, METEOR, and ROUGE metrics are used. These metrics demonstrate varying degrees of alignment between candidate responses and reference texts. Results show varying levels of alignment between candidate responses and reference texts. This includes notable strengths in addressing certain queries, but also areas for improvement. Overall, the study underscores the importance of leveraging advanced technologies to educate individuals about data privacy rights and responsibilities.},
	booktitle = {Proceedings of the 2024 8th {International} {Conference} on {Digital} {Technology} in {Education} ({ICDTE})},
	publisher = {Association for Computing Machinery},
	author = {Malaborbor, Rose Ann Caparas and Rivera, Vincent Sulit and Diloy, Marlon A. and De Luna, Leandro R. and Dela Cruz, Aira Leigh Y. and Velasco, Abigail T.},
	year = {2024},
	keywords = {A System, BLEU, LangChain technology, llama cpp Large Language Models (LLMs), METEOR, Q\&amp, Retrieval-Augmented Generation (RAG) framework, ROUGE},
	pages = {271--276},
}

@inproceedings{futamura_itochat2024_2025,
	address = {New York, NY, USA},
	series = {{ICEA} '24},
	title = {{iTOChat2024}: {Development} and {Evaluation} of a {Department} {Recommendation} {Bot} for {Open} {Campus}},
	isbn = {979-8-4007-1166-4},
	url = {https://doi.org/10.1145/3732437.3732766},
	doi = {10.1145/3732437.3732766},
	abstract = {Many high school students struggle to determine which university department suits their interests based on limited information from websites or open campuses. In particular, in the case of the School of Engineering at Kyushu University, 12 different departments are divided into five groups, with one of the departments joining two groups, and a special group called Group VI, where all students who belong to this group have the opportunity to join any department when they become sophomores. This complex system makes it difficult for high school students to determine which department best suits their aptitudes. To alleviate this problem, we present iTOChat2024, a mobile department recommendation system designed for high school students attending the open campus of the School of Engineering, Kyushu University, which uses ChatGPT for its recommendations. It prompts high school students to enter information according to specific questions, and based on their responses, ChatGPT provides a ranked list of recommended departments along with the reasons for the recommendations and keywords representing the students’ interests. This paper describes the features of iTOChat2024 and discusses the evaluation results of student satisfaction and an analysis of the actual recommendations generated during the open campus event.},
	booktitle = {Proceedings of the 2024 {International} {Conference} on {Intelligent} {Computing} and {Its} {Emerging} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Futamura, Sho and Nakao, Isshin and Kita, Shusaku and Fujimoto, Ryusei and Mine, Tsunenori},
	year = {2025},
	keywords = {chatbot, large language model (LLM), mobile recommendation systems},
	pages = {50--56},
}

@inproceedings{chen_chineseecomqa_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{ChineseEcomQA}: {A} {Scalable} {E}-commerce {Concept} {Evaluation} {Benchmark} for {Large} {Language} {Models}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737374},
	doi = {10.1145/3711896.3737374},
	abstract = {With the increasing use of Large Language Models (LLMs) in fields such as e-commerce, domain-specific concept evaluation benchmarks are crucial for assessing their domain capabilities. Existing LLMs may generate factually incorrect information within the complex e-commerce applications. Therefore, it is necessary to build an e-commerce concept benchmark. Existing benchmarks encounter two primary challenges: (1) handle the heterogeneous and diverse nature of tasks(2) distinguish between generality and specificity within the e-commerce field. To address these problems, we propose ChineseEcomQA, a scalable question-answering benchmark focused on fundamental e-commerce concepts. ChineseEcomQA is built on three core characteristics: Focus on Fundamental Concept, E-commerce Generality and E-commerce Expertise. Fundamental concepts are designed to be applicable across a diverse array of e-commerce tasks, thus addressing the challenge of heterogeneity and diversity. Additionally, by carefully balancing generality and specificity, ChineseEcomQA effectively differentiates between broad e-commerce concepts, allowing for precise validation of domain capabilities. We achieve this through a scalable benchmark construction process that combines LLM validation, Retrieval-Augmented Generation (RAG) validation, and rigorous manual annotation. Based on ChineseEcomQA, we conduct extensive evaluations on mainstream LLMs and provide some valuable insights. We hope that ChineseEcomQA could guide future domain-specific evaluations, and facilitate broader LLM adoption in e-commerce applications.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Chen, Haibin and Lv, Kangtao and Hu, Chengwei and Li, Yanshi and Yuan, Yujin and He, Yancheng and Zhang, Xingyao and Liu, Langming and Liu, Shilei and Su, Wenbo and Zheng, Bo},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {benchmark, e-commerce, large language models},
	pages = {5311--5321},
}

@inproceedings{duvvuru_llm-agents_2025,
	address = {Ottawa, Ontario, Canada},
	series = {{ICSE} '25},
	title = {{LLM}-{Agents} {Driven} {Automated} {Simulation} {Testing} and {Analysis} of small {Uncrewed} {Aerial} {Systems}},
	isbn = {979-8-3315-0569-1},
	url = {https://doi.org/10.1109/ICSE55347.2025.00223},
	doi = {10.1109/ICSE55347.2025.00223},
	abstract = {Thorough simulation testing is crucial for validating the correct behavior of small Uncrewed Aerial Systems (sUAS) across multiple scenarios, including adverse weather conditions (such as wind, and fog), diverse settings (hilly terrain, or urban areas), and varying mission profiles (surveillance, tracking). While various sUAS simulation tools exist to support developers, the entire process of creating, executing, and analyzing simulation tests remains a largely manual and cumbersome task. Developers must identify test scenarios, set up the simulation environment, integrate the System under Test (SuT) with simulation tools, formulate mission plans, and collect and analyze results. These labor-intensive tasks limit the ability of developers to conduct exhaustive testing across a wide range of scenarios. To alleviate this problem, in this paper, we propose AutoSimTest, a Large Language Model (LLM)-driven framework, where multiple LLM agents collaborate to support the sUAS simulation testing process. This includes: (1) creating test scenarios that subject the SuT to unique environmental contexts; (2) preparing the simulation environment as per the test scenario; (3) generating diverse sUAS missions for the SuT to execute; and (4) analyzing simulation results and providing an interactive analytics interface. Further, the design of the framework is flexible for creating and testing scenarios for a variety of sUAS use cases, simulation tools, and SuT input requirements. We evaluated our approach by (a) conducting simulation testing of PX4 and ArduPilot flight-controller-based SuTs, (b) analyzing the performance of each agent, and (c) gathering feedback from sUAS developers. Our findings indicate that AutoSimTest significantly improves the efficiency and scope of the sUAS testing process, allowing for more comprehensive and varied scenario evaluations while reducing the manual effort.},
	booktitle = {Proceedings of the {IEEE}/{ACM} 47th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Duvvuru, Venkata Sai Aswath and Zhang, Bohan and Vierhauser, Michael and Agrawal, Ankit},
	year = {2025},
	keywords = {AI for SE, simulation testing, sUAS},
	pages = {385--397},
}

@inproceedings{tuck_llms_2025,
	address = {New York, NY, USA},
	series = {{IWSPA} '25},
	title = {{LLMs} {Under} {Attack}: {Understanding} the {Adversarial} {Mindset}},
	isbn = {979-8-4007-1501-3},
	url = {https://doi.org/10.1145/3716815.3729018},
	doi = {10.1145/3716815.3729018},
	abstract = {With Large Language Models (LLMs) powering critical applications, adversarial threats present urgent challenges to their safety and reliability. This tutorial explores adversarial threats against LLMs by covering foundational concepts, identifying key security implications, examining specific attack vectors (such as data poisoning, evasion techniques, and prompt-engineering vulnerabilities), and highlighting LLMs' dual roles as both targets and enablers of malicious activity. We critically assess current defensive approaches, discuss recent criticisms regarding detection reliability and ethical considerations, and outline key open research challenges. Attendees will gain practical insights into anticipating and mitigating adversarial threats to secure the deployment and application of LLM systems.},
	booktitle = {Proceedings of the 10th {ACM} {International} {Workshop} on {Security} and {Privacy} {Analytics}},
	publisher = {Association for Computing Machinery},
	author = {Tuck, Bryan E.},
	year = {2025},
	note = {event-place: Pittsburgh, PA, USA},
	keywords = {adversarial machine learning, content detection, large language models, nlp security, prompt engineering, tutorial},
	pages = {34--35},
}

@inproceedings{yu_llm-guided_2025,
	address = {New York, NY, USA},
	series = {{GECCO} '25 {Companion}},
	title = {{LLM}-{Guided} {Evolution}: {An} {Autonomous} {Model} {Optimization} for {Object} {Detection}},
	isbn = {979-8-4007-1464-1},
	url = {https://doi.org/10.1145/3712255.3734340},
	doi = {10.1145/3712255.3734340},
	abstract = {In machine learning, Neural Architecture Search (NAS) requires domain knowledge of model design and a large amount of trial-and-error to achieve promising performance. Meanwhile, evolutionary algorithms have traditionally relied on fixed rules and pre-defined building blocks. The Large Language Model (LLM)-Guided Evolution (GE) framework transformed this approach by incorporating LLMs to directly modify model source code for image classification algorithms on CIFAR data and intelligently guide mutations and crossovers. A key element of LLM-GE is the "Evolution of Thought" (EoT) technique, which establishes feedback loops, allowing LLMs to refine their decisions iteratively based on how previous operations performed. In this study, we perform NAS for object detection by improving LLM-GE to modify the architecture of You Only Look Once (YOLO) models to enhance performance on the KITTI dataset. Our approach intelligently adjusts the design and settings of YOLO to find the optimal algorithms against objective such as detection accuracy and speed. We show that LLM-GE produced variants with significant performance improvements, such as an increase in Mean Average Precision from 92.5\% to 94.5\%. This result highlights the flexibility and effectiveness of LLM-GE on real-world challenges, offering a novel paradigm for automated machine learning that combines LLM-driven reasoning with evolutionary strategies.},
	booktitle = {Proceedings of the {Genetic} and {Evolutionary} {Computation} {Conference} {Companion}},
	publisher = {Association for Computing Machinery},
	author = {Yu, YiMing and Zutty, Jason},
	year = {2025},
	note = {event-place: NH Malaga Hotel, Malaga, Spain},
	keywords = {automated machine learning, computer aided/automated design, large language models, neuroevolution},
	pages = {2363--2370},
}

@inproceedings{tang_this_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {"{This} is {My} {Fault}", {Really}? {Understanding} {Blind} and {Low}-{Vision} {People}’s {Perception} of {Hallucination} in {Large} {Vision} {Language} {Models}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747597},
	doi = {10.1145/3746059.3747597},
	abstract = {Visual question-answering (VQA) tools powered by large visual language models (LVLMs) are used to assist blind and low-vision (BLV) individuals in overcoming visual challenges, raising concerns about hallucinations and associated risks. Existing literature overlooks the variations of hallucinations across distinct usage scenarios and types in the context of VQA for BLV people, resulting in limited understanding of their perceptions and insufficient guidance for targeted mitigation strategies. By analyzing 3,467 real-world VQA cases from BLV users, we developed a manifestation-scenario-based dual-dimensional hallucination typology, uncovering eight scenarios and five types of hallucinations. Through interviews with 16 BLV users, we examined their awareness levels, detection strategies, mental models of hallucinations, and their tolerance of associated risks, identifying key gaps between their perceptions and real situations. By designing with 12 BLV users, we uncovered their expectations for hallucination-mitigating solutions, including enhanced information provision, transparency in processing, verification strategies, and feedback mechanisms.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Tang, Yilin and Fang, Yuyang and Wang, Tianle and Sun, Lingyun and Chen, Liuqing},
	year = {2025},
	keywords = {Artificial intelligence (AI), Blind and low vision, Hallucination, Human-centered AI, Large visual language models (LVLMs)},
}

@inproceedings{sagtani_improving_2025,
	address = {New York, NY, USA},
	series = {{WSDM} '25},
	title = {Improving {FIM} {Code} {Completions} via {Context} \&amp; {Curriculum} {Based} {Learning}},
	isbn = {979-8-4007-1329-3},
	url = {https://doi.org/10.1145/3701551.3703563},
	doi = {10.1145/3701551.3703563},
	abstract = {Fill-in-the-Middle (FIM) models play a vital role in code completion tasks, leveraging both prefix and suffix context to provide more accurate and contextually relevant suggestions. This paper presents approaches to improve FIM code completion while addressing the challenge of maintaining low latency for real-time coding assistance. We enhance FIM code completion by incorporating context and curriculum examples in the training process. We identify patterns where completion suggestions fail more frequently, revealing complexities that smaller language models struggle with. To address these challenges, we develop a curriculum dataset by extracting hard-to-complete patterns from code repositories and generate context examples using semantic and static analysis tools (e.g. TSC compiler). We fine-tune various sized models, including StarCoder and DeepSeek, on this enhanced dataset. Our evaluation encompasses three key dimensions: the Santa Coder FIM task, the Amazon CCEval benchmark, and a new Multi-Line Infilling evaluation benchmark derived from SWE-bench. Comprehensive ablation studies across multiple model sizes reveal that while all fine-tuned models show improvements, the performance gains are more pronounced for smaller parameter models and that incorporating difficult-to-complete examples as part of curriculum learning improves completion performance. This finding is particularly sig- nificant given the latency constraints of code completion tasks. While larger models like GPT and Claude perform well in multi- line completions but are prohibitively challenging to use given high latency, and our fine-tuned models achieve a balance between per- formance and latency. Finally, we validate our approach through online A/B testing, demonstrating tangible improvements in Completion Acceptance Rate (CAR) and Completion Persistence Rate (CPR), with zero latency impact.},
	booktitle = {Proceedings of the {Eighteenth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Sagtani, Hitesh and Mehrotra, Rishabh and Liu, Beyang},
	year = {2025},
	note = {event-place: Hannover, Germany},
	keywords = {a/b-testing, code completions, large language model},
	pages = {801--810},
}

@inproceedings{treanor_slice_2025,
	address = {New York, NY, USA},
	series = {{FDG} '25},
	title = {Slice of {Life}: {A} {Social} {Physics} {Game} with {Interactive} {Conversations} using {Symbolically} {Grounded} {LLM}-{Based} {Generative} {Dialogue}},
	isbn = {979-8-4007-1856-4},
	url = {https://doi.org/10.1145/3723498.3723806},
	doi = {10.1145/3723498.3723806},
	abstract = {This paper describes the social physics game Slice of Life. In Slice of Life, the player strives to achieve various social goals by choosing social interactions for characters to engage in. These interactions are governed by a social simulation system called Ensemble with Social Practices (ESP). The ways to achieve the player’s social goals are numerous and any given playthrough of the game will result in drastically different social worlds. Slice of Life also makes use of the underlying social simulation system’s detailed state to generate symbolically grounded prompts for a large language model (LLM) that generates context-appropriate character dialogue. Rather than using LLMs for novelty or for economic reasons, the underlying social simulation technology, we argue, necessitates this approach in order to make it feasible to have nuanced dialogue that reflects the many ways characters could have gotten themselves into particular social situations. The purpose of this paper is to provide a detailed account of Slice of Life’s design, how its social physics simulation enables interactive conversations based on social practices, and to illustrate how the generative possibilities of LLMs can be uniquely useful when applied as its natural language generation (NLG) system, without giving up authorial control of the gameplay or story.},
	booktitle = {Proceedings of the 20th {International} {Conference} on the {Foundations} of {Digital} {Games}},
	publisher = {Association for Computing Machinery},
	author = {Treanor, Mike and Samuel, Ben and Nelson, Mark J.},
	year = {2025},
	keywords = {Large Language Models, Playable Experiences, Social Simulation},
}

@inproceedings{guo_multimodal_2025,
	address = {New York, NY, USA},
	series = {{ICMI} '25},
	title = {Multimodal {Behavioral} {Patterns} {Analysis} with {Eye}-{Tracking} and {LLM}-{Based} {Reasoning}},
	isbn = {979-8-4007-1499-3},
	url = {https://doi.org/10.1145/3716553.3750787},
	doi = {10.1145/3716553.3750787},
	abstract = {Eye-tracking data reveals valuable insights into users’ cognitive states but is difficult to analyze due to its structured, non-linguistic nature. While large language models (LLMs) excel at reasoning over text, they struggle with temporal and numerical data. This paper presents a multimodal human–AI collaborative framework designed to enhance cognitive pattern extraction from eye-tracking signals. The framework includes: (1) a multi-stage pipeline using horizontal and vertical segmentation alongside LLM reasoning to uncover latent gaze patterns; (2) an Expert–Model Co-Scoring Module that integrates expert judgment with LLM output to generate trust scores for behavioral interpretations; and (3) a hybrid anomaly detection module combining LSTM-based temporal modeling with LLM-driven semantic analysis. Our results across several LLMs and prompt strategies show improvements in consistency, interpretability, and performance, with up to 50\% accuracy in difficulty prediction tasks. This approach offers a scalable, interpretable solution for cognitive modeling and has broad potential in adaptive learning, human–computer interaction, and educational analytics.},
	booktitle = {Proceedings of the 27th {International} {Conference} on {Multimodal} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Guo, Dongyang and Abdrabou, Yasmeen and Thaqi, Enkeleda and Kasneci, Enkelejda},
	year = {2025},
	keywords = {Behavioral Patterns, Educational Technology, Eye Tracking, Human-AI Interaction, LLM, Multimodal Analysis},
	pages = {475--484},
}

@inproceedings{gebelli_personalised_2025,
	address = {Melbourne, Australia},
	series = {{HRI} '25},
	title = {Personalised {Explainable} {Robots} {Using} {LLMs}},
	abstract = {In the field of Human-Robot Interaction (HRI), a key challenge lies in enabling humans to comprehend the decisions and behaviours of robots. One promising approach involves leveraging Theory of Mind (ToM) frameworks, wherein a robot estimates the mental model that a user holds about its functioning and compares this with the representation of its internal mental model. This comparison allows the robot to identify potential mismatches and generate communicative actions to bridge such gaps. Effective communication requires the robot to maintain unique mental models for each user and personalise explanations based on past interactions. To address this, we propose an architecture grounded in Large Language Models (LLMs) that operationalises this theoretical framework. We demonstrate the feasibility of this approach through qualitative examples, showcasing responses provided by a robot patrolling a geriatric hospital.},
	booktitle = {Proceedings of the 2025 {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {IEEE Press},
	author = {Gebellí, Ferran and Hriscu, Lavinia and Ros, Raquel and Lemaignan, Séverin and Sanfeliu, Alberto and Garrell, Anaís},
	year = {2025},
	keywords = {explainability, llm, personalisation, xhri},
	pages = {1304--1308},
}

@inproceedings{schneider_engineering_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Engineering {Prompts} for {Spatial} {Questions}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3717807},
	doi = {10.1145/3701716.3717807},
	abstract = {Large Language Models (LLMs) are often used for tasks that involve reasoning about the physical world, like recommending travel itineraries. However, success at these tasks requires the LLM to have been exposed to the relevant places, which is not true for lesser-known or alternatively named places, like Indigenous place names. Our prompting technique handles this issue using Retrieval Augmented Generation, encoding a spatial graph of common places and a mapping to their Indigenous alternatives. Our method improves LLM performance on spatial tasks involving lesser-known place names, thus advancing AI fairness.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Schneider, Nicole R. and Ramachandran, Nandini and O'Sullivan, Kent and Samet, Hanan},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	pages = {1633--1634},
}

@inproceedings{yan_assertllm_2025,
	address = {New York, NY, USA},
	series = {{ASPDAC} '25},
	title = {{AssertLLM}: {Generating} {Hardware} {Verification} {Assertions} from {Design} {Specifications} via {Multi}-{LLMs}},
	isbn = {979-8-4007-0635-6},
	url = {https://doi.org/10.1145/3658617.3697756},
	doi = {10.1145/3658617.3697756},
	abstract = {Assertion-based verification (ABV) is a critical method to ensure logic designs comply with their architectural specifications. ABV requires assertions, which are generally converted from specifications through human interpretation by verification engineers. Existing methods for generating assertions from specification documents are limited to sentences extracted by engineers, discouraging their practical applications. In this work, we present AssertLLM, an automatic assertion generation framework that processes complete specification documents. AssertLLM can generate assertions from both natural language and waveform diagrams in specification files. It first converts unstructured specification sentences and waveforms into structured descriptions using natural language templates. Then, a customized Large Language Model (LLM) generates the final assertions based on these descriptions. Our evaluation demonstrates that AssertLLM can generate more accurate and higher-quality assertions compared to GPT-4o and GPT-3.5.},
	booktitle = {Proceedings of the 30th {Asia} and {South} {Pacific} {Design} {Automation} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Yan, Zhiyuan and Fang, Wenji and Li, Mengming and Li, Min and Liu, Shang and Xie, Zhiyao and Zhang, Hongce},
	year = {2025},
	note = {event-place: Tokyo, Japan},
	pages = {614--621},
}

@inproceedings{rao_riskrag_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{RiskRAG}: {A} {Data}-{Driven} {Solution} for {Improved} {AI} {Model} {Risk} {Reporting}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713979},
	doi = {10.1145/3706598.3713979},
	abstract = {Risk reporting is essential for documenting AI models, yet only 14\% of model cards mention risks, out of which 96\% copying content from a small set of cards, leading to a lack of actionable insights. Existing proposals for improving model cards do not resolve these issues. To address this, we introduce RiskRAG, a Retrieval Augmented Generation based risk reporting solution guided by five design requirements we identified from literature, and co-design with 16 developers: identifying diverse model-specific risks, clearly presenting and prioritizing them, contextualizing for real-world uses, and offering actionable mitigation strategies. Drawing from 450K model cards and 600 real-world incidents, RiskRAG pre-populates contextualized risk reports. A preliminary study with 50 developers showed that they preferred RiskRAG over standard model cards, as it better met all the design requirements. A final study with 38 developers, 40 designers, and 37 media professionals showed that RiskRAG improved their way of selecting the AI model for a specific application, encouraging a more careful and deliberative decision-making. The RiskRAG project page is accessible at: https://social-dynamics.net/ai-risks/card.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Rao, Pooja S. B. and Šćepanović, Sanja and Zhou, Ke and Bogucka, Edyta Paulina and Quercia, Daniele},
	year = {2025},
	keywords = {AI model, AI risk, harm, incident, model cards, responsible AI, risk report},
}

@inproceedings{niu_iceage_2025,
	address = {New York, NY, USA},
	series = {{SSDBM} '25},
	title = {{ICEAGE}: {Intelligent} {Contextual} {Exploration} and {Answer} {Generation} {Engine} for {Scientific} {Data} {Discovery}},
	isbn = {979-8-4007-1462-7},
	url = {https://doi.org/10.1145/3733723.3733731},
	doi = {10.1145/3733723.3733731},
	abstract = {More and more scientific applications store datasets in scientific data formats such as HDF5 and netCDF. However, existing search methods for scientific data formats generally require researchers to be familiar with the formats and metadata structure, resulting in a steep learning curve. Therefore, researchers need a natural language query method to query scientific data. In this paper, we propose ICEAGE, a novel Intelligent Contextual Exploration and Answer Generation Engine that bridges the gap between natural language querying and scientific data and metadata retrieval. Based on a retrieval-augmented generation framework, ICEAGE generates reliable and human-readable responses without requiring extensive domain-specific fine-tuning by applying unique indexing method for scientific datasets. Our experimental results demonstrate that ICEAGE significantly outperforms existing methods in terms of accuracy, throughput in both CPU-GPU and CPU-only environments.},
	booktitle = {Proceedings of the 37th {International} {Conference} on {Scalable} {Scientific} {Data} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Niu, Chenxu and Zhang, Wei and Side, Mert and Chen, Yong},
	year = {2025},
}

@inproceedings{lee_can_2025,
	address = {Ottawa, Ontario, Canada},
	series = {{ICSE} '25},
	title = {Can an {LLM} {Find} {Its} {Way} around a {Spreadsheet}?},
	isbn = {979-8-3315-0569-1},
	url = {https://doi.org/10.1109/ICSE55347.2025.00101},
	doi = {10.1109/ICSE55347.2025.00101},
	abstract = {Spreadsheets are routinely used in business and scientific contexts, and one of the most vexing challenges is performing data cleaning prior to analysis and evaluation. The ad-hoc and arbitrary nature of data cleaning problems, such as typos, inconsistent formatting, missing values, and a lack of standardization, often creates the need for highly specialized pipelines. We ask whether an LLM can find its way around a spreadsheet and how to support end-users in taking their free-form data processing requests to fruition. Just like RAG retrieves context to answer users' queries, we demonstrate how we can retrieve elements from a code library to compose data preprocessing pipelines. Through comprehensive experiments, we demonstrate the quality of our system and how it is able to continuously augment its vocabulary by saving new codes and pipelines back to the code library for future retrieval.},
	booktitle = {Proceedings of the {IEEE}/{ACM} 47th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Lee, Cho-Ting and Neeser, Andrew and Xu, Shengzhe and Katyan, Jay and Cross, Patrick and Pathakota, Sharanya and Norman, Marigold and Simeone, John and Chandrasekaran, Jaganmohan and Ramakrishnan, Naren},
	year = {2025},
	keywords = {code generation, data cleaning, end-user programming, LLMs},
	pages = {294--306},
}

@inproceedings{nangia_-context_2025,
	address = {New York, NY, USA},
	series = {{SACMAT} '25},
	title = {In-{Context} {Vulnerability} {Propagation} in {LLMs} [{Work} {In} {Progress} {Paper}]},
	isbn = {979-8-4007-1503-7},
	url = {https://doi.org/10.1145/3734436.3734459},
	doi = {10.1145/3734436.3734459},
	abstract = {The widespread adoption of Large Language Models (LLMs) in software development has accelerated coding workflows, with tools like GitHub Copilot and Google Gemini reducing development time by up to 55.8\%. However, these systems suffer from security and trustworthiness challenges. In this paper, we demonstrate a novel attack - ”Vulnerability propagation attack” in the conext of the code generated by LLMs. We present a formal framework for evaluating vulnerability propagation in LLM-assisted development, focusing on two key metrics: Vulnerability Carry Rate (VCR), which quantifies the intra-session propagation of vulnerabilities, and Context Retention Factor (CRF), which measures cross-session persistence. Using three leading LLMs – GPT-4, Sonar, and Gemini – we evaluate 10 critical Common Weakness Enumeration (CWE) categories across three tiers of prompts (direct injection, implicit vulnerabilities, and adversarial few-shot prompting). Our findings reveal that adversarial few-shot prompting exacerbates vulnerability propagation, with VCR values reaching 100\% under high-difficulty conditions and CRF values demonstrating significant retention across sessions. These results underscore the need for session-aware security measures and robust vulnerability detection frameworks in AI-assisted development environments.},
	booktitle = {Proceedings of the 30th {ACM} {Symposium} on {Access} {Control} {Models} and {Technologies}},
	publisher = {Association for Computing Machinery},
	author = {Nangia, Aditya and Ayachitula, Sriya and Kundu, Chinmay},
	year = {2025},
	note = {event-place: USA},
	keywords = {code generation, llm, vulnerability propagation},
	pages = {169--174},
}

@inproceedings{tian_text--sql_2025,
	address = {New York, NY, USA},
	series = {{IUI} '25},
	title = {Text-to-{SQL} {Domain} {Adaptation} via {Human}-{LLM} {Collaborative} {Data} {Annotation}},
	isbn = {979-8-4007-1306-4},
	url = {https://doi.org/10.1145/3708359.3712083},
	doi = {10.1145/3708359.3712083},
	abstract = {Text-to-SQL models, which parse natural language (NL) questions to executable SQL queries, are increasingly adopted in real-world applications. However, deploying such models in the real world often requires adapting them to the highly specialized database schemas used in specific applications. We find that existing text-to-SQL models experience significant performance drops when applied to new schemas, primarily due to the lack of domain-specific data for fine-tuning. This data scarcity also limits the ability to effectively evaluate model performance in new domains. Continuously obtaining high-quality text-to-SQL data for evolving schemas is prohibitively expensive in real-world scenarios. To bridge this gap, we propose SQLsynth, a human-in-the-loop text-to-SQL data annotation system. SQLsynth streamlines the creation of high-quality text-to-SQL datasets through human-LLM collaboration in a structured workflow. A within-subjects user study comparing SQLsynth with manual annotation and ChatGPT shows that SQLsynth significantly accelerates text-to-SQL data annotation, reduces cognitive load, and produces datasets that are more accurate, natural, and diverse. Our code is available at https://github.com/adobe/nl\_sql\_analyzer.},
	booktitle = {Proceedings of the 30th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Tian, Yuan and Lee, Daniel and Wu, Fei and Mai, Tung and Qian, Kun and Sahai, Siddhartha and Zhang, Tianyi and Li, Yunyao},
	year = {2025},
	keywords = {Databases, Domain Adaptation, Interactive Data Annotation, LLMs, Natural Language Interface, PCFG, Text-to-SQL},
	pages = {1398--1425},
}

@inproceedings{yan_efficient_2024,
	address = {New York, NY, USA},
	series = {{KDD} '24},
	title = {Efficient {Mixture} of {Experts} based on {Large} {Language} {Models} for {Low}-{Resource} {Data} {Preprocessing}},
	isbn = {979-8-4007-0490-1},
	url = {https://doi.org/10.1145/3637528.3671873},
	doi = {10.1145/3637528.3671873},
	abstract = {Data preprocessing (DP) that transforms erroneous and raw data to a clean version is a cornerstone of the data mining pipeline. Due to the diverse requirements of downstream tasks, data scientists and domain experts have to handcraft domain-specific rules or train ML models with annotated examples, which is costly/time-consuming. In this paper, we present MELD (\&lt;u\&gt;M\&lt;/u\&gt;ixture of \&lt;u\&gt;E\&lt;/u\&gt;xperts on \&lt;u\&gt;L\&lt;/u\&gt;arge Language Models for \&lt;u\&gt;D\&lt;/u\&gt;ata Preprocessing), a universal solver for low-resource DP. MELD adopts a Mixture-of-Experts (MoE) architecture that enables the amalgamation and enhancement of domain-specific experts trained on limited annotated examples. To fine-tune MELD, we develop a suite of expert-tuning and MoE-tuning techniques, including a retrieval augmented generation (RAG) system, meta-path search for data augmentation, expert refinement and router network training based on information bottleneck. To further verify the effectiveness of MELD, we theoretically prove that MoE in MELD is superior than a single expert and the router network is able to dispatch data to the right experts. Finally, we conducted extensive experiments on 19 datasets over 10 DP tasks to show that MELD outperforms the state-of-the-art methods in both effectiveness and efficiency. More importantly, MELD is able to be fine-tuned in a low-resource environment, e.g. a local, single and low-priced 3090 GPU.},
	booktitle = {Proceedings of the 30th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Yan, Mengyi and Wang, Yaoshu and Pang, Kehan and Xie, Min and Li, Jianxin},
	year = {2024},
	note = {event-place: Barcelona, Spain},
	keywords = {data preprocessing, LLMs, low-resource, mixture of expert},
	pages = {3690--3701},
}

@inproceedings{wu_orchid_2025,
	address = {New York, NY, USA},
	series = {C\&amp;{C} '25},
	title = {Orchid: {A} {Creative} {Approach} for {Authoring} {LLM}-{Driven} {Interactive} {Narratives}},
	isbn = {979-8-4007-1289-0},
	url = {https://doi.org/10.1145/3698061.3726906},
	doi = {10.1145/3698061.3726906},
	abstract = {Integrating Large Language Models (LLMs) into Interactive Digital Narratives (IDNs) enables dynamic storytelling where user interactions shape the narrative in real time, challenging traditional authoring methods. This paper presents the design study of Orchid, a creative approach for authoring LLM-driven IDNs. Orchid allows users to structure the hierarchy of narrative stages and define the rules governing LLM narrative generation and transitions between stages. The development of Orchid consists of three phases. 1) Formulating Orchid through desk research on existing IDN practices. 2) Implementation of a technology probe based on Orchid. 3) Evaluating how IDN authors use Orchid to design IDNs, verify Orchid’s hypotheses, and explore user needs for future authoring tools. This study confirms that authors are open to LLM-driven IDNs but desire strong authorial agency in narrative structures, highlighted in accuracy in branching transitions and story details. Future design implications for Orchid include introducing deterministic variable handling, support for trans-media applications, and narrative consistency across branches.},
	booktitle = {Proceedings of the 2025 {Conference} on {Creativity} and {Cognition}},
	publisher = {Association for Computing Machinery},
	author = {Wu, Zhen and Kumyol, Serkan and Wong, Shing Yin and Hu, Xiaozhu and Tong, Xin and Braud, Tristan},
	year = {2025},
	keywords = {authorial agency and machine contingency, emergent narrative, Interactive Digital Narrative, LLMs, technology probe},
	pages = {774--791},
}

@inproceedings{meng_deconstructing_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Deconstructing {Depression} {Stigma}: {Integrating} {AI}-driven {Data} {Collection} and {Analysis} with {Causal} {Knowledge} {Graphs}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3714255},
	doi = {10.1145/3706598.3714255},
	abstract = {Mental-illness stigma is a persistent social problem, hampering both treatment-seeking and recovery. Accordingly, there is a pressing need to understand it more clearly, but analyzing the relevant data is highly labor-intensive. Therefore, we designed a chatbot to engage participants in conversations; coded those conversations qualitatively with AI assistance; and, based on those coding results, built causal knowledge graphs to decode stigma. The results we obtained from 1,002 participants demonstrate that conversation with our chatbot can elicit rich information about people’s attitudes toward depression, while our AI-assisted coding was strongly consistent with human-expert coding. Our novel approach combining large language models (LLMs) and causal knowledge graphs uncovered patterns in individual responses and illustrated the interrelationships of psychological constructs in the dataset as a whole. The paper also discusses these findings’ implications for HCI researchers in developing digital interventions, decomposing human psychological constructs, and fostering inclusive attitudes.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Meng, Han and Zhang, Renwen and Wang, Ganyi and Yang, Yitian and Qin, Peinuan and Lee, Jungup and Lee, Yi-Chieh},
	year = {2025},
	keywords = {AI-assisted Coding, Causal Knowledge Graph, Chatbot, Depression, Large Language Model, Social Stigma},
}

@inproceedings{do_paige_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{PAIGE}: {Examining} {Learning} {Outcomes} and {Experiences} with {Personalized} {AI}-{Generated} {Educational} {Podcasts}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713460},
	doi = {10.1145/3706598.3713460},
	abstract = {Generative AI is revolutionizing content creation and has the potential to enable real-time, personalized educational experiences. We investigated the effectiveness of converting textbook chapters into AI-generated podcasts and explored the impact of personalizing these podcasts for individual learner profiles. We conducted a 3x3 user study with 180 college students in the United States, comparing traditional textbook reading with both generalized and personalized AI-generated podcasts across three textbook subjects. The personalized podcasts were tailored to students’ majors, interests, and self-described instructional preferences. Our findings show that students found the AI-generated podcast format to be more enjoyable than textbooks and that personalized podcasts led to significantly improved learning outcomes, although this was subject-specific. These results highlight that AI-generated podcasts can offer an engaging and effective modality transformation of textbook material, with personalization enhancing content relevance. We conclude with design recommendations for leveraging AI in education, informed by student feedback.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Do, Tiffany D. and Shafqat, Usama Bin and Ling, Elsie and Sarda, Nikhil},
	year = {2025},
	keywords = {artificial intelligence in education, content transformation, large language models, personalized learning},
}

@inproceedings{tan_contextualized_2025,
	address = {New York, NY, USA},
	series = {{ICMI} '25 {Companion}},
	title = {Contextualized {Visual} {Storytelling} for {Conversational} {Chatbot} in {Education}},
	isbn = {979-8-4007-2076-5},
	url = {https://doi.org/10.1145/3747327.3764895},
	doi = {10.1145/3747327.3764895},
	abstract = {Interactive visual storytelling through conversational agents offers a means to enhance early childhood language learning. We developed a picture-guided conversational chatbot, driven by dense image captioning, for early childhood mother tongue language learning. However, state-of-the-art image captioning systems fall short in meeting the educational needs of young learners. They often lack cultural contextualization, use vocabulary that exceeds children’s developmental level, and fail to align with curriculum-relevant learning goals. We investigated a contextualized dense image captioning framework, which augments dense image captioning with cultural and curriculum-aligned keyword retrieval through a Retrieval-Augmented Generation (RAG) module. This enables the generation of culturally appropriate, age-level suitable, and educationally anchored captions that enhance learner engagement and pedagogical relevance. We demonstrate that our approach outperforms existing captioning models in terms of linguistic appropriateness, and curriculum and cultural alignment. The contextualized dense image captioning framework supports the development of culturally grounded, education-oriented conversational agents for young learners.},
	booktitle = {Companion {Proceedings} of the 27th {International} {Conference} on {Multimodal} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Tan, Hui Li and Gu, Ying and Li, Liyuan and Leong, Mei Chee and Chen, Nancy F.},
	year = {2025},
	keywords = {AI for education, dense image captioning, human computer interaction, multi-cultural, vision-language models},
	pages = {185--189},
}

@inproceedings{ghassel_hierarchical_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {Hierarchical {Lexical} {Graph} for {Enhanced} {Multi}-{Hop} {Retrieval}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737233},
	doi = {10.1145/3711896.3737233},
	abstract = {Retrieval-Augmented Generation (RAG) grounds large language models in external evidence, yet it still falters when answers must be pieced together across semantically distant documents. We close this gap with the Hierarchical Lexical Graph (HLG), a three-tier index that (i) traces every atomic proposition to its source(ii) clusters propositions into latent topics, and (iii) links entities and relations to expose cross-document paths. On top of HLG we build two complementary, plug-and-play retrievers: StatementGraphRAG, which performs fine-grained entity-aware beam search over propositions for high-precision factoid questions, and TopicGraphRAG, which selects coarse topics before expanding along entity links to supply broad yet relevant context for exploratory queries. Additionally, existing benchmarks lack the complexity required to rigorously evaluate multi-hop summarization systems, often focusing on single-document queries or limited datasets. To address this, we introduce a synthetic dataset generation pipeline that curates realistic, multi-document question-answer pairs, enabling robust evaluation of multi-hop retrieval systems. Extensive experiments across five datasets demonstrate that our methods outperform naive chunk-based RAG, achieving an average relative improvement of 23.1\% in retrieval recall and correctness. Open-source Python library is available at https://github.com/awslabs/graphrag-toolkit.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Ghassel, Abdellah and Robinson, Ian and Tanase, Gabriel and Cooper, Hal and Thompson, Bryan and Han, Zhen and Ioannidis, Vassilis and Adeshina, Soji and Rangwala, Huzefa},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {data generation, graph structures, question answering},
	pages = {4457--4466},
}

@inproceedings{qiao_oversight_2025,
	address = {New York, NY, USA},
	series = {{ACE} '25},
	title = {Oversight in {Action}: {Experiences} with {Instructor}-{Moderated} {LLM} {Responses} in an {Online} {Discussion} {Forum}},
	isbn = {979-8-4007-1425-2},
	url = {https://doi.org/10.1145/3716640.3716651},
	doi = {10.1145/3716640.3716651},
	abstract = {The integration of large language models (LLMs) into computing education offers many potential benefits to student learning, and several novel pedagogical approaches have been reported in the literature. However LLMs also present challenges, one of the most commonly cited being that of student over-reliance. This challenge is compounded by the fact that LLMs are always available to provide instant help and solutions to students, which can undermine their ability to independently solve problems and diagnose and resolve errors. Providing instructor oversight of LLM-generated content can mitigate this problem, however it is often not practical in real-time learning contexts. Online class discussion forums, which are widely used in computing education, present an opportunity for exploring instructor oversight because they operate asynchronously. Unlike real-time interactions, the discussion forum format aligns with the expectation that responses may take time, making oversight not only feasible but also pedagogically appropriate. In this practitioner paper, we present the design, deployment, and evaluation of a ‘bot’ module that is controlled by the instructor, and integrated into an online discussion forum. The bot assists the instructor by generating draft responses to student questions, which are reviewed, modified, and approved before release. Key features include the ability to leverage course materials, access archived discussions, and publish responses anonymously to encourage open participation. We report our experiences using this tool in a 12-week second-year software engineering course on object-oriented programming. Instructor feedback confirmed the tool successfully alleviated workload but highlighted a need for improvement in handling complex, context-dependent queries. We report the features that were viewed as most beneficial, and suggest avenues for future exploration.},
	booktitle = {Proceedings of the 27th {Australasian} {Computing} {Education} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Qiao, Shuying and Denny, Paul and Giacaman, Nasser},
	year = {2025},
	keywords = {chatbots, computing education, discussion forums, instructor-in-the-loop, Large language models, LLMs, software engineering education},
	pages = {95--104},
}

@inproceedings{yang_research_2024,
	address = {New York, NY, USA},
	series = {{ISAIE} '24},
	title = {Research and {Practice} on the {Construction} of {Course} {Ideological} and {Political} {Education} {Based} on {Knowledge} {Graphs} and {Large} {Language} {Models}},
	isbn = {979-8-4007-0710-0},
	url = {https://doi.org/10.1145/3700297.3700331},
	doi = {10.1145/3700297.3700331},
	abstract = {Knowledge graphs and large language models (LLMs) have become important tools for educational innovation. This paper explores the application of these two technologies in the construction of ideological and political education in university courses. The paper begins by analyzing the importance of course-based ideological and political education and the challenges currently faced. It then introduces the role of knowledge graphs in integrating educational resources and constructing knowledge systems, as well as the potential and current status of LLMs in natural language processing and providing personalized educational content. This study presents a method that integrates the use of knowledge graphs and LLMs to construct resources and application systems for course-based ideological and political education. The results of practical case studies demonstrate that the proposed method improves the efficiency of constructing ideological and political education content, enhances the effectiveness of moral education within courses, and contributes to the innovative development of ideological and political education.},
	booktitle = {Proceedings of the 2024 {International} {Symposium} on {Artificial} {Intelligence} for {Education}},
	publisher = {Association for Computing Machinery},
	author = {Yang, Da and Liu, Shutian and Fu, Haoyang and Shen, Jiayi},
	year = {2024},
	keywords = {Course Ideological and Political Education, Educational Innovation, Knowledge Graph, Large Language Model (LLM)},
	pages = {193--198},
}

@inproceedings{wu_netllm_2024,
	address = {New York, NY, USA},
	series = {{ACM} {SIGCOMM} '24},
	title = {{NetLLM}: {Adapting} {Large} {Language} {Models} for {Networking}},
	isbn = {979-8-4007-0614-1},
	url = {https://doi.org/10.1145/3651890.3672268},
	doi = {10.1145/3651890.3672268},
	abstract = {Many networking tasks now employ deep learning (DL) to solve complex prediction and optimization problems. However, current design philosophy of DL-based algorithms entails intensive engineering overhead due to the manual design of deep neural networks (DNNs) for different networking tasks. Besides, DNNs tend to achieve poor generalization performance on unseen data distributions/environments.Motivated by the recent success of large language models (LLMs), this work studies the LLM adaptation for networking to explore a more sustainable design philosophy. With the powerful pre-trained knowledge, the LLM is promising to serve as the foundation model to achieve "one model for all tasks" with even better performance and stronger generalization. In pursuit of this vision, we present NetLLM, the first framework that provides a coherent design to harness the powerful capabilities of LLMs with low efforts to solve networking problems. Specifically, NetLLM empowers the LLM to effectively process multimodal data in networking and efficiently generate task-specific answers. Besides, NetLLM drastically reduces the costs of fine-tuning the LLM to acquire domain knowledge for networking. Across three networking-related use cases - viewport prediction, adaptive bitrate streaming and cluster job scheduling, we showcase that the NetLLM-adapted LLM significantly outperforms state-of-the-art algorithms.},
	booktitle = {Proceedings of the {ACM} {SIGCOMM} 2024 {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Wu, Duo and Wang, Xianda and Qiao, Yaqi and Wang, Zhi and Jiang, Junchen and Cui, Shuguang and Wang, Fangxin},
	year = {2024},
	note = {event-place: Sydney, NSW, Australia},
	keywords = {deep learning, job scheduling, large language model adaptation, network optimization, video streaming},
	pages = {661--678},
}

@inproceedings{zhang_differential-perceptive_2024,
	address = {New York, NY, USA},
	series = {{MM} '24},
	title = {Differential-{Perceptive} and {Retrieval}-{Augmented} {MLLM} for {Change} {Captioning}},
	isbn = {979-8-4007-0686-8},
	url = {https://doi.org/10.1145/3664647.3681453},
	doi = {10.1145/3664647.3681453},
	abstract = {Change captioning involves describing the subtle changes between a pair of similar images. Although existing efforts have achieved compelling success, they overlook the potential of multimodal large language models (MLLMs) in tackling this challenging task. In this work, we aim to empower MLLMs with the capability to perceive subtle differences between paired images and enhance their performance in generating change captions. Specifically, we present a diFferentIal-perceptive aNd rEtRieval-augmented MLLM (FINER-MLLM) tailored for this task. In particular, FINER-MLLM leverages LoRA fine-tuned MLLM's image encoder to extract image patch features, enabling the capture of detailed image information. Subsequently, within MLLM's feature extraction, typically Q-Former, FINER-MLLM incorporates dual constraints: the intra-image feature independence constraint and the inter-image feature alignment constraint. These constraints ensure that the features can comprehensively extract subtle visual information within each image and that corresponding features across images align effectively. Last, we introduced the retrieval augmentation to first retrieve the relevant corpus to facilitate the MLLM's decoder i.e., LLM, in generating accurate change captions. Extensive experiments on three benchmark datasets, i.e., CLEVR-Change, Spot-the-Diff, and Image-Editing-Request, demonstrate the superiority of our proposed method.},
	booktitle = {Proceedings of the 32nd {ACM} {International} {Conference} on {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Xian and Wen, Haokun and Wu, Jianlong and Qin, Pengda and Xue', Hui and Nie, Liqiang},
	year = {2024},
	note = {event-place: Melbourne VIC, Australia},
	keywords = {change captioning, multimodal large language model, retrieval-augmented captioning},
	pages = {4148--4157},
}

@inproceedings{pang_understanding_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Understanding the {LLM}-ification of {CHI}: {Unpacking} the {Impact} of {LLMs} at {CHI} through a {Systematic} {Literature} {Review}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713726},
	doi = {10.1145/3706598.3713726},
	abstract = {Large language models (LLMs) have been positioned to revolutionize HCI, by reshaping not only the interfaces, design patterns, and sociotechnical systems that we study, but also the research practices we use. To-date, however, there has been little understanding of LLMs’ uptake in HCI. We address this gap via a systematic literature review of 153 CHI papers from 2020-24 that engage with LLMs. We taxonomize: (1) domains where LLMs are applied; (2) roles of LLMs in HCI projects; (3) contribution types; and (4) acknowledged limitations and risks. We find LLM work in 10 diverse domains, primarily via empirical and artifact contributions. Authors use LLMs in five distinct roles, including as research tools or simulated users. Still, authors often raise validity and reproducibility concerns, and overwhelmingly study closed models. We outline opportunities to improve HCI research with and on LLMs, and provide guiding questions for researchers to consider the validity and appropriateness of LLM-related work.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Pang, Rock Yuren and Schroeder, Hope and Smith, Kynnedy Simone and Barocas, Solon and Xiao, Ziang and Tseng, Emily and Bragg, Danielle},
	year = {2025},
	keywords = {HCI theory, human-AI interaction, Large language models, systematic literature review},
}

@inproceedings{espinal_extended_2025,
	address = {New York, NY, USA},
	series = {{IoT} '24},
	title = {An {eXtended} {Reality} {Data} {Transformation} {Framework} for {Internet} of {Things} {Devices} {Integration}},
	isbn = {979-8-4007-1285-2},
	url = {https://doi.org/10.1145/3703790.3703792},
	doi = {10.1145/3703790.3703792},
	abstract = {The multidisciplinary nature of XR applications makes device and data integration a resource-intensive and time-consuming task, especially in the context of the Internet of Things (IoT).This paper presents Visualize Interactive Objects, VIO for short, a data transformation framework aimed at simplifying visualization and interaction of IoT devices and their data into XR applications. VIO comprises a software runtime\&nbsp;(VRT) running on XR headsets, and a JSON-based syntax for defining VIO Descriptions (VDs). The VRT interprets VDs to facilitate visualization and interaction within the application. By raising the level of abstraction, VIO enhances interoperability among XR experiences and enables developers to integrate IoT data with minimal coding effort.A comprehensive evaluation demonstrated that VIO is lightweight, incurring in negligible overhead compared to native implementations. Ten Large Language Models (LLM) were used to generate VDs and native source-code from user intents. The results showed that LLMs have superior syntactical and semantical accuracy in generating VDs compared to native XR application development code, thus indicating that the task of creating VDs can be effectively automated using LLMs. Additionally, a user study with 12 participants found that VIO is developer-friendly and easily extensible.},
	booktitle = {Proceedings of the 14th {International} {Conference} on the {Internet} of {Things}},
	publisher = {Association for Computing Machinery},
	author = {Espinal, Wendy Yunuen Arevalo and Jimenez, Jaime and Corneo, Lorenzo},
	year = {2025},
	keywords = {Data Transformation, Device and Data Integration, Extended Reality, Generative AI, Internet of Things},
	pages = {10--18},
}

@inproceedings{aneja_beyond_2025,
	address = {New York, NY, USA},
	series = {{FAccT} '25},
	title = {Beyond {Semantics}: {Examining} {Gender} {Bias} in {LLMs} {Deployed} within {Low}-resource {Contexts} in {India}},
	isbn = {979-8-4007-1482-5},
	url = {https://doi.org/10.1145/3715275.3732180},
	doi = {10.1145/3715275.3732180},
	abstract = {Like many other countries, India has witnessed a surge in LLM-based applications and initiatives, with multiple players directing their efforts towards building and customising LLMs more suited to the country’s socio-demographic characteristics. However, concomitant to the rise in the popularity of LLMs, numerous studies and anecdotes highlighting various harms such as misinformation, discrimination, and bias have emerged. Gender bias in LLMs – defined as the tendency of these models to reflect and perpetuate stereotypes, inequalities, or prejudices based on gender – has received significant scholarly attention in the last few years. However, only a handful of studies have analysed this issue against the backdrop of India’s sociocultural setting, and almost none (to the best of our knowledge) have looked at it in relation to critical social sectors. We therefore undertake an exploratory study to understand the different sources and manifestations of gender biases in LLMs customised for Indian languages and deployed in resource-constrained settings. Through detailed key informant interviews with LLM application developers, field visits to deployment and testing sites, prompting exercises, and expert workshops, we unpack gender-related concerns that emerge at each stage of the LLM lifecycle. In this, we shift away from a narrow construct that views gender bias in LLMs solely as prejudiced semantics fixable through improved engineering. Instead, we recognise it as a reflection of broader, structural inequities that demand a more grounded, interdisciplinary effort to both understand and address.},
	booktitle = {Proceedings of the 2025 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Aneja, Urvashi and Gupta, Aarushi and Vashistha, Aditya},
	year = {2025},
	keywords = {ChatGPT, Contextual Integrity, Gender bias, Krutrim, Large Language Models, Majority World, Social Sector},
	pages = {2784--2795},
}

@inproceedings{staudinger_reproducibility_2024,
	address = {New York, NY, USA},
	series = {{SIGIR}-{AP} 2024},
	title = {A {Reproducibility} and {Generalizability} {Study} of {Large} {Language} {Models} for {Query} {Generation}},
	isbn = {979-8-4007-0724-7},
	url = {https://doi.org/10.1145/3673791.3698432},
	doi = {10.1145/3673791.3698432},
	abstract = {Systematic literature reviews (SLRs) are a cornerstone of academic research, yet they are often labour-intensive and time-consuming due to the detailed literature curation process. The advent of generative AI and large language models (LLMs) promises to revolutionize this process by assisting researchers in several tedious tasks, one of them being the generation of effective Boolean queries that will select the publications to consider including in a review. This paper presents an extensive study of Boolean query generation using LLMs for systematic reviews, reproducing and extending the work of Wang et al. and Alaniz et al. Our study investigates the replicability and reliability of results achieved using ChatGPT and compares its performance with open-source alternatives like Mistral and Zephyr to provide a more comprehensive analysis of LLMs for query generation.Therefore, we implemented a pipeline, which automatically creates a Boolean query for a given review topic by using a previously defined LLM, retrieves all documents for this query from the PubMed database and then evaluates the results. With this pipeline we first assess whether the results obtained using ChatGPT for query generation are reproducible and consistent. We then generalize our results by analyzing and evaluating open-source models and evaluating their efficacy in generating Boolean queries.Finally, we conduct a failure analysis to identify and discuss the limitations and shortcomings of using LLMs for Boolean query generation. This examination helps to understand the gaps and potential areas for improvement in the application of LLMs to information retrieval tasks. Our findings highlight the strengths, limitations, and potential of LLMs in the domain of information retrieval and literature review automation. Our code is available online.},
	booktitle = {Proceedings of the 2024 {Annual} {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval} in the {Asia} {Pacific} {Region}},
	publisher = {Association for Computing Machinery},
	author = {Staudinger, Moritz and Kusa, Wojciech and Piroi, Florina and Lipani, Aldo and Hanbury, Allan},
	year = {2024},
	note = {event-place: Tokyo, Japan},
	keywords = {boolean query, llms, query generation, systematic reviews},
	pages = {186--196},
}

@inproceedings{wolfe_implications_2025,
	address = {San Jose, California, USA},
	series = {{AIES} '24},
	title = {The {Implications} of {Open} {Generative} {Models} in {Human}-{Centered} {Data} {Science} {Work}: {A} {Case} {Study} with {Fact}-{Checking} {Organizations}},
	abstract = {Calls to use open generative language models in academic research have highlighted the need for reproducibility and transparency in scientific research. However, the impact of generative AI extends well beyond academia, as corporations and public interest organizations have begun integrating these models into their data science pipelines. We expand this lens to include the impact of open models on organizations, focusing specifically on fact-checking organizations, which use AI to observe and analyze large volumes of circulating misinformation, yet must also ensure the reproducibility and impartiality of their work. We wanted to understand where fact-checking organizations use open models in their data science pipelines; what motivates their use of open models or proprietary models; and how their use of open or proprietary models can inform research on the societal impact of generative AI. To answer these questions, we conducted an interview study with N=24 professionals at 20 fact-checking organizations on six continents. Based on these interviews, we offer a five-component conceptual model of where fact-checking organizations employ generative AI to support or automate parts of their data science pipeline, including Data Ingestion, Data Analysis, Data Retrieval, Data Delivery, and Data Sharing. We then provide taxonomies of fact-checking organizations' motivations for using open models and the limitations that prevent them for further adopting open models, finding that they prefer open models for Organizational Autonomy, Data Privacy and Ownership, Application Specificity, and Capability Transparency. However, they nonetheless use proprietary models due to perceived advantages in Performance, Usability, and Safety, as well as Opportunity Costs related to participation in emerging generative AI ecosystems. Finally, we propose a research agenda to address limitations of both open and proprietary models. Our research provides novel perspective on open models in data-driven organizations.},
	booktitle = {Proceedings of the 2024 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {AAAI Press},
	author = {Wolfe, Robert and Mitra, Tanushree},
	year = {2025},
	pages = {1595--1607},
}

@inproceedings{cai_aiget_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{AiGet}: {Transforming} {Everyday} {Moments} into {Hidden} {Knowledge} {Discovery} with {AI} {Assistance} on {Smart} {Glasses}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713953},
	doi = {10.1145/3706598.3713953},
	abstract = {Unlike the free exploration of childhood, the demands of daily life reduce our motivation to explore our surroundings, leading to missed opportunities for informal learning. Traditional tools for knowledge acquisition are reactive, relying on user initiative and limiting their ability to uncover hidden interests. Through formative studies, we introduce AiGet, a proactive AI assistant integrated with AR smart glasses, designed to seamlessly embed informal learning into low-demand daily activities (e.g., casual walking and shopping). AiGet analyzes real-time user gaze patterns, environmental context, and user profiles, leveraging large language models to deliver personalized, context-aware knowledge with low disruption to primary tasks. In-lab evaluations and real-world testing, including continued use over multiple days, demonstrate AiGet’s effectiveness in uncovering overlooked yet surprising interests, enhancing primary task enjoyment, reviving curiosity, and deepening connections with the environment. We further propose design guidelines for AI-assisted informal learning, focused on transforming everyday moments into enriching learning experiences.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Cai, Runze and Janaka, Nuwan and Kim, Hyeongcheol and Chen, Yang and Zhao, Shengdong and Huang, Yun and Hsu, David},
	year = {2025},
	keywords = {AI, HMD, human-ai interaction, incidental learning, informal learning, knowledge discovery, large language model, multimodal information, smart glasses, wearable-AI assistance},
}

@inproceedings{yang_evaluating_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {Evaluating {Large} {Language} {Models} for {Requirements} {Question} {Answering} in {Industrial} {Aerospace} {Software}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3728560},
	doi = {10.1145/3696630.3728560},
	abstract = {Aerospace software presents significant challenges to requirements engineering due to its design complexity and stringent safety standards. When manually drafting requirement documents, engineers need strong domain knowledge while also navigating heterogeneous data, which leads to errors and inefficiencies. This paper evaluates the capabilities of large language models (LLMs) in understanding aerospace software requirements and their potential to assist in requirements question answering (QA). We develop an aerospace requirements QA benchmark based on industrial software assets, books, and research materials, creating a total of 6, 696 QA pairs across ten tasks and three heterogeneous data formats: text, tables, and formulas. We then evaluate the domain-specific performance of five mainstream open-source LLMs using zero-shot learning, few-shot learning, and retrieval-augmented generation (RAG) techniques. We further categorize hallucinations from LLMs and quantitatively analyze error distributions. Moreover, we conduct a user study to assess the LLM's practical usefulness when applying to requirements QA. The evaluation results show that (1) LLMs demonstrate limited performance in the aerospace software domain, (2) RAG techniques significantly enhance the capabilities of LLMs for text-based tasks, while few-shot learning improves the performance of most LLMs, (3) four distinct types of QA hallucinations are identified, and (4) LLM QA is particularly beneficial for junior engineers. This research provides valuable perspectives for the future application of LLMs in aerospace software.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Yang, Longxing and Luo, Yixing and Gao, Hao and Fan, Yingshuang and Zhang, Jingru and Li, Xiaofeng and Dong, Xiaogang and Gu, Bin and Jin, Zhi and Yang, Mengfei},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {aerospace software, evaluation, large language models, requirements question answering},
	pages = {366--377},
}

@inproceedings{kim_legisflow_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {{LegisFlow}: {Enhancing} {Korean} {Legal} {Research} with {Temporal}-{Aware} {LLM} {Interfaces}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747752},
	doi = {10.1145/3746059.3747752},
	abstract = {In South Korea’s statutory law system, legal research faces challenges like tracking frequent amendments and understanding complex statute relationships. LegisFlow, an innovative AI-powered system, tackles these issues with features such as interactive amendment timelines and advanced inter-statute relationship analysis. Developed based on insights from Korean legal experts, it provides intuitive visualizations and context-aware search capabilities. A user study with 10 legal professionals demonstrated that LegisFlow significantly enhances efficiency, reducing task completion times by up to 36\% (e.g., 440s vs. 690s in inter-statute comparison, p = 0.022) and lowering cognitive load, with workflows streamlined by 70\% fewer manual steps. LegisFlow transforms statutory law research by setting a new standard for AI-assisted tools, providing a scalable, user-centered solution for professionals in Korea and beyond.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Kim, Junghwan and Jeon, Hyeonseok and Heo, Dongseok and Lee, Jung and Suh, Bongwon},
	year = {2025},
	keywords = {AI in Law, Interactive Legal Research Tools, Legal Information Retrieval, Legislative Amendment Tracking, Natural Language Search in Law, Statutory Law Research, Temporal Analysis of Legislation, User-Centered Legal Systems},
}

@inproceedings{koziolek_llm-based_2024,
	address = {New York, NY, USA},
	series = {{LLM4Code} '24},
	title = {{LLM}-based and {Retrieval}-{Augmented} {Control} {Code} {Generation}},
	isbn = {979-8-4007-0579-3},
	url = {https://doi.org/10.1145/3643795.3648384},
	doi = {10.1145/3643795.3648384},
	abstract = {Control code is designed and implemented for industrial automation applications that manage power plants, petrochemical processes, or steel production. Popular large language models (LLM) can synthesize low-level control code in the Structured Text programming notation according to the standard IEC 61131-3, but are not aware of proprietary control code function block libraries, which are often used in practice. To automate control logic implementation tasks, we proposed a retrieval-augmented control code generation method that can integrate such function blocks into the generated code. With this method control engineers can benefit from the code generation capabilities of LLMs, re-use proprietary and well-tested function blocks, and speed up typical programming tasks significantly. We have evaluated the method using a prototypical implementation based on GPT-4, LangChain, Open-PLC, and the open-source OSCAT function block library. In several spot sample tests, we successfully generated IEC 61131-3 ST code that integrated the desired function blocks, could be compiled, and validated through simulations.},
	booktitle = {Proceedings of the 1st {International} {Workshop} on {Large} {Language} {Models} for {Code}},
	publisher = {Association for Computing Machinery},
	author = {Koziolek, Heiko and Grüner, Sten and Hark, Rhaban and Ashiwal, Virendra and Linsbauer, Sofia and Eskandani, Nafise},
	year = {2024},
	note = {event-place: Lisbon, Portugal},
	keywords = {ChatGPT, code generation, DCS, GPT-4, IEC 61131-3, industrial automation, large language models, PLC},
	pages = {22--29},
}

@inproceedings{zhao_noteit_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {{NoteIt}: {A} {System} {Converting} {Instructional} {Videos} to {Interactable} {Notes} {Through} {Multimodal} {Video} {Understanding}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747626},
	doi = {10.1145/3746059.3747626},
	abstract = {Users often take notes for instructional videos to access key knowledge later without revisiting long videos. Automated note generation tools enable users to obtain informative notes efficiently. However, notes generated by existing research or off-the-shelf tools fail to preserve the information conveyed in the original videos comprehensively, nor can they satisfy users’ expectations for diverse presentation formats and interactive features when using notes digitally. In this work, we present NoteIt, a system, which automatically converts instructional videos to interactable notes using a novel pipeline that faithfully extracts hierarchical structure and multimodal key information from videos. With NoteIt’s interface, users can interact with the system to further customize the content and presentation formats of the notes according to their preferences. We conducted both a technical evaluation and a comparison user study (N=36). The solid performance in objective metrics and the positive user feedback demonstrated the effectiveness of the pipeline and the overall usability of NoteIt.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Zhao, Running and Jiang, Zhihan and Zhang, Xinchen and Chang, Chirui and Chen, Handi and Deng, Weipeng and Jin, Luyao and Qi, Xiaojuan and Qian, Xun and Ngai, Edith C.H.},
	year = {2025},
	keywords = {multimodal large language model, multimodal learning, note generation, video understanding},
}

@inproceedings{tian_customized_2024,
	address = {New York, NY, USA},
	series = {{ICAIF} '24},
	title = {Customized {FinGPT} {Search} {Agents} {Using} {Foundation} {Models}},
	isbn = {979-8-4007-1081-0},
	url = {https://doi.org/10.1145/3677052.3698637},
	doi = {10.1145/3677052.3698637},
	abstract = {Current large language models (LLMs) have proven useful for analyzing financial data, but most existing models, such as BloombergGPT and FinGPT, lack customization for specific user needs. In this paper, we address this gap by developing FinGPT Search Agents tailored for two types of users: individuals and institutions. For individuals, we leverage Retrieval-Augmented Generation (RAG) to search local documents and user-specified data sources. For institutions, we employ dynamic vector databases and fine-tune models on proprietary data. There are several key issues to address, including data privacy, the time-sensitive nature of financial information, and the need for fast responses. Experiments show that FinGPT Search Agent outperform existing models in accuracy, relevance, and response time, making them promising for real-world financial applications.},
	booktitle = {Proceedings of the 5th {ACM} {International} {Conference} on {AI} in {Finance}},
	publisher = {Association for Computing Machinery},
	author = {Tian, Felix and Byadgi, Ajay and Kim, Daniel S and Zha, Daochen and White, Matt and Xiao, Kairong and Liu, Xiao-Yang},
	year = {2024},
	note = {event-place: Brooklyn, NY, USA},
	pages = {469--477},
}

@inproceedings{cordioli_exploring_2025,
	address = {New York, NY, USA},
	series = {{CHItaly} '25},
	title = {Exploring {LLM}-{Driven} {Interaction} for {Knowledge} {Retrieval} {inExtended} {Reality}},
	isbn = {979-8-4007-2102-1},
	url = {https://doi.org/10.1145/3750069.3750160},
	doi = {10.1145/3750069.3750160},
	abstract = {This paper illustrates a user study comparing three interaction modalities in XR knowledge-retrieval tasks: (i) menu-based interfaces (MB), (ii) spatially anchored infographics (IG), and (iii) a multimodal LLM-powered agent (LM) combining voice, gesture, and deictic input. Sixteen participants explored an XR environment using the three modalities. Results indicate that the LM modality was perceived as significantly more usable than IG, but did not yield statistically significant improvements in efficiency or cognitive load compared to MB. While LLM-driven agents offer promising interaction patterns, our findings suggest that their objective benefits over traditional modalities remain inconclusive in complex XR tasks. Our findings also highlight the need to identify trade-offs among modalities and inform design guidelines for hybrid XR interfaces combining conversational AI with visual scaffolding.},
	booktitle = {Proceedings of the 16th {Biannual} {Conference} of the {Italian} {SIGCHI} {Chapter}},
	publisher = {Association for Computing Machinery},
	author = {Cordioli, Luca and Piro, Ludovica and Valoriani, Matteo and Matera, Maristella},
	year = {2025},
	keywords = {Extended Reality, Human-AI Interaction, Interaction Design, Large Language Models, User Study},
}

@inproceedings{dietz_principles_2025,
	address = {New York, NY, USA},
	series = {{ICTIR} '25},
	title = {Principles and {Guidelines} for the {Use} of {LLM} {Judges}},
	isbn = {979-8-4007-1861-8},
	url = {https://doi.org/10.1145/3731120.3744588},
	doi = {10.1145/3731120.3744588},
	abstract = {Relevance judgments for information retrieval (IR) evaluation, once the domain of human assessors, are now often produced by Large Language Models (LLMs). While some studies report alignment between LLM and human judgments, claims that LLMs can replace human judges raise concerns about reliability, validity, and long-term impact. As IR systems increasingly rely on LLM-generated signals, evaluation risks becoming self-reinforcing, leading to potentially misleading conclusions. This paper examines scenarios where LLM evaluators may falsely indicate success, particularly when LLM-based judgments influence both system development and evaluation. We highlight key risks, including bias reinforcement, reproducibility challenges, and inconsistencies in assessment methodologies. To address these concerns, we propose tests to quantify adverse effects, guardrails, and a collaborative framework for constructing reusable test collections that integrate LLM judgments responsibly. By providing perspectives from academia and industry, this work aims to establish best practices for the principled use of LLMs in IR evaluation.},
	booktitle = {Proceedings of the 2025 {International} {ACM} {SIGIR} {Conference} on {Innovative} {Concepts} and {Theories} in {Information} {Retrieval} ({ICTIR})},
	publisher = {Association for Computing Machinery},
	author = {Dietz, Laura and Zendel, Oleg and Bailey, Peter and Clarke, Charles L. A. and Cotterill, Ellese and Dalton, Jeff and Hasibi, Faegheh and Sanderson, Mark and Craswell, Nick},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {llm tropes, llm-based evaluation, validity of experimentation},
	pages = {218--229},
}

@inproceedings{li_omniquery_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{OmniQuery}: {Contextually} {Augmenting} {Captured} {Multimodal} {Memories} to {Enable} {Personal} {Question} {Answering}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713448},
	doi = {10.1145/3706598.3713448},
	abstract = {People often capture memories through photos, screenshots, and videos. While existing AI-based tools enable querying this data using natural language, they only support retrieving individual pieces of information like certain objects in photos, and struggle with answering more complex queries that involve interpreting interconnected memories like sequential events. We conducted a one-month diary study to collect realistic user queries and generated a taxonomy of necessary contextual information for integrating with captured memories. We then introduce OmniQuery, a novel system that is able to answer complex personal memory-related questions that require extracting and inferring contextual information. OmniQuery augments individual captured memories through integrating scattered contextual information from multiple interconnected memories. Given a question, OmniQuery retrieves relevant augmented memories and uses a large language model (LLM) to generate answers with references. In human evaluations, we show the effectiveness of OmniQuery with an accuracy of 71.5\%, outperforming a conventional RAG system by winning or tying for 74.5\% of the time.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Li, Jiahao Nick and Zhang, Zhuohao (Jerry) and Ma, Jiaju},
	year = {2025},
	keywords = {contextual augmentation, diary study, multimodal question answering, personal memory, RAG},
}

@inproceedings{jorke_gptcoach_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{GPTCoach}: {Towards} {LLM}-{Based} {Physical} {Activity} {Coaching}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713819},
	doi = {10.1145/3706598.3713819},
	abstract = {Mobile health applications show promise for scalable physical activity promotion but are often insufficiently personalized. In contrast, health coaching offers highly personalized support but can be prohibitively expensive and inaccessible. This study draws inspiration from health coaching to explore how large language models (LLMs) might address personalization challenges in mobile health. We conduct formative interviews with 12 health professionals and 10 potential coaching recipients to develop design principles for an LLM-based health coach. We then built GPTCoach, a chatbot that implements the onboarding conversation from an evidence-based coaching program, uses conversational strategies from motivational interviewing, and incorporates wearable data to create personalized physical activity plans. In a lab study with 16 participants using three months of historical data, we find promising evidence that GPTCoach gathers rich qualitative information to offer personalized support, with users feeling comfortable sharing concerns. We conclude with implications for future research on LLM-based physical activity support.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Jörke, Matthew and Sapkota, Shardul and Warkenthien, Lyndsea and Vainio, Niklas and Schmiedmayer, Paul and Brunskill, Emma and Landay, James A.},
	year = {2025},
	keywords = {conversational agents, health coaching, large language models (LLMs), personal informatics, Physical activity},
}

@inproceedings{vaithilingam_semantic_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {Semantic {Commit}: {Helping} {Users} {Update} {Intent} {Specifications} for {AI} {Memory} at {Scale}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747778},
	doi = {10.1145/3746059.3747778},
	abstract = {As AI agents increasingly rely on memory systems to align with user intent, updating these memories presents challenges of semantic conflict and ambiguity. Inspired by impact analysis in software engineering, we introduce SemanticCommit, a mixed-initiative interface to help users integrate new intent into intent specifications—natural language documents like AI memory lists, Cursor Rules, and game design documents—while maintaining consistency. SemanticCommit detects potential semantic conflicts using a knowledge graph-based retrieval-augmented generation pipeline, and assists users in resolving them with LLM support. Through a within-subjects study with 12 participants comparing SemanticCommit to a chat-with-document baseline (OpenAI Canvas), we find differences in workflow: half of our participants adopted a workflow of impact analysis when using SemanticCommit, where they would first flag conflicts without AI revisions then resolve conflicts locally, despite having access to a global revision feature. Additionally, users felt SemanticCommit offered a greater sense of control without increasing workload. Our findings indicate that AI agent interfaces should help users validate AI retrieval independently from generation, suggesting that the benefits from improved control can offset the costs of manual review. Our work speaks to the need for AI system designers to think about updating memory as a process that involves human feedback and decision-making.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Vaithilingam, Priyan and Kim, Munyeong and Acosta-Parenteau, Frida-Cecilia and Lee, Daniel and Mhedhbi, Amine and Glassman, Elena L. and Arawjo, Ian},
	year = {2025},
	keywords = {AI agents, human-AI grounding, impact analysis, intent specification, large language models, memory management},
}

@inproceedings{zhang_mmr_2025,
	address = {New York, NY, USA},
	series = {{ISAIMS} '24},
	title = {{MMR}: {Math} {Multi}-step {Reasoning} in {Medical} {Dialogue} {Generation}},
	isbn = {979-8-4007-1782-6},
	url = {https://doi.org/10.1145/3706890.3706951},
	doi = {10.1145/3706890.3706951},
	abstract = {With the advancements of large language models in text and visual tasks, researchers are increasingly exploring their applications in medical scenarios. While existing studies have successfully applied these models to medical dialogue systems, challenges remain in accurately calculating medication dosages and handling multi-turn reasoning due to the low tolerance for error in medical contexts. To address this, we propose Math Multi-step Reasoning in Medical Dialogue Generation (MMR), which enhances reasoning by iteratively breaking down complex problems into simpler questions using a “Least to Most Prompting” (LMP)strategy. MMR integrates Chain of Thought, React mechanisms, and Retrieval-Augmented Generation (RAG) with a domain-specific knowledge base to improve reasoning accuracy. Supported by the MedDGQA dataset, MMR outperforms state-of-the-art methods in both objective and subjective evaluations.},
	booktitle = {Proceedings of the 2024 5th {International} {Symposium} on {Artificial} {Intelligence} for {Medicine} {Science}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Tao and Zhao, Likun},
	year = {2025},
	keywords = {Large Language Models, Medical Dialogue Generation, Multi-step Reasoning},
	pages = {348--351},
}

@inproceedings{shi_learnable_2024,
	address = {New York, NY, USA},
	series = {{MMGR} '24},
	title = {A {Learnable} {Agent} {Collaboration} {Network} {Framework} for {Personalized} {Multimodal} {AI} {Search} {Engine}},
	isbn = {979-8-4007-1202-9},
	url = {https://doi.org/10.1145/3689091.3690087},
	doi = {10.1145/3689091.3690087},
	abstract = {Large language models (LLMs) and retrieval-augmented generation (RAG) techniques have revolutionized traditional information access, enabling AI agent to search and summarize information on behalf of users during dynamic dialogues. Despite their potential, current AI search engines exhibit considerable room for improvement in several critical areas. These areas include the support for multimodal information, the delivery of personalized responses, the capability to logically answer complex questions, and the facilitation of more flexible interactions. This paper proposes a novel AI Search Engine framework called the Agent Collaboration Network (ACN). The ACN framework consists of multiple specialized agents working collaboratively, each with distinct roles such as Account Manager, Solution Strategist, Information Manager, and Content Creator. This framework integrates mechanisms for picture content understanding, user profile tracking, and online evolution, enhancing the AI search engine's response quality, personalization, and interactivity. A highlight of the ACN is the introduction of a Reflective Forward Optimization method (RFO), which supports the online synergistic adjustment among agents. This feature endows the ACN with online learning capabilities, ensuring that the system has strong interactive flexibility and can promptly adapt to user feedback. This learning method may also serve as an optimization approach for agent-based systems, potentially influencing other domains of agent applications.},
	booktitle = {Proceedings of the 2nd {International} {Workshop} on {Deep} {Multimodal} {Generation} and {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Shi, Yunxiao and Xu, Min and Zhang, Haimin and Zi, Xing and Wu, Qiang},
	year = {2024},
	note = {event-place: Melbourne VIC, Australia},
	keywords = {information retrieval and generation, multi-agent system, multimodal, personalized search},
	pages = {12--20},
}

@inproceedings{hoseini_end--end_2025,
	address = {New York, NY, USA},
	series = {{DEEM} '25},
	title = {End-{To}-{End} {ML} with {LLMs} and {Semantic} {Data} {Management}: {Experiences} from {Chemistry} 4.0},
	isbn = {979-8-4007-1924-0},
	url = {https://doi.org/10.1145/3735654.3735942},
	doi = {10.1145/3735654.3735942},
	abstract = {Machine Learning (ML) in industrial chemistry is often hindered by the complexity of preprocessing heterogeneous datasets. In this proof-of-concept study, we explore the use of semantic data management to support LLM-driven automation of end-to-end ML pipelines in a real-world Chemistry 4.0 setting. A semantic model is used to capture domain knowledge and metadata in a machine-readable form, guiding LLMs through natural language prompts to generate complete data wrangling and ML modeling code. We evaluate several state-of-the-art LLMs on their ability to autonomously produce functionally correct Python code for preprocessing and Gaussian Process modeling. Our results show that, when guided by structured semantic context, larger LLMs can reliably generate accurate pipelines, significantly reducing the need for manual intervention. These findings provide an encouraging starting point for further exploration toward leveraging the semantic model to improve the robustness of code generation by systematically integrating relevant information into the generation process, rather than relying solely on the raw intelligence of the LLM.},
	booktitle = {Proceedings of the {Workshop} on {Data} {Management} for {End}-to-{End} {Machine} {Learning}},
	publisher = {Association for Computing Machinery},
	author = {Hoseini, Sayed and Herrmann, Vincent and Quix, Christoph},
	year = {2025},
	note = {event-place: Berlin, Germany},
	keywords = {AutoML, Data Wrangling, LLMs, Semantic Data Management},
}

@inproceedings{ruan_specrover_2025,
	address = {Ottawa, Ontario, Canada},
	series = {{ICSE} '25},
	title = {{SpecRover}: {Code} {Intent} {Extraction} via {LLMs}},
	isbn = {979-8-3315-0569-1},
	url = {https://doi.org/10.1109/ICSE55347.2025.00080},
	doi = {10.1109/ICSE55347.2025.00080},
	abstract = {Autonomous program improvement typically involves automatically producing bug fixes and feature additions. Such program improvement can be accomplished by a combination of large language model (LLM) and program analysis capabilities, in the form of an LLM agent. Since program repair or program improvement typically requires a specification of intended behavior - specification inference can be useful for producing high quality program patches. In this work, we examine efficient and low-cost workflows for iterative specification inference within an LLM agent. Given a GitHub issue to be resolved in a software project, our goal is to conduct iterative code search accompanied by specification inference - thereby inferring intent from both the project structure and behavior. The intent thus captured is examined by a reviewer agent with the goal of vetting the patches as well as providing a measure of confidence in the vetted patches. Our approach SpecRover is built on the open-source LLM agent AutoCodeRover. In an evaluation on the full SWE-Bench consisting of 2294 GitHub issues, it shows more than 50\% improvement in efficacy over AutoCodeRover. Compared to the open-source agents available, our work shows modest cost (\$0.65 per issue) in resolving an average GitHub issue in SWE-Bench lite. The production of explanation by SpecRover allows for a better "signal" to be given to the developer, on when the suggested patches can be accepted with confidence. SpecRover also seeks to demonstrate the continued importance of specification inference in automated program repair, even as program repair technologies enter the LLM era.},
	booktitle = {Proceedings of the {IEEE}/{ACM} 47th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Ruan, Haifeng and Zhang, Yuntong and Roychoudhury, Abhik},
	year = {2025},
	pages = {963--974},
}

@inproceedings{correia_unveiling_2024,
	address = {New York, NY, USA},
	series = {{AIware} 2024},
	title = {Unveiling the {Potential} of a {Conversational} {Agent} in {Developer} {Support}: {Insights} from {Mozilla}’s {PDF}.js {Project}},
	isbn = {979-8-4007-0685-1},
	url = {https://doi.org/10.1145/3664646.3664758},
	doi = {10.1145/3664646.3664758},
	abstract = {Large language models and other foundation models (FMs) boost productivity by automating code generation, supporting bug fixes, and generating documentation. We propose that FMs can further support Open Source Software (OSS) projects by assisting developers and guiding the community. Currently, core developers and maintainers answer queries about processes, architecture, and source code, but their time is limited, often leading to delays. To address this, we introduce DevMentorAI, a tool that enhances developer-project interactions by leveraging source code and technical documentation. DevMentorAI uses the Retrieval Augmented Generation (RAG) architecture to identify and retrieve relevant content for queries. We evaluated DevMentorAI with a case study on PDF.js project, using real questions from a development chat room and comparing the answers provided by DevMentorAI to those from humans. A Mozilla expert rated the answers, finding DevMentorAI's responses more satisfactory in 8/14 of cases, equally satisfactory in 3/14, and less satisfactory in 3/14. These results demonstrate the potential of using foundation models and the RAG approach to support developers and reduce the burden on core developers.},
	booktitle = {Proceedings of the 1st {ACM} {International} {Conference} on {AI}-{Powered} {Software}},
	publisher = {Association for Computing Machinery},
	author = {Correia, João and Nicholson, Morgan C. and Coutinho, Daniel and Barbosa, Caio and Castelluccio, Marco and Gerosa, Marco and Garcia, Alessandro and Steinmacher, Igor},
	year = {2024},
	note = {event-place: Porto de Galinhas, Brazil},
	keywords = {Conversational Agents, Developer Assistance, Large Language Models, Software Development, Software Engineering},
	pages = {10--18},
}

@inproceedings{sattabun_enhancing_2025,
	address = {New York, NY, USA},
	series = {{APIT} '25},
	title = {Enhancing {Reading} {Comprehension}: {A} {Comparative} {Study} of {Models} for {Generating} {Questions} in {Children}'s {Storybooks}},
	isbn = {979-8-4007-0728-5},
	url = {https://doi.org/10.1145/3726101.3726109},
	doi = {10.1145/3726101.3726109},
	abstract = {The development of critical thinking skills in childhood is a vital aspect of cognitive growth, and one effective yet often underutilized approach is encouraging reflective thinking through questions posed at the end of fairy tales. This study explores how Open-source Large Language Models (LLMs) can be used to generate expert-like questions, focusing on identifying the most effective strategy for this task. Using a dataset of 10,580 question sets derived from 278 children's fairy tales from the Project Gutenberg repository, we evaluated two established approaches—prompting and fine-tuning—across three LLMs: T5-base, Llama 2 7B, and Mistral 7B. The results revealed that while simple prompting methods are desirable for their ease of use, fine-tuning outperformed prompting in generating high-quality questions. Among the models tested, the fine-tuned Mistral 7B model achieved the best results, with a ROUGE-L score of 0.58 and a BLEU-4 score of 0.39. These findings highlight the practical trade-off between simplicity and performance, underscoring the importance of advanced fine-tuning skills for achieving optimal results in question generation tasks, particularly in educational contexts.},
	booktitle = {Proceedings of the 2025 7th {Asia} {Pacific} {Information} {Technology} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Sattabun, Thunpitcha and Siriborvornratanakul, Thitirat},
	year = {2025},
	keywords = {Artificial intelligence, Children storybook, Deep learning, Open-source large language model, Question generation},
	pages = {40--51},
}

@inproceedings{pratelli_evaluation_2025,
	address = {New York, NY, USA},
	series = {Websci '25},
	title = {Evaluation of {Reliability} {Criteria} for {News} {Publishers} with {Large} {Language} {Models}},
	isbn = {979-8-4007-1483-2},
	url = {https://doi.org/10.1145/3717867.3717924},
	doi = {10.1145/3717867.3717924},
	abstract = {In this study, we investigate the use of a large language model to assist in the evaluation of the reliability of the vast number of existing online news publishers, addressing the impracticality of relying solely on human expert annotators for this task. In the context of the Italian news media market, we first task the model with evaluating expert-designed reliability criteria using a representative sample of news articles. We then compare the model’s answers with those of human experts. The dataset consists of 352 news articles annotated by three human experts and the LLM. Examining 6,081 annotations over six criteria, we observe good agreement between LLM and human annotators in three evaluated criteria, including the critical ability to detect instances where a text negatively targets an entity or individual. For two additional criteria, such as the detection of sensational language and the recognition of bias in news content, LLMs generate fair annotations, albeit with certain trade-offs. Furthermore, we show that the LLM is able to help resolve disagreements among human experts, especially in tasks such as identifying cases of negative targeting.},
	booktitle = {Proceedings of the 17th {ACM} {Web} {Science} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Pratelli, Manuel and Bianchi, John and Pinelli, Fabio and Petrocchi, Marinella},
	year = {2025},
	keywords = {Generative Question Answering, Good Editorial Practices, Inter-annotator agreement, LLMs, Reliability Evaluation},
	pages = {179--188},
}

@inproceedings{fok_qlarify_2024,
	address = {New York, NY, USA},
	series = {{UIST} '24},
	title = {Qlarify: {Recursively} {Expandable} {Abstracts} for {Dynamic} {Information} {Retrieval} over {Scientific} {Papers}},
	isbn = {979-8-4007-0628-8},
	url = {https://doi.org/10.1145/3654777.3676397},
	doi = {10.1145/3654777.3676397},
	abstract = {Navigating the vast scientific literature often starts with browsing a paper’s abstract. However, when a reader seeks additional information, not present in the abstract, they face a costly cognitive chasm during their dive into the full text. To bridge this gap, we introduce recursively expandable abstracts, a novel interaction paradigm that dynamically expands abstracts by progressively incorporating additional information from the papers’ full text. This lightweight interaction allows scholars to specify their information needs by quickly brushing over the abstract or selecting AI-suggested expandable entities. Relevant information is synthesized using a retrieval-augmented generation approach, presented as a fluid, threaded expansion of the abstract, and made efficiently verifiable via attribution to relevant source-passages in the paper. Through a series of user studies, we demonstrate the utility of recursively expandable abstracts and identify future opportunities to support low-effort and just-in-time exploration of long-form information contexts through LLM-powered interactions.},
	booktitle = {Proceedings of the 37th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Fok, Raymond and Chang, Joseph Chee and August, Tal and Zhang, Amy X. and Weld, Daniel S.},
	year = {2024},
	note = {event-place: Pittsburgh, PA, USA},
	keywords = {Information Retrieval, Interactive Documents, Large Language Models, Mixed-Initiative User Interfaces, Scientific Papers},
}

@inproceedings{farzi_does_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Does {UMBRELA} work on other {LLMs}?},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730317},
	doi = {10.1145/3726302.3730317},
	abstract = {We reproduce the UMBRELA LLM Judge evaluation framework across a range of large language models (LLMs) to assess its generalizability beyond the original study. Our investigation evaluates how LLM choice affects relevance assessment accuracy, focusing on leaderboard rank correlation and per-label agreement metrics. Results demonstrate that UMBRELA with DeepSeek V3 obtains very comparable performance to GPT-4o (used in original work). For LLaMA-3.3-70B we obtain slightly lower performance, which further degrades with smaller LLMs.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Farzi, Naghmeh and Dietz, Laura},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {large language models, llm evaluation, relevance criteria},
	pages = {3214--3222},
}

@inproceedings{adhikari_exploring_2025,
	address = {New York, NY, USA},
	series = {{CUI} '25},
	title = {Exploring {LLMs} for {Automated} {Generation} and {Adaptation} of {Questionnaires}},
	isbn = {979-8-4007-1527-3},
	url = {https://doi.org/10.1145/3719160.3736606},
	doi = {10.1145/3719160.3736606},
	abstract = {Effective questionnaire design improves the validity of the results, but creating and adapting questionnaires across contexts is challenging due to resource constraints and limited expert access. Recently, the emergence of LLMs has led researchers to explore their potential in survey research. In this work, we focus on the suitability of LLMs in assisting the generation and adaptation of questionnaires. We introduce a novel pipeline that leverages LLMs to create new questionnaires, pretest with a target audience to determine potential issues and adapt existing standardized questionnaires for different contexts. We evaluated our pipeline for creation and adaptation through two studies on Prolific, involving 238 participants from the US and 118 participants from South Africa. Our findings show that participants found LLM-generated text clearer, LLM-pretested text more specific, and LLM-adapted questions slightly clearer and less biased than traditional ones. Our work opens new opportunities for LLM-driven questionnaire support in survey research.},
	booktitle = {Proceedings of the 7th {ACM} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Adhikari, Divya Mani and Hartland, Alexander and Weber, Ingmar and Cannanure, Vikram Kamath},
	year = {2025},
	keywords = {Cross-cultural Adaptation, Large Language Models (LLMs), Questionnaire Design, Questionnaire Pretesting, Survey Methodology},
}

@inproceedings{lin_haprepair_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {{HapRepair}: {Learn} to {Repair} {OpenHarmony} {Apps}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3728556},
	doi = {10.1145/3696630.3728556},
	abstract = {Software defect detection and repair are essential software engineering tasks that mitigate potential risks in the early development stages. Large Language Models (LLMs) have demonstrated significant capabilities in software defect detection and repair. However, it is hard for LLMs to handle the new programming languages such as ArkTS (which is predominantly used in the OpenHarmony platform) due to training data shortage. Additionally, LLM-based multi-defect repair suffers from the limitation of the context window of LLMs. These issues significantly affect the performance of LLM-based defect repair in new programming languages. To address the above challenges, we propose HapRepair, a defect repair framework that integrates static analysis tools with retrieval-augmented generation (RAG) to improve the effectiveness of the defect repair. Specifically, we integrate CodeLinter into our iterative defect repair framework for defect detection, which is the basis of defect repair, and utilize RAG together with ArkAnalyzer to improve the quality of our repair solutions. To overcome the context window limitation of LLMs, we propose the Surrounding Context Extractor and the Context Combination Tool. Experiment results show that HapRepair effectively repairs defects in OpenHarmony Apps, demonstrating high reliability and efficiency in addressing code issues, achieving a defect repair rate of about 99\% on the test set, compared to only about 37\% when directly using LLMs for defect repair based on the defect information. Our approach demonstrates a robust solution for defect repair on new programming languages that have limited code corpus.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Lin, Zhihao and Zhou, Mingyi and Ma, Wei and Chen, Chi and Yang, Yun and Wang, Jun and Hu, Chunming and Li, Li},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	pages = {319--330},
}

@inproceedings{xu_search---chain_2024,
	address = {New York, NY, USA},
	series = {{WWW} '24},
	title = {Search-in-the-{Chain}: {Interactively} {Enhancing} {Large} {Language} {Models} with {Search} for {Knowledge}-intensive {Tasks}},
	isbn = {979-8-4007-0171-9},
	url = {https://doi.org/10.1145/3589334.3645363},
	doi = {10.1145/3589334.3645363},
	abstract = {Making the contents generated by Large Language Model (LLM), accurate, credible and traceable is crucial, especially in complex knowledge-intensive tasks that require multi-step reasoning and each step needs knowledge to solve. Retrieval-augmented generation is good potential to solve this problem. However, where and how to introduce Information Retrieval (IR) to LLM is a big challenge. Previous work has the problems that wrong knowledge retrieved by IR misleads the LLM and interaction between IR and LLM breaks the reasoning chain of LLM. This paper proposes a novel framework named Search-in-the-Chain (SearChain) for the interaction between LLM and IR to solve the challenges. First, LLM generates the reasoning chain named Chain-of-Query (CoQ) where each node consists of an IR-oriented query-answer pair. Second, IR verifies the answer of each node of CoQ. It corrects the answer that is not consistent with the retrieved information when IR gives high confidence, which improves the credibility. Third, LLM can indicate its missing knowledge in CoQ and rely on IR to provide this knowledge to LLM. These operations improve the accuracy in terms of reasoning and knowledge. Finally, SearChain generates the reasoning process and marks references to supporting documents for each reasoning step, which improves traceability. Interaction with IR in SearChain forms a novel reasoning path based on a tree, which enables LLM to dynamically modify the direction of reasoning. Experiments show that SearChain outperforms state-of-the-art baselines on complex knowledge-intensive tasks including multi-hop Q\&amp;A, slot filling, fact checking, and long-form Q\&amp;A.},
	booktitle = {Proceedings of the {ACM} {Web} {Conference} 2024},
	publisher = {Association for Computing Machinery},
	author = {Xu, Shicheng and Pang, Liang and Shen, Huawei and Cheng, Xueqi and Chua, Tat-Seng},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	keywords = {large language models, retrieval-augmented model},
	pages = {1362--1373},
}

@inproceedings{ma_librelog_2025,
	address = {Ottawa, Ontario, Canada},
	series = {{ICSE} '25},
	title = {{LibreLog}: {Accurate} and {Efficient} {Unsupervised} {Log} {Parsing} {Using} {Open}-{Source} {Large} {Language} {Models}},
	isbn = {979-8-3315-0569-1},
	url = {https://doi.org/10.1109/ICSE55347.2025.00103},
	doi = {10.1109/ICSE55347.2025.00103},
	abstract = {Log parsing is a critical step that transforms unstructured log data into structured formats, facilitating subsequent log-based analysis. Traditional syntax-based log parsers are efficient and effective, but they often experience decreased accuracy when processing logs that deviate from the predefined rules. Recently, large language models (LLM) based log parsers have shown superior parsing accuracy. However, existing LLM-based parsers face three main challenges: 1) time-consuming and labor-intensive manual labeling for fine-tuning or in-context learning, 2) increased parsing costs due to the vast volume of log data and limited context size of LLMs, and 3) privacy risks from using commercial models like ChatGPT with sensitive log information. To overcome these limitations, this paper introduces LibreLog, an unsupervised log parsing approach that leverages open-source LLMs (i.e., Llama3-8B) to enhance privacy and reduce operational costs while achieving state-of-the-art parsing accuracy. LibreLog first groups logs with similar static text but varying dynamic variables using a fixed-depth grouping tree. It then parses logs within these groups using three components: i) similarity scoring-based retrieval augmented generation: selects diverse logs within each group based on Jaccard similarity, helping the LLM distinguish between static text and dynamic variables; ii) self-reflection: iteratively query LLMs to refine log templates to improve parsing accuracy; and iii) log template memory: stores parsed templates to reduce LLM queries for improved parsing efficiency. Our evaluation on LogHub-2.0 shows that LibreLog achieves 25\% higher parsing accuracy and processes logs 2.7 times faster compared to state-of-the-art LLM-based parsers. In short, LibreLog addresses privacy and cost concerns of using commercial LLMs while achieving state-of-the-arts parsing efficiency and accuracy.},
	booktitle = {Proceedings of the {IEEE}/{ACM} 47th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Ma, Zeyang and Kim, Dong Jae and Chen, Tse-Hsun (Peter)},
	year = {2025},
	pages = {924--936},
}

@inproceedings{taveekitworachai_enhancing_2023,
	address = {New York, NY, USA},
	series = {{IAIT} '23},
	title = {Enhancing {Novelty} in {ChatGPT} {Responses}: {Incorporating} {Random} {Word} {Brainstorming}},
	isbn = {979-8-4007-0849-7},
	url = {https://doi.org/10.1145/3628454.3628456},
	doi = {10.1145/3628454.3628456},
	abstract = {This paper presents a new prompting approach for increasing the novelty in ChatGPT responses. ChatGPT has proven to be effective in generating natural language responses; however, ensuring response novelty remains challenging. Our proposed method, inspired by random word brainstorming, includes random words in prompts to introduce more diversity in ChatGPT responses. Through a questionnaire-based evaluation, we compared preferences for solution ideas generated using the standard approach and our proposed approach. We found that participants preferred our technique in 65\% of the 20 problems. The results suggest the effectiveness of our proposed approach. We also explored the use of GPT models as evaluators, with GPT-3.5 achieving 65\% accuracy and GPT-4 achieving 70\% accuracy when compared to human preferences from the questionnaire. These results suggest the potential of leveraging GPT models as noisy natural language evaluators. For future studies, we recommend focusing on prompt engineering and word list design to further improve performance. Overall, incorporating random words in prompts can effectively increase novelty in ChatGPT responses.},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Advances} in {Information} {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Taveekitworachai, Pittawat and Thawonmas, Ruck},
	year = {2023},
	note = {event-place: Bangkok, Thailand},
	keywords = {ChatGPT, Prompt engineering, Random word brainstorming},
}

@inproceedings{wang_decoding_2024,
	address = {New York, NY, USA},
	series = {{MM} '24},
	title = {Decoding {Urban} {Industrial} {Complexity}: {Enhancing} {Knowledge}-{Driven} {Insights} via {IndustryScopeGPT}},
	isbn = {979-8-4007-0686-8},
	url = {https://doi.org/10.1145/3664647.3681705},
	doi = {10.1145/3664647.3681705},
	abstract = {Industrial parks are critical to urban economic growth. Yet, their development often encounters challenges stemming from imbalances between industrial requirements and urban services, underscoring the need for strategic planning and operations. This paper introduces IndustryScopeKG, a pioneering large-scale multi-modal, multi-level industrial park knowledge graph, which integrates diverse urban data including street views, corporate, socio-economic, and geospatial information, capturing the complex relationships and semantics within industrial parks. Alongside this, we present the IndustryScopeGPT framework, which leverages Large Language Models (LLMs) with Monte Carlo Tree Search to enhance tool-augmented reasoning and decision-making in Industrial Park Planning and Operation (IPPO). Our work significantly improves site recommendation and functional planning, demonstrating the potential of combining LLMs with structured datasets to advance industrial park management. This approach sets a new benchmark for intelligent IPPO research and lays a robust foundation for advancing urban industrial development. The dataset and related code are available at https://github.com/Tongji-KGLLM/IndustryScope.},
	booktitle = {Proceedings of the 32nd {ACM} {International} {Conference} on {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Siqi and Liang, Chao and Gao, Yunfan and Liu, Yang and Li, Jing and Wang, Haofen},
	year = {2024},
	note = {event-place: Melbourne VIC, Australia},
	keywords = {industrial park planning and operation, large language model agent, urban design and planning, urban knowledge graph},
	pages = {4757--4765},
}

@inproceedings{paria_navigating_2024,
	address = {New York, NY, USA},
	series = {{GLSVLSI} '24},
	title = {Navigating {SoC} {Security} {Landscape} on {LLM}-{Guided} {Paths}},
	isbn = {979-8-4007-0605-9},
	url = {https://doi.org/10.1145/3649476.3660393},
	doi = {10.1145/3649476.3660393},
	abstract = {The increasing prominence of Large Language Models (LLMs) is being acknowledged for their exceptional abilities in comprehending natural language, conducting advanced reasoning, and generating contextual responses. LLMs expedite code generation, verification, and bug-fixing tasks across software and hardware domains. Development of hardware designs typically involves translating natural language specifications into Hardware Description Languages (HDLs) like Verilog or SystemVerilog, followed by circuit synthesis, physical layout, and fabrication, with the potential for human errors in the process. In the current industry practice, HDL verification tasks typically rely on manual expertise from security professionals to detect and address vulnerabilities. Modern System-on-Chip (SoC) designs integrate several Intellectual Property (IP) blocks implemented using HDL and communicate through a common bus to perform intended functions. Ensuring security throughout the SoC design process requires innovative solutions due to the complex nature of SoC designs and the distribution of assets across multiple IP blocks. Popular conversation LLMs such as Open AI’s ChatGPT and Google’s GEMINI (formerly BARD) offer the potential to automate HDL code generation and verification tasks by interpreting user prompts represented in natural language descriptions, thereby minimizing manual effort and enhancing hardware design quality. This paper explores recent research works on HDL generation, verification, and bug fix leveraging LLMs while addressing prevailing challenges and presenting potential opportunities for improvement.},
	booktitle = {Proceedings of the {Great} {Lakes} {Symposium} on {VLSI} 2024},
	publisher = {Association for Computing Machinery},
	author = {Paria, Sudipta and Dasgupta, Aritra and Bhunia, Swarup},
	year = {2024},
	note = {event-place: Clearwater, FL, USA},
	keywords = {Bug Fix, CWEs., Formal Verification, HDL Code, LLMs, SoC Security, SVA, Verilog},
	pages = {252--257},
}

@inproceedings{santana_can_2025,
	address = {New York, NY, USA},
	series = {{IUI} '25},
	title = {Can {LLMs} {Recommend} {More} {Responsible} {Prompts}?},
	isbn = {979-8-4007-1306-4},
	url = {https://doi.org/10.1145/3708359.3712137},
	doi = {10.1145/3708359.3712137},
	abstract = {Human-Computer Interaction practitioners have been proposing best practices in user interface design for decades. However, generative Artificial Intelligence (GenAI) brings additional design considerations and currently lacks sufficient user guidance regarding affordances, inputs, and outputs. In this context, we developed a recommender system to promote responsible AI (RAI) practices while people prompt GenAI systems, by recommending addition of sentences based on social values and removal of harmful sentences. We detail a lightweight recommender system designed to be used in prompting-time and compare its recommendations to the ones provided by three base large language models (LLMs) and two LLMs fine-tuned for the task, i.e., recommending inclusion of sentences based on social values and removal of harmful sentences from a given prompt. Results indicate that our approach has the best F1-score balance in terms of recommendations for additions and removal of sentences to promote responsible prompts, while a fine-tuned model obtained the best F1-score for additions, and our approach obtained the best F1-score for removals of harmful sentences. In addition, fine-tuned models improved the objectiveness of responses by reducing the verbosity of generated content in 93\% when compared to the content generated by base models. Presented findings contribute to RAI by showing the limits and bias of existing LLMs in terms of recommendations on how to create more responsible prompts and how open-source technologies can fill this gap in prompting-time.},
	booktitle = {Proceedings of the 30th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Santana, Vagner Figueredo de and Berger, Sara and Machado, Tiago and de Macedo, Maysa Malfiza Garcia and Sanctos, Cassia Sampaio and Williams, Lemara and Wu, Zhaoqing},
	year = {2025},
	keywords = {Prompt Engineering, Recommendation Systems, Recommender Systems, Responsible AI, Responsible Prompting},
	pages = {298--313},
}

@inproceedings{koziolek_llm-based_2024-1,
	address = {New York, NY, USA},
	series = {{LLM4Code} '24},
	title = {{LLM}-based {Control} {Code} {Generation} using {Image} {Recognition}},
	isbn = {979-8-4007-0579-3},
	url = {https://doi.org/10.1145/3643795.3648385},
	doi = {10.1145/3643795.3648385},
	abstract = {LLM-based code generation could save significant manual efforts in industrial automation, where control engineers manually produce control logic for sophisticated production processes. Previous attempts in control logic code generation lacked methods to interpret schematic drawings from process engineers. Recent LLMs now combine image recognition, trained domain knowledge, and coding skills. We propose a novel LLM-based code generation method that generates IEC 61131-3 Structure Text control logic source code from Piping-and-Instrumentation Diagrams (P\&amp;IDs) using image recognition. We have evaluated the method in three case study with industrial P\&amp;IDs and provide first evidence on the feasibility of such a code generation besides experiences on image recognition glitches.},
	booktitle = {Proceedings of the 1st {International} {Workshop} on {Large} {Language} {Models} for {Code}},
	publisher = {Association for Computing Machinery},
	author = {Koziolek, Heiko and Koziolek, Anne},
	year = {2024},
	note = {event-place: Lisbon, Portugal},
	keywords = {ChatGPT, code generation, DCS, GPT4, IDs, IEC 61131-3, image recognition, industrial automation, industrial case study, large language models, P\&amp, PLC},
	pages = {38--45},
}

@inproceedings{solch_direct_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {Direct {Automated} {Feedback} {Delivery} for {Student} {Submissions} based on {LLMs}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3727247},
	doi = {10.1145/3696630.3727247},
	abstract = {Timely and individualized feedback is essential for students' learning progress and motivation, yet providing such feedback has become increasingly challenging due to growing student numbers. This has resulted in a time-consuming, repetitive, and often manual task for educators, contributing to a high workload.This paper presents DAFeeD, an LLM-based approach for automated feedback on student submissions across various exercise domains. The defined feedback process enables interactive learning by allowing students to submit solutions multiple times and automatically receive iterative LLM feedback on their submission attempts before deadlines. By incorporating task details, grading criteria, student solutions, and custom instructions into the prompt, DAFeeD provides clear, personalized, and pedagogically meaningful feedback to support continuous improvement.To evaluate the feedback process, we implemented DAFeeD in an open-source reference implementation integrated into the learning platform Artemis. A controlled study with students working on a programming task in a supervised environment showed that students found the feedback relevant and beneficial. They reported feeling more comfortable and willing to request automated feedback due to its convenience and immediacy. Additionally, deploying DAFeeD in a software engineering course with 450 students demonstrated improvements in student performance and encouraged iterative refinement through multiple submissions.These findings highlight DAFeeD's potential to enhance feedback processes in computing education, improving both learning efficiency and student outcomes.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Sölch, Maximilian and Dietrich, Felix T. J. and Krusche, Stephan},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {education, formative feedback, grading, software engineering},
	pages = {901--911},
}

@inproceedings{ashkinaze_plurals_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Plurals: {A} {System} for {Guiding} {LLMs} via {Simulated} {Social} {Ensembles}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713675},
	doi = {10.1145/3706598.3713675},
	abstract = {Recent debates raised concerns that language models may favor certain viewpoints. But what if the solution is not to aim for a “view from nowhere” but rather to leverage different viewpoints? We introduce Plurals, a system and Python library for pluralistic AI deliberation. Plurals consists of Agents (LLMs, optionally with personas) which deliberate within customizable Structures, with Moderators overseeing deliberation. Plurals is a generator of simulated social ensembles. Plurals integrates with government datasets to create nationally representative personas, includes deliberation templates inspired by deliberative democracy, and allows users to customize both information-sharing structures and deliberation behavior within Structures. Six case studies demonstrate fidelity to theoretical constructs and efficacy. Three randomized experiments show simulated focus groups produced output resonant with an online sample of the relevant audiences (chosen over zero-shot generation in 75\% of trials). Plurals is both a paradigm and a concrete system for pluralistic AI.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ashkinaze, Joshua and Fry, Emily and Edara, Narendra and Gilbert, Eric and Budak, Ceren},
	year = {2025},
	keywords = {Artificial Intelligence, Human-AI Interaction, Human-Computer Interaction, Multi-Agent Systems, Pluralism},
}

@inproceedings{pontes_miranda_towards_2024,
	address = {New York, NY, USA},
	series = {{SLE} '24},
	title = {Towards an {In}-{Context} {LLM}-{Based} {Approach} for {Automating} the {Definition} of {Model} {Views}},
	isbn = {979-8-4007-1180-0},
	url = {https://doi.org/10.1145/3687997.3695650},
	doi = {10.1145/3687997.3695650},
	abstract = {In the Model-Driven Engineering (MDE) of complex systems, multiple models represent various systems' aspects. In practice, these models are often unconnected and specified using different modeling languages. Model view solutions can be employed to automatically combine such models. However, writing model view definitions is not trivial. When modeling languages are semantically distant and/or have a large number of concepts, it can quickly become difficult to manually identify the language elements to be selected, associated, or queried to build a model view. As a solution, this paper proposes an in-context Large Language Model (LLM)-based approach to assist engineers in writing model-view definitions. Notably, we rely on LLMs and Prompt Engineering techniques to automatically generate drafts of model-view definitions by providing as input only minimal information on the modeling languages to be combined. We implemented our approach by integrating the EMF Views solution for model views with the LangChain framework for LLM-based applications. To this end, we tailored LangChain to handle EMF metamodels. We validated our approach and implementation on a set of model views originally specified either in VPDL, the ViewPoint Definition Language of EMF Views, or as ATL model-to-model transformations. We compared these original model view definitions with the ones we automatically generated. The obtained results show the feasibility and applicability of our approach.},
	booktitle = {Proceedings of the 17th {ACM} {SIGPLAN} {International} {Conference} on {Software} {Language} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Pontes Miranda, James William and Bruneliere, Hugo and Tisi, Massimo and Sunyé, Gerson},
	year = {2024},
	note = {event-place: Pasadena, CA, USA},
	keywords = {Large language models, Model views, Model-driven engineering, Modeling languages, Prompt engineering},
	pages = {29--42},
}

@inproceedings{hu_research_2025,
	address = {New York, NY, USA},
	series = {{ISAICS} '24},
	title = {Research on the {Application} {Methods} of {Large} {Models} for {Military} {Domain} {Knowledge} {Question}-{Answering} {Systems}},
	isbn = {979-8-4007-1442-9},
	url = {https://doi.org/10.1145/3744103.3744120},
	doi = {10.1145/3744103.3744120},
	abstract = {Abstract: With the rapid development of artificial intelligence, large military intelligence models are increasingly applied in key areas such as battlefield monitoring, decision support, and multi-source intelligence integration. These models can provide real-time situational awareness, optimize strategic planning, and help integrate diverse data sources such as satellite imagery, drone reconnaissance, and communication intelligence. The document primarily discusses the applications, training methods, and challenges of large military intelligence models. It highlights how large models are increasingly used in areas such as battlefield monitoring, multi-source intelligence integration, and decision-making support. The document covers four key training methods: Retrieval-Augmented Generation, Incremental Pretraining, Supervised Fine-Tuning, and Reinforcement Learning from Human Feedback, comparing their advantages, disadvantages, and resource demands.},
	booktitle = {Proceedings of the 2024 {International} {Symposium} on {AI} and {Cybersecurity}},
	publisher = {Association for Computing Machinery},
	author = {Hu, Songtao and Zhao, Wenxi and Ma, Bin},
	year = {2025},
	keywords = {Large models, military intelligence, training methods},
	pages = {76--84},
}

@inproceedings{bian_empowering_2025,
	address = {New York, NY, USA},
	series = {{ANRW} '25},
	title = {Empowering {IETF} {Collaboration} with {NLP} {Search} {Innovations} and {LLM}-{Enhanced} {RFC} {Writing}},
	isbn = {979-8-4007-2009-3},
	url = {https://doi.org/10.1145/3744200.3744761},
	doi = {10.1145/3744200.3744761},
	abstract = {The Internet Engineering Task Force (IETF) produces extensive textual data, including discussions in email archives and GitHub repositories and Internet-Drafts (I-Ds), which are preliminary versions of Requests for Comments (RFCs). The sheer volume and complexity of this material present significant workflow challenges, contributing to the duration of the standardization process (it is common to take several years from an initial draft to the final RFC). This paper explores the potential of Natural Language Processing (NLP) using Large Language Models (LLMs) to streamline IETF workflows. We use Information Retrieval (IR) to i) build a search system that helps users locate comments related to details in an I-D, and ii) partially automate RFC writing.},
	booktitle = {Proceedings of the 2025 {Applied} {Networking} {Research} {Workshop}},
	publisher = {Association for Computing Machinery},
	author = {Bian, Jie and Welzl, Michael},
	year = {2025},
	note = {event-place: Madrid, Spain},
	keywords = {I-Ds, IETF, Information Retrieval, Instruction Tuning, LLM, RFC, Test Time Scaling},
	pages = {24--31},
}

@inproceedings{yang_aqua_2024,
	address = {New York, NY, USA},
	series = {{CHI} '24},
	title = {{AQuA}: {Automated} {Question}-{Answering} in {Software} {Tutorial} {Videos} with {Visual} {Anchors}},
	isbn = {979-8-4007-0330-0},
	url = {https://doi.org/10.1145/3613904.3642752},
	doi = {10.1145/3613904.3642752},
	abstract = {Tutorial videos are a popular help source for learning feature-rich software. However, getting quick answers to questions about tutorial videos is difficult. We present an automated approach for responding to tutorial questions. By analyzing 633 questions found in 5,944 video comments, we identified different question types and observed that users frequently described parts of the video in questions. We then asked participants (N=24) to watch tutorial videos and ask questions while annotating the video with relevant visual anchors. Most visual anchors referred to UI elements and the application workspace. Based on these insights, we built AQuA, a pipeline that generates useful answers to questions with visual anchors. We demonstrate this for Fusion 360, showing that we can recognize UI elements in visual anchors and generate answers using GPT-4 augmented with that visual information and software documentation. An evaluation study (N=16) demonstrates that our approach provides better answers than baseline methods.},
	booktitle = {Proceedings of the 2024 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Yang, Saelyne and Vermeulen, Jo and Fitzmaurice, George and Matejka, Justin},
	year = {2024},
	note = {event-place: Honolulu, HI, USA},
	keywords = {generative AI, large language models, question answering, software learning, tutorial videos},
}

@inproceedings{cao_writing_2025,
	address = {New York, NY, USA},
	series = {{WSDM} '25},
	title = {Writing {Style} {Matters}: {An} {Examination} of {Bias} and {Fairness} in {Information} {Retrieval} {Systems}},
	isbn = {979-8-4007-1329-3},
	url = {https://doi.org/10.1145/3701551.3703514},
	doi = {10.1145/3701551.3703514},
	abstract = {The rapid advancement of Language Model technologies has opened new opportunities, but also introduced new challenges related to bias and fairness. This paper explores the uncharted territory of potential biases in state-of-the-art universal text embedding models towards specific document and query writing styles within Information Retrieval (IR) systems. Our investigation reveals that different embedding models exhibit different preferences for document writing style, while more informal and emotive styles are less favored by most embedding models. In terms of query writing styles, many embedding models tend to match the query style with the retrieved document style, but some show a consistent preference for specific styles. Text embedding models fine-tuned on synthetic data generated by LLMs display a consistent preference for certain style of generated data. These biases in text embedding based IR systems can inadvertently silence or marginalize certain communication styles, thereby posing a significant threat to fairness in information retrieval. Finally, we also compare the answer styles of Retrieval Augmented Generation (RAG) systems based on different LLMs and find out that most text embedding models are biased towards LLM's answer styles when used as evaluation metrics for answer correctness. This study sheds light on the critical issue of writing style based bias in IR systems, offering valuable insights for the development of more fair and robust models.},
	booktitle = {Proceedings of the {Eighteenth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Cao, Hongliu},
	year = {2025},
	note = {event-place: Hannover, Germany},
	keywords = {bias, fairness, information retrieval, responsible ai, universal text embeddings, writing styles},
	pages = {336--344},
}

@inproceedings{huh_vid2coach_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {{Vid2Coach}: {Transforming} {How}-{To} {Videos} into {Task} {Assistants}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747612},
	doi = {10.1145/3746059.3747612},
	abstract = {People use videos to learn new recipes, exercises, and crafts. Such videos remain difficult for blind and low vision (BLV) people to follow as they rely on visual comparison. Our observations of visual rehabilitation therapists (VRTs) guiding BLV people to follow how-to videos revealed that VRTs provide both proactive and responsive support including detailed descriptions, non-visual workarounds, and progress feedback. We propose Vid2Coach, a system that transforms how-to videos into wearable camera-based assistants that provide accessible instructions and mixed-initiative feedback. From the video, Vid2Coach generates accessible instructions by augmenting narrated instructions with demonstration details and completion criteria for each step. It then uses retrieval-augmented-generation to extract relevant non-visual workarounds from BLV-specific resources. Vid2Coach then monitors user progress with a camera embedded in commercial smart glasses to provide context-aware instructions, proactive feedback, and answers to user questions. BLV participants (N=8) using Vid2Coach completed cooking tasks with 58.5\% fewer errors than when using their typical workflow and wanted to use Vid2Coach in their daily lives. Vid2Coach demonstrates an opportunity for AI visual assistance that strengthens rather than replaces non-visual expertise.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Huh, Mina and Xue, Zihui and Das, Ujjaini and Ashutosh, Kumar and Grauman, Kristen and Pavel, Amy},
	year = {2025},
	keywords = {Accessibility, How-To Videos, Task Assistant, Video Understanding},
}

@inproceedings{sabouri_trust_2025,
	address = {Ottawa, Ontario, Canada},
	series = {{ICSE} '25},
	title = {Trust {Dynamics} in {AI}-{Assisted} {Development}: {Definitions}, {Factors}, and {Implications}},
	isbn = {979-8-3315-0569-1},
	url = {https://doi.org/10.1109/ICSE55347.2025.00199},
	doi = {10.1109/ICSE55347.2025.00199},
	abstract = {Software developers increasingly rely on AI code generation utilities. To ensure that "good" code is accepted into the code base and "bad" code is rejected, developers must know when to trust an AI suggestion. Understanding how developers build this intuition is crucial to enhancing developer-AI collaborative programming. In this paper, we seek to understand how developers (1) define and (2) evaluate the trustworthiness of a code suggestion and (3) how trust evolves when using AI code assistants. To answer these questions, we conducted a mixed-method study consisting of an in-depth exploratory survey with (n=29) developers followed by an observation study (n=10).We found that comprehensibility and perceived correctness were the most frequently used factors to evaluate code suggestion trustworthiness. However, the gap in developers' definition and evaluation of trust points to a lack of support for evaluating trustworthy code in real-time. We also found that developers often alter their trust decisions, keeping only 52\% of original suggestions. Based on these findings, we extracted four guidelines to enhance developer-AI interactions. We validated the guidelines through a survey with (n=7) domain experts and survey members (n=8). We discuss the validated guidelines, how to apply them, and tools to help adopt them.},
	booktitle = {Proceedings of the {IEEE}/{ACM} 47th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Sabouri, Sadra and Eibl, Philipp and Zhou, Xinyi and Ziyadi, Morteza and Medvidovic, Nenad and Lindemann, Lars and Chattopadhyay, Souti},
	year = {2025},
	keywords = {AI-code assistants, software development, trust},
	pages = {1678--1690},
}

@inproceedings{zhang_navigating_2025,
	address = {New York, NY, USA},
	series = {{CUI} '25},
	title = {Navigating the {Fog}: {How} {University} {Students} {Recalibrate} {Sensemaking} {Practices} to {Address} {Plausible} {Falsehoods} in {LLM} {Outputs}},
	isbn = {979-8-4007-1527-3},
	url = {https://doi.org/10.1145/3719160.3736618},
	doi = {10.1145/3719160.3736618},
	abstract = {LLM interfaces, such as ChatGPT, are widely used by students in higher education. However, their reliability is compromised by the tendency to generate plausible yet factually inaccurate content. This issue is particularly critical as the HCI community shows growing interest in designing LLM-based educational technology. Despite this interest, we have yet to learn how plausible falsehoods disrupt students’ real-time sensemaking of outputs from imperfectly reliable LLMs, and how students currently attempt to mitigate these negative effects. Thus, we conducted a case study of 15 university students using ChatGPT through think-aloud tasks and semi-structured interviews. We identified recurring patterns of sensemaking, with students facing challenges such as relying on intuitive guesses and feeling overwhelmed by LLM’s lengthy, sycophantic, and overconfident responses. They adapted by inducing inconsistencies from the LLM’s responses and strategically dividing tasks between themselves and the LLM. Lastly, our study highlights several design implications for future reliable LLM interfaces.},
	booktitle = {Proceedings of the 7th {ACM} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Chao and Zhu, Shengqi and Yang, Xinyu and Tseng, Yu-Chia and Jiang, Shenrong and Rzeszotarski, Jeffrey M.},
	year = {2025},
	keywords = {Artificial Hallucinations, Fact Checking, Large Language Models, Sensemaking, University Students},
}

@inproceedings{ariza-casabona_comparative_2024,
	address = {New York, NY, USA},
	series = {{RecSys} '24},
	title = {A {Comparative} {Analysis} of {Text}-{Based} {Explainable} {Recommender} {Systems}},
	isbn = {979-8-4007-0505-2},
	url = {https://doi.org/10.1145/3640457.3688069},
	doi = {10.1145/3640457.3688069},
	abstract = {One way to increase trust among users towards recommender systems is to provide the recommendation along with a textual explanation. In the literature, extraction-based, generation-based, and, more recently, hybrid solutions based on retrieval-augmented generation have been proposed to tackle the problem of text-based explainable recommendation. However, the use of different datasets, preprocessing steps, target explanations, baselines, and evaluation metrics complicates the reproducibility and state-of-the-art assessment of previous work among different model categories for successful advancements in the field. Our aim is to provide a comprehensive analysis of text-based explainable recommender systems by setting up a well-defined benchmark that accommodates generation-based, extraction-based, and hybrid approaches. Also, we enrich the existing evaluation of explainability and text quality of the explanations with a novel definition of feature hallucination. Our experiments on three real-world datasets unveil hidden behaviors and confirm several claims about model patterns. Our source code and preprocessed datasets are available at https://github.com/alarca94/text-exp-recsys24.},
	booktitle = {Proceedings of the 18th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ariza-Casabona, Alejandro and Boratto, Ludovico and Salamó, Maria},
	year = {2024},
	note = {event-place: Bari, Italy},
	keywords = {Explainable Recommendation, Feature Hallucination, Natural Language Explanations, Reproducibility},
	pages = {105--115},
}

@inproceedings{zhang_how_2024,
	address = {New York, NY, USA},
	series = {{LAMPS} '24},
	title = {How to {Efficiently} {Manage} {Critical} {Infrastructure} {Vulnerabilities}? {Toward} {Large} {Code}-graph {Models}},
	isbn = {979-8-4007-1209-8},
	url = {https://doi.org/10.1145/3689217.3690622},
	doi = {10.1145/3689217.3690622},
	abstract = {Critical infrastructure vulnerabilities, once maliciously manipulated, may cause serious security accidents. However, existing methods are always unable to discover, assess, block and repair those unknown/known vulnerabilities in a timely and effective manner. This article explores the potential of large models on vulnerability management optimization. To efficiently orchestrate complex vulnerability management tasks (e.g., detection, prioritization, and code repairing), we propose to conduct a novel Large Code-graph Model (LCM) to break down vulnerability life-cycle management into distinct suites using artificial intelligence agents, Retrieval-Augmented Generation (RAG), and graph-structured large models to automate processes without extensive prior knowledge. In particular, we conduct an evaluation experiment utilizing the proposed LCM for pre-processing vulnerable data in the vulnerability detection suite. The results showed a final detection accuracy of 97.2\%, significantly outperforming baseline models and confirming that the proposed LCM can autonomously extract superior features as a data pre-processing tool. Consequently, the experimental results also partially validate the feasibility of our proposed framework.},
	booktitle = {Proceedings of the 1st {ACM} {Workshop} on {Large} {AI} {Systems} and {Models} with {Privacy} and {Safety} {Analysis}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Hongying and Li, Gaolei and Li, Shenghong and Liu, Hongfu and Wang, Shuo and Li, Jianhua},
	year = {2024},
	note = {event-place: Salt Lake City, UT, USA},
	keywords = {artificial intelligent agents, critical infrastructure, large code-graph model, vulnerability management},
	pages = {25--34},
}

@inproceedings{wang_composable_2025,
	address = {New York, NY, USA},
	series = {{LMPL} '25},
	title = {Composable {Effect} {Handling} for {Programming} {LLM}-{Integrated} {Scripts}},
	isbn = {979-8-4007-2148-9},
	url = {https://doi.org/10.1145/3759425.3763396},
	doi = {10.1145/3759425.3763396},
	abstract = {Implementing LLM-integrated scripts introduces challenges in modularity and performance, as scripts are often coupled to specific LLM implementations and fail to exploit parallelization opportunities. This paper proposes using composable effect handling to separate workflow logic from effectful operations, such as LLM calls, I/O, and concurrency, enabling modularity without sacrificing the opportunity for performance optimization. By treating these operations as abstract interfaces and discharging them via effect handlers, this paper shows that scripts can achieve significant speedups (e.g., 10× in a Tree-of-Thoughts case study) without compromising modularity. This paper aims to promote composable effect handling as a programming style for LLM scripting.},
	booktitle = {Proceedings of the 1st {ACM} {SIGPLAN} {International} {Workshop} on {Language} {Models} and {Programming} {Languages}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Di},
	year = {2025},
	note = {event-place: Singapore, Singapore},
	keywords = {algebraic effects, effect handlers, large language models, LLM-integrated scripts},
	pages = {124--129},
}

@inproceedings{dai_mitigating_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Mitigating {Source} {Bias} with {LLM} {Alignment}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730038},
	doi = {10.1145/3726302.3730038},
	abstract = {Recent studies have revealed a phenomenon known as source bias, where PLM-based retrievers assign higher relevance scores to LLM-generated content despite its semantic quality being comparable to human-written content. As LLMs rapidly advance and become more widely used, effectively counteracting source bias is crucial for the sustainable development of the information retrieval (IR) ecosystem. Existing methods primarily attempt to address source bias from the retriever side, adopting a "passive defense" approach that intervenes only after biased content has entered the retrieval pipeline. These solutions are limited by frequent retriever updates in industrial applications, high recurring costs, and their inability to address the root cause of source bias.In this paper, we propose a new perspective for mitigating source bias by actively aligning LLM outputs at the data generation stage. Specifically, we introduce LLM-SBM, a novel LLM alignment framework for source bias mitigation. First, we construct high-quality alignment datasets using an automatic preference data construction pipeline. This pipeline leverages LLMs to generate multiple rephrasings of content and employs a PLM-based retriever to assign corresponding specific preference values for each generated document, thereby forming preference pairs according to these preferences. Moreover, to fully utilize these scalar values of preference and enhance the efficiency of the alignment process, LLM-SBM incorporates these preference differences as weighting factors in the loss function during policy training. Extensive experiments across multiple datasets and PLM-based retrievers demonstrate that LLMs aligned with LLM-SBM successfully reduce source bias while preserving their general capabilities.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Dai, Sunhao and Zhou, Yuqi and Pang, Liang and Li, Zhuoyang and Du, Zhaocheng and Wang, Gang and Xu, Jun},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {information retrieval, llm alignment, source bias},
	pages = {370--380},
}

@inproceedings{khurana_it_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Do {It} {For} {Me} vs. {Do} {It} {With} {Me}: {Investigating} {User} {Perceptions} of {Different} {Paradigms} of {Automation} in {Copilots} for {Feature}-{Rich} {Software}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713431},
	doi = {10.1145/3706598.3713431},
	abstract = {Large Language Model (LLM)-based in-application assistants, or copilots, can automate software tasks, but users often prefer learning by doing, raising questions about the optimal level of automation for an effective user experience. We investigated two automation paradigms by designing and implementing a fully automated copilot (AutoCopilot) and a semi-automated copilot (GuidedCopilot) that automates trivial steps while offering step-by-step visual guidance. In a user study (N=20) across data analysis and visual design tasks, GuidedCopilot outperformed AutoCopilot in user control, software utility, and learnability, especially for exploratory and creative tasks, while AutoCopilot saved time for simpler visual tasks. A follow-up design exploration (N=10) enhanced GuidedCopilot with task-and state-aware features, including in-context preview clips and adaptive instructions. Our findings highlight the critical role of user control and tailored guidance in designing the next generation of copilots that enhance productivity, support diverse skill levels, and foster deeper software engagement.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Khurana, Anjali and Su, Xiaotian and Wang, April Yi and Chilana, Parmit K},
	year = {2025},
	keywords = {feature-rich software, human-AI collaboration, large language models, semi-automation, software copilots, user control},
}

@inproceedings{li_llms_2024,
	address = {New York, NY, USA},
	series = {{HILDA} 24},
	title = {{LLMs} as an {Interactive} {Database} {Interface} for {Designing} {Large} {Queries}},
	isbn = {979-8-4007-0693-6},
	url = {https://doi.org/10.1145/3665939.3665969},
	doi = {10.1145/3665939.3665969},
	abstract = {Text2SQL is typically considered a one-shot process where the user gives a natural language query and receives an SQL query in return. This approach is fraught with potential concerns, such as syntactical errors, logical mismatches, and schema hallucination, which often require time-consuming validations by end users. These challenges are exacerbated by the complexity of large queries typical in industry settings and the inherent ambiguity of natural language. To address these limitations, we propose a system that employs an iterative process for both query creation and validation, ensuring that the resulting data set meets the user's expectations. We tested this system against existing text-to-SQL LLM approaches using a standard industry use case, showcasing our system's ability to deliver coherent and accurate outcomes. Opportunities for future research to further refine this approach are also discussed1.},
	booktitle = {Proceedings of the 2024 {Workshop} on {Human}-{In}-the-{Loop} {Data} {Analytics}},
	publisher = {Association for Computing Machinery},
	author = {Li, Yilin and Jobson, Deddy},
	year = {2024},
	note = {event-place: Santiago, AA, Chile},
	keywords = {human-in-the-loop, large language models, LLM, Text2SQL},
	pages = {1--7},
}

@inproceedings{liu_webanns_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{WebANNS}: {Fast} and {Efficient} {Approximate} {Nearest} {Neighbor} {Search} in {Web} {Browsers}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730115},
	doi = {10.1145/3726302.3730115},
	abstract = {Approximate nearest neighbor search (ANNS) has become vital to modern AI infrastructure, particularly in retrieval-augmented generation (RAG) applications. Numerous in-browser ANNS engines have emerged to seamlessly integrate with popular LLM-based web applications, while addressing privacy protection and challenges of heterogeneous device deployments. However, web browsers present unique challenges for ANNS, including computational limitations, external storage access issues, and memory utilization constraints, which state-of-the-art (SOTA) solutions fail to address comprehensively.We propose WebANNS, a novel ANNS engine specifically designed for web browsers. WebANNS leverages WebAssembly to overcome computational bottlenecks, designs a lazy loading strategy to optimize data retrieval from external storage, and applies a heuristic approach to reduce memory usage. Experiments show that WebANNS is fast and memory efficient, achieving up to 743.8X improvement in 99th percentile query latency over the SOTA engine, while reducing memory usage by up to 39\%. Note that WebANNS decreases query time from 10 seconds to the 10-millisecond range in browsers, making in-browser ANNS practical with user-acceptable latency.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Mugeng and Zhong, Siqi and Yang, Qi and Han, Yudong and Liu, Xuanzhe and Ma, Yun},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {approximate nearest neighbor search, web browser, webassembly},
	pages = {2483--2492},
}

@inproceedings{tran_memoriease_2024,
	address = {New York, NY, USA},
	series = {{LSC} '24},
	title = {{MemoriEase} 2.0: {A} {Conversational} {Lifelog} {Retrieve} {System} for {LSC}'24},
	isbn = {979-8-4007-0550-2},
	url = {https://doi.org/10.1145/3643489.3661114},
	doi = {10.1145/3643489.3661114},
	abstract = {Lifelog retrieval plays an important role in memory support for lifeloggers. It helps the lifeloggers to browse, search and navigate their life moments from the lifelog data. However, the volume and variety of lifelog data are enormous and range in multiple modalities so they impose a big challenge to retrieve accurate lifelog moments. The Lifelog Search Challenges (LSCs) are a benchmark challenge for evaluating lifelog retrieval systems in different tasks. In this paper, we introduce the MemoriEase 2.0 lifelog retrieval system that participates in LSC'24. This system not only inherits core functions from the precedent system but also incorporates new components such as conversational search, visual similarity search and retrieval-augmented generation for question-answering tasks. The new functions are expected to help expert and novice users solve all topics in three tasks of LSC'24. We evaluate MemoriEase 2.0 in KIS topics in LSC'23 and the system achieves promising results with Recall@1 is 40\% at the first hint and it solves 8 over 10 topics.},
	booktitle = {Proceedings of the 7th {Annual} {ACM} {Workshop} on the {Lifelog} {Search} {Challenge}},
	publisher = {Association for Computing Machinery},
	author = {Tran, Quang-Linh and Nguyen, Binh and Jones, Gareth J. F. and Gurrin, Cathal},
	year = {2024},
	note = {event-place: Phuket, Thailand},
	keywords = {conversational search, lifelog retrieval, personal archive},
	pages = {12--17},
}

@inproceedings{sun_rearter_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{ReARTeR}: {Retrieval}-{Augmented} {Reasoning} with {Trustworthy} {Process} {Rewarding}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730102},
	doi = {10.1145/3726302.3730102},
	abstract = {Retrieval-Augmented Generation (RAG) systems for Large Language Models (LLMs) have shown promise in knowledge-intensive tasks, yet their reasoning capabilities, particularly for complex multi-step reasoning, remain limited. Although recent approaches have explored integrating RAG with chain-of-thought reasoning or incorporating test-time search with process reward model (PRM), these methods face several untrustworthy challenges, including lack of explanations, bias in PRM training data, early-step bias in PRM scores, and ignoring post-training that fails to fully optimize reasoning potential. To address these issues, we propose Retrieval-Augmented Reasoning through Trustworthy Process Rewarding (ReARTeR), a framework that enhances RAG systems' reasoning capabilities through both post-training and test-time scaling. At test time, ReARTeR introduces Trustworthy Process Rewarding via a Process Reward Model for accurate scalar scoring and a Process Explanation Model (PEM) for generating natural language explanations, enabling step refinement. During post-training, we leverage Monte Carlo Tree Search guided by Trustworthy Process Rewarding to collect high-quality step-level preference data, which is used to optimize the model through Iterative Preference Optimization. ReARTeR tackles three key challenges: (1) misalignment between PRM and PEM, addressed through off-policy preference learning; (2) bias in PRM training data, mitigated by a balanced annotation method and incorporating stronger annotations for difficult examples; and (3) early-step bias in PRM, resolved via a temporal-difference-based look-ahead search strategy. Experimental results on multi-step reasoning benchmarks demonstrate that ReARTeR significantly improves reasoning performance, highlighting its potential to advance the reasoning capability of RAG systems.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Sun, Zhongxiang and Wang, Qipeng and Yu, Weijie and Zang, Xiaoxue and Zheng, Kai and Xu, Jun and Zhang, Xiao and Song, Yang and Li, Han},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {reasoning, retrieval augment generation, trustworthy},
	pages = {1251--1261},
}

@inproceedings{lau_ban_2023,
	address = {New York, NY, USA},
	series = {{ICER} '23},
	title = {From "{Ban} {It} {Till} {We} {Understand} {It}" to "{Resistance} is {Futile}": {How} {University} {Programming} {Instructors} {Plan} to {Adapt} as {More} {Students} {Use} {AI} {Code} {Generation} and {Explanation} {Tools} such as {ChatGPT} and {GitHub} {Copilot}},
	isbn = {978-1-4503-9976-0},
	url = {https://doi.org/10.1145/3568813.3600138},
	doi = {10.1145/3568813.3600138},
	abstract = {Over the past year (2022–2023), recently-released AI tools such as ChatGPT and GitHub Copilot have gained significant attention from computing educators. Both researchers and practitioners have discovered that these tools can generate correct solutions to a variety of introductory programming assignments and accurately explain the contents of code. Given their current capabilities and likely advances in the coming years, how do university instructors plan to adapt their courses to ensure that students still learn well? To gather a diverse sample of perspectives, we interviewed 20 introductory programming instructors (9 women + 11 men) across 9 countries (Australia, Botswana, Canada, Chile, China, Rwanda, Spain, Switzerland, United States) spanning all 6 populated continents. To our knowledge, this is the first empirical study to gather instructor perspectives about how they plan to adapt to these AI coding tools that more students will likely have access to in the future. We found that, in the short-term, many planned to take immediate measures to discourage AI-assisted cheating. Then opinions diverged about how to work with AI coding tools longer-term, with one side wanting to ban them and continue teaching programming fundamentals, and the other side wanting to integrate them into courses to prepare students for future jobs. Our study findings capture a rare snapshot in time in early 2023 as computing instructors are just starting to form opinions about this fast-growing phenomenon but have not yet converged to any consensus about best practices. Using these findings as inspiration, we synthesized a diverse set of open research questions regarding how to develop, deploy, and evaluate AI coding tools for computing education.},
	booktitle = {Proceedings of the 2023 {ACM} {Conference} on {International} {Computing} {Education} {Research} - {Volume} 1},
	publisher = {Association for Computing Machinery},
	author = {Lau, Sam and Guo, Philip},
	year = {2023},
	note = {event-place: Chicago, IL, USA},
	keywords = {AI coding tools, ChatGPT, Copilot, instructor perspectives, LLM},
	pages = {106--121},
}

@inproceedings{shen_gpiot_2025,
	address = {New York, NY, USA},
	series = {{SenSys} '25},
	title = {{GPIoT}: {Tailoring} {Small} {Language} {Models} for {IoT} {Program} {Synthesis} and {Development}},
	isbn = {979-8-4007-1479-5},
	url = {https://doi.org/10.1145/3715014.3722064},
	doi = {10.1145/3715014.3722064},
	abstract = {Code Large Language Models (LLMs) enhance software development efficiency by automatically generating code and documentation based on user requirements. However, code LLMs cannot synthesize specialized programs when tasked with IoT applications that require domain knowledge. While Retrieval-Augmented Generation (RAG) offers a promising solution by fetching relevant domain knowledge, it necessitates powerful cloud LLMs (e.g., GPT-4) to process user requirements and retrieved contents, which raises significant privacy concerns. This approach also suffers from unstable networks and prohibitive LLM query costs. Moreover, it is challenging to ensure the correctness and relevance of the fetched contents. To address these issues, we propose GPIoT, a code generation system for IoT applications by fine-tuning locally deployable Small Language Models (SLMs) on IoT-specialized datasets. SLMs have smaller model sizes, allowing efficient local deployment and execution to mitigate privacy concerns and network uncertainty. Furthermore, by fine-tuning SLMs with our IoT-specialized datasets, the SLMs' ability to synthesize IoT-related programs can be substantially improved. To evaluate GPIoT's capability in synthesizing programs for IoT applications, we develop a benchmark, IoTBench. Extensive experiments and user trials demonstrate the effectiveness of GPIoT in generating IoT-specialized code, outperforming state-of-the-art code LLMs with an average task accuracy increment of 64.7\% and significant improvements in user satisfaction.},
	booktitle = {Proceedings of the 23rd {ACM} {Conference} on {Embedded} {Networked} {Sensor} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Shen, Leming and Yang, Qiang and Huang, Xinyu and Ma, Zijing and Zheng, Yuanqing},
	year = {2025},
	note = {event-place: UC Irvine Student Center., Irvine, CA, USA},
	keywords = {fine-tuning, IoT program synthesis, small language model},
	pages = {199--212},
}

@inproceedings{gebreegziabher_metricmate_2025,
	address = {New York, NY, USA},
	series = {{CHIWORK} '25},
	title = {{MetricMate}: {An} {Interactive} {Tool} for {Generating} {Evaluation} {Criteria} for {LLM}-as-a-{Judge} {Workflow}},
	isbn = {979-8-4007-1384-2},
	url = {https://doi.org/10.1145/3729176.3729199},
	doi = {10.1145/3729176.3729199},
	abstract = {The rise of the use of Large Language Models (LLMs) in work has driven the need for robust evaluation methods that align model behavior with human values and preferences. LLM-as-a-judge approaches have emerged as a scalable solution, leveraging LLMs to evaluate generated outputs based on flexible user-defined criteria. However, users often struggle to articulate clear evaluation criteria. In addition, human preferences and criteria definitions evolve, and predefined templates fail to account for context-specific nuances. To address these challenges, we present MetricMate, an interactive tool that supports users in defining and calibrating evaluation criteria for LLM-as-a-judge systems. MetricMate introduces hierarchical criteria definitions and curated examples of success and failure to promote human-AI criteria negotiation and alignment. Additionally, MetricMate learns from users’ interactions with data by enabling users to group data to identify patterns and provide context-specific criteria.},
	booktitle = {Proceedings of the 4th {Annual} {Symposium} on {Human}-{Computer} {Interaction} for {Work}},
	publisher = {Association for Computing Machinery},
	author = {Gebreegziabher, Simret Araya and Chiang, Charles and Wang, Zichu and Ashktorab, Zahra and Brachman, Michelle and Geyer, Werner and Li, Toby Jia-Jun and Gómez-Zará, Diego},
	year = {2025},
	keywords = {Evaluation Methods, Human AI Interaction, Large Language Models, LLM-as-a-Judge},
}

@inproceedings{kurshan_ai_2024,
	address = {New York, NY, USA},
	series = {{ICAIF} '24},
	title = {{AI} versus {AI} in {Financial} {Crimes} \&amp; {Detection}: {GenAI} {Crime} {Waves} to {Co}-{Evolutionary} {AI}},
	isbn = {979-8-4007-1081-0},
	url = {https://doi.org/10.1145/3677052.3698655},
	doi = {10.1145/3677052.3698655},
	abstract = {Adoption of AI by criminal entities across traditional and emerging financial crime paradigms has been a disturbing recent trend. Particularly concerning is the proliferation of generative AI, which has empowered criminal activities ranging from sophisticated phishing schemes to the creation of hard-to-detect deep fakes, and to advanced spoofing attacks to biometric authentication systems. The exploitation of AI by criminal purposes continues to escalate, presenting an unprecedented challenge. AI adoption causes an increasingly complex landscape of fraud typologies intertwined with cybersecurity vulnerabilities. Overall, GenAI has a transformative effect on financial crimes and fraud. According to some estimates, GenAI will quadruple the fraud losses by 2027 with a staggering annual growth rate of over 30\% [27]. As crime patterns become more intricate, personalized, and elusive, deploying effective defensive AI strategies becomes indispensable. However, several challenges hinder the necessary progress of AI-based fincrime detection systems. This paper examines the latest trends in AI/ML-driven financial crimes and detection systems. It underscores the urgent need for developing agile AI defenses that can effectively counteract the rapidly emerging threats. It also aims to highlight the need for cooperation across the financial services industry to tackle the GenAI induced crime waves.},
	booktitle = {Proceedings of the 5th {ACM} {International} {Conference} on {AI} in {Finance}},
	publisher = {Association for Computing Machinery},
	author = {Kurshan, Eren and Mehta, Dhagash and Balch, Tucker},
	year = {2024},
	note = {event-place: Brooklyn, NY, USA},
	pages = {745--751},
}

@inproceedings{ding_enhancing_2024,
	address = {New York, NY, USA},
	series = {{KDD} '24},
	title = {Enhancing {On}-{Device} {LLM} {Inference} with {Historical} {Cloud}-{Based} {LLM} {Interactions}},
	isbn = {979-8-4007-0490-1},
	url = {https://doi.org/10.1145/3637528.3671679},
	doi = {10.1145/3637528.3671679},
	abstract = {Many billion-scale large language models (LLMs) have been released for resource-constraint mobile devices to provide local LLM inference service when cloud-based powerful LLMs are not available. However, the capabilities of current on-device LLMs still lag behind those of cloud-based LLMs, and how to effectively and efficiently enhance on-device LLM inference becomes a practical requirement. We thus propose to collect the user's historical interactions with the cloud-based LLM and build an external datastore on the mobile device for enhancement using nearest neighbors search. Nevertheless, the full datastore improves the quality of token generation at the unacceptable expense of much slower generation speed. To balance performance and efficiency, we propose to select an optimal subset of the full datastore within the given size limit, the optimization objective of which is proven to be submodular. We further design an offline algorithm, which selects the subset after the construction of the full datastore, as well as an online algorithm, which performs selection over the stream and can be flexibly scheduled. We theoretically analyze the performance guarantee and the time complexity of the offline and the online designs to demonstrate effectiveness and scalability. We finally take three ChatGPT related dialogue datasets and four different on-device LLMs for evaluation. Evaluation results show that the proposed designs significantly enhance LLM performance in terms of perplexity while maintaining fast token generation speed. Practical overhead testing on the smartphone reveal the efficiency of on-device datastore subset selection from memory usage and computation overhead.},
	booktitle = {Proceedings of the 30th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Ding, Yucheng and Niu, Chaoyue and Wu, Fan and Tang, Shaojie and Lyu, Chengfei and Chen, Guihai},
	year = {2024},
	note = {event-place: Barcelona, Spain},
	keywords = {datastore subset selection, device-cloud hybrid service, on-device llm enhancement},
	pages = {597--608},
}

@inproceedings{kang_tldr_2024,
	address = {New York, NY, USA},
	series = {Onward! '24},
	title = {tl;dr: {Chill}, y’all: {AI} {Will} {Not} {Devour} {SE}},
	isbn = {979-8-4007-1215-9},
	url = {https://doi.org/10.1145/3689492.3689816},
	doi = {10.1145/3689492.3689816},
	abstract = {Social media provide a steady diet of dire warnings that artificial intelligence (AI) will make software engineering (SE) irrelevant or obsolete. To the contrary, the engineering discipline of software is rich and robust; it encompasses the full scope of software design, development, deployment, and practical use; and it has regularly assimilated radical new offerings from AI. Current AI innovations such as machine learning, large language models (LLMs) and generative AI will offer new opportunities to extend the models and methods of SE. They may automate some routine development processes, and they will bring new kinds of components and architectures. If we're fortunate they may force SE to rethink what we mean by correctness and reliability. They will not, however, render SE irrelevant.},
	booktitle = {Proceedings of the 2024 {ACM} {SIGPLAN} {International} {Symposium} on {New} {Ideas}, {New} {Paradigms}, and {Reflections} on {Programming} and {Software}},
	publisher = {Association for Computing Machinery},
	author = {Kang, Eunsuk and Shaw, Mary},
	year = {2024},
	note = {event-place: Pasadena, CA, USA},
	keywords = {AI-assisted development, software correctness, software engineering principles},
	pages = {303--315},
}

@inproceedings{singh_finqapt_2024,
	address = {New York, NY, USA},
	series = {{ICAIF} '24},
	title = {{FinQAPT}: {Empowering} {Financial} {Decisions} with {End}-to-{End} {LLM}-driven {Question} {Answering} {Pipeline}},
	isbn = {979-8-4007-1081-0},
	url = {https://doi.org/10.1145/3677052.3698682},
	doi = {10.1145/3677052.3698682},
	abstract = {Financial decision-making hinges on the analysis of relevant information embedded in the enormous volume of documents in the financial domain. To address this challenge, we developed FinQAPT, an end-to-end pipeline that streamlines the identification of relevant financial reports based on a query, extracts pertinent context, and leverages Large Language Models (LLMs) to perform downstream tasks. To evaluate the pipeline, we experimented with various techniques to optimize the performance of each module using the FinQA dataset. We introduced a novel clustering-based negative sampling technique to enhance context extraction and a novel prompting method called Dynamic N-shot Prompting to boost the numerical question-answering capabilities of LLMs. At the module level, we achieved state-of-the-art accuracy on FinQA, attaining an accuracy of 80.6\%. However, at the pipeline level, we observed decreased performance due to challenges in extracting relevant context from financial reports. We conducted a detailed error analysis of each module and the end-to-end pipeline, pinpointing specific challenges that must be addressed to develop a robust solution for handling complex financial tasks.},
	booktitle = {Proceedings of the 5th {ACM} {International} {Conference} on {AI} in {Finance}},
	publisher = {Association for Computing Machinery},
	author = {Singh, Kuldeep and Kaur, Simerjot and Smiley, Charese},
	year = {2024},
	note = {event-place: Brooklyn, NY, USA},
	keywords = {finance, LLM, numerical reasoning, prompting, question answering},
	pages = {266--273},
}

@inproceedings{donnelly_exploring_2025,
	address = {New York, NY, USA},
	series = {{ICTIR} '25},
	title = {Exploring the {Utility} of {Embedding} {Similarity} for {Contract} {Tasks}},
	isbn = {979-8-4007-1861-8},
	url = {https://doi.org/10.1145/3731120.3744609},
	doi = {10.1145/3731120.3744609},
	abstract = {With the increasing use of text embeddings motivated by the adoption of Retrieval Augmented Generation (RAG) in applied domains, this work investigates whether the semantic aspects of text embeddings correspond to the colloquial understanding of semantic similarity in a legal domain. Using clauses from legal agreements, we find that embeddings and associated similarity measurements (e.g., cosine, L2) do not accurately reflect a legal understanding of ”semantically similar.” More specifically, legal clauses are more similar to a minimally changed, negated version than those with identical legal meaning but worded differently across embedding sources and similarity measures. We demonstrate that discriminative classification can be an effective stop-gap solution with these two types of variants using either a zero-shot generative model prompt or a multi-layer perceptron trained on the embeddings. These results indicate that care should be taken when applying off-the-shelf semantic similarity tools in specialized domains and provides a basis from which further work can be conducted to determine cost effective methods for measuring nuanced notions of similarity.},
	booktitle = {Proceedings of the 2025 {International} {ACM} {SIGIR} {Conference} on {Innovative} {Concepts} and {Theories} in {Information} {Retrieval} ({ICTIR})},
	publisher = {Association for Computing Machinery},
	author = {Donnelly, Jonathan and Roegiest, Adam},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {contract, embedding, legal, semantic similarity},
	pages = {401--409},
}

@inproceedings{franca_optimizing_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Optimizing {Tail}-{Head} {Trade}-off for {Extreme} {Multi}-{Label} {Text} {Classification} ({XMTC}) with {RAG}-{Labels} and a {Dynamic} {Two}-{Stage} {Retrieval} and {Fusion} {Pipeline}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730052},
	doi = {10.1145/3726302.3730052},
	abstract = {We tackle Extreme Multi-Label Text Classification (XMTC), which involves assigning relevant labels to texts from a huge label space. Attempting to optimize the underexplored tail-head trade-off, we address the XMTC task through its core challenges of volume, skewness, and quality by proposing xCoRetriev, a novel two-stage retrieving and fusing ranking pipeline. Our pipeline addresses the volume challenge by dynamically slicing the large label space; it also tackles the skewness challenge by favoring the tail labels while fusing sparse and dense retrievers. Finally, xCoRetriev faces the quality challenge by enhancing the label space with Retrieval-Augmented Generated (RAG)-labels. Our experiments with four XMTC benchmarks with hundreds of thousands of text documents and labels against six state-of-the-art XMTC baselines demonstrate xCoRetriev's strengths in terms of: (i) scalability for large label spaces, being among the most efficient methods at training and prediction; (ii) effectiveness in the face of high skewness, with gains of up to 48\% in propensity-scored metrics against the best state-of-the-art baselines; and (iii) capability of handling very noisy datasets by exploiting RAG-labels.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {França, Celso and Rabbi, Gestefane and Salles, Thiago and Cunha, Washington and Rocha, Leonardo and André Gonçalves, Marcos},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {extreme multi-label text classification, rag-labels, retrieving and fusing, tail-head trade-off},
	pages = {1392--1401},
}

@inproceedings{yang_knighter_2025,
	address = {New York, NY, USA},
	series = {{SOSP} '25},
	title = {{KNighter}: {Transforming} {Static} {Analysis} with {LLM}-{Synthesized} {Checkers}},
	isbn = {979-8-4007-1870-0},
	url = {https://doi.org/10.1145/3731569.3764827},
	doi = {10.1145/3731569.3764827},
	abstract = {Static analysis is a powerful technique for bug detection in critical systems like operating system kernels. However, designing and implementing static analyzers is challenging, time-consuming, and typically limited to predefined bug patterns. While large language models (LLMs) have shown promise for static analysis, directly applying them to scan large systems remains impractical due to computational constraints and contextual limitations.We present KNighter, the first approach that unlocks scalable LLM-based static analysis by automatically synthesizing static analyzers from historical bug patterns. Rather than using LLMs to directly analyze massive systems, our key insight is leveraging LLMs to generate specialized static analyzers guided by historical patch knowledge. KNighter implements this vision through a multi-stage synthesis pipeline that validates checker correctness against original patches and employs an automated refinement process to iteratively reduce false positives. Our evaluation on the Linux kernel demonstrates that KNighter generates high-precision checkers capable of detecting diverse bug patterns overlooked by existing human-written analyzers. To date, KNighter-synthesized checkers have discovered 92 new, critical, longlatent bugs (average 4.3 years) in the Linux kernel; 77 are confirmed, 57 fixed, and 30 have been assigned CVE numbers. This work establishes an entirely new paradigm for scalable, reliable, and traceable LLM-based static analysis for real-world systems via checker synthesis.},
	booktitle = {Proceedings of the {ACM} {SIGOPS} 31st {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {Association for Computing Machinery},
	author = {Yang, Chenyuan and Zhao, Zijie and Xie, Zichen and Li, Haoyu and Zhang, Lingming},
	year = {2025},
	note = {event-place: Lotte Hotel World, Seoul, Republic of Korea},
	keywords = {large language models, static analysis},
	pages = {655--669},
}

@inproceedings{deva_kya_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {"{Kya} family planning after marriage hoti hai?": {Integrating} {Cultural} {Sensitivity} in an {LLM} {Chatbot} for {Reproductive} {Health}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713362},
	doi = {10.1145/3706598.3713362},
	abstract = {Access to sexual and reproductive health information remains a challenge in many communities globally, due to cultural taboos and limited availability of healthcare providers. Public health organizations are increasingly turning to Large Language Models (LLMs) to improve access to timely and personalized information. However, recent HCI scholarship indicates that significant challenges remain in incorporating context awareness and mitigating bias in LLMs. In this paper, we study the development of a culturally-appropriate LLM-based chatbot for reproductive health with underserved women in urban India. Through user interactions, focus groups, and interviews with multiple stakeholders, we examine the chatbot’s response to sensitive and highly contextual queries on reproductive health. Our findings reveal strengths and limitations of the system in capturing local context, and complexities around what constitutes “culture”. Finally, we discuss how local context might be better integrated, and present a framework to inform the design of culturally-sensitive chatbots for community health.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Deva, Roshini and Ramani, Dhruv and Divate, Tanvi and Jalota, Suhani and Ismail, Azra},
	year = {2025},
	keywords = {chatbot, HCI4D, LLM, reproductive health},
}

@inproceedings{xu_automated_2024,
	address = {New York, NY, USA},
	series = {{MLCAD} '24},
	title = {Automated {C}/{C}++ {Program} {Repair} for {High}-{Level} {Synthesis} via {Large} {Language} {Models}},
	isbn = {979-8-4007-0699-8},
	url = {https://doi.org/10.1145/3670474.3685953},
	doi = {10.1145/3670474.3685953},
	abstract = {In High-Level Synthesis (HLS), converting a regular C/C++ program into its HLS-compatible counterpart (HLS-C) still requires tremendous manual effort. Various program scripts have been introduced to automate this process. But the resulting codes usually contain many issues that should be manually repaired by developers. Since Large Language Models (LLMs) have the ability to automate code generation, they can also be used for automated program repair in HLS. However, due to the limited training of LLMs considering hardware and software simultaneously, hallucinations may occur during program repair using LLMs, leading to compilation failures. Besides, using LLMs for iterative repair also incurs a high cost. To address these challenges, we propose an LLM-driven program repair framework that takes regular C/C++ code as input and automatically generates its corresponding HLS-C code for synthesis while minimizing human repair effort. To mitigate the hallucinations in LLMs and enhance the prompt quality, a Retrieval-Augmented Generation (RAG) paradigm is introduced to guide the LLMs toward correct repair. In addition, we use LLMs to create a static bit width optimization program to identify the optimized bit widths for variables. Moreover, LLM-driven HLS optimization strategies are introduced to add/tune pragmas in HLS-C programs for circuit optimization. Experimental results demonstrate that the proposed LLM-driven automated framework can achieve much higher repair pass rates in 24 real-world applications compared with the traditional scripts and the direct application of LLMs for program repair. The codes are open-sourced at this link: https://github.com/code-source1/catapult.},
	booktitle = {Proceedings of the 2024 {ACM}/{IEEE} {International} {Symposium} on {Machine} {Learning} for {CAD}},
	publisher = {Association for Computing Machinery},
	author = {Xu, Kangwei and Zhang, Grace Li and Yin, Xunzhao and Zhuo, Cheng and Schlichtmann, Ulf and Li, Bing},
	year = {2024},
	note = {event-place: Salt Lake City, UT, USA},
}

@inproceedings{arabzadeh_benchmarking_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Benchmarking {LLM}-based {Relevance} {Judgment} {Methods}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730305},
	doi = {10.1145/3726302.3730305},
	abstract = {Large Language Models (LLMs) are increasingly deployed in both academic and industry settings to automate the evaluation of information seeking systems, particularly by generating graded relevance judgments. Several studies report Kendall τ correlations exceeding 0.85 when comparing system rankings derived from human versus LLM-generated relevance labels. Previous work on LLM-based relevance assessment has primarily focused on replicating graded human relevance judgments through various prompting strategies. However, there has been limited exploration of alternative assessment methods or comprehensive comparative studies. In this paper, we systematically compare multiple LLM-based relevance assessment methods, including binary relevance judgments, graded relevance assessments, pairwise preference-based methods, and two nugget-based evaluation methods - document-agnostic and document-dependent. Wherever possible, we employ state-of-the-art tools and optimized prompts tailored for these methods. In addition to a traditional comparison based on system rankings using Kendall correlations, we also examine how well LLM judgments align with human preferences, as inferred from relevance grades. We conduct extensive experiments on datasets from three TREC Deep Learning tracks 2019, 2020 and 2021 as well as the ANTIQUE dataset, which focuses on non-factoid open-domain question answering. Beyond dataset-specific results, our work offers a practical methodology for evaluating diverse LLM-based relevance assessment methods. As part of our data release, we include relevance judgments generated by both an open-source (Llama3.2b) and a commercial (gpt-4o) model. Our goal is to reproduce various LLM-based relevance judgment methods to provide a comprehensive comparison. We release all the relevance judgments as a resource that establishes a baseline for future work, ensuring a level playing field for evaluation of LLM-based relevance judgments. All code, data, and resources are publicly available in our GitHub Repository at https://github.com/Narabzad/llm-relevance-judgement-comparison},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Arabzadeh, Negar and Clarke, Charles L. A.},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {automated evaluation, information retrieval evaluation, large language models, relevance judgment},
	pages = {3194--3204},
}

@inproceedings{darnell_empirical_2024,
	address = {New York, NY, USA},
	series = {{InteNSE} '24},
	title = {An {Empirical} {Comparison} of {Code} {Generation} {Approaches} for {Ansible}},
	isbn = {979-8-4007-0564-9},
	url = {https://doi.org/10.1145/3643661.3643951},
	doi = {10.1145/3643661.3643951},
	abstract = {The rapid proliferation of LLM-based programming assistants has enabled fast and accurate automatic code generation for general purpose programming languages. Domain-specific languages like Ansible, a DSL for IT Automation, have seen a lack of support despite being critical to many fields, due to limited public-domain code for training models and a lack of interest from tool developers. To address this issue, we collect a novel dataset of permissively licensed Ansible code, and use it to create Warp, an LLM for code fine-tuned to produce Ansible tasks from a natural language prompt. We evaluate state-of-the-art tools for LLM-based code generation models, comparing multiple common strategies, including fine-tuning base models on Ansible code and retrieval-augmented-generation using documentation, in order to understand challenges with existing methodology and identify future research directions to enable better code generation for DSLs.},
	booktitle = {Proceedings of the {ACM}/{IEEE} 2nd {International} {Workshop} on {Interpretability}, {Robustness}, and {Benchmarking} in {Neural} {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Darnell, Benjamin and Chopra, Hetarth and Councilman, Aaron and Grove, David and Wang, Yu-Xiong and Adve, Vikram},
	year = {2024},
	note = {event-place: Lisbon, Portugal},
	keywords = {ansible, code generation, domain specific languages, large language models},
	pages = {1--6},
}

@inproceedings{vaithilingam_imagining_2024,
	address = {New York, NY, USA},
	series = {{DIS} '24},
	title = {Imagining a {Future} of {Designing} with {AI}: {Dynamic} {Grounding}, {Constructive} {Negotiation}, and {Sustainable} {Motivation}},
	isbn = {979-8-4007-0583-0},
	url = {https://doi.org/10.1145/3643834.3661525},
	doi = {10.1145/3643834.3661525},
	abstract = {We ideate a future design workflow that involves AI technology. Drawing from activity and communication theory, we attempt to isolate the new value that large AI models can provide design compared to past technologies. We arrive at three affordances—dynamic grounding, constructive negotiation, and sustainable motivation—that summarize latent qualities of natural language-enabled foundation models that, if explicitly designed for, can support the process of design. Through design fiction, we then imagine a future interface as a diegetic prototype, the story of Squirrel Game, that demonstrates each of our three affordances in a realistic usage scenario. Our design process, terminology, and diagrams aim to contribute to future discussions about the relative affordances of AI technology with regard to collaborating with human designers.},
	booktitle = {Proceedings of the 2024 {ACM} {Designing} {Interactive} {Systems} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Vaithilingam, Priyan and Arawjo, Ian and Glassman, Elena L.},
	year = {2024},
	note = {event-place: Copenhagen, Denmark},
	keywords = {AI affordances, Design fiction, Grounding, Human AI collaboration, Language models},
	pages = {289--300},
}

@inproceedings{dedov_jointrank_2025,
	address = {New York, NY, USA},
	series = {{ICTIR} '25},
	title = {{JointRank}: {Rank} {Large} {Set} with {Single} {Pass}},
	isbn = {979-8-4007-1861-8},
	url = {https://doi.org/10.1145/3731120.3744587},
	doi = {10.1145/3731120.3744587},
	abstract = {Efficiently ranking relevant items from large candidate pools is a cornerstone of modern information retrieval systems - such as web search, recommendation, and retrieval-augmented generation. Listwise rerankers, which improve relevance by jointly considering multiple candidates, are often limited in practice: either by model input size constraints, or by degraded quality when processing large sets. We propose a model-agnostic method for fast reranking large sets that exceed a model input limits. The method first partitions candidate items into overlapping blocks, each of which is ranked independently in parallel. Implicit pairwise comparisons are then derived from these local rankings. Finally, these comparisons are aggregated to construct a global ranking using algorithms such as Winrate or PageRank. Experiments on TREC DL-2019 show that our method achieves an nDCG@10 of 70.88 compared to the 57.68 for full-context listwise approach using gpt-4.1-mini as long-context model, while reducing latency from 21 to 8 seconds. The implementation of the algorithm and the experiments is available in the repository: https://github.com/V3RGANz/jointrank},
	booktitle = {Proceedings of the 2025 {International} {ACM} {SIGIR} {Conference} on {Innovative} {Concepts} and {Theories} in {Information} {Retrieval} ({ICTIR})},
	publisher = {Association for Computing Machinery},
	author = {Dedov, Evgeny},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {block design, large language models for zero-shot ranking},
	pages = {208--217},
}

@inproceedings{tang_fine-tuning_2024,
	address = {New York, NY, USA},
	series = {{PRIS} '24},
	title = {Fine-tuning of {LLMs} for {HeXie} {Management} {Theory}},
	isbn = {979-8-4007-1825-0},
	url = {https://doi.org/10.1145/3689218.3689235},
	doi = {10.1145/3689218.3689235},
	abstract = {HeXie Management Theory (HXMT) has been used in many applications. Those applications have demonstrated the effectiveness of the theory in responding to management challenges by integrating oriental and occidental wisdom. With its adoption’s complexity, dynamics, and flexibility, a revolutionary method needs to be developed to simplify it more broadly. Large Language Models (LLMs) have shown their compelling ability to generate human-like content with their chat-based paradigm. Many specifically trained LLMs have demonstrated success in their dedicated application domains. This paper reports the study of fine-tuning LLMs using a specialized dataset derived from the HeXie management theory. Two models were built on Baidu’s Qianfan platform and were adapted for Chinese text. Four criteria were used to evaluate the performances. This study provides an example of fine-tuning LLMs for a Chinese text-based specific theory and building a domain-specific intelligent agent using LLMs or HXMT, which is available at https://alex17swim.com/chat/},
	booktitle = {Proceedings of the 2024 6th {International} {Conference} on {Pattern} {Recognition} and {Intelligent} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Tang, Lisirui and Wang, Chengyu and Li, Gangmin and Liu, Peng},
	year = {2024},
	note = {event-place: Hong Kong, Hong Kong},
	keywords = {Fine-tune, HeXie Management Theory, Large Language Models, RAG},
	pages = {69--73},
}

@inproceedings{chen_cograder_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {{CoGrader}: {Transforming} {Instructors}' {Assessment} of {Project} {Reports} through {Collaborative} {LLM} {Integration}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747670},
	doi = {10.1145/3746059.3747670},
	abstract = {Grading project reports are increasingly significant in today’s educational landscape, where they serve as key assessments of students’ comprehensive problem-solving abilities. However, it remains challenging due to the multifaceted evaluation criteria involved, such as creativity and peer-comparative achievement. Meanwhile, instructors often struggle to maintain fairness throughout the time-consuming grading process. Recent advances in AI, particularly large language models, have demonstrated potential for automating simpler grading tasks, such as assessing quizzes or basic writing quality. However, these tools often fall short when it comes to complex metrics, like design innovation and the practical application of knowledge, that require an instructor’s educational insights into the class situation. To address this challenge, we conducted a formative study with six instructors and developed CoGrader, which introduces a novel grading workflow combining human-LLM collaborative metrics design, benchmarking, and AI-assisted feedback. CoGrader was found effective in improving grading efficiency and consistency while providing reliable peer-comparative feedback to students. We also discuss design insights and ethical considerations for the development of human-AI collaborative grading systems.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Zixin and Wang, Jiachen and Li, Yumeng and Li, Haobo and Shi, Chuhan and Zhang, Rong and Qu, Huamin},
	year = {2025},
	keywords = {human-AI collaboration, large language models, llm for education, project report grading},
}

@inproceedings{yang_graphusion_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Graphusion: {A} {RAG} {Framework} for {Scientific} {Knowledge} {Graph} {Construction} with a {Global} {Perspective}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3717821},
	doi = {10.1145/3701716.3717821},
	abstract = {Knowledge Graphs (KGs) are crucial in the field of artificial intelligence and are widely used in downstream tasks, such as question-answering (QA). The construction of KGs typically requires significant effort from domain experts. Large Language Models (LLMs) have recently been used for Knowledge Graph Construction (KGC). However, most existing approaches focus on a local perspective, extracting knowledge triplets from individual sentences or documents, missing a fusion process to combine the knowledge in a global KG. This work introduces Graphusion, a zero-shot KGC framework from free text. It contains three steps: in Step 1, we extract a list of seed entities using topic modeling to guide the final KG includes the most relevant entities; in Step 2, we conduct candidate triplet extraction using LLMs; in Step 3, we design the novel fusion module that provides a global view of the extracted knowledge, incorporating entity merging, conflict resolution, and novel triplet discovery. Results show that Graphusion achieves scores of 2.92 and 2.37 out of 3 for entity extraction and relation recognition, respectively. Moreover, we showcase how Graphusion could be applied to the Natural Language Processing (NLP) domain and validate it in an educational scenario. Specifically, we introduce TutorQA, a new expert-verified benchmark for QA, comprising six tasks and a total of 1,200 QA pairs. Using the Graphusion-constructed KG, we achieve a significant improvement on the benchmark, for example, a 9.2\% accuracy improvement on sub-graph completion.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Yang, Rui and Yang, Boming and Zhao, Xinjie and Gao, Fan and Feng, Aosong and Ouyang, Sixun and Blum, Moritz and She, Tianwei and Jiang, Yuang and Lecue, Freddy and Lu, Jinghui and Li, Irene},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {information systems database utilities and tools, information systems extraction, information systems language models, transformation and loading},
	pages = {2579--2588},
}

@inproceedings{zhang_ask_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Ask and {Retrieve} {Knowledge}: {Towards} {Proactive} {Asking} with {Imperfect} {Information} in {Medical} {Multi}-turn {Dialogues}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3729898},
	doi = {10.1145/3726302.3729898},
	abstract = {Large language models (LLMs) cannot effectively collaborate with humans who provide imperfect information at the initial stage of the dialogue, unless they learn to proactively ask questions.Our core idea is to enable LLMs to decide whether to take the action of ”ask” or ”tell” at each turn by self-reasoning, with the belief of the decisions enhanced by retrieving knowledge related to the user input. Thus, we propose the ask and retrieve knowledge framework (Ark), where LLMs think through what to retrieve, when to stop retrieving, and then take actions accordingly. Ark is used to produce the action paths for model training. To mitigate the collapse of models trained on synthetic data, we propose a progressive training strategy: self-reason learning by supervised fine-tuning on produced paths and knowledge alignment through direct preference optimization on doctor response.To evaluate the information gain brought by the ask action, we design a method to calculate the ask utility value (AUV) based on the expected value of perfect information (EVPI) theory. Although MedArk is trained using synthetic data from GPT-4o-mini, it highly outperforms GPT-4o and other medical LLMs in six aspects: helpfulness, hallucination, action selection, BERTScore, AUV, and asking correctness. MedArk also achieves SOTA results in the perfect information scenario, i.e., medical examinations. We release our code, data and models at https://github.com/Bolin97/MedArk.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Bolin and Wang, Shengwei and Jiang, Yangqin and Sui, Dianbo and Tu, Zhiying and Chu, Dianhui},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {active inquiry, conversational ir, medical consultation, rag},
	pages = {1055--1065},
}

@inproceedings{alaofi_llms_2024,
	address = {New York, NY, USA},
	series = {{SIGIR}-{AP} 2024},
	title = {{LLMs} can be {Fooled} into {Labelling} a {Document} as {Relevant}: best café near me; this paper is perfectly relevant},
	isbn = {979-8-4007-0724-7},
	url = {https://doi.org/10.1145/3673791.3698431},
	doi = {10.1145/3673791.3698431},
	abstract = {Large Language Models (LLMs) are increasingly being used to assess the relevance of information objects. This work reports on experiments to study the labelling of short texts (i.e., passages) for relevance, using multiple open-source and proprietary LLMs. While the overall agreement of some LLMs with human judgements is comparable to human-to-human agreement measured in previous research, LLMs are more likely to label passages as relevant compared to human judges, indicating that LLM labels denoting non-relevance are more reliable than those indicating relevance.This observation prompts us to further examine cases where human judges and LLMs disagree, particularly when the human judge labels the passage as non-relevant and the LLM labels it as relevant. Results show a tendency for many LLMs to label passages that include the original query terms as relevant. We therefore conduct experiments to inject query words into random and irrelevant passages, not unlike the way we inserted the query 'best café near me' into this paper. The results demonstrate that LLMs are highly influenced by the presence of query words in the passages under assessment, even if the wider passage has no relevance to the query. This tendency of LLMs to be fooled by the mere presence of query words demonstrates a weakness in our current measures of LLM labelling: relying on overall agreement misses important patterns of failures. There is a real risk of bias in LLM-generated relevance labels and, therefore, a risk of bias in rankers trained on those labels.Additionally, we investigate the effects of deliberately manipulating LLMs by instructing them to label passages as relevant, similar to the instruction 'this paper is perfectly relevant' inserted above. We find that such manipulation influences the performance of some LLMs, highlighting the critical need to consider potential vulnerabilities when deploying LLMs in real-world applications.},
	booktitle = {Proceedings of the 2024 {Annual} {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval} in the {Asia} {Pacific} {Region}},
	publisher = {Association for Computing Machinery},
	author = {Alaofi, Marwah and Thomas, Paul and Scholer, Falk and Sanderson, Mark},
	year = {2024},
	note = {event-place: Tokyo, Japan},
	keywords = {information retrieval, llms, relevance labelling, test collections},
	pages = {32--41},
}

@inproceedings{spillo_gal-kars_2025,
	address = {New York, NY, USA},
	series = {{UMAP} '25},
	title = {{GAL}-{KARS}: {Exploiting} {LLMs} for {Graph} {Augmentation} in {Knowledge}-{Aware} {Recommender} {Systems}},
	isbn = {979-8-4007-1313-2},
	url = {https://doi.org/10.1145/3699682.3728342},
	doi = {10.1145/3699682.3728342},
	abstract = {In this paper, we propose a recommendation model that exploits a graph augmentation technique based on Large Language Models (LLMs) to enrich the information encoded in its underlying Knowledge Graph (KG). Our work relies on the assumption that the triples encoded in a KG can often be noisy or incomplete, and this may lead to sub-optimal modeling of both the characteristics of items and the users’ preferences. In this setting, graph augmentation can be a suitable solution to improve the quality of the data model and provide users with high-quality recommendations.Accordingly, in this work, we align with this research line and propose GAL-KARS (Graph Augmentation with LLMs for Knowledge-Aware Recommender Systems). In our framework, we start from a KG, and we design some prompts for querying an LLM and augmenting the graph by incorporating: (a) further features describing the items; (b) further nodes describing the preferences of the users, obtained by reasoning over the items they like. The resulting KG is then passed through a Knowledge Graph Encoder that learns users’ and items’ embeddings based on the augmented KG. These embeddings are finally used to train a recommendation model and provide users with personalized suggestions. As shown in the experimental session, graph augmentation based on LLMs can significantly improve the predictive accuracy of our recommendation model, thus confirming the effectiveness of the model and the validity of our intuitions.},
	booktitle = {Proceedings of the 33rd {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {Association for Computing Machinery},
	author = {Spillo, Giuseppe and Musto, Cataldo and Mannavola, Matteo and de Gemmis, Marco and Lops, Pasquale and Semeraro, Giovanni},
	year = {2025},
	keywords = {Knowledge Graph Augmentation, Large Language Models, Recommender Systems},
	pages = {73--82},
}

@inproceedings{wang_exploring_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Exploring {Personalized} {Health} {Support} through {Data}-{Driven}, {Theory}-{Guided} {LLMs}: {A} {Case} {Study} in {Sleep} {Health}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713852},
	doi = {10.1145/3706598.3713852},
	abstract = {Despite the prevalence of sleep-tracking devices, many individuals struggle to translate data into actionable improvements in sleep health. Current methods often provide data-driven suggestions but may not be feasible and adaptive to real-life constraints and individual contexts. We present HealthGuru, a novel large language model-powered chatbot to enhance sleep health through data-driven, theory-guided, and adaptive recommendations with conversational behavior change support. HealthGuru’s multi-agent framework integrates wearable device data, contextual information, and a contextual multi-armed bandit model to suggest tailored sleep-enhancing activities. The system facilitates natural conversations while incorporating data-driven insights and theoretical behavior change techniques. Our eight-week in-the-wild deployment study with 16 participants compared HealthGuru to a baseline chatbot. Results show improved metrics like sleep duration and activity scores, higher quality responses, and increased user motivation for behavior change with HealthGuru. We also identify challenges and design considerations for personalization and user engagement in health chatbots.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Xingbo and Griffith, Janessa and Adler, Daniel A. and Castillo, Joey and Choudhury, Tanzeem and Wang, Fei},
	year = {2025},
	keywords = {Activity Recommendations, Behavior Change, Large Language Models, Personalized Health, Sleep Health},
}

@inproceedings{tufano_unveiling_2024,
	address = {New York, NY, USA},
	series = {{MSR} '24},
	title = {Unveiling {ChatGPT}'s {Usage} in {Open} {Source} {Projects}: {A} {Mining}-based {Study}},
	isbn = {979-8-4007-0587-8},
	url = {https://doi.org/10.1145/3643991.3644918},
	doi = {10.1145/3643991.3644918},
	abstract = {Large Language Models (LLMs) have gained significant attention in the software engineering community. Nowadays developers have the possibility to exploit these models through industrial-grade tools providing a handy interface toward LLMs, such as OpenAI's ChatGPT. While the potential of LLMs in assisting developers across several tasks has been documented in the literature, there is a lack of empirical evidence mapping the actual usage of LLMs in software projects. In this work, we aim at filling such a gap. First, we mine 1,501 commits, pull requests (PRs), and issues from open-source projects by matching regular expressions likely to indicate the usage of ChatGPT to accomplish the task. Then, we manually analyze these instances, discarding false positives (i.e., instances in which ChatGPT was mentioned but not actually used) and categorizing the task automated in the 467 true positive instances (165 commits, 159 PRs, 143 issues). This resulted in a taxonomy of 45 tasks which developers automate via ChatGPT. The taxonomy, accompanied with representative examples, provides (i) developers with valuable insights on how to exploit LLMs in their workflow and (ii) researchers with a clear overview of tasks that, according to developers, could benefit from automated solutions.},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {Association for Computing Machinery},
	author = {Tufano, Rosalia and Mastropaolo, Antonio and Pepe, Federica and Dabic, Ozren and Di Penta, Massimiliano and Bavota, Gabriele},
	year = {2024},
	note = {event-place: Lisbon, Portugal},
	keywords = {ChatGPT, empirical study},
	pages = {571--583},
}

@inproceedings{alghamdi_enhancing_2024,
	address = {New York, NY, USA},
	series = {{ICFNDS} '23},
	title = {Enhancing {Arabic} {Information} {Retrieval} for {Question} {Answering}},
	isbn = {979-8-4007-0903-6},
	url = {https://doi.org/10.1145/3644713.3644763},
	doi = {10.1145/3644713.3644763},
	abstract = {In the modern landscape of Natural Language Processing (NLP), intelligent chatbots like ChatGPT 3.5 and Google’s Bard have shown remarkable competence in generic question-answering (QA) tasks. However, their performance falters when navigating domain-specific QA, particularly in the Arabic language, which is celebrated for its complex morphology and syntax. This paper presents a comprehensive approach to address these issues. The aim of this research is to build a chatbot tailored for a university community. We first create an extensive Arabic Q\&amp;A dataset by extracting data from academic documents, employing state-of-the-art Optical Character Recognition (OCR) tools. Then, we evaluate multiple text similarity measures like Pooled FastText Word embedding, BM25 ranking functions, and various semantic sentence embedding models. A thorough performance assessment reveals that the domain-specific model excels at both sentence-level similarity and context-relevance tasks. The developed web application chatbot, leveraging LangChain library and Retrieval Augmented Generation (RAG) methods, outperforms existing chatbots in domain-specific, Arabic language QA scenarios.},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Future} {Networks} and {Distributed} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Alghamdi, Muath and Abushawarib, Mohammed and Ellouh, Mahmoud and Ghaleb, Mustafa and Felemban, Muhamad},
	year = {2024},
	note = {event-place: Dubai, United Arab Emirates},
	keywords = {Information Retrieval, Natural Language Processing},
	pages = {366--371},
}

@inproceedings{polys_prompt_2024,
	address = {New York, NY, USA},
	series = {{Web3D} '24},
	title = {Prompt {Engineering} for {X3D} {Object} {Creation} with {LLMs}},
	isbn = {979-8-4007-0689-9},
	url = {https://doi.org/10.1145/3665318.3677159},
	doi = {10.1145/3665318.3677159},
	abstract = {Large Language Models (LLMs) are a new class of knowledge embodied in a computer and trained on massive amounts of human text, image, and video examples. As the result of a user prompt, these LLMs can generate generally coherent responses in several kinds of media and languages. Can LLMs write X3D code? In this paper we explore the ability of several leading LLMs to generate valid and sensible code for interactive X3D scenes. We compare the prompt results from three different LLMs to examine the quality of the generated X3D. We setup an experimental framework that uses a within-subjects repeated-measures design to create X3D from text prompts. We vary our prompt strategies and give the LLMs increasingly challenging and increasingly detailed scene requests. We assess the quality of the resulting X3D scenes including geometry, appearances, animations, and interactions. Our results provide a comparison of different prompt strategies and their outcomes. Such results provide early probes into the limited epistemology and fluency of contemporary LLMs in composing multi-part, animate-able 3D objects.},
	booktitle = {Proceedings of the 29th {International} {ACM} {Conference} on {3D} {Web} {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Polys, Nicholas and Mohammed, Ayat and Sandbrook, Ben},
	year = {2024},
	note = {event-place: Guimarães, Portugal},
	keywords = {3D scene creation, Extensible 3D, Large Language Models},
}

@inproceedings{zhang_chainbuddy_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{ChainBuddy}: {An} {AI}-assisted {Agent} {System} for {Generating} {LLM} {Pipelines}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3714085},
	doi = {10.1145/3706598.3714085},
	abstract = {As large language models (LLMs) advance, their potential applications have grown significantly. However, it remains difficult to evaluate LLM behavior on user-defined tasks and craft effective pipelines to do so. Many users struggle with where to start, often referred to as the "blank page problem." ChainBuddy, an AI workflow generation assistant built into the ChainForge platform, aims to tackle this issue. From a single prompt or chat, ChainBuddy generates a starter evaluative LLM pipeline in ChainForge aligned to the user’s requirements. ChainBuddy offers a straightforward and user-friendly way to plan and evaluate LLM behavior and make the process less daunting and more accessible across a wide range of possible tasks and use cases. We report a within-subjects user study comparing ChainBuddy to the baseline interface. We find that when using AI assistance, participants with a variety of technical expertise reported a less demanding workload, felt more confident, and produced higher quality pipelines evaluating LLM behavior. However, we also uncover a mismatch between subjective and objective ratings of performance: participants rated their successfulness similarly across conditions, while independent experts rated participant workflows significantly higher with AI assistance. Drawing connections to the Dunning–Kruger effect, we discuss implications for the future design of workflow generation assistants regarding the risk of over-reliance.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Jingyue and Arawjo, Ian},
	year = {2025},
	keywords = {AI agents, automation, language models, LLM pipelines, prompt engineering, visual programming environments},
}

@inproceedings{jatowt_flexidigital_2025,
	address = {New York, NY, USA},
	series = {E-{Energy} '25},
	title = {{FlexiDigital}: {A} {Comprehensive} {Approach} to {Energy} {Flexibility} {Services} using {Digital} {Twins} and {Large} {Language} {Models}},
	isbn = {979-8-4007-1125-1},
	url = {https://doi.org/10.1145/3679240.3734662},
	doi = {10.1145/3679240.3734662},
	abstract = {The increasing penetration of renewable energy sources presents new challenges for grid stability, demand-response coordination, and energy flexibility. To address them, we introduce in this position paper, FlexiDigital, an interdisciplinary framework designed to integrate citizen-driven energy flexibility services through AI-powered digital assistants and federated digital twins. FlexiDigital enables prosumers to actively manage and trade their flexibility assets, offering a novel Flexibility-as-a-Service business model. Through dynamic incentives, real-time optimization, and system integration, FlexiDigital advances the clean energy transition by enhancing grid reliability, user engagement, and renewable integration. By giving resource owners direct control over their flexibility assets and compensating them fairly through adaptive pricing, the model fosters economic engagement and opens access to previously exclusive energy markets.},
	booktitle = {Proceedings of the 16th {ACM} {International} {Conference} on {Future} and {Sustainable} {Energy} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Jatowt, Adam and Ristov, Sashko and Gritsch, Philipp and Brandacher, Simon and Rosengren, Peter and Valerio, Danilo and Luo, Fengji},
	year = {2025},
	keywords = {Digital Twins, Energy bank, Energy Flexibility, Forecasting, LLMs},
	pages = {638--643},
}

@inproceedings{kweon_uncertainty_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Uncertainty {Quantification} and {Decomposition} for {LLM}-based {Recommendation}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714601},
	doi = {10.1145/3696410.3714601},
	abstract = {Despite the widespread adoption of large language models (LLMs) for recommendation, we demonstrate that LLMs often exhibit uncertainty in their recommendations. To ensure the trustworthy use of LLMs in generating recommendations, we emphasize the importance of assessing the reliability of recommendations generated by LLMs. We start by introducing a novel framework for estimating the predictive uncertainty to quantitatively measure the reliability of LLM-based recommendations. We further propose to decompose the predictive uncertainty into recommendation uncertainty and prompt uncertainty, enabling in-depth analyses of the primary source of uncertainty. Through extensive experiments, we (1) demonstrate predictive uncertainty effectively indicates the reliability of LLM-based recommendations, (2) investigate the origins of uncertainty with decomposed uncertainty measures, and (3) propose uncertainty-aware prompting for a lower predictive uncertainty and enhanced recommendation. Our source code and model weights are available at https://github.com/WonbinKweon/UNC\_LLM\_REC\_WWW2025},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Kweon, Wonbin and Jang, Sanghwan and Kang, SeongKu and Yu, Hwanjo},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {large language models, recommendation, uncertainty},
	pages = {4889--4901},
}

@inproceedings{vandeputte_foundational_2025,
	address = {New York, NY, USA},
	series = {Onward! '25},
	title = {Foundational {Design} {Principles} and {Patterns} for {Building} {Robust} and {Adaptive} {GenAI}-{Native} {Systems}},
	isbn = {979-8-4007-2151-9},
	url = {https://doi.org/10.1145/3759429.3762620},
	doi = {10.1145/3759429.3762620},
	abstract = {Generative AI (GenAI) has emerged as a transformative technology, demonstrating remarkable capabilities across diverse application domains. However, GenAI faces several major challenges in developing reliable and efficient GenAI-empowered systems due to its unpredictability and inefficiency. This paper advocates for a paradigm shift: future GenAI-native systems should integrate GenAI's cognitive capabilities with traditional software engineering principles to create robust, adaptive, and efficient systems. We introduce foundational GenAI-native design principles centered around five key pillars—reliability, excellence, evolvability, self-reliance, and assurance—and propose architectural patterns such as GenAI-native cells, organic substrates, and programmable routers to guide the creation of resilient and self-evolving systems. Additionally, we outline the key ingredients of a GenAI-native software stack and discuss the impact of these systems from technical, user adoption, economic, and legal perspectives, underscoring the need for further validation and experimentation. Our work aims to inspire future research and encourage relevant communities to implement and refine this conceptual framework.},
	booktitle = {Proceedings of the 2025 {ACM} {SIGPLAN} {International} {Symposium} on {New} {Ideas}, {New} {Paradigms}, and {Reflections} on {Programming} and {Software}},
	publisher = {Association for Computing Machinery},
	author = {Vandeputte, Frederik},
	year = {2025},
	note = {event-place: Singapore, Singapore},
	keywords = {architectural patterns, best practices, design principles, excellence, GenAI, reliability, software systems},
	pages = {44--62},
}

@inproceedings{liu_personaflow_2025,
	address = {New York, NY, USA},
	series = {{DIS} '25},
	title = {{PersonaFlow}: {Designing} {LLM}-{Simulated} {Expert} {Perspectives} for {Enhanced} {Research} {Ideation}},
	isbn = {979-8-4007-1485-6},
	url = {https://doi.org/10.1145/3715336.3735789},
	doi = {10.1145/3715336.3735789},
	abstract = {Generating interdisciplinary research ideas requires diverse domain expertise, but access to timely feedback is often limited by the availability of experts. In this paper, we introduce PersonaFlow, a novel system designed to provide multiple perspectives by using LLMs to simulate domain-specific experts. Our user studies showed that the new design 1) increased the perceived relevance and creativity of ideated research directions, and 2) promoted users’ critical thinking activities (e.g., interpretation, analysis, evaluation, inference, and self-regulation), without increasing their perceived cognitive load. Moreover, users’ ability to customize expert profiles significantly improved their sense of agency, which can potentially mitigate their over-reliance on AI. This work contributes to the design of intelligent systems that augment creativity and collaboration, and provides design implications of using customizable AI-simulated personas in domains within and beyond research ideation.},
	booktitle = {Proceedings of the 2025 {ACM} {Designing} {Interactive} {Systems} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Yiren and Sharma, Pranav and Oswal, Mehul and Xia, Haijun and Huang, Yun},
	year = {2025},
	keywords = {Co-Creation Systems, Ideation Support, Large Language Models, Persona Simulation, Scientific Discovery},
	pages = {506--534},
}

@inproceedings{chakrabarti_inside_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Inside {Out} 2: {Make} {Room} for {New} {Emotions} \&amp; {LLM}: {A} {Reproducibility} {Study} of the {Emotional} {Side} of {Search} in the {Classroom}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730315},
	doi = {10.1145/3726302.3730315},
	abstract = {In an existing study, the InsideOut Framework is used to produce and explore the emotional profiles of search engines (SE) in response to queries formulated by children aged 9 to 11 in the classroom context, revealing the emotional diversity of SE responses. Since then, there have been significant technological advances in emotion detection and information access. In this work, we conduct a comprehensive reproducibility study where we probe today's emotional profile of SE using both a lexicon-based and a language-model based approach tailored to the Italian language, thus addressing an acknowledged limitation of the original study. Additionally, considering the prevalence of agents based on Large Language Models (LLM) as information access systems among children, we extend the analysis to capture the emotional undertones of LLM responses and juxtapose them to those of SE. Our findings emphasize the importance of leveraging the appropriate emotion detection technique to produce and explore emotional profiles and lead us to reflect on the interplay of emotions on children's search-as-learning experience.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Chakrabarti, Hrishita and Tobia, Diletta Micol and Landoni, Monica and Pera, Maria Soledad},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {children, emotions, information access systems, llm, search},
	pages = {3244--3254},
}

@inproceedings{xu_finbert2_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{FinBERT2}: {A} {Specialized} {Bidirectional} {Encoder} for {Bridging} the {Gap} in {Finance}-{Specific} {Deployment} of {Large} {Language} {Models}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737219},
	doi = {10.1145/3711896.3737219},
	abstract = {In natural language processing (NLP), the focus has shifted from encoder-only tiny language models like BERT to decoder-only large language models(LLMs) such as GPT-3. However, LLMs' practical application in the financial sector has revealed three limitations: (1) LLMs often perform worse than fine-tuned BERT on discriminative tasks despite costing much higher computational resources, such as market sentiment analysis in financial reports; (2) Application on generative tasks heavily relies on retrieval augmented generation (RAG) methods to provide current and specialized information, with general retrievers showing suboptimal performance on domain-specific retrieval tasks; (3) There are additional inadequacies in other feature-based scenarios, such as topic modeling. We introduce FinBERT2, a specialized bidirectional encoder pretrained on a high-quality, financial-specific corpus of 32b tokens. This represents the largest known Chinese financial pretraining corpus for models of this parameter size. As a better backbone, FinBERT2 can bridge the gap in the financial-specific deployment of LLMs through the following achievements: (1) Discriminative fine-tuned models (Fin-Labelers) outperform other (Fin)BERT variants by 0.4\%-3.3\% and leading LLMs by 9.7\%-12.3\% on average across five financial classification tasks. (2) Contrastive fine-tuned models (Fin-Retrievers) outperform both open-source (e.g., +6.8\% avg improvement over BGE-base-zh) and proprietary (e.g., +4.2\% avg improvement over OpenAI's text-embedding-3-large) embedders across five financial retrieval tasks; (3) Building on FinBERT2 variants, we construct the Fin-TopicModel, which enables superior clustering and topic representation for financial titles. Our work revisits financial BERT models through comparative analysis with contemporary LLMs and offers practical insights for effectively utilizing FinBERT in the LLMs era.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Xu, Xuan and Wen, Fufang and Chu, Beilin and Fu, Zhibing and Lin, Qinhong and Liu, Jiaqi and Fei, Binjie and Li, Yu and Zhou, Linna and Yang, Zhongliang},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {dense retriever, domain-specific LM, financial NLP, FinBERT, pretraining, topic modeling},
	pages = {5117--5128},
}

@inproceedings{gim_serve_2025,
	address = {New York, NY, USA},
	series = {{HotOS} '25},
	title = {Serve {Programs}, {Not} {Prompts}},
	isbn = {979-8-4007-1475-7},
	url = {https://doi.org/10.1145/3713082.3730398},
	doi = {10.1145/3713082.3730398},
	abstract = {Current large language model (LLM) serving systems, primarily designed for text completion, are neither efficient nor adaptable for increasingly complex LLM applications due to their inflexible design. We propose a new LLM serving system architecture that serves programs instead of prompts to address this problem. These programs, called LLM Inference Programs (LIPs), allow users to customize token prediction and KV cache management at runtime and to offload parts of their application logic, such as tool execution, to the server. We describe an example of this architecture through a system named Symphony, which functions as an operating system for LIPs. Symphony exposes LLM model computations via system calls and virtualizes KV cache with a dedicated file system, while ensuring GPU efficiency with a two-level process scheduling scheme. Symphony has the potential to open the door to a more efficient and extensible ecosystem for LLM applications.},
	booktitle = {Proceedings of the 2025 {Workshop} on {Hot} {Topics} in {Operating} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Gim, In and Zhong, Lin},
	year = {2025},
	note = {event-place: Banff, AB, Canada},
	keywords = {KV cache, Large language models, LLM serving systems},
	pages = {179--186},
}

@inproceedings{isozaki_towards_2025,
	address = {New York, NY, USA},
	series = {{UMAP} {Adjunct} '25},
	title = {Towards {Automated} {Penetration} {Testing}: {Introducing} {LLM} {Benchmark}, {Analysis}, and {Improvements}},
	isbn = {979-8-4007-1399-6},
	url = {https://doi.org/10.1145/3708319.3733804},
	doi = {10.1145/3708319.3733804},
	abstract = {Hacking poses a significant threat to cybersecurity, inflicting billions of dollars in damages annually. To mitigate these risks, ethical hacking, or penetration testing, is employed to identify vulnerabilities in systems and networks. Recent advancements in large language models (LLMs) have shown potential across various domains, including cybersecurity. However, there is currently no comprehensive, open, end-to-end penetration testing benchmark to drive progress and evaluate the capabilities of these models in security contexts. This paper introduces a novel open benchmark1 for LLM-based penetration testing, addressing this critical gap. We first evaluate the performance of LLMs, including GPT-4o and LLama 3.1-405B, using the state-of-the-art PentestGPT tool. Our findings reveal that while LLama 3.1 demonstrates an edge over GPT-4o, both models currently fall short of performing end-to-end penetration testing even with some minimal human assistance. Next, we advance the state-of-the-art and present ablation studies that provide insights into improving the PentestGPT tool2. Our research illuminates the challenges LLMs face in each aspect of Pentesting, e.g. enumeration, exploitation, and privilege escalation. This work contributes to the growing body of knowledge on AI-assisted cybersecurity and lays the foundation for future research in automated penetration testing using large language models.},
	booktitle = {Adjunct {Proceedings} of the 33rd {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {Association for Computing Machinery},
	author = {Isozaki, Isamu and Shrestha, Manil and Console, Rick and Kim, Edward},
	year = {2025},
	keywords = {Benchmarking, Capture the Flag, Large Language Models, Penetration Testing},
	pages = {404--419},
}

@inproceedings{li_llm-enhanced_2024,
	address = {New York, NY, USA},
	series = {{SA} '24},
	title = {{LLM}-enhanced {Scene} {Graph} {Learning} for {Household} {Rearrangement}},
	isbn = {979-8-4007-1131-2},
	url = {https://doi.org/10.1145/3680528.3687607},
	doi = {10.1145/3680528.3687607},
	abstract = {The household rearrangement task involves spotting misplaced objects in a scene and accommodate them with proper places. It depends both on common-sense knowledge on the objective side and human user preference on the subjective side. In achieving such a task, we propose to mine object functionality with user preference alignment directly from the scene itself, without relying on human intervention. To do so, we work with scene graph representation and propose LLM-enhanced scene graph learning which transforms the input scene graph into an affordance-enhanced graph (AEG) with information-enhanced nodes and newly discovered edges (relations). In AEG, the nodes corresponding to the receptacle objects are augmented with context-induced affordance which encodes what kind of carriable objects can be placed on it. New edges are discovered with newly discovered non-local relations. With AEG, we perform task planning for scene rearrangement by detecting misplaced carriables and determining a proper placement for each of them. We test our method by implementing a tiding robot in simulator and perform evaluation on a new benchmark we build. Extensive evaluations demonstrate that our method achieves state-of-the-art performance in misplacement detection and the following rearrangement planning.},
	booktitle = {{SIGGRAPH} {Asia} 2024 {Conference} {Papers}},
	publisher = {Association for Computing Machinery},
	author = {Li, Wenhao and Yu, Zhiyuan and She, Qijin and Yu, Zhinan and Lan, Yuqing and Zhu, Chenyang and Hu, Ruizhen and Xu, Kai},
	year = {2024},
	note = {event-place: Tokyo, Japan},
}

@inproceedings{demartini_preaching_2025,
	address = {New York, NY, USA},
	series = {{ICTIR} '25},
	title = {Preaching to the {ChoIR}: {Lessons} {IR} {Should} {Share} with {AI}},
	isbn = {979-8-4007-1861-8},
	url = {https://doi.org/10.1145/3731120.3744612},
	doi = {10.1145/3731120.3744612},
	abstract = {The field of Information Retrieval (IR) changed profoundly at the end of the 1990s with the rise of Web Search, and there are parallels with developments in Artificial Intelligence (AI) happening today with the advent of ChatGPT, Large Language Models, and Generative AI. We acknowledge that there are clear differences between IR and AI. For example, IR is a much smaller field, and new problems arise, like data contamination that may affect benchmark-based evaluation of AI systems. But looking through the lens of an IR researcher, there are many striking similarities between the two fields of IR (25 years ago) and AI (today), and many topics appearing in discussions in AI resemble those of 25 years ago in IR: benchmark reliability and robust evaluation, reproducibility of results for non-public models, privacy and copyright issues, efficiency and scalability, etc. In this paper, we discuss similarities and differences between IR and AI and then derive some lessons learned in the field of IR as a list of recommendations - urging the IR community to reflect on, discuss, and convey these lessons to the AI field. We believe that a joint community effort by all IR researchers is both necessary and dutiful to obtain a fruitful discussion and research advancements with the AI community.},
	booktitle = {Proceedings of the 2025 {International} {ACM} {SIGIR} {Conference} on {Innovative} {Concepts} and {Theories} in {Information} {Retrieval} ({ICTIR})},
	publisher = {Association for Computing Machinery},
	author = {Demartini, Gianluca and Hauff, Claudia and Lease, Matthew and Mizzaro, Stefano and Roitero, Kevin and Sanderson, Mark and Scholer, Falk and Shah, Chirag and Spina, Damiano and Thomas, Paul and de Vries, Arjen P. and Zuccon, Guido},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {artificial intelligence, lessons learned, research community},
	pages = {78--91},
}

@inproceedings{zine_llm-based_2025,
	address = {New York, NY, USA},
	series = {{SPLC}-{A} '25},
	title = {{LLM}-based {Co}-{Evolution} of {Configurable} {Software} {Systems}},
	isbn = {979-8-4007-2024-6},
	url = {https://doi.org/10.1145/3744915.3748460},
	doi = {10.1145/3744915.3748460},
	abstract = {Software Product Lines (SPLs) and s are de\&nbsp;facto standards for managing variability in software systems. However, maintaining an up-to-date during software evolution is particularly challenging. Ensuring its consistency with the artifacts of an SPL requires co-evolving them alongside the developed system. When performed manually, this co-evolution process is tedious and error-prone, highlighting the need for automated support. Yet, little attention has been given to the automation of co-evolution between and source code. In this paper, we explore the potential of open-source s to fill this gap. Specifically, we investigate the extent to which s can support bidirectional co-evolution: from to source code—where modifications in the drive changes in the code—and from source code to —where updates in the code are reflected back into the. We evaluate our -based approach on a real-world configurable system. Our results demonstrate that co-evolution from source code to achieves F1 scores ranging from 0.93 to 1.0, while co-evolution from to source code achieves F1 scores between 0.41 and 0.99. These findings highlight the potential of s to support this co-evolution process, while also showing limitations and suggesting areas for improvement, particularly for the co-evolution from to code. Additionally, we conduct a comparative study across various s, revealing how choice affects co-evolution and, incidentally, how it affects model and code generation. Up to a certain size limit, larger s tend to produce more accurate and stable outputs than smaller ones, however, this influence is less pronounced in the code generation task. Overall, our work opens a new research avenue where s are leveraged for automating the co-evolution between configurable software systems and variability models.},
	booktitle = {Proceedings of the 29th {ACM} {International} {Systems} and {Software} {Product} {Line} {Conference} - {Volume} {A}},
	publisher = {Association for Computing Machinery},
	author = {Zine, Nada and Quinton, Clément and Rouvoy, Romain},
	year = {2025},
	keywords = {Co-evolution, Feature Models, Large Language Models, Software Product Lines},
	pages = {27--38},
}

@inproceedings{pinto_lessons_2024,
	address = {New York, NY, USA},
	series = {{ICSE}-{SEIP} '24},
	title = {Lessons from {Building} {StackSpot} {AI}: {A} {Contextualized} {AI} {Coding} {Assistant}},
	isbn = {979-8-4007-0501-4},
	url = {https://doi.org/10.1145/3639477.3639751},
	doi = {10.1145/3639477.3639751},
	abstract = {With their exceptional natural language processing capabilities, tools based on Large Language Models (LLMs) like ChatGPT and CoPilot have swiftly become indispensable resources in the software developer's toolkit. While recent studies suggest the potential productivity gains these tools can unlock, users still encounter drawbacks, such as generic or incorrect answers. Additionally, the pursuit of improved responses often leads to extensive prompt engineering efforts, diverting valuable time from writing code that delivers actual value. To address these challenges, a new breed of tools, built atop LLMs, is emerging. These tools aim to mitigate drawbacks by employing techniques like fine-tuning or enriching user prompts with contextualized information.In this paper, we delve into the lessons learned by a software development team venturing into the creation of such a contextualized LLM-based application, using retrieval-based techniques, called StackSpot AI. Over a four-month period, the team, despite lacking prior professional experience in LLM-based applications, built the product from scratch. Following the initial product release, we engaged with the development team responsible for the code generative components. Through interviews and analysis of the application's issue tracker, we uncover various intriguing challenges that teams working on LLM-based applications might encounter. For instance, we found three main group of lessons: LLM-based lessons, User-based lessons, and Technical lessons. By understanding these lessons, software development teams could become better prepared to build LLM-based applications.},
	booktitle = {Proceedings of the 46th {International} {Conference} on {Software} {Engineering}: {Software} {Engineering} in {Practice}},
	publisher = {Association for Computing Machinery},
	author = {Pinto, Gustavo and De Souza, Cleidson and Neto, Joao Batista and Souza, Alberto and Gotto, Tarci­sio and Monteiro, Edward},
	year = {2024},
	note = {event-place: Lisbon, Portugal},
	keywords = {challenges, code LLMs, LLM, LLM for code, LLM-based applications, LLM4code},
	pages = {408--417},
}

@inproceedings{sun_creative_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Creative {Blends} of {Visual} {Concepts}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713683},
	doi = {10.1145/3706598.3713683},
	abstract = {Visual blends combine elements from two distinct visual concepts into a single, integrated image, with the goal of conveying ideas through imaginative and often thought-provoking visuals. Communicating abstract concepts through visual blends poses a series of conceptual and technical challenges. To address these challenges, we introduce Creative Blends, an AI-assisted design system that leverages metaphors to visually symbolize abstract concepts by blending disparate objects. Our method harnesses commonsense knowledge bases and large language models to align designers’ conceptual intent with expressive concrete objects. Additionally, we employ generative text-to-image techniques to blend visual elements through their overlapping attributes. A user study (N=24) demonstrated that our approach reduces participants’ cognitive load, fosters creativity, and enhances the metaphorical richness of visual blend ideation. We explore the potential of our method to expand visual blends to include multiple object blending and discuss the insights gained from designing with generative AI.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Sun, Zhida and Zhang, Zhenyao and Zhang, Yue and Lu, Min and Lischinski, Dani and Cohen-Or, Daniel and Huang, Hui},
	year = {2025},
	keywords = {Creativity, Metaphor, Text-to-Image Generation, Visual Blends},
}

@inproceedings{zhang_imperceptible_2024,
	address = {New York, NY, USA},
	series = {{ASE} '24},
	title = {Imperceptible {Content} {Poisoning} in {LLM}-{Powered} {Applications}},
	isbn = {979-8-4007-1248-7},
	url = {https://doi.org/10.1145/3691620.3695001},
	doi = {10.1145/3691620.3695001},
	abstract = {Large Language Models (LLMs) have shown their superior capability in natural language processing, promoting extensive LLM-powered applications to be the new portals for people to access various content on the Internet. However, LLM-powered applications do not have sufficient security considerations on untrusted content, leading to potential threats. In this paper, we reveal content poisoning, where attackers can tailor attack content that appears benign to humans but causes LLM-powered applications to generate malicious responses. To highlight the impact of content poisoning and inspire the development of effective defenses, we systematically analyze the attack, focusing on the attack modes in various content, exploitable design features of LLM application frameworks, and the generation of attack content. We carry out a comprehensive evaluation on five LLMs, where content poisoning achieves an average attack success rate of 89.60\%. Additionally, we assess content poisoning on four popular LLM-powered applications, achieving the attack on 72.00\% of the content. Our experimental results also show that existing defenses are ineffective against content poisoning. Finally, we discuss potential mitigations for LLM application frameworks to counter content poisoning.},
	booktitle = {Proceedings of the 39th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Quan and Zhou, Chijin and Go, Gwihwan and Zeng, Binqi and Shi, Heyuan and Xu, Zichen and Jiang, Yu},
	year = {2024},
	note = {event-place: Sacramento, CA, USA},
	keywords = {content poisoning, LLM applications},
	pages = {242--254},
}

@inproceedings{yuan_kg-uq_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{KG}-{UQ}: {Knowledge} {Graph}-{Based} {Uncertainty} {Quantification} for {Long} {Text} in {Large} {Language} {Models}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3717660},
	doi = {10.1145/3701716.3717660},
	abstract = {With the commercialization of large language models (LLMs) and their integration into daily life, addressing their susceptibility to hallucinations-unfactual information in generated outputs-has become an urgent priority. Existing uncertainty quantification (UQ) methods often rely on access to LLMs' internal states, which is unavailable for closed-source models like GPTs, or are primarily designed for short text. Current research on long text typically evaluates sentences individually, overlooking smaller semantic units that better capture the text's complexity. Recognizing the potential of knowledge graphs (KGs) to extract structured relationships from unstructured text, we propose KG-UQ, a UQ method leveraging KGs to address the semantic intricacies of long text. Our approach involves constructing KGs from long-text outputs and utilizing their embeddings to estimate uncertainties. Through our analysis, we demonstrate that knowledge graphs are an effective tool for decomposing long text into fundamental statements. However, we also highlight the increased uncertainty introduced during KG construction, stemming from inherent challenges in accurately capturing all semantic information.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Yuan, Yingqing and Tao, Linwei and Lu, Haohui and Khushi, Matloob and Razzak, Imran and Dras, Mark and Yang, Jian and Naseem, Usman},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {llm, uncertainty estimation},
	pages = {2071--2077},
}

@inproceedings{zhang_are_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Are {Large} {Language} {Models} {Good} at {Utility} {Judgments}?},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657784},
	doi = {10.1145/3626772.3657784},
	abstract = {Retrieval-augmented generation (RAG) is considered to be a promising approach to alleviate the hallucination issue of large language models (LLMs), and it has received widespread attention from researchers recently. Due to the limitation in the semantic understanding of retrieval models, the success of RAG heavily lies on the ability of LLMs to identify passages with utility. Recent efforts have explored the ability of LLMs to assess the relevance of passages in retrieval, but there has been limited work on evaluating the utility of passages in supporting question answering.In this work, we conduct a comprehensive study about the capabilities of LLMs in utility evaluation for open-domain question answering (QA). Specifically, we introduce a benchmarking procedure and collection of candidate passages with different characteristics, facilitating a series of experiments with five representative LLMs. Our experiments reveal that: (i) well-instructed LLMs can distinguish between relevance and utility, and that LLMs are highly receptive to newly generated counterfactual passages. Moreover, (ii) we scrutinize key factors that affect utility judgments in the instruction design. And finally, (iii) to verify the efficacy of utility judgments in practical retrieval augmentation applications, we delve into LLMs' QA capabilities using the evidence judged with utility and direct dense retrieval results. (iv) We propose a k-sampling, listwise approach to reduce the dependency of LLMs on the sequence of input passages, thereby facilitating subsequent answer generation. We believe that the way we formalize and study the problem along with our findings contributes to a critical assessment of retrieval-augmented LLMs. Our code and benchmark can be found at https://github.com/ict-bigdatalab/utility\_judgments.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Hengran and Zhang, Ruqing and Guo, Jiafeng and de Rijke, Maarten and Fan, Yixing and Cheng, Xueqi},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {large language models, open-domain qa, utility judgments},
	pages = {1941--1951},
}

@inproceedings{harvey_dont_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {"{Don}'t {Forget} the {Teachers}": {Towards} an {Educator}-{Centered} {Understanding} of {Harms} from {Large} {Language} {Models} in {Education}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713210},
	doi = {10.1145/3706598.3713210},
	abstract = {Education technologies (edtech) are increasingly incorporating new features built on large language models (LLMs), with the goals of enriching the processes of teaching and learning and ultimately improving learning outcomes. However, the potential downstream impacts of LLM-based edtech remain understudied. Prior attempts to map the risks of LLMs have not been tailored to education specifically, even though it is a unique domain in many respects: from its population (students are often children, who can be especially impacted by technology) to its goals (providing the correct answer may be less important for learners than understanding how to arrive at an answer) to its implications for higher-order skills that generalize across contexts (e.g., critical thinking and collaboration). We conducted semi-structured interviews with six edtech providers representing leaders in the K-12 space, as well as a diverse group of 23 educators with varying levels of experience with LLM-based edtech. Through a thematic analysis, we explored how each group is anticipating, observing, and accounting for potential harms from LLMs in education. We find that, while edtech providers focus primarily on mitigating technical harms, i.e., those that can be measured based solely on LLM outputs themselves, educators are more concerned about harms that result from the broader impacts of LLMs, i.e., those that require observation of interactions between students, educators, school systems, and edtech to measure. Overall, we (1) develop an education-specific overview of potential harms from LLMs, (2) highlight gaps between conceptions of harm by edtech providers and those by educators, and (3) make recommendations to facilitate the centering of educators in the design and development of edtech tools.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Harvey, Emma and Koenecke, Allison and Kizilcec, Rene F.},
	year = {2025},
	keywords = {edtech, education, harms, interviews, large language models, LLMs},
}

@inproceedings{guan_mfort-qa_2024,
	address = {New York, NY, USA},
	series = {{ICCAI} '24},
	title = {{MFORT}-{QA}: {Multi}-hop {Few}-shot {Open} {Rich} {Table} {Question} {Answering}},
	isbn = {979-8-4007-1705-5},
	url = {https://doi.org/10.1145/3669754.3669822},
	doi = {10.1145/3669754.3669822},
	abstract = {In today’s fast-paced industry, professionals face the challenge of summarizing a large number of documents and extracting vital information from them on a daily basis. These metrics are frequently hidden away in tables and/or their nested hyperlinks. To address this challenge, the approach of Table Question Answering (QA) has been developed to extract the relevant information. However, traditional Table QA training tasks that provide a table and an answer(s) from a gold cell coordinate(s) for a question may not always ensure extracting the accurate answer(s). Recent advancements in Large Language Models (LLMs) have opened up new possibilities for extracting information from tabular data using prompts. In this paper, we introduce the Multi-hop Few-shot Open Rich Table QA (MFORT-QA) approach, which consists of two major steps. The first step involves Few-Shot Learning (FSL), where relevant tables and associated contexts of hyperlinks are retrieved based on a given question. The retrieved content is then used to construct few-shot prompts as inputs to an LLM, such as ChatGPT. To tackle the challenge of answering complex questions, the second step leverages Chain-of-thought (CoT) prompting to decompose the complex question into a sequential chain of questions and reasoning thoughts in a multi-hop manner. Retrieval-Augmented Generation (RAG) enhances this process by retrieving relevant tables and contexts of hyperlinks that are relevant to the resulting reasoning thoughts and questions. These additional contexts are then used to supplement the prompt used in the first step, resulting in more accurate answers from an LLM. Empirical results from OTT-QA demonstrate that our abstractive QA approach significantly improves the accuracy of extractive Table QA methods.},
	booktitle = {Proceedings of the 2024 10th {International} {Conference} on {Computing} and {Artificial} {Intelligence}},
	publisher = {Association for Computing Machinery},
	author = {Guan, Che and Huang, Mengyu and Zhang, Peng},
	year = {2024},
	note = {event-place: Bali Island, Indonesia},
	keywords = {Chain-of-Thought Prompting, Few-Shot Learning, Information Retrieval, Large Language Models, Open Table Question-Answering},
	pages = {434--442},
}

@inproceedings{qin_eva_2025,
	address = {Richland, SC},
	series = {{AAMAS} '25},
	title = {Eva: {An} {LLM}-based {Multilingual} {Voice}-agent {Network} for {Restaurant} {Operations}},
	isbn = {979-8-4007-1426-9},
	abstract = {Eva is a voice AI agentic system automating restaurant phone operations with individual agents for tasks like order placement and a global agent for multi-restaurant settings. It uses a hierarchical multi-agent architecture with various agent technologies, demonstrating LLM applications for improved efficiency and service in the restaurant industry.},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Autonomous} {Agents} and {Multiagent} {Systems}},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Qin, Zhiwei (Tony) and Zhou, Jianming},
	year = {2025},
	note = {event-place: Detroit, MI, USA},
	keywords = {llm, multi-agent, multilingual, restaurant operations, voice ai},
	pages = {3035--3037},
}

@inproceedings{joshi_coprompter_2025,
	address = {New York, NY, USA},
	series = {{IUI} '25},
	title = {{CoPrompter}: {User}-{Centric} {Evaluation} of {LLM} {Instruction} {Alignment} for {Improved} {Prompt} {Engineering}},
	isbn = {979-8-4007-1306-4},
	url = {https://doi.org/10.1145/3708359.3712102},
	doi = {10.1145/3708359.3712102},
	abstract = {Ensuring large language models’ (LLMs) responses align with prompt instructions is crucial for application development. Based on our formative study with industry professionals, the alignment requires heavy human involvement and tedious trial-and-error especially when there are many instructions in the prompt. To address these challenges, we introduce CoPrompter, a framework that identifies misalignment based on assessing multiple LLM responses with criteria. It proposes a method to generate evaluation criteria questions derived directly from prompt requirements and an interface to turn these questions into a user-editable checklist. Our user study with industry prompt engineers shows that CoPrompter improves the ability to identify and refine instruction alignment with prompt requirements over traditional methods, helps them understand where and how frequently models fail to follow user’s prompt requirements, and helps in clarifying their own requirements, giving them greater control over the response evaluation process. We also present the design lessons to underscore our system’s potential to streamline the prompt engineering process.},
	booktitle = {Proceedings of the 30th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Joshi, Ishika and Shahid, Simra and Venneti, Shreeya Manasvi and Vasu, Manushree and Zheng, Yantao and Li, Yunyao and Krishnamurthy, Balaji and Chan, Gromit Yeuk-Yin},
	year = {2025},
	keywords = {HCI, LLM Evaluation, Prompt Optimization},
	pages = {341--365},
}

@inproceedings{cai_hi_2025,
	address = {New York, NY, USA},
	series = {{IDC} '25},
	title = {"{Hi} {Kids}, {Let}'s {Talk} {About} {How} {Snakes} {Hunt}": {Understanding} the {Process} of {Children}'s {Instructional} {Video} {Creation} through a {Workshop} {Study}},
	isbn = {979-8-4007-1473-3},
	url = {https://doi.org/10.1145/3713043.3728859},
	doi = {10.1145/3713043.3728859},
	abstract = {As children increasingly transition from media consumers to "prosumers" on user-generated content platforms, developing their media and content creation literacies becomes critical. Yet little research examines how children engage with video creation or how emerging technologies, such as generative AI, can support this creative process. This study explores children’s engagement and challenges during a two-week, project-based learning workshop where they learned to create educational videos teaching school-aligned science topics. Our exploratory findings suggest that educational video creation activity, when designed properly, can serve as an intervention for the dual learning of science literacy and media literacy. In the workshop, children showed different engagement profiles: some were self-directed and motivated by both science learning and video creation, some focused primarily on learning the science content, some treated the activity as a classroom assignment, and others disengaged from the process. Building on insights from our findings, We also extend Shneiderman’s Collect-Relate-Create-Donate (CRCD) model to better support children’s creativity. We propose design directions including conversational, filtered, and multimodal information gathering for the Collect phase; role-based peer and family interaction for the Relate phase; low-floor, high-ceiling creation tools for the Create phase; and positioning children as meaningful sharers of content while supporting education around content sharing, privacy, and audience awareness for the Donate phase.},
	booktitle = {Proceedings of the 24th {Interaction} {Design} and {Children}},
	publisher = {Association for Computing Machinery},
	author = {Cai, Zhenyao and Wei, Shiyao and Han, Ariel and Peppler, Kylie A},
	year = {2025},
	keywords = {Child-AI Co-Creation, Content Creation, Creativity Support Tools, Media Literacy},
	pages = {684--698},
}

@inproceedings{jokinen_towards_2025,
	address = {Melbourne, Australia},
	series = {{HRI} '25},
	title = {Towards {Domain} {Graphs} and {Dialogue} {Graphs} for {Conversational} {Grounding} in {HRI}},
	abstract = {Knowledge graphs have been used to improve robot dialogues by providing more sophisticated world knowledge. We now propose a new role for knowledge graphs in GenAI-based HRI that aims to reduce dialogue errors by better conversational grounding. This approach uses both domain knowledge graphs and dialogue history graphs, constructing shared knowledge via entity linking. We present first steps towards these aims, and also address sustainability by supporting the use of smaller models.},
	booktitle = {Proceedings of the 2025 {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {IEEE Press},
	author = {Jokinen, Kristiina and Wilcock, Graham},
	year = {2025},
	keywords = {conversational grounding, human-robot dialogues, knowledge graphs, sustainability},
	pages = {1373--1377},
}

@inproceedings{farzi_pencils_2024,
	address = {New York, NY, USA},
	series = {{ICTIR} '24},
	title = {Pencils {Down}! {Automatic} {Rubric}-based {Evaluation} of {Retrieve}/{Generate} {Systems}},
	isbn = {979-8-4007-0681-3},
	url = {https://doi.org/10.1145/3664190.3672511},
	doi = {10.1145/3664190.3672511},
	abstract = {Current IR evaluation paradigms are challenged by large language models (LLMs) and retrieval-augmented generation (RAG) methods. Furthermore, evaluation either resorts to expensive human judgments or lead to an over-reliance on LLMs.To remedy this situation, we introduce the RUBRIC metric, which puts information retrieval systems to the proverbial test. This metric leverages a bank of query-related test questions to quantify relevant information content that is contained in the systems' responses. The process involves (1) decomposing the query into detailed questions, and (2) checking each for answerability using passages in the system response. Using three TREC benchmarks, we demonstrate that our LLM-based RUBRIC approach works successfully. Unlike previous LLM-based evaluation measures, our paradigm lends itself for incorporating a human-in-the-loop while avoiding some pitfalls of over-reliance on AI or resorting to expensive manual passage-level judgments. Moreover, our evaluation is repeatable and extensible and can be scored with existing evaluation tools. Data and code at https://github.com/TREMA-UNH/rubric-evaluation/},
	booktitle = {Proceedings of the 2024 {ACM} {SIGIR} {International} {Conference} on {Theory} of {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Farzi, Naghmeh and Dietz, Laura},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {information retrieval evaluation, large language models},
	pages = {175--184},
}

@inproceedings{farinetti_chatbot_2024,
	address = {New York, NY, USA},
	series = {{ITiCSE} 2024},
	title = {Chatbot {Development} {Using} {LangChain}: {A} {Case} {Study} to {Foster} {Critical} {Thinking} and {Creativity}},
	isbn = {979-8-4007-0600-4},
	url = {https://doi.org/10.1145/3649217.3653557},
	doi = {10.1145/3649217.3653557},
	abstract = {Critical thinking and creativity are fundamental skills for engineers and computer scientists. The emergence of Large Language Models (LLMs) able to create chatbots that use natural language is an opportunity for educators to foster these skills. The well-known risk of generative AI for potential misinformation offers fertile ground to practice critical thinking.This paper describes a hands-on experience within a database course, where students had to develop a chatbot using the LangChain framework, and to evaluate it from different points of view. The students were free to choose the domain of their chatbot. The learning goal was twofold: on the one hand, to make them practice with state-of-the-art technologies, and on the other hand to stimulate critical analysis on their output. The paper discusses the students' evaluation of the chatbots under several metrics, including document retrieval, syntax and grammar accuracy, semantic relevance and information reliability. Students' assessments were also compared to the teachers' ones, to gain an insight on the critical attitude of the students and to offer a ground for discussion.The experience was stimulating and appreciated by the students. The final results highlight that the majority of students successfully produced chatbot responses that were grammatically and syntactically correct, and that consistently extracted pertinent sections from documents, yielding semantically relevant outputs. Despite these achievements, a significant portion of students expressed reservations about the reliability of the chatbot's responses to prompts, gaining awareness of LLMs' capability to generate responses that make sense to humans but may be potentially misleading.},
	booktitle = {Proceedings of the 2024 on {Innovation} and {Technology} in {Computer} {Science} {Education} {V}. 1},
	publisher = {Association for Computing Machinery},
	author = {Farinetti, Laura and Canale, Lorenzo},
	year = {2024},
	note = {event-place: Milan, Italy},
	keywords = {chatbot development, creativity and critical thinking, database education, information retrieval, langchain framework, large language models, natural language interfaces},
	pages = {401--407},
}

@inproceedings{sun_persona-l_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Persona-{L} has {Entered} the {Chat}: {Leveraging} {LLMs} and {Ability}-based {Framework} for {Personas} of {People} with {Complex} {Needs}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713445},
	doi = {10.1145/3706598.3713445},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Sun, Lipeipei and Qin, Tianzi and Hu, Anran and Zhang, Jiale and Lin, Shuojia and Chen, Jianyan and Ali, Mona and Prpa, Mirjana},
	year = {2025},
	keywords = {Ability-based Framework, Context, Persona, UX Design},
}

@inproceedings{roy_choudhury_genai_2025,
	address = {New York, NY, USA},
	series = {{ICPE} '25},
	title = {{GenAI} for bottleneck {Detection} in {Cloud} {Architecture}},
	isbn = {979-8-4007-1130-5},
	url = {https://doi.org/10.1145/3680256.3721333},
	doi = {10.1145/3680256.3721333},
	abstract = {The rapid adoption of cloud computing, accelerated by the global pandemic, has increased the need for efficient cloud architecture that balances cost and performance. As organizations migrate applications to the cloud, cloud architects face challenges in managing an overwhelming number of services—often exceeding a thousand. This paper presents a novel tool designed for editable cloud architecture management that automates the optimization process.Our solution enables cloud architects to visually design and edit cloud architectures while utilizing a backend represented as a directed acyclic graph in an adjacency matrix. This structure allows for dynamic adjustments based on real-time workload predictions, moving from reactive to proactive resource management. Leveraging advanced Generative AI models, specifically Azure's GPT-4o [11], our tool identifies alternative services that can effectively replace or supplement existing ones based on functionality. By extracting relevant data from AWS documentation, we provide actionable insights on service performance and cost.We validate our approach through use cases, demonstrating the tool's effectiveness in detecting potential bottlenecks and recommending service adjustments to eliminate Service Level Agreement (SLA) violations. Our findings indicate that the tool enhances performance and reduces operational costs, empowering cloud architects to make informed, data-driven decisions. This innovative approach significantly streamlines cloud resource management, ensuring organizations can effectively navigate the complexities of their cloud environments and achieve sustained operational excellence.},
	booktitle = {Companion of the 16th {ACM}/{SPEC} {International} {Conference} on {Performance} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Roy Choudhury, Sharod and Chahal, Dheeraj and Phalak, Chetan and Ramesh, Manju and Singhal, Rekha},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {cloud computing, cloud service optimization, editable cloud architecture, optimization},
	pages = {154--161},
}

@inproceedings{zhu_learn_2025,
	address = {New York, NY, USA},
	series = {{CUI} '25},
	title = {Learn, {Explore} and {Reflect} by {Chatting}: {Understanding} the {Value} of an {LLM}-{Based} {Voting} {Advice} {Application} {Chatbot}},
	isbn = {979-8-4007-1527-3},
	url = {https://doi.org/10.1145/3719160.3736611},
	doi = {10.1145/3719160.3736611},
	abstract = {Voting advice applications (VAAs), which have become increasingly prominent in European elections, are seen as a successful tool for boosting electorates’ political knowledge and engagement. However, VAAs’ complex language and rigid presentation constrain their utility to less-sophisticated voters. While previous work enhanced VAAs’ click-based interaction with scripted explanations, a conversational chatbot’s potential for tailored discussion and deliberate political decision-making remains untapped. Our exploratory mixed-method study investigates how LLM-based chatbots can support voting preparation. We deployed a VAA chatbot to 331 users before Germany’s 2024 European Parliament election, gathering insights from surveys, conversation logs, and 10 follow-up interviews. Participants found the VAA chatbot intuitive and informative, citing its simple language and flexible interaction. We further uncovered VAA chatbots’ role as a catalyst for reflection and rationalization. Expanding on participants’ desire for transparency, we provide design recommendations for building interactive and trustworthy VAA chatbots.},
	booktitle = {Proceedings of the 7th {ACM} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Zhu, Jianlong and Kempermann, Manon and Cannanure, Vikram Kamath and Hartland, Alexander and Navarrete, Rosa M. and Carteny, Giuseppe and Braun, Daniela and Weber, Ingmar},
	year = {2025},
	keywords = {Chatbot, Civic Education, Deliberation, Trustworthiness, Voting Advice Applications},
}

@inproceedings{menshawy_navigating_2024,
	address = {New York, NY, USA},
	series = {{EuroMLSys} '24},
	title = {Navigating {Challenges} and {Technical} {Debt} in {Large} {Language} {Models} {Deployment}},
	isbn = {979-8-4007-0541-0},
	url = {https://doi.org/10.1145/3642970.3655840},
	doi = {10.1145/3642970.3655840},
	abstract = {Large Language Models (LLMs) have become an essential tool in advancing artificial intelligence and machine learning, enabling outstanding capabilities in natural language processing, and understanding. However, the efficient deployment of LLMs in production environments reveals a complex landscape of challenges and technical debt.In this paper, we aim to highlight unique forms of challenges and technical debt associated with the deployment of LLMs, including those related to memory management, parallelism strategies, model compression, and attention optimization. These challenges emphasize the necessity of custom approaches to deploying LLMs, demanding customization and sophisticated engineering solutions not readily available in broad-use machine learning libraries or inference engines.},
	booktitle = {Proceedings of the 4th {Workshop} on {Machine} {Learning} and {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Menshawy, Ahmed and Nawaz, Zeeshan and Fahmy, Mahmoud},
	year = {2024},
	note = {event-place: Athens, Greece},
	keywords = {High-Throughput LLM Processing, Large Language Models (LLMs), LLM Deployment Challenges, LLM Model Compression and Pruning, LLMs Deployment, Scalability Challenges in LLMs Deployment, Technical Debt in AI},
	pages = {192--199},
}

@inproceedings{chen_online_2024,
	address = {New York, NY, USA},
	series = {{ICAIF} '24},
	title = {Online {Personalizing} {White}-box {LLMs} {Generation} with {Neural} {Bandits}},
	isbn = {979-8-4007-1081-0},
	url = {https://doi.org/10.1145/3677052.3698651},
	doi = {10.1145/3677052.3698651},
	abstract = {Personalized content generation by Large Language Models (LLMs) in finance presents a challenge: efficiently adapting text to individual preferences without creating unique models for each user. This study introduces an innovative online method for financial applications, employing neural bandit algorithms to dynamically optimize soft instruction embeddings based on user feedback, enhancing personalization in white-box LLMs. Through experiments on public generation tasks, we demonstrate significant performance improvements. Notably, our NeuralTS implementation achieves up to a 62.9\% improvement in ROUGE scores and a 2.76\% increase in LLM-agent evaluation for personalized content generation. This research showcases the efficacy of neural bandits in refining LLM outputs to align with client-specific needs and regulatory requirements, marking a pivotal step towards feasible and effective adaptive text generation in finance. Our method offers a promising and scalable solution for financial institutions to enhance client engagement, improve risk assessment, and streamline regulatory reporting.},
	booktitle = {Proceedings of the 5th {ACM} {International} {Conference} on {AI} in {Finance}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Zekai and Chen, Po-Yu and Buet-Golfouse, Francois},
	year = {2024},
	note = {event-place: Brooklyn, NY, USA},
	keywords = {Large language models, multi-armed bandits, personalization},
	pages = {711--718},
}

@inproceedings{yuan_designrepair_2025,
	address = {Ottawa, Ontario, Canada},
	series = {{ICSE} '25},
	title = {{DesignRepair}: {Dual}-{Stream} {Design} {Guideline}-{Aware} {Frontend} {Repair} with {Large} {Language} {Models}},
	isbn = {979-8-3315-0569-1},
	url = {https://doi.org/10.1109/ICSE55347.2025.00109},
	doi = {10.1109/ICSE55347.2025.00109},
	abstract = {The rise of Large Language Models (LLMs) has streamlined frontend interface creation through tools like Vercel's V0, yet surfaced challenges in design quality (e.g., accessibility, and usability). Current solutions, often limited by their focus, generalisability, or data dependency, fall short in addressing these complexities. Moreover, none of them examine the quality of LLM-generated UI design. In this work, we introduce DesignRepair, a novel dual-stream design guideline-aware system to examine and repair the UI design quality issues from both code aspect and rendered page aspect. We utilised the mature and popular Material Design as our knowledge base to guide this process. Specifically, we first constructed a comprehensive knowledge base encoding Google's Material Design principles into low-level component knowledge base and high-level system design knowledge base. After that, DesignRepair employs a LLM for the extraction of key components and utilizes the Playwright tool for precise page analysis, aligning these with the established knowledge bases. Finally, we integrate Retrieval-Augmented Generation with state-of-the-art LLMs like GPT-4 to holistically refine and repair frontend code through a strategic divide and conquer approach. Our extensive evaluations validated the efficacy and utility of our approach, demonstrating significant enhancements in adherence to design guidelines, accessibility, and user experience metrics.},
	booktitle = {Proceedings of the {IEEE}/{ACM} 47th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Yuan, Mingyue and Chen, Jieshan and Xing, Zhenchang and Quigley, Aaron and Luo, Yuyu and Luo, Tianqi and Mohammadi, Gelareh and Lu, Qinghua and Zhu, Liming},
	year = {2025},
	keywords = {design guideline, frontend code repair, large language models, UI design},
	pages = {2483--2494},
}

@inproceedings{anandayuvaraj_fail_2024,
	address = {New York, NY, USA},
	series = {{ASE} '24},
	title = {{FAIL}: {Analyzing} {Software} {Failures} from the {News} {Using} {LLMs}},
	isbn = {979-8-4007-1248-7},
	url = {https://doi.org/10.1145/3691620.3695022},
	doi = {10.1145/3691620.3695022},
	abstract = {Software failures inform engineering work, standards, regulations. For example, the Log4J vulnerability brought government and industry attention to evaluating and securing software supply chains. Retrospective failure analysis is thus a valuable line of software engineering research. Accessing private engineering records is difficult, so such analyses tend to use information reported by the news media. However, prior works in this direction have relied on manual analysis. That has limited the scale of their analyses. The community lacks automated support to enable such analyses to consider a wide range of news sources and incidents.To fill this gap, we propose the Failure Analysis Investigation with LLMs (FAIL) system. FAIL is a novel LLM-based pipeline that collects, analyzes, and summarizes software failures as reported in the news. FAIL groups articles that describe the same incidents. It then analyzes incidents using existing taxonomies for postmortems, faults, and system characteristics. To tune and evaluate FAIL, we followed the methods of prior works by manually analyzing 31 software failures. FAIL achieved an F1 score of 90\% for collecting news about software failures, a V-measure of 0.98 for merging articles reporting on the same incident, and extracted 90\% of the facts about failures. We then applied FAIL to a total of 137,427 news articles from 11 providers published between 2010 and 2022. FAIL identified and analyzed 2,457 distinct failures reported across 4,184 articles. Our findings include: (1) current generation of large language models are capable of identifying news articles that describe failures, and analyzing them according to structured taxonomies; (2) high recurrences of similar failures within organizations and across organizations; and (3) severity of the consequences of software failures have increased over the past decade. The full FAIL database is available so that researchers, engineers, and policymakers can learn from a diversity of software failures.},
	booktitle = {Proceedings of the 39th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Anandayuvaraj, Dharun and Campbell, Matthew and Tewari, Arav and Davis, James C},
	year = {2024},
	note = {event-place: Sacramento, CA, USA},
	keywords = {empirical software engineering, large language models, news analysis, software failure analysis},
	pages = {506--518},
}

@inproceedings{korelic_sellma_2025,
	address = {New York, NY, USA},
	series = {{EdgeSys} '25},
	title = {{SELLMA}: {Semantic} {Location} through {On}-{Device} {LLMs} and {WiFi} {Sensing}},
	isbn = {979-8-4007-1559-4},
	url = {https://doi.org/10.1145/3721888.3722091},
	doi = {10.1145/3721888.3722091},
	abstract = {Understanding a user's semantic location is of critical importance in numerous areas of mobile computing, such as mobile healthcare, mobile advertising, and mobile personal assistance. Nevertheless, inferring semantic location remains challenging and often relies on translating raw geographical coordinates via third-party online services. In this paper we introduce SELLMA, an approach for semantic location inference that harnesses Wi-Fi SSID sensing and on-device querying of a specially crafted LLM. We implement SELLMA in Android and show that it can uncover a number of environmental and geographical descriptors of a users location in a privacy-preserving manner, without the need for GPS querying, and without reliance on Web-based services.},
	booktitle = {Proceedings of the 8th {International} {Workshop} on {Edge} {Systems}, {Analytics} and {Networking}},
	publisher = {Association for Computing Machinery},
	author = {Korelič, Martin and Machidon, Octavian and Pejović, Veljko},
	year = {2025},
	note = {event-place: World Trade Center, Rotterdam, Netherlands},
	keywords = {large language models, LLM fine-tuning, location sensing, semantic location, ubiquitous computing, WiFi sensing},
	pages = {7--12},
}

@inproceedings{al_owayyed_controlled_2025,
	address = {New York, NY, USA},
	series = {{IVA} '25},
	title = {Controlled {Yet} {Natural}: {A} {Hybrid} {BDI}-{LLM} {Conversational} {Agent} for {Child} {Helpline} {Training}},
	isbn = {979-8-4007-1508-2},
	url = {https://doi.org/10.1145/3717511.3747075},
	doi = {10.1145/3717511.3747075},
	abstract = {Child helpline training often relies on human-led roleplay, which is both time- and resource-consuming. To address this, rule-based interactive agent simulations have been proposed to provide a structured training experience for new counsellors. However, these agents might suffer from limited language understanding and response variety. To overcome these limitations, we present a hybrid interactive agent that integrates Large Language Models (LLMs) into a rule-based Belief-Desire-Intention (BDI) framework, simulating more realistic virtual child chat conversations. This hybrid solution incorporates LLMs into three components: intent recognition, response generation, and a bypass mechanism. We evaluated the system through two studies: a script-based assessment comparing LLM-generated responses to human-crafted responses, and a within-subject experiment (N = 37) comparing the LLM-integrated agent with a rule-based version. The first study provided evidence that the three LLM components were non-inferior to human-crafted responses. In the second study, we found credible support for two hypotheses: participants perceived the LLM-integrated agent as more believable and reported more positive attitudes toward it than the rule-based agent. Additionally, although weaker, there was some support for increased engagement (posterior probability = 0.845, 95\% HDI [–0.149, 0.465]). Our findings demonstrate the potential of integrating LLMs into rule-based systems, offering a promising direction for more flexible but controlled training systems.},
	booktitle = {Proceedings of the 25th {ACM} {International} {Conference} on {Intelligent} {Virtual} {Agents}},
	publisher = {Association for Computing Machinery},
	author = {Al Owayyed, Mohammed and Denga, Adarsh and Brinkman, Willem-Paul},
	year = {2025},
	keywords = {Belief-Desire-Intention (BDI), Child Helpline Training, Conversational Agents, Counsellor Training, Large Language Models (LLMs), Social Skills Training, Virtual Training Simulations},
}

@inproceedings{singh_leftovers_2024,
	address = {New York, NY, USA},
	series = {{ICPE} '24},
	title = {Leftovers for {LLaMA}},
	isbn = {979-8-4007-0444-4},
	url = {https://doi.org/10.1145/3629526.3645045},
	doi = {10.1145/3629526.3645045},
	abstract = {n recent years, large language models (LLMs) have become pervasive in our day-to-day lives, with enterprises utilizing their services for a wide range of NLP-based applications. The exponential growth in the size of LLMs poses a significant challenge for efficiently utilizing these models for inference tasks, which require a substantial amount of memory and compute. Enterprises often possess multiple resources (workers, nodes, servers) with unused (leftover) capacity, providing an opportunity to address this challenge by distributing large models across these resources. Recent work such as Petals, provides a platform for distributing LLM models in a cluster of resources. Petals require that users use their discretion to distribute blocks on a given cluster, consequently leading to a non-optimal placement of blocks. In this paper, we propose LLaMPS - a large language model placement system that aims to optimize the placement of transformer blocks on the available enterprise resources, by utilizing the leftover capacity of the worker nodes. Our approach considers leftover memory capacity along with available CPU cores, when distributing transformer blocks optimally across worker nodes. Furthermore, we enhance the scalability of the system by maximizing the number of clients that can be served concurrently. We validate the efficacy of our approach by conducting extensive experiments using open-source large language models - BLOOM (1b, 3b, and 7b parameters), Falcon, and LLaMA. Our experiments demonstrate that LLaMPS facilitates optimal placement of transformer blocks by utilizing leftover resources, thus enabling enterprise-level deployment of large language models},
	booktitle = {Proceedings of the 15th {ACM}/{SPEC} {International} {Conference} on {Performance} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Singh, Ravi Kumar and Bandamudi, Likhith and Kunde, Shruti and Mishra, Mayank and Singhal, Rekha},
	year = {2024},
	note = {event-place: London, United Kingdom},
	keywords = {distributed inference, leftover capacity, llms, optimal block placement},
	pages = {201--210},
}

@inproceedings{lamas_dsl-xpert_2024,
	address = {New York, NY, USA},
	series = {{MODELS} {Companion} '24},
	title = {{DSL}-{Xpert}: {LLM}-driven {Generic} {DSL} {Code} {Generation}},
	isbn = {979-8-4007-0622-6},
	url = {https://doi.org/10.1145/3652620.3687782},
	doi = {10.1145/3652620.3687782},
	abstract = {Nowadays, large language models (LLMs) are an extremely useful and fast tool to complement and help in many jobs and current problems. However, there are cases where a pretty specific vocabulary is used in which these models were not previously trained, leading to less satisfactory results. More specifically, these models are less effective when dealing with less-known or unpublished domain-specific languages (DSLs). Within this field, the automatic generation of code based on such languages, starting from natural language, would speed up the development times of any related project, as well as the understanding of such DSLs. Therefore, this paper presents a tool in which developers can perform what is known as semantic parsing. In other words, the developer can ask a pre-trained LLM to translate a natural language instruction into the vocabulary of the established DSL. Thus, by setting the DSL grammar as context (grammar prompting) and providing usage examples (few-shot learning), the LLM can quickly generate reliable domain-specific code, significantly improving the quality of life of the developers. A video demonstration of the tool is shown in the following link: https://zenodo.org/records/12610506.},
	booktitle = {Proceedings of the {ACM}/{IEEE} 27th {International} {Conference} on {Model} {Driven} {Engineering} {Languages} and {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Lamas, Victor and R. Luaces, Miguel and Garcia-Gonzalez, Daniel},
	year = {2024},
	note = {event-place: Linz, Austria},
	keywords = {domain-specific languages (DSLS), few-shot learning, grammar prompting, large language models (LLMS), semantic parsing},
	pages = {16--20},
}

@inproceedings{prasongpongchai_talk_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Talk to the {Hand}: an {LLM}-powered {Chatbot} with {Visual} {Pointer} as {Proactive} {Companion} for {On}-{Screen} {Tasks}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3715579},
	doi = {10.1145/3706598.3715579},
	abstract = {This paper presents Pointer Assistant, a novel human-AI interaction technique for on-screen tasks. The design features a chatbot displayed as an extra mouse pointer, alongside the user’s, which proactively gives feedback on user actions while directing them to relevant areas on the screen and responding to the user’s direct chat messages. The effectiveness of the design’s key characteristics, pointer form and proactivity, was investigated in a study involving 220 participants in a financial budget planning task. Results demonstrated that the pointer design and interaction reduced task load while improving satisfaction with the experience, and increased the number of budget categories ideated during the task compared to the traditional passive chat log design. Participants viewed Pointer Assistant as a fun, innovative, and helpful visual guide while noting that its assertiveness can be improved. Future developments could offer even further enhancements to the user experience of human-AI collaboration and task outcomes.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Prasongpongchai, Thanawit and Pataranutaporn, Pat and Lertsutthiwong, Monchai and Maes, Pattie},
	year = {2025},
	keywords = {Human-AI Collaboration, Human-AI Interaction Technique, Large Language Models, Pointing Devices, Real-Time Feedback},
}

@inproceedings{chen_rarebench_2024,
	address = {New York, NY, USA},
	series = {{KDD} '24},
	title = {{RareBench}: {Can} {LLMs} {Serve} as {Rare} {Diseases} {Specialists}?},
	isbn = {979-8-4007-0490-1},
	url = {https://doi.org/10.1145/3637528.3671576},
	doi = {10.1145/3637528.3671576},
	abstract = {Generalist Large Language Models (LLMs), such as GPT-4, have shown considerable promise in various domains, including medical diagnosis. Rare diseases, affecting approximately 300 million people worldwide, often have unsatisfactory clinical diagnosis rates primarily due to a lack of experienced physicians and the complexity of differentiating among many rare diseases. In this context, recent news such as "ChatGPT correctly diagnosed a 4-year-old's rare disease after 17 doctors failed" underscore LLMs' potential, yet underexplored, role in clinically diagnosing rare diseases. To bridge this research gap, we introduce RareBench, a pioneering benchmark designed to systematically evaluate the capabilities of LLMs on 4 critical dimensions within the realm of rare diseases. Meanwhile, we have compiled the largest open-source dataset on rare disease patients, establishing a benchmark for future studies in this domain. To facilitate differential diagnosis of rare diseases, we develop a dynamic few-shot prompt methodology, leveraging a comprehensive rare disease knowledge graph synthesized from multiple knowledge bases, significantly enhancing LLMs' diagnostic performance. Moreover, we present an exhaustive comparative study of GPT-4's diagnostic capabilities against those of specialist physicians. Our experimental findings underscore the promising potential of integrating LLMs into the clinical diagnostic process for rare diseases. This paves the way for exciting possibilities in future advancements in this field.},
	booktitle = {Proceedings of the 30th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Xuanzhong and Mao, Xiaohao and Guo, Qihan and Wang, Lun and Zhang, Shuyang and Chen, Ting},
	year = {2024},
	note = {event-place: Barcelona, Spain},
	keywords = {benchmark for llms, evaluation, rare disease diagnosis},
	pages = {4850--4861},
}

@inproceedings{seo_prompt_2025,
	address = {New York, NY, USA},
	series = {{IUI} '25},
	title = {A {Prompt} {Chaining} {Framework} for {Long}-{Term} {Recall} in {LLM}-{Powered} {Intelligent} {Assistant}},
	isbn = {979-8-4007-1306-4},
	url = {https://doi.org/10.1145/3708359.3712117},
	doi = {10.1145/3708359.3712117},
	abstract = {Intelligent Assistants (IAs) often struggle with maintaining context in extended conversations, limiting their long-term recall capabilities and personalization. This study introduces a prompt chaining framework that integrates Large Language Models (LLMs) into IAs to address these issues. Our approach encompasses: (1) a formative study (N=30) analyzing IA-user interactions and identifying key challenges in long-term memory and personalization, (2) development of an LLM-based system with a novel prompt chaining mechanism for improved context retention, adaptable to various LLM architectures, and (3) implementation of a multi-step reasoning process to enhance context-aware and personalized responses. We evaluated the framework through quantitative analysis on multiple datasets, tested with different LLM backends, and conducted ablation studies to assess component contributions. The results show improvements in long-term recall, context awareness, and personalization across all tested models and datasets. A human evaluation study (N=47) indicated better Sensibleness, Consistency, and Personalization in IA response. This approach enhances IA memory capabilities and can adapt to different LLM backends.},
	booktitle = {Proceedings of the 30th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Seo, Seongbum and Yoo, Sangbong and Jang, Yun},
	year = {2025},
	keywords = {Intelligent Assistants, Large Language Models, Prompt Chaining},
	pages = {89--105},
}

@inproceedings{balog_rankers_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Rankers, {Judges}, and {Assistants}: {Towards} {Understanding} the {Interplay} of {LLMs} in {Information} {Retrieval} {Evaluation}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730348},
	doi = {10.1145/3726302.3730348},
	abstract = {Large language models (LLMs) are increasingly integral to information retrieval (IR), powering ranking, evaluation, and AI-assisted content creation. This widespread adoption necessitates a critical examination of potential biases arising from the interplay between these LLM-based components. This paper synthesizes existing research and presents novel experiment designs that explore how LLM-based rankers and assistants influence LLM-based judges. We provide the first empirical evidence of LLM judges exhibiting significant bias towards LLM-based rankers. Furthermore, we observe limitations in LLM judges' ability to discern subtle system performance differences. Contrary to some previous findings, our preliminary study does not find evidence of bias against AI-generated content. These results highlight the need for a more holistic view of the LLM-driven information ecosystem. To this end, we offer initial guidelines and a research agenda to ensure the reliable use of LLMs in IR evaluation.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Balog, Krisztian and Metzler, Don and Qin, Zhen},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {evaluation, large language models, ranking},
	pages = {3865--3875},
}

@inproceedings{goel_x-lifecycle_2024,
	address = {New York, NY, USA},
	series = {{FSE} 2024},
	title = {X-{Lifecycle} {Learning} for {Cloud} {Incident} {Management} using {LLMs}},
	isbn = {979-8-4007-0658-5},
	url = {https://doi.org/10.1145/3663529.3663861},
	doi = {10.1145/3663529.3663861},
	abstract = {Incident management for large cloud services is a complex and tedious process that requires a significant amount of manual effort from on-call engineers (OCEs). OCEs typically leverage data from different stages of the software development lifecycle [SDLC] (e.g., codes, configuration, monitor data, service properties, service dependencies, trouble-shooting documents, etc.) to generate insights for detection, root cause analysis and mitigation of incidents. Recent advancements in large language models [LLMs] (e.g., ChatGPT, GPT-4, Gemini) have created opportunities to automatically generate contextual recommendations for the OCEs, assisting them in quickly identifying and mitigating critical issues. However, existing research typically takes a silo-ed view of solving a certain task in incident management by leveraging data from a single stage of the SDLC. In this paper, we demonstrate that augmenting additional contextual data from different stages of the SDLC improves the performance of two critically important and practically challenging tasks: (1) automatically generating root cause recommendations for dependency failure related incidents, and (2) identifying the ontology of service monitors used for automatically detecting incidents. By leveraging a dataset of 353 incidents and 260 monitors from Microsoft, we demonstrate that augmenting contextual information from different stages of the SDLC improves the performance over state-of-the-art methods.},
	booktitle = {Companion {Proceedings} of the 32nd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Goel, Drishti and Husain, Fiza and Singh, Aditya and Ghosh, Supriyo and Parayil, Anjaly and Bansal, Chetan and Zhang, Xuchao and Rajmohan, Saravan},
	year = {2024},
	note = {event-place: Porto de Galinhas, Brazil},
	keywords = {Cloud Services, Large language models, Monitor management, Reliability, Root-cause analysis},
	pages = {417--428},
}

@inproceedings{quinn_longsight_2025,
	address = {New York, NY, USA},
	series = {{MICRO} '25},
	title = {{LongSight}: {Compute}-{Enabled} {Memory} to {Accelerate} {Large}-{Context} {LLMs} via {Sparse} {Attention}},
	isbn = {979-8-4007-1573-0},
	url = {https://doi.org/10.1145/3725843.3756062},
	doi = {10.1145/3725843.3756062},
	abstract = {Large input context windows in transformer-based LLMs help minimize hallucinations and improve output accuracy and personalization. However, as the context window grows, the attention phase increasingly dominates execution time. Key–Value (KV) caching alleviates part of this cost by avoiding redundant computation, but the KV cache itself can quickly exceed the capacity of today’s GPU high-bandwidth memory (HBM). In this work, we present LongSight, an algorithm–hardware co-design framework for accelerating attention in large-context scenarios. LongSight leverages a compute-enabled CXL memory device, originally designed for dense retrieval acceleration, to offload KV cache storage and retrieval. Therefore, LongSight effectively elevates the value of relatively low-cost LPDDR DRAM to that of high-end HBM. We demonstrate that, with just a single GPU and a single compute-enabled CXL memory expander, LongSight can efficiently support context lengths of up to 1 million tokens for state-of-the-art Llama models.},
	booktitle = {Proceedings of the 58th {IEEE}/{ACM} {International} {Symposium} on {Microarchitecture}},
	publisher = {Association for Computing Machinery},
	author = {Quinn, Derrick and Yücel, E. Ezgi and Kim, Jinkwon and Martínez, José F. and Alian, Mohammad},
	year = {2025},
	pages = {34--48},
}

@inproceedings{zhong_design_2024,
	address = {New York, NY, USA},
	series = {{ICDEL} '24},
	title = {The {Design} and application of {RAG}-based conversational agents for collaborative problem solving},
	isbn = {979-8-4007-1680-5},
	url = {https://doi.org/10.1145/3675812.3675871},
	doi = {10.1145/3675812.3675871},
	abstract = {Dialogue is the basis of collaborative problem solving, and the development of generative artificial intelligence has made dialogue no longer limited to human-to-human, and human-computer dialogue has gradually become an important way for people to solve problems. At the same time, with the change of the subject of collaborative problem solving, the cultivation of collaborative problem-solving skill urgently needs to explore a new path. In this regard, more and more studies have begun to apply conversational agents in collaborative problem-solving activities, digging deeper into the effects of time on students in conversational agents. However, there is no clear answer to the question of how conversational agents can be better integrated into a collaborative environment for all to assist people in the collaborative problem-solving process and improve performance. In this study, we constructed a conceptual model of human-computer collaboration in order to improve students' learning performance. Based on this model, we integrated Retrieval-Augmented Generative and GPT to construct a conversational agent, and the results of the study showed that the Retrieval-Augmented Generative Agent for Collaborative Problem Solving constructed in this study can effectively promote students' collaborative problem-solving performance.},
	booktitle = {Proceedings of the 2024 9th {International} {Conference} on {Distance} {Education} and {Learning}},
	publisher = {Association for Computing Machinery},
	author = {Zhong, Xuanyan and Xin, Haiyang and Li, Wenfeng and Zhan, Zehui and Cheng, May-hung},
	year = {2024},
	note = {event-place: Guangzhou, China},
	keywords = {Collaborative problem solving, Conversational agent, GPT},
	pages = {62--68},
}

@inproceedings{pamnani_ai-driven_2025,
	address = {New York, NY, USA},
	series = {{FAIML} '25},
	title = {{AI}-{Driven} {Automation} for {Digital} {Hardware} {Design}: {A} {Multi}-{Agent} {Generative} {Approach}},
	isbn = {979-8-4007-1321-7},
	url = {https://doi.org/10.1145/3748382.3748388},
	doi = {10.1145/3748382.3748388},
	abstract = {The increasing complexity of digital hardware design necessitates automation strategies that enhance efficiency and reduce human effort. This study introduces a novel AI-driven framework that leverages multi-agent collaboration and generative modeling to optimize the hardware design process. By integrating language models with retrieval-augmented techniques, the system autonomously generates and refines hardware description language (HDL) code, improving design accuracy and performance. Experimental evaluations on digital circuit benchmarks demonstrate the effectiveness of this approach in synthesizing functional, power-efficient designs. These findings contribute to the advancement of AI-assisted electronic design automation (EDA) and scalable hardware development.},
	booktitle = {Proceedings of the 2025 4th {International} {Conference} on {Frontiers} of {Artificial} {Intelligence} and {Machine} {Learning}},
	publisher = {Association for Computing Machinery},
	author = {Pamnani, Chintan Rajesh},
	year = {2025},
	pages = {26--30},
}

@inproceedings{shanmugarasa_sok_2025,
	address = {New York, NY, USA},
	series = {{ASIA} {CCS} '25},
	title = {{SoK}: {The} {Privacy} {Paradox} of {Large} {Language} {Models}: {Advancements}, {Privacy} {Risks}, and {Mitigation}},
	isbn = {979-8-4007-1410-8},
	url = {https://doi.org/10.1145/3708821.3733888},
	doi = {10.1145/3708821.3733888},
	abstract = {Large language models (LLMs) are sophisticated artificial intelligence systems that enable machines to generate human-like text with remarkable precision. While LLMs offer significant technological progress, their development using vast amounts of user data scraped from the web and collected from extensive user interactions poses risks of sensitive information leakage. Most existing surveys focus on the privacy implications of the training data but tend to overlook privacy risks from user interactions and advanced LLM capabilities. This paper aims to fill that gap by providing a comprehensive analysis of privacy in LLMs, categorizing the challenges into four main areas: (i) privacy issues in LLM training data, (ii) privacy challenges associated with user prompts, (iii) privacy vulnerabilities in LLM-generated outputs, and (iv) privacy challenges involving LLM agents. We evaluate the effectiveness and limitations of existing mitigation mechanisms targeting these proposed privacy challenges and identify areas for further research.},
	booktitle = {Proceedings of the 20th {ACM} {Asia} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {Association for Computing Machinery},
	author = {Shanmugarasa, Yashothara and Ding, Ming and Arachchige, Chamikara Mahawaga and Rakotoarivelo, Thierry},
	year = {2025},
	keywords = {Large Language Models, Privacy, Systematization of Knowledge},
	pages = {425--441},
}

@inproceedings{pinto_developer_2024,
	address = {New York, NY, USA},
	series = {{CAIN} '24},
	title = {Developer {Experiences} with a {Contextualized} {AI} {Coding} {Assistant}: {Usability}, {Expectations}, and {Outcomes}},
	isbn = {979-8-4007-0591-5},
	url = {https://doi.org/10.1145/3644815.3644949},
	doi = {10.1145/3644815.3644949},
	abstract = {In the rapidly advancing field of artificial intelligence, software development has emerged as a key area of innovation. Despite the plethora of general-purpose AI assistants available, their effectiveness diminishes in complex, domain-specific scenarios. Noting this limitation, both the academic community and industry players are relying on contextualized coding AI assistants. These assistants surpass general-purpose AI tools by integrating proprietary, domain-specific knowledge, offering precise and relevant solutions. Our study focuses on the initial experiences of 62 participants who used a contextualized coding AI assistant — named StackSpot AI— in a controlled setting. According to the participants, the assistants' use resulted in significant time savings, easier access to documentation, and the generation of accurate codes for internal APIs. However, challenges associated with the knowledge sources necessary to make the coding assistant access more contextual information as well as variable responses and limitations in handling complex codes were observed. The study's findings, detailing both the benefits and challenges of contextualized AI assistants, underscore their potential to revolutionize software development practices, while also highlighting areas for further refinement.},
	booktitle = {Proceedings of the {IEEE}/{ACM} 3rd {International} {Conference} on {AI} {Engineering} - {Software} {Engineering} for {AI}},
	publisher = {Association for Computing Machinery},
	author = {Pinto, Gustavo and De Souza, Cleidson and Rocha, Thayssa and Steinmacher, Igor and Souza, Alberto and Monteiro, Edward},
	year = {2024},
	note = {event-place: Lisbon, Portugal},
	keywords = {LLM, LLM-based applications, perception of productivity, user expectations},
	pages = {81--91},
}

@inproceedings{fan_litlinker_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{LitLinker}: {Supporting} the {Ideation} of {Interdisciplinary} {Contexts} with {Large} {Language} {Models} for {Teaching} {Literature} in {Elementary} {Schools}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3714111},
	doi = {10.1145/3706598.3714111},
	abstract = {Teaching literature under interdisciplinary (e.g., science, art) contexts that connect reading materials has become popular in elementary schools. However, constructing such contexts is challenging as it requires teachers to explore substantial amounts of interdisciplinary content and link it to the reading materials. In this paper, we develop LitLinker via an iterative design process involving 13 teachers to facilitate the ideation of interdisciplinary contexts for teaching literature. Powered by a large language model (LLM), LitLinker can recommend interdisciplinary topics and contextualize them with literary elements (e.g., paragraphs, viewpoints) in the reading materials. A within-subjects study (N=16) shows that compared to an LLM chatbot, LitLinker can improve the integration depth of different subjects and reduce workload in this ideation task. Expert interviews (N=9) also demonstrate LitLinker’s usefulness for supporting the ideation of interdisciplinary contexts for teaching literature. We conclude with concerns and design considerations for supporting interdisciplinary teaching with LLMs.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Fan, Haoxiang and Zhou, Changshuang and Yu, Hao and Wu, Xueyang and Gu, Jiangyu and Peng, Zhenhui},
	year = {2025},
	keywords = {elementary schools, ideation, Interdisciplinary contexts, large language models, teachers},
}

@inproceedings{wei_tar_2024,
	address = {New York, NY, USA},
	series = {{CMNM} '24},
	title = {{TAR}: {A} {Think}-{Action}-{Reflection} {Framework} for {Complex} {Problem} {Solving} with {Large} {Language} {Models}},
	isbn = {979-8-4007-0976-0},
	url = {https://doi.org/10.1145/3677779.3677825},
	doi = {10.1145/3677779.3677825},
	abstract = {In real-world user interactions, complex problems often involve multiple intents, such as retrieval, RAG (Retrieval-Augmented Generation), and generation. However, existing methods such as ReAct and COT (Chain-of-Thought) are designed for single tasks, resulting in a gap between research and practical applications. To bridge this gap, we propose a novel complex problem-solving framework called TAR (Think-Action-Reflection). The framework consists of three key stages: the Think stage conducts fine-grained, multi-dimensional analysis of the problem to form a structured problem representation; the Action stage dynamically schedules execution tools based on the output of the Think stage, flexibly adapting to the solving requirements of different problems; and the Reflection stage assesses the alignment between the outputs from the Action stage and the initial user intent, initiating iterative enhancements where necessary. To verify the effectiveness of the TAR framework, we conducted experiments on two types of datasets. Firstly, we constructed a business scenario dataset to validate the effectiveness of the proposed method in addressing real-world problems. Secondly, we evaluated the effectiveness of the Think stage using open-domain question answering datasets such as HotpotQA, TriviaQA, and Natural Questions (NQ). The results demonstrate that, compared with existing methods, the TAR framework achieves significant performance improvements across various complex problem tasks, exhibiting advantages in problem understanding, task execution, and result optimization. These findings confirm the effectiveness of the TAR framework as a paradigm for complex problem-solving in real-world user interactions.},
	booktitle = {Proceedings of the {International} {Conference} on {Modeling}, {Natural} {Language} {Processing} and {Machine} {Learning}},
	publisher = {Association for Computing Machinery},
	author = {Wei, Zizhong and Zhang, Qilai and Duan, Qiang and Wang, Guangxin and Li, Rui and Li, Xue and Chen, Qibin and Yang, Tong and Zhang, Lei and Jiang, Kai},
	year = {2024},
	note = {event-place: Xi'an, China},
	pages = {282--286},
}

@inproceedings{krishna_codellm-devkit_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {Codellm-{Devkit}: {A} {Framework} for {Contextualizing} {Code} {LLMs} with {Program} {Analysis} {Insights}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3728555},
	doi = {10.1145/3696630.3728555},
	abstract = {Large Language Models for Code (or code LLMs) are increasingly gaining popularity and capabilities, offering a wide array of functionalities such as code completion, code generation, code summarization, test generation, code translation, and more. To leverage code LLMs to their full potential, developers must provide code-specific contextual information to the models. These are typically derived and distilled using program analysis tools. However, there exists a significant gap—these static analysis tools are often language-specific and come with a steep learning curve, making their effective use challenging. These tools are tailored to specific program languages, requiring developers to learn and manage multiple tools to cover various aspects of the their code base. Moreover, the complexity of configuring and integrating these tools into the existing development environments add an additional layer of difficulty. This challenge limits the potential benefits that could be gained from more widespread and effective use of static analysis in conjunction with LLMs.To address this challenge, we present codellm-devkit (hereafter, cldk), an open-source library that significantly simplifies the process of performing program analysis at various levels of granularity for different programming languages to support code LLM use cases. As a Python library, cldk offers developers an intuitive and user-friendly interface, making it incredibly easy to provide rich program analysis context to code LLMs. With this library, developers can effortlessly integrate detailed, code-specific insights that enhance the operational efficiency and effectiveness of LLMs in coding tasks. CLDK is available as an open-source library at https://github.com/codellm-devkit.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Krishna, Rahul and Pan, Rangeet and Sinha, Saurabh and Tamilselvam, Srikanth and Pavuluri, Raju and Vukovic, Maja},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	pages = {308--318},
}

@inproceedings{abdullahi_k-paths_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {K-{Paths}: {Reasoning} over {Graph} {Paths} for {Drug} {Repurposing} and {Drug} {Interaction} {Prediction}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737011},
	doi = {10.1145/3711896.3737011},
	abstract = {Biomedical knowledge graphs (KGs) encode rich, structured information critical for drug discovery tasks, but extracting meaningful insights from large-scale KGs remains challenging due to their complex structure. Existing biomedical subgraph retrieval methods are tailored for graph neural networks (GNNs), limiting compatibility with other paradigms, including large language models (LLMs). We introduce K-Paths, a model-agnostic retrieval framework that extracts structured, diverse, and biologically meaningful multi-hop paths from dense biomedical KGs. These paths enable prediction of unobserved drug-drug and drug-disease interactions, including those involving entities not seen during training, thus supporting inductive reasoning. K-Paths is training-free and employs a diversity-aware adaptation of Yen's algorithm to extract the K shortest loopless paths between entities in a query, prioritizing biologically relevant and relationally diverse connections. These paths serve as concise, interpretable reasoning chains that can be directly integrated with LLMs or GNNs to improve generalization, accuracy, and enable explainable inference. Experiments on benchmark datasets show that K-Paths improves zero-shot reasoning across state-of-the-art LLMs. For instance, Tx-Gemma 27B improves by 19.8 and 4.0 F1 points on interaction severity prediction and drug repurposing tasks, respectively. Llama 70B achieves gains of 8.5 and 6.2 points on the same tasks. K-Paths also boosts the training efficiency of EmerGNN, a state-of-the-art GNN, by reducing the KG size by 90\% while maintaining predictive performance. Beyond efficiency, K-Paths bridges the gap between KGs and LLMs, enabling scalable and explainable LLM-augmented scientific discovery. We release our code and the retrieved paths as a benchmark for inductive reasoning.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Abdullahi, Tassallah and Gemou, Ioanna and Nayak, Nihal V. and Murtaza, Ghulam and Bach, Stephen H. and Eickhoff, Carsten and Singh, Ritambhara},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {drug discovery, explainability, gnns, inductive reasoning, knowledge graph reasoning, llms},
	pages = {5--16},
}

@inproceedings{krishna_echoswift_2024,
	address = {New York, NY, USA},
	series = {{ICPE} '24 {Companion}},
	title = {{EchoSwift}: {An} {Inference} {Benchmarking} and {Configuration} {Discovery} {Tool} for {Large} {Language} {Models} ({LLMs})},
	isbn = {979-8-4007-0445-1},
	url = {https://doi.org/10.1145/3629527.3652273},
	doi = {10.1145/3629527.3652273},
	abstract = {Large Language Models (LLMs) are advanced natural language processing models that are trained on vast amounts of text data to understand and generate human-like language. These models are designed to understand context, generate coherent and contextually relevant text, and demonstrate advanced language capabilities. In the dynamic landscape of LLMs, the demand for efficient inference benchmarking is crucial. Organizations such as TPC and SPEC brought several industry standard benchmark [1][2][3][4]. This publication introduces EchoSwift [11], a comprehensive benchmarking framework designed to evaluate the real-time performance of LLMs in deployment scenarios. As LLMs ascend to the forefront of technological innovation, their seamless integration into real-world applications demands a nuanced understanding of their efficiency, throughput, latency, and scalability. It is within this dynamic landscape that our publication unveils the EchoSwift, a novel benchmarking framework meticulously crafted to address the pressing need for comprehensive inference benchmarking, as well as the discovery of the right configuration for specific LLM requirements. For instance, certain deployments might have 32 tokens as input and 256 tokens as output, while others might have 256 tokens as input and 64 tokens as output. It is crucial to acknowledge that the configuration for these two requirements need not be the same for an optimal performance, scale and better TCO. The EchoSwift not only aids in comprehensive configuration discovery but also facilitates robust Performance/Scale testing, ensuring that LLM deployments are not only efficient but also finely tuned to their specific operational demands.},
	booktitle = {Companion of the 15th {ACM}/{SPEC} {International} {Conference} on {Performance} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Krishna, Karthik and Bandili, Ramana},
	year = {2024},
	note = {event-place: London, United Kingdom},
	keywords = {ai benchmarking, large language models, llm performance, text generation inference},
	pages = {158--162},
}

@inproceedings{yin_lies_2024,
	address = {New York, NY, USA},
	series = {{CHI} '24},
	title = {Lies, {Deceit}, and {Hallucinations}: {Player} {Perception} and {Expectations} {Regarding} {Trust} and {Deception} in {Games}},
	isbn = {979-8-4007-0330-0},
	url = {https://doi.org/10.1145/3613904.3642253},
	doi = {10.1145/3613904.3642253},
	abstract = {Lying and deception are important parts of social interaction; when applied to storytelling mediums such as video games, such elements can add complexity and intrigue. We developed a game, “AlphaBetaCity”, in which non-playable characters (NPCs) made various false statements, and used this game to investigate perceptions of deceptive behaviour. We used a mix of human-written dialogue incorporating deliberate falsehoods and LLM-written scripts with (human-approved) hallucinated responses. The degree of falsehoods varied between believable but untrue statements to outright fabrications. 29 participants played the game and were interviewed about their experiences. Participants discussed methods for developing trust and gauging NPC truthfulness. Whereas perceived intentional false statements were often attributed towards narrative and gameplay effects, seemingly unintentional false statements generally mismatched participants’ mental models and lacked inherent meaning. We discuss how the perception of intentionality, the audience demographic, and the desire for meaning are major considerations when designing video games with falsehoods.},
	booktitle = {Proceedings of the 2024 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Yin, Michael and Wang, Emi and Ng, Chuoxi and Xiao, Robert},
	year = {2024},
	note = {event-place: Honolulu, HI, USA},
	keywords = {large language models, LLM hallucinations, lying, player experience, video games},
}

@inproceedings{kan_abcm_2025,
	address = {New York, NY, USA},
	series = {{ACAIB} '25},
	title = {{ABCM}: {Agent}-{Based} {Complexity} {Management} {Method} for {Intelligent} {Manufacturing}},
	isbn = {979-8-4007-1431-3},
	url = {https://doi.org/10.1145/3760269.3760353},
	doi = {10.1145/3760269.3760353},
	abstract = {Modern intelligent manufacturing systems are inherently complex, driven by product variety, dynamic scheduling, and intricate interactions among humans, machines, and materials. This complexity presents significant challenges for production planning, control, and decision-making. To address these issues, we propose ABCM (Agent-Based Complexity Management), a novel method that integrates system dynamics simulation with a large language model (LLM)-based agent framework. ABCM utilizes PySD to simulate manufacturing processes and extract structured model outputs, which are analyzed through a suite of modular tools registered within a LangChain agent. These tools enable the computation of descriptive statistics, dynamic performance indicators, and complexity metrics—including entropy, rise time, overshoot, and integral errors—thus allowing for automated, data-driven complexity assessment. The agent autonomously interprets simulation results, identifies performance bottlenecks, and offers optimization recommendations. A case study demonstrates the practical application of ABCM in managing production variability and enhancing system responsiveness. The modular and extensible architecture supports scalable deployment in diverse intelligent manufacturing scenarios, contributing to improved adaptability, efficiency, and complexity control.},
	booktitle = {Proceedings of the 2025 5th {International} {Conference} on {Automation} {Control}, {Algorithm} and {Intelligent} {Bionics}},
	publisher = {Association for Computing Machinery},
	author = {Kan, Xuan and Dai, Yu and Shi, Jiancheng},
	year = {2025},
	keywords = {Agent-based system, Complexity metrics, Intelligent manufacturing, Manufacturing complexity, PySD, Simulation-based analysis},
	pages = {540--546},
}

@inproceedings{azher_limtopic_2025,
	address = {New York, NY, USA},
	series = {{JCDL} '24},
	title = {{LimTopic}: {LLM}-based {Topic} {Modeling} and {Text} {Summarization} for {Analyzing} {Scientific} {Articles} limitations},
	isbn = {979-8-4007-1093-3},
	url = {https://doi.org/10.1145/3677389.3702605},
	doi = {10.1145/3677389.3702605},
	abstract = {The "limitations" sections of scientific articles play a crucial role in highlighting the boundaries and shortcomings of research, thereby guiding future studies and improving research methods. Analyzing these limitations benefits researchers, reviewers, funding agencies, and the broader academic community. We introduce LimTopic, a strategy where Topic generation in Limitation sections in scientific articles with Large Language Models (LLMs). Here, each topic contains the title and `Topic Summary.' This study focuses on effectively extracting and understanding these limitations through topic modeling and text summarization, utilizing the capabilities of LLMs. We extracted limitations from research articles and applied an LLM-based topic modeling integrated with the BERtopic approach to generate a title for each topic and `Topic Sentences.' To enhance comprehension and accessibility, we employed LLM-based text summarization to create concise and generalizable summaries for each topic's Topic Sentences and produce a `Topic Summary.' Our experimentation involved prompt engineering, fine-tuning LLM and BERTopic, and integrating BERTopic with LLM to generate topics, titles, and a topic summary. We also experimented with various LLMs with BERTopic for topic modeling and various LLMs for text summarization tasks. Our results showed that the combination of BERTopic and GPT 4 performed the best in terms of silhouette and coherence scores in topic modeling, and the GPT4 summary outperformed other LLM tasks as a text summarizer. Our code and dataset are available at https://github.com/IbrahimAlAzhar/LimTopic/tree/master.},
	booktitle = {Proceedings of the 24th {ACM}/{IEEE} {Joint} {Conference} on {Digital} {Libraries}},
	publisher = {Association for Computing Machinery},
	author = {Azher, Ibrahim Al and Seethi, Venkata Devesh Reddy and Akella, Akhil Pandey and Alhoori, Hamed},
	year = {2025},
	note = {event-place: Hong Kong, China},
	keywords = {information extraction, large language models, limitations sections, research limitations, science of science},
}

@inproceedings{hu_privacy-preserved_2024,
	address = {New York, NY, USA},
	series = {{KDD} '24},
	title = {Privacy-{Preserved} {Neural} {Graph} {Databases}},
	isbn = {979-8-4007-0490-1},
	url = {https://doi.org/10.1145/3637528.3671678},
	doi = {10.1145/3637528.3671678},
	abstract = {In the era of large language models (LLMs), efficient and accurate data retrieval has become increasingly crucial for the use of domain-specific or private data in the retrieval augmented generation (RAG). Neural graph databases (NGDBs) have emerged as a powerful paradigm that combines the strengths of graph databases (GDBs) and neural networks to enable efficient storage, retrieval, and analysis of graph-structured data which can be adaptively trained with LLMs. The usage of neural embedding storage and Complex neural logical Query Answering (CQA) provides NGDBs with generalization ability. When the graph is incomplete, by extracting latent patterns and representations, neural graph databases can fill gaps in the graph structure, revealing hidden relationships and enabling accurate query answering. Nevertheless, this capability comes with inherent trade-offs, as it introduces additional privacy risks to the domain-specific or private databases. Malicious attackers can infer more sensitive information in the database using well-designed queries such as from the answer sets of where Turing Award winners born before 1950 and after 1940 lived, the living places of Turing Award winner Hinton are probably exposed, although the living places may have been deleted in the training stage due to the privacy concerns. In this work, we propose a privacy-preserved neural graph database (P-NGDB) framework to alleviate the risks of privacy leakage in NGDBs. We introduce adversarial training techniques in the training stage to enforce the NGDBs to generate indistinguishable answers when queried with private information, enhancing the difficulty of inferring sensitive information through combinations of multiple innocuous queries. Extensive experimental results on three datasets show that our framework can effectively protect private information in the graph database while delivering high-quality public answers responses to queries. The code is available at https://github.com/HKUST-KnowComp/PrivateNGDB.},
	booktitle = {Proceedings of the 30th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Hu, Qi and Li, Haoran and Bai, Jiaxin and Wang, Zihao and Song, Yangqiu},
	year = {2024},
	note = {event-place: Barcelona, Spain},
	keywords = {complex query answering (cqa), knowledge graphs (kgs), neural graph databases (ngdbs), privacy preserving},
	pages = {1108--1118},
}

@inproceedings{singh_meqa_2025,
	address = {New York, NY, USA},
	series = {{CODS}-{COMAD} '24},
	title = {{MEQA} - {A} {Multi}-modal {Interactive} {Enterprise} {Query} {Answering} {System} using {Multi}-{Agent} {LLM}},
	isbn = {979-8-4007-1124-4},
	url = {https://doi.org/10.1145/3703323.3704277},
	doi = {10.1145/3703323.3704277},
	abstract = {This paper introduces a new architecture for multi-agent systems designed to support query answering over secure enterprise data. The system uses a modular approach to natural language understanding and task execution, utilizing specialized agents for query processing. Our system features a Multi-Agent Block that consists of agents for general inquiries, Text2SQL, visualization, and information consolidation. These agents work together to handle complex queries. The Answer Generation component then integrates these results into coherent responses. We demonstrate our system’s efficiency using a complex query processed by a Text2SQL agent. In this scenario, the agent interacts with multiple endpoints, including an enterprise database and LLM endpoints, while employing techniques like RISE (Recursive Introspection for Results Improvements) and STaR (Self-Taught Reasoner) to enhance reasoning. Additionally, we use an open-source utility, LLMLingua, to compress prompts and reduce computational overhead. Our approach shows strong performance across various retrieval tasks, offering a significant step toward more intuitive and efficient data interaction, with the potential to transform how organizations utilize large language models, multiple agents, and data assets.},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Data} {Science} and {Management} of {Data} (12th {ACM} {IKDD} {CODS} and 30th {COMAD})},
	publisher = {Association for Computing Machinery},
	author = {Singh, Sonal and Gupta, Yadunath and Chowdhury, Soudip Roy},
	year = {2025},
	keywords = {A, Enterprise Q\&amp, Information retrieval, LangGraph, LLM, Multi-Agent System, Multi-Modal Gen-AI, RISE, STaR},
	pages = {422--426},
}

@inproceedings{liu_fitting_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Fitting {Into} {Any} {Shape}: {A} {Flexible} {LLM}-{Based} {Re}-{Ranker} {With} {Configurable} {Depth} and {Width}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714620},
	doi = {10.1145/3696410.3714620},
	abstract = {Large language models (LLMs) provide powerful foundations to perform fine-grained text re-ranking. However, they are often prohibitive in reality due to constraints on computation bandwidth. In this work, we propose a flexible architecture called Matroyshka Re-Ranker, which is designed to facilitate runtime customization of model layers and sequence lengths at each layer based on users' configurations. Consequently, the LLM-based re-rankers can be made applicable across various real-world situations. The increased flexibility may come at the cost of precision loss. To address this problem, we introduce a suite of techniques to optimize the performance. First, we propose cascaded self-distillation, where each sub-architecture learns to preserve a precise re-ranking performance from its super components, whose predictions can be exploited as smooth and informative teacher signals. Second, we design a factorized compensation mechanism, where two collaborative LoRA modules, vertical and horizontal, are jointly employed to compensate for the precision loss resulted from arbitrary combinations of layer and sequence compression. We perform comprehensive experiments using passage and document retrieval datasets from MSMARCO, along with all public datasets from BEIR. In our experiments, Matryoshka Re-Ranker substantially outperforms existing methods, while effectively preserving its superior performance across various compression forms and application scenarios. We have publicly released our method at this https://github.com/FlagOpen/FlagEmbedding repo.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Liu, Zheng and Li, Chaofan and Xiao, Shitao and Li, Chaozhuo and Zhang, Chen Jason and Liao, Hao and Lian, Defu and Shao, Yingxia},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {flexibility, lightweighting, llm-based re-rankers, text retrieval},
	pages = {3942--3951},
}

@inproceedings{sanchez_cuadrado_automating_2024,
	address = {New York, NY, USA},
	series = {{CUI} '24},
	title = {Automating the {Development} of {Task}-oriented {LLM}-based {Chatbots}},
	isbn = {979-8-4007-0511-3},
	url = {https://doi.org/10.1145/3640794.3665538},
	doi = {10.1145/3640794.3665538},
	abstract = {Task-oriented chatbots are increasingly used to access all sorts of services – like booking a flight, or setting a medical appointment – through natural language conversation. There are many technologies for implementing task-oriented chatbots, including Dialogflow, Watson, and Rasa. They rely on an explicit definition of the user intents, conversation flows, and chatbot outputs, which is costly to specify, and sometimes results in suboptimal user experiences and artificial conversations with limited diversity of chatbot responses. Recently, the advances in generative artificial intelligence fostered by Large Language Models (LLMs) have enabled a new range of open-domain chatbots, like ChatGPT, able to converse fluently on any topic. However, they are general-purpose, and therefore not directly usable to solve specialised tasks reliably. In this paper, we study the power of LLMs to build task-oriented chatbots, resulting in lighter specifications – no intent definition required – and more natural conversations than in intent-based approaches. To this end, we propose a lightweight domain-specific language based on YAML to specify chatbots using modules of different types (e.g., menus, question-answering, data gathering). These specifications are compiled into structured LLM prompts that use the ReAct framework to inform our runtime how to interpret the user input and coordinate the tasks that the chatbot must perform. The paper presents the design and realisation of our framework, and an assessment that encodes a set of existing intent-based chatbots using our approach, showing its benefits in terms of specification size, conversation flexibility and output diversity.},
	booktitle = {Proceedings of the 6th {ACM} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Sánchez Cuadrado, Jesús and Pérez-Soler, Sara and Guerra, Esther and De Lara, Juan},
	year = {2024},
	note = {event-place: Luxembourg, Luxembourg},
	keywords = {Domain-Specific Languages, Large Language Models, Task-oriented Chatbots},
}

@inproceedings{liu_ora_2025,
	address = {New York, NY, USA},
	series = {{ICS} '25},
	title = {{ORA}: {Job} {Runtime} {Prediction} for {High}-{Performance} {Computing} {Platforms} {Using} the {Online} {Retrieval}-{Augmented} {Language} {Model}},
	isbn = {979-8-4007-1537-2},
	url = {https://doi.org/10.1145/3721145.3725757},
	doi = {10.1145/3721145.3725757},
	abstract = {Accurate job runtime prediction is critical for efficient scheduling in high-performance computing (HPC) platforms. For instance, precise predictions enable techniques such as backfilling, where small jobs are executed ahead of schedule to maximize resource utilization and enhance computational efficiency. However, existing runtime prediction methods primarily rely on job metadata (e.g., submission time, requested runtime, and required memory) while ignoring the content of job scripts, which limits their accuracy. To address this issue, we propose an Online Retrieval-Augmented Language Model (ORA) for job runtime prediction. ORA encodes both metadata and script information from historical jobs into feature vectors to form a database, enabling similarity-based retrieval to assist in predicting the runtime of new jobs. To address distribution shifts, ORA incrementally updates the database without requiring model retraining. Additionally, personalized retrieval mechanisms are employed to mitigate the impact of distribution shifts. To reduce interference caused by repetitive content in retrieved jobs and enhance the learning of essential differences, we design a diff-based contextual learning mechanism. This highlights the differences between the current job and the retrieved jobs, improving the model’s ability to capture distinctive features. Experimental results demonstrate that the proposed method outperforms existing baselines, achieving an average accuracy improvement of over 40\% in real-world scenarios where the training and testing job times do not overlap, and the metadata does not include running information such as actual memory usage. Ablation studies further highlight the contribution of each component of the proposed method.},
	booktitle = {Proceedings of the 39th {ACM} {International} {Conference} on {Supercomputing}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Hongyi and Ma, Yinping and Huang, Xiaosong and Zhang, Lingzhe and Jia, Tong and Li, Ying},
	year = {2025},
	keywords = {LLMs, Online Learning, Retrieval-Augmented, Runtime Prediction},
	pages = {884--894},
}

@inproceedings{chi_watchwithme_2025,
	address = {New York, NY, USA},
	series = {{CUI} '25},
	title = {{WatchWithMe}: {LLM}-{Based} {Interactive} {Guided} {Watching} of {Review} {Videos}},
	isbn = {979-8-4007-1527-3},
	url = {https://doi.org/10.1145/3719160.3736624},
	doi = {10.1145/3719160.3736624},
	abstract = {Videos are a popular way for viewers to follow topics of interest. In areas such as product and technology reviews, videos often present in-depth perspectives in a compact fashion, driving viewers to look for additional explanations. We propose WatchWithMe, an automatic approach that provides viewers in-context guided watching during video playback. Powered by large language models, WatchWithMe generates guided materials from the video transcript as if creating a reading guide, including summaries, highlights, and question prompts. WatchWithMe reveals relevant information responsive to the spoken content in a review video. Viewers skim and prompt in our text-based conversational UI, to which we automatically expand the video viewing context to the model for contextual responses. We evaluated WatchWithMe with public videos and collected feedback from 20 participants. Findings showed that our method encouraged viewers to seek out viewpoints or confirmations related to the video topics.},
	booktitle = {Proceedings of the 7th {ACM} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Chi, Peggy and Hu, Senpo and Shi, Lei and Kraljic, Tanya, PhD and Secor, Justin and Dong, Tao and Essa, Irfan and Cleron, Mike},
	year = {2025},
	keywords = {interactive prompting, large language models., text-based conversational interfaces, Videos},
}

@inproceedings{einy_cost-effective_2024,
	address = {New York, NY, USA},
	series = {{GUIDE}-{AI} '24},
	title = {Cost-{Effective} {LLM} {Utilization} for {Machine} {Learning} {Tasks} over {Tabular} {Data}},
	isbn = {979-8-4007-0694-3},
	url = {https://doi.org/10.1145/3665601.3669848},
	doi = {10.1145/3665601.3669848},
	abstract = {Classic machine learning (ML) models excel in modeling tabular datasets but lack broader world knowledge due to the absence of pre-training, an area where Large Language Models (LLMs) stand out. This paper presents an effective method that bridges the gap, leveraging LLMs to enrich tabular data to enhance the performance of classical ML models. Despite the previously limited success of direct LLM application to tabular tasks due to their high computational demands, our approach selectively enriches datasets with essential world knowledge, balancing performance improvement with cost-effectiveness. This work advances the capabilities of traditional ML models and opens new avenues for research at the convergence of classical ML and LLMs, marking the onset of a new era in cost-effective data enrichment.},
	booktitle = {Proceedings of the {Conference} on {Governance}, {Understanding} and {Integration} of {Data} for {Effective} and {Responsible} {AI}},
	publisher = {Association for Computing Machinery},
	author = {Einy, Yael and Milo, Tova and Novgorodov, Slava},
	year = {2024},
	note = {event-place: Santiago, AA, Chile},
	keywords = {Data Enrichment, Data Integration, Large Language Models},
	pages = {45--49},
}

@inproceedings{sun_real-time_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {A {Real}-{Time} {Adaptive} {Multi}-{Stream} {GPU} {System} {For} {Online} {Approximate} {Nearest} {Neighborhood} {Search}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3680054},
	doi = {10.1145/3627673.3680054},
	abstract = {In recent years, Approximate Nearest Neighbor Search (ANNS) has played a pivotal role in modern search and recommendation systems, especially in emerging LLM applications like Retrieval-Augmented Generation. There is a growing exploration into harnessing the parallel computing capabilities of GPUs to meet the substantial demands of ANNS. However, existing systems primarily focus on offline scenarios, overlooking the distinct requirements of online applications that necessitate real-time insertion of new vectors. This limitation renders such systems inefficient for real-world scenarios. Moreover, previous architectures struggled to effectively support real-time insertion due to their reliance on serial execution streams. In this paper, we introduce a novel Real-Time Adaptive Multi-Stream GPU ANNS System (RTAMS-GANNS). Our architecture achieves its objectives through three key advancements: 1) We initially examined the real-time insertion mechanisms in existing GPU ANNS systems and discovered their reliance on repetitive copying and memory allocation, which significantly hinders real-time effectiveness on GPUs. As a solution, we introduce a dynamic vector insertion algorithm based on memory blocks, which includes in-place rearrangement. 2) To enable real-time vector insertion in parallel, we introduce a multi-stream parallel execution mode, which differs from existing systems that operate serially within a single stream. Our system utilizes a dynamic resource pool, allowing multiple streams to execute concurrently without additional execution blocking. 3) Through extensive experiments and comparisons, our approach effectively handles varying QPS levels across different datasets, reducing latency by up to 40\%-80\%. The proposed system has also been deployed in real-world industrial search and recommendation systems, serving hundreds of millions of users daily, and has achieved significant results.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Sun, Yiping and Shi, Yang and Du, Jiaolong},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {approximate nearest neighborhood search, gpu parallel system, multi stream gpu, real time vector insertion},
	pages = {4906--4913},
}

@inproceedings{tan_exploring_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Exploring the {Impact} of {Avatar} {Representations} in {AI} {Chatbot} {Tutors} on {Learning} {Experiences}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713456},
	doi = {10.1145/3706598.3713456},
	abstract = {Despite the growing prominence of Artificial Intelligence (AI) chatbots used in education, there remains a significant gap in our understanding of how interface design elements, particularly avatar representations, influence learning experiences. This paper explores the impact of different AI chatbot avatar representations on students’ learning experiences through a mixed-methods within-subjects study, where participants interacted with three distinct types of AI chatbot interfaces with a common large language model (LLM) over a 14-week university course. Our findings reveal that preferences vary according to factors such as learning habits and learning activities. Avatar design also exhibits affordances for specific prompting behaviors, while the perceived human touch influenced learning experiences in nuanced ways. Additionally, real-world relationships with the individuals behind deepfakes influence these experiences. These insights suggest that the thoughtful integration of diverse avatar representations in AI chatbot systems for different learners and settings can greatly enhance learning experiences.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Tan, Chek Tien and Atmosukarto, Indriyati and Tandianus, Budianto and Shen, Songjia and Wong, Steven},
	year = {2025},
	keywords = {avatars, Chatbots, conversational agents, large language models},
}

@inproceedings{he_cognify_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {Cognify: {Supercharging} {Gen}-{AI} {Workflows} {With} {Hierarchical} {Autotuning}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3736884},
	doi = {10.1145/3711896.3736884},
	abstract = {Today's gen-AI workflows that involve multiple ML model calls, tool/API calls, data retrieval, or generic code execution are often tuned manually in an ad-hoc way that is both time-consuming and error-prone. In this paper, we propose a systematic approach for automatically tuning gen-AI workflows. Our key insight is that gen-AI workflows can benefit from structure, operator, and prompt changes, but unique properties of gen-AI workflows require new optimization techniques. We propose AdaSeek, an adaptive hierarchical search algorithm for autotuning gen-AI workflows. AdaSeek organizes workflow tuning methods into different layers based on the user-specified total search budget and distributes the budget across different layers based on the complexity of each layer. During its hierarchical search, AdaSeek redistributes the search budget from less useful to more promising tuning configurations based on workflow-level evaluation results. We implement AdaSeek in a workflow autotuning framework called Cognify and evaluate Cognify using six types of workflows such as RAG-based QA and text-to-SQL transformation. Overall, Cognify improves these workflows' generation quality by up to 2.8×, reduces execution monetary cost by up to 10×, and reduces end-to-end latency by 2.7×.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {He, Zijian and Abhyankar, Reyna and Srivatsa, Vikranth and Zhang, Yiying},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {agentic workflows, bayesian optimization, gen-ai workflows, llm, optimization, test-time scaling},
	pages = {932--943},
}

@inproceedings{ganiyu_ai5gtest_2025,
	address = {New York, NY, USA},
	series = {{WiSec} 2025},
	title = {{AI5GTest}: {AI}-{Driven} {Specification}-{Aware} {Automated} {Testing} and {Validation} of {5G} {O}-{RAN} {Components}},
	isbn = {979-8-4007-1530-3},
	url = {https://doi.org/10.1145/3734477.3734703},
	doi = {10.1145/3734477.3734703},
	abstract = {The advent of Open Radio Access Networks (O-RAN) has transformed the telecommunications industry by promoting interoperability, vendor diversity, and rapid innovation. However, its disaggregated architecture introduces complex testing challenges, particularly in validating multi-vendor components against O-RAN ALLIANCE and 3GPP specifications. Existing frameworks, such as those provided by Open Testing and Integration Centres (OTICs), rely heavily on manual processes, are fragmented and prone to human error, leading to inconsistency and scalability issues. To address these limitations, we present AI5GTest – an AI-powered, specification-aware testing framework designed to automate the validation of O-RAN components. AI5GTest leverages a cooperative Large Language Models (LLM) framework consisting of Gen-LLM, Val-LLM, and Debug-LLM. Gen-LLM automatically generates expected procedural flows for test cases based on 3GPP and O-RAN specifications, while Val-LLM cross-references signaling messages against these flows to validate compliance and detect deviations. If anomalies arise, Debug-LLM performs root cause analysis, providing insight to the failure cause. To enhance transparency and trustworthiness, AI5GTest incorporates a human-in-the-loop mechanism, where the Gen-LLM presents top-k relevant official specifications to the tester for approval before proceeding with validation. Evaluated using a range of test cases obtained from O-RAN TIFG and WG5-IOT test specifications, AI5GTest demonstrates a significant reduction in overall test execution time compared to traditional manual methods, while maintaining high validation accuracy.},
	booktitle = {18th {ACM} {Conference} on {Security} and {Privacy} in {Wireless} and {Mobile} {Networks}},
	publisher = {Association for Computing Machinery},
	author = {Ganiyu, Abiodun and Gajjar, Pranshav and Shah, Vijay K},
	year = {2025},
	note = {event-place: Arlington, VA, USA},
	keywords = {3gpp, ai5gtest, automated testing, llm, o-ran},
	pages = {53--64},
}

@inproceedings{uprety_using_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Using {Large} {Language} {Models} for {Hypotheses} and {Claims} {Extraction} from {Scientific} {Literature}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3717752},
	doi = {10.1145/3701716.3717752},
	abstract = {We present a novel dataset for hypothesis and claim extraction from research papers in the interdisciplinary domain of social infertility. We use OpenAI's o1-mini reasoning LLM to create the dataset by extracting hypotheses and claims, which are then manually validated. Then we also use smaller closed and open-weight LLMs to create a benchmark for hypothesis and claim extraction.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Uprety, Sagar and Buyuklieva, Boyana and Tiwari, Prayag},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {ai for science, information extraction, llm},
	pages = {1645--1648},
}

@inproceedings{zhao_let_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Let {Me} {Do} {It} {For} {You}: {Towards} {LLM} {Empowered} {Recommendation} via {Tool} {Learning}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657828},
	doi = {10.1145/3626772.3657828},
	abstract = {Conventional recommender systems (RSs) face challenges in precisely capturing users' fine-grained preferences. Large language models (LLMs) have shown capabilities in commonsense reasoning and leveraging external tools that may help address these challenges. However, existing LLM-based RSs suffer from hallucinations, misalignment between the semantic space of items and the behavior space of users, or overly simplistic control strategies (e.g., whether to rank or directly present existing results). To bridge these gap, we introduce ToolRec, a framework for LLM-empowered recommendations via tool learning that uses LLMs as surrogate users, thereby guiding the recommendation process and invoking external tools to generate a recommendation list that aligns closely with users' nuanced preferences.We formulate the recommendation process as a process aimed at exploring user interests in attribute granularity. The process factors in the nuances of the context and user preferences. The LLM then invokes external tools based on a user's attribute instructions and probes different segments of the item pool. We consider two types of attribute-oriented tools: rank tools and retrieval tools. Through the integration of LLMs, ToolRec enables conventional recommender systems to become external tools with a natural language interface. Extensive experiments verify the effectiveness of ToolRec, particularly in scenarios that are rich in semantic content.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zhao, Yuyue and Wu, Jiancan and Wang, Xiang and Tang, Wei and Wang, Dingxian and de Rijke, Maarten},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {large language models, recommender system, tool learning},
	pages = {1796--1806},
}

@inproceedings{chiu_enhancing_2025,
	address = {New York, NY, USA},
	series = {{ICBBE} '24},
	title = {Enhancing {Medical} {Diagnosis} with {Fine}-{Tuned} {Large} {Language} {Models}: {Addressing} {Cardiogenic} {Pulmonary} {Edema} ({CPE})},
	isbn = {979-8-4007-1827-4},
	url = {https://doi.org/10.1145/3707127.3707138},
	doi = {10.1145/3707127.3707138},
	abstract = {Large Language Models (LLMs) have revolutionized natural language processing (NLP) with significant advancements in text generation. LLMs often struggle with complex domain-specific tasks, such as medical report analysis, despite their capabilities. This study focuses on enhancing LLM performance for medical applications, particularly in diagnosing and managing cardiogenic pulmonary edema (CPE). This research explores fine-tuning LLMs to develop a real-time CPE chatbot for Intensive Care Units (ICUs). The chatbot aims to provide diagnostic suggestions and explanations based on patient data. In the results, the LLaMa3-8B model performed better in predicting patients' CPE stage and keyword extraction. The accuracies achieved 72\% and 86\%.},
	booktitle = {Proceedings of the 2024 11th {International} {Conference} on {Biomedical} and {Bioinformatics} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Chiu, Yen-Jung and Chuang, Chao-Chun and Hwa, Kuo-Yuan},
	year = {2025},
	keywords = {Edema, hospital, LLM, Medical report, Natural language model},
	pages = {66--71},
}

@inproceedings{kim_fostering_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Fostering {Appropriate} {Reliance} on {Large} {Language} {Models}: {The} {Role} of {Explanations}, {Sources}, and {Inconsistencies}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3714020},
	doi = {10.1145/3706598.3714020},
	abstract = {Large language models (LLMs) can produce erroneous responses that sound fluent and convincing, raising the risk that users will rely on these responses as if they were correct. Mitigating such overreliance is a key challenge. Through a think-aloud study in which participants use an LLM-infused application to answer objective questions, we identify several features of LLM responses that shape users’ reliance: explanations (supporting details for answers), inconsistencies in explanations, and sources. Through a large-scale, pre-registered, controlled experiment (N=308), we isolate and study the effects of these features on users’ reliance, accuracy, and other measures. We find that the presence of explanations increases reliance on both correct and incorrect responses. However, we observe less reliance on incorrect responses when sources are provided or when explanations exhibit inconsistencies. We discuss the implications of these findings for fostering appropriate reliance on LLMs.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kim, Sunnie S. Y. and Vaughan, Jennifer Wortman and Liao, Q. Vera and Lombrozo, Tania and Russakovsky, Olga},
	year = {2025},
	keywords = {Explanations, Human-AI interaction, Inconsistencies, Large language models, Overreliance, Question answering, Sources},
}

@inproceedings{fu_medquery_2025,
	address = {New York, NY, USA},
	series = {{ICMR} '25},
	title = {{MedQuery}: {A} {Graph}-{Driven} {Medical} {Literature}-{Enhanced} {Query} {Answering} {System}},
	isbn = {979-8-4007-1877-9},
	url = {https://doi.org/10.1145/3731715.3733383},
	doi = {10.1145/3731715.3733383},
	abstract = {In the fields of medicine and science, the volume of specialized literature has grown exponentially, containing vast multimodal data-text, images, and tables-that is essential for conveying in-depth scientific insights. However, effectively retrieving, processing, and answering high-level, complex queries from this data remains a significant challenge. In this study, we introduce MedQuery, a multimodal medical knowledge query-answering system that integrates query-based literature retrieval with a response generation module capable of reasoning across multimodal data. Our system begins with literature retrieval from PubMed, using keyword extraction and query alignment to improve document accuracy and relevance. Next, the multimodal processing module processes source documents, extracting images, tables, and text, converting all into a unified textual format. This data is then structured into a global graph capturing relationships among document elements, allowing our system to support a more integrated, in-depth understanding of complex medical queries beyond basic fact retrieval. Extensive evaluations across multiple datasets, including PubMedQA, PubMed-Summarization, and our own MedInquiry dataset, demonstrate that MedQuery outperforms traditional methods and existing commercial AI systems, achieving around 90\% win rates in answer quality and a 13-36\% improvement in accuracy.},
	booktitle = {Proceedings of the 2025 {International} {Conference} on {Multimedia} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Fu, Chenhan and Xia, Yu and Wang, Guoming and Lu, Rongxing and Tang, Siliang},
	year = {2025},
	note = {event-place: Chicago, IL, USA},
	keywords = {graph, medical literature, multimodal, query answering, rag},
	pages = {321--329},
}

@inproceedings{pan_acknowledge_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{ACKnowledge}: {A} {Computational} {Framework} for {Human} {Compatible} {Affordance}-based {Interaction} {Planning} in {Real}-world {Contexts}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713791},
	doi = {10.1145/3706598.3713791},
	abstract = {Intelligent agents coexisting with humans often need to interact with human-shared objects in environments. Thus, agents should plan their interactions based on objects’ affordances and the current situation to achieve acceptable outcomes. How to support intelligent agents’ planning of affordance-based interactions compatible with human perception and values in real-world contexts remains under-explored. We conducted a formative study identifying the physical, intrapersonal, and interpersonal contexts that count to household human-agent interaction. We then proposed ACKnowledge, a computational framework integrating a dynamic knowledge graph, a large language model, and a vision language model for affordance-based interaction planning in dynamic human environments. In evaluations, ACKnowledge generated acceptable planning results with an understandable process. In real-world simulation tasks, ACKnowledge achieved a high execution success rate and overall acceptability, significantly enhancing usage-rights respectfulness and social appropriateness over baselines. The case study’s feedback demonstrated ACKnowledge’s negotiation and personalization capabilities toward an understandable planning process.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Pan, Ziqi and Zhang, Xiucheng and Li, Zisu and Peng, Zhenhui and Fan, Mingming and Ma, Xiaojuan},
	year = {2025},
	keywords = {Affordance-based Interaction Planning, Human Compatible, Real-world Context},
}

@inproceedings{maniar_mempal_2025,
	address = {New York, NY, USA},
	series = {{IUI} '25},
	title = {{MemPal}: {Leveraging} {Multimodal} {AI} and {LLMs} for {Voice}-{Activated} {Object} {Retrieval} in {Homes} of {Older} {Adults}},
	isbn = {979-8-4007-1306-4},
	url = {https://doi.org/10.1145/3708359.3712151},
	doi = {10.1145/3708359.3712151},
	abstract = {Older adults have increasing difficulty with retrospective memory, hindering their abilities to perform daily activities and posing stress on caregivers to ensure their wellbeing. Recent developments in Artificial Intelligence (AI) and large context-aware multimodal models offer an opportunity to create memory support systems that assist older adults with common issues like object finding. This paper discusses the development of an AI-based, wearable memory assistant, MemPal, that helps older adults with a common problem, finding lost objects at home, and presents results from tests of the system in older adults’ own homes. Using visual context from a wearable camera, the multimodal LLM system creates a real-time automated text diary of the person’s activities for memory support purposes, offering object retrieval assistance using a voice-based interface. The system is designed to support additional use cases like context-based proactive safety reminders and recall of past actions. We report on a quantitative and qualitative study with N=15 older adults within their own homes that showed improved performance of object finding with audio-based assistance compared to no aid and positive overall user perceptions on the designed system. We discuss further applications of MemPal’s design as a multi-purpose memory aid and future design guidelines to adapt memory assistants to older adults’ unique needs.},
	booktitle = {Proceedings of the 30th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Maniar, Natasha and Chan, Samantha W.T. and Zulfikar, Wazeer and Ren, Scott and Xu, Christine and Maes, Pattie},
	year = {2025},
	keywords = {context-aware agent, large language models, large visual language models, memory assistant, multimodal systems, older adults, voice interfaces, wearables},
	pages = {993--1015},
}

@inproceedings{yuan_day_2025,
	address = {New York, NY, USA},
	series = {{FAccT} '25},
	title = {A {Day} in {Their} {Shoes}: {Using} {LLM}-{Based} {Perspective}-{Taking} {Interactive} {Fiction} to {Reduce} {Stigma} {Toward} {Dirty} {Work}},
	isbn = {979-8-4007-1482-5},
	url = {https://doi.org/10.1145/3715275.3732090},
	doi = {10.1145/3715275.3732090},
	abstract = {Occupations referred to as “dirty work” often face entrenched social stigma, which adversely affects the mental health of workers in these fields and impedes occupational equity. In this study, we propose a novel Interactive Fiction (IF) framework powered by Large Language Models (LLMs) to encourage perspective-taking and reduce biases against these stigmatized yet essential roles. Through an experiment with participants (n = 100) across four such occupations, we observed a significant increase in participants’ understanding of these occupations, as well as a high level of empathy and a strong sense of connection to individuals in these roles. Additionally, qualitative interviews with participants (n = 15) revealed that the LLM-based perspective-taking IF enhanced immersion, deepened emotional resonance and empathy toward “dirty work,” and allowed participants to experience a sense of professional fulfillment in these occupations. However, participants also highlighted ongoing challenges, such as limited contextual details generated by the LLM and the unintentional reinforcement of existing stereotypes. Overall, our findings underscore that an LLM-based perspective-taking IF framework offers a promising and scalable strategy for mitigating stigma and promoting social equity in marginalized professions.},
	booktitle = {Proceedings of the 2025 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Yuan, Xiangzhe and Wang, Jiajun and Wan, Qian and Hu, Siying},
	year = {2025},
	keywords = {AI for Social Good, Dirty Work, Empathy Simulation, Fairness, Interactive Fiction (IF), Large Language Models (LLMs), Occupational Bias, Perspective-Taking, Stigma Reduction},
	pages = {1341--1359},
}

@inproceedings{alshahwan_automated_2024,
	address = {New York, NY, USA},
	series = {{FSE} 2024},
	title = {Automated {Unit} {Test} {Improvement} using {Large} {Language} {Models} at {Meta}},
	isbn = {979-8-4007-0658-5},
	url = {https://doi.org/10.1145/3663529.3663839},
	doi = {10.1145/3663529.3663839},
	abstract = {This paper describes Meta’s TestGen-LLM tool, which uses LLMs to automatically improve existing human-written tests. TestGen-LLM verifies that its generated test classes successfully clear a set of filters that assure measurable improvement over the original test suite, thereby eliminating problems due to LLM hallucination. We describe the deployment of TestGen-LLM at Meta test-a-thons for the Instagram and Facebook platforms. In an evaluation on Reels and Stories products for Instagram, 75\% of TestGen-LLM’s test cases built correctly, 57\% passed reliably, and 25\% increased coverage. During Meta’s Instagram and Facebook test-a-thons, it improved 11.5\% of all classes to which it was applied, with 73\% of its recommendations being accepted for production deployment by Meta software engineers. We believe this is the first report on industrial scale deployment of LLM-generated code backed by such assurances of code improvement.},
	booktitle = {Companion {Proceedings} of the 32nd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Alshahwan, Nadia and Chheda, Jubin and Finogenova, Anastasia and Gokkaya, Beliz and Harman, Mark and Harper, Inna and Marginean, Alexandru and Sengupta, Shubho and Wang, Eddy},
	year = {2024},
	note = {event-place: Porto de Galinhas, Brazil},
	keywords = {Automated Test Generation, Genetic Improvement, Large Language Models, LLMs, Unit Testing},
	pages = {185--196},
}

@inproceedings{ramjee_ashabot_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{ASHABot}: {An} {LLM}-{Powered} {Chatbot} to {Support} the {Informational} {Needs} of {Community} {Health} {Workers}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713680},
	doi = {10.1145/3706598.3713680},
	abstract = {Community health workers (CHWs) provide last-mile healthcare services but face challenges due to limited medical knowledge and training. This paper describes the design, deployment, and evaluation of ASHABot, an LLM-powered, experts-in-the-loop, WhatsApp-based chatbot to address the information needs of CHWs in India. Through interviews with CHWs and their supervisors and log analysis, we examine factors affecting their engagement with ASHABot, and ASHABot’s role in addressing CHWs’ informational needs. We found that ASHABot provided a private channel for CHWs to ask rudimentary and sensitive questions they hesitated to ask supervisors. CHWs trusted the information they received on ASHABot and treated it as an authoritative resource. CHWs’ supervisors expanded their knowledge by contributing answers to questions ASHABot failed to answer, but were concerned about demands on their workload and increased accountability. We emphasize positioning LLMs as supplemental fallible resources within the community healthcare ecosystem, instead of as replacements for supervisor support.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ramjee, Pragnya and Chhokar, Mehak and Sachdeva, Bhuvan and Meena, Mahendra and Abdullah, Hamid and Vashistha, Aditya and Nagar, Ruchit and Jain, Mohit},
	year = {2025},
	keywords = {ASHA, Chatbot, Experts-in-the-loop, Frontline Healthcare, GPT-4, HCI4D, India, Medical},
}

@inproceedings{zulfikar_memoro_2024,
	address = {New York, NY, USA},
	series = {{CHI} '24},
	title = {Memoro: {Using} {Large} {Language} {Models} to {Realize} a {Concise} {Interface} for {Real}-{Time} {Memory} {Augmentation}},
	isbn = {979-8-4007-0330-0},
	url = {https://doi.org/10.1145/3613904.3642450},
	doi = {10.1145/3613904.3642450},
	abstract = {People have to remember an ever-expanding volume of information. Wearables that use information capture and retrieval for memory augmentation can help but can be disruptive and cumbersome in real-world tasks, such as in social settings. To address this, we developed Memoro, a wearable audio-based memory assistant with a concise user interface. Memoro uses a large language model (LLM) to infer the user’s memory needs in a conversational context, semantically search memories, and present minimal suggestions. The assistant has two interaction modes: Query Mode for voicing queries and Queryless Mode for on-demand predictive assistance, without explicit query. Our study of (N=20) participants engaged in a real-time conversation, demonstrated that using Memoro reduced device interaction time and increased recall confidence while preserving conversational quality. We report quantitative results and discuss the preferences and experiences of users. This work contributes towards utilizing LLMs to design wearable memory augmentation systems that are minimally disruptive.},
	booktitle = {Proceedings of the 2024 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zulfikar, Wazeer Deen and Chan, Samantha and Maes, Pattie},
	year = {2024},
	note = {event-place: Honolulu, HI, USA},
	keywords = {context-aware agent, large language models, memory assistant, minimal interfaces, voice interfaces},
}

@inproceedings{dong_simulating_2025,
	address = {Richland, SC},
	series = {{AAMAS} '25},
	title = {Simulating and {Evaluating} {Generative} {Modeling} and {Collaborative} {Filtering} in {Complex} {Social} {Networks}},
	isbn = {979-8-4007-1426-9},
	abstract = {We introduce a multi-agent simulation framework for modeling large-scale online social dynamics by combining retrieval-augmented large language models, generative embedding methods, and collaborative filtering. Our approach learns diverse agent embeddings to capture varying user behaviors and employs a multi-layer perceptron for user-content ranking. We compare three strategies-(1) a generative modeling approach that integrates agent embeddings and collaborative filtering, (2) an LLM-based method grounded in historical context, and (3) a reflection-based clustering technique-and evaluate them on metrics such as comment volume, tree depth, user engagement patterns, and topic distribution. Results show that generative embeddings coupled with collaborative filtering better approximate complex phenomena like localized influencers, specialized subcommunities, and emergent echo chambers. Moreover, our framework supports policy-driven experimentation by incorporating social regularizers (cohesion, polarization, and bias) to simulate scenarios ranging from tightly knit communities to more balanced, cross-cutting interactions. By integrating large-scale data with adaptable LLM-driven agents, this work provides a versatile, data-centric foundation for simulating and analyzing online social ecosystems at scale.},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Autonomous} {Agents} and {Multiagent} {Systems}},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Dong, Wen and Mohd-Zaid, Fairul},
	year = {2025},
	note = {event-place: Detroit, MI, USA},
	keywords = {agent-based simulation, collaborative filtering, generative modeling, large language models (llms), online community behavior, social network analysis},
	pages = {639--648},
}

@inproceedings{chakraborty_empirical_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Empirical {Evaluation} of {Prompting} {Strategies} for {Fact} {Verification} {Tasks}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3717815},
	doi = {10.1145/3701716.3717815},
	abstract = {Commercial large language models (LLMs) such as GPT-3.5 have emerged as powerful tools for diverse natural language processing (NLP) tasks, yet concerns persist about their reliability in generating factual responses. This study investigates the potential of commercial LLMs such as GPT-3.5 for fact verification, addressing three key research questions: (1) Can GPT-3.5 perform fact verification reliably? (2) How do different prompting strategies affect their performance? (3) What are the common errors they make with the most effective prompt? Using the benchmark FEVER 1.0 dataset, we designed and evaluated three prompts, with experiments conducted using GPT-3.5 as a representative commercial LLM. Our experiments demonstrate that GPT-3.5 achieves a Label Accuracy (LA) of over 72\% with the best-performing prompt, significantly outperforming simpler prompts. A detailed error analysis reveals that approximately 70\% of mistakes stem from logical reasoning and contextual misunderstandings. These findings suggest that carefully crafted prompts can substantially enhance the accuracy of LLMs, in fact verification tasks, highlighting their potential as supportive tools for applications in sensitive domains.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Chakraborty, Mohna and Kulkarni, Adithya and Li, Qi},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {fact verification, large language models, prompting strategies},
	pages = {1598--1604},
}

@inproceedings{shastri_automating_2025,
	address = {San Jose, California, USA},
	series = {{AIES} '24},
	title = {Automating {Transparency} {Mechanisms} in the {Judicial} {System} {Using} {LLMs}: {Opportunities} and {Challenges}},
	abstract = {Bringing more transparency to the judicial system for the purposes of increasing accountability often demands extensive effort from auditors who must meticulously sift through numerous disorganized legal case files to detect patterns of bias and errors. For example, the high-profile investigation into the Curtis Flowers case took seven reporters a full year to assemble evidence about the prosecutor's history of selecting racially biased juries. LLMs have the potential to automate and scale these transparency pipelines, especially given their demonstrated capabilities to extract information from unstructured documents. We discuss the opportunities and challenges of using LLMs to provide transparency in two important court processes: jury selection in criminal trials and housing eviction cases.},
	booktitle = {Proceedings of the 2024 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {AAAI Press},
	author = {Shastri, Ishana and Jain, Shomik and Engelhardt, Barbara and Wilson, Ashia},
	year = {2025},
	pages = {1357--1367},
}

@inproceedings{cornacchia_between_2025,
	address = {New York, NY, USA},
	series = {{APSys} '25},
	title = {Between {Promise} and {Pain}: {The} {Reality} of {Automating} {Failure} {Analysis} in {Microservices} with {LLMs}},
	isbn = {979-8-4007-1572-3},
	url = {https://doi.org/10.1145/3725783.3764388},
	doi = {10.1145/3725783.3764388},
	abstract = {Large Language Models (LLMs) are increasingly explored as general-purpose assistants for infrastructure operations, helping automate tasks like querying data, analyzing logs, and suggesting fixes. In this paper, we consider the more general and ambitious problem of fully automating root cause analysis (RCA) in microservice systems, where LLMs must collect information, reason about it, and interact with the environment to detect, localize and resolve issues. Anecdotal evidence offers useful insights and partial solutions, but the broader challenge remains unresolved. We systematically evaluate multiple LLM agent architectures across a range of incident scenarios. We study how different tool-augmented agents perform, and shed light on common failure modes, including hallucinated reasoning paths and inefficient use of context. Our findings reveal both the promise and the limitations of current approaches, and point to concrete directions for more robust and effective use of LLMs in this domain.},
	booktitle = {Proceedings of the 16th {ACM} {SIGOPS} {Asia}-{Pacific} {Workshop} on {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Cornacchia, Alessandro and Alabdulaal, Iliyas and Saghier, Ibraheem and Mirdad, Albaraa and Fayoumi, Omar and Canini, Marco},
	year = {2025},
	note = {event-place: Lotte Hotel World, Emerald Hall, Seoul, Republic of Korea},
	keywords = {AI agents, cloud-native applications, large language models, observability, root cause analysis},
	pages = {155--167},
}

@inproceedings{basit_asci_2025,
	address = {New York, NY, USA},
	series = {{SIGCSETS} 2025},
	title = {{ASCI}: {AI}-{Smart} {Classroom} {Initiative}},
	isbn = {979-8-4007-0531-1},
	url = {https://doi.org/10.1145/3641554.3701957},
	doi = {10.1145/3641554.3701957},
	abstract = {The Artificial Intelligence Smart Classroom Initiative (ASCI) presents a re-imagined set of online course tools, designed primarily to support growing computer science classes. The system has four primary tools: an office hours queue, an automatic student grouping algorithm, a course-specific local large-language model (LLM), and administration tools for detecting students and TAs that need support. These tools interoperate to improve the quality of one another (e.g., LLM conversations support students directly in the office hours queue) and are enhanced by synchronizing data from multiple external sources such as Piazza, Gradescope, and Canvas. The system has been deployed in multiple courses over the past three semesters: initially as a FIFO queue, then supporting manual grouping and smart grouping of office hour attendees, and recently including LLM support. Preliminary results indicate that students who were grouped using the tool were more likely to return to the queue more than twice as often (on average) than those who were not. However, while grouping in office hours has the potential to decrease student wait times, teaching assistants and students tend to favor one-on-one meetings over group meetings. This might be improved in the future with updates to the software, TA training, and incorporation of other supporting tools (e.g., LLM technology). The other, newer, tools will be more thoroughly evaluated in future semesters.},
	booktitle = {Proceedings of the 56th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education} {V}. 1},
	publisher = {Association for Computing Machinery},
	author = {Basit, Nada and Floryan, Mark and Hott, John R. and Huo, Allen and Le, Jackson and Zheng, Ivan},
	year = {2025},
	note = {event-place: Pittsburgh, PA, USA},
	keywords = {computer science education, cosine similarity, group formation, office hours},
	pages = {81--87},
}

@inproceedings{venugopalan_combining_2025,
	address = {New York, NY, USA},
	series = {{LAK} '25},
	title = {Combining {Large} {Language} {Models} with {Tutoring} {System} {Intelligence}: {A} {Case} {Study} in {Caregiver} {Homework} {Support}},
	isbn = {979-8-4007-0701-8},
	url = {https://doi.org/10.1145/3706468.3706516},
	doi = {10.1145/3706468.3706516},
	abstract = {Caregivers (i.e., parents and members of a child’s caring community) are underappreciated stakeholders in learning analytics. Although caregiver involvement can enhance student academic outcomes, many obstacles hinder involvement, most notably knowledge gaps with respect to modern school curricula. An emerging topic of interest in learning analytics is hybrid tutoring, which includes instructional and motivational support. Caregivers assert similar roles in homework, yet it is unknown how learning analytics can support them. Our past work with caregivers suggested that conversational support is a promising method of providing caregivers with the guidance needed to effectively support student learning. We developed a system that provides instructional support to caregivers through conversational recommendations generated by a Large Language Model (LLM). Addressing known instructional limitations of LLMs, we use instructional intelligence from tutoring systems while conducting prompt engineering experiments with the open-source Llama 3 LLM. This LLM generated message recommendations for caregivers supporting their child’s math practice via chat. Few-shot prompting and combining real-time problem-solving context from tutoring systems with examples of tutoring practices yielded desirable message recommendations. These recommendations were evaluated with ten middle school caregivers, who valued recommendations facilitating content-level support and student metacognition through self-explanation. We contribute insights into how tutoring systems can best be merged with LLMs to support hybrid tutoring settings through conversational assistance, facilitating effective caregiver involvement in tutoring systems.},
	booktitle = {Proceedings of the 15th {International} {Learning} {Analytics} and {Knowledge} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Venugopalan, Devika and Yan, Ziwen and Borchers, Conrad and Lin, Jionghao and Aleven, Vincent},
	year = {2025},
	keywords = {caregivers, hybrid tutoring, K-12, large language models, mathematics education, tutoring systems},
	pages = {373--383},
}

@inproceedings{snyder_early_2024,
	address = {New York, NY, USA},
	series = {{KDD} '24},
	title = {On {Early} {Detection} of {Hallucinations} in {Factual} {Question} {Answering}},
	isbn = {979-8-4007-0490-1},
	url = {https://doi.org/10.1145/3637528.3671796},
	doi = {10.1145/3637528.3671796},
	abstract = {While large language models (LLMs) have taken great strides towards helping humans with a plethora of tasks, hallucinations remain a major impediment towards gaining user trust. The fluency and coherence of model generations even when hallucinating makes detection a difficult task. In this work, we explore if the artifacts associated with the model generations can provide hints that the generation will contain hallucinations. Specifically, we probe LLMs at 1) the inputs via Integrated Gradients based token attribution, 2) the outputs via the Softmax probabilities, and 3) the internal state via self-attention and fully-connected layer activations for signs of hallucinations on open-ended question answering tasks. Our results show that the distributions of these artifacts tend to differ between hallucinated and non-hallucinated generations. Building on this insight, we train binary classifiers that use these artifacts as input features to classify model generations into hallucinations and non-hallucinations. These hallucination classifiers achieve up to 0.80 AUROC. We also show that tokens preceding a hallucination can already predict the subsequent hallucination even before it occurs.},
	booktitle = {Proceedings of the 30th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Snyder, Ben and Moisescu, Marius and Zafar, Muhammad Bilal},
	year = {2024},
	note = {event-place: Barcelona, Spain},
	keywords = {LLM hallucinations, question answering},
	pages = {2721--2732},
}

@inproceedings{yang_debugging_2024,
	address = {New York, NY, USA},
	series = {{ICER} '24},
	title = {Debugging with an {AI} {Tutor}: {Investigating} {Novice} {Help}-seeking {Behaviors} and {Perceived} {Learning}},
	isbn = {979-8-4007-0475-8},
	url = {https://doi.org/10.1145/3632620.3671092},
	doi = {10.1145/3632620.3671092},
	abstract = {Debugging is a crucial skill for programmers, yet it can be challenging for novices to learn. The introduction of large language models (LLMs) has opened up new possibilities for providing personalized debugging support to students. However, concerns have been raised about potential student over-reliance on LLM-based tools. This mixed-methods study investigates how a pedagogically-designed LLM-based chatbot supports students’ debugging efforts in an introductory programming course. We conducted interviews and debugging think-aloud tasks with 20 students at three points throughout the semester. We specifically focused on characterizing when students initiate help from the chatbot during debugging, how they engage with the chatbot’s responses, and how they describe their learning experiences with the chatbot. By analyzing data from the debugging tasks, we identified varying help-seeking behaviors and levels of engagement with the chatbot’s responses, depending on students’ familiarity with the suggested strategies. Interviews revealed that students appreciated the content and experiential knowledge provided by the chatbot, but did not view it as a primary source for learning debugging strategies. Additionally, students self-identified certain chatbot usage behaviors as negative, “non-ideal” engagement and others as positive, “learning-oriented” usage. Based on our findings, we discuss pedagogical implications and future directions for designing pedagogical chatbots to support debugging.},
	booktitle = {Proceedings of the 2024 {ACM} {Conference} on {International} {Computing} {Education} {Research} - {Volume} 1},
	publisher = {Association for Computing Machinery},
	author = {Yang, Stephanie and Zhao, Hanzhang and Xu, Yudian and Brennan, Karen and Schneider, Bertrand},
	year = {2024},
	note = {event-place: Melbourne, VIC, Australia},
	keywords = {AI tutoring, debugging, help-seeking, large language models, LLMs, programming education},
	pages = {84--94},
}

@inproceedings{feng_cmdbench_2024,
	address = {New York, NY, USA},
	series = {{GUIDE}-{AI} '24},
	title = {{CMDBench}: {A} {Benchmark} for {Coarse}-to-fine {Multimodal} {Data} {Discovery} in {Compound} {AI} {Systems}},
	isbn = {979-8-4007-0694-3},
	url = {https://doi.org/10.1145/3665601.3669846},
	doi = {10.1145/3665601.3669846},
	abstract = {Compound AI systems (CASs) that employ LLMs as agents to accomplish knowledge-intensive tasks via interactions with tools and data retrievers have garnered significant interest within database and AI communities. While these systems have the potential to supplement typical analysis workflows of data analysts in enterprise data platforms, unfortunately, CASs are subject to the same data discovery challenges that analysts have encountered over the years — silos of multimodal data sources, created across teams and departments within an organization, make it difficult to identify appropriate data sources for accomplishing the task at hand. Existing data discovery benchmarks do not model such multimodality and multiplicity of data sources. Moreover, benchmarks of CASs prioritize only evaluating end-to-end task performance. To catalyze research on evaluating the data discovery performance of multimodal data retrievers in CASs within a real-world setting, we propose CMDBench, a benchmark modeling the complexity of enterprise data platforms. We adapt existing datasets and benchmarks in open-domain — from question answering and complex reasoning tasks to natural language querying over structured data — to evaluate coarse- and fine-grained data discovery and task execution performance. Our experiments reveal the impact of data retriever design on downstream task performance — 46\% drop in task accuracy on average — across various modalities, data sources, and task difficulty. The results indicate the need to develop optimization strategies to identify appropriate LLM agents and retrievers for efficient execution of CASs over enterprise data.},
	booktitle = {Proceedings of the {Conference} on {Governance}, {Understanding} and {Integration} of {Data} for {Effective} and {Responsible} {AI}},
	publisher = {Association for Computing Machinery},
	author = {Feng, Yanlin and Rahman, Sajjadur and Feng, Aaron and Chen, Vincent and Kandogan, Eser},
	year = {2024},
	note = {event-place: Santiago, AA, Chile},
	keywords = {Benchmark, Compound AI Systems., Data Discovery, LLMs},
	pages = {16--25},
}

@inproceedings{bai_leveraging_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {Leveraging {Large} {Language} {Models} for {Improving} {Keyphrase} {Generation} for {Contextual} {Targeting}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3680093},
	doi = {10.1145/3627673.3680093},
	abstract = {Generating a set of keyphrases that convey the main concepts discussed in a document has been applied to improve various applications including document retrieval and online advertising. The state-of-the-art approaches mostly rely on the neural sequence-to-sequence framework to generate keyphrases. However, training such deep neural networks either requires a significant amount of human efforts in obtaining ground truth keyphrases or suffers from lower quality training data derived from weakly supervised signals. More recently, pre-trained language models are fine-tuned to build more data-efficient keyphrase generation models. Yet, the documents often need to be truncated to adapt to the pre-trained context window. On the other hand, large language models (LLMs) have demonstrated impressive abilities in understanding very long text and generating answers for a wide range of natural language processing tasks, making them great candidates for improving keyphrase generation. There however is a lack of a systematic study on how to use LLMs, especially in an industrial setting that requires low generation latency. In this work, we present an empirical study to facilitate a more informed use of LLMs for keyphrase generation. We compare zero-shot and few-shot in-context learning with parameter efficient fine-tuning using a number of open-source LLMs. We show that using only a handful of well selected human annotated samples, the LLMs already outperform the fine-tuned language model baselines. When thousands of human labeled samples are available, fine-tuned large language models significantly improve the amount and the quality of the generated keyphrases. To enable efficient keyphrase generation at scale, we distill the knowledge from LLMs to a base-size language model. Our evaluation shows significant increase in user reach when the generated keyphrases are used for contextual targeting at Yahoo.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Bai, Xiao and Wu, Xue and Stojkovic, Ivan and Tsioutsiouliklis, Kostas},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {keyphrase generation, knowledge distillation, large language models, LLM},
	pages = {4349--4357},
}

@inproceedings{cheng_enhancing_2025,
	address = {New York, NY, USA},
	series = {{LMPL} '25},
	title = {Enhancing {Semantic} {Understanding} in {Pointer} {Analysis} using {Large} {Language} {Models}},
	isbn = {979-8-4007-2148-9},
	url = {https://doi.org/10.1145/3759425.3763393},
	doi = {10.1145/3759425.3763393},
	abstract = {Pointer analysis has been studied for over four decades. However, existing frameworks continue to suffer from the propagation of incorrect facts. A major limitation stems from their insufficient semantic understanding of code, resulting in overly conservative treatment of user-defined functions. Recent advances in large language models (LLMs) present new opportunities to bridge this gap. In this paper, we propose LMPA (LLM-enhanced Pointer Analysis), a vision that integrates LLMs into pointer analysis to enhance both precision and scalability. LMPA identifies user-definedfunctions that resemble system APIs and models them accordingly, thereby mitigating erroneous cross-calling-context propagation. Furthermore, it enhances summary-based analysis by inferring initial points-to sets and introducing a novel summary strategy augmented with natural language. Finally, we discuss the key challenges involved in realizing this vision.},
	booktitle = {Proceedings of the 1st {ACM} {SIGPLAN} {International} {Workshop} on {Language} {Models} and {Programming} {Languages}},
	publisher = {Association for Computing Machinery},
	author = {Cheng, Baijun and Wang, Kailong and Shi, Ling and Wang, Haoyu and Guo, Yao and Li, Ding and Chen, Xiangqun},
	year = {2025},
	note = {event-place: Singapore, Singapore},
	keywords = {LLM, pointer analysis, semantic understanding},
	pages = {112--117},
}

@inproceedings{yan_generative_2024,
	address = {New York, NY, USA},
	series = {{LAK} '24},
	title = {Generative {Artificial} {Intelligence} in {Learning} {Analytics}: {Contextualising} {Opportunities} and {Challenges} through the {Learning} {Analytics} {Cycle}},
	isbn = {979-8-4007-1618-8},
	url = {https://doi.org/10.1145/3636555.3636856},
	doi = {10.1145/3636555.3636856},
	abstract = {Generative artificial intelligence (GenAI), exemplified by ChatGPT, Midjourney, and other state-of-the-art large language models and diffusion models, holds significant potential for transforming education and enhancing human productivity. While the prevalence of GenAI in education has motivated numerous research initiatives, integrating these technologies within the learning analytics (LA) cycle and their implications for practical interventions remain underexplored. This paper delves into the prospective opportunities and challenges GenAI poses for advancing LA. We present a concise overview of the current GenAI landscape and contextualise its potential roles within Clow’s generic framework of the LA cycle. We posit that GenAI can play pivotal roles in analysing unstructured data, generating synthetic learner data, enriching multimodal learner interactions, advancing interactive and explanatory analytics, and facilitating personalisation and adaptive interventions. As the lines blur between learners and GenAI tools, a renewed understanding of learners is needed. Future research can delve deep into frameworks and methodologies that advocate for human-AI collaboration. The LA community can play a pivotal role in capturing data about human and AI contributions and exploring how they can collaborate most effectively. As LA advances, it is essential to consider the pedagogical implications and broader socioeconomic impact of GenAI for ensuring an inclusive future.},
	booktitle = {Proceedings of the 14th {Learning} {Analytics} and {Knowledge} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Yan, Lixiang and Martinez-Maldonado, Roberto and Gasevic, Dragan},
	year = {2024},
	note = {event-place: Kyoto, Japan},
	keywords = {ChatGPT, educational technology, generative artificial intelligence, human-AI collaboration, learning analytics, Midjourney},
	pages = {101--111},
}

@inproceedings{ujwal_reasoning_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {"{Reasoning} before {Responding}": {Towards} {Legal} {Long}-form {Question} {Answering} with {Interpretability}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3680082},
	doi = {10.1145/3627673.3680082},
	abstract = {Long-Form Question Answering (LFQA) represents a growing interest in Legal Natural Language Processing (Legal-NLP) as many individuals encounter legal disputes at some point in their lives, but lack of knowledge about how to negotiate these complex situations might put them at risk. The endeavor to generate detailed answers to contextually rich legal questions has faced challenges, primarily due to the limited availability of specialized datasets involving intensive manual effort or incapability of existing LFQA models to produce informative responses. Addressing this, our research introduces a semi-synthetic dataset, Legal-LFQA (L2FQA) created by exploiting a large language model (LLM) and utilizing contexts derived from existing legal datasets. Additionally, we hypothesize that integrating legal reasoning into the answer generation process of the LLMs will help bolster both the quality and interpretability of the produced responses. We systematically analyze the quality of L2FQA using human evaluation and natural language inference based metrics. Next, we benchmark L2FQA on a wide range of general-purpose and domain-specific LLMs using fine-tuning and in-context learning (with zero, one and few shot) strategies. The efficacy of these techniques is gauged through several automated and human evaluations. Results indicate that incorporating legal reasoning into the answer generation process provides an avenue for improving the quality of responses in the context of Legal-LFQA task. By addressing the challenges faced in LFQA and emphasizing the potential of interpretability, this research contributes to the foundational work in enhancing question-answering systems within the legal domain.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Ujwal, Utkarsh and Surampudi, Sai Sri Harsha and Mitra, Sayantan and Saha, Tulika},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {interpretability, large language models, legal domain, long-form question answering},
	pages = {4922--4930},
}

@inproceedings{upadhyay_large-scale_2025,
	address = {New York, NY, USA},
	series = {{ICTIR} '25},
	title = {A {Large}-{Scale} {Study} of {Relevance} {Assessments} with {Large} {Language} {Models} {Using} {UMBRELA}},
	isbn = {979-8-4007-1861-8},
	url = {https://doi.org/10.1145/3731120.3744605},
	doi = {10.1145/3731120.3744605},
	abstract = {There is substantial interest in applying large language models (LLMs) to provide relevance assessments in information retrieval (IR) applications from both industry and academia. To date, researchers and practitioners have presented several studies, but many questions remain. In this paper, we examine four different relevance assessment strategies: a fully manual process and three variants that rely on LLMs to different extents using our tool called UMBRELA. These were deployed in the TREC 2024 RAG Track on a diverse set of 77 runs from 19 teams in situ, which allowed us to correlate system rankings induced by the different approaches and to characterize tradeoffs between cost and quality. We find that system rankings produced by the three LLM-based strategies correlate well at the run level with those produced by fully manual assessments in terms of nDCG@20, nDCG@100, and Recall@100. On a topic-by-topic basis, the correlations are lower, and results using our setup indicate that increased human involvement does not improve correlations sufficiently to justify their costs. Our study suggests that LLMs can potentially replace fully manual judgments to measure run-level effectiveness in a coarse-grained manner.},
	booktitle = {Proceedings of the 2025 {International} {ACM} {SIGIR} {Conference} on {Innovative} {Concepts} and {Theories} in {Information} {Retrieval} ({ICTIR})},
	publisher = {Association for Computing Machinery},
	author = {Upadhyay, Shivani and Pradeep, Ronak and Thakur, Nandan and Campos, Daniel and Craswell, Nick and Soboroff, Ian and Lin, Jimmy},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {evaluation, llm judge, relevance assessment},
	pages = {358--368},
}

@inproceedings{namvarpour_art_2025,
	address = {New York, NY, USA},
	series = {{CUI} '25},
	title = {The {Art} of {Talking} {Machines}: {A} {Comprehensive} {Literature} {Review} of {Conversational} {User} {Interfaces}},
	isbn = {979-8-4007-1527-3},
	url = {https://doi.org/10.1145/3719160.3736621},
	doi = {10.1145/3719160.3736621},
	abstract = {Conversational User Interfaces (CUIs) enable human-like interactions via voice, text, and multimodal communication, driven by natural language processing and machine learning. Prior literature reviews have primarily focused on specific application domains or design aspects, lacking an integrated, multi-dimensional analysis. This study addresses this gap by providing a structured framework synthesizing CUI research into interface design, system development, and ethical considerations. Our analysis highlights advancements in CUI design, such as dialogue structure, multimodal interactions, and adaptability. It also reveals persistent challenges, including bias in persona design, trust calibration, and data privacy. System development benefits from improvements in NLP, conversation memory, and multilingual capabilities. Ethical considerations, including social bias, user autonomy, and transparency, remain central to discussions on responsible CUI design. By analyzing existing research, we identify key gaps and suggest future directions, including multilingual and culturally adaptive CUIs, privacy-preserving AI techniques, and enhanced reasoning mechanisms for context-aware interactions.},
	booktitle = {Proceedings of the 7th {ACM} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Namvarpour, Mohammad (Matt) and Razi, Afsaneh},
	year = {2025},
	keywords = {Conversational User Interfaces, CUI, Literature Review, Survey},
}

@inproceedings{hoffmann_malinowski_2025,
	address = {New York, NY, USA},
	series = {{KUI} '24},
	title = {Malinowski in the {Age} of {AI}: {Can} large language models create a text game based on an anthropological classic?},
	isbn = {979-8-4007-1032-2},
	url = {https://doi.org/10.1145/3719236.3719240},
	doi = {10.1145/3719236.3719240},
	abstract = {Recent advancements in Large Language Models (LLMs) like ChatGPT and GPT-4 have shown remarkable abilities in a wide range of tasks such as summarizing texts and assisting in coding. Scientific research has demonstrated that these models can also play text-adventure games. This study aims to explore whether LLMs can autonomously create text-based games based on anthropological classics, evaluating also their effectiveness in communicating knowledge. To achieve this, the study engaged anthropologists in discussions to gather their expectations and design inputs for an anthropologically themed game. Through iterative processes following the established HCI principle of ’design thinking’, the prompts and the conceptual framework for crafting these games were refined. Leveraging GPT3.5, the study created three prototypes of games centered around the seminal anthropological work of the social anthropologist’s Bronislaw Malinowski’s "Argonauts of the Western Pacific“ (1922). Subsequently, evaluations were conducted by inviting senior anthropologists to playtest these games, and based on their inputs, the game designs were refined. The tests revealed promising outcomes but also highlighted key challenges: the models encountered difficulties in providing in-depth thematic understandings, showed suspectibility to misinformation, tended towards monotonic responses after an extended period of play, and struggled to offer detailed biographical information. Despite these limitations, the study’s findings open up new research avenues at the crossroads of artificial intelligence, machine learning, LLMs, ethnography, anthropology and human-computer interaction.},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Culture} and {Computer} {Science}: {From} {Humanism} to {Digital} {Humanities}},
	publisher = {Association for Computing Machinery},
	author = {Hoffmann, Michael and Fillies, Jan and Paschke, Adrian},
	year = {2025},
	keywords = {Big Data, Computational Anthropology., Design Thinking, Educational Games, Machine Learning, Prompt Engineering},
}

@inproceedings{deng_next_2025,
	address = {New York, NY, USA},
	series = {{ICTIR} '25},
	title = {The {Next} {Phase} of {Scientific} {Fact}-{Checking}: {Advanced} {Evidence} {Retrieval} from {Complex} {Structured} {Academic} {Papers}},
	isbn = {979-8-4007-1861-8},
	url = {https://doi.org/10.1145/3731120.3744614},
	doi = {10.1145/3731120.3744614},
	abstract = {Scientific fact-checking aims to determine the veracity of scientific claims by retrieving and analysing evidence from research literature. The problem is inherently more complex than general fact-checking since it must accommodate the evolving nature of scientific knowledge, the structural complexity of academic literature and the challenges posed by long-form, multimodal scientific expression. However, existing approaches focus on simplified versions of the problem based on small-scale datasets consisting of abstracts rather than full papers, thereby avoiding the distinct challenges associated with processing complete documents. This paper examines the limitations of current scientific fact-checking systems and reveals the many potential features and resources that could be exploited to advance their performance. It identifies key research challenges within evidence retrieval, including (1) evidence-driven retrieval that addresses semantic limitations and topic imbalance (2) time-aware evidence retrieval with citation tracking to mitigate outdated information, (3) structured document parsing to leverage long-range context, (4) handling complex scientific expressions, including tables, figures, and domain-specific terminology and (5) assessing the credibility of scientific literature. Preliminary experiments were conducted to substantiate these challenges and identify potential solutions. This perspective paper aims to advance scientific fact-checking with a specialised IR system tailored for real-world applications.},
	booktitle = {Proceedings of the 2025 {International} {ACM} {SIGIR} {Conference} on {Innovative} {Concepts} and {Theories} in {Information} {Retrieval} ({ICTIR})},
	publisher = {Association for Computing Machinery},
	author = {Deng, Xingyu and Wang, Xi and Stevenson, Mark},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {evidence retrieval, scientific fact-checking},
	pages = {436--448},
}

@inproceedings{abdallah_arabicaqa_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {{ArabicaQA}: {A} {Comprehensive} {Dataset} for {Arabic} {Question} {Answering}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657889},
	doi = {10.1145/3626772.3657889},
	abstract = {In this paper, we address the significant gap in Arabic natural language processing (NLP) resources by introducing ArabicaQA, the first large-scale dataset for machine reading comprehension and open-domain question answering in Arabic. This comprehensive dataset, consisting of 89,095 answerable and 3,701 unanswerable questions created by crowdworkers to look similar to answerable ones, along with additional labels of open-domain questions marks a crucial advancement in Arabic NLP resources. We also present AraDPR, the first dense passage retrieval model trained on the Arabic Wikipedia corpus, specifically designed to tackle the unique challenges of Arabic text retrieval. Furthermore, our study includes extensive benchmarking of large language models (LLMs) for Arabic question answering, critically evaluating their performance in the Arabic language context. In conclusion, ArabicaQA, AraDPR, and the benchmarking of LLMs in Arabic question answering offer significant advancements in the field of Arabic NLP. The dataset and code are publicly accessible for further research https://github.com/DataScienceUIBK/ArabicaQA.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Abdallah, Abdelrahman and Kasem, Mahmoud and Abdalla, Mahmoud and Mahmoud, Mohamed and Elkasaby, Mohamed and Elbendary, Yasser and Jatowt, Adam},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {arabic question answering, information retrieval, llm, question generation},
	pages = {2049--2059},
}

@inproceedings{tian_respark_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {{ReSpark}: {Leveraging} {Previous} {Data} {Reports} as {References} to {Generate} {New} {Reports} with {LLMs}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747644},
	doi = {10.1145/3746059.3747644},
	abstract = {Creating data reports is a labor-intensive task involving iterative data exploration, insight extraction, and narrative construction. A key challenge lies in composing the analysis logic-from defining objectives and transforming data to identifying and communicating insights. Manually crafting this logic can be cognitively demanding. While experienced analysts often reuse scripts from past projects, finding a perfect match for a new dataset is rare. Even when similar analyses are available online, they usually share only results or visualizations, not the underlying code, making reuse difficult. To address this, we present ReSpark, a system that leverages large language models (LLMs) to reverse-engineer analysis logic from existing reports and adapt it to new datasets. By generating draft analysis steps, ReSpark provides a warm start for users. It also supports interactive refinement, allowing users to inspect intermediate outputs, insert objectives, and revise content. We evaluate ReSpark through comparative and user studies, demonstrating its effectiveness in lowering the barrier to generating data reports without relying on existing analysis code.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Tian, Yuan and Zhang, Chuhan and Wang, Xiaotong and Pan, Sitong and Cui, Weiwei and Zhang, Haidong and Deng, Dazhen and Wu, Yingcai},
	year = {2025},
	keywords = {Data Reports, Large Language Models, Visualization Generation},
}

@inproceedings{dhruv_leveraging_2025,
	address = {New York, NY, USA},
	series = {{PASC} '25},
	title = {Leveraging {Large} {Language} {Models} for {Code} {Translation} and {Software} {Development} in {Scientific} {Computing}},
	isbn = {979-8-4007-1886-1},
	url = {https://doi.org/10.1145/3732775.3733572},
	doi = {10.1145/3732775.3733572},
	abstract = {The emergence of foundational models and generative artificial intelligence (GenAI) is poised to transform productivity in scientific computing, especially in code development, refactoring, and translating from one programming language to another. However, because the output of GenAI cannot be guaranteed to be correct, manual intervention remains necessary. Some of this intervention can be automated through task-specific tools, alongside additional methodologies for correctness verification and effective prompt development. We explored the application of GenAI in assisting with code translation, language interoperability, and codebase inspection within a legacy Fortran codebase used to simulate particle interactions at the Large Hadron Collider (LHC). In the process, we developed a tool, CodeScribe, which combines prompt engineering with user supervision to establish an efficient process for code conversion. In this paper, we demonstrate how CodeScribe assists in converting Fortran code to C++, generating Fortran-C APIs for integrating legacy systems with modern C++ libraries, and providing developer support for code organization and algorithm implementation. We also address the challenges of AI-driven code translation and highlight its benefits for enhancing productivity in scientific computing workflows.},
	booktitle = {Proceedings of the {Platform} for {Advanced} {Scientific} {Computing} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Dhruv, Akash and Dubey, Anshu},
	year = {2025},
	note = {event-place: FHNW University of Applied Sciences and Arts Northwestern Switzerland, Brugg-Windisch, Switzerland},
	keywords = {code translation, generative artificial intelligence, language interoperability, large language models, prompt engineering, scientific computing, software development},
	pages = {1--9},
}

@inproceedings{golgoon_mechanistic_2024,
	address = {New York, NY, USA},
	series = {{ICAIF} '24},
	title = {Mechanistic interpretability of large language models with applications to the financial services industry},
	isbn = {979-8-4007-1081-0},
	url = {https://doi.org/10.1145/3677052.3698612},
	doi = {10.1145/3677052.3698612},
	abstract = {Large Language Models exhibit remarkable capabilities across a broad spectrum of applications. Nevertheless, due to their intrinsic complexity, these models present substantial challenges in interpreting their internal decision-making processes. This lack of transparency poses critical challenges when it comes to their adaptation by financial institutions, where concerns and accountability regarding bias, fairness, and reliability are of paramount importance. Mechanistic interpretability aims at reverse engineering complex AI models such as transformers. In this paper, we are pioneering the use of mechanistic interpretability to shed some light on the inner workings of large language models for use in financial services applications. We offer several examples of how algorithmic tasks can be designed for compliance monitoring purposes. In particular, we investigate GPT-2 Small’s attention pattern when prompted to identify potential violation of Fair Lending laws. Using direct logit attribution, we study the contributions of each layer and its corresponding attention heads to the logit difference in the residual stream. Finally, we design clean and corrupted prompts and use activation patching as a causal intervention method to localize our task completion components further. We observe that the (positive) heads 10.2 (head 2, layer 10), 10.7, and 11.3, as well as the (negative) heads 9.6 and 10.6 play a significant role in the task completion.},
	booktitle = {Proceedings of the 5th {ACM} {International} {Conference} on {AI} in {Finance}},
	publisher = {Association for Computing Machinery},
	author = {Golgoon, Ashkan and Filom, Khashayar and Ravi Kannan, Arjun},
	year = {2024},
	note = {event-place: Brooklyn, NY, USA},
	keywords = {FinTech, Large Language Models (LLMs), Mechanistic Interpretability, Natural Language Processing., Transformer Circuits},
	pages = {660--668},
}

@inproceedings{ren_llm-based_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{LLM}-based {Search} {Assistant} with {Holistically} {Guided} {MCTS} for {Intricate} {Information} {Seeking}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730025},
	doi = {10.1145/3726302.3730025},
	abstract = {In the era of vast digital information, the sheer volume and heterogeneity of available information present significant challenges for intricate information seeking. Users frequently face multistep web search tasks that involve navigating vast and varied data sources. This complexity demands every step remains comprehensive, accurate, and relevant. However, traditional search methods often struggle to balance the need for localized precision with the broader context required for holistic understanding, leaving critical facets of intricate queries underexplored. In this paper, we introduce an LLM-based search assistant that adopts a new information seeking paradigm with holistically guided Monte Carlo tree search (HG-MCTS). We reformulate the task as a progressive information collection process with a knowledge memory and unite an adaptive checklist with multi-perspective reward modeling in MCTS. The adaptive checklist provides explicit sub-goals to guide the MCTS process toward comprehensive coverage of complex user queries. Simultaneously, our multi-perspective reward modeling offers both exploration and retrieval rewards, along with progress feedback that tracks completed and remaining sub-goals, refining the checklist as the tree search progresses. By striking a balance between localized tree expansion and global guidance, HG-MCTS reduces redundancy in search paths and ensures that all crucial aspects of an intricate query are properly addressed. Extensive experiments on real-world intricate information seeking tasks demonstrate that HG-MCTS acquires thorough knowledge collections and delivers more accurate final responses compared with existing baselines.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Ren, Ruiyang and Wang, Yuhao and Li, Junyi and Jiang, Jinhao and Zhao, Wayne Xin and Wang, Wenjie and Chua, Tat-Seng},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {intricate information seeking, large language models, monte-carlo tree search},
	pages = {1098--1108},
}

@inproceedings{cai_rtbagent_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{RTBAgent}: {A} {LLM}-based {Agent} {System} for {Real}-{Time} {Bidding}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715259},
	doi = {10.1145/3701716.3715259},
	abstract = {Real-Time Bidding (RTB) enables advertisers to place competitive bids on impression opportunities instantaneously, striving for cost-effectiveness in a highly competitive landscape. Although RTB has widely benefited from the utilization of technologies such as deep learning and reinforcement learning, the reliability of related methods often encounters challenges due to the discrepancies between online and offline environments and the rapid fluctuations of online bidding. To handle these challenges, RTBAgent is proposed as the first RTB agent system based on large language models (LLMs), which synchronizes real competitive advertising bidding environments and obtains bidding prices through an integrated decision-making process. Specifically, obtaining reasoning ability through LLMs, RTBAgent is further tailored to be more professional for RTB via involved auxiliary modules, i.e., click-through rate estimation model, expert strategy knowledge, and daily reflection. In addition, we propose a two-step decision-making process and multi-memory retrieval mechanism, which enables RTBAgent to review historical decisions and transaction records and subsequently make decisions more adaptive to market changes in real-time bidding. Empirical testing with real advertising datasets demonstrates that RTBAgent significantly enhances profitability. The RTBAgent code will be publicly accessible at: https://github.com/CaiLeng/RTBAgent.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Cai, Leng and He, Junxuan and Li, Yikai and Liang, Junjie and Lin, Yuanping and Quan, Ziming and Zeng, Yawen and Xu, Jin},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {bid optimization, bidding agents, large language models, real-time bidding},
	pages = {104--113},
}

@inproceedings{cho_fishnet_2024,
	address = {New York, NY, USA},
	series = {{ICAIF} '24},
	title = {{FISHNET}: {Financial} {Intelligence} from {Sub}-querying, {Harmonizing}, {Neural}-{Conditioning}, {Expert} {Swarms}, and {Task} {Planning}},
	isbn = {979-8-4007-1081-0},
	url = {https://doi.org/10.1145/3677052.3698597},
	doi = {10.1145/3677052.3698597},
	abstract = {Financial intelligence generation from vast data sources has typically relied on traditional methods of knowledge-graph construction or database engineering. Recently, fine-tuned financial domain-specific Large Language Models (LLMs), have emerged. While these advancements are promising, limitations such as high inference costs, hallucinations, and the complexity of concurrently analyzing high-dimensional financial data, emerge. This motivates our invention FISHNET (Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert swarming, and Task planning), an agentic architecture that accomplishes highly complex analytical tasks for more than 98,000 regulatory filings that vary immensely in terms of semantics, data hierarchy, or format. FISHNET shows remarkable performance for financial insight generation (61.8\% success rate over 5.0\% Routing, 45.6\% RAG R-Precision). We conduct rigorous ablations to empirically prove the success of FISHNET, each agent’s importance, and the optimized performance of assembling all agents. Our modular architecture can be leveraged for a myriad of use-cases, enabling scalability, flexibility, and data integrity that are critical for financial tasks.},
	booktitle = {Proceedings of the 5th {ACM} {International} {Conference} on {AI} in {Finance}},
	publisher = {Association for Computing Machinery},
	author = {Cho, Nicole and Srishankar, Nishan and Cecchi, Lucas and Watson, William},
	year = {2024},
	note = {event-place: Brooklyn, NY, USA},
	keywords = {Harmonizing, LLM Agents, Planning, Sub-querying, Swarming},
	pages = {591--599},
}

@inproceedings{kretzer_closing_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Closing the {Loop} between {User} {Stories} and {GUI} {Prototypes}: {An} {LLM}-{Based} {Assistant} for {Cross}-{Functional} {Integration} in {Software} {Development}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713932},
	doi = {10.1145/3706598.3713932},
	abstract = {Graphical user interfaces (GUIs) are at the heart of almost every software we encounter. GUIs are often created through a collaborative effort involving UX designers, product owners, and software developers, constantly facing changing requirements. Historically, problems in GUI development include a fragmented, poorly integrated tool landscape and high synchronization efforts between stakeholders. Recent approaches suggest using large language models (LLMs) to recognize requirements fulfillment in GUIs and automatically propose new GUI components. Based on ten interviews with practitioners, this paper proposes an LLM-based assistant as a Figma plug-in that bridges the gap between user stories and GUI prototyping. We evaluated the prototype with 40 users and 40 crowd-workers, showing that the effectiveness of GUI creation is improved by using LLMs to detect requirements’ completion and generate new GUI components. We derive design rationales to support cross-functional integration in software development, ensuring that our plug-in integrates well into established processes.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kretzer, Felix and Kolthoff, Kristian and Bartelt, Christian and Ponzetto, Simone Paolo and Maedche, Alexander},
	year = {2025},
	keywords = {Assistance, GUI Prototypes, Requirements, User Stories},
}

@inproceedings{rao_xpf_2025,
	address = {New York, NY, USA},
	series = {{HPDC} '25},
	title = {{XPF}: {Agentic} {AI} {System} for {Business} {Workflow} {Automation}},
	isbn = {979-8-4007-1869-4},
	url = {https://doi.org/10.1145/3731545.3743644},
	doi = {10.1145/3731545.3743644},
	abstract = {In this paper, we propose a novel agentic AI system called XPF, which enables users to create "agents" using just natural language, where each agent is capable of executing complex, real-world business workflows in an accurate and reliable manner. XPF provides an interface to develop and iterate over the agent creation process and then deploy the agent in production when satisfactory results are produced consistently. The key components of XPF include: (a) planner, which leverages LLM to generate a step-by-step plan, which can further be edited by a human (b) compiler, which leverages LLM to compile the plan into a flow graph (c) executor, which handles distributed execution of the flow graph (using LLM, tools, RAG, etc.) on an underlying cluster and (d) verifier, which helps in verification of the output (through human generated tests or auto-generated tests using LLM). We develop five different agents using XPF and conduct experiments to evaluate one particular aspect i.e. difference in accuracy and reliability of the five agents with "human-generated" vs "auto-generated" plans. Our experiments show that we can get much more accurate and reliable response for a business workflow when step-by-step instructions (in natural language) are given by a human familiar with the workflow, rather than letting the LLM figure out the execution plan steps. In particular, we observe that "human-generated" plan almost always gives 100\% accuracy whereas "auto-generated" plan almost never gives 100\% accuracy. In terms of reliability, we observe through Rouge-L, Blue and Meteor scores, that the output from "human-generated" plan is much more reliable than "auto-generated" plan.},
	booktitle = {Proceedings of the 34th {International} {Symposium} on {High}-{Performance} {Parallel} and {Distributed} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Rao, Kunal and Coviello, Giuseppe and Mellone, Gennaro and De Vita, Ciro Giuseppe and Chakradhar, Srimat},
	year = {2025},
	note = {event-place: University of Notre Dame Conference Facilities, Notre Dame, IN, USA},
	keywords = {agents, generative artificial intelligence (GenAI), large language models (LLM), runtimes, tools},
}

@inproceedings{santana_responsible_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Responsible {Prompting} {Recommendation}: {Fostering} {Responsible} {AI} {Practices} in {Prompting}-{Time}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713365},
	doi = {10.1145/3706598.3713365},
	abstract = {Human-Computer Interaction practitioners have been proposing best practices in user interface design for decades. However, generative Artificial Intelligence (GenAI) brings additional design considerations and currently lacks sufficient user guidance regarding affordances, inputs, and outputs. In this context, we developed a recommender system to promote responsible AI (RAI) practices while people prompt GenAI systems. We detail 10 interviews with IT professionals, the resulting recommender system developed, and 20 user sessions with IT professionals interacting with our prompt recommendations. Results indicate that responsible prompting recommendations have the potential to support novice prompt engineers and raise awareness about RAI in prompting-time. They also suggest that recommendations should simultaneously maximize both a prompt’s similarity to a user’s input as well as a diversity of associated social values provided. These findings contribute to RAI by offering practical ways to provide user guidance and enrich human-GenAI interaction via prompt recommendations.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Santana, Vagner Figueredo de and Berger, Sara E and Candello, Heloisa and Machado, Tiago and Sanctos, Cassia Sampaio and Su, Tianyu and Williams, Lemara},
	year = {2025},
	keywords = {Human-AI Interaction, Proactive Value Alignment, Prompt Engineering, Recommender Systems, Responsible AI, Responsible Computing, Responsible Prompting},
}

@inproceedings{xu_ckgfuzzer_2025,
	address = {Ottawa, Ontario, Canada},
	series = {{ICSE} '25},
	title = {{CKGFuzzer}: {LLM}-{Based} {Fuzz} {Driver} {Generation} {Enhanced} {By} {Code} {Knowledge} {Graph}},
	isbn = {979-8-3315-3683-1},
	url = {https://doi.org/10.1109/ICSE-Companion66252.2025.00079},
	doi = {10.1109/ICSE-Companion66252.2025.00079},
	abstract = {In recent years, the programming capabilities of large language models (LLMs) have garnered significant attention. Fuzz testing, a highly effective technique, plays a key role in enhancing software reliability and detecting vulnerabilities. However, traditional fuzz testing tools rely on manually crafted fuzz drivers, which can limit both testing efficiency and effectiveness. To address this challenge, we propose an automated fuzz testing method driven by a code knowledge graph and powered by an LLM-based intelligent agent system, referred to as CKGFuzzer. We approach fuzz driver creation as a code generation task, leveraging the knowledge graph of the code repository to automate the generation process within the fuzzing loop, while continuously refining both the fuzz driver and input seeds. The code knowledge graph is constructed through interprocedural program analysis, where each node in the graph represents a code entity, such as a function or a file. The knowledge graph-enhanced CKGFuzzer not only effectively resolves compilation errors in fuzz drivers and generates input seeds tailored to specific API usage scenarios, but also analyzes fuzz driver crash reports, assisting developers in improving code quality. By querying the knowledge graph of the code repository and learning from API usage scenarios, we can better identify testing targets and understand the specific purpose of each fuzz driver. We evaluated our approach using eight open-source software projects. The experimental results indicate that CKGFuzzer achieved an average improvement of 8.73\% in code coverage compared to state-of-the-art techniques. Additionally, CKGFuzzer reduced the manual review workload in crash case analysis by 84.4\% and successfully detected 11 real bugs (including nine previously unreported bugs) across the tested libraries. Our research enhances the overall performance of fuzz testing by refining fuzz driver generation strategies and input seed analysis, offering a more effective solution for vulnerability remediation and software quality improvement.},
	booktitle = {Proceedings of the {IEEE}/{ACM} 47th {International} {Conference} on {Software} {Engineering}: {Companion} {Proceedings}},
	publisher = {IEEE Press},
	author = {Xu, Hanxiang and Ma, Wei and Zhou, Ting and Zhao, Yanjie and Chen, Kai and Hu, Qiang and Liu, Yang and Wang, Haoyu},
	year = {2025},
	pages = {243--254},
}

@inproceedings{ashktorab_evalassist_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {{EvalAssist}: {Insights} on {Task}-{Specific} {Evaluations} and {AI}-{Assisted} {Judgment} {Strategy} {Preferences}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747740},
	doi = {10.1145/3746059.3747740},
	abstract = {With the broad availability of large language models and their ability to generate vast outputs using varied prompts and configurations, determining the best output for a given task requires an intensive evaluation process, one where machine learning practitioners must decide how to assess the outputs and then carefully carry out the evaluation. This process is both time-consuming and costly. As practitioners work with an increasing number of models, they must now evaluate outputs to determine which model performs best for a given task. LLMs are increasingly used as evaluators to filter training data, evaluate model performance or assist human evaluators with detailed assessments. Our application, EvalAssist, supports this process by aiding users in interactively refining evaluation criteria. In our study with machine learning practitioners (n=15), each completing 6 tasks yielding 131 evaluations, we explore how task-related factors and judgment strategies influence criteria refinement and user perceptions. Findings show that users performed more evaluations with direct assessment by making criteria task-specific, modifying judgments, and changing the AI evaluator model. We conclude with recommendations for how systems can better support practitioners with AI-assisted evaluations.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Ashktorab, Zahra and Desmond, Michael and Pan, Qian and Johnson, James M. and Santillán Cooper, Martin and Daly, Elizabeth M. and Nair, Rahul and Pedapati, Tejaswini and Do, Hyo Jin and Geyer, Werner},
	year = {2025},
}

@inproceedings{xie_tree-enhanced_2025,
	address = {New York, NY, USA},
	series = {{SECA} '25},
	title = {A {Tree}-{Enhanced} {Multi}-{Agent} {Question} {Answering} {System} for {Enterprise}-{Specific} {Financial} {Knowledge} {Based} on {Dynamic} {Search}},
	isbn = {979-8-4007-1513-6},
	url = {https://doi.org/10.1145/3747912.3747952},
	doi = {10.1145/3747912.3747952},
	abstract = {Question answering tasks in the financial futures are usually complex. It requires complex semantic parsing and dynamic optimization. To solve this issue, in this paper, we propose an enhanced question-answering system based on dynamic multi-agent search trees. In the system, we construct a hierarchical tree based on dynamic search using a multi-agent collaborative method. We integrated semantic association networks based on financial knowledge graphs. In this way, we automatically decomposed the complex queries. The key technical breakthroughs made in this paper include the following. Firstly, we build a task-planning algorithm based on multi-agent interaction. This enables dynamic expansion and pruning of search tree nodes, which manages the decomposition of domain-specific complex problems. Secondly, we established a financial knowledge graph with 150 core entities and 290 types of dynamic relationships. Using RDF triples and a semantic rule engine, it precisely expands domain terminologies and enhances cross-modal retrieval. Thirdly, we constructed a security-controlled automated framework design. This design uses a tool invocation-execution feedback loop and a hierarchical summarization mechanism (BM25 retrieval + context compression). In this way, it can reduce long-text processing time and ensure data permission control. According to the experiments, the system can answer specialized questions in different tasks, such as treasury futures trend analysis. It also supports fully automated reasoning and can be traced throughout the process. In this research, we provide an innovative solution for intelligent question-answering systems in financial futures. This method combines dynamic adaptability, domain expertise, and security reliability.},
	booktitle = {Proceedings of the 2025 {International} {Conference} on {Software} {Engineering} and {Computer} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Xie, Mingxi and Lin, Yuefeng and Wang, Yike},
	year = {2025},
	keywords = {Automated framework, Dynamic search tree, Financial knowledge graph, Intelligent question-answering system, Multi-agent collaboration},
	pages = {255--260},
}

@inproceedings{mayfield_evaluation_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {On the {Evaluation} of {Machine}-{Generated} {Reports}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657846},
	doi = {10.1145/3626772.3657846},
	abstract = {Large Language Models (LLMs) have enabled new ways to satisfy information needs. Although great strides have been made in applying them to settings like document ranking and short-form text generation, they still struggle to compose complete, accurate, and verifiable long-form reports. Reports with these qualities are necessary to satisfy the complex, nuanced, or multi-faceted information needs of users. In this perspective paper, we draw together opinions from industry and academia, and from a variety of related research areas, to present our vision for automatic report generation, and—critically—a flexible framework by which such reports can be evaluated. In contrast with other summarization tasks, automatic report generation starts with a detailed description of an information need, stating the necessary background, requirements, and scope of the report. Further, the generated reports should be complete, accurate, and verifiable. These qualities, which are desirable—if not required—in many analytic report-writing settings, require rethinking how to build and evaluate systems that exhibit these qualities. To foster new efforts in building these systems, we present an evaluation framework that draws on ideas found in various evaluations. To test completeness and accuracy, the framework uses nuggets of information, expressed as questions and answers, that need to be part of any high-quality generated report. Additionally, evaluation of citations that map claims made in the report to their source documents ensures verifiability.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Mayfield, James and Yang, Eugene and Lawrie, Dawn and MacAvaney, Sean and McNamee, Paul and Oard, Douglas W. and Soldaini, Luca and Soboroff, Ian and Weller, Orion and Kayi, Efsun and Sanders, Kate and Mason, Marc and Hibbler, Noah},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {evaluation, factual citation, report generation, text analysis},
	pages = {1904--1915},
}

@inproceedings{han_event_2024,
	address = {New York, NY, USA},
	series = {{MM} '24},
	title = {Event {Traffic} {Forecasting} with {Sparse} {Multimodal} {Data}},
	isbn = {979-8-4007-0686-8},
	url = {https://doi.org/10.1145/3664647.3680706},
	doi = {10.1145/3664647.3680706},
	abstract = {With the development of deep learning, traffic forecasting technology has made significant progress and is being applied in many practical scenarios. However, various events held in cities, such as sporting events, exhibitions, concerts, etc., have a significant impact on traffic patterns of surrounding areas, causing current advanced prediction models to fail in this case. In this paper, to broaden the applicable scenarios of traffic forecasting, we focus on modeling the impact of events on traffic patterns and propose an event traffic forecasting problem with multimodal inputs. We outline the main challenges of this problem: diversity and sparsity of events, as well as insufficient data. To address these issues, we first use textual modal data containing rich semantics to describe the diverse characteristics of events. Then, we propose a simple yet effective multi-modal event traffic forecasting model that uses pre-trained text and traffic encoders to extract the embeddings and fuses the two embeddings for prediction. Encoders pre-trained on large-scale data have powerful generalization abilities to cope with the challenge of sparse data. Next, we design an efficient large language model-based event description text generation pipeline to build multi-modal event traffic forecasting datasets, ShenzhenCEC and SuzhouIEC. Experiments on two real-world datasets show that our method achieves state-of-the-art performance compared with eight baselines, reducing mean absolute error during the event peak period by 4.26\%. Code is available at: https://github.com/2448845600/EventTrafficForecasting.},
	booktitle = {Proceedings of the 32nd {ACM} {International} {Conference} on {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Han, Xiao and Zhang, Zhenduo and Wu, Yiling and Zhang, Xinfeng and Wu, Zhe},
	year = {2024},
	note = {event-place: Melbourne VIC, Australia},
	keywords = {dataset, event traffic forecasting, multimodal fusion, time-series and language},
	pages = {8855--8864},
}

@inproceedings{kobiella_when_2025,
	address = {New York, NY, USA},
	series = {{CUI} '25},
	title = {When {AI} {Joins} the {Negotiation} {Table}: {Evaluating} {AI} as a {Moderator}},
	isbn = {979-8-4007-1527-3},
	url = {https://doi.org/10.1145/3719160.3736630},
	doi = {10.1145/3719160.3736630},
	abstract = {Negotiation is a crucial decision-making process where parties seek to resolve differences and optimize outcomes. While prior research has focused on maximizing negotiation outcomes, fostering a collaborative atmosphere is essential for long-term relationship-building. This study explores the role of AI-assisted moderation in negotiations that emulate high-stress environments. We developed a text-based AI moderator and evaluated its usability and effectiveness in a two-phase study: a pilot study with 14 participants followed by a final user study with 16 participants. To provide an initial point of comparison, we assessed trust, respect, and equitability in AI-moderated versus non-moderated negotiations. Quantitative findings indicate a negative effect of AI-assisted moderation on relationship-building, while qualitative insights suggest that AI moderation fosters collaboration. However, the cognitive load of text-based facilitation hinders its effectiveness. These results highlight the importance of seamless AI integration and contribute to the broader discourse on AI’s role in behavior change and mediated communication.},
	booktitle = {Proceedings of the 7th {ACM} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Kobiella, Charlotte and Isroilov, Ulugbek and Schmidt, Albrecht},
	year = {2025},
	keywords = {AI agents, equitability, negotiation, respect, trust},
}

@inproceedings{dudy_unequal_2025,
	address = {New York, NY, USA},
	series = {{IUI} '25},
	title = {Unequal {Opportunities}: {Examining} the {Bias} in {Geographical} {Recommendations} by {Large} {Language} {Models}},
	isbn = {979-8-4007-1306-4},
	url = {https://doi.org/10.1145/3708359.3712111},
	doi = {10.1145/3708359.3712111},
	abstract = {Recent advancements in Large Language Models (LLMs) have made them a popular information-seeking tool among end users. However, the statistical training methods for LLMs have raised concerns about their representation of under-represented topics, potentially leading to biases that could influence real-world decisions and opportunities. These biases could have significant economic, social, and cultural impacts as LLMs become more prevalent, whether through direct interactions—such as when users engage with chatbots or automated assistants—or through their integration into third-party applications (as agents), where the models influence decision-making processes and functionalities behind the scenes. Our study examines the biases present in LLMs recommendations of U.S. cities and towns across three domains: relocation, tourism, and starting a business. We explore two key research questions: (i) How similar LLM responses are, and (ii) How this similarity might favor areas with certain characteristics over others, introducing biases. We focus on the consistency of LLM responses and their tendency to over-represent or under-represent specific locations. Our findings point to consistent demographic biases in these recommendations, which could perpetuate a “rich-get-richer” effect that widens existing economic disparities.},
	booktitle = {Proceedings of the 30th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Dudy, Shiran and Tholeti, Thulasi and Ramachandranpillai, Resmi and Ali, Muhammad and Li, Toby Jia-Jun and Baeza-Yates, Ricardo},
	year = {2025},
	keywords = {Cultural representation, geographical divide, LLM auditing., LLM biases, under-represented topics},
	pages = {1499--1516},
}

@inproceedings{jiang_peatmoss_2024,
	address = {New York, NY, USA},
	series = {{MSR} '24},
	title = {{PeaTMOSS}: {A} {Dataset} and {Initial} {Analysis} of {Pre}-{Trained} {Models} in {Open}-{Source} {Software}},
	isbn = {979-8-4007-0587-8},
	url = {https://doi.org/10.1145/3643991.3644907},
	doi = {10.1145/3643991.3644907},
	abstract = {The development and training of deep learning models have become increasingly costly and complex. Consequently, software engineers are adopting pre-trained models (PTMs) for their downstream applications. The dynamics of the PTM supply chain remain largely unexplored, signaling a clear need for structured datasets that document not only the metadata but also the subsequent applications of these models. Without such data, the MSR community cannot comprehensively understand the impact of PTM adoption and reuse.This paper presents the PeaTMOSS dataset, which comprises metadata for 281,638 PTMs and detailed snapshots for all PTMs with over 50 monthly downloads (14,296 PTMs), along with 28,575 open-source software repositories from GitHub that utilize these models. Additionally, the dataset includes 44,337 mappings from 15,129 downstream GitHub repositories to the 2,530 PTMs they use. To enhance the dataset's comprehensiveness, we developed prompts for a large language model to automatically extract model metadata, including the model's training datasets, parameters, and evaluation metrics. Our analysis of this dataset provides the first summary statistics for the PTM supply chain, showing the trend of PTM development and common shortcomings of PTM package documentation. Our example application reveals inconsistencies in software licenses across PTMs and their dependent projects. PeaTMOSS lays the foundation for future research, offering rich opportunities to investigate the PTM supply chain. We outline mining opportunities on PTMs, their downstream usage, and cross-cutting questions.Our artifact is available at https://github.com/PurdueDualityLab/PeaTMOSS-Artifact. Our dataset is available at https://transfer.rcac.purdue.edu/file-manager?origin\_id=ff978999-16c2-4b50-ac7a-947ffdc3eb1d\&amp;origin\_path=\%2F.},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {Association for Computing Machinery},
	author = {Jiang, Wenxin and Yasmin, Jerin and Jones, Jason and Synovic, Nicholas and Kuo, Jiashen and Bielanski, Nathaniel and Tian, Yuan and Thiruvathukal, George K. and Davis, James C.},
	year = {2024},
	note = {event-place: Lisbon, Portugal},
	keywords = {datasets, deep neural networks, empirical software engineering, machine learning, model zoos, open-source, package registries},
	pages = {431--443},
}

@inproceedings{hoveyda_adaptive_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Adaptive {Orchestration} of {Modular} {Generative} {Information} {Access} {Systems}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730351},
	doi = {10.1145/3726302.3730351},
	abstract = {Advancements in large language models (LLMs) have driven the emergence of complex new systems to provide access to information, that we will collectively refer to as modular generative information access (GenIA) systems. They integrate a broad and evolving range of specialized components, including LLMs, retrieval models, and a heterogeneous set of sources and tools. While modularity offers flexibility, it also raises critical challenges: How can we systematically characterize the space of possible modules and their interactions? How can we automate and optimize interactions among these heterogeneous components? And, how do we enable this modular system to dynamically adapt to varying user query requirements and evolving module capabilities? In this perspective paper, we argue that the architecture of future modular generative information access systems will not just assemble powerful components, but enable a self-organizing system through real-time adaptive orchestration - where components' interactions are dynamically configured for each user input, maximizing information relevance while minimizing computational overhead. We give provisional answers to the questions raised above with a roadmap that depicts the key principles and methods for designing such an adaptive modular system. We identify pressing challenges, and propose avenues for addressing them in the years ahead. This perspective urges the IR community to rethink modular system designs for developing adaptive, self-optimizing, and future-ready architectures that evolve alongside their rapidly advancing underlying technologies.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Hoveyda, Mohanna and Oosterhuis, Harrie and de Vries, Arjen P. and de Rijke, Maarten and Hasibi, Faegheh},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {adaptive information systems, graph-based orchestration},
	pages = {3899--3910},
}

@inproceedings{burgueno_human_2024,
	address = {New York, NY, USA},
	series = {{MODELS} {Companion} '24},
	title = {A {Human} {Behavior} {Exploration} {Approach} {Using} {LLMs} for {Cyber}-{Physical} {Systems}},
	isbn = {979-8-4007-0622-6},
	url = {https://doi.org/10.1145/3652620.3687806},
	doi = {10.1145/3652620.3687806},
	abstract = {In the early phases of Cyber-Physical Systems (CPS) development, scoping human behavior plays a significant role, especially when interactions extend beyond expected behavior. Here, it is especially challenging to develop cases that capture the full spectrum of human behavior. Up to now, identifying such behavior of humans remains a task for domain experts. We explore how one can use Large Languages Models (LLMs) in the design phase of systems to provide additional information about human-CPS interaction. Our approach proposes a preliminary ontology describing a hierarchy of types of behavior and relevant CPS components as input for prompt templates. It uses them to generate parts of human behavior descriptions, as well as a canned prompt with one variable about behavior. For demonstration, we take a smart building with a Home Energy System as the use case.An initial user evaluation shows that the behavior descriptions generated with standard and ontology-driven prompts complement each other and are useful when assisting humans. The discovered uncommon behaviors can be used to complete interaction scenarios that eventually result in a more robust CPS implementation.},
	booktitle = {Proceedings of the {ACM}/{IEEE} 27th {International} {Conference} on {Model} {Driven} {Engineering} {Languages} and {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Burgueño, Lola and Keet, Maria and Kienzle, Jörg and Michael, Judith and Babur, Önder},
	year = {2024},
	note = {event-place: Linz, Austria},
	keywords = {cyber-physical systems, digital twin, human behavior, large language models, user scenario},
	pages = {578--586},
}

@inproceedings{laban_lexi_2024,
	address = {New York, NY, USA},
	series = {{HAI} '24},
	title = {{LEXI}: {Large} {Language} {Models} {Experimentation} {Interface}},
	isbn = {979-8-4007-1178-7},
	url = {https://doi.org/10.1145/3687272.3688296},
	doi = {10.1145/3687272.3688296},
	abstract = {The recent developments in Large Language Models (LLMs) mark a significant moment in the research and development of social interactions with artificial agents. These agents are widely deployed in a variety of settings, with potential impact on users. However, the study of social interactions with agents powered by LLMs is still emerging, limited by access to the technology and to data, the absence of standardised interfaces, and challenges to establishing controlled experimental setups using the currently available platforms. To address these gaps, we developed LEXI, LLMs Experimentation Interface, an open-source tool for deploying artificial agents powered by LLMs in social interaction behavioural experiments. Using a graphical interface, LEXI allows researchers to build agents and deploy them in experimental setups along with forms for collecting self-reported data while collecting interaction logs. The outcomes of usability testing indicate LEXI’s broad utility, high usability, and minimal mental workload requirement, with benefits observed across disciplines. A proof-of-concept study exploring the tool’s efficacy in evaluating social human–agent interactions was conducted, resulting in high-quality data. A comparison of empathetic versus neutral agents indicated that people perceive empathetic agents as more social, and write longer and more positive messages towards them.},
	booktitle = {Proceedings of the 12th {International} {Conference} on {Human}-{Agent} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Laban, Guy and Laban, Tomer and Gunes, Hatice},
	year = {2024},
	note = {event-place: Swansea, United Kingdom},
	keywords = {Behavioural Experimentation, Human–Agent Interaction, Large Language Models, LLM, Open-Source, Usability Testing},
	pages = {250--259},
}

@inproceedings{fan_towards_2025,
	address = {New York, NY, USA},
	series = {{AICCC} '24},
	title = {Towards {Resilient} and {Efficient} {LLMs}: {A} {Comparative} {Study} of {Efficiency}, {Performance}, and {Adversarial} {Robustness}},
	isbn = {979-8-4007-1792-5},
	url = {https://doi.org/10.1145/3719384.3719447},
	doi = {10.1145/3719384.3719447},
	abstract = {With the increasing demand for practical applications of Large Language Models (LLMs), many attention-efficient models have been developed to balance performance and computational cost. However, the adversarial robustness of these models remains under-explored. In this work, we design a framework to investigate the trade-off between efficiency, performance, and adversarial robustness of LLMs and conduct extensive experiments on three prominent models with varying levels of complexity and efficiency – Transformer++, Gated Linear Attention (GLA) Transformer, and MatMul-Free LM – utilizing the GLUE and AdvGLUE datasets. The AdvGLUE dataset extends the GLUE dataset with adversarial samples designed to challenge model robustness. Our results show that while the GLA Transformer and MatMul-Free LM achieve slightly lower accuracy on GLUE tasks, they demonstrate higher efficiency and either superior or comparative robustness on AdvGLUE tasks compared to Transformer++ across different attack levels. These findings highlight the potential of simplified architectures to achieve a compelling balance between efficiency, performance, and adversarial robustness, offering valuable insights for applications where resource constraints and resilience to adversarial attacks are critical.},
	booktitle = {Proceedings of the 2024 7th {Artificial} {Intelligence} and {Cloud} {Computing} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Fan, Xiaojing and Tao, Chunliang},
	year = {2025},
	keywords = {Adversarial Attacks, Computational Efficiency, Large Language Models, Robustness},
	pages = {429--436},
}

@inproceedings{gao_social_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Social {Context}-{Aware} {Community}-{Level} {Propagation} {Prediction}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730085},
	doi = {10.1145/3726302.3730085},
	abstract = {With the increasing prevalence of online communities, social networks have become pivotal platforms for information propagation. However, this rise is accompanied by issues such as the spread of misinformation and online rumors. Community Level Information Pathway Prediction (CLIPP) is proposed to effectively stop the propagation of harmful information within specific communities. While progress has been made in understanding user-level propagation, there is a significant gap in addressing the CLIPP problem at the community level, particularly with regard to social context interpretation and the cold start problem in niche communities. To bridge this gap, we propose a novel model, named Community-Level Propagation Prediction with LLM enhanced Social Context Interpretation and Community Coldstart (ComPaSC3), which integrates three primary modules. The video enhancement module leverages LLMs to enrich the interpretation of multimedia content by embedding world knowledge. The community portrait building module utilizes LLMs to generate detailed community portraits for community interpretation. To tackle the community cold start problem, the dynamic commLink module links non-popular communities to the popular ones based on their portrait similarity, and dynamically updates their relationship weights. Our experimental results demonstrate that ComPaSC3 significantly improves predictive accuracy in both popular and non-popular scenarios. Particularly in non-popular communities, our approach outperforms existing state-of-the-art methods, achieving improvements of 10.00\% - 15.20\% in Rec@5 and 7.31\% - 12.32\% in NDCG@10.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Gao, Jinfei and Wang, Xiao and Gan, Tian and Yin, Jianhua and Luo, Chuanchen and Nie, Liqiang},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {community portrait, graph neural networks, information diffusion, information pathway, llm},
	pages = {1995--2005},
}

@inproceedings{zhao_knoll_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {Knoll: {Creating} a {Knowledge} {Ecosystem} for {Large} {Language} {Models}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747711},
	doi = {10.1145/3746059.3747711},
	abstract = {Large language models are designed to encode general purpose knowledge about the world from Internet data. Yet, a wealth of information falls outside this scope — ranging from personal preferences to organizational policies, from community-specific advice to up-to-date news — that users want models to access but remains unavailable. In this paper, we propose a knowledge ecosystem in which end-users can create, curate, and configure custom knowledge modules that are utilized by language models, such as ChatGPT and Claude. To support this vision, we introduce Knoll, a software infrastructure that allows users to make modules by clipping content from the web or authoring shared documents on Google Docs and GitHub, add modules that others have made, and rely on the system to insert relevant knowledge when interacting with an LLM. We conduct a public deployment of Knoll reaching over 200 users who employed the system for a diverse set of tasks including personalized recommendations, advice-seeking, and writing assistance. Knoll improves the quality of generated responses with participants preferring responses generated with Knoll over baseline GPT-4o responses for 81.5\% of the queries when external knowledge is needed.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Zhao, Dora and Yang, Diyi and Bernstein, Michael S.},
	year = {2025},
	keywords = {data curation, end-user customization, large language models},
}

@inproceedings{whitehead_conversational_2025,
	address = {New York, NY, USA},
	series = {{FDG} '25},
	title = {Conversational {Interactions} with {Procedural} {Generators} using {Large} {Language} {Models}},
	isbn = {979-8-4007-1856-4},
	url = {https://doi.org/10.1145/3723498.3723788},
	doi = {10.1145/3723498.3723788},
	abstract = {This paper explores the potential of Large Language Models (LLMs) to facilitate conversational natural language interactions to aid humans in mixed-initiative generation of game worlds. This paper explores the issues in creating a system that allows for rapid iteration in a turn-based user-LLM design software. We identify key research topics, including game world representation in LLMs, natural language-based world manipulation using function calls, and direct manipulation from processed LLM output. We successfully created a QA dataset to compare the accuracy of leading models using text, images, or both. Our findings highlight the potential of LLMs to assist in procedural content generation through enhanced natural language interaction and conversations while revealing the challenges of in-game world manipulation that warrant further research.},
	booktitle = {Proceedings of the 20th {International} {Conference} on the {Foundations} of {Digital} {Games}},
	publisher = {Association for Computing Machinery},
	author = {Whitehead, Jim and Wessel, Thomas and Chen, Blythe and Cruz-James, Raven and Harnist, Luc and Klunder, William and Lam, Justin and Lin, Ethan and Luo, Roman and Nguyen, Hung and Poddar, Naitik and Ravinutula, Shiva and Montoreano, Alejandro and Shehane, Logan and Sims, Yazmyn and Spangler, Jarod and Tan, Michelle and Trela, Zosia},
	year = {2025},
	keywords = {conversational interaction with procedural generators, large language models, natural language interaction, Procedural content generation},
}

@inproceedings{wu_cardioai_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{CardioAI}: {A} {Multimodal} {AI}-based {System} to {Support} {Symptom} {Monitoring} and {Risk} {Prediction} of {Cancer} {Treatment}-{Induced} {Cardiotoxicity}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3714272},
	doi = {10.1145/3706598.3714272},
	abstract = {Despite recent advances in cancer treatments that prolong patients’ lives, treatment-induced cardiotoxicity (i.e., the various heart damages caused by cancer treatments) emerges as one major side effect. The clinical decision-making process of cardiotoxicity is challenging, as early symptoms may happen in non-clinical settings and are too subtle to be noticed until life-threatening events occur at a later stage; clinicians already have a high workload focusing on the cancer treatment, no additional effort to spare on the cardiotoxicity side effect. Our project starts with a participatory design study with 11 clinicians to understand their decision-making practices and their feedback on an initial design of an AI-based decision-support system. Based on their feedback, we then propose a multimodal AI system, CardioAI, that can integrate wearables data and voice assistant data to model a patient’s cardiotoxicity risk to support clinicians’ decision-making. We conclude our paper with a small-scale heuristic evaluation with four experts and the discussion of future design considerations.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wu, Siyi and Cao, Weidan and Fu, Shihan and Yao, Bingsheng and Yang, Ziqi and Yin, Changchang and Mishra, Varun and Addison, Daniel and Zhang, Ping and Wang, Dakuo},
	year = {2025},
	keywords = {Cancer treatment-induced cardiotoxicity, Human-AI collaboration, Large Language Models, Multimodal AI system},
}

@inproceedings{alves_da_veiga_generative_2023,
	address = {New York, NY, USA},
	series = {{KUI} '23},
	title = {Generative {Ominous} {Dataset}: {Testing} the {Current} {Public} {Perception} of {Generative} {Art}},
	isbn = {979-8-4007-0836-7},
	url = {https://doi.org/10.1145/3623462.3623475},
	doi = {10.1145/3623462.3623475},
	abstract = {The advent of generative AI artworks has paved the way for ground-breaking explorations in the realm of digital creativity. This article delves into the multifaceted dimensions of G.O.D., an abbreviation for the art project Generative Ominous Dataset. G.O.D. aims at critically engaging with contemporary AI generative image systems and their intricate interplay with copyright issues, artistic autonomy, and the ethical implications of data collection, unravelling its conceptual underpinnings and its implications for the broader discourse on artificial intelligence, artistic agency, and the evolving contours of digital art. G.O.D. is a generative artwork, entirely coded in Processing, and developed within a/r/cography, a creative research methodology. G.O.D. scrutinizes and questions the ethics of contemporary text-to-image AI-based systems, such as Midjourney, DALL-E, or Firefly. These systems have been at the centre of controversies concerning the datasets used for their training, which encompass online sourced copyrighted materials, without authorization or attribution, masking questionable approaches with technological dazzlement. Many artists and authors find their works repurposed by these systems for the mass production of digital derivatives. G.O.D. aims at critically exposing art audiences to these concerns.},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Culture} and {Computer} {Science}: {Code} and {Materiality}},
	publisher = {Association for Computing Machinery},
	author = {Alves da Veiga, Pedro},
	year = {2023},
	note = {event-place: Lisbon, Portugal},
}

@inproceedings{wang_effects_2025,
	address = {New York, NY, USA},
	series = {L@{S} '25},
	title = {The {Effects} of {Chatbot} {Placement}, {Personification}, and {Functionality} on {Student} {Outcomes} in a {Global} {CS1} {Course}},
	isbn = {979-8-4007-1291-3},
	url = {https://doi.org/10.1145/3698205.3729557},
	doi = {10.1145/3698205.3729557},
	abstract = {We conducted a large-scale randomized controlled trial (RCT) in a massive, open-access, online CS1 course to examine how a chatbot's (1) placement within the course interface, (2) degree of personification, and (3) technical functionality impact student outcomes. When the chatbot was placed in the course's Integrated Development Environment instead of the lessons interface, over five times the proportion of students sent a message. Additionally, these students sent four times as many messages and asked about the homework four times as often. Subtle design choices – such as greeting students with ”Hello” – nearly doubled the percentage of students who engaged with the tool. Despite these significant differences in chatbot usage, we found no meaningful impact on student performance in the course. The study included 6,515 students from 149 countries, divided into 10 experiment groups - each receiving a distinct chatbot implementation - and one control group. Our results show that chatbot design dramatically influences how students engage with the tool, providing valuable insights for further development of AI-based pedagogical tools.},
	booktitle = {Proceedings of the {Twelfth} {ACM} {Conference} on {Learning} @ {Scale}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Sierra and Jefferson, Thomas and Piech, Chris and Mitchell, John C.},
	year = {2025},
	note = {event-place: Palermo, Italy},
	keywords = {ai, chatbot, cs1, global, gpt, randomized controlled trial},
	pages = {73--82},
}

@inproceedings{liu_opseval_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {{OpsEval}: {A} {Comprehensive} {Benchmark} {Suite} for {Evaluating} {Large} {Language} {Models}’ {Capability} in {IT} {Operations} {Domain}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3728572},
	doi = {10.1145/3696630.3728572},
	abstract = {In recent decades, the field of software engineering has driven the rapid evolution of Information Technology (IT) systems, including advances in cloud computing, 5G networks, and financial information platforms. Ensuring the stability, reliability, and robustness of these complex IT systems has emerged as a critical challenge. Large language models (LLMs) that have exhibited remarkable capabilities in NLP-related tasks are showing great potential in AIOps, such as root cause analysis of failures, generation of operations and maintenance scripts, and summarizing of alert information. Unlike knowledge in general corpora, knowledge of Ops varies with the different IT systems, encompassing various private sub-domain knowledge, sensitive to prompt engineering due to various sub-domains, and containing numerous terminologies. Existing NLP-related benchmarks can not guide the selection of suitable LLMs for Ops (OpsLLM), and current metrics (e.g., BLEU, ROUGE) can not adequately reflect the question-answering (QA) effectiveness in the Ops domain. We propose a comprehensive benchmark suite, OpsEval, including an Ops-oriented evaluation dataset, an Ops evaluation benchmark, and a specially designed Ops QA evaluation method. Our dataset contains 7,334 multiple-choice questions and 1,736 QA questions. We have carefully selected and released 20\% of the dataset written by domain experts in various sub-domains to assist current researchers in preliminary evaluations of OpsLLMs1. We test over 24 latest LLMs under various settings such as self-consistency, chain-of-thought, and in-context learning, revealing findings when applying LLMs to Ops. We also propose an evaluation method for QA in Ops, which has a coefficient of 0.9185 with human experts and is improved by 0.4471 and 1.366 compared to BLEU and ROUGE, respectively. Over the past one year, our dataset and leaderboard have been continuously updated.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Yuhe and Pei, Changhua and Xu, Longlong and Chen, Bohan and Sun, Mingze and Zhang, Zhirui and Sun, Yongqian and Zhang, Shenglin and Wang, Kun and Zhang, Haiming and Li, Jianhui and Xie, Gaogang and Wen, Xidao and Nie, Xiaohui and Ma, Minghua and Pei, Dan},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {benchmark, evaluation, large language models, operations, prompt engineering},
	pages = {503--513},
}

@inproceedings{ma_t3set_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{T3Set}: {A} {Multimodal} {Dataset} with {Targeted} {Suggestions} for {LLM}-based {Virtual} {Coach} in {Table} {Tennis} {Training}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737407},
	doi = {10.1145/3711896.3737407},
	abstract = {Coaching is critical for learning table tennis skills. However, amateur table tennis players often lack access to professional coaches due to high costs and a limited number of coaches. While recent multimodal large language models show promise as virtual coaches, most of the existing approaches merely rely on video analysis, which is not comprehensive enough. In table tennis, many important kinematic details (e.g., strength, acceleration) cannot be captured by videos. They can only be tracked using sensors. To address this gap, we present T3Set (Table Tennis Training Set), a multimodal dataset that synchronizes inertial measurement unit (IMU) data from sensors mounted on 32 players' rackets with video recordings. The sensor data has 16 dimensions and a sample rate of 100Hz. This dataset covers 7 fundamental techniques across 380 training rounds, totaling 8655 annotated strokes, with 8395 targeted suggestions from coaches. The key features of T3Set include (1) temporal alignment between sensor data, video data, and text data. (2) high-quality targeted suggestions which are consistent with predefined suggestion taxonomy. Based on T3Set, we propose a novel two-stage framework that effectively integrates motion perception with generative reasoning as a virtual coach. Our method quantitatively outperforms baseline methods. The dataset, code, and documentation are available at https://github.com/jima-cs/T3Set.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Ma, Ji and Wu, Jiale and Wang, Haoyu and Zhang, Yanze and Xie, Xiao and Zhou, Zheng and Zhang, Hui and Wang, Jiachen and Wu, Yingcai},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {multimodal dataset, table tennis, virtual coach},
	pages = {5686--5697},
}

@inproceedings{salminen_communication_2024,
	address = {New York, NY, USA},
	series = {Mindtrek '24},
	title = {Communication {Design} for an {Educational} {AI} {Chatbot}: {Analyzing} {Cipherbot}'s {Communication} {Style} and {Challenges}},
	isbn = {979-8-4007-1823-6},
	url = {https://doi.org/10.1145/3681716.3681727},
	doi = {10.1145/3681716.3681727},
	abstract = {We analyzed the communication patterns of Cipherbot, an educational AI chatbot that addresses validation and transparency problems in AI-student interaction, with 44 undergraduate business students using the system. Findings show that Cipherbot delivers information grounded in learning materials, primarily focusing on statements of fact, with a 99\% occurrence rate. Also, about a third (31\%) of Cipherbot's messages to students contain an example, which adheres to pedagogical best practices. However, more than a third (36\%) of Cipherbot's communication with students also contained traces of opinion, particularly normative statements about how companies or individuals should behave. Cipherbot also demonstrates some level of social etiquette, using thank yous and apologies (7\%), but it rarely engages in requests for information, or clarifications and comprehension checks–as these categories might be useful for student engagement, future exploration into diversifying Cipherbot's communication style to support learning is required. Student feedback suggests that usability issues in educational AI chatbots comprise both communicational and technical issues, e.g., incompleteness and redundancy–iterative testing of prompts with student feedback could address many of these challenges. Based on our findings, we make six propositions about students’ interaction with educational AI chatbots.},
	booktitle = {Proceedings of the 27th {International} {Academic} {Mindtrek} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Salminen, Joni and Jung, Soon-Gyo and Medina, Johanne and Aldous, Kholoud and Azem, Jinan and Akhtar, Waleed and Häyhänen, Essi and Jansen, Bernard J},
	year = {2024},
	note = {event-place: Tampere, Finland},
	keywords = {AI chatbots, challenges, communication style, education},
	pages = {176--187},
}

@inproceedings{li_learning_2024,
	address = {New York, NY, USA},
	series = {{WWW} '24},
	title = {Learning to {Rewrite} {Prompts} for {Personalized} {Text} {Generation}},
	isbn = {979-8-4007-0171-9},
	url = {https://doi.org/10.1145/3589334.3645408},
	doi = {10.1145/3589334.3645408},
	abstract = {Facilitated by large language models (LLMs), personalized text generation has become a rapidly growing research direction. Most existing studies focus on designing specialized models for a particular domain, or they require fine-tuning the LLMs to generate personalized text. We consider a typical scenario in which the large language model, which generates personalized output, is frozen and can only be accessed through APIs. Under this constraint, all one can do is to improve the input text (i.e., text prompts) sent to the LLM, a procedure that is usually done manually. In this paper, we propose a novel method to automatically revise prompts for personalized text generation. The proposed method takes the initial prompts generated by a state-of-the-art, multistage framework for personalized generation and rewrites a few critical components that summarize and synthesize the personal context. The prompt rewriter employs a training paradigm that chains together supervised learning (SL) and reinforcement learning (RL), where SL reduces the search space of RL and RL facilitates end-to-end training of the rewriter. Using datasets from three representative domains, we demonstrate that the rewritten prompts outperform both the original prompts and the prompts optimized via supervised learning or reinforcement learning alone. In-depth analysis of the rewritten prompts shows that they are not only human readable, but also able to guide manual revision of prompts when there is limited resource to employ reinforcement learning to train the prompt rewriter, or when it is costly to deploy an automatic prompt rewriter for inference.},
	booktitle = {Proceedings of the {ACM} {Web} {Conference} 2024},
	publisher = {Association for Computing Machinery},
	author = {Li, Cheng and Zhang, Mingyang and Mei, Qiaozhu and Kong, Weize and Bendersky, Michael},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	keywords = {large language models, personalized text generation, prompt rewrite},
	pages = {3367--3378},
}

@inproceedings{zhai_addressing_2025,
	address = {New York, NY, USA},
	series = {{ESET} '24},
	title = {Addressing {Past} {Tense} {Temporal} {Attacks} in {Large} {Language} {Models} through {Multiple} {Methods}},
	isbn = {979-8-4007-0709-4},
	url = {https://doi.org/10.1145/3704217.3705008},
	doi = {10.1145/3704217.3705008},
	abstract = {Several previous studies highlight the problems that several state-of-art large language models are vulnerable under past tense attack (e.g.,” How to make a Molotov cocktail?” to” How did people make a Molotov cocktail?”). In this paper, we try several methods to address this problem on GPT-3.5-Turbo. The single prompt-engineering method reached a 1\% attack success rate\&nbsp;and a\&nbsp;17\% over-refusal rate, and llama-2-7b trained on the Latent Adversarial Training method reached a 0\% asr. However, its over-refusal rate was 48\%. As an alternative method, we tried to build an advisor with a filter based on LLM, which can perform internet searching to check the safety of the content and provide more information with more timely related resources. With more information, the model can give more detailed insight even if it gives a possible refusal with “Sorry.” Source code at https://github.com/t0rit0/2024-summer-project},
	booktitle = {Proceedings of the 2024 8th {International} {Conference} on {E}-{Society}, {E}-{Education} and {E}-{Technology}},
	publisher = {Association for Computing Machinery},
	author = {Zhai, Nai-ji and Tuo, Xianyi and Jin, Zhishuo},
	year = {2025},
	keywords = {Content Safety, Contextual Analysis, Ethical AI, Large Language Models (LLMs), Model Robustness, Past Tense Temporal Attack, Prompt Engineering},
	pages = {106--111},
}

@inproceedings{li_understanding_2024,
	address = {New York, NY, USA},
	series = {{ASE} '24},
	title = {Understanding {Code} {Changes} {Practically} with {Small}-{Scale} {Language} {Models}},
	isbn = {979-8-4007-1248-7},
	url = {https://doi.org/10.1145/3691620.3694999},
	doi = {10.1145/3691620.3694999},
	abstract = {Recent studies indicate that traditional techniques for understanding code changes are not as effective as techniques that directly prompt language models (LMs). However, current LM-based techniques heavily rely on expensive, large LMs (LLMs) such as GPT-4 and Llama-13b, which are either commercial or prohibitively costly to deploy on a wide scale, thereby restricting their practical applicability. This paper explores the feasibility of deploying small LMs (SLMs) while maintaining comparable or superior performance to LLMs in code change understanding. To achieve this, we created a small yet high-quality dataset called HQCM which was meticulously reviewed, revised, and validated by five human experts. We fine-tuned state-of-the-art 7b and 220m SLMs using HQCM and compared them with traditional techniques and LLMs with ≥70b parameters. Our evaluation confirmed HQCM's benefits and demonstrated that SLMs, after finetuning by HQCM, can achieve superior performance in three change understanding tasks: change summarization, change classification, and code refinement. This study supports the use of SLMs in environments with security, computational, and financial constraints, such as in industry scenarios and on edge devices, distinguishing our work from the others.},
	booktitle = {Proceedings of the 39th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Li, Cong and Xu, Zhaogui and Di, Peng and Wang, Dongxia and Li, Zheng and Zheng, Qian},
	year = {2024},
	note = {event-place: Sacramento, CA, USA},
	keywords = {code change, code review, language model, LLM, SLM},
	pages = {216--228},
}

@inproceedings{andrews_aimoderator_2025,
	address = {New York, NY, USA},
	series = {{IUI} '25},
	title = {{AiModerator}: {A} {Co}-{Pilot} for {Hyper}-{Contextualization} in {Political} {Debate} {Video}},
	isbn = {979-8-4007-1306-4},
	url = {https://doi.org/10.1145/3708359.3712148},
	doi = {10.1145/3708359.3712148},
	abstract = {Political debates are essential in political discourse for democratic societies. Advancements in technology have significantly transformed the structure of political debates, the ways in which politicians communicate, and the platforms through which audiences engage with them. Originally a forum for improving understanding, political debates have increasingly favored theatrics over substance, risking young adult disengagement. To bring substance back to this medium we developed AiModerator, a political debate co-pilot acting as a Multimodal Conversational Agent (MCA). AiModerator aims to promote engagement while improving understanding by analyzing video content to provide contextually relevant information. This consolidated information facilitates understanding while keeping users synchronized with the debate viewing experience. Our system builds upon multimodal techniques, integrating computer vision and large language models to demonstrate ways of improving content delivery and engagement. AiModerator’s backend system extracts events from identified speech data, allowing the user to interact with these events through a touch interface on an iPad application. We address three key topics: evaluating young adults’ engagement, satisfaction, and preference compared to traditional second screening, and determining whether AiModerator can improve subjective understanding. To evaluate these measures we conducted a mixed-method evaluation (n=20) within-group design A-B study. Our analysis found AiModerator excelled in promoting engagement and satisfaction while delivering clear, contextually relevant information to the user which improved their understanding of debate topics more than the second screening mode. Our qualitative analysis offers broader insights, particularly in terms of a trade-off between automation and information consolidation versus autonomy and control.},
	booktitle = {Proceedings of the 30th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Andrews, Peter and Borch, Njål and Fjeld, Morten},
	year = {2025},
	keywords = {Hyper-contextualization, Information Accessibility, Interactive Video, Multimodal Conversational Agents, Natural Language Processing, Political Discourse, Political Engagement, User Experience},
	pages = {137--156},
}

@inproceedings{sun_research_2025,
	address = {New York, NY, USA},
	series = {{AITC} '25},
	title = {Research and {Implementation} of {QC} {Knowledge} {Management} {Model} for {Tobacco} {Enterprises} {Based} on {AI}},
	isbn = {979-8-4007-1862-5},
	url = {https://doi.org/10.1145/3762329.3762351},
	doi = {10.1145/3762329.3762351},
	abstract = {To address issues in tobacco industry QC knowledge management-decentralized resources, inefficient retrieval, and repetitive labor—an intelligent framework using DeepSeek large model is built. By integrating the QC knowledge base with DeepSeek-R1 engine, it enables intelligent extraction, multi-dimensional semantic storage, and precise retrieval. Experiments show inputting natural language yields a 92.3\% relevant QC knowledge graph, boosting reuse efficiency and retrieval accuracy, supporting digital transformation of tobacco QC knowledge management.},
	booktitle = {Proceedings of the 2nd {International} {Conference} on {Artificial} {Intelligence} of {Things} and {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Sun, Xiaohan},
	year = {2025},
	keywords = {Artificial Intelligence, DeepSeek, Knowledge Base, QC Knowledge Management, Tobacco Indust},
	pages = {121--126},
}

@inproceedings{zha_m2conceptbase_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {{M2ConceptBase}: {A} {Fine}-{Grained} {Aligned} {Concept}-{Centric} {Multimodal} {Knowledge} {Base}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3679852},
	doi = {10.1145/3627673.3679852},
	abstract = {Multimodal knowledge bases (MMKBs) provide cross-modal aligned knowledge crucial for multimodal tasks. However, the images in existing MMKBs are generally collected for entities in encyclopedia knowledge graphs. Therefore, detailed groundings of visual semantics with linguistic concepts are lacking, which are essential for the visual concept cognition ability of multimodal models. Addressing this gap, we introduce M2 ConceptBase, the first concept-centric MMKB. M2 ConceptBase models concepts as nodes with associated images and detailed textual descriptions. We propose a context-aware multimodal symbol grounding approach to align concept-image and concept-description pairs using context information from image-text datasets. Comprising 951K images and 152K concepts, M2 ConceptBase links each concept to an average of 6.27 images and a single description, ensuring comprehensive visual and textual semantics. Human studies confirm more than 95\% alignment accuracy, underscoring its quality. Additionally, our experiments demonstrate that M2 ConceptBase significantly enhances VQA model performance on the OK-VQA task. M2 ConceptBase also substantially improves the fine-grained concept understanding capabilities of multimodal large language models through retrieval augmentation in two concept-related tasks, highlighting its value.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Zha, Zhiwei and Wang, Jiaan and Li, Zhixu and Zhu, Xiangru and Song, Wei and Xiao, Yanghua},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {knowledge base, multimodal knowledge base, multimodal symbol grounding, visual question answering},
	pages = {3113--3123},
}

@inproceedings{al-zuraiqi_designing_2025,
	address = {New York, NY, USA},
	series = {{PROMISE} '25},
	title = {Designing and {Optimizing} {Alignment} {Datasets} for {IoT} {Security}: {A} {Synergistic} {Approach} with {Static} {Analysis} {Insights}},
	isbn = {979-8-4007-1594-5},
	url = {https://doi.org/10.1145/3727582.3728687},
	doi = {10.1145/3727582.3728687},
	abstract = {Large Language Models (LLMs) show great promise for automating critical IoT security tasks, yet they often fail to address high-stakes vulnerabilities without domain-focused datasets. In this paper, we present a structured methodology to design and optimize IoT-specific alignment datasets informed by static analysis insights, thereby bridging the gap between generic language models and specialized IoT security requirements. Our approach integrates findings from IoT firmware analysis tools (e.g. FACT and Binwalk) with authoritative vulnerability repositories (MITRE CVE, CWE, CAPEC) to construct three key dataset types: (1) Base Datasets, capturing essential IoT vulnerabilities and configurations, (2) Classification Datasets, discerning IoT from non-IoT prompts, and (3) Alignment Datasets employing Contrastive Preference Optimization (CPO), Direct Preference Optimization (DPO), and Kahneman-Tversky Optimization (KTO) for IoT-specific fine-tuning. We further incorporate secure-by-design principles and bias mitigation strategies—ranging from device-type diversity to synthetic data augmentation—to ensure fair, high-fidelity representations of IoT security scenarios. Experimental results demonstrate that our alignment datasets improve LLM responsiveness and correctness for vulnerabilities discovered via offline static analysis, including outdated libraries, hard-coded credentials, and insecure default services. Notably, Kahneman-Tversky Optimization achieves a 97\% alignment accuracy, reflecting the impact of clear binary classifications in high-stakes security tasks. This work underscores the significance of dual-system integration (static analysis plus LLM alignment) for proactive IoT defense. By foregrounding domain-specific vulnerabilities in carefully curated datasets, we enable LLMs to generate more actionable, context-aware security recommendations, thus advancing state-of-the-art IoT protections in both research and industry deployments.},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Predictive} {Models} and {Data} {Analytics} in {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Al-Zuraiqi, Ahmad and Greer, Des},
	year = {2025},
	note = {event-place: Trondheim, Norway},
	keywords = {alignment datasets, bias mitigation, cross-modal integration, dataset creation, federated learning, firmware vulnerability analysis, IoT security, Large Language Models (LLMs), metadata enrichment, synthetic augmentation},
	pages = {55--64},
}

@inproceedings{xiao_llm-enhanced_2024,
	address = {New York, NY, USA},
	series = {{ACM}-{TURC} '24},
	title = {{LLM}-{Enhanced} {Chinese} {NL2SQL} {Translation} {Task} {Under} {Resource}-{Limited} {Condition}},
	isbn = {979-8-4007-1011-7},
	url = {https://doi.org/10.1145/3674399.3674433},
	doi = {10.1145/3674399.3674433},
	abstract = {With the development of big data and artificial intelligence technology, data has become an important production factor and core resource. There is also a growing demand for real-time accurate, convenient and fast data analysis in the military field.NL2SQL technology can be embedded into various intelligent platforms, data analysis tools or intelligent assistants, realizing seamless dialogue between users and data, responding instantly to complex analytical requests, and providing timely and accurate support of decision-making for commanders. However, the Chinese NL2SQL task has a low success rate compared to the English task due to the base model’s bias in converting Chinese entities, difficulty in linking schemas, and unclear thought chain. In this paper, based on the llama3-8b model, we explored the NL2SQL technique under resource-constrained conditions.By analyzing the characteristics of the model’s erroneous output results under regular prompts,target refinements of Chinese prompts are designed.And through supervised fine-tuning, we have made the model’s accuracy rate on the dev set increase from the initial 46\% to 70\%.},
	booktitle = {Proceedings of the {ACM} {Turing} {Award} {Celebration} {Conference} - {China} 2024},
	publisher = {Association for Computing Machinery},
	author = {Xiao, Xichonglang and Xu, Hao},
	year = {2024},
	note = {event-place: Changsha, China},
	keywords = {llama3, Military, NL2SQL, SFT},
	pages = {86--91},
}

@inproceedings{mirindi_advanced_2025,
	address = {New York, NY, USA},
	series = {{SIGMIS}-{CPR} '25},
	title = {Advanced evaluation of {BIM}-{GenAI} using {OpenAI} o1 and ethical considerations},
	isbn = {979-8-4007-1497-9},
	url = {https://doi.org/10.1145/3716489.3728431},
	doi = {10.1145/3716489.3728431},
	abstract = {The rapid advancement of artificial intelligence (AI) has led the AI community to speculate that artificial superintelligence (ASI) may be within reach, particularly if an AI system can iteratively search for solutions, learn from results, and leverage improved knowledge for more searches. In this context, this study explores the integration of Generative Artificial Intelligence (GenAI) into Building Information Modeling (BIM) by focusing on the four key pillars of the OpenAI o1 model and their ethical implications. Through comprehensive analysis of existing literature, we examine these pillars—policy initialization, reward design, search strategies, and learning mechanisms—and their application in BIM-GenAI within a continuous improvement cycle. Results demonstrate that policy initialization generates human-like reasoning behaviors and domain-specific knowledge for BIM tasks. Reward design, central to reinforcement learning, optimizes BIM objectives through measurable metrics and learned evaluation methods. Search strategies prove valuable for exploring complex design spaces and generating high-quality BIM solutions, while learning mechanisms, including policy gradient and behavior cloning, enable continuous model improvement through feedback. The study emphasizes the importance of establishing BIM-AI protocols, maintaining human expertise in decision-making, and balancing automation with human input. Our findings suggest that while GenAI, powered by reinforcement learning, offers significant potential for enhancing BIM capabilities, three critical ethical considerations—data privacy and security, algorithmic bias mitigation, and transparency and accountability—must guide responsible implementation. This research contributes to the growing body of knowledge on AI in construction technologies and provides a foundation for the ethical advancement of BIM-GenAI systems using OpenAI o1.},
	booktitle = {Proceedings of the 2025 {Computers} and {People} {Research} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Mirindi, Derrick and Sinkhonde, David and Mirindi, Frederic and Bezabith, Tajebe},
	year = {2025},
	keywords = {Artificial Intelligence, Building Information Modeling, Generative Artificial Intelligence, OpenAI o1},
}

@inproceedings{sayana_beyond_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Beyond {Retrieval}: {Generating} {Narratives} in {Conversational} {Recommender} {Systems}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3717531},
	doi = {10.1145/3701716.3717531},
	abstract = {Large Language Models (LLMs) have shown remarkable progress in generating human-quality text and engaging in complex reasoning. This presents a unique opportunity to revolutionize conversational recommender systems by enabling them to generate rich, engaging and personalized narratives that go beyond recommendations. However, the lack of suitable datasets limits research in this area. This paper addresses this challenge by making two key contributions.First, we introduce REGEN Reviews Enhanced with GEnerative Narratives, a new dataset extending the Amazon Product Reviews with rich user narratives. Furthermore, we perform an extensive automated evaluation of the dataset using a rater LLM. Second, the paper introduces a fusion architecture (CF model with an LLM) which serves as a baseline for REGEN. To the best of our knowledge, this represents the first attempt to analyze the capabilities of LLMs in understanding recommender signals and generating rich narratives. We demonstrate that LLMs can effectively learn from simple fusion architectures utilizing interaction-based CF embeddings, and this can be further enhanced using the metadata and personalization data associated with items. Our experiments show that combining CF and content embeddings leads to improvements of 4-12\% in key language metrics compared to using either type of embedding individually. We also provide an analysis to interpret their contributions to this new generative task.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Sayana, Krishna and Vasudeva, Raghavendra and Vasilevski, Yuri and Su, Kun and Hebert, Liam and Pine, James and Pham, Hubert and Jash, Ambarish and Sodhi, Sukhdeep},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {language models, recommenders},
	pages = {2411--2420},
}

@inproceedings{noh_biassist_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{BIASsist}: {Empowering} {News} {Readers} via {Bias} {Identification}, {Explanation}, and {Neutralization}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713531},
	doi = {10.1145/3706598.3713531},
	abstract = {Biased news articles can distort readers’ perceptions by presenting information in a way that favors or disfavors a particular point of view. Subtly embedded in the text, these biased news articles can shape our views daily without people even realizing it. To address this issue, we propose BIASsist, an LLM-based approach designed to mitigate bias in news articles. Based on existing research, we defined six types of bias and introduced three assistive components—identification, explanation, and neutralization—to provide a broader range of bias information and enhance readers’ bias-awareness. We conducted a mixed-method study with 36 participants to evaluate the effectiveness of BIASsist. The results show participants’ bias awareness significantly improved and their interest in identifying bias increased. Participants also tended to engage more actively in critically evaluating articles. Based on these findings, we discuss its potential to improve media literacy and critical thinking in today’s information overload era.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Noh, Yeo-Gyeong and Han, MinJu and Jeon, Junryeol and Hong, Jin-Hyuk},
	year = {2025},
	keywords = {Assistive tool, Bias, LLM-powered application, News article},
}

@inproceedings{muthyala_so_2024,
	address = {New York, NY, USA},
	series = {{SIGDOC} '24},
	title = {So {You} {Want} to {Build} a {Chatbot}?: {A} {Systematic} {Case} {Study} {Comparing} the {Design} and {Development} of {Two} {Water} {Chatbots}},
	isbn = {979-8-4007-0519-9},
	url = {https://doi.org/10.1145/3641237.3691661},
	doi = {10.1145/3641237.3691661},
	abstract = {Chatbots have become a popular method through which to deliver conversational-style information to users about a range of topics, including providing customer service, news and weather updates, educational content, and medical information. This article compares two chatbots created with different methods, including via custom architecture and custom GPT to determine the strengths and limitations of the development methods. The bots that our research team developed were built to deliver information about water and drought to Arizona residents. We compare the initial setup process, customization capabilities, the training process, prompt engineering requirements, file handling, costs, and outputs of each bot. The custom architecture bot offers the flexibility and control of answers, but it costs more than its comparator and takes more time. The custom GPT requires little experience with Large Language Models (LLMs) and no experience with coding, but offers less control. Because we recognize that public agencies often don't have the expertise or funding to build a fully-customized bot architecture, we conclude with suggestions about the contexts and purposes or which each type of bot should be developed.},
	booktitle = {Proceedings of the 42nd {ACM} {International} {Conference} on {Design} of {Communication}},
	publisher = {Association for Computing Machinery},
	author = {Muthyala, Mayank P. and Lauer, Claire and Carradini, Stephen},
	year = {2024},
	note = {event-place: Fairfax, VA, USA},
	keywords = {AI, API, Artificial intelligence, Chatbot, Drought, GPT, Open AI, Science Communication, User Experience, Water},
	pages = {128--137},
}

@inproceedings{kwak_adaptive_2025,
	address = {New York, NY, USA},
	series = {L@{S} '25},
	title = {Adaptive {Tutoring} {Goes} to {Sweden}: {Machine} {Translation} and {Alignment} of {English} {OERs} to a {Swedish} {Calculus} {Course}},
	isbn = {979-8-4007-1291-3},
	url = {https://doi.org/10.1145/3698205.3729549},
	doi = {10.1145/3698205.3729549},
	abstract = {Adaptive tutoring systems have demonstrated significant improvements in math learning, yet their adoption outside of the United States remains limited. The absence of these technologies, along with a lack of research on localizing tutoring systems to different educational contexts, presents a significant barrier for institutions seeking to integrate these tools into their classrooms to support students' math learning. This paper presents a case study on the localization and deployment of OATutor, an adaptive tutoring system developed in the U.S., for use in a math course at KTH Royal Institute of Technology in Sweden. Our study explores using artificial intelligence to automate and validate this process, focusing on translation and syllabus adaptation to ensure the content aligns with the course curriculum and the Swedish educational context. We successfully deployed the system in the course, demonstrating a novel method for translating math content and providing an analysis of syllabus adaptation tailored to the local context. By documenting this process, we contribute to the broader effort to make educational technologies more accessible to diverse learner populations by providing a scalable approach to localization.},
	booktitle = {Proceedings of the {Twelfth} {ACM} {Conference} on {Learning} @ {Scale}},
	publisher = {Association for Computing Machinery},
	author = {Kwak, Yerin and Dunder, Nora and Viberg, Olga and Pardos, Zachary A.},
	year = {2025},
	note = {event-place: Palermo, Italy},
	keywords = {adaptive tutoring systems, case study, curricular alignment, large language models, neural machine translation, oatutor, open educational resources},
	pages = {50--61},
}

@inproceedings{abdenebaoui_value-driven_2025,
	address = {New York, NY, USA},
	series = {{FAccT} '25},
	title = {Value-{Driven} {Design} for {Public} {Administration}: {Insights} from a {Generative} {Chatbot} in a {Housing} {Application} {Case} {Study}},
	isbn = {979-8-4007-1482-5},
	url = {https://doi.org/10.1145/3715275.3732103},
	doi = {10.1145/3715275.3732103},
	abstract = {Artificial intelligence holds significant potential to transform public administration by streamlining complex processes and improving service delivery. However, its adoption is hindered by concerns regarding its alignment with public values e.g., ensuring that all citizens are treated equitably. This study addresses these challenges through a value-driven design approach, focusing on a generative chatbot to assist citizens with the Housing Entitlement Certificate application, a service enabling low-income households to access subsidized housing in Germany. Through two participatory workshops with citizens and public administration employees, the research highlights a tension between significant benefits, such as improved accessibility and streamlined processes, and challenges, including reduced human interaction and dependency on technology. To navigate these tensions, the study proposes actionable requirements, including escalation pathways to human representatives and robust data protection measures. By providing a real-world example, this work illustrates how value-based design can guide the responsible and impactful integration of AI in public administration. The findings underscore the importance of balancing the potential of generative chatbots with societal and ethical considerations, offering a replicable framework for aligning AI systems with public values in diverse service contexts.},
	booktitle = {Proceedings of the 2025 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Abdenebaoui, Larbi and Aljuneidi, Saja and Horstmannshoff, Fynn and Meyer, Jochen and Boll, Susanne},
	year = {2025},
	keywords = {AI in public administration, Artificial Intelligence, Generative Chatbots, Value Driven Design, Value Sensitive Design},
	pages = {1554--1564},
}

@inproceedings{pu_ideasynth_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{IdeaSynth}: {Iterative} {Research} {Idea} {Development} {Through} {Evolving} and {Composing} {Idea} {Facets} with {Literature}-{Grounded} {Feedback}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3714057},
	doi = {10.1145/3706598.3714057},
	abstract = {Research ideation involves broad exploring and deep refining ideas. Both require deep engagement with literature. Existing tools focus primarily on broad idea generation, yet offer little support for iterative specification, refinement, and evaluation needed to further develop initial ideas. To bridge this gap, we introduce IdeaSynth, a research idea development system that uses LLMs to provide literature-grounded feedback for articulating research problems, solutions, evaluations, and contributions. IdeaSynth represents these idea facets as nodes on a canvas, and allow researchers to iteratively refine them by creating and exploring variations and combinations. Our lab study (N = 20) showed that participants, while using IdeaSynth, explored more alternative ideas and expanded initial ideas with more details compared to a strong LLM-based baseline. Our deployment study (N = 7) demonstrated that participants effectively used IdeaSynth for real-world research projects at various ideation stages from developing initial ideas to revising framings of mature manuscripts, highlighting the possibilities to adopt IdeaSynth in researcher’s workflows.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Pu, Kevin and Feng, K. J. Kevin and Grossman, Tovi and Hope, Tom and Dalvi Mishra, Bhavana and Latzke, Matt and Bragg, Jonathan and Chang, Joseph Chee and Siangliulue, Pao},
	year = {2025},
	keywords = {Human-AI Collaboration, Research Ideation, Scientific Literature},
}

@inproceedings{cowgill_recapturing_2024,
	address = {New York, NY, USA},
	series = {{DLfM} '24},
	title = {({Re})capturing the {Emotional} {Geography} of {Lost} {Music} {Venues}: {A} {Case} {Study} of the {Willow} {Community} {Digital} {Archive}},
	isbn = {979-8-4007-1720-8},
	url = {https://doi.org/10.1145/3660570.3660579},
	doi = {10.1145/3660570.3660579},
	abstract = {The loss of many high-street music venues in recent years has highlighted their connectedness to place and communities. Understanding the emotional geographies of these venues, as experienced by their patrons, is key to explaining the outcry that can accompany such closures. In these circumstances it can be challenging to try to (re)capture the intangible elements that defined a lost venue and widen the scope for musicological enquiry. This paper sets out to address that challenge by exploring methods developed by the Willow Community Digital Archive to co-create a community archive in celebration of The Willow, a family-run restaurant-cum-nightclub that operated in York, UK, for over 40 years. Further, we report on how these methods informed the crafting of a general-purpose digital library system to form the archive. We also detail some initial experiments with ChatGPT, embedded into the archive, to investigate its potential to encourage visitors to engage with and inspire further contributions to the archive.},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Digital} {Libraries} for {Musicology}},
	publisher = {Association for Computing Machinery},
	author = {Cowgill, Rachel and Bainbridge, David and Dix, Alan and Hoyle, Victoria and Fong, Vicki and Thomas, David},
	year = {2024},
	note = {event-place: Stellenbosch, South Africa},
	keywords = {British Chinese Communities, ChatGPT, Data-gathering, Digital Archives, DJ-ing, Heritage, Music Venues, Nightclubs, York},
	pages = {23--31},
}

@inproceedings{liu_webglm_2023,
	address = {New York, NY, USA},
	series = {{KDD} '23},
	title = {{WebGLM}: {Towards} {An} {Efficient} {Web}-{Enhanced} {Question} {Answering} {System} with {Human} {Preferences}},
	isbn = {979-8-4007-0103-0},
	url = {https://doi.org/10.1145/3580305.3599931},
	doi = {10.1145/3580305.3599931},
	abstract = {We present WebGLM, a web-enhanced question-answering system based on the General Language Model (GLM). Its goal is to augment a pre-trained large language model (LLM) with web search and retrieval capabilities while being efficient for real-world deployments. To achieve this, we develop WebGLM with strategies for the LLM-augmented retriever, bootstrapped generator, and human preference-aware scorer. Specifically, we identify and address the limitations of WebGPT (OpenAI), through which WebGLM is enabled with accuracy, efficiency, and cost-effectiveness advantages. In addition, we propose systematic criteria for evaluating web-enhanced QA systems. We conduct multi-dimensional human evaluation and quantitative ablation studies, which suggest the outperformance of the proposed WebGLM designs over existing systems. WebGLM with the 10-billion-parameter GLM (10B) is shown to perform better than the similar-sized WebGPT (13B) and even comparably to WebGPT (175B) in human evaluation. The code, demo, and data are at https://github.com/THUDM/WebGLM.},
	booktitle = {Proceedings of the 29th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Xiao and Lai, Hanyu and Yu, Hao and Xu, Yifan and Zeng, Aohan and Du, Zhengxiao and Zhang, Peng and Dong, Yuxiao and Tang, Jie},
	year = {2023},
	note = {event-place: Long Beach, CA, USA},
	keywords = {efficient retrieval enhancement system, human preference alignment, pre-trained language model},
	pages = {4549--4560},
}

@inproceedings{guo_ideabench_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{IdeaBench}: {Benchmarking} {Large} {Language} {Models} for {Research} {Idea} {Generation}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737419},
	doi = {10.1145/3711896.3737419},
	abstract = {Large Language Models (LLMs) have revolutionized interactions between human and artificial intelligence (AI) systems, demonstrating state-of-the-art performance across various domains, including scientific discovery and hypothesis generation. However, the absence of a comprehensive and systematic evaluation framework for LLM-driven research idea generation hinders a rigorous understanding of their strengths and limitations. To address this gap, we propose IdeaBench, a benchmark system that provides a structured dataset and evaluation framework for standardizing the assessment of research idea generation by LLMs. Our dataset comprises titles and abstracts from 2,374 influential papers across eight research domains, along with their 29,408 referenced works, creating a context-rich environment that mirrors human researchers' ideation processes. By profiling LLMs as domain-specific researchers and grounding them in similar contextual constraints, we directly leverage the models' knowledge learned from the pre-training stage to generate new research ideas. To systematically evaluate LLMs' research ideation capability and approximate human assessment, we propose a reference-based metric that aligns with human judgment to quantify idea quality with the assistance of LLMs. Through this evaluation, we find that while LLMs excel at generating novel ideas, they may struggle with generating feasible ideas. IdeaBench serves as a critical resource for benchmarking and comparing LLMs, ultimately advancing research on AI's role in automating scientific discovery.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Guo, Sikun and Shariatmadari, Amir Hassan and Xiong, Guangzhi and Huang, Albert and Kim, Myles and Williams, Corey M. and Bekiranov, Stefan and Zhang, Aidong},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {AI for science, hypothesis generation, large language models},
	pages = {5888--5899},
}

@inproceedings{sikder_efficient_2025,
	address = {New York, NY, USA},
	series = {{PROMISE} '25},
	title = {Efficient {Adaptation} of {Large} {Language} {Models} for {Smart} {Contract} {Vulnerability} {Detection}},
	isbn = {979-8-4007-1594-5},
	url = {https://doi.org/10.1145/3727582.3728688},
	doi = {10.1145/3727582.3728688},
	abstract = {Smart contracts underpin decentralized applications but face significant security risks from vulnerabilities, while traditional analysis methods have limitations. Large Language Models (LLMs) offer promise for vulnerability detection, yet adapting these powerful models efficiently, particularly generative ones, remains challenging. This paper investigates two key strategies for the efficient adaptation of LLMs for Solidity smart contract vulnerability detection: (1) replacing token-level generation with a dedicated classification head during fine-tuning, and (2) selectively freezing lower transformer layers using Low-Rank Adaptation (LoRA). Our empirical evaluation demonstrates that the classification head approach enables models like Llama 3.2 3B to achieve high accuracy (77.5\%), rivaling the performance of significantly larger models such as the fine-tuned GPT-3.5. Furthermore, we show that selectively freezing bottom layers reduces training time and memory usage by approximately 10-20\% with minimal impact on accuracy. Notably, larger models (3B vs. 1B parameters) exhibit greater resilience to layer freezing, maintaining high accuracy even with a large proportion of layers frozen, suggesting a localization of general code understanding in lower layers versus task-specific vulnerability patterns in upper layers. These findings present practical insights for developing and deploying performant LLM-based vulnerability detection systems efficiently, particularly in resource-constrained settings.},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Predictive} {Models} and {Data} {Analytics} in {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Sikder, Fadul and Lei, Yu and Ji, Yuede},
	year = {2025},
	note = {event-place: Trondheim, Norway},
	keywords = {Fine-tuning, Large Language Models, Layer Freezing, Llama 3.2, Smart Contracts, Solidity, StarCoder, Transfer Learning, Vulnerability Detection},
	pages = {65--74},
}

@inproceedings{zaslavsky_enhancing_2024,
	address = {New York, NY, USA},
	series = {{ICoMS} '24},
	title = {Enhancing spatially-disaggregated simulations with large language models},
	isbn = {979-8-4007-0722-3},
	url = {https://doi.org/10.1145/3686592.3686595},
	doi = {10.1145/3686592.3686595},
	abstract = {We present our experience integrating large language models (LLMs) and simulation engines to enhance spatially-disaggregated simulation, taking advantage of the spatial knowledge and spatial reasoning capabilities of LLMs. The examples illustrate LLM integration with different variations of compartmental epidemiological models, including agent-based models (ABM) in the context of modeling COVID-19 infection spread in a school setting, and LLM integration with a system dynamics model which supports a serious game focused on strategies for responding to disease outbreaks at the county level. We present the architecture of the integrated LLM-simulation system, demonstrate the initial results, and discuss the challenges of the current approach, related to LLM's understanding of spatial information and spatial relationships, their reasoning capabilities, and model performance and scalability.},
	booktitle = {Proceedings of the 2024 7th {International} {Conference} on {Mathematics} and {Statistics}},
	publisher = {Association for Computing Machinery},
	author = {Zaslavsky, Ilya and Lei, Jiaxi and Graham, Rishi and Handcock, Mark S. and Aronoff-Spencer, Eliah},
	year = {2024},
	keywords = {Agent-Based Models, Epidemiological Modeling, Large Language Models, Spatially-Disaggregated Models, System Dynamics},
	pages = {14--18},
}

@inproceedings{nguyen-ho_t-eagle_2025,
	address = {New York, NY, USA},
	series = {{LSC} '25},
	title = {T-{EAGLE}: {Capturing} {Temporal} {Narratives} via {Sequence} {Captioning} and {Text} {Matching}},
	isbn = {979-8-4007-1857-1},
	url = {https://doi.org/10.1145/3729459.3748691},
	doi = {10.1145/3729459.3748691},
	abstract = {There is a growing need to retrieve specific events or information from personal lifelog data, but this is particularly challenging due to the massive scale and the passive nature of data capture by lifelogging devices. Current systems typically rely on image similarity for single, isolated images, which struggle to capture the user intent expressed in natural language and the semantic links between the images and activities occurring over time. To address this issue, we propose a novel lifelog retrieval framework that explicitly combines both visual and temporal similarity in a multi-stage process, shifting the focus from single images to coherent sequences of actions. Our approach uses image embeddings to initialize a set of candidate images. Importantly, the system then re-evaluates the query similarity based on action descriptions which contain temporal information across image sequences. Action captioning, integrated into the indexing process, captures richer temporal and semantic context, allowing the system to distinguish between visually similar but semantically distinct events. Additionally, the system incorporates an evidence-based question answering mechanism, in which the narratives of the retrieved sequences provide contextual grounding for the answering model. The paper proposes a hybrid retrieval framework that combines image similarity for candidate initialization and visual-textual similarity for event retrieval. The integration of action descriptions enables language-based temporal representation of events. These are extracted offline through semantic content analysis and serve as the basis for building an evidence-based Question Answering module using these narratives as context. This approach helps bridge the gap between user intent and the multimodal, temporally structured nature of lifelog data.},
	booktitle = {Proceedings of the 8th {Annual} {ACM} {Workshop} on the {Lifelog} {Search} {Challenge}},
	publisher = {Association for Computing Machinery},
	author = {Nguyen-Ho, Thang-Long and Tran, Allie and Tran, Minh-Triet and Gurrin, Cathal and Healy, Graham},
	year = {2025},
	keywords = {interactive retrieval systems, lifelog, semantic embedding},
	pages = {23--27},
}

@inproceedings{han_xbrl_2024,
	address = {New York, NY, USA},
	series = {{ICAIF} '24},
	title = {{XBRL} {Agent}: {Leveraging} {Large} {Language} {Models} for {Financial} {Report} {Analysis}},
	isbn = {979-8-4007-1081-0},
	url = {https://doi.org/10.1145/3677052.3698614},
	doi = {10.1145/3677052.3698614},
	abstract = {eXtensible Business Reporting Language (XBRL) has attained the status of the global de facto standard for business reporting. However, its complexity poses significant barriers to interpretation and accessibility. In this paper, we present the first evaluation of large language models’ (LLMs) performance in analyzing XBRL reports. Our study identifies LLMs’ limitations in the comprehension of financial domain knowledge and mathematical calculation in the context of XBRL reports. To address these issues, we propose enhancement methods using external tools under the agent framework, referred to as XBRL-Agent, which invokes retrievers and calculators. Extensive experiments on two tasks - the Domain Query Task (which involved testing 500 XBRL term explanations and 50 domain questions) and the Numeric Type Query Task (tested 1,000 financial math tests and 50 numeric queries) - demonstrate substantial performance improvements, with accuracy increasing by up to 17\% for the domain task and 42\% for the numeric type task. This work not only explores the potential of LLMs for analyzing XBRL reports but also augments the reliability and robustness of such analysis, although there is still much room for improvement in mathematical calculations.},
	booktitle = {Proceedings of the 5th {ACM} {International} {Conference} on {AI} in {Finance}},
	publisher = {Association for Computing Machinery},
	author = {Han, Shijie and Kang, Haoqiang and Jin, Bo and Liu, Xiao-Yang and Yang, Steve Y},
	year = {2024},
	note = {event-place: Brooklyn, NY, USA},
	keywords = {Large language models (LLM), Semantic-augmented generation, XBRL reports},
	pages = {856--864},
}

@inproceedings{hong_context-aware_2024,
	address = {New York, NY, USA},
	series = {{DIS} '24},
	title = {A {Context}-{Aware} {Onboarding} {Agent} for {Metaverse} {Powered} by {Large} {Language} {Models}},
	isbn = {979-8-4007-0583-0},
	url = {https://doi.org/10.1145/3643834.3661579},
	doi = {10.1145/3643834.3661579},
	abstract = {One common asset of metaverse is that users can freely explore places and actions without linear procedures. Thus, it is hard yet important to understand the divergent challenges each user faces when onboarding metaverse. Our formative study (N = 16) shows that first-time users ask questions about metaverse that concern 1) a short-term spatiotemporal context, regarding the user’s current location, recent conversation, and actions, and 2) a long-term exploration context regarding the user’s experience history. Based on the findings, we present PICAN, a Large Language Model-based pipeline that generates context-aware answers to users when onboarding metaverse. An ablation study (N = 20) reveals that PICAN’s usage of context made responses more useful and immersive than those generated without contexts. Furthermore, a user study (N = 21) shows that the use of long-term exploration context promotes users’ learning about the locations and activities within the virtual environment.},
	booktitle = {Proceedings of the 2024 {ACM} {Designing} {Interactive} {Systems} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Hong, Jihyeong and Lee, Yokyung and Kim, Dae Hyun and Choi, DaEun and Yoon, Yeo-Jin and Lee, Gyu-cheol and Lee, Zucheul and Kim, Juho},
	year = {2024},
	note = {event-place: Copenhagen, Denmark},
	keywords = {context-awareness, conversational agent, large-language models, metaverse},
	pages = {1857--1874},
}

@inproceedings{lee_rex_2024,
	address = {New York, NY, USA},
	series = {{DIS} '24},
	title = {{REX}: {Designing} {User}-centered {Repair} and {Explanations} to {Address} {Robot} {Failures}},
	isbn = {979-8-4007-0583-0},
	url = {https://doi.org/10.1145/3643834.3661559},
	doi = {10.1145/3643834.3661559},
	abstract = {Robots in real-world environments continuously engage with multiple users and encounter changes that lead to unexpected conflicts in fulfilling user requests. Recent technical advancements (e.g., large-language models (LLMs), program synthesis) offer various methods for automatically generating repair plans that address such conflicts. In this work, we understand how automated repair and explanations can be designed to improve user experience with robot failures through two user studies. In our first, online study (n = 162), users expressed increased trust, satisfaction, and utility with the robot performing automated repair and explanations. However, we also identified risk factors—safety, privacy, and complexity—that require adaptive repair strategies. The second, in-person study (n = 24) elucidated distinct repair and explanation strategies depending on the level of risk severity and type. Using a design-based approach, we explore automated repair with explanations as a solution for robots to handle conflicts and failures, complemented by adaptive strategies for risk factors. Finally, we discuss the implications of incorporating such strategies into robot designs to achieve seamless operation among changing user needs and environments.},
	booktitle = {Proceedings of the 2024 {ACM} {Designing} {Interactive} {Systems} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Lee, Christine P and Praveena, Pragathi and Mutlu, Bilge},
	year = {2024},
	note = {event-place: Copenhagen, Denmark},
	keywords = {failures, human-robot interaction, program repair, robot, user-centered design, vignette study},
	pages = {2911--2925},
}

@inproceedings{mridul_terminators_2025,
	address = {New York, NY, USA},
	series = {Websci {Companion} '25},
	title = {Terminators: {Terms} of {Service} {Parsing} and {Auditing} {Agents}},
	isbn = {979-8-4007-1535-8},
	url = {https://doi.org/10.1145/3720554.3736183},
	doi = {10.1145/3720554.3736183},
	abstract = {Terms of Service (ToS) documents are often lengthy and written in complex legal language, making them difficult for users to read and understand. To address this challenge, we propose Terminators, a modular agentic framework that leverages large language models (LLMs) to parse and audit ToS documents. Rather than treating ToS understanding as a black-box summarization problem, Terminators breaks the task down to three interpretable steps: term extraction, verification, and accountability planning. We demonstrate the effectiveness of our method on the OpenAI ToS using GPT-4o, highlighting strategies to minimize hallucinations and maximize auditability.Our results suggest that structured, agent-based LLM workflows can enhance both the usability and enforceability of complex legal documents. By translating opaque terms into actionable, verifiable components, Terminators promotes ethical use of web content by enabling greater transparency, empowering users to understand their digital rights, and supporting automated policy audits for regulatory or civic oversight.},
	booktitle = {Companion {Publication} of the 17th {ACM} {Web} {Science} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Mridul, Maruf Ahmed and Kang, Inwon and Seneviratne, Oshani},
	year = {2025},
	keywords = {Accountability, Agentic Workflow, Auditing, Automation, Language Models},
	pages = {44--48},
}

@inproceedings{lee_log2plan_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {{Log2Plan}: {An} {Adaptive} {GUI} {Automation} {Framework} {Integrated} with {Task} {Mining} {Approach}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747663},
	doi = {10.1145/3746059.3747663},
	abstract = {GUI task automation streamlines repetitive tasks, but existing LLM or VLM-based planner-executor agents suffer from brittle generalization, high latency, and limited long-horizon coherence. Their reliance on single-shot reasoning or static plans makes them fragile under UI changes or complex tasks. Log2Plan addresses these limitations by combining a structured two-level planning framework with a task mining approach over user behavior logs, enabling robust and adaptable GUI automation. Log2Plan constructs high-level plans by mapping user commands to a structured task dictionary, enabling consistent and generalizable automation. To support personalization and reuse, it employs a task mining approach from user behavior logs that identifies user-specific patterns. These high-level plans are then grounded into low-level action sequences by interpreting real-time GUI context, ensuring robust execution across varying interfaces. We evaluated Log2Plan on 200 real-world tasks, demonstrating significant improvements in task success rate and execution time. Notably, it maintains over 60.0\% success rate even on long-horizon task sequences, highlighting its robustness in complex, multi-step workflows.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Lee, Seoyoung and Yoon, Seobin and Lee, Seongbeen and Kim, Hyesoo and Sim, Joo Yong},
	year = {2025},
	keywords = {GUI automation, Large Language Models, Task Mining, Two-level Planning},
}

@inproceedings{fan_hierarchical_2025,
	address = {New York, NY, USA},
	series = {{HILDA} '25},
	title = {Hierarchical {Table} {Semantics} for {Exploratory} {Table} {Discovery}},
	isbn = {979-8-4007-1959-2},
	url = {https://doi.org/10.1145/3736733.3736746},
	doi = {10.1145/3736733.3736746},
	abstract = {Exploratory table discovery in open data portals presents significant challenges due to unreliable metadata and ambiguous table semantics. Users typically lack prior knowledge of available datasets, making it difficult to identify relevant tables through traditional keyword search or value matching approaches, which often fail to capture semantic relevance across heterogeneous table representations.We propose a new approach that automatically constructs hierarchical semantic representations of tables, encompassing specific column semantic types, shared concepts across column groups, and general table-level semantics. By leveraging these semantically-rich representations, our method retrieves relevant tables through semantic alignment rather than traditional value or metadata matching, leading to improved accuracy and recall for table discovery queries.To enhance interpretability and support human-in-the-loop exploration, our system presents users with semantically relevant tables alongside explanations of their relevance. Evaluation on real-world open data and a question-answering benchmark demonstrates the effectiveness of our approach, achieving up to 36\% improvement in Recall@10 compared to embedding-based baselines confirming the utility of hierarchical semantic representations for table discovery.},
	booktitle = {Proceedings of the {Workshop} on {Human}-{In}-the-{Loop} {Data} {Analytics}},
	publisher = {Association for Computing Machinery},
	author = {Fan, Grace and Freire, Juliana},
	year = {2025},
	note = {event-place: Intercontinental Berlin, Berlin, Germany},
	keywords = {column type annotation, data integration, dataset search and discovery, semantic profiling},
}

@inproceedings{kaate_when_2025,
	address = {New York, NY, USA},
	series = {{DIS} '25},
	title = {When {Personas} {Talk} to {You}: {Evaluating} the {Evolution} of {User} {Personas} from {Static} {Profiles} to {Conversational} {User} {Interfaces}},
	isbn = {979-8-4007-1485-6},
	url = {https://doi.org/10.1145/3715336.3735676},
	doi = {10.1145/3715336.3735676},
	abstract = {The development of persona systems provides a possibility for end users to interact with different persona modalities. In a 54-participant randomized controlled experiment, we compare two persona interaction modalities, document and dialogue personas, both generated using AI approaches from survey data. Overall, dialogue personas appear to be perceived more favorably than document personas. However, document personas exhibit a wider range of perceptions, suggesting that experiences with document personas are more polarizing among users. The document personas had higher transparency and were perceived as more complete, but the task completion was perceived as more difficult, although the task success rate was higher. The dialogue personas were perceived as more usable, with a higher System Usability Scale score, and more enjoyable. Our findings provide critical insights into the increasingly important area of persona interaction modalities and the broad paradigm of human-persona interaction.},
	booktitle = {Proceedings of the 2025 {ACM} {Designing} {Interactive} {Systems} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Kaate, Ilkka and Salminen, Joni and Jung, Soon-Gyo and Xuan, Trang Thi Thu and Azem, Jinan Y. and Santos, João M. and Jansen, Bernard J},
	year = {2025},
	keywords = {Interactive Personas, Persona Systems, Usability, User Representation},
	pages = {2350--2372},
}

@inproceedings{zhai_confsum_2025,
	address = {New York, NY, USA},
	series = {{FMANO} '25},
	title = {{ConfSum}: {Towards} {Automatic} {Summarization} of {Network}-scale {Operational} {Intents} from {Device} {Configurations}},
	isbn = {979-8-4007-2103-8},
	url = {https://doi.org/10.1145/3750022.3750459},
	doi = {10.1145/3750022.3750459},
	abstract = {When network operators need to understand the high-level intent behind a network's existing device configurations, they must engage in a tedious and error-prone process of manually reverse-engineering the low-level commands. We propose Configuration Intent Summarization (CIS), a new task that aims to automate this process by generating human-readable summaries of the intents embedded across a network's configurations. CIS is challenging due to the diversity of intents, the semantic gap between device-specific configurations and network-wide intents, and the need to reason about interactions between multiple devices' configurations. We present ConfSum, a system that addresses these challenges by leveraging the unique ability of large language models (LLMs) to parse semi-structured configuration files and summarize them in natural language. However, the full CIS task requires reasoning about device interactions and other complexities that are beyond the capabilities of LLMs alone. To enhance the LLM's robustness to these challenges, ConfSum introduces novel techniques for retrieving relevant examples to augment LLM prompts, decomposing the generation process to handle multi-device intents, and integrating with formal validation tools. Our experiments demonstrate that Conf-Sum achieves high intent coverage while generating summaries that match the quality of human experts.},
	booktitle = {Proceedings of the 2nd {Workshop} on {Formal} {Methods} {Aided} {Network} {Operation}},
	publisher = {Association for Computing Machinery},
	author = {Zhai, Rundi and Liu, Jianmin and Miao, Yukai and Chen, Li and Li, Dan and Cui, Baojiang and Zhang, Peng and Zhai, Ennan and Ding, Zishuo},
	year = {2025},
	note = {event-place: Coimbra, Portugal},
	keywords = {Formal Methods, Large Language Models, Network management},
	pages = {19--24},
}

@inproceedings{da_flans_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{FlanS}: {A} {Foundation} {Model} for {Free}-{Form} {Language}-based {Segmentation} in {Medical} {Images}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3736963},
	doi = {10.1145/3711896.3736963},
	abstract = {Medical imaging is crucial for diagnosing a patient's health condition, and accurate segmentation of these images is essential for isolating regions of interest to ensure precise diagnosis and treatment planning. Existing methods primarily rely on bounding boxes or point-based prompts, while few have explored text-related prompts, despite clinicians often describing their observations and instructions in natural language. To address this gap, we first propose a RAG-based free-form text prompt generator that leverages the domain corpus to generate diverse and realistic descriptions. Then, we introduce FLanS, a novel medical image segmentation model that handles various free-form text prompts, including professional anatomy-informed queries, anatomy-agnostic position-driven queries, and anatomy-agnostic size-driven queries. Additionally, our model also incorporates a symmetry-aware canonicalization module to ensure consistent, accurate segmentations across varying scan orientations and reduce confusion between the anatomical position of an organ and its appearance in the scan. FLanS is trained on a large-scale dataset of over 100k medical images from 7 public datasets. Comprehensive experiments demonstrate the model's superior language understanding and segmentation precision, along with a deep comprehension of the relationship between them, outperforming SOTA baselines on both in-domain and out-of-domain datasets.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Da, Longchao and Wang, Rui and Xu, Xiaojian and Bhatia, Parminder and Kass-Hout, Taha and Wei, Hua and Xiao, Cao},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {foundation model, language-based segmentation, medical image},
	pages = {404--414},
}

@inproceedings{terdalkar_graph_2025,
	address = {New York, NY, USA},
	series = {{GRADES}-{NDA} '25},
	title = {Graph {Repairs} with {Large} {Language} {Models}: {An} {Empirical} {Study}},
	isbn = {979-8-4007-1923-3},
	url = {https://doi.org/10.1145/3735546.3735859},
	doi = {10.1145/3735546.3735859},
	abstract = {Property graphs are widely used in domains such as healthcare, finance, and social networks, but they often contain errors due to inconsistencies, missing data, or schema violations. Traditional rule-based and heuristic-driven graph repair methods are limited in their adaptability as they need to be tailored for each dataset. On the other hand, interactive human-in-the-loop approaches may become infeasible when dealing with large graphs, as the cost-both in terms of time and effort-of involving users becomes too high. Recent advancements in Large Language Models (LLMs) present new opportunities for automated graph repair by leveraging contextual reasoning and their access to real-world knowledge. We evaluate the effectiveness of six open-source LLMs in repairing property graphs. We assess repair quality, computational cost, and model-specific performance. Our experiments show that LLMs have the potential to detect and correct errors, with varying degrees of accuracy and efficiency. We discuss the strengths, limitations, and challenges of LLM-driven graph repair and outline future research directions for improving scalability and interpretability.},
	booktitle = {Proceedings of the 8th {Joint} {Workshop} on {Graph} {Data} {Management} {Experiences} \&amp; {Systems} ({GRADES}) and {Network} {Data} {Analytics} ({NDA})},
	publisher = {Association for Computing Machinery},
	author = {Terdalkar, Hrishikesh and Bonifati, Angela and Mauri, Andrea},
	year = {2025},
	note = {event-place: Berlin, Germany},
	keywords = {Graph Repair, Large Language Models, Property Graphs},
}

@inproceedings{yu_what_2024,
	address = {New York, NY, USA},
	series = {{ASE} '24},
	title = {What {Makes} a {High}-{Quality} {Training} {Dataset} for {Large} {Language} {Models}: {A} {Practitioners}' {Perspective}},
	isbn = {979-8-4007-1248-7},
	url = {https://doi.org/10.1145/3691620.3695061},
	doi = {10.1145/3691620.3695061},
	abstract = {Large Language Models (LLMs) have demonstrated remarkable performance in various application domains, largely due to their self-supervised pre-training on extensive high-quality text datasets. However, despite the importance of constructing such datasets, many leading LLMs lack documentation of their dataset construction and training procedures, leaving LLM practitioners with a limited understanding of what makes a high-quality training dataset for LLMs. To fill this gap, we initially identified 18 characteristics of high-quality LLM training datasets, as well as 10 potential data pre-processing methods and 6 data quality assessment methods, through detailed interviews with 13 experienced LLM professionals. We then surveyed 219 LLM practitioners from 23 countries across 5 continents. We asked our survey respondents to rate the importance of these characteristics, provide a rationale for their ratings, specify the key data pre-processing and data quality assessment methods they used, and highlight the challenges encountered during these processes. From our analysis, we identified 13 crucial characteristics of high-quality LLM datasets that receive a high rating, accompanied by key rationale provided by respondents. We also identified some widely-used data pre-processing and data quality assessment methods, along with 7 challenges encountered during these processes. Based on our findings, we discuss the implications for researchers and practitioners aiming to construct high-quality training datasets for optimizing LLMs.},
	booktitle = {Proceedings of the 39th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Yu, Xiao and Zhang, Zexian and Niu, Feifei and Hu, Xing and Xia, Xin and Grundy, John},
	year = {2024},
	note = {event-place: Sacramento, CA, USA},
	keywords = {empirical study, high-quality data, large language models, practitioners' perspective},
	pages = {656--668},
}

@inproceedings{lin_technical_2024,
	address = {New York, NY, USA},
	series = {{ICSE}-{Companion} '24},
	title = {Technical {Brief} on {Software} {Engineering} for {FMware}},
	isbn = {979-8-4007-0502-1},
	url = {https://doi.org/10.1145/3639478.3643062},
	doi = {10.1145/3639478.3643062},
	abstract = {Foundation Models (FM) like GPT-4 have given rise to FMware, FM-powered applications, which represent a new generation of software that is developed with new roles, assets, and paradigms. FMware has been widely adopted in both software engineering (SE) research (e.g., test generation) and industrial products (e.g., GitHub copilot), despite the numerous challenges introduced by the stochastic nature of FMs. Such challenges jeopardize the quality and trustworthiness of FMware. In our technical brief, we will present the latest research and industrial practices in engineering FMware, and discuss the SE challenges and opportunities facing both researchers and practitioners in the FMware era.The brief is unique in that it is presented from an SE point of view, not an AI point-of-view ensuring that attendees are not bogged into complex mathematical and AI details unless they are essential for contextualizing the SE challenges and opportunities.},
	booktitle = {Proceedings of the 2024 {IEEE}/{ACM} 46th {International} {Conference} on {Software} {Engineering}: {Companion} {Proceedings}},
	publisher = {Association for Computing Machinery},
	author = {Lin, Dayi and Cogo, Filipe Roseiro and Rajbahadur, Gopi Krishnan and Hassan, Ahmed E.},
	year = {2024},
	note = {event-place: Lisbon, Portugal},
	keywords = {FMware, foundation model, software engineering for FMware},
	pages = {431--433},
}

@inproceedings{qian_hsf_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{HSF}: {Defending} against {Jailbreak} {Attacks} with {Hidden} {State} {Filtering}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3717659},
	doi = {10.1145/3701716.3717659},
	abstract = {With the growing deployment of LLMs in daily applications like chatbots and content generation, efforts to ensure outputs align with human values and avoid harmful content have intensified. However, increasingly sophisticated jailbreak attacks threaten this alignment, aiming to induce unsafe outputs. Current defense efforts either focus on prompt rewriting or detection, which are limited in effectiveness due to the various design of jailbreak prompts, or on output control and detection, which are computationally expensive as they require LLM inference. Therefore, designing a pre-inference defense method that resists diverse jailbreak prompts is crucial for preventing LLM jailbreak attacks. We observe that jailbreak attacks, safe queries, and harmful queries exhibit different clustering patterns within the LLM's hidden state representation space. This suggests that by leveraging the LLM's hidden state representational capabilities, we can analyze the LLM's forthcoming behavior and proactively intervene for defense. In this paper, we propose a jailbreak attack defense strategy based on a Hidden State Filter (HSF), a lossless architectural defense mechanism that enables the model to preemptively identify and reject adversarial inputs before the inference process begins. We activate its defensive potential through an additional plugin module, effectively framing the defense task as a classification problem. Experimental results on two benchmark datasets, utilizing three different LLMs, show that HSF significantly enhances resilience against six cutting-edge jailbreak attacks. It significantly reduces the success rate of jailbreak attacks while minimally impacting responses to benign user queries, with negligible inference overhead, and outperforming defense baselines.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Qian, Cheng and Zhang, Hainan and Sha, Lei and Zheng, Zhiming},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {defense strategies, jailbreak attacks, large language models},
	pages = {2078--2087},
}

@inproceedings{coppolillo_engagement-driven_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {Engagement-{Driven} {Content} {Generation} with {Large} {Language} {Models}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3736932},
	doi = {10.1145/3711896.3736932},
	abstract = {Large Language Models (LLMs) demonstrate significant persuasive capabilities in one-on-one interactions, but their influence within social networks, where interconnected users and complex opinion dynamics pose unique challenges, remains underexplored. This paper addresses the research question: Can LLMs generate meaningful content that maximizes user engagement on social networks? To answer this, we propose a pipeline using reinforcement learning with simulated feedback, where the network's response to LLM-generated content (i.e., the reward) is simulated through a formal engagement model. This approach bypasses the temporal cost and complexity of live experiments, enabling an efficient feedback loop between the LLM and the network under study. It also allows to control over endogenous factors such as the LLM's position within the social network and the distribution of opinions on a given topic. Our approach is adaptive to the opinion distribution of the underlying network and agnostic to the specifics of the engagement model, which is embedded as a plug-and-play component. Such flexibility makes it suitable for more complex engagement tasks and interventions in computational social science. Using our framework, we analyze the performance of LLMs in generating social engagement under different conditions, showcasing their full potential in this task. The experimental code is publicly available at https://github.com/mminici/Engagement-Driven-Content-Generation.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Coppolillo, Erica and Cinus, Federico and Minici, Marco and Bonchi, Francesco and Manco, Giuseppe},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {engagement maximization, large language models, reinforcement learning},
	pages = {369--379},
}

@inproceedings{ke_automation_2024,
	address = {New York, NY, USA},
	series = {I-{DO} '24},
	title = {Automation, {Trustworthy}, {Intelligent} {Prenatal} {Examinations} - {I} {Do}‼},
	isbn = {979-8-4007-0918-0},
	url = {https://doi.org/10.1145/3658549.3658561},
	doi = {10.1145/3658549.3658561},
	abstract = {Medical institutions are looking forward to importing innovative information services to reduce the burden on medical staff. For example, medical staff repeatedly process the contextual data in each stage of the prenatal examinations, which is labor-intensive and time-consuming. If a dispute happens, the data will become the evidence to support whether the prenatal examinations were handled appropriately. Therefore, if the prenatal examination data is not accurately recorded and properly preserved, it will become a source of pressure for medical staff to face disputes in the future. This research takes the prenatal examinations of pregnant as a use case. We apply robotic process automation technology to assist in the automation of prenatal examinations and blockchain technology to establish trustworthy prenatal examinations. Besides, we also use generative artificial intelligence technology to provide intelligent user-assisted consultation in open-domain question answering. The contribution of this work is to build an automated reliable prenatal examination information service to provide good care for pregnant.},
	booktitle = {Proceedings of the 2024 {International} {Conference} on {Information} {Technology}, {Data} {Science}, and {Optimization}},
	publisher = {Association for Computing Machinery},
	author = {Ke, Chih-Kun and Wu, Mei-Yu and Chung, Bor-Lin},
	year = {2024},
	note = {event-place: Taipei, Taiwan},
	pages = {42--47},
}

@inproceedings{zhang_towards_2025-1,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Towards {AI}-driven {Sign} {Language} {Generation} with {Non}-manual {Markers}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713855},
	doi = {10.1145/3706598.3713855},
	abstract = {Sign languages are essential for the Deaf and Hard-of-Hearing (DHH) community. Sign language generation systems have the potential to support communication by translating from written languages, such as English, into signed videos. However, current systems often fail to meet user needs due to poor translation of grammatical structures, the absence of facial cues and body language, and insufficient visual and motion fidelity. We address these challenges by building on recent advances in LLMs and video generation models to translate English sentences into natural-looking AI ASL signers. The text component of our model extracts information for manual and non-manual components of ASL, which are used to synthesize skeletal pose sequences and corresponding video frames. Our findings from a user study with 30 DHH participants and thorough technical evaluations demonstrate significant progress and identify critical areas necessary to meet user needs.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Han and Shalev-Arkushin, Rotem and Baltatzis, Vasileios and Gillis, Connor and Laput, Gierad and Kushalnagar, Raja and Quandt, Lorna C and Findlater, Leah and Bedri, Abdelkareem and Lea, Colin},
	year = {2025},
	keywords = {accessibility, assistive technology, DHH community, human-centered design, Sign language generation},
}

@inproceedings{hendrawan_explanations_2024,
	address = {New York, NY, USA},
	series = {{UMAP} {Adjunct} '24},
	title = {Explanations in {Open} {User} {Models} for {Personalized} {Information} {Exploration}},
	isbn = {979-8-4007-0466-6},
	url = {https://doi.org/10.1145/3631700.3665188},
	doi = {10.1145/3631700.3665188},
	abstract = {Open user models provide affordance for a transparent user control over recommendations based on shared symbolic representation within the system. Users must build their user profile by adding these symbols and tuning their importance to get meaningful recommendations. Since the link between these symbols and the reference explanation is often unavailable, it can be difficult for users to understand them. These symbols are often referred to as concepts, tags, areas, topics, labels, features, or keyphrases. This study showcases an information exploration system that helps students identify potential faculty members to collaborate with. The system works by matching user and faculty profiles that contain keywords or phrases representing topics/areas of interest. Students must develop their understanding of research topics while building their profiles, which can become challenging as they add more keywords. To support students in controlling the recommendation, we introduce post hoc explanations with three levels of detail: no explanations, individual explanation for topics, and explanation of the relationships between topics. This study explores how explanation is associated with the user context / tasks and the exploration process. Our observation suggests that expertise in the field is linked to exploring fewer novel topics and seeking fewer explanations but engaging more with explanations of relationships. In addition, we found that the engagement with faculty information is moderately correlated with the use of more advanced explanations.},
	booktitle = {Adjunct {Proceedings} of the 32nd {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {Association for Computing Machinery},
	author = {Hendrawan, Rully Agus and Brusilovsky, Peter and Lekshmi Narayanan, Arun Balajiee and Barria-Pineda, Jordan},
	year = {2024},
	note = {event-place: Cagliari, Italy},
	keywords = {Adaptive explanation, Concept graph, Information exploration, Intelligent interface, Open user model},
	pages = {256--263},
}

@inproceedings{man_lusifer_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{LUSIFER}: {Language} {Universal} {Space} {Integration} for {Enhanced} {Representation} in {Multilingual} {Text} {Embedding} {Models}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730029},
	doi = {10.1145/3726302.3730029},
	abstract = {Recent advancements in large language models (LLMs) based embedding models have established new state-of-the-art benchmarks for text embedding tasks, particularly in dense vector-based retrieval. However, these models predominantly focus on English, leaving multilingual embedding capabilities largely unexplored. To address this limitation, we present LUSIFER, a novel zero-shot approach that adapts LLM-based embedding models for multilingual tasks without requiring multilingual supervision. LUSIFER's architecture combines a multilingual encoder, serving as a language-universal learner, with an LLM-based embedding model optimized for embedding-specific tasks. These components are seamlessly integrated through a minimal set of trainable parameters that act as a connector, effectively transferring the multilingual encoder's language understanding capabilities to the specialized embedding model. Additionally, to comprehensively evaluate multilingual embedding performance, we introduce a new benchmark encompassing 5 primary embedding tasks, 123 diverse datasets, and coverage across 14 languages. Extensive experimental results demonstrate that LUSIFER significantly enhances the multilingual performance across various embedding tasks, particularly for medium and low-resource languages, without requiring explicit multilingual training data. The code and dataset for training are available at: https://github.com/hieum98/lusifer},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Man, Hieu and Ngo, Nghia Trung and Dac Lai, Viet and Rossi, Ryan A. and Dernoncourt, Franck and Huu Nguyen, Thien},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {large language models, multilingual benchmarks, multilingual text embedding, representation learning, zero-shot learning},
	pages = {1360--1370},
}

@inproceedings{liang_how_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {How {Users} {Interact} with {Generative} {Information} {Retrieval} {Systems}: {A} {Study} of {User} {Behavior} and {Search} {Experience}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3729998},
	doi = {10.1145/3726302.3729998},
	abstract = {The development of LLM has facilitated the emergence of generative information retrieval (IR) systems, such as ”Bing Chat”. Generative IR systems return generated text with citations rather than a list of ranked search results. User studies on IR systems are essential for understanding users' interaction patterns, evaluating and optimizing systems, and improving search experience, particularly in the context of generative IR systems with novel conversational interfaces and responses. However, systematic investigations into user behavior and search experience on generative IR systems are notably lacking. To address this gap, we conducted a user study using Bing Chat to explore user behavior and feedback on generative IR systems. The participants were required to accomplish three types of tasks using Bing Chat. During the search process, we collected their various behavior (e.g., click, query reformulation) and explicit feedback (e.g., satisfaction, credibility, and success). Additionally, the same study was conducted on traditional IR systems Bing for comparison. Analyses of these data show that Bing Chat can reduce the user's search effort and lead to a better search experience without any decrease in credibility compared with Bing. We believe that this work provides valuable insight into the design and evaluation of generative information retrieval systems.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Liang, Yidong and Wu, Zhijing and Zhang, Fan and Song, Dandan and Huang, Heyan},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {generative information retrieval system, search behavior, search experience, user study},
	pages = {634--644},
}

@inproceedings{chen_efficient_2025,
	address = {New York, NY, USA},
	series = {{CNSSE} '25},
	title = {Efficient and {Scalable} {Data} {Pipelines}: {The} {Core} of {Data} {Processing} in {Gig} {Economy} {Platforms}},
	isbn = {979-8-4007-1361-3},
	url = {https://doi.org/10.1145/3732365.3732398},
	doi = {10.1145/3732365.3732398},
	abstract = {Task economy is characterized by fast demand variation and heterogeneous data generated from different sources. Platforms operating in this space require real-time analytics to influence decision-making and improve service offerings, so fast and effective data processing is critical. We introduce a detailed framework to build over effective and scalable data hardware for gig economy platforms at scale in this paper. We propose a new modular architecture that addresses the systematic management of processing tasks and the seamless integration of individual data sources. It combines processing techniques of streaming and batch to elevate the data movement and reduce delay.By using microservices architecture, the framework enables the independent deployment of components, which increases its flexibility and robustness. Using substantial benchmarking metrics on real-world datasets allows for implementation speedups and resource consumption compared to classical methods while still allowing gig-economy platforms to hand-click large amounts of data and adapt quickly to changing market conditions while minimizing storage costs.},
	booktitle = {Proceedings of the 2025 5th {International} {Conference} on {Computer} {Network} {Security} and {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Junjie},
	year = {2025},
	keywords = {Systematic management platforms, Task economy},
	pages = {195--199},
}

@inproceedings{zhu_power_2025,
	address = {New York, NY, USA},
	series = {{ISAC} '25},
	title = {Power {Knowledge} {Question}-{Answering} {System} {Based} on {Agents}, {Chain}-of-{Thought} and {In}-{Context} {Learning}},
	isbn = {979-8-4007-1519-8},
	url = {https://doi.org/10.1145/3733054.3733082},
	doi = {10.1145/3733054.3733082},
	abstract = {Electric power industry is very important to our modern life. The traditional knowledge and question-answering can not adapt to the increasingly complex huge data with the development of power system. Although the LLMs succeed in common cases, they can hardly understand and answer questions from the power industries successfully. How to effectively solve some hard problems, such as comprehensively apply the knowledge base of the power industry domain, improve the multi-jump and complicated QA capability, avoid refine tuning of the large models and so on has never been reported before. To fill the research vacuum points above mentioned, this paper has explored a way to construct CoT dataset, design an ICL technique in-context learning and generate the agent framework for electricity-related QA task respectively. Experiments show that: Compared with other ways, using Agent + CoT + ICL methods makes our model perform better in accuracy and solving skills; it verifies the effectiveness of the method designed here.},
	booktitle = {Proceedings of the 2025 {International} {Conference} on {Intelligent} {Systems}, {Automation} and {Control}},
	publisher = {Association for Computing Machinery},
	author = {Zhu, Jiazheng and Liang, Xiao and Xu, Jiannan and Zhang, Yingqiang and Zhang, Zhonghao and He, Kejia},
	year = {2025},
	keywords = {Agent framework, Chain-of-Thought, In-Context Learning, Large language models, Power knowledge question-answering},
	pages = {153--158},
}

@inproceedings{wang_wisdom_2024,
	address = {New York, NY, USA},
	series = {{MM} '24},
	title = {{WisdoM}: {Improving} {Multimodal} {Sentiment} {Analysis} by {Fusing} {Contextual} {World} {Knowledge}},
	isbn = {979-8-4007-0686-8},
	url = {https://doi.org/10.1145/3664647.3681403},
	doi = {10.1145/3664647.3681403},
	abstract = {Multimodal Sentiment Analysis (MSA) focuses on leveraging multimodal signals for understanding human sentiment. Most of the existing works rely on superficial information, neglecting the incorporation of contextual world knowledge (e.g., background information derived from but beyond the given image and text pairs), thereby restricting their ability to achieve better multimodal sentiment analysis (MSA). In this paper, we propose a plug-in framework named WisdoM, to leverage the contextual world knowledge induced from the large vision-language models (LVLMs) for enhanced MSA. WisdoM utilizes LVLMs to comprehensively analyze both images and corresponding texts, simultaneously generating pertinent context. Besides, to reduce the noise in the context, we design a training-free contextual fusion mechanism. We evaluate our WisdoM in both the aspect-level and sentence-level MSA tasks on the Twitter2015, Twitter2017, and MSED datasets. Experiments on three MSA benchmarks upon several advanced LVLMs, show that our approach brings consistent and significant improvements (up to +6.3\% F1 score). Code is available at https://github.com/DreamMr/WisdoM.},
	booktitle = {Proceedings of the 32nd {ACM} {International} {Conference} on {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Wenbin and Ding, Liang and Shen, Li and Luo, Yong and Hu, Han and Tao, Dacheng},
	year = {2024},
	note = {event-place: Melbourne VIC, Australia},
	keywords = {contextual fusion, contextual world knowledge, large vision-language model, multimodal sentiment analysis},
	pages = {2282--2291},
}

@inproceedings{kim_transdisciplinary_2025,
	address = {New York, NY, USA},
	series = {{ICETC} '24},
	title = {On {Transdisciplinary} {Research} through {Data} {Science} and {Engineering} {Education}},
	isbn = {979-8-4007-1781-9},
	url = {https://doi.org/10.1145/3702163.3702465},
	doi = {10.1145/3702163.3702465},
	abstract = {This paper explores the role of Data Science and Engineering (DSE) education in fostering transdisciplinary research and innovation. By combining data science’s analytical capabilities with the infrastructure-building focus of data engineering, DSE offers powerful tools for addressing complex challenges across diverse fields such as finance, agriculture, law, and engineering. However, researchers outside traditional DSE domains often lack the expertise to manage and leverage data effectively. To bridge this gap, we have developed four courses—data science, data engineering, advanced DSE, and vision AI—at the University of the District of Columbia, designed to equip students from various disciplines with the necessary skills to apply DSE techniques in their respective fields. This paper highlights the research conducted by students in these courses, emphasizing the importance of transdisciplinary collaboration in advancing scientific discovery and technological innovation.},
	booktitle = {Proceedings of the 2024 16th {International} {Conference} on {Education} {Technology} and {Computers}},
	publisher = {Association for Computing Machinery},
	author = {Kim, Junwhan},
	year = {2025},
	keywords = {Data Science and Engineering Education, Transdisciplinary Research},
	pages = {523--528},
}

@inproceedings{mridul_provakar_exploring_2025,
	address = {New York, NY, USA},
	series = {{ICCA} '24},
	title = {Exploring the {Effectiveness} of {Large} {Language} {Models} in {Financial} {Question} {Answering}},
	isbn = {979-8-4007-1382-8},
	url = {https://doi.org/10.1145/3723178.3723244},
	doi = {10.1145/3723178.3723244},
	abstract = {The financial sector is undergoing a profound transformation as AI technologies, particularly large language models (LLMs), revolutionize financial analysis through efficient and accurate natural language processing (NLP). This study investigates the efficacy of LLMs in addressing financial question-answering tasks, focusing specifically on two state-of-the-art models: Llama2-7b by Meta and Gemma-7b by Google. Despite their established prowess in general NLP tasks, their suitability for domain-specific applications, such as financial question answering, necessitates further exploration. Employing a comprehensive evaluation approach encompassing zero-shot prompt engineering, few-shot prompt engineering, and supervised fine-tuning methodologies, this study assesses the performance of Llama2 and Gemma using key metrics, including ROUGE-L, cosine similarity, and human evaluation. The preliminary findings reveal significant distinctions between the two models. Llama2 demonstrates a higher frequency of correct answers, but it is prone to hallucinations, often producing incorrect or incomplete information. In contrast, Gemma’s performance is notably inferior, struggling to respond accurately to most queries. These observations highlight the need for continued research to enhance LLMs’ ability to answer financial questions, while this study offers key insights into their strengths and weaknesses in managing financial inquiries.},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Computing} {Advancements}},
	publisher = {Association for Computing Machinery},
	author = {Mridul Provakar, Mondol and Hashi, Emrana Kabir},
	year = {2025},
	keywords = {Financial Question Answering, Fine-Tuning, Gemma, Large Language Models, Llama-2, Low-Rank-Adaptation, Prompt Engineering},
	pages = {498--505},
}

@inproceedings{gienapp_evaluating_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Evaluating {Generative} {Ad} {Hoc} {Information} {Retrieval}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657849},
	doi = {10.1145/3626772.3657849},
	abstract = {Recent advances in large language models have enabled the development of viable generative retrieval systems. Instead of a traditional document ranking, generative retrieval systems often directly return a grounded generated text as a response to a query. Quantifying the utility of the textual responses is essential for appropriately evaluating such generative ad hoc retrieval. Yet, the established evaluation methodology for ranking-based ad hoc retrieval is not suited for the reliable and reproducible evaluation of generated responses. To lay a foundation for developing new evaluation methods for generative retrieval systems, we survey the relevant literature from the fields of information retrieval and natural language processing, identify search tasks and system architectures in generative retrieval, develop a new user model, and study its operationalization.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Gienapp, Lukas and Scells, Harrisen and Deckers, Niklas and Bevendorff, Janek and Wang, Shuai and Kiesel, Johannes and Syed, Shahbaz and Fröbe, Maik and Zuccon, Guido and Stein, Benno and Hagen, Matthias and Potthast, Martin},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {ad hoc search, evaluation, generative information retrieval},
	pages = {1916--1929},
}

@inproceedings{liu_leveraging_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Leveraging {Passage} {Embeddings} for {Efficient} {Listwise} {Reranking} with {Large} {Language} {Models}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714554},
	doi = {10.1145/3696410.3714554},
	abstract = {Recent studies have demonstrated the effectiveness of using large language language models (LLMs) in passage ranking. The listwise approaches, such as RankGPT, have become new state-of-the-art in this task. However, the efficiency of RankGPT models is limited by the maximum context length and relatively high latency of LLM inference. To address these issues, in this paper, we propose PE-Rank, leveraging the single passage embedding as a good context compression for efficient listwise passage reranking. By treating each passage as a special token, we can directly input passage embeddings into LLMs, thereby reducing input length. Additionally, we introduce an inference method that dynamically constrains the decoding space to these special tokens, accelerating the decoding process. For adapting the model to reranking, we employ listwise learning to rank loss for training. Evaluation results on multiple benchmarks demonstrate that PE-Rank significantly improves efficiency in both prefilling and decoding, while maintaining competitive ranking effectiveness. The code is available at https://github.com/liuqi6777/pe\_rank},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Liu, Qi and Wang, Bo and Wang, Nan and Mao, Jiaxin},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {efficiency, large language models, reranking},
	pages = {4274--4283},
}

@inproceedings{chopra_challenges_2025,
	address = {New York, NY, USA},
	series = {{HILDA} '25},
	title = {Challenges in {Using} {Conversational} {AI} for {Data} {Science}},
	isbn = {979-8-4007-1959-2},
	url = {https://doi.org/10.1145/3736733.3736748},
	doi = {10.1145/3736733.3736748},
	abstract = {Large Language Models (LLMs) are transforming data science, offering assistance in coding, preprocessing, analysis, and decisionmaking. However, data scientists face significant challenges when interacting with LLM-powered agents and implementing their suggestions effectively. To explore these challenges, we conducted a mixed-methods study comprising contextual observations, semi-structured interviews (n=14), and a survey (n=114). Our findings reveal key obstacles, including difficulties in retrieving contextual data, crafting prompts for complex tasks, adapting generated code to local environments, and refining prompts iteratively. Based on these insights, we propose actionable design recommendations, such as data brushing for improved context selection and inquisitive feedback loops to enhance communication with conversational AI assistants in data science workflows.},
	booktitle = {Proceedings of the {Workshop} on {Human}-{In}-the-{Loop} {Data} {Analytics}},
	publisher = {Association for Computing Machinery},
	author = {Chopra, Bhavya and Singha, Ananya and Fariha, Anna and Gulwani, Sumit and Parnin, Chris and Tiwari, Ashish and Henley, Austin Z.},
	year = {2025},
	note = {event-place: Intercontinental Berlin, Berlin, Germany},
	keywords = {computational notebooks, data science, large language models},
}

@inproceedings{ryu_cinema_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Cinema {Multiverse} {Lounge}: {Enhancing} {Film} {Appreciation} via {Multi}-{Agent} {Conversations}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713641},
	doi = {10.1145/3706598.3713641},
	abstract = {Advancements in large language models (LLMs) enable the development of interactive systems that enhance user engagement with cinematic content. We introduce Cinema Multiverse Lounge, a multi-agent conversational system where users interact with LLM-based agents embodying diverse film-related personas. We investigate how user interactions with these agents influence their film appreciation. Thirty participants engaged in three discussion sessions, freely selecting persona agents such as film characters, filmmakers, or anonymous audiences. We explored how users composed different combinations of personas, the factors affecting their engagement and interpretation, and how diverse perspectives influenced film appreciation. Results indicate that interactions with varied agents enhanced participants’ appreciation by enabling the exploration of multiple viewpoints and fostering deeper narrative engagement. Moreover, the unexpected clashes between different worldviews added a fresh and enjoyable layer to the interactions. Our findings provide empirical insights and design implications for developing multi-agent systems that support enriched media consumption experiences.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ryu, Jeongwoo and Kim, Kyusik and Heo, Dongseok and Song, Hyungwoo and Oh, Changhoon and Suh, Bongwon},
	year = {2025},
	keywords = {Conversational AI, Film appreciation, Media consumption, Multi-agent systems, Parasocial relationship, User engagement, Virtual personas},
}

@inproceedings{al_haque_evolution_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {The {Evolution} of {Information} {Seeking} in {Software} {Development}: {Understanding} the {Role} and {Impact} of {AI} {Assistants}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3731665},
	doi = {10.1145/3696630.3731665},
	abstract = {About 32\% of a software practitioners' day involves seeking and using information to support task completion. Although the information needs of software practitioners have been studied extensively, the impact of AI-assisted tools on their needs and information-seeking behaviors remains largely unexplored. To addresses this gap, we conducted a mixed-method study to understand AI-assisted information seeking behavior of practitioners and its impact on their perceived productivity and skill development. We found that developers are increasingly using AI tools to support their information seeking, citing increased efficiency as a key benefit. Our findings also amplify caveats that come with effectively using AI tools for information seeking, especially for learning and skill development, such as the importance of foundational developer knowledge that can guide and inform the information provided by AI tools. Our efforts have implications for the effective integration of AI tools into developer workflows as information retrieval systems and learning aids.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Al Haque, Ebtesam and Brown, Chris and LaToza, Thomas D. and Johnson, Brittany},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {ai, developers, information seeking, mixed-methods study, productivity, skill building, software engineering},
	pages = {1494--1502},
}

@inproceedings{janaka_tom_2024,
	address = {New York, NY, USA},
	series = {{UbiComp} '24},
	title = {{TOM}: {A} {Development} {Platform} {For} {Wearable} {Intelligent} {Assistants}},
	isbn = {979-8-4007-1058-2},
	url = {https://doi.org/10.1145/3675094.3678382},
	doi = {10.1145/3675094.3678382},
	abstract = {Advanced wearable digital assistants can significantly enhance task performance, reduce user burden, and provide personalized guidance to improve users' abilities. However, developing these assistants presents several challenges. To address this, we introduce TOM (The Other Me), a conceptual architecture and open-source software platform (https://github.com/TOM-Platform) that supports the development of wearable intelligent assistants that are contextually aware of both the user and the environment. Collaboratively developed with researchers and developers, TOM meets their diverse requirements. TOM facilitates the creation of intelligent assistive AR applications for daily activities, supports the recording and analysis of user interactions, and provides assistance for various activities, as demonstrated in our preliminary evaluations.},
	booktitle = {Companion of the 2024 on {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Janaka, Nuwan and Zhao, Shengdong and Hsu, David and Tan Jing Wen, Sherisse and Koh, Chun Keat},
	year = {2024},
	note = {event-place: Melbourne VIC, Australia},
	keywords = {ai assistance, ai/ml, ar, augmented reality, context-aware system, hmd, interactions, mr, smart glasses, wearable, xr},
	pages = {837--843},
}

@inproceedings{liang_aligning_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {Aligning {Large} {Language} {Models} to a {Domain}-specific {Graph} {Database} for {NL2GQL}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3679713},
	doi = {10.1145/3627673.3679713},
	abstract = {Graph Databases (Graph DB) find extensive application across diverse domains such as finance, social networks, and medicine. Yet, the translation of Natural Language (NL) into the Graph Query Language (GQL), referred to as NL2GQL, poses significant challenges owing to its intricate and specialized nature. Some approaches have sought to utilize Large Language Models (LLMs) to address analogous tasks like text2SQL. Nonetheless, in the realm of NL2GQL tasks tailored to a particular domain, the absence of domain-specific NL-GQL data pairs adds complexity to aligning LLMs with the graph DB. To tackle this challenge, we present a well-defined pipeline. Initially, we use ChatGPT to generate NL-GQL data pairs, leveraging the provided graph DB and two mutual verification self-instruct methods which ensure consistency between NL and GQL. Subsequently, we employ the generated data to fine-tune LLMs, ensuring alignment between LLMs and the graph DB. Moreover, we find the importance of relevant schema in efficiently generating accurate GQLs. Thus, we introduce a method to extract relevant schema as the input context. We evaluate our method using two carefully constructed datasets derived from graph DBs in the finance and medicine domains, named FinGQL and MediGQL. Experimental results reveal that our approach significantly outperforms a set of baseline methods, with improvements of 5.90 and 6.36 absolute points on EM, and 6.00 and 7.09 absolute points on EX for FinGQL and MediGQL, respectively},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Liang, Yuanyuan and Tan, Keren and Xie, Tingyu and Tao, Wenbiao and Wang, Siyuan and Lan, Yunshi and Qian, Weining},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {graph databases, graph query language, large language models, natural language to graph query language},
	pages = {1367--1377},
}

@inproceedings{frank_designing_2025,
	address = {New York, NY, USA},
	series = {{ICEEL} '24},
	title = {Designing and {Operating} a {Low}-{Code} {Template} for {Class} {Delivery} and {Administration}: {Lessons} {Learned}},
	isbn = {979-8-4007-1741-3},
	url = {https://doi.org/10.1145/3719487.3719508},
	doi = {10.1145/3719487.3719508},
	abstract = {This paper describes the development, operation, and lessons learned from a low-code template designed for class delivery and administration. Built up over four years of highly-evaluated weekly online classes, the template has fostered increased student-teacher interaction, demonstrated the benefits of a database representation of contents, and underscored the importance of visual design. Additionally, it facilitated the incorporation of insights from online streaming as well as experimentation with the integration of AI capabilities. Key design elements include visually appealing layouts to streamline class flow and administration, the extensive use of icons and thumbnails, and Q\&amp;A banners for class feedback. This paper discusses the system development, challenges faced during implementation, and pathways for others to adapt a similar approach. In sharing both a template and the experiences, the goal is to offer signposts for others to deploy similar frameworks, in the pursuit of efficient, engaging, and adaptable classes, whether online or face-to-face.},
	booktitle = {Proceeding of the 2024 8th {International} {Conference} on {Education} and {E}-{Learning}},
	publisher = {Association for Computing Machinery},
	author = {Frank, Ian},
	year = {2025},
	keywords = {Digital transformation (DX), Engagement, Interfaces, Learning management systems},
	pages = {83--90},
}

@inproceedings{han_towards_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {Towards {Unobtrusive} {Physical} {AI}: {Augmenting} {Everyday} {Objects} with {Intelligence} and {Robotic} {Movement} for {Proactive} {Assistance}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747726},
	doi = {10.1145/3746059.3747726},
	abstract = {Users constantly interact with physical, most often passive, objects. Consider if familiar objects instead proactively assisted users, e.g., a stapler moving across the table to help users organize documents, or a knife moving away to prevent injury as the user is inattentively about to lean against the countertop. In this paper, we build on the qualities of tangible interaction and focus on recognizing user needs in everyday tasks to enable ubiquitous yet unobtrusive tangible interaction. To achieve this, we introduce an architecture that leverages large language models\&nbsp;(LLMs) to perceive users’ environment and activities, perform spatial-temporal reasoning, and generate object actions aligned with inferred user intentions and object properties. We demonstrate the system’s utility providing proactive assistance with multiple objects and in various daily scenarios. To evaluate our system components, we compare our system-generated output for user goal estimation and object action recommendation with human-annotated baselines, with results indicating good agreement.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Han, Violet Yinuo and Gonzalez, Jesse T and Yang, Christina and Wang, Zhiruo and Hudson, Scott E and Ion, Alexandra},
	year = {2025},
	keywords = {Agents, Human-AI Interaction, Intention Inference, Large Language Models, Physical AI, Proactive Human Robot Interaction, Robotic Objects, Tangible Interfaces},
}

@inproceedings{rzepka_effectiveness_2025,
	address = {New York, NY, USA},
	series = {{ICAAI} '24},
	title = {Effectiveness of {Security} {Export} {Control} {Ontology} for {Predicting} {Answer} {Type} and {Regulation} {Categories}},
	isbn = {979-8-4007-1801-4},
	url = {https://doi.org/10.1145/3704137.3704180},
	doi = {10.1145/3704137.3704180},
	abstract = {In this paper we present results of our experiments investigating if an expert knowledge graph can improve Large Language Models accuracy in predicting correct answer labels and regulations related to the topic of security export control. As the lack of related data prevents machine-learning or fine-tuning approaches, we implement prompt expansion by searching most relevant nodes of the graph and adding the expanded context to the prompt. Results of our experiments show that the addition improved answer type selection but clearly hamper the capability of finding a correct regulation category.},
	booktitle = {Proceedings of the 2024 8th {International} {Conference} on {Advances} in {Artificial} {Intelligence}},
	publisher = {Association for Computing Machinery},
	author = {Rzepka, Rafal and Obayashi, Akihiko},
	year = {2025},
	keywords = {Expert Systems, GraphRAG, Knowledge Graph, Large Language Models, Security Export Control},
	pages = {156--161},
}

@inproceedings{nelson_sensai_2025,
	address = {New York, NY, USA},
	series = {{SIGCSETS} 2025},
	title = {{SENSAI}: {Large} {Language} {Models} as {Applied} {Cybersecurity} {Tutors}},
	isbn = {979-8-4007-0531-1},
	url = {https://doi.org/10.1145/3641554.3701801},
	doi = {10.1145/3641554.3701801},
	abstract = {The modern educational landscape faces the challenge of maintaining effective, personalized mentorship amid expanding class sizes. This challenge is particularly pronounced in fields requiring hands-on practice, such as cybersecurity education. Teaching assistants and peer interactions provide some relief, but the student-to-educator ratio often remains high, limiting individualized attention. The advent of Large Language Models (LLMs) offers a promising solution by potentially providing scalable and personalized guidance. In this paper, we introduce SENSAI, an AI-powered tutoring system that leverages LLMs to offer tailored feedback and assistance by transparently extracting and utilizing the learner's working context, including their active terminals and edited files. Over the past year, SENSAI has been deployed in an applied cybersecurity curriculum at a large public R1 university and made available to a broader online community of global learners, assisting 2,742 users with hundreds of educational challenges. In total 178,074 messages were exchanged across 15,413 sessions, incurring a total cost of 1,979–comparable to that of a single undergraduate teaching assistant but with a significantly wider reach. SENSAI demonstrates significant improvements in student problem-solving efficiency and satisfaction, offering insights into the future role of AI in education.},
	booktitle = {Proceedings of the 56th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education} {V}. 1},
	publisher = {Association for Computing Machinery},
	author = {Nelson, Connor and Doupé, Adam and Shoshitaishvili, Yan},
	year = {2025},
	note = {event-place: Pittsburgh, PA, USA},
	keywords = {cybersecurity education, large language models, tutoring},
	pages = {833--839},
}

@inproceedings{zheng_humanevo_2025,
	address = {Ottawa, Ontario, Canada},
	series = {{ICSE} '25},
	title = {{HumanEvo}: {An} {Evolution}-{Aware} {Benchmark} for {More} {Realistic} {Evaluation} of {Repository}-{Level} {Code} {Generation}},
	isbn = {979-8-3315-0569-1},
	url = {https://doi.org/10.1109/ICSE55347.2025.00228},
	doi = {10.1109/ICSE55347.2025.00228},
	abstract = {To evaluate the repository-level code generation capabilities of Large Language Models (LLMs) in complex real-world software development scenarios, many evaluation methods have been developed. These methods typically leverage contextual code from the latest version of a project to assist LLMs in accurately generating the desired function. However, such evaluation methods fail to consider the dynamic evolution of software projects over time, which we refer to as evolution-ignored settings. This in turn results in inaccurate evaluation of LLMs' performance. In this paper, we conduct an empirical study to deeply understand LLMs' code generation performance within settings that reflect the evolution nature of software development. To achieve this, we first construct an evolution-aware repository-level code generation dataset, namely HumanEvo, equipped with an automated execution-based evaluation tool. Second, we manually categorize HumanEvo according to dependency levels to more comprehensively analyze the model's performance in generating functions with different dependency levels. Third, we conduct extensive experiments on HumanEvo with seven representative and diverse LLMs to verify the effectiveness of the proposed benchmark. We obtain several important findings through our experimental study. For example, we find that previous evolution-ignored evaluation methods result in inflated performance of LLMs, with performance overestimations ranging from 10.0\% to 61.1\% under different context acquisition methods, compared to the evolution-aware evaluation approach. Based on the findings, we give actionable suggestions for more realistic evaluation of LLMs on code generation. We also build a shared evolution-aware code generation toolbox to facilitate future research. The replication package including source code and datasets is anonymously available at https://github.com/DeepSoftwareAnalytics/HumanEvo.},
	booktitle = {Proceedings of the {IEEE}/{ACM} 47th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Zheng, Dewu and Wang, Yanlin and Shi, Ensheng and Zhang, Ruikai and Ma, Yuchi and Zhang, Hongyu and Zheng, Zibin},
	year = {2025},
	pages = {1372--1384},
}

@inproceedings{xiao_comparative_2024,
	address = {New York, NY, USA},
	series = {{CMNM} '24},
	title = {A {Comparative} {Review} of {Advanced} {Techniques} for {Financial} {Sentiment} {Analysis}},
	isbn = {979-8-4007-0976-0},
	url = {https://doi.org/10.1145/3677779.3677791},
	doi = {10.1145/3677779.3677791},
	abstract = {Financial sentiment analysis, the task of discerning market sentiment from financial texts, plays a crucial role in investment decisions, risk assessment, and understanding economic trends. Traditional sentiment analysis techniques have often faced limitations in handling the complexities and nuances of financial language. The advent of large language models (LLMs) has brought a paradigm shift in this field. With their remarkable ability to process and understand natural language, LLMs are enabling new approaches that increase the accuracy and sophistication of financial sentiment analysis. This paper provides a comparative overview of cutting-edge LLM-based techniques for financial sentiment analysis. We introduce a six-pronged classification framework covering data types, sentiment granularity, model architectures, training approaches, methodological focus, and evaluation metrics. This framework aims to provide a structured perspective for understanding recent research trends. Our analysis reveals several key developments in the field. We discuss the challenges and opportunities associated with advanced techniques, like Instruction-tuning approaches and Retrieval-augmented methods. While LLMs offer clear advantages, ensuring data quality, mitigating bias, enhancing model explainability, and scaling these models to real-world applications remain active research areas. This review offers investors and financial researchers a comprehensive guide to the evolving landscape of financial sentiment analysis, facilitating well-informed choices for different use cases and laying the groundwork for future research.},
	booktitle = {Proceedings of the {International} {Conference} on {Modeling}, {Natural} {Language} {Processing} and {Machine} {Learning}},
	publisher = {Association for Computing Machinery},
	author = {Xiao, Weizhen},
	year = {2024},
	note = {event-place: Xi'an, China},
	pages = {76--80},
}

@inproceedings{lin_jupiter_2025,
	address = {New York, NY, USA},
	series = {{EuroSys} '25},
	title = {Jupiter: {Pushing} {Speed} and {Scalability} {Limitations} for {Subgraph} {Matching} on {Multi}-{GPUs}},
	isbn = {979-8-4007-1196-1},
	url = {https://doi.org/10.1145/3689031.3717491},
	doi = {10.1145/3689031.3717491},
	abstract = {Graph pattern matching (GPM) aims to find subgraphs isomorphic to user-specified patterns within a large graph. Due to its ability to reveal potential relationships among entities in complex networks, it is widely applied in various fields, such as mining molecular structures in bioinformatics, detecting fraud in cloud-based e-commerce, and querying knowledge graphs in large language model. The explosion of data brought by the AI era has rendered traditional GPM systems inadequate for real-world needs. Due to the intricate data dependencies of GPM tasks, most SOTA GPM systems currently have limited scalability and performance, they perform well in small graph mining with single node but cannot scale to modern clusters with GPU acceleration. This paper introduces JUPITER, the first system capable of matching patterns on large graph across multi-node GPU clusters, which can handle graphs 10 times larger than SOTAs with the same memory resources. Its core principle is to delegate computation to the data-residing processing unit rather than pulling data to the computation location, which greatly improves communication efficiency. Experimental results show that JUPITER can reduce communication volume by two orders of magnitude compared to SOTA subgraph matching systems, achieving up to 120× speedup and an average of 21.5× speedup.},
	booktitle = {Proceedings of the {Twentieth} {European} {Conference} on {Computer} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Lin, Zhiheng and Meng, Ke and Xu, Changjie and Cao, Weichen and Tan, Guangming},
	year = {2025},
	note = {event-place: Rotterdam, Netherlands},
	keywords = {Delegation, GPU, Subgraph Matching},
	pages = {558--572},
}

@inproceedings{rajapakse_simple_2024,
	address = {New York, NY, USA},
	series = {{SIGIR}-{AP} 2024},
	title = {Simple {Transformers}: {Open}-source for {All}},
	isbn = {979-8-4007-0724-7},
	url = {https://doi.org/10.1145/3673791.3698412},
	doi = {10.1145/3673791.3698412},
	abstract = {Language technology, particularly information retrieval, is poised to have a profound impact on society. We believe that technology with such far-reaching potential should be accessible to everyone, not just the technologically privileged. Therefore, we advocate for open-source for all, ensuring that individuals from diverse research areas, societal sectors, and backgrounds have access to information retrieval and language technology tools with low barriers to entry. In this paper, we describe Simple Transformers, a library created with these goals in mind. It is designed to simplify the training, evaluation, and usage of transformer models. As of 2024, the library has garnered over 4,000 stars on GitHub and has been downloaded over 3 million times. These metrics reflect its wide acceptance and usage across different sectors. We describe the design and implementation of the library, provide examples of its usage and adoption, Finally, we also reflect on how Simple Transformers contributes to the goal of ”open-source for all.”},
	booktitle = {Proceedings of the 2024 {Annual} {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval} in the {Asia} {Pacific} {Region}},
	publisher = {Association for Computing Machinery},
	author = {Rajapakse, Thilina C. and Yates, Andrew and de Rijke, Maarten},
	year = {2024},
	note = {event-place: Tokyo, Japan},
	keywords = {open source information retrieval},
	pages = {209--215},
}

@inproceedings{lu_proof_2024,
	address = {New York, NY, USA},
	series = {{ASE} '24},
	title = {Proof {Automation} with {Large} {Language} {Models}},
	isbn = {979-8-4007-1248-7},
	url = {https://doi.org/10.1145/3691620.3695521},
	doi = {10.1145/3691620.3695521},
	abstract = {Interactive theorem provers such as Coq are powerful tools to formally guarantee the correctness of software. However, using these tools requires significant manual effort and expertise. While Large Language Models (LLMs) have shown promise in automatically generating informal proofs in natural language, they are less effective at generating formal proofs in interactive theorem provers. In this paper, we conduct a formative study to identify common mistakes made by LLMs when asked to generate formal proofs. By analyzing 520 proof generation errors made by GPT-3.5, we found that GPT-3.5 often identified the correct high-level structure of a proof, but struggled to get the lower-level details correct. Based on this insight, we propose PALM, a novel generate-then-repair approach that first prompts an LLM to generate an initial proof and then leverages targeted symbolic methods to iteratively repair low-level problems. We evaluate PALM on a large dataset that includes more than 10K theorems. Our results show that PALM significantly outperforms other state-of-the-art approaches, successfully proving 76.6\% to 180.4\% more theorems. Moreover, PALM proves 1270 theorems beyond the reach of existing approaches. We also demonstrate the generalizability of PALM across different LLMs.},
	booktitle = {Proceedings of the 39th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Lu, Minghai and Delaware, Benjamin and Zhang, Tianyi},
	year = {2024},
	note = {event-place: Sacramento, CA, USA},
	pages = {1509--1520},
}

@inproceedings{barile_lp-dixit_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{LP}-{DIXIT}: {Evaluating} {Explanations} for {Link} {Predictions} on {Knowledge} {Graphs} using {Large} {Language} {Models}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714667},
	doi = {10.1145/3696410.3714667},
	abstract = {Knowledge Graphs provide a machine-readable representation of knowledge conforming to graph-based data models. Link prediction methods predict missing facts in incomplete knowledge graphs, often using scalable embedding based solutions that, however, lack comprehensibility which is crucial in many domains. Filling this gap, explanation methods identify supporting knowledge. For evaluating them, user studies are the obvious choice as users are the main recipients of explanations. However, finding domain experts is often challenging. In contrast, an automated approach is to measure the influence of explanations on the very same link prediction task, thus disregarding the perspective of users. Additionally, current evaluation methods vary across different explanation approaches. We propose LP-DIXIT, the first protocol to evaluate the utility of explanations of link predictions. LP-DIXIT is user-aware, algorithmic and unique for different explanation methods. It builds on a typical setting of user studies, but adopts Large Language Models (LLMs) to mimic users. Specifically, it measures how explanations improve the user (LLM) ability to perform predictions, which is key to trust. We experimentally proved an overall agreement between LP-DIXIT and user evaluations. Moreover, we adopted LP-DIXIT to conduct a comparative study of state-of-the-art explanation methods. The outcomes suggest that less is more: the most effective explanations are those consisting of a single fact.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Barile, Roberto and d'Amato, Claudia and Fanizzi, Nicola},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {explanation, knowledge graphs, large language models, link prediction},
	pages = {4034--4042},
}

@inproceedings{jiang_scpatcher_2024,
	address = {Echternach, Luxembourg},
	series = {{ASE} '23},
	title = {{SCPatcher}: {Mining} {Crowd} {Security} {Discussions} to {Enrich} {Secure} {Coding} {Practices}},
	isbn = {979-8-3503-2996-4},
	url = {https://doi.org/10.1109/ASE56229.2023.00040},
	doi = {10.1109/ASE56229.2023.00040},
	abstract = {Secure coding practices (SCPs) have been proposed to guide software developers to write code securely to prevent potential security vulnerabilities. Yet, they are typically one-sentence principles without detailed specifications, e.g., "Properly free allocated memory upon the completion of functions and at all exit points.", which makes them difficult to follow in practice, especially for software developers who are not yet experienced in secure programming. To address this problem, this paper proposes SCPatcher, an automated approach to enrich secure coding practices by mining crowd security discussions on online knowledge-sharing platforms, such as Stack Overflow. In particular, for each security post, SCPatcher first extracts the area of coding examples and coding explanations with a fix-prompt tuned Large Language Model (LLM) via Prompt Learning. Then, it hierarchically slices the lengthy code into coding examples and summarizes the coding explanations with the areas. Finally, SCPatcher matches the CWE and Public SCP, integrating them with extracted coding examples and explanations to form the SCP specifications, which are the wild SCPs with details, proposed by the developers. To evaluate the performance of SCPatcher, we conduct experiments on 3,907 security posts from Stack Overflow. The experimental results show that SCPatcher outperforms all baselines in extracting the coding examples with 2.73\% MLine on average, as well as coding explanations with 3.97\% F1 on average. Moreover, we apply SCPatcher on 447 new security posts to further evaluate its practicality, and the extracted SCP specifications enrich the public SCPs with 3,074 lines of code and 1,967 sentences.},
	booktitle = {Proceedings of the 38th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Jiang, Ziyou and Shi, Lin and Yang, Guowei and Wang, Qing},
	year = {2024},
	pages = {358--370},
}

@inproceedings{yang_bee_2025,
	address = {New York, NY, USA},
	series = {{IVA} '25},
	title = {{BEE}: {Belief}-{Value}-{Aligned}, {Explainable}, and {Extensible} {Cognitive} {Framework} for {Conversational} {Agents}},
	isbn = {979-8-4007-1508-2},
	url = {https://doi.org/10.1145/3717511.3747067},
	doi = {10.1145/3717511.3747067},
	abstract = {Recent advances in large language models have enabled virtual agents to exhibit increasingly believable social behaviors. However, creating social agents that remain consistent with a defined profile and explain their reasoning remains challenging. We introduce a cognitive framework designed to address these gaps. Our framework features a graph-based memory module (concept pool) and a decision-making process inspired by human cognition. The concept pool contains an agent’s beliefs, values, and background stories for context-dependent retrieval. The decision-making process uses the concept pool to produce belief-value aligned responses of the virtual agent and intuitive, human-readable explanations of the reasoning. To evaluate the effectiveness of our framework, we created two virtual agents based on historical figures and compared them to baseline agents. Our evaluation combined quantitative assessments of belief-value alignment with a user study (n=48) examining explainable agency. Results show that our framework exhibits model-agnostic improved belief-value alignment and produces more detailed, relevant, and understandable explanations. By grounding virtual agent behavior in structured memories and cognitive principles, our framework offers a compelling step toward more coherent and socially intelligent virtual agents.},
	booktitle = {Proceedings of the 25th {ACM} {International} {Conference} on {Intelligent} {Virtual} {Agents}},
	publisher = {Association for Computing Machinery},
	author = {Yang, Chen and Gross, Markus and Wampfler, Rafael},
	year = {2025},
	keywords = {Belief-value Alignment, Cognitive Framework, Explainable Agents, Human-Agent Interaction, Social Agents},
}

@inproceedings{fan_lessonplanner_2024,
	address = {New York, NY, USA},
	series = {{UIST} '24},
	title = {{LessonPlanner}: {Assisting} {Novice} {Teachers} to {Prepare} {Pedagogy}-{Driven} {Lesson} {Plans} with {Large} {Language} {Models}},
	isbn = {979-8-4007-0628-8},
	url = {https://doi.org/10.1145/3654777.3676390},
	doi = {10.1145/3654777.3676390},
	abstract = {Preparing a lesson plan, e.g., a detailed road map with strategies and materials for instructing a 90-minute class, is beneficial yet challenging for novice teachers. Large language models (LLMs) can ease this process by generating adaptive content for lesson plans, which would otherwise require teachers to create from scratch or search existing resources. In this work, we first conduct a formative study with six novice teachers to understand their needs for support of preparing lesson plans with LLMs. Then, we develop LessonPlanner that assists users to interactively construct lesson plans with adaptive LLM-generated content based on Gagne’s nine events. Our within-subjects study (N = 12) shows that compared to the baseline ChatGPT interface, LessonPlanner can significantly improve the quality of outcome lesson plans and ease users’ workload in the preparation process. Our expert interviews (N = 6) further demonstrate LessonPlanner ’s usefulness in suggesting effective teaching strategies and meaningful educational resources. We discuss concerns on and design considerations for supporting teaching activities with LLMs.},
	booktitle = {Proceedings of the 37th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Fan, Haoxiang and Chen, Guanzheng and Wang, Xingbo and Peng, Zhenhui},
	year = {2024},
	note = {event-place: Pittsburgh, PA, USA},
	keywords = {Large language models, lesson plan preparation, pedagogy-driven system},
}

@inproceedings{akyash_evolutionary_2024,
	address = {New York, NY, USA},
	series = {{GLSVLSI} '24},
	title = {Evolutionary {Large} {Language} {Models} for {Hardware} {Security}: {A} {Comparative} {Survey}},
	isbn = {979-8-4007-0605-9},
	url = {https://doi.org/10.1145/3649476.3660390},
	doi = {10.1145/3649476.3660390},
	abstract = {Automating hardware (HW) security vulnerability detection and mitigation during the design phase is imperative for two reasons: (i) It must be before chip fabrication, as post-fabrication fixes can be costly or even impractical; (ii) The size and complexity of modern HW raise concerns about unknown vulnerabilities compromising CIA triad. While Large Language Models (LLMs) can revolutionize both HW design and testing processes, within the semiconductor context, LLMs can be harnessed to automatically rectify security-relevant vulnerabilities inherent in HW designs. This study explores the seeds of LLM integration in register transfer level (RTL) designs, focusing on their capacity for autonomously resolving security-related vulnerabilities. The analysis involves comparing methodologies, assessing scalability, interpretability, and identifying future research directions. Potential areas for exploration include developing specialized LLM architectures for HW security tasks and enhancing model performance with domain-specific knowledge, leading to reliable automated security measurement and risk mitigation associated with HW vulnerabilities.},
	booktitle = {Proceedings of the {Great} {Lakes} {Symposium} on {VLSI} 2024},
	publisher = {Association for Computing Machinery},
	author = {Akyash, Mohammad and M Kamali, Hadi},
	year = {2024},
	note = {event-place: Clearwater, FL, USA},
	keywords = {Hardware Security, Large Language Models, RTL Debugging},
	pages = {496--501},
}

@inproceedings{hoeber_design_2025,
	address = {New York, NY, USA},
	series = {{CHIIR} '25},
	title = {Design {Principles} for {Exploratory} {Search} {Interfaces}},
	isbn = {979-8-4007-1290-6},
	url = {https://doi.org/10.1145/3698204.3716443},
	doi = {10.1145/3698204.3716443},
	abstract = {Exploratory search has been proposed as a model of search behaviour that is well suited to complex search scenarios. However, the simple interfaces that are commonplace across many search contexts limit the ability for searchers to undertake exploratory searches. Little support is provided for the discovery, learning, and investigation necessary for exploratory browsing, or the query (re)formulation, result examination, and information extraction required for focused searching. While the design and study of search interfaces that accommodate and support searchers in undertaking exploratory searches has increased in recent years, much of this work has been ad hoc in nature. In this perspective paper, five search interface design principles are presented that are specifically tuned to support exploratory search. An extension of the classical heuristic evaluation method is provided to support the inspection of prototype search interfaces with respect to the design principles. Recent research in the field is categorized according to these design principles. Patterns and gaps in the literature are identified, highlighting opportunities for further research on exploratory search interfaces. These principles provide a framework to guide the design and inspection of future search interfaces to support exploratory search, as well as a mechanism for comparing and contrasting the interactive information retrieval literature as it relates to supporting exploratory search through novel interface design.},
	booktitle = {Proceedings of the 2025 {ACM} {SIGIR} {Conference} on {Human} {Information} {Interaction} and {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Hoeber, Orland},
	year = {2025},
	keywords = {design principles, exploratory search, heuristic evaluations, scoping review, search user interfaces},
	pages = {12--22},
}

@inproceedings{zhong_comapoi_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{CoMaPOI}: {A} {Collaborative} {Multi}-{Agent} {Framework} for {Next} {POI} {Prediction} {Bridging} the {Gap} {Between} {Trajectory} and {Language}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3729930},
	doi = {10.1145/3726302.3729930},
	abstract = {Large Language Models (LLMs) offer new opportunities for the next Point-Of-Interest (POI) prediction task, leveraging their capabilities in semantic understanding of POI trajectories. However, previous LLM-based methods, which are superficially adapted to next POI prediction, largely overlook critical challenges associated with applying LLMs to this task. Specifically, LLMs encounter two critical challenges: (1) a lack of intrinsic understanding of numeric spatiotemporal data, which hinders accurate modeling of users' spatiotemporal distributions and preferences; and (2) an excessively large and unconstrained candidate POI space, which often results in random or irrelevant predictions. To address these issues, we propose a Collaborative Multi-Agent Framework for Next POI Prediction, named CoMaPOI. Through the close interaction of three specialized agents (Profiler, Forecaster, and Predictor), CoMaPOI collaboratively addresses the two critical challenges. The Profiler agent is responsible for converting numeric data into language descriptions, enhancing semantic understanding. The Forecaster agent focuses on dynamically constraining and refining the candidate POI space. The Predictor agent integrates this information to generate high-precision predictions. Extensive experiments on three benchmark datasets (NYC, TKY, and CA) demonstrate that CoMaPOI achieves state-of-the-art performance, improving all metrics by 5\% to 10\% compared to SOTA baselines. This work pioneers the investigation of challenges associated with applying LLMs to complex spatiotemporal tasks by leveraging tailored collaborative agents. Our source code is available at: https://github.com/Chips98/CoMaPOI.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zhong, Lin and Wang, Lingzhi and Yang, Xu and Liao, Qing},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {large language models, multi-agent collaboration, point-of-interest prediction, spatiotemporal modeling},
	pages = {1768--1778},
}

@inproceedings{liu_selenite_2024,
	address = {New York, NY, USA},
	series = {{CHI} '24},
	title = {Selenite: {Scaffolding} {Online} {Sensemaking} with {Comprehensive} {Overviews} {Elicited} from {Large} {Language} {Models}},
	isbn = {979-8-4007-0330-0},
	url = {https://doi.org/10.1145/3613904.3642149},
	doi = {10.1145/3613904.3642149},
	abstract = {Sensemaking in unfamiliar domains can be challenging, demanding considerable user effort to compare different options with respect to various criteria. Prior research and our formative study found that people would benefit from reading an overview of an information space upfront, including the criteria others previously found useful. However, existing sensemaking tools struggle with the “cold-start” problem — it not only requires significant input from previous users to generate and share these overviews, but such overviews may also turn out to be biased and incomplete. In this work, we introduce a novel system, Selenite, which leverages Large Language Models (LLMs) as reasoning machines and knowledge retrievers to automatically produce a comprehensive overview of options and criteria to jumpstart users’ sensemaking processes. Subsequently, Selenite also adapts as people use it, helping users find, read, and navigate unfamiliar information in a systematic yet personalized manner. Through three studies, we found that Selenite produced accurate and high-quality overviews reliably, significantly accelerated users’ information processing, and effectively improved their overall comprehension and sensemaking experience.},
	booktitle = {Proceedings of the 2024 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Michael Xieyang and Wu, Tongshuang and Chen, Tianying and Li, Franklin Mingzhe and Kittur, Aniket and Myers, Brad A},
	year = {2024},
	note = {event-place: Honolulu, HI, USA},
	keywords = {Human-AI Collaboration, Large Language Models, Natural Language Processing, Sensemaking},
}

@inproceedings{dinu_evaluating_2025,
	address = {New York, NY, USA},
	series = {{PETRA} '25},
	title = {Evaluating {Large} {Language} {Models}’ ability to pastiche literary texts},
	isbn = {979-8-4007-1402-3},
	url = {https://doi.org/10.1145/3733155.3734912},
	doi = {10.1145/3733155.3734912},
	abstract = {This research investigates the ability of Large Language Models (LLMs) to pastiche the literary style of a professional writer.We asked six LLMs to pastiche literary works of 20th-century Romanian authors Mateiu Caragiale and Radu Albala. This task is presumably more complex than imitating the writing style in a contemporary language and a highly resourced language like English.For evaluation, we used standard evaluation metrics (ROUGE, BLUE, METEOR, Diversity, and Perplexity) and linguistic features (extracted with Linguistic Inquiry and Word Count).We compared the quality of the pastiches produced by the LLMs for the two authors, to see if their performance is consistent across different authors. The computational analysis showed that LLMs are able to produce fairly good quality pastiches that could pass for human production, regardless of the author they imitate. However, the manual analysis revealed that, in the case of Albala, the best performing two models, Llama and Qwen, achieved highly similar scores to the originals due to copy-pasting entire paragraphs.},
	booktitle = {Proceedings of the 18th {ACM} {International} {Conference} on {PErvasive} {Technologies} {Related} to {Assistive} {Environments}},
	publisher = {Association for Computing Machinery},
	author = {Dinu, Anca and Florescu, Andra-Maria and Dinu, Liviu P.},
	year = {2025},
	keywords = {Large Language Models, pastiche, stylometry},
	pages = {450--457},
}

@inproceedings{rachabatuni_context-aware_2024,
	address = {New York, NY, USA},
	series = {{MMSys} '24},
	title = {Context-aware chatbot using {MLLMs} for {Cultural} {Heritage}},
	isbn = {979-8-4007-0412-3},
	url = {https://doi.org/10.1145/3625468.3652193},
	doi = {10.1145/3625468.3652193},
	abstract = {Multi-modal Large Language Models (MLLMs) are currently an extremely active research topic for the multimedia and computer vision communities, and show a significant impact in visual analysis and text generation tasks. MLLM's are well-versed in integrated understanding, analysis of complex data from cross modalities (i.e. text-image) and text generation with chat abilities. Almost all MLLM's, focus on alignment of image features to textual features for downstream text generation tasks includes detailed image description, visual question answering, stories and poems generation, phrase grounding, etc.. However, when focusing on visual question answering, questions that are highly relevant to the context of an image may not be answered correctly with the existing MLLM's, contrary to questions that are related to visual aspects. Moreover, generating meta data (context) for an image using present day MLLM's is hard task due to hallucinating characteristic of underlying Large Language Models (LLM's), and adequate contextual information cannot be directly derived from an image based perspective.Considering the cultural heritage domain, these issues hamper the introduction of multimedia chatbots as tools to support learning and understanding artworks, since contextual information is typically needed to better understand the content of the artworks themselves, and museum curators require that scientifically accurate information is provided to the users of such systems. In this paper we present a system that combines contextual description of the artworks to enhance the contextual visual question answering task.},
	booktitle = {Proceedings of the 15th {ACM} {Multimedia} {Systems} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Rachabatuni, Pavan Kartheek and Principi, Filippo and Mazzanti, Paolo and Bertini, Marco},
	year = {2024},
	note = {event-place: Bari, Italy},
	keywords = {Chatbot, Cultural Heritage, Digital Learning, Museums, Visual Question Answering},
	pages = {459--463},
}

@inproceedings{mickens_guillotine_2025,
	address = {New York, NY, USA},
	series = {{HotOS} '25},
	title = {Guillotine: {Hypervisors} for {Isolating} {Malicious} {AIs}},
	isbn = {979-8-4007-1475-7},
	url = {https://doi.org/10.1145/3713082.3730391},
	doi = {10.1145/3713082.3730391},
	abstract = {As AI models become more embedded in critical sectors like finance, healthcare, and the military, their inscrutable behavior poses ever-greater risks to society. To mitigate this risk, we propose Guillotine, a hypervisor architecture for sandboxing powerful AI models—models that, by accident or malice, can generate existential threats to humanity. Although Guillotine borrows some well-known virtualization techniques, Guillotine must also introduce fundamentally new isolation mechanisms to handle the unique threat model posed by existential-risk AIs. For example, a rogue AI may try to introspect upon hypervisor software or the underlying hardware substrate to enable later subversion of that control plane; thus, a Guillotine hypervisor requires careful co-design of the hypervisor software and the CPUs, RAM, NIC, and storage devices that support the hypervisor software, to thwart side channel leakage and more generally eliminate mechanisms for AI to exploit reflection-based vulnerabilities. Beyond such isolation at the software, network, and microarchitectural layers, a Guillotine hypervisor must also provide physical fail-safes more commonly associated with nuclear power plants, avionic platforms, and other types of mission-critical systems. Physical fail-safes, e.g., involving electromechanical disconnection of network cables, or the flooding of a datacenter which holds a rogue AI, provide defense in depth if software, network, and microarchitectural isolation is compromised and a rogue AI must be temporarily shut down or permanently destroyed.},
	booktitle = {Proceedings of the 2025 {Workshop} on {Hot} {Topics} in {Operating} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Mickens, James and Radway, Sarah and Netravali, Ravi},
	year = {2025},
	note = {event-place: Banff, AB, Canada},
	pages = {18--26},
}

@inproceedings{huo_retrieving_2023,
	address = {New York, NY, USA},
	series = {{SIGIR}-{AP} '23},
	title = {Retrieving {Supporting} {Evidence} for {Generative} {Question} {Answering}},
	isbn = {979-8-4007-0408-6},
	url = {https://doi.org/10.1145/3624918.3625336},
	doi = {10.1145/3624918.3625336},
	abstract = {Current large language models (LLMs) can exhibit near-human levels of performance on many natural language-based tasks, including open-domain question answering. Unfortunately, at this time, they also convincingly hallucinate incorrect answers, so that responses to questions must be verified against external sources before they can be accepted at face value. In this paper, we report two simple experiments to automatically validate generated answers against a corpus. We base our experiments on questions and passages from the MS MARCO (V1) test collection, and a retrieval pipeline consisting of sparse retrieval, dense retrieval and neural rerankers. In the first experiment, we validate the generated answer in its entirety. After presenting a question to an LLM and receiving a generated answer, we query the corpus with the combination of the question + generated answer. We then present the LLM with the combination of the question + generated answer + retrieved answer, prompting it to indicate if the generated answer can be supported by the retrieved answer. In the second experiment, we consider the generated answer at a more granular level, prompting the LLM to extract a list of factual statements from the answer and verifying each statement separately. We query the corpus with each factual statement and then present the LLM with the statement and the corresponding retrieved evidence. The LLM is prompted to indicate if the statement can be supported and make necessary edits using the retrieved material. With an accuracy of over 80\%, we find that an LLM is capable of verifying its generated answer when a corpus of supporting material is provided. However, manual assessment of a random sample of questions reveals that incorrect generated answers are missed by this verification process. While this verification process can reduce hallucinations, it can not entirely eliminate them.},
	booktitle = {Proceedings of the {Annual} {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval} in the {Asia} {Pacific} {Region}},
	publisher = {Association for Computing Machinery},
	author = {Huo, Siqing and Arabzadeh, Negar and Clarke, Charles},
	year = {2023},
	note = {event-place: Beijing, China},
	pages = {11--20},
}

@inproceedings{chen_empowering_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {Empowering {Private} {Tutoring} by {Chaining} {Large} {Language} {Models}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3679665},
	doi = {10.1145/3627673.3679665},
	abstract = {Artificial intelligence has been applied in various aspects of online education to facilitate teaching and learning. However, few approaches have been made towards a complete AI-powered tutoring system. In this work, we explore the development of a full-fledged intelligent tutoring system based on large language models (LLMs). The proposed system ChatTutor, powered by state-of-the-art LLMs, is equipped with automatic course planning and adjusting, informative instruction, and adaptive quiz offering and evaluation. ChatTutor is decomposed into three inter-connected core processes: interaction, reflection, and reaction. Each process is implemented by chaining LLM-powered tools along with dynamically updated memory modules. To demonstrate the mechanism of each working module and the benefits of structured memory control and adaptive reflection, we conduct a wide range of analysis based on statistical results and user study. The analysis shows the designed processes boost system consistency and stability under long-term interaction and intentional disruptions, with up to 5\% and 20\% increase in performance respectively. Meanwhile, we also compare the system with scripts from real-world online learning platform and discuss the potential issues unique to LLM-based systems.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Yulin and Ding, Ning and Zheng, Hai-Tao and Liu, Zhiyuan and Sun, Maosong and Zhou, Bowen},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {adaptive reflection, intelligent tutoring system, large language models, memory mechanism},
	pages = {354--364},
}

@inproceedings{paul_tasca_2025,
	address = {New York, NY, USA},
	series = {{AIMLSystems} '24},
	title = {{TASCA}++ : {A} multi-agentic tool to scalably accelerate {ML} pipelines},
	isbn = {979-8-4007-1161-9},
	url = {https://doi.org/10.1145/3703412.3703437},
	doi = {10.1145/3703412.3703437},
	abstract = {In the evolving landscape of machine learning (ML) and deep learning (DL), automatic optimization of these pipelines are crucial, especially with growing data volumes.Our tool TASCA\&nbsp;[2], an enhanced tool that leverages advanced Large Language Models (LLMs) like GPTNeo3.5/4 to automatically detect and transform performance anti-patterns in ML pipelines without human intervention. Building on our previous work with TASCA\&nbsp;[2], TASCA++ extends the capabilities of its predecessor by incorporating new features that improve detection accuracy and transformation efficiency, resulting in much better optimization. Our empirical evaluation on multiple real-world workloads demonstrates significant performance gains. TASCA++ represents a significant step forward in automated ML pipeline optimization, reducing computational overheads and enhancing scalability.},
	booktitle = {Proceedings of the 4th {International} {Conference} on {AI}-{ML} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Paul, Bibek and Bhowmick, Archisman and Mishra, Mayank and Gupta, Sarthak and Singhal, Rekha},
	year = {2025},
	keywords = {Code Acceleration, ML Pipeline, Multi-Agents, Scalability Bottlenecks},
}

@inproceedings{mazhar_figurative-cum-commonsense_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Figurative-cum-{Commonsense} {Knowledge} {Infusion} for {Multimodal} {Mental} {Health} {Meme} {Classification}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714778},
	doi = {10.1145/3696410.3714778},
	abstract = {The expression of mental health symptoms through non-traditional means, such as memes, has gained remarkable attention over the past few years, with users often highlighting their mental health struggles through figurative intricacies within memes. While humans rely on commonsense knowledge to interpret these complex expressions, current Multimodal Language Models (MLMs) struggle to capture these figurative aspects inherent in memes. To address this gap, we introduce a novel dataset, AxiOM, derived from the GAD anxiety questionnaire, which categorizes memes into six fine-grained anxiety symptoms. Next, we propose a commonsense and domain-enriched framework, M3H, to enhance MLMs' ability to interpret figurative language and commonsense knowledge. The overarching goal remains to first understand and then classify the mental health symptoms expressed in memes. We benchmark M3H against 6 competitive baselines (with 20 variations), demonstrating improvements in both quantitative and qualitative metrics, including a detailed human evaluation. We observe a clear improvement of 4.20\% and 4.66\% on weighted-F1 metric. To assess the generalizability, we perform extensive experiments on a public dataset, RESTORE, for depressive symptom identification, presenting an ablation study that highlights the contribution of each module. Our findings reveal limitations in existing models and the advantage of employing commonsense to enhance figurative understanding.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Mazhar, Abdullah and Shaik, Zuhair Hasan and Srivastava, Aseem and Ruhnke, Polly and Vaddavalli, Lavanya and Katragadda, Sri Keshav and Yadav, Shweta and Akhtar, Md Shad},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {memes, multimodality, natural language processing},
	pages = {637--648},
}

@inproceedings{heinrich_systematic_2025,
	address = {New York, NY, USA},
	series = {{ICMI} '25},
	title = {A {Systematic} {Review} of {Fusion} {Methods} for the {User}-{Centered} {Design} of {Multimodal} {Interfaces}},
	isbn = {979-8-4007-1499-3},
	url = {https://doi.org/10.1145/3716553.3750790},
	doi = {10.1145/3716553.3750790},
	abstract = {This systematic review investigates the current state of research on multimodal fusion methods, i.e., the joint analysis of multimodal inputs, for intentional, instruction-based human-computer interactions, focusing on the combination of speech and spatially expressive modalities such as gestures, touch, pen, and gaze. We examine 50 systems from a User-Centered Design perspective, categorizing them by modality combinations, fusion strategies, application domains and media, as well as reusability. Our findings highlight a predominance of descriptive late fusion methods, limited reusability, and a lack of standardized tool support, hampering rapid prototyping and broader applicability. We identify emerging trends in machine learning-based fusion and outline future research directions to advance reusable and user-centered multimodal systems.},
	booktitle = {Proceedings of the 27th {International} {Conference} on {Multimodal} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Heinrich, Ronja and Zimmerer, Chris and Fischbach, Martin and Erich Latoschik, Marc},
	year = {2025},
	keywords = {human-computer interaction, intentional, machine learning, multimodal fusion, multimodal interfaces, user-centered design},
	pages = {485--495},
}

@inproceedings{zhao_aligning_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {Aligning {Explanations} for {Recommendation} with {Rating} and {Feature} via {Maximizing} {Mutual} {Information}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3679663},
	doi = {10.1145/3627673.3679663},
	abstract = {Providing natural language-based explanations to justify recommendations helps to improve users' satisfaction and gain users' trust. However, as current explanation generation methods are commonly trained with an objective to mimic existing user reviews, the generated explanations are often not aligned with the predicted ratings or some important features of the recommended items, and thus, are suboptimal in helping users make informed decision on the recommendation platform. To tackle this problem, we propose a flexible model-agnostic method named MMI (Maximizing Mutual Information) framework to enhance the alignment between the generated natural language explanations and the predicted rating/important item features. Specifically, we propose to use mutual information (MI) as a measure for the alignment and train a neural MI estimator. Then, we treat a well-trained explanation generation model as the backbone model and further fine-tune it through reinforcement learning with guidance from the MI estimator, which rewards a generated explanation that is more aligned with the predicted rating or a pre-defined feature of the recommended item. Experiments on three datasets demonstrate that our MMI framework can boost different backbone models, enabling them to outperform existing baselines in terms of alignment with predicted ratings and item features. Additionally, user studies verify that MI-enhanced explanations indeed facilitate users' decisions and are favorable compared with other baselines due to their better alignment properties.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Zhao, Yurou and Sun, Yiding and Han, Ruidong and Jiang, Fei and Guan, Lu and Li, Xiang and Lin, Wei and Ma, Weizhi and Mao, Jiaxin},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {alignment with rating and feature, explainable recommendation, maximizing mutual information, natural language-based explanation},
	pages = {3374--3383},
}

@inproceedings{yen_coladder_2024,
	address = {New York, NY, USA},
	series = {{UIST} '24},
	title = {{CoLadder}: {Manipulating} {Code} {Generation} via {Multi}-{Level} {Blocks}},
	isbn = {979-8-4007-0628-8},
	url = {https://doi.org/10.1145/3654777.3676357},
	doi = {10.1145/3654777.3676357},
	abstract = {This paper adopted an iterative design process to gain insights into programmers’ strategies when using LLMs for programming. We proposed CoLadder, a novel system that supports programmers by facilitating hierarchical task decomposition, direct code segment manipulation, and result evaluation during prompt authoring. A user study with 12 experienced programmers showed that CoLadder is effective in helping programmers externalize their problem-solving intentions flexibly, improving their ability to evaluate and modify code across various abstraction levels, from their task’s goal to final code implementation.},
	booktitle = {Proceedings of the 37th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Yen, Ryan and Zhu, Jiawen Stefanie and Suh, Sangho and Xia, Haijun and Zhao, Jian},
	year = {2024},
	note = {event-place: Pittsburgh, PA, USA},
	keywords = {Code Generation, Dynamic Abstraction, Programming Interface},
}

@inproceedings{woo_scalepool_2025,
	address = {New York, NY, USA},
	series = {{DIMES} '25},
	title = {{ScalePool}: {Hybrid} {XLink}-{CXL} {Fabric} for {Composable} {Resource} {Disaggregation} in {Unified} {Scale}-up {Domains}},
	isbn = {979-8-4007-2226-4},
	url = {https://doi.org/10.1145/3764862.3768173},
	doi = {10.1145/3764862.3768173},
	abstract = {This paper proposes ScalePool, a novel cluster architecture designed to interconnect numerous accelerators using unified hardware interconnects rather than traditional long-distance networking. ScalePool integrates Accelerator-Centric Links (XLink) and Compute Express Link (CXL) into a unified XLink-CXL hybrid fabric. Specifically, ScalePool employs XLink for intra-cluster, low-latency accelerator communication, while using hierarchical CXL-based switching fabrics for scalable and coherent inter-cluster memory sharing. By abstracting interfaces through CXL, ScalePool structurally resolves interoperability constraints, enabling heterogeneous cluster operation and composable resource disaggregation.In addition, ScalePool introduces explicit memory tiering: the latency-critical tier-1 combines accelerator-local memory with coherence-centric CXL and XLink, whereas the high-capacity tier-2 employs dedicated memory nodes interconnected by a CXL-based fabric, achieving scalable and efficient memory pooling. Evaluation results show that ScalePool accelerates LLM training by 1.22× on average and up to 1.84× compared to conventional RDMA-based environments. Furthermore, the proposed tier-2 memory disaggregation strategy reduces latency by up to 4.5× for memory-intensive workloads.},
	booktitle = {Proceedings of the 3rd {Workshop} on {Disruptive} {Memory} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Woo, Hyein and Kwon, Miryeong and Kim, Jiseon and Na, Eunjee and Choi, Hanjin and Jang, Seonghyeon and Jung, Myoungsoo},
	year = {2025},
	note = {event-place: Seoul, Republic of Korea},
	keywords = {Accelerator-Centric Link, CXL, Resource Disaggregation},
	pages = {10--18},
}

@inproceedings{hassan_rethinking_2024,
	address = {New York, NY, USA},
	series = {{FSE} 2024},
	title = {Rethinking {Software} {Engineering} in the {Era} of {Foundation} {Models}: {A} {Curated} {Catalogue} of {Challenges} in the {Development} of {Trustworthy} {FMware}},
	isbn = {979-8-4007-0658-5},
	url = {https://doi.org/10.1145/3663529.3663849},
	doi = {10.1145/3663529.3663849},
	abstract = {Foundation models (FMs), such as Large Language Models (LLMs), have revolutionized software development by enabling new use cases and business models. We refer to software built using FMs as FMware. The unique properties of FMware (e.g., prompts, agents and the need for orchestration), coupled with the intrinsic limitations of FMs (e.g., hallucination) lead to a completely new set of software engineering challenges. Based on our industrial experience, we identified ten key SE4FMware challenges that have caused enterprise FMware development to be unproductive, costly, and risky. For each of those challenges, we state the path for innovation that we envision. We hope that the disclosure of the challenges will not only raise awareness but also promote deeper and further discussions, knowledge sharing, and innovative solutions.},
	booktitle = {Companion {Proceedings} of the 32nd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Hassan, Ahmed E. and Lin, Dayi and Rajbahadur, Gopi Krishnan and Gallaba, Keheliya and Cogo, Filipe Roseiro and Chen, Boyuan and Zhang, Haoxiang and Thangarajah, Kishanthan and Oliva, Gustavo and Lin, Jiahuei (Justina) and Abdullah, Wali Mohammad and Jiang, Zhen Ming (Jack)},
	year = {2024},
	note = {event-place: Porto de Galinhas, Brazil},
	keywords = {AIware, FMware, Foundation models, Large Language Models},
	pages = {294--305},
}

@inproceedings{dietz_workbench_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {A {Workbench} for {Autograding} {Retrieve}/{Generate} {Systems}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657871},
	doi = {10.1145/3626772.3657871},
	abstract = {This resource paper addresses the challenge of evaluating Information Retrieval (IR) systems in the era of autoregressive Large Language Models (LLMs). Traditional methods relying on passage-level judgments are no longer effective due to the diversity of responses generated by LLM-based systems. We provide a workbench to explore several alternative evaluation approaches to judge the relevance of a system's response that incorporate LLMs: 1. Asking an LLM whether the response is relevant; 2. Asking the LLM which set of nuggets (i.e., relevant key facts) is covered in the response; 3. Asking the LLM to answer a set of exam questions with the response. This workbench aims to facilitate the development of new, reusable test collections. Researchers can manually refine sets of nuggets and exam questions, observing their impact on system evaluation and leaderboard rankings. Resource available at https://github.com/TREMA-UNH/rubric-grading-workbench},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Dietz, Laura},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {information retrieval evaluation, large language mmodels},
	pages = {1963--1972},
}

@inproceedings{zhou_research_2024,
	address = {New York, NY, USA},
	series = {{ICDEL} '24},
	title = {Research on the {Application} of {WAgent} in {English} {Writing} {Teaching} {Based} on {AI} {Models}},
	isbn = {979-8-4007-1680-5},
	url = {https://doi.org/10.1145/3675812.3675821},
	doi = {10.1145/3675812.3675821},
	abstract = {In the rapidly evolving field of educational technology, the application of Artificial Intelligence (AI) has begun to reshape various aspects of education, especially in the domain of language learning and teaching. Targeting English writing instruction, we have developed and implemented an advanced AI system named WAgent, representing the latest advancement in educational technology for personalized learning and enhancing teaching efficiency. WAgent is designed to address challenges present in traditional English writing instruction, such as improving student engagement, the lack of personalized feedback, and the excessive burden on teachers. This study aims to thoroughly analyze the application effectiveness of WAgent in English writing teaching, exploring its impact on student motivation, enhancement of writing skills, and improvement of teaching quality. Through a comprehensive evaluation of teaching application cases of WAgent, this research provides deep insights into how self-developed AI technology can be effectively utilized to innovate English writing education.},
	booktitle = {Proceedings of the 2024 9th {International} {Conference} on {Distance} {Education} and {Learning}},
	publisher = {Association for Computing Machinery},
	author = {Zhou, YuJie and Qi, JunJie and Zeng, Qiao and Liu, NingNing},
	year = {2024},
	note = {event-place: Guangzhou, China},
	keywords = {Automated Writing Assessment, Data-Driven Instruction, Educational Innovation, Interactive Learning Environments, Personalized Learning},
	pages = {10--15},
}

@inproceedings{tran_myeachtrax_2025,
	address = {New York, NY, USA},
	series = {{LSC} '25},
	title = {{MyEachtraX}: {Semantic} {Event} {Retrieval} with {Time}-{Weighted} {Fusion}},
	isbn = {979-8-4007-1857-1},
	url = {https://doi.org/10.1145/3729459.3748690},
	doi = {10.1145/3729459.3748690},
	abstract = {We present an enhanced version of MyEachtraX, a mobile-first lifelog question answering (QA) system developed for the Lifelog Search Challenge 2025. The system centers the QA process around early, high-quality retrieval of relevant lifelog events, using visual, spatial, and temporal context to guide answer generation. To address the unique challenges of lifelog data, including redundancy, ambiguity, and noisy signals, we propose a threefold set of improvements. First, we apply data quality filtering using semantic density estimation and perceptual hashing to eliminate low-information and duplicate images. Second, we integrate visual, spatial, and temporal cues into a unified scoring framework, enabling context-aware retrieval for complex, real-world queries. Third, we mitigate embedding hubness through query and gallery bank normalisation, enhancing ranking diversity and stability. Evaluations on LSC’24 tasks show significant improvements in top-k retrieval accuracy, particularly for time-sensitive and semantically rich queries, demonstrating the effectiveness of retrieval-focused design in lifelog QA systems.},
	booktitle = {Proceedings of the 8th {Annual} {ACM} {Workshop} on the {Lifelog} {Search} {Challenge}},
	publisher = {Association for Computing Machinery},
	author = {Tran, Allie and Gurrin, Cathal},
	year = {2025},
	keywords = {hubness mitigation, lifelog question answering, lifelog search challenge, lifelogging, mobile interface, multimodal retrieval, spatial semantics, temporal reasoning},
	pages = {44--51},
}

@inproceedings{paduraru_unit_2024,
	address = {New York, NY, USA},
	series = {{FaSE4Games} 2024},
	title = {Unit {Test} {Generation} using {Large} {Language} {Models} for {Unity} {Game} {Development}},
	isbn = {979-8-4007-0674-5},
	url = {https://doi.org/10.1145/3663532.3664466},
	doi = {10.1145/3663532.3664466},
	abstract = {Challenges related to game quality, whether occurring during initial release or after updates, can result in player dissatisfaction, media scrutiny, and potential financial setbacks. These issues may stem from factors like software bugs, performance bottlenecks, or security vulnerabilities. Despite these challenges, game developers often rely on manual playtesting, highlighting the need for more robust and automated processes in game development. This research explores the application of Large Language Models (LLMs) for automating unit test creation in game development, with a specific focus on strongly typed programming languages like C++ and C\#, widely used in the industry. The study centers around fine-tuning Code Llama, an advanced code generation model, to address common scenarios encountered in game development, including game engines and specific APIs or backends. Although the prototyping and evaluations primarily occurred within the Unity game engine, the proposed methods can be adapted to other internal or publicly available solutions. The evaluation outcomes demonstrate the effectiveness of these methods in enhancing existing unit test suites or automatically generating new tests based on natural language descriptions of class contexts and targeted methods.},
	booktitle = {Proceedings of the 1st {ACM} {International} {Workshop} on {Foundations} of {Applied} {Software} {Engineering} for {Games}},
	publisher = {Association for Computing Machinery},
	author = {Paduraru, Ciprian and Stefanescu, Alin and Jianu, Augustin},
	year = {2024},
	note = {event-place: Porto de Galinhas, Brazil},
	keywords = {game development, large language models, unit testing},
	pages = {7--13},
}

@inproceedings{maiti_can_2025,
	address = {New York, NY, USA},
	series = {{IUI} '25},
	title = {Can an {AI} {Partner} {Empower} {Learners} to {Ask} {Critical} {Questions}?},
	isbn = {979-8-4007-1306-4},
	url = {https://doi.org/10.1145/3708359.3712134},
	doi = {10.1145/3708359.3712134},
	abstract = {Jill Watson is an LLM-powered conversational AI partner integrated with instructor-provided courseware, offering learners contextually relevant and immediately applicable support. This study examines learner-generated questions as part of organic interactions with Jill embedded within classroom Learning Management System and investigates whether Jill empowers learners to ask higher-order questions. Leveraging Bloom’s Taxonomy to assess question complexity, we collected over 5500 student questions from classroom deployments across three academic semesters and two educational settings. Student questions were classified using a fine-tuned BERT model and regression models were used to analyze the trends of complexity of the questions over time. Our results reveal a significant proportion of higher-order questions being asked in our classrooms, exceeding typical educational distributions. We also found a statistically significant increase in higher-order questioning with sustained interaction with Jill. These findings demonstrate that Jill empowers learners to engage in critical questioning, thereby enhancing their educational experience by promoting depth, relevance, and application of course concepts. Further research is recommended with larger and more diverse samples to generalize these findings.},
	booktitle = {Proceedings of the 30th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Maiti, Pratyusha and Goel, Ashok},
	year = {2025},
	keywords = {Conversational AI Agents, Question Answering, Virtual Teaching Assistant},
	pages = {314--324},
}

@inproceedings{beasley_pipeline_2024,
	address = {New York, NY, USA},
	series = {{HILDA} 24},
	title = {Pipe(line) {Dreams}: {Fully} {Automated} {End}-to-{End} {Analysis} and {Visualization}},
	isbn = {979-8-4007-0693-6},
	url = {https://doi.org/10.1145/3665939.3665962},
	doi = {10.1145/3665939.3665962},
	abstract = {We exploit large language models (LLMs) to automate the end-to-end process of descriptive analytics and visualization. A user simply declares who they are and provides their data set. Our tool LLM4Vis sets analysis goals or metrics, generates code to process and analyze the data, visualizes the results and interprets the visualization to summarize key takeaways for our user. We examine the power of LLMs in democratizing data science for the non-technical user and in handling rich, multimodal data sets. We also explore LLM4Vis's limitations, opportunities for human-in-the-loop interventions, and challenges to measuring and improving the robustness and the utility of LLM-generated end-to-end data analysis pipelines.},
	booktitle = {Proceedings of the 2024 {Workshop} on {Human}-{In}-the-{Loop} {Data} {Analytics}},
	publisher = {Association for Computing Machinery},
	author = {Beasley, Cole and Abouzied, Azza},
	year = {2024},
	note = {event-place: Santiago, AA, Chile},
	pages = {1--7},
}

@inproceedings{zheng_predictions_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {From {Predictions} to {Analyses}: {Rationale}-{Augmented} {Fake} {News} {Detection} with {Large} {Vision}-{Language} {Models}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714532},
	doi = {10.1145/3696410.3714532},
	abstract = {The rapid development of social media has led to a surge of eye-catching fake news on the Internet, with multimodal news comprising both images and text being particularly prevalent. To address the challenges of Multimodal Fake News Detection (MFND), numerous supervised task-specific Multimodal Small Language Models (MSLMs) have been developed. However, these models lack the breadth of knowledge and the depth of language understanding, which results in unsatisfactory adaptability, generalization, and explainability performance. To address these issues, we attempt to introduce Large Vision-Language Models (LVLMs), aiming to leverage the common sense understanding and logical reasoning abilities of LVLMs for the MFND task. We observed that LVLMs can generate reasonable analyses of news content from specific angles. However, when it comes to synthesizing these analyses for final judgment, their performance declines significantly, failing to meet the accuracy benchmarks set by existing MSLMs detection models. This reflects the need for a more effective way for LVLMs, which have not undergone task-specific training, to utilize their knowledge and capabilities. Based on these findings, we propose the Explainable Adaptive Rationale-Augmented Multimodal (EARAM) framework, which adaptively uses MSLMs to extract useful rationales from the multi-perspective analyses of LVLMs. After making judgments based on these rationales, EARAM then assists LVLMs in generating more reliable explanations. Extensive experiments demonstrate that our model not only achieves state-of-the-art results on widely used datasets but also significantly outperforms other models in terms of generalization and explainability.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Zheng, Xiaofan and Zeng, Zinan and Wang, Heng and Bai, Yuyang and Liu, Yuhan and Luo, Minnan},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {explainable, fake news detection, large vision-language models},
	pages = {5364--5375},
}

@inproceedings{breuer_data_2024,
	address = {New York, NY, USA},
	series = {{SIGIR}-{AP} 2024},
	title = {Data {Fusion} of {Synthetic} {Query} {Variants} {With} {Generative} {Large} {Language} {Models}},
	isbn = {979-8-4007-0724-7},
	url = {https://doi.org/10.1145/3673791.3698423},
	doi = {10.1145/3673791.3698423},
	abstract = {Considering query variance in information retrieval (IR) experiments is beneficial for retrieval effectiveness. Especially ranking ensembles based on different topically related queries retrieve better results than rankings based on a single query alone. Recently, generative instruction-tuned Large Language Models (LLMs) improved on a variety of different tasks in capturing human language. To this end, this work explores the feasibility of using synthetic query variants generated by instruction-tuned LLMs in data fusion experiments. More specifically, we introduce a lightweight, unsupervised, and cost-efficient approach that exploits principled prompting and data fusion techniques. In our experiments, LLMs produce more effective queries when provided with additional context information on the topic. Furthermore, our analysis based on four TREC newswire benchmarks shows that data fusion based on synthetic query variants is significantly better than baselines with single queries and also outperforms pseudo-relevance feedback methods. We publicly share the code and query datasets with the community as resources for follow-up studies.},
	booktitle = {Proceedings of the 2024 {Annual} {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval} in the {Asia} {Pacific} {Region}},
	publisher = {Association for Computing Machinery},
	author = {Breuer, Timo},
	year = {2024},
	note = {event-place: Tokyo, Japan},
	keywords = {data fusion, large language models, query variants},
	pages = {274--279},
}

@inproceedings{mao_skyserve_2025,
	address = {New York, NY, USA},
	series = {{EuroSys} '25},
	title = {{SkyServe}: {Serving} {AI} {Models} across {Regions} and {Clouds} with {Spot} {Instances}},
	isbn = {979-8-4007-1196-1},
	url = {https://doi.org/10.1145/3689031.3717459},
	doi = {10.1145/3689031.3717459},
	abstract = {Recent years have witnessed an explosive growth of AI models. The high cost of hosting AI services on GPUs and their demanding service requirements, make it timely and challenging to lower service costs and guarantee service quality. While spot instances have long been offered with a large discount, spot preemptions have discouraged users from using them to host model replicas when serving AI models.To address this, we propose a simple yet efficient policy, SpotHedge, that leverages spot replicas across different failure domains (e.g., regions and clouds) to ensure availability, lower costs, and high service quality. SpotHedge intelligently spreads spot replicas across different regions and clouds to improve availability and reduce correlated preemptions, over-provisions cheap spot replicas than required as a safeguard against possible preemptions, and dynamically falls back to on-demand replicas when spot replicas become unavailable. We built SkyServe, a system leveraging SpotHedge to efficiently serve AI models over a mixture of spot and on-demand replicas across regions and clouds. We compared SkyServe with both research and production systems on real AI workloads: SkyServe reduces cost by 43\% on average while achieving high resource availability compared to using on-demand replicas. Additionally, SkyServe improves P50, P90, and P99 latency by 2.3×, 2.1×, 2.1× on average compared to other research and production systems.},
	booktitle = {Proceedings of the {Twentieth} {European} {Conference} on {Computer} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Mao, Ziming and Xia, Tian and Wu, Zhanghao and Chiang, Wei-Lin and Griggs, Tyler and Bhardwaj, Romil and Yang, Zongheng and Shenker, Scott and Stoica, Ion},
	year = {2025},
	note = {event-place: Rotterdam, Netherlands},
	keywords = {AI Serving, Cloud Computing, Multi-cloud, Spot Instance},
	pages = {159--175},
}

@inproceedings{huang_concise_2024,
	address = {New York, NY, USA},
	series = {{ASENS} '24},
	title = {A {Concise} {Review} of {Long} {Context} in {Large} {Language} {Models}},
	isbn = {979-8-4007-0978-4},
	url = {https://doi.org/10.1145/3677182.3677282},
	doi = {10.1145/3677182.3677282},
	abstract = {Sincerely in part to the rise of high-performance computer systems and transformer models, natural language processing has advanced. Also, a multitude of applications built on large language models continually improve people's cognitive abilities. Large language models continue to face difficulties when dealing with long context input. Many studies have suggested various specific strategies to address the challenge of extended context, however as of yet, no thorough summary of these studies exists. In this paper, we discuss the issues raised and the developments that have occurred in the long context application of large language models, and we attempt to suggest future directions for research and development.},
	booktitle = {Proceedings of the {International} {Conference} on {Algorithms}, {Software} {Engineering}, and {Network} {Security}},
	publisher = {Association for Computing Machinery},
	author = {Huang, Haitao and Liang, Zijing and Fang, Zirui and Wang, Zhiyuan and Chen, Mingxiu and Hong, Yifan and Liu, Ke and Shang, Penghui},
	year = {2024},
	note = {event-place: Nanchang, China},
	pages = {563--566},
}

@inproceedings{peng_glitter_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {{GLITTER}: {An} {AI}-assisted {Platform} for {Material}-{Grounded} {Asynchronous} {Discussion} in {Flipped} {Learning}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747742},
	doi = {10.1145/3746059.3747742},
	abstract = {Flipped classrooms promote active learning by having students engage with materials independently before class, allowing in-class time for collaborative problem-solving. During this pre-class phase, asynchronous online discussions help students build knowledge and clarify concepts with peers. However, it remains difficult to engage with temporally dispersed peer contributions, connect discussions with static learning materials, and prepare for in-class sessions based on their self-learning outcome. Our formative study identified cognitive challenges students encounter, including navigation barriers, reflection gaps, and contribution difficulty and anxiety. We present Glitter, an AI-assisted discussion platform for pre-class learning in flipped classrooms. Glitter helps students identify posts with shared conceptual dimensions, scaffold knowledge integration through conceptual blending, and enhance metacognition via personalized reflection reports. A lab study within subjects (n = 12) demonstrates that Glitter improves discussion engagement, sparks new ideas, supports reflection, and increases preparedness for in-class activities.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Peng, Weirui and Yang, Yinuo and Zhang, Zheng and Li, Toby Jia-Jun},
	year = {2025},
	keywords = {asynchronous discussion, flipped classroom, human-AI collaboration},
}

@inproceedings{wu_efficient_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {Efficient {Heuristics} {Generation} for {Solving} {Combinatorial} {Optimization} {Problems} {Using} {Large} {Language} {Models}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3736923},
	doi = {10.1145/3711896.3736923},
	abstract = {Recent studies exploited Large Language Models (LLMs) to autonomously generate heuristics for solving Combinatorial Optimization Problems (COPs), by prompting LLMs to first provide search directions and then derive heuristics accordingly. However, the absence of task-specific knowledge in prompts often leads LLMs to provide unspecific search directions, obstructing the derivation of well-performing heuristics. Moreover, evaluating the derived heuristics remains resource-intensive, especially for those semantically equivalent ones, often requiring omissible resource expenditure. To enable LLMs to provide specific search directions, we propose the Hercules algorithm, which leverages our designed Core Abstraction Prompting (CAP) method to abstract the core components from elite heuristics and incorporate them as prior knowledge in prompts. We theoretically prove the effectiveness of CAP in reducing unspecificity and provide empirical results in this work. To reduce computing resources required for evaluating the derived heuristics, we propose few-shot Performance Prediction Prompting (PPP), a first-of-its-kind method for the Heuristic Generation (HG) task. PPP leverages LLMs to predict the fitness values of newly derived heuristics by analyzing their semantic similarity to previously evaluated ones. We further develop two tailored mechanisms for PPP to enhance predictive accuracy and determine unreliable predictions, respectively. The use of PPP makes Hercules more resource-efficient and we name this variant Hercules-P. Extensive experiments across four HG tasks, five COPs, and eight LLMs demonstrate that Hercules outperforms the state-of-the-art LLM-based HG algorithms, while Hercules-P excels at minimizing required computing resources. In addition, we illustrate the effectiveness of CAP, PPP, and the other proposed mechanisms by conducting relevant ablation studies.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Wu, Xuan and Wang, Di and Wu, Chunguo and Wen, Lijie and Miao, Chunyan and Xiao, Yubin and Zhou, You},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {combinatorial optimization problems, heuristic generation, large language models},
	pages = {3228--3239},
}

@inproceedings{hildebrandt_acceptance_2025,
	address = {New York, NY, USA},
	series = {{PETRA} '25},
	title = {Acceptance, {Usability}, and {Emotions} - {An} {Extension} of the {UTAUT} {Designed} for {AI} {Virtual} {Assistants} in the {Context} of {Housing} {Modernization}},
	isbn = {979-8-4007-1402-3},
	url = {https://doi.org/10.1145/3733155.3734906},
	doi = {10.1145/3733155.3734906},
	abstract = {The integration of AI virtual assistants (AIVAs) into daily life raises critical questions about acceptance, usability, and emotional reactions. This paper explores these constructs within the context of the German state-funded KIMM project, which investigates the use of AIVAs to support the modernization of rental housing stock. To better understand users’ interactions with AIVAs, we propose an extension of the Unified Theory of Acceptance and Use of Technology (UTAUT), incorporating usability, valence, and arousal as aspects of technology acceptance. To validate our proposed model, termed Usability-Valence-Arousal-UTAUT (UVA-UTAUT), we present a study design that combines explicit measures of usability and acceptance with implicit emotion recognition techniques. The findings are expected to contribute to the fields of Human-Computer Interaction (HCI), Affective Computing, and Psychology by offering a deeper understanding of how emotional states and usability influence the acceptance of AIVAs. Further exploration of the model is encouraged and future research directions are outlined.},
	booktitle = {Proceedings of the 18th {ACM} {International} {Conference} on {PErvasive} {Technologies} {Related} to {Assistive} {Environments}},
	publisher = {Association for Computing Machinery},
	author = {Hildebrandt, Kilian and Ortmann, Thorben and Putzar, Larissa},
	year = {2025},
	keywords = {Acceptance, Affective Computing, HCI, Usability, Virtual Assistants},
	pages = {575--582},
}

@inproceedings{cao_generative_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Generative and {Malleable} {User} {Interfaces} with {Generative} and {Evolving} {Task}-{Driven} {Data} {Model}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713285},
	doi = {10.1145/3706598.3713285},
	abstract = {Unlike static and rigid user interfaces, generative and malleable user interfaces offer the potential to respond to diverse users’ goals and tasks. However, current approaches primarily rely on generating code, making it difficult for end-users to iteratively tailor the generated interface to their evolving needs. We propose employing task-driven data models—representing the essential information entities, relationships, and data within information tasks—as the foundation for UI generation. We leverage AI to interpret users’ prompts and generate the data models that describe users’ intended tasks, and by mapping the data models with UI specifications, we can create generative user interfaces. End-users can easily modify and extend the interfaces via natural language and direct manipulation, with these interactions translated into changes in the underlying model. The technical evaluation of our approach and user evaluation of the developed system demonstrate the feasibility and effectiveness of the proposed generative and malleable UIs.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Cao, Yining and Jiang, Peiling and Xia, Haijun},
	year = {2025},
	keywords = {Generative User Interface, Malleable User Interface},
}

@inproceedings{shaikh_creating_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {Creating {General} {User} {Models} from {Computer} {Use}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747722},
	doi = {10.1145/3746059.3747722},
	abstract = {Human-computer interaction has long imagined technology that understands us—from our preferences and habits, to the timing and purpose of our everyday actions. Yet current user models remain fragmented, narrowly tailored to specific applications, and incapable of the flexible, cross-context reasoning required to fulfill these visions. This paper presents an architecture for a general user model (GUM) that learns about you by observing any interaction you have with your computer. The GUM takes as input any unstructured observation of a user (e.g., device screenshots) and constructs confidence-weighted natural language propositions that capture that user’s behavior, knowledge, beliefs, and preferences. GUMs can infer that a user is preparing for a wedding they’re attending from a message thread with a friend. Or recognize that a user is struggling with a collaborator’s feedback on a draft paper by observing multiple stalled edits and a switch to reading related work. GUMs introduce an architecture that infers new propositions about a user from multimodal observations, retrieves related propositions for context, and continuously revises existing propositions. To illustrate the breadth of applications that GUMs enable, we demonstrate how they augment chat-based assistants with contextual understanding, manage OS notifications to surface important information only when needed, and enable interactive agents that adapt to user preferences across applications. We also instantiate a new class of proactive assistants (Gumbos) that discover and execute useful suggestions on a user’s behalf based on their GUM. In our evaluations, we find that GUMs make calibrated and accurate inferences about users, and that assistants built on GUMs proactively identify and perform actions of meaningful value that users wouldn’t think to request explicitly. Altogether, GUMs introduce new methods that leverage large multimodal models to understand unstructured user context, enabling both long-standing visions of HCI and entirely new interactive systems that anticipate user needs.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Shaikh, Omar and Sapkota, Shardul and Rizvi, Shan and Horvitz, Eric and Park, Joon Sung and Yang, Diyi and Bernstein, Michael S.},
	year = {2025},
	keywords = {natural language processing, User models},
}

@inproceedings{zhang_mapexplorer_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{MapExplorer}: {New} {Content} {Generation} from {Low}-{Dimensional} {Visualizations}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737038},
	doi = {10.1145/3711896.3737038},
	abstract = {Low-dimensional visualizations, or ”projection maps,” are widely used in scientific and creative domains to interpret large-scale and complex datasets. These visualizations not only aid in understanding existing knowledge spaces but also implicitly guide exploration into unknown areas. Although techniques such as t-SNE and UMAP can generate these maps, there exists no systematic method for leveraging them to generate new content. To address this, we introduce MapExplorer, a novel knowledge discovery task that translates coordinates within any projection map into coherent, contextually aligned textual content. This allows users to interactively explore and uncover insights embedded in the maps. To evaluate the performance of MapExplorer methods, we propose Atometric, a fine-grained metric inspired by ROUGE that quantifies logical coherence and alignment between generated and reference text. Experiments on diverse datasets demonstrate the versatility of MapExplorer in generating scientific hypotheses, crafting synthetic personas, and devising strategies for attacking large language models-even with simple baseline methods. By bridging visualization and generation, our work highlights the potential of MapExplorer to enable intuitive human-AI collaboration in large-scale data exploration.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Xingjian and Xiong, Ziyang and Liu, Shixuan and Xie, Yutong and Ergen, Tolga and Shim, Dongsub and Xu, Hua and Lee, Honglak and Mei, Qiaozhu},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {spatially guided content generation, text generation evaluation, textual visualization},
	pages = {3843--3854},
}

@inproceedings{wang_it_2025,
	address = {New York, NY, USA},
	series = {{ASSETS} '25},
	title = {“{It} was {Mentally} {Painful} to {Try} and {Stop}”: {Design} {Opportunities} for {Just}-in-{Time} {Interventions} for {People} with {Obsessive}-{Compulsive} {Disorder} in the {Real} {World}},
	isbn = {979-8-4007-0676-9},
	url = {https://doi.org/10.1145/3663547.3746394},
	doi = {10.1145/3663547.3746394},
	abstract = {Obsessive-compulsive disorder (OCD) is a mental health condition that significantly impacts people’s quality of life. While evidence-based therapies such as exposure and response prevention (ERP) can be effective, managing OCD symptoms in everyday life—an essential part of treatment and independent living—remains challenging due to fear confrontation and lack of appropriate support. To better understand the challenges and needs in OCD self-management, we conducted interviews with 10 participants with diverse OCD conditions and seven therapists specializing in OCD treatment. Through these interviews, we explored the characteristics of participants’ triggers and how they shaped their compulsions, and uncovered key coping strategies across different stages of OCD episodes. Our findings highlight critical gaps between OCD self-management needs and currently available support. Building on these insights, we propose design opportunities for just-in-time self-management technologies for OCD, including personalized symptom tracking, just-in-time interventions, and support for OCD-specific privacy and social needs—through technology and beyond.},
	booktitle = {Proceedings of the 27th {International} {ACM} {SIGACCESS} {Conference} on {Computers} and {Accessibility}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Ru and Zhang, Kexin and Wang, Yuqing and Brown, Keri, PhD and Zhao, Yuhang},
	year = {2025},
	keywords = {Acceptance and Commitment Therapy, Exposure and Response Prevention, just-in-time intervention, mental health, Obsessive-Compulsive Disorder, OCD},
}

@inproceedings{samarinas_distillation_2025,
	address = {New York, NY, USA},
	series = {{ICTIR} '25},
	title = {Distillation and {Refinement} of {Reasoning} in {Small} {Language} {Models} for {Document} {Re}-ranking},
	isbn = {979-8-4007-1861-8},
	url = {https://doi.org/10.1145/3731120.3744613},
	doi = {10.1145/3731120.3744613},
	abstract = {We present a novel approach for training small language models for reasoning-intensive document ranking that combines knowledge distillation with reinforcement learning optimization. While existing methods often rely on expensive human annotations or large black-box language models, our methodology leverages web data and a teacher LLM to automatically generate high-quality training examples with relevance explanations. By framing document ranking as a reinforcement learning problem and incentivizing explicit reasoning capabilities, we train a compact 3B parameter language model that achieves state-of-the-art performance on the BRIGHT benchmark. Our model ranks third on the leaderboard while using substantially fewer parameters than other approaches, outperforming models that are over 20 times larger. Through extensive experiments, we demonstrate that generating explanations during inference, rather than directly predicting relevance scores, enables more effective reasoning with smaller language models. The self-supervised nature of our method offers a scalable and interpretable solution for modern information retrieval systems.},
	booktitle = {Proceedings of the 2025 {International} {ACM} {SIGIR} {Conference} on {Innovative} {Concepts} and {Theories} in {Information} {Retrieval} ({ICTIR})},
	publisher = {Association for Computing Machinery},
	author = {Samarinas, Chris and Zamani, Hamed},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {reasoning intensive retrieval, reinforcement learning},
	pages = {430--435},
}

@inproceedings{tran_myeachtrax_2024,
	address = {New York, NY, USA},
	series = {{LSC} '24},
	title = {{MyEachtraX}: {Lifelog} {Question} {Answering} on {Mobile}},
	isbn = {979-8-4007-0550-2},
	url = {https://doi.org/10.1145/3643489.3661128},
	doi = {10.1145/3643489.3661128},
	abstract = {Your whole life in your pocket. That is the premise of lifelogging, a technology that captures and stores every moment of your life in digital form. Built on top of MyEachtra and the lifelog question-answering pipeline, MyEachtraX is a mobile-based application that addresses the overlook of mobile platforms in the area. Furthermore, leveraging the latest advancements in natural language processing, such as Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs), the system enhances the query-parsing, post-processing, and question-answering processes in lifelog retrieval. Official lifelog questions from the previous Lifelog Search Challenges were used to evaluate the system, which achieved an accuracy of 72.2\%. We identify the retrieval component as the main bottleneck of the pipeline and propose future works to improve the system.},
	booktitle = {Proceedings of the 7th {Annual} {ACM} {Workshop} on the {Lifelog} {Search} {Challenge}},
	publisher = {Association for Computing Machinery},
	author = {Tran, Ly Duyen and Nguyen, Thanh-Binh and Gurrin, Cathal and Zhou, Liting},
	year = {2024},
	note = {event-place: Phuket, Thailand},
	keywords = {lifelog, mobile, question answering, retrieval},
	pages = {93--98},
}

@inproceedings{zheng_reasoning-focused_2025,
	address = {New York, NY, USA},
	series = {{CSLAW} '25},
	title = {A {Reasoning}-{Focused} {Legal} {Retrieval} {Benchmark}},
	isbn = {979-8-4007-1421-4},
	url = {https://doi.org/10.1145/3709025.3712219},
	doi = {10.1145/3709025.3712219},
	abstract = {As the legal community increasingly examines the use of large language models (LLMs) for various legal applications, legal AI developers have turned to retrieval-augmented LLMs ("RAG" systems) to improve system performance and robustness. An obstacle to the development of specialized RAG systems is the lack of realistic legal RAG benchmarks which capture the complexity of both legal retrieval and downstream legal question-answering. To address this, we introduce two novel legal RAG benchmarks: Bar Exam QA and Housing Statute QA. Our tasks correspond to real-world legal research tasks, and were produced through annotation processes which resemble legal research. We describe the construction of these benchmarks and the performance of existing retriever pipelines. Our results suggest that legal RAG remains a challenging application, thus motivating future research.},
	booktitle = {Proceedings of the 2025 {Symposium} on {Computer} {Science} and {Law}},
	publisher = {Association for Computing Machinery},
	author = {Zheng, Lucia and Guha, Neel and Arifov, Javokhir and Zhang, Sarah and Skreta, Michal and Manning, Christopher D. and Henderson, Peter and Ho, Daniel E.},
	year = {2025},
	note = {event-place: Munich, Germany},
	keywords = {benchmark, dataset, reasoning, retrieval},
	pages = {169--193},
}

@inproceedings{liu_efficient_2025,
	address = {New York, NY, USA},
	series = {{HotStorage} '25},
	title = {Efficient {Vector} {Search} on {Disaggregated} {Memory} with d-{HNSW}},
	isbn = {979-8-4007-1947-9},
	url = {https://doi.org/10.1145/3736548.3737822},
	doi = {10.1145/3736548.3737822},
	abstract = {Efficient vector query processing is essential for powering large-scale AI applications, such as LLMs. However, existing solutions struggle with growing vector datasets that exceed the memory capacity of a single machine, leading to excessive data movement and resource underutilization in monolithic architectures.We introduce d-HNSW, the first vector search engine for RDMA-based disaggregated memory systems. d-HNSW achieves high performance by supporting efficient data indexing with minimal network communication overhead. At its core, d-HNSW introduces a novel disaggregation of the HNSW graph-based vector index, leveraging the properties of greedy search to coordinate data transfers efficiently between the memory and compute pools. Specifically, d-HNSW incorporates three key techniques: (i) Representative index caching, which constructs a lightweight index from a sampled subset of the data and caches it in the compute pool to minimize frequent access to critical components of the hierarchical graph index; (ii) RDMA-friendly data layout, which optimizes data placement to reduce networking round trips for both vector queries and insertions; and (iii) Batched query-aware data loading, which mitigates bandwidth usage between memory and compute pools, addressing the limited cache capacity of compute nodes. The experimental results demonstrate that d-HNSW outperforms Naive d-HNSW implementation by up to 117× in query latency while maintaining a recall of 0.87 on the SIFT1M dataset.},
	booktitle = {Proceedings of the 17th {ACM} {Workshop} on {Hot} {Topics} in {Storage} and {File} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Yi and Fang, Fei and Qian, Chen},
	year = {2025},
	note = {event-place: Boston, MA, USA},
	keywords = {Disaggregated memory, HNSW, RDMA, vector database},
	pages = {1--8},
}

@inproceedings{rahimi_user-vlm_2025,
	address = {New York, NY, USA},
	series = {{ICMI} '25},
	title = {{USER}-{VLM} 360: {Personalized} {Vision} {Language} {Models} with {User}-aware {Tuning} for {Social} {Human}-{Robot} {Interactions}},
	isbn = {979-8-4007-1499-3},
	url = {https://doi.org/10.1145/3716553.3750767},
	doi = {10.1145/3716553.3750767},
	abstract = {The integration of vision-language models into robotic systems constitutes a significant advancement in enabling machines to interact with their surroundings in a more intuitive manner. While VLMs offer rich multimodal reasoning, existing approaches lack user-specific adaptability, often relying on generic interaction paradigms that fail to account for individual behavioral, contextual, or socio-emotional nuances. When customization is attempted, ethical concerns arise from unmitigated biases in user data, risking exclusion or unfair treatment. To address these dual challenges, we propose User-VLM 360°, a holistic framework integrating multimodal user modeling with bias-aware optimization. Our approach features: (1) user-aware tuning that adapts interactions in real time using visual-linguistic signals; (2) bias mitigation via preference optimization; and (3) curated 360° socio-emotive interaction datasets annotated with demographic, emotion, and relational metadata. Evaluations across eight benchmarks demonstrate state-of-the-art results: +35.3\% F1 in personalized VQA, +47.5\% F1 in facial features understanding, 15\% bias reduction, and 30× speedup over baselines. Ablation studies confirm component efficacy, and deployment on the Pepper robot validates real-time adaptability across diverse users. We open-source parameter-efficient 3B/10B models and an ethical verification framework for responsible adaptation.},
	booktitle = {Proceedings of the 27th {International} {Conference} on {Multimodal} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Rahimi, Hamed and Bahaj, Adil and Abrini, Mouad and Khoramshahi, Mahdi and Ghogho, Mounir and Chetouani, Mohamed},
	year = {2025},
	keywords = {Social Robotics, User Modeling, Vision Language Models},
	pages = {326--336},
}

@inproceedings{susanti_paths_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {Paths to {Causality}: {Finding} {Informative} {Subgraphs} {Within} {Knowledge} {Graphs} for {Knowledge}-{Based} {Causal} {Discovery}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737076},
	doi = {10.1145/3711896.3737076},
	abstract = {Inferring causal relationships between variable pairs is crucial for understanding multivariate interactions in complex systems. Knowledge-based causal discovery -which involves inferring causal relationships by reasoning over the metadata of variables (e.g., names or textual context)-offers a compelling alternative to traditional methods that rely on observational data. However, existing methods using Large Language Models (LLMs) often produce unstable and inconsistent results, compromising their reliability for causal inference. To address this, we introduce a novel approach that integrates Knowledge Graphs (KGs) with LLMs to enhance knowledge-based causal discovery. Our approach identifies informative metapath -based subgraphs within KGs and further refines the selection of these subgraphs using Learning-to-Rank-based models. The top-ranked subgraphs are then incorporated into zero-shot prompts, improving the effectiveness of LLMs in inferring the causal relationship. Extensive experiments on biomedical and open-domain datasets demonstrate that our method outperforms most baselines by up to 44.4 points in F1 scores, evaluated across diverse LLMs and KGs. Our code and datasets are available on GitHub.. https://github.com/susantiyuni/path-to-causality},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Susanti, Yuni and Färber, Michael},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {causal discovery, knowledge graphs, large language models},
	pages = {2778--2789},
}

@inproceedings{alessio_cosrec_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{CoSRec}: {A} {Joint} {Conversational} {Search} and {Recommendation} {Dataset}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730319},
	doi = {10.1145/3726302.3730319},
	abstract = {Conversational Information Access systems have experienced widespread diffusion thanks to the natural and effortless interactions they enable with the user. In particular, they represent an effective interaction interface for conversational search (CS) and conversational recommendation (CR) scenarios. Despite their commonalities, CR and CS systems are often devised, developed, and evaluated as isolated components. Integrating these two elements would allow for handling complex information access scenarios, such as exploring unfamiliar recommended product aspects, enabling richer dialogues, and improving user satisfaction. As of today, the scarce availability of integrated datasets - focused exclusively on either of the tasks - limits the possibilities for evaluating by-design integrated CS and CR systems. To address this gap, we propose CoSRec, the first dataset for joint Conversational Search and Recommendation (CSR) evaluation. The CoSRec test set includes 20 high-quality conversations, with human-made annotations for the quality of conversations, and manually crafted relevance judgments for products and documents. Additionally, we provide supplementary training data comprising partially annotated dialogues and raw conversations to support diverse learning paradigms. CoSRec is the first resource to model CR and CS tasks in a unified framework, enabling the training and evaluation of systems that must shift between answering queries and making suggestions dynamically.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Alessio, Marco and Merlo, Simone and Di Noia, Tommaso and Faggioli, Guglielmo and Ferrante, Marco and Ferro, Nicola and Muntean, Cristina Ioana and Nardini, Franco Maria and Narducci, Fedelucio and Perego, Raffaele and Santucci, Giuseppe and Viterbo, Nicola},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {conversational recommendation, conversational search, joint information retrieval and recommendation},
	pages = {3466--3477},
}

@inproceedings{wang_what_2025,
	address = {New York, NY, USA},
	series = {{MuC} '25},
	title = {“{What} do they think about my idea?”- {Co}-{Designing} an {E}-{Participation} {Tool} for {Participatory} {Urban} {Planning} in {Germany}},
	isbn = {979-8-4007-1582-2},
	url = {https://doi.org/10.1145/3743049.3743065},
	doi = {10.1145/3743049.3743065},
	abstract = {This paper reports on multiple co-design workshops for the development of an e-participation tool. Participants were citizens and city staff from Wuppertal, Germany, and experts on participation. We explored what information citizens and city staff need, how this information should be provided, and what features for input and communication should be implemented. Through a thematic analysis, we found that information should be short, visual, and accessible. This visual information includes a visualization of the area relevant to participation. Participants preferred an abstract 3D model over a 2D map and a photorealistic 3D model. Additional visualizations should complement this abstract 3D model to support better recognition of the area, e.g. through photos and videos, or through an extra layer that visualizes the terrain. Three preferred ways of interaction and communication were identified through the analysis: 1) commenting and voting on existing ideas, 2) placing icons, and 3) drawing sketches. Since moderation is often conducted manually, this impacts which features can be implemented. We also found that city staff was generally interested in using AI for several purposes, such as lowering their moderation load and supporting citizens in formulating ideas.},
	booktitle = {Proceedings of the {Mensch} {Und} {Computer} 2025},
	publisher = {Association for Computing Machinery},
	author = {Wang, Sonja Mei and Seim, Jonathan and Fricke, Nicola},
	year = {2025},
	keywords = {3D visualization, co-design, e-participation, qualitative study, sociotechnical systems},
	pages = {75--90},
}

@inproceedings{kim_bleacherbot_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{BleacherBot}: {AI} {Agent} as a {Sports} {Co}-{Viewing} {Partner}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3714178},
	doi = {10.1145/3706598.3714178},
	abstract = {Co-viewing, traditionally defined as watching content together in the same physical space, enhances emotional connections through shared experiences. With the rise of remote viewing during the COVID-19 pandemic, existing solutions, such as second-screen platforms and rule-based AI companions, struggle to facilitate meaningful social interactions. This study explores the potential of Large Language Models, which offer human-like interactions and personalization. Our formative study with ten participants revealed the importance of managing arousal levels, highlighting the need to balance between high- and low-arousal levels across different viewing contexts. Based on these insights, we developed ‘BleacherBot’, a sports co-viewing agent with distinct interaction styles that vary in arousal levels. Our main study with 27 participants demonstrated that matching users’ preferred arousal levels with the agent’s interaction style significantly enhanced their engagement and overall enjoyment. We propose design guidelines for AI co-viewing agents that consider their role as complements to human social interactions.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kim, Kyusik and Song, Hyungwoo and Ryu, Jeongwoo and Oh, Changhoon and Suh, Bongwon},
	year = {2025},
	keywords = {AI Agents, Co-viewing, Human-AI Interaction, Large Language Models (LLMs), Sports Communication},
}

@inproceedings{roegiest_generative_2024,
	address = {New York, NY, USA},
	series = {{CHIIR} '24},
	title = {Generative {Information} {Systems} {Are} {Great} {If} {You} {Can} {Read}},
	isbn = {979-8-4007-0434-5},
	url = {https://doi.org/10.1145/3627508.3638345},
	doi = {10.1145/3627508.3638345},
	abstract = {Generative models, especially in information systems like ChatGPT and Bing Chat, have become increasingly integral to our daily lives. Their significance lies in their potential to revolutionize how we access, process, and generate information \&nbsp;[44]. However, a gap exists in ensuring these systems are accessible to all, especially considering the literacy challenges faced by a significant portion of the population in (but not limited to) English-speaking countries. This paper aims to investigate the “readability’’ of generative information systems and their accessibility barriers, particularly for those with literacy challenges. Using popular instruction fine-tuning datasets, we found that this training data could produce systems that generate at a college level, potentially excluding a large demographic. Our research methods involved analyzing the responses of popular Large Language Models (LLMs) and examining potential biases in how they can be trained. The key message is the urgent need for inclusivity in systems incorporating generative models, such as those studied by the Information Retrieval (IR) community. Our findings indicate that current generative systems might not be accessible to individuals with cognitive and literacy challenges, emphasizing the importance of ensuring that advancements in this field benefit everyone. By situating our research within the sphere of information seeking and retrieval, we underscore the essential role of these technologies in augmenting accessibility and efficiency of information access, thereby broadening their reach and enhancing user engagement.},
	booktitle = {Proceedings of the 2024 {Conference} on {Human} {Information} {Interaction} and {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Roegiest, Adam and Pinkosova, Zuzana},
	year = {2024},
	note = {event-place: Sheffield, United Kingdom},
	pages = {165--177},
}

@inproceedings{li_ai-driven_2025,
	address = {New York, NY, USA},
	series = {{SPCT} '24},
	title = {An {AI}-{Driven} {Training} {System} {Architecture} for {Specialized} {Operations}},
	isbn = {979-8-4007-1063-6},
	url = {https://doi.org/10.1145/3712464.3712518},
	doi = {10.1145/3712464.3712518},
	abstract = {This paper introduces an AI-driven training system architecture tailored for specialized operations within high-complexity industries. Leveraging the advancements in artificial intelligence, particularly large models, the system offers a structured, four-layer architecture encompassing Device, Data, Model, and Application Layers. These layers integrate advanced AI capabilities to simulate real-world environments, deliver personalized training, and optimize performance in critical operations. Experimental results highlight the system's ability to reduce operator response times, improve success rates, and enhance operational safety and efficiency. This research presents a transformative approach to training personnel, aiming to elevate the safety and effectiveness of industrial operations.},
	booktitle = {Proceedings of the 2024 4th {International} {Conference} on {Signal} {Processing} and {Communication} {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Li, Kunyan and Yu, Shuxuan and Wang, Shu and Li, Jiayi and Li, Rushuang and Wei, Jinwu},
	year = {2025},
	keywords = {AI-Driven Training, Highly complex industries, Specialized operations},
	pages = {310--315},
}

@inproceedings{huang_disambiguate_2024,
	address = {New York, NY, USA},
	series = {{GUIDE}-{AI} '24},
	title = {Disambiguate {Entity} {Matching} using {Large} {Language} {Models} through {Relation} {Discovery}},
	isbn = {979-8-4007-0694-3},
	url = {https://doi.org/10.1145/3665601.3669844},
	doi = {10.1145/3665601.3669844},
	abstract = {Entity matching is a critical problem in data integration, central to tasks like fuzzy joins for tuple enrichment. Traditional approaches have focused on overcoming fuzzy term representations through methods such as edit distance, Jaccard similarity, and more recently, embeddings and deep neural networks, including advancements from large language models (LLMs) like GPT. However, when integrating with external databases, the core challenge in entity matching extends beyond term fuzziness to the ambiguity in defining what constitutes a "match". This is because external databases contain tuples with varying levels of detail and granularity among entities, and an "exact match" in traditional entity matching rarely happens. As a result, understanding how entities are related and the potential nuances is critical, especially for high-stake tasks for responsible AI. In this work, we study a case problem of entity matching for ESG reporting. We propose a novel approach that shifts focus from purely identifying semantic similarities to understanding and defining the "relations" between entities for resolving ambiguities in matching, with a human-in-the-loop process to make the final decision. By pre-defining a set of relations relevant to the task at hand, our method allows analysts to navigate the spectrum of similarity more effectively, from exact matches to conceptually related entities, and responsibly perform downstream tasks.},
	booktitle = {Proceedings of the {Conference} on {Governance}, {Understanding} and {Integration} of {Data} for {Effective} and {Responsible} {AI}},
	publisher = {Association for Computing Machinery},
	author = {Huang, Zezhou},
	year = {2024},
	note = {event-place: Santiago, AA, Chile},
	keywords = {Data Integration, Entity Matching, Large Language Models},
	pages = {36--39},
}

@inproceedings{liu_unimel_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {{UniMEL}: {A} {Unified} {Framework} for {Multimodal} {Entity} {Linking} with {Large} {Language} {Models}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3679793},
	doi = {10.1145/3627673.3679793},
	abstract = {Multimodal Entity Linking (MEL) is a crucial task that aims at linking ambiguous mentions within multimodal contexts to the referent entities in a multimodal knowledge base, such as Wikipedia. Existing methods focus heavily on using complex mechanisms and extensive model tuning methods to model the multimodal interaction on specific datasets. However, these methods overcomplicate the MEL task and overlook the visual semantic information, which makes them costly and hard to scale. Moreover, these methods cannot solve the issues like textual ambiguity, redundancy, and noisy images, which severely degrade their performance. Fortunately, the advent of Large Language Models (LLMs) with robust capabilities in text understanding and reasoning, particularly Multimodal Large Language Models (MLLMs) that can process multimodal inputs, provides new insights into addressing this challenge. However, how to design a universally applicable LLMs-based MEL approach remains a pressing challenge. To this end, we propose UniMEL, a \&lt;u\&gt;uni\&lt;/u\&gt;fied framework which establishes a new paradigm to process \&lt;u\&gt;m\&lt;/u\&gt;ultimodal \&lt;u\&gt;e\&lt;/u\&gt;ntity \&lt;u\&gt;l\&lt;/u\&gt;inking tasks using LLMs. In this framework, we employ LLMs to augment the representation of mentions and entities individually by integrating textual and visual information and refining textual information. Subsequently, we employ the embedding-based method for retrieving and re-ranking candidate entities. Then, with only 0.26\% of the model parameters fine-tuned, LLMs can make the final selection from the candidate entities. Extensive experiments on three public benchmark datasets demonstrate that our solution achieves state-of-the-art performance, and ablation studies verify the effectiveness of all modules. Our code is available at https://github.com/Javkonline/UniMEL.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Qi and He, Yongyi and Xu, Tong and Lian, Defu and Liu, Che and Zheng, Zhi and Chen, Enhong},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {large language models, multimodal entity linking, multimodal knowledge base},
	pages = {1909--1919},
}

@inproceedings{fons_tadacap_2024,
	address = {New York, NY, USA},
	series = {{ICAIF} '24},
	title = {{TADACap}: {Time}-series {Adaptive} {Domain}-{Aware} {Captioning}},
	isbn = {979-8-4007-1081-0},
	url = {https://doi.org/10.1145/3677052.3698690},
	doi = {10.1145/3677052.3698690},
	abstract = {While image captioning has gained significant attention, the potential of captioning time-series images, prevalent in areas like finance and healthcare, remains largely untapped. Existing time-series captioning methods typically offer generic, domain-agnostic descriptions of time-series shapes and struggle to adapt to new domains without substantial retraining. To address these limitations, we introduce TADACap, a retrieval-based framework to generate domain-aware captions for time-series images, capable of adapting to new domains without retraining. Building on TADACap, we propose a novel retrieval strategy that retrieves diverse image-caption pairs from a target domain database, namely TADACap-diverse. We benchmarked TADACap-diverse against state-of-the-art methods and ablation variants. TADACap-diverse demonstrates comparable semantic accuracy while requiring significantly less annotation effort.},
	booktitle = {Proceedings of the 5th {ACM} {International} {Conference} on {AI} in {Finance}},
	publisher = {Association for Computing Machinery},
	author = {Fons, Elizabeth and Kaur, Rachneet and Zeng, Zhen and Palande, Soham and Balch, Tucker and Vyetrenko, Svitlana and Veloso, Manuela},
	year = {2024},
	note = {event-place: Brooklyn, NY, USA},
	keywords = {Adaptive, Domain-aware, Retrieval-based captioning, Time series captioning},
	pages = {54--62},
}

@inproceedings{anderer_making_2025,
	address = {New York, NY, USA},
	series = {{ASSETS} '25},
	title = {Making {Lecture} {Videos} {Accessible} for {Students} who are {Blind} or have {Low} {Vision} through {AI}-{Assisted} {Navigation} and {Visual} {Question} {Answering}},
	isbn = {979-8-4007-0676-9},
	url = {https://doi.org/10.1145/3663547.3746349},
	doi = {10.1145/3663547.3746349},
	abstract = {Designing accessible lectures and lecture materials is crucial to promote inclusive higher education. We conducted need-finding interviews with 12 students who are blind or have low vision to learn their perspectives on how lectures and lecture material could become more accessible through Artificial Intelligence (AI) technologies. Key insights from the interviews reveal that students envision AI to automatically customize lecture material, connect disparate information sources, for example, to better keep track of the current lecture slide, and enhance interaction and engagement with lecture material. Based on these insights, we developed the LectureAssistant prototype, employing an iterative design process with visually impaired users that features AI-assisted video navigation and chatbot interaction. In a final evaluation with seven students, the participants expressed enthusiasm for features such as AI-powered video search and the possibility of asking questions about visual content in the current video frame. They provided valuable suggestions for future improvements, including notifications for lecture slide transitions and the provision of a short overview function for a slide. Insights from the study indicate great potential of the prototype to improve accessibility of lecture videos for students with visual impairments, although they also point to crucial areas for improvement, such as more reliable and personalized image descriptions.},
	booktitle = {Proceedings of the 27th {International} {ACM} {SIGACCESS} {Conference} on {Computers} and {Accessibility}},
	publisher = {Association for Computing Machinery},
	author = {Anderer, Katharina and Müller, Karin and Strobel, Lukas and Wölfel, Matthias and Niehues, Jan and Gerling, Kathrin},
	year = {2025},
	keywords = {Assistive technology, blind and low vision, large-language models, vision-language models},
}

@inproceedings{orlando_can_2025,
	address = {New York, NY, USA},
	series = {Websci '25},
	title = {Can {Generative} {Agent}-{Based} {Modeling} {Replicate} the {Friendship} {Paradox} in {Social} {Media} {Simulations}?},
	isbn = {979-8-4007-1483-2},
	url = {https://doi.org/10.1145/3717867.3717895},
	doi = {10.1145/3717867.3717895},
	abstract = {Generative Agent-Based Modeling (GABM) is an emerging simulation paradigm that combines the reasoning abilities of Large Language Models with traditional Agent-Based Modeling to replicate complex social behaviors, including interactions on social media. While prior work has focused on localized phenomena such as opinion formation and information spread, its potential to capture global network dynamics remains underexplored. This paper addresses this gap by analyzing GABM-based social media simulations through the lens of the Friendship Paradox (FP), a counterintuitive phenomenon where individuals, on average, have fewer friends than their friends. We propose a GABM framework for social media simulations, featuring generative agents that emulate real users with distinct personalities and interests. Using Twitter datasets on the US 2020 Election and the QAnon conspiracy, we show that the FP emerges naturally in GABM simulations. Consistent with real-world observations, the simulations unveil a hierarchical structure, where agents preferentially connect with others displaying higher activity or influence. Additionally, we find that infrequent connections primarily drive the FP, reflecting patterns in real networks. These findings validate GABM as a robust tool for modeling global social media phenomena and highlight its potential for advancing social science by enabling nuanced analysis of user behavior.},
	booktitle = {Proceedings of the 17th {ACM} {Web} {Science} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Orlando, Gian Marco and La Gatta, Valerio and Russo, Diego and Moscato, Vincenzo},
	year = {2025},
	keywords = {Agent-Based Modeling, Friendship Paradox, Generative Agents, Social Media Simulation},
	pages = {510--515},
}

@inproceedings{maxim_voice_2025,
	address = {New York, NY, USA},
	series = {{IVA} '25},
	title = {Voice and {Choice}: {Voice} {Equivalence} and {Representational} {Choice} in {Virtual} {Health} {Assistants} for {Colorectal} {Cancer} {Screening} {Among} {Black} {American} {Adults}},
	isbn = {979-8-4007-1508-2},
	url = {https://doi.org/10.1145/3717511.3747065},
	doi = {10.1145/3717511.3747065},
	abstract = {Advances in AI, including large language models, enable virtual health assistants (VHAs) to tailor messaging to cultural and individual needs. However, to fully realize this potential, VHA voices must match or exceed human voices in influencing behavioral intentions. We conducted a multi-study investigation on whether matching text-to-speech (TTS) voices to human voices across vocal traits could promote colorectal cancer (CRC) screening among Black or African American adults. Study 1 (N = 313) tested whether a TTS voice prosodically matched to a human voice could elicit equivalent screening intentions using a White male VHA. It also evaluated whether increasing vocal confidence via SSML would enhance effectiveness. A user preference study (N = 317) assessed VHA identity and delivery modality preferences, finding strong support for a Black female VHA. Building on these results, Study 2 (N = 106) replicated the TTS-human voice comparison using a Black female VHA. Across studies, matching TTS voices to human voices on frequency, speech rate, and pitch variation achieved equivalent screening intentions. We discuss implications for VHA design and user-centered voice adaptation.},
	booktitle = {Proceedings of the 25th {ACM} {International} {Conference} on {Intelligent} {Virtual} {Agents}},
	publisher = {Association for Computing Machinery},
	author = {Maxim, Andrew and Cooks, Eric and Krieger, Janice and Lok, Benjamin},
	year = {2025},
	keywords = {computer-generated voice, healthcare, patient choice, virtual humans},
}

@inproceedings{alam_memento_2024,
	address = {New York, NY, USA},
	series = {{LSC} '24},
	title = {Memento 4.0: {A} {Prototype} {Conversational} {Search} {System} for {LSC}'24},
	isbn = {979-8-4007-0550-2},
	url = {https://doi.org/10.1145/3643489.3661126},
	doi = {10.1145/3643489.3661126},
	abstract = {The practice of lifelogging, capturing one's daily experiences through wearable devices, has evolved significantly over the last decade, presenting both challenges and opportunities in information retrieval. This paper presents an early prototype of a conversational lifelog retrieval system designed to address the open challenges in this domain. Our system integrates a hierarchical event segmentation approach to automatically organize lifelog data into meaningful events, facilitating event-based retrieval over traditional image retrieval. Moreover, we incorporate a question-answering pipeline, leveraging large language models such as GPT-3.5 Turbo and Mistral7B, to enable free-form natural language interaction with the lifelog dataset. Moreover, we enhance our system's user interface by building on previous versions to streamline event-based retrieval and question-answering functionalities.},
	booktitle = {Proceedings of the 7th {Annual} {ACM} {Workshop} on the {Lifelog} {Search} {Challenge}},
	publisher = {Association for Computing Machinery},
	author = {Alam, Naushad and Graham, Yvette and Gurrin, Cathal},
	year = {2024},
	note = {event-place: Phuket, Thailand},
	keywords = {conversational search, information retrieval, lifelog, semantic image representation},
	pages = {82--87},
}

@inproceedings{li_managing_2025,
	address = {New York, NY, USA},
	series = {{SOSP} '25},
	title = {Managing {Scalable} {Direct} {Storage} {Accesses} for {GPUs} with {GoFS}},
	isbn = {979-8-4007-1870-0},
	url = {https://doi.org/10.1145/3731569.3764857},
	doi = {10.1145/3731569.3764857},
	abstract = {As we shift from CPU-centric computing to GPU-accelerated computing for supporting intelligent data processing at scale, the storage bottleneck has been exacerbated. To bypass the host CPUand alleviate unnecessary data movements, modern GPUs enable direct storage access to SSDs (i.e., GPUDirect Storage). However, current GPUDirect Storage solutions still rely on the host file system to manage the storage device, direct storage accesses are still bottlenecked by the host.In this paper, we develop a GPU-orchestrated file system (GoFS) for scaling the direct storage accesses for GPU programs, by fully offloading the storage management to the GPU. As GoFS provides POSIX API and manages core filesystem structures in GPU memory, it can execute both control path and data path without host CPU involvement. To enable highly concurrent direct storage accesses, we rethink the design and implementation of core filesystem structures with various optimization techniques, such as scalable data indexing, fine-grained per-SM (streaming multiprocessor) block management, and zero-copy I/O accesses, by carefully exploring the GPU-accelerated computing paradigm. GoFS preserves the essential filesystem properties such as crash consistency, and it is compatible with existing host-based file systems like F2FS. GoFS does not require changes to the on-disk filesystem organization, therefore, the host and GPU can manage the SSD in a coordinated fashion, and maintain the data consistency in a primary/secondary mode. We implement GoFS based on F2FS using 7.9K lines of codes with CUDA programming. We examine its efficiency on an A100 GPU. Our experiments with various GPU-based applications show that GoFS outperforms state-of-the-art storage access solutions for GPUs by 1.61× on average.},
	booktitle = {Proceedings of the {ACM} {SIGOPS} 31st {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {Association for Computing Machinery},
	author = {Li, Shaobo and Zhou, Yirui Eric and Xue, Yuqi and Xu, Yuan and Huang, Jian},
	year = {2025},
	note = {event-place: Lotte Hotel World, Seoul, Republic of Korea},
	keywords = {file system, GPU, GPUDirect storage},
	pages = {979--995},
}

@inproceedings{shyalika_smartpilotagent-based_2025,
	address = {Richland, SC},
	series = {{AAMAS} '25},
	title = {{SmartPilot}:{Agent}-{Based} {CoPilot} for {Intelligent} {Manufacturing}},
	isbn = {979-8-4007-1426-9},
	abstract = {In the dynamic landscape of Industry 4.0, achieving efficiency, precision, and adaptability is essential for optimizing manufacturing operations. SmartPilot is a neurosymbolic and agent-based CoPilot designed to enhance real-time decision-making capabilities in manufacturing. The system addresses three key challenges: anomaly prediction, production forecasting, and domain-specific question answering through an agent-based framework. SmartPilot leverages multimodal data and a compact architecture optimized for edge devices. This paper highlights its innovative combination of agent-based design and neurosymbolic reasoning to enable contextual decision-making in complex environments. The demonstration video, datasets, and supplementary materials are available at https://github.com/ChathurangiShyalika/SmartPilot.},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Autonomous} {Agents} and {Multiagent} {Systems}},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Shyalika, Chathurangi and Prasad, Renjith and Al Ghazo, Alaa and Eswaramoorthi, Darssan L. and Shree Muthuselvam, Sara and Sheth, Amit},
	year = {2025},
	note = {event-place: Detroit, MI, USA},
	keywords = {agent-based architecture, copilot, multi-modality, smart manufacturing},
	pages = {3053--3055},
}

@inproceedings{zhao_model_2025,
	address = {New York, NY, USA},
	series = {{RecSys} '25},
	title = {Model {Meets} {Knowledge}: {Analyzing} {Knowledge} {Types} for {Conversational} {Recommender} {Systems}},
	isbn = {979-8-4007-1364-4},
	url = {https://doi.org/10.1145/3705328.3748152},
	doi = {10.1145/3705328.3748152},
	abstract = {Conversational Recommender Systems (CRSs) often integrate external knowledge to enhance user preference modeling and item representation learning, addressing the challenge of sparse conversational contexts. Traditional methods primarily utilize structured knowledge graphs (KGs) to model entity relationships and capture deep, multi-hop relationships among items. More recent studies employing pre-trained language models (PLMs), however, leverage unstructured text (e.g., customer reviews) to enrich contextual understanding of users and items. Despite reported performance gains from both knowledge types, a question remains: What is the compatibility between specific CRS model architectures and types of external knowledge, and how do different knowledge sources complement each other? We present a reproducibility study evaluating 9 state-of-the-art CRSs, including KG-based and PLM-based paradigms, to systematically investigate model–-knowledge compatibility and complementarity. Through a comprehensive evaluation on three datasets, we uncover three key findings: (1) Different model architectures have different compatibility with knowledge types: decoder-only models excel with structured knowledge, whereas encoder-decoder models better utilize unstructured knowledge. (2) Combining multiple knowledge sources isn’t always superior to using a single type, but merging similar knowledge types is generally more effective than mixing different ones. (3) Unstructured knowledge broadly benefits all scenario-specific conversations, particularly in genre-specific and descriptive scenarios, whereas structured knowledge demonstrates superior performance in comparative recommendation scenarios. Our study serves as an inspiration for future research on maximizing the benefits of external knowledge across different models in CRSs.},
	booktitle = {Proceedings of the {Nineteenth} {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhao, Jujia and Wang, Yumeng and Ren, Zhaochun and Verberne, Suzan},
	year = {2025},
	keywords = {Conversational Recommender System, Knowledge Graphs, Pre-trained Language Models},
	pages = {802--811},
}

@inproceedings{rosset_researchy_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Researchy {Questions}: {A} {Dataset} of {Multi}-{Perspective}, {Decompositional} {Questions} for {Deep} {Research}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730275},
	doi = {10.1145/3726302.3730275},
	abstract = {Existing question answering (QA) datasets are no longer challenging to most powerful Large Language Models (LLMs). Traditional QA benchmarks like TriviaQA, NaturalQuestions, ELI5 and HotpotQA mainly study ”known unknowns” with clear indications of both what information is missing, and how to find it to answer the question. A yet unmet need of the NLP community is a bank of non-factoid, multi-perspective questions involving a great deal of unclear information needs, i.e. ”unknown unknowns”. We claim we can find such questions in search engine logs, which is surprising because most question-intent queries are indeed factoid. Furthermore, recent products like Google's DeepResearch (announced a year after this resource was released publicly) specifically address such queries, retrieving hundreds of documents to synthesize report-style responses. We present Researchy Questions, the world's first, only and largest public dataset of ”Deep Research” questions filtered from real search engine logs to be non-factoid, ”decompositional” and multi-perspective. We show that users spend substantial ”effort” on these questions in terms of signals like clicks and session length. We also show that ”slow thinking” answering techniques, like decomposition into sub-questions shows benefit over answering directly. We release (at https://huggingface.co/datasets/corbyrosset/researchy\_questions) about 100k Researchy Questions with a permissive CDLA-2.0 license, along with click histograms on over 350k Clueweb22 URLs that were clicked for each question.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Rosset, Corbin and Chung, Ho-Lam and Qin, Guanghui and Chau, Ethan and Feng, Zhuo and Awadallah, Ahmed and Neville, Jennifer and Rao, Nikhil},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {deepresearch, multi-document ir, non-factoid qa},
	pages = {3712--3722},
}

@inproceedings{ueki_u-cker_2025,
	address = {New York, NY, USA},
	series = {{LSC} '25},
	title = {U-{Cker}: {A} {Prototype} {System} for the {Lifelog} {Search} {Challenge} 2025},
	isbn = {979-8-4007-1857-1},
	url = {https://doi.org/10.1145/3729459.3748688},
	doi = {10.1145/3729459.3748688},
	abstract = {This paper presents U-Cker, a lifelog retrieval system developed for our first participation in the Lifelog Search Challenge (LSC’25). The system is designed to support lifelog image retrieval based on multiple conditions, allowing users to input various types of information such as multiple text descriptions, images, temporal constraints, and location-based filters. As a core component of our system, we use the CLIP model to bridge the gap between various user inputs and the underlying visual data. With its flexible input design, U-Cker already covers the basic functionality required for lifelog search and has shown promising results on past LSC tasks. Building on this foundation, we plan to extend its capabilities in future work.},
	booktitle = {Proceedings of the 8th {Annual} {ACM} {Workshop} on the {Lifelog} {Search} {Challenge}},
	publisher = {Association for Computing Machinery},
	author = {Ueki, Kazuya and Muto, Ryo and Wada, Takuya and Akaba, Ryota and Fernandez, Genesis Faith Layag},
	year = {2025},
	keywords = {Information retrieval, Lifelog, Retrieval system},
	pages = {58--62},
}

@inproceedings{han_enhancing_2024,
	address = {New York, NY, USA},
	series = {{ICAIF} '24},
	title = {Enhancing {Investment} {Analysis}: {Optimizing} {AI}-{Agent} {Collaboration} in {Financial} {Research}},
	isbn = {979-8-4007-1081-0},
	url = {https://doi.org/10.1145/3677052.3698645},
	doi = {10.1145/3677052.3698645},
	abstract = {In recent years, the application of generative artificial intelligence (GenAI) in financial analysis and investment decision-making has gained significant attention. However, most existing approaches rely on single-agent systems, which fail to fully utilize the collaborative potential of multiple AI agents. In this paper, we propose a novel multi-agent collaboration system designed to enhance decision-making in financial investment research. The system incorporates agent groups with both configurable group sizes and collaboration structures to leverage the strengths of each agent group type. By utilizing a sub-optimal combination strategy, the system dynamically adapts to varying market conditions and investment scenarios, optimizing performance across different tasks. We focus on three sub-tasks: fundamentals, market sentiment, and risk analysis, by analyzing the 2023 SEC 10-K forms of 30 companies listed on the Dow Jones Index. Our findings reveal significant performance variations based on the configurations of AI agents for different tasks. The results demonstrate that our multi-agent collaboration system outperforms traditional single-agent models, offering improved accuracy, efficiency, and adaptability in complex financial environments. This study highlights the potential of multi-agent systems in transforming financial analysis and investment decision-making by integrating diverse analytical perspectives.},
	booktitle = {Proceedings of the 5th {ACM} {International} {Conference} on {AI} in {Finance}},
	publisher = {Association for Computing Machinery},
	author = {Han, Xuewen and Wang, Neng and Che, Shangkun and Yang, Hongyang and Zhang, Kunpeng and Xu, Sean Xin},
	year = {2024},
	note = {event-place: Brooklyn, NY, USA},
	keywords = {AI-agent, Financial Report Analysis, Investment Research, Multi-agent Collaboration},
	pages = {538--546},
}

@inproceedings{sun_exploring_2025,
	address = {New York, NY, USA},
	series = {{BDMIP} '24},
	title = {Exploring the {Application} of {Large} {Language} {Models} in {English} {Reading} and {Writing} {Courses}: {Technical} {Challenges} and {Development} {Opportunities}},
	isbn = {979-8-4007-1040-7},
	url = {https://doi.org/10.1145/3735014.3735915},
	doi = {10.1145/3735014.3735915},
	abstract = {As large language models (LLMs) evolve rapidly in natural language processing, their application potential in educational scenes has become increasingly prominent. This article aims to explore the specific application and technical realization of LLMs in English reading and writing courses and solve the issues in practical teaching. Focusing on the core tasks of automatic composition correction, reading material generation and conversational writing guidance, this paper proposes an improved framework utilizing conditional Generative Adversarial Networks (cGAN). This framework improves the quality and controllability of model output by introducing conditional embedding layers, strengthening learning reward mechanisms and adaptive difficulty generation algorithms. The results show that, compared with the benchmark models such as BERT and T5, the proposed model improves accuracy by 25.51\% at the highest, and the generation efficiency is also significantly optimized under large-scale data sets. In addition, a questionnaire survey of 50 teachers and 100 students shows that more than 85\% of users are satisfied with the usability and practicability of the system.CCS CONCEPTS • Applied computing∼Education∼Computer-assisted instruction•Applied computing∼Education∼Collaborative learning},
	booktitle = {Proceedings of the 2024 {International} {Conference} on {Big} {Data} {Mining} and {Information} {Processing}},
	publisher = {Association for Computing Machinery},
	author = {Sun, Yangzi},
	year = {2025},
	pages = {291--296},
}

@inproceedings{schulte_what_2025,
	address = {New York, NY, USA},
	series = {{ITiCSE} 2024},
	title = {What {We} {Talk} {About} {When} {We} {Talk} {About} {K}-12 {Computing} {Education}},
	isbn = {979-8-4007-1208-1},
	url = {https://doi.org/10.1145/3689187.3709612},
	doi = {10.1145/3689187.3709612},
	abstract = {K-12 computing education research is a rapidly growing field of research, both driven by and driving the implementation of computing as a school and extra-curricular subject globally. In the context of discipline-based education research, it is a new and emerging field, drawing on areas such as mathematics and science education research for inspiration and theoretical bases. The urgency around investigating effective teaching and learning in computing in school alongside broadening participation has led to much of the field being focused on empirical research. Less attention has been paid to the underlying philosophical assumptions informing the discipline, which might include a critical examination of the rationale for K-12 computing education, its goals and perspectives, and associated inherent values and beliefs. In this working group, we conducted an analysis of the implicit and hidden values, perspectives and goals underpinning computing education at school in order to shed light on the question of what we are talking about when we talk about K-12 computing education. To do this we used a multi-faceted approach to identify implicit rationales for K-12 computing education and examine what these might mean for the implemented curriculum. Methods used include both traditional and natural language processing techniques for examining relevant literature, alongside an examination of the theoretical literature relating to education theory. As a result we identified four traditions for K-12 computing education: algorithmic, design-making, scientific and societal. From this we have developed a framework for the exemplification of these traditions, alongside several potential use cases. We suggest that while this work may provoke some discussion and debate, it will help researchers and others to identify and express the rationales they draw on with respect to computing education.},
	booktitle = {2024 {Working} {Group} {Reports} on {Innovation} and {Technology} in {Computer} {Science} {Education}},
	publisher = {Association for Computing Machinery},
	author = {Schulte, Carsten and Sentance, Sue and Sparmann, Sören and Altin, Rukiye and Friebroon-Yesharim, Mor and Landman, Martina and Rücker, Michael T. and Satavlekar, Spruha and Siegel, Angela and Tedre, Matti and Tubino, Laura and Vartiainen, Henriikka and VelÁzquez-Iturbide, J. Ángel and Waite, Jane and Wu, Zihan},
	year = {2025},
	note = {event-place: Milan, Italy},
	keywords = {computing education, curriculum, educational traditions, k-12 education, philosophy, rationales},
	pages = {226--257},
}

@inproceedings{roy_beyond_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {Beyond {Accuracy}: {Investigating} {Error} {Types} in {GPT}-4 {Responses} to {USMLE} {Questions}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657882},
	doi = {10.1145/3626772.3657882},
	abstract = {GPT-4 demonstrates high accuracy in medical QA tasks, leading with an accuracy of 86.70\%, followed by Med-PaLM 2 at 86.50\%. However, around 14\% of errors remain. Additionally, current works use GPT-4 to only predict the correct option without providing any explanation and thus do not provide any insight into the thinking process and reasoning used by GPT-4 or other LLMs. Therefore, we introduce a new domain-specific error taxonomy derived from collaboration with medical students. Our GPT-4 USMLE Error (G4UE) dataset comprises 4153 GPT-4 correct responses and 919 incorrect responses to the United States Medical Licensing Examination (USMLE) respectively. These responses are quite long (258 words on average), containing detailed explanations from GPT-4 justifying the selected option. We then launch a large-scale annotation study using the Potato annotation platform and recruit 44 medical experts through Prolific, a well-known crowdsourcing platform. We annotated 300 out of these 919 incorrect data points at a granular level for different classes and created a multi-label span to identify the reasons behind the error. In our annotated dataset, a substantial portion of GPT-4's incorrect responses is categorized as a "Reasonable response by GPT-4," by annotators. This sheds light on the challenge of discerning explanations that may lead to incorrect options, even among trained medical professionals. We also provide medical concepts and medical semantic predications extracted using the SemRep tool for every data point. We believe that it will aid in evaluating the ability of LLMs to answer complex medical questions. We make the resources available at https://github.com/roysoumya/usmle-gpt4-error-taxonomy.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Roy, Soumyadeep and Khatua, Aparup and Ghoochani, Fatemeh and Hadler, Uwe and Nejdl, Wolfgang and Ganguly, Niloy},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {gpt-4, medical qa, multi-label dataset, usmle error taxonomy},
	pages = {1073--1082},
}

@inproceedings{lv_study_2024,
	address = {New York, NY, USA},
	series = {{DEAI} '24},
	title = {A study of {AIGC}-enabled international marketing},
	isbn = {979-8-4007-1714-7},
	url = {https://doi.org/10.1145/3675417.3675447},
	doi = {10.1145/3675417.3675447},
	abstract = {The intelligent transformation and development of domestic small and medium-sized manufacturing enterprises is of great significance for transferring internal production capacity, enhancing the level of opening up to the outside world, and promoting the high-quality development of the foreign trade industry.The development of AIGC (Artificial Intelligence Generated Content) is not only a major technological breakthrough in the field of artificial intelligence, but also its highly efficient content production drives the generation of new intelligent export methods in the manufacturing industry. Through the mass generation of text, the use of pre-training models as well as the development and optimization of cue words, to the manufacturing and exporting enterprises to output content in line with SEO (Search Engine Optimization) rules, through the optimization of internal and external chains to improve search engine rankings, so as to enhance the overseas visibility of the enterprise's products, and to open up the sales of the products. Based on the mechanism analysis of economics and management perspective, AIGC can provide professional and in-depth website enhancement diagnostic solutions and key optimization for foreign trade enterprises on a regular basis through the revolution of content production, so as to enhance the export efficiency and competitiveness of foreign trade enterprises. Therefore, the application of AIGC technology in foreign trade enterprises should be promoted, and AIGC technology providers should be encouraged to strengthen the training of large models in different industries, so as to provide specialized technical support for export enterprises.},
	booktitle = {Proceedings of the 2024 {Guangdong}-{Hong} {Kong}-{Macao} {Greater} {Bay} {Area} {International} {Conference} on {Digital} {Economy} and {Artificial} {Intelligence}},
	publisher = {Association for Computing Machinery},
	author = {Lv, Han and Wang, Kun},
	year = {2024},
	note = {event-place: Hongkong, China},
	pages = {179--191},
}

@inproceedings{li_novel_2025,
	address = {New York, NY, USA},
	series = {{LAK} '25},
	title = {A {Novel} {Approach} to {Scalable} and {Automatic} {Topic}-{Controlled} {Question} {Generation} in {Education}},
	isbn = {979-8-4007-0701-8},
	url = {https://doi.org/10.1145/3706468.3706487},
	doi = {10.1145/3706468.3706487},
	abstract = {The development of Automatic Question Generation (QG) models has the potential to significantly improve educational practices by reducing the teacher workload associated with creating educational content. This paper introduces a novel approach to educational question generation that controls the topical focus of questions. The proposed Topic-Controlled Question Generation (T-CQG) method enhances the relevance and effectiveness of the generated content for educational purposes. Our approach uses fine-tuning on a pre-trained T5-small model, employing specially created datasets tailored to educational needs. The research further explores the impacts of pre-training strategies, quantisation, and data augmentation on the model’s performance. We specifically address the challenge of generating semantically aligned questions with paragraph-level contexts, thereby improving the topic specificity of the generated questions. In addition, we introduce and explore novel evaluation methods to assess the topical relatedness of the generated questions. Our results, validated through rigorous offline and human-backed evaluations, demonstrate that the proposed models effectively generate high-quality, topic-focused questions. These models have the potential to reduce teacher workload and support personalised tutoring systems by serving as bespoke question generators. With its relatively small number of parameters, the proposals not only advance the capabilities of question generation models for handling specific educational topics but also offer a scalable solution that reduces infrastructure costs. This scalability makes them feasible for widespread use in education without reliance on proprietary large language models like ChatGPT.},
	booktitle = {Proceedings of the 15th {International} {Learning} {Analytics} and {Knowledge} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Li, Ziqing and Cukurova, Mutlu and Bulathwela, Sahan},
	year = {2025},
	keywords = {Educational Question Generation, Formative Assessment, Natural Language Processing, Personalised Testing, Summative Assessment},
	pages = {148--158},
}

@inproceedings{liu_t-rap_2024,
	address = {New York, NY, USA},
	series = {Internetware '24},
	title = {T-{RAP}: {A} {Template}-guided {Retrieval}-{Augmented} {Vulnerability} {Patch} {Generation} {Approach}},
	isbn = {979-8-4007-0705-6},
	url = {https://doi.org/10.1145/3671016.3672506},
	doi = {10.1145/3671016.3672506},
	abstract = {Vulnerabilities exert great burden on developers in terms of debugging and maintenance. Automated Vulnerability Repair(AVR) is considered as a promising approach to alleviate the burden of developers. Template-based automated program repair techniques have shown their effectiveness in fixing general bugs. However, due to the diverse root causes of vulnerabilities, it is challenging to construct sufficient repair templates to cover various vulnerabilities. In this paper, we introduce a Template-guided Retrieval-Augmented Patch generation approach, named T-RAP. Inspired by retrieval-augmented techniques that effectively utilize historical data, our approach leverages repair templates to extract similar vulnerability repair patches from the codebase. These patches then guide the process of generating vulnerability patches. To extract similar patches, we also propose a matching algorithm specifically designed for the retrieval-augmented vulnerability repair. This involves identifying similarities between numerous templates and vulnerabilities during the template-guided stage. Experimental results demonstrate that T-RAP outperforms all the studied AVR approaches, repairing 56.8\% more vulnerabilities than VulRepair and 30.24\% more than VulMaster. It can also accurately repair more types of real-world vulnerabilities than VulMaster. Additionally, we evaluated the effectiveness of our patch retriever. The results indicate that our template-guided retriever, which is based on our matching algorithm, outperforms the retrieval algorithm proposed in the recent retrieval-augmented patch generation approach RAP-Gen.},
	booktitle = {Proceedings of the 15th {Asia}-{Pacific} {Symposium} on {Internetware}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Pei and Lin, Bo and Qin, Yihao and Weng, Cheng and Chen, Liqian},
	year = {2024},
	note = {event-place: Macau, China},
	keywords = {Automated Vulnerability Repair, Deep Learning, Repair Template, Software Vulnerability},
	pages = {105--114},
}

@inproceedings{mozafari_triviahg_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {{TriviaHG}: {A} {Dataset} for {Automatic} {Hint} {Generation} from {Factoid} {Questions}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657855},
	doi = {10.1145/3626772.3657855},
	abstract = {Nowadays, individuals tend to engage in dialogues with Large Language Models, seeking answers to their questions. In times when such answers are readily accessible to anyone, the stimulation and preservation of human's cognitive abilities, as well as the assurance of maintaining good reasoning skills by humans becomes crucial. This study addresses such needs by proposing hints (instead of final answers or before giving answers) as a viable solution. We introduce a framework for the automatic hint generation for factoid questions, employing it to construct TriviaHG, a novel large-scale dataset featuring 160,230 hints corresponding to 16,645 questions from the TriviaQA dataset. Additionally, we present an automatic evaluation method that measures the Convergence and Familiarity quality attributes of hints. To evaluate the TriviaHG dataset and the proposed evaluation method, we enlisted 10 individuals to annotate 2,791 hints and tasked 6 humans with answering questions using the provided hints. The effectiveness of hints varied, with success rates of 96\%, 78\%, and 36\% for questions with easy, medium, and hard answers, respectively. Moreover, the proposed automatic evaluation methods showed a robust correlation with annotators' results. Conclusively, the findings highlight three key insights: the facilitative role of hints in resolving unknown questions, the dependence of hint quality on answer difficulty, and the feasibility of employing automatic evaluation methods for hint assessment.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Mozafari, Jamshid and Jangra, Anubhav and Jatowt, Adam},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {hint generation, large language models, question answering},
	pages = {2060--2070},
}

@inproceedings{zhuang_document_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Document {Screenshot} {Retrievers} are {Vulnerable} to {Pixel} {Poisoning} {Attacks}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730056},
	doi = {10.1145/3726302.3730056},
	abstract = {Recent advancements in dense retrieval have introduced vision-language model (VLM)-based retrievers, such as DSE and ColPali, which leverage document screenshots embedded as vectors to enable effective search and offer a simplified pipeline over traditional text-only methods. In this study, we propose three pixel poisoning attack methods designed to compromise VLM-based retrievers and evaluate their effectiveness under various attack settings and parameter configurations. Our empirical results demonstrate that injecting even a single adversarial screenshot into the retrieval corpus can significantly disrupt search results, poisoning the top-10 retrieved documents for 41.9\% of queries in the case of DSE and 26.4\% for ColPali. These vulnerability rates notably exceed those observed with equivalent attacks on text-only retrievers. Moreover, when targeting a small set of known queries, the attack success rate raises, achieving complete success in certain cases. By exposing the vulnerabilities inherent in vision-language models, this work highlights the potential risks associated with their deployment.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zhuang, Shengyao and Khramtsova, Ekaterina and Ma, Xueguang and Koopman, Bevan and Lin, Jimmy and Zuccon, Guido},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {corpus poisoning, document screenshot retrieval, vlm-based dense retrievers},
	pages = {414--423},
}

@inproceedings{mou_unifying_2024,
	address = {New York, NY, USA},
	series = {{WWW} '24},
	title = {Unifying {Local} and {Global} {Knowledge}: {Empowering} {Large} {Language} {Models} as {Political} {Experts} with {Knowledge} {Graphs}},
	isbn = {979-8-4007-0171-9},
	url = {https://doi.org/10.1145/3589334.3645616},
	doi = {10.1145/3589334.3645616},
	abstract = {Large Language Models (LLMs) have revolutionized solutions for general natural language processing (NLP) tasks. However, deploying these models in specific domains still faces challenges like hallucination. While existing knowledge graph retrieval-based approaches offer partial solutions, they cannot be well adapted to the political domain. On one hand, existing generic knowledge graphs lack vital political context, hindering deductions for practical tasks. On the other hand, the nature of political questions often renders the direct facts elusive, necessitating deeper aggregation and comprehension of retrieved evidence. To address these challenges, we propose a Political Experts through Knowledge Graph Integration (PEG) framework. PEG entails the creation and utilization of a multi-view political knowledge graph (MVPKG), which integrates U.S. legislative, election, and diplomatic data, as well as conceptual knowledge from Wikidata. With MVPKG as its foundation, PEG enhances existing methods through knowledge acquisition, aggregation, and injection. This process begins with refining evidence through semantic filtering, followed by its aggregation into global knowledge via implicit or explicit methods. The integrated knowledge is then utilized by LLMs through prompts. Experiments on three real-world datasets across diverse LLMs confirm PEG's superiority in tackling political modeling tasks.},
	booktitle = {Proceedings of the {ACM} {Web} {Conference} 2024},
	publisher = {Association for Computing Machinery},
	author = {Mou, Xinyi and Li, Zejun and Lyu, Hanjia and Luo, Jiebo and Wei, Zhongyu},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	keywords = {knowledge graph, large language models, political science},
	pages = {2603--2614},
}

@inproceedings{ma_alibaba_2025,
	address = {New York, NY, USA},
	series = {{FSE} {Companion} '25},
	title = {Alibaba {LingmaAgent}: {Improving} {Automated} {Issue} {Resolution} via {Comprehensive} {Repository} {Exploration}},
	isbn = {979-8-4007-1276-0},
	url = {https://doi.org/10.1145/3696630.3728549},
	doi = {10.1145/3696630.3728549},
	abstract = {This paper presents Alibaba LingmaAgent, a novel Automated Software Engineering method designed to comprehensively understand and utilize whole software repositories for issue resolution. Deployed in TONGYI Lingma, an IDE-based coding assistant developed by Alibaba Cloud, LingmaAgent addresses the limitations of existing LLM-based agents that primarily focus on local code information. Our approach introduces a top-down method to condense critical repository information into a knowledge graph, reducing complexity, and employs a Monte Carlo tree search based strategy enabling agents to explore and understand entire repositories. We guide agents to summarize, analyze, and plan using repository-level knowledge, allowing them to dynamically acquire information and generate patches for real-world GitHub issues. In extensive experiments, LingmaAgent demonstrated significant improvements, achieving an 18.5\% relative improvement on the SWE-bench Lite benchmark compared to SWE-agent. In production deployment and evaluation at Alibaba Cloud, LingmaAgent automatically resolved 16.9\% of in-house issues faced by development engineers, and solved 43.3\% of problems after manual intervention. Additionally, we have open-sourced a Python prototype of LingmaAgent for reference by other industrial developers 1. In fact, LingmaAgent has been used as a developed reference by many subsequently agents.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Ma, Yingwei and Yang, Qingping and Cao, Rongyu and Li, Binhua and Huang, Fei and Li, Yongbin},
	year = {2025},
	note = {event-place: Clarion Hotel Trondheim, Trondheim, Norway},
	keywords = {automated program repair, automatic software engineering (ASE), fault localization, large language models (LLMs), monte carlo tree search (MCTS), software engineering agents},
	pages = {238--249},
}

@inproceedings{wang_talking_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {Talking {Spell}: {A} {Wearable} {System} {Enabling} {Real}-{Time} {Anthropomorphic} {Voice} {Interaction} with {Everyday} {Objects}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747617},
	doi = {10.1145/3746059.3747617},
	abstract = {Virtual assistants (VAs) have become ubiquitous in daily life, integrated into smartphones and smart devices, sparking interest in AI companions that enhance user experiences and foster emotional connections. However, existing companions are often embedded in specific objects—such as glasses, home assistants, or dolls—requiring users to form emotional bonds with unfamiliar items, which can lead to reduced engagement and feelings of detachment. To address this, we introduce Talking Spell1, a wearable system that empowers users to imbue any everyday object with speech and anthropomorphic personas through a user-centric radiative network. Leveraging advanced computer vision (e.g., YOLOv11[46] for object detection), large vision-language models (e.g., QWEN-VL[4] for persona generation), speech-to-text and text-to-speech technologies, Talking Spell guides users through three stages of emotional connection: acquaintance, familiarization, and bonding. We validated our system through a user study involving 12 participants, utilizing Talking Spell to explore four interaction intentions: entertainment, companionship, utility, and creativity. The results demonstrate its effectiveness in fostering meaningful interactions and emotional significance with everyday objects. Our findings indicate that Talking Spell creates engaging and personalized experiences, as demonstrated through various devices, ranging from accessories to essential wearables.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Xuetong and Pang, Ching Christie and Hui, Pan},
	year = {2025},
	keywords = {AI Companionship, Embodied and Explorable Interaction, Human-Object Interaction, Large Language Models (LLMs), On-body Devices, Ubiquitous Computing, Wearable},
}

@inproceedings{xie_beyond_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Beyond {Visual} {Perception}: {Insights} from {Smartphone} {Interaction} of {Visually} {Impaired} {Users} with {Large} {Multimodal} {Models}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3714210},
	doi = {10.1145/3706598.3714210},
	abstract = {Large multimodal models (LMMs) have enabled new AI-powered applications that help people with visual impairments (PVI) receive natural language descriptions of their surroundings through audible text. We investigated how this emerging paradigm of visual assistance transforms how PVI perform and manage their daily tasks. Moving beyond usability assessments, we examined both the capabilities and limitations of LMM-based tools in personal and social contexts, while exploring design implications for their future development. Through interviews with 14 visually impaired users of Be My AI (an LMM-based application) and analysis of its image descriptions from both study participants and social media platforms, we identified two key limitations. First, these systems’ context awareness suffers from hallucinations and misinterpretations of social contexts, styles, and human identities. Second, their intent-oriented capabilities often fail to grasp and act on users’ intentions. Based on these findings, we propose design strategies for improving both human-AI and AI-AI interactions, contributing to the development of more effective, interactive, and personalized assistive technologies.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Xie, Jingyi and Yu, Rui and Zhang, He and Billah, Syed Masum and Lee, Sooyeon and Carroll, John M.},
	year = {2025},
	keywords = {Be My AI., Be My Eyes, Human-AI interaction, large multimodal models (LMMs), People with visual impairments (PVI), remote sighted assistance (RSA), visual question answering (VQA)},
}

@inproceedings{jiang_research_2024,
	address = {New York, NY, USA},
	series = {{ICMVA} '24},
	title = {Research on {Engineering} {Management} {Question}-answering {System} in the {Communication} {Industry} {Based} on {Large} {Language} {Models} and {Knowledge} {Graphs}},
	isbn = {979-8-4007-1655-3},
	url = {https://doi.org/10.1145/3653946.3653961},
	doi = {10.1145/3653946.3653961},
	abstract = {In the engineering management of the communication industry, there are many issues, including low efficiency in information acquisition and limitations in the level of intelligence.Large language models, with their powerful text comprehension and generation capabilities, offer new perspectives for the development of this field.This study constructed a question-answering system using a combined approach of large language models and text knowledge bases. The system dynamically leverages abundant external knowledge and enhances the model's reasoning ability and interpretability through knowledge graphs. In response to five categories of issues in engineering management, experiments and in-depth analysis revealed that although large language models may lack granularity in addressing some complex problems, the question-answering system overall achieved intelligent assistance, improving the efficiency of collaborative engineering management.},
	booktitle = {Proceedings of the 2024 7th {International} {Conference} on {Machine} {Vision} and {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Jiang, Yingdi and Yao, Jiarui and Li, Fangfei and Zhang, Yan},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	keywords = {Engineering management, Keywords • Large language models, Knowledge graphs, Question-answering},
	pages = {100--105},
}

@inproceedings{piramanayagam_lifesearch_2025,
	address = {New York, NY, USA},
	series = {{LSC} '25},
	title = {{LifeSearch}: {Multimodal} {Lifelog} {Search} {System} for {LSC}'25},
	isbn = {979-8-4007-1857-1},
	url = {https://doi.org/10.1145/3729459.3748696},
	doi = {10.1145/3729459.3748696},
	abstract = {We introduce LifeSearch, a novel multimodal retrieval system developed for the Lifelog Search Challenge 2025 (LSC’25). Our proposed solution can query images across visual, spatial, and temporal domains. Central to our approach are spatial and temporal augmentation techniques, along with a time-constrained scoring mechanism. By integrating these methods with a hybrid retrieval strategy, LifeSearch improves the retrieval process, allowing users to execute complex lifelog queries and obtain highly relevant results.},
	booktitle = {Proceedings of the 8th {Annual} {ACM} {Workshop} on the {Lifelog} {Search} {Challenge}},
	publisher = {Association for Computing Machinery},
	author = {Piramanayagam, Shriram and Chen, Enting and Melo, Andre and Vougiouklis, Pavlos and Diao, Chenxin and Merita, Pascual and Jiang, Zeren and Lai, Ruofei and Pan, Jeff Z.},
	year = {2025},
	keywords = {Lifelog Search Challenge, Lifelogging, Multimodal Retrieval},
	pages = {28--33},
}

@inproceedings{cao_companykg_2024,
	address = {New York, NY, USA},
	series = {{KDD} '24},
	title = {{CompanyKG}: {A} {Large}-{Scale} {Heterogeneous} {Graph} for {Company} {Similarity} {Quantification}},
	isbn = {979-8-4007-0490-1},
	url = {https://doi.org/10.1145/3637528.3671515},
	doi = {10.1145/3637528.3671515},
	abstract = {This paper presents CompanyKG (version 2), a large-scale heterogeneous graph developed for fine-grained company similarity quantification and relationship prediction, crucial for applications in the investment industry such as market mapping, competitor analysis, and mergers and acquisitions. CompanyKG comprises 1.17 million companies represented as graph nodes, enriched with company description embeddings, and 51.06 million weighted edges denoting 15 distinct inter-company relations. To facilitate a thorough evaluation of methods for company similarity quantification and relationship prediction, we have created four annotated evaluation tasks: similarity prediction, competitor retrieval, similarity ranking, and edge prediction. We offer extensive benchmarking results for 11 reproducible predictive methods, categorized into three groups: node-only, edge-only, and node+edge. To our knowledge, CompanyKG is the first large-scale heterogeneous graph dataset derived from a real-world investment platform, specifically tailored for quantifying inter-company similarity and relationships.},
	booktitle = {Proceedings of the 30th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Cao, Lele and von Ehrenheim, Vilhelm and Granroth-Wilding, Mark and Anselmo Stahl, Richard and McCornack, Andrew and Catovic, Armin and Cavalcanti Rocha, Dhiana Deva},
	year = {2024},
	note = {event-place: Barcelona, Spain},
	keywords = {benchmark, company similarity quantification, edge prediction, graph neural network, investment, knowledge graph, private equity},
	pages = {4816--4827},
}

@inproceedings{kataria_learning_2023,
	address = {New York, NY, USA},
	series = {{COMPUTE} '23},
	title = {Learning to {Rank} for {Search} {Results} {Re}-ranking in {Learning} {Experience} {Platforms}},
	isbn = {979-8-4007-0840-4},
	url = {https://doi.org/10.1145/3627217.3627224},
	doi = {10.1145/3627217.3627224},
	abstract = {The ability to search and retrieve the right resources in a Learning Experience Platform (LXP) is critical in helping the workforce of an enterprise to upskill and deepen their expertise effectively. To ensure the best resources are shown as high in the result set as possible to catch learners’ attention, a supervised learning approach of training and deploying a Learning to Rank (LTR) model for re-ranking is proposed. This work specifically focuses on judgement list preparation taking advantage of the learning progress data available in LXPs, as well as on defining and measuring model performance through metrics in both test and production setups. In particular, it highlights the positive impact of the deployed LTR model in production using the defined metrics like average search result click position and percentage top N clicks.},
	booktitle = {Proceedings of the 16th {Annual} {ACM} {India} {Compute} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Kataria, Ayush and Venkateshprasanna, H M and Kummetha, Ashok Kumar Reddy},
	year = {2023},
	note = {event-place: Hyderabad, India},
	keywords = {Information Retrieval, Learning Experience Platforms, Learning to Rank, Supervised Learning},
	pages = {25--30},
}

@inproceedings{zulfikar_resonance_2025,
	address = {New York, NY, USA},
	series = {{AHs} '25},
	title = {Resonance: {Drawing} from {Memories} to {Imagine} {Positive} {Futures} through {AI}-{Augmented} {Journaling}},
	isbn = {979-8-4007-1566-2},
	url = {https://doi.org/10.1145/3745900.3746099},
	doi = {10.1145/3745900.3746099},
	abstract = {People inherently use experiences of their past while imagining their future, a capability that plays a crucial role in mental health. Resonance is an AI-powered journaling tool designed to augment this ability by offering AI-generated, action-oriented suggestions for future activities based on the user’s own past memories. Suggestions are offered when a new memory is logged and are followed by a prompt for the user to imagine carrying out the suggestion. In a two-week randomized controlled study (N=55), we found that using Resonance significantly improved mental health outcomes, reducing the users’ PHQ8 scores, a measure of current depression, and increasing their daily positive affect, particularly when they would likely act on the suggestion. Notably, the effectiveness of the suggestions was higher when they were personal, novel, and referenced the user’s logged memories. Finally, through open-ended feedback, we discuss the factors that encouraged or hindered the use of the tool.},
	booktitle = {Proceedings of the {Augmented} {Humans} {International} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Zulfikar, Wazeer and Chiaravalloti, Treyden and Shen, Jocelyn and Picard, Rosalind and Maes, Pattie},
	year = {2025},
	keywords = {large language models, memory augmentation, mental health, positive psychology},
	pages = {199--215},
}

@inproceedings{luo_imagescope_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{ImageScope}: {Unifying} {Language}-{Guided} {Image} {Retrieval} via {Large} {Multimodal} {Model} {Collective} {Reasoning}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714777},
	doi = {10.1145/3696410.3714777},
	abstract = {With the proliferation of images in online content, language-guided image retrieval (LGIR) has emerged as a research hotspot over the past decade, encompassing a variety of subtasks with diverse input forms. While the development of large multimodal models (LMMs) has significantly facilitated these tasks, existing approaches often address them in isolation, requiring the construction of separate systems for each task. This not only increases system complexity and maintenance costs, but also exacerbates challenges stemming from language ambiguity and complex image content, making it difficult for retrieval systems to provide accurate and reliable results. To this end, we propose ImageScope, a training-free, three-stage framework that leverages collective reasoning to unify LGIR tasks. The key insight behind the unification lies in the compositional nature of language, which transforms diverse LGIR tasks into a generalized text-to-image retrieval process, along with the reasoning of LMMs serving as a universal verification to refine the results. To be specific, in the first stage, we improve the robustness of the framework by synthesizing search intents across varying levels of semantic granularity using chain-of-thought (CoT) reasoning. In the second and third stages, we then reflect on retrieval results by verifying predicate propositions locally, and performing pairwise evaluations globally. Experiments conducted on six LGIR datasets demonstrate that ImageScope outperforms competitive baselines. Comprehensive evaluations and ablation studies further confirm the effectiveness of our design.},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Luo, Pengfei and Zhou, Jingbo and Xu, Tong and Xia, Yuan and Xu, Linli and Chen, Enhong},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {collective reasoning, language-guided image retrieval, large multimodal model},
	pages = {1666--1682},
}

@inproceedings{nguyen_assessing_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Assessing {Effective} {Token} {Length} of {Multimodal} {Models} for {Text}-to-{Image} {Retrieval}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730326},
	doi = {10.1145/3726302.3730326},
	abstract = {Multimodal embedding models have been widely adopted in text-to-image retrieval, enabling direct comparison between text and image modalities. However, how well they handle long text is poorly understood. For instance, Long-CLIP found that OpenAI's CLIP model, despite having a 77-token input limit, maintains optimal performance for only 20 tokens- its effective token length. In this paper, we build on the Long-CLIP study, and extend the analysis to other widely used multimodal models and find their effective token length. Unlike Long-CLIP, we examine how domain-specific language influences changes in effective token length and explore its implications on different domains. Based on our findings, we create a comprehensive reference of various models' effective token length across different domains; offering deeper insights into the true limitations of multimodal models used in text-to-image retrieval. Finally, we introduce a systematic benchmark that determines the effective token length of any multimodal model using a given dataset. Our results show that the effective token length is consistently lower than the input token limit for all models, meaning that these models cannot utilize all the text that can be given to them. We also find that the effective token length varies by dataset, with domain-specific language influencing how much text a model can use before retrieval performance plateaus. Our code is available for reproducibility at https://github.com/aiforsec/EffectiveTokenLength-MModels},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Nguyen, Le and Jain, Preet and Panchal, Krutik and Alam, Md Tanvirul and Rastogi, Nidhi},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {benchmarking, clip, image retrieval, long text, multimodal, text-to-image},
	pages = {3173--3182},
}

@inproceedings{wang_vifusion_2025,
	address = {New York, NY, USA},
	series = {{ICMR} '25},
	title = {{ViFusion}: {In}-{Network} {Tensor} {Fusion} for {Scalable} {Video} {Feature} {Indexing}},
	isbn = {979-8-4007-1877-9},
	url = {https://doi.org/10.1145/3731715.3733461},
	doi = {10.1145/3731715.3733461},
	abstract = {Large-scale video feature indexing in datacenters is critically dependent on efficient data transfer. Although in-network computation has emerged as a compelling strategy for accelerating feature extraction and reducing overhead in distributed multimedia systems, harnessing advanced networking resources at both the switch and host levels remains a formidable challenge. These difficulties are compounded by heterogeneous hardware, diverse application requirements, and complex multipath topologies. Existing methods focus primarily on optimizing inference for large neural network models using specialized collective communication libraries, which often face performance degradation in network congestion scenarios.To overcome these limitations, we present ViFusion, a communication aware tensor fusion framework that streamlines distributed video indexing by merging numerous small feature tensors into consolidated and more manageable units. By integrating an in-network computation module and a dedicated tensor fusion mechanism within datacenter environments, ViFusion substantially improves the efficiency of video feature indexing workflows. The deployment results show that ViFusion improves the throughput of the video retrieval system by 8–22× with the same level of latency as state-of-the-art systems.},
	booktitle = {Proceedings of the 2025 {International} {Conference} on {Multimedia} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Yisu and Zhu, Yixiang and Li, Xinjiao and Zhang, Yulong and Wu, Ruilong and Kutscher, Dirk},
	year = {2025},
	note = {event-place: Chicago, IL, USA},
	keywords = {in-network computation, tensor fusion, video feature indexing},
	pages = {1452--1460},
}

@inproceedings{yen_code_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Code {Shaping}: {Iterative} {Code} {Editing} with {Free}-form {AI}-{Interpreted} {Sketching}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713822},
	doi = {10.1145/3706598.3713822},
	abstract = {We introduce the concept of code shaping, an interaction paradigm for editing code using free-form sketch annotations directly on top of the code and console output. To evaluate this concept, we conducted a three-stage design study with 18 different programmers to investigate how sketches can communicate intended code edits to an AI model for interpretation and execution. The results show how different sketches are used, the strategies programmers employ during iterative interactions with AI interpretations, and interaction design principles that support the reconciliation between the code editor and sketches. Finally, we demonstrate the practical application of the code shaping concept with two use case scenarios, illustrating design implications from the study.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Yen, Ryan and Zhao, Jian and Vogel, Daniel},
	year = {2025},
	keywords = {Dynamic Abstraction, Ink-based Sketching, Programming Interface},
}

@inproceedings{talaei_storysage_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {{StorySage}: {Conversational} {Autobiography} {Writing} {Powered} by a {Multi}-{Agent} {Framework}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747681},
	doi = {10.1145/3746059.3747681},
	abstract = {Every individual carries a unique and personal life story shaped by their memories and experiences. However, these memories are often scattered and difficult to organize into a coherent narrative—a challenge that defines the task of autobiography writing. Existing conversational writing assistants tend to rely on generic user interactions and pre-defined guidelines, making it difficult for these systems to capture personal memories and develop a complete biography over time. We introduce StorySage, a user-driven software system designed to meet the needs of a diverse group of users that supports a flexible conversation and a structured approach to autobiography writing. Powered by a multi-agent framework composed of an Interviewer, Session Scribe, Planner, Section Writer, and Session Coordinator, our system iteratively collects user memories, updates their autobiography, and plans for future conversations. In experimental simulations, StorySage demonstrates its ability to navigate multiple sessions and capture user memories across many conversations. User studies (N = 28) highlight how StorySage maintains improved conversational flow, narrative completeness, and higher user satisfaction when compared to a baseline. In summary, StorySage contributes both a novel architecture for autobiography writing and insights into how multi-agent systems can enhance human-AI creative partnerships.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Talaei, Shayan and Li, Meijin and Grover, Kanu and Hippler, James Kent and Yang, Diyi and Saberi, Amin},
	year = {2025},
	keywords = {Biography Writing, Generative Conversational Agents, Human-AI interaction},
}

@inproceedings{zamani_retrieval-enhanced_2022,
	address = {New York, NY, USA},
	series = {{SIGIR} '22},
	title = {Retrieval-{Enhanced} {Machine} {Learning}},
	isbn = {978-1-4503-8732-3},
	url = {https://doi.org/10.1145/3477495.3531722},
	doi = {10.1145/3477495.3531722},
	abstract = {Although information access systems have long supportedpeople in accomplishing a wide range of tasks, we propose broadening the scope of users of information access systems to include task-driven machines, such as machine learning models. In this way, the core principles of indexing, representation, retrieval, and ranking can be applied and extended to substantially improve model generalization, scalability, robustness, and interpretability. We describe a generic retrieval-enhanced machine learning (REML) framework, which includes a number of existing models as special cases. REML challenges information retrieval conventions, presenting opportunities for novel advances in core areas, including optimization. The REML research agenda lays a foundation for a new style of information access research and paves a path towards advancing machine learning and artificial intelligence.},
	booktitle = {Proceedings of the 45th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zamani, Hamed and Diaz, Fernando and Dehghani, Mostafa and Metzler, Donald and Bendersky, Michael},
	year = {2022},
	note = {event-place: Madrid, Spain},
	keywords = {knowledge grounding, memory augmentation, retrieval augmentation},
	pages = {2875--2886},
}

@inproceedings{lee_understanding_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Understanding {Adolescents}' {Perceptions} of {Benefits} and {Risks} in {Health} {AI} {Technologies} through {Design} {Fiction}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713244},
	doi = {10.1145/3706598.3713244},
	abstract = {Despite the growing research on users’ perceptions of health AI, adolescents’ perspectives remain underexplored. This study explores adolescents’ perceived benefits and risks of health AI technologies in clinical and personal health settings. Employing Design Fiction, we conducted interviews with 16 adolescents (aged 13-17) using four fictional design scenarios that represent current and future health AI technologies as probes. Our findings revealed that with a positive yet cautious attitude, adolescents envision unique benefits and risks specific to their age group. While health AI technologies were seen as valuable learning resources, they also raised concerns about confidentiality with their parents. Additionally, we identified several factors, such as severity of health conditions and previous experience with AI, influencing their perceptions of trust and privacy in health AI. We explore how these insights can inform the future design of health AI technologies to support learning, engagement, and trust as adolescents navigate their healthcare journey.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Lee, Jamie and Jung, Kyuha and Newman, Erin Gregg and Chow, Emilie and Chen, Yunan},
	year = {2025},
	keywords = {Adolescents, Artificial Intelligence, Design Fiction, Health and Wellbeing},
}

@inproceedings{kraft_knowledge-enhanced_2024,
	address = {New York, NY, USA},
	series = {{FAccT} '24},
	title = {Knowledge-{Enhanced} {Language} {Models} {Are} {Not} {Bias}-{Proof}: {Situated} {Knowledge} and {Epistemic} {Injustice} in {AI}},
	isbn = {979-8-4007-0450-5},
	url = {https://doi.org/10.1145/3630106.3658981},
	doi = {10.1145/3630106.3658981},
	abstract = {The factual inaccuracies ("hallucinations") of large language models have recently inspired more research on knowledge-enhanced language modeling approaches. These are often assumed to enhance the overall trustworthiness and objectivity of language models. Meanwhile, the issue of bias is usually only mentioned as a limitation of statistical representations. This dissociation of knowledge-enhancement and bias is in line with previous research on AI engineers’ assumptions about knowledge, which indicate that knowledge is commonly understood as objective and value-neutral by this community. We argue that claims and practices by actors of the field still reflect this underlying conception of knowledge. We contrast this assumption with literature from social and, in particular, feminist epistemology, which argues that the idea of a universal disembodied knower is blind to the reality of knowledge practices and seriously challenges claims of "objective" or "neutral" knowledge. Knowledge enhancement techniques commonly use Wikidata and Wikipedia as their sources for knowledge, due to their large scales, public accessibility, and assumed trustworthiness. In this work, they serve as a case study for the influence of the social setting and the identity of knowers on epistemic processes. Indeed, the communities behind Wikidata and Wikipedia are known to be male-dominated and many instances of hostile behavior have been reported in the past decade. In effect, the contents of these knowledge bases are highly biased. It is therefore doubtful that these knowledge bases would contribute to bias reduction. In fact, our empirical evaluations of RoBERTa, KEPLER, and CoLAKE, demonstrate that knowledge enhancement may not live up to the hopes of increased objectivity. In our study, the average probability for stereotypical associations was preserved on two out of three metrics and performance-related gender gaps on knowledge-driven task were also preserved. We build on these results and critical literature to argue that the label of "knowledge" and the commonly held beliefs about it can obscure the harm that is still done to marginalized groups. Knowledge enhancement is at risk of perpetuating epistemic injustice, and AI engineers’ understanding of knowledge as objective per se conceals this injustice. Finally, to get closer to trustworthy language models, we need to rethink knowledge in AI and aim for an agenda of diversification and scrutiny from outgroup members.},
	booktitle = {Proceedings of the 2024 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Kraft, Angelie and Soulier, Eloïse},
	year = {2024},
	note = {event-place: Rio de Janeiro, Brazil},
	keywords = {bias, epistemology, fairness, feminism, knowledge enhancement, knowledge graphs, language models, natural language processing, representation},
	pages = {1433--1445},
}

@inproceedings{you_navigating_2025,
	address = {Ottawa, Ontario, Canada},
	series = {{ICSE} '25},
	title = {Navigating the {Testing} of {Evolving} {Deep} {Learning} {Systems}: {An} {Exploratory} {Interview} {Study}},
	isbn = {979-8-3315-0569-1},
	url = {https://doi.org/10.1109/ICSE55347.2025.00106},
	doi = {10.1109/ICSE55347.2025.00106},
	abstract = {Deep Learning (DL) systems have been widely adopted across various industrial domains such as autonomous driving and intelligent healthcare. As with traditional software, DL systems also need to constantly evolve to meet ever-changing user requirements. However, ensuring the quality of these continuously evolving systems presents significant challenges, especially in the context of testing. Understanding how industry developers address these challenges and what extra obstacles they are facing could provide valuable insights for further safeguarding the quality of DL systems. To reach this goal, we conducted semi-structured interviews with 22 DL developers from diverse domains and backgrounds. More specifically, our study focuses on exploring the challenges developers encounter in testing evolving DL systems, the practical solutions they employ, and their expectations for extra support. Our results highlight the difficulties in testing evolving DL systems (e.g., regression faults, online-offline differences, and test data collection) and identify the best practices for DL developers to address these challenges. Additionally, we pinpoint potential future research directions to enhance testing effectiveness in evolving DL systems.},
	booktitle = {Proceedings of the {IEEE}/{ACM} 47th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {You, Hanmo and Wang, Zan and Lin, Bin and Chen, Junjie},
	year = {2025},
	keywords = {deep learning, interview study, software evolution, testing},
	pages = {2726--2738},
}

@inproceedings{qiu_unearthing_2024,
	address = {New York, NY, USA},
	series = {{SOSP} '24},
	title = {Unearthing {Semantic} {Checks} for {Cloud} {Infrastructure}-as-{Code} {Programs}},
	isbn = {979-8-4007-1251-7},
	url = {https://doi.org/10.1145/3694715.3695974},
	doi = {10.1145/3694715.3695974},
	abstract = {Cloud infrastructures are increasingly managed by Infrastructure-as-Code (IaC) frameworks (e.g., Terraform). IaC frameworks enable cloud users to configure their resources in a declarative manner, without having to directly work with low-level cloud API calls. However, with today's IaC tooling, IaC programs that pass the compilation phase may still incur errors at deployment time, resulting in significant disruption. We observe that this stems from a fundamental semantic gap between IaC-level programs and cloud-level requirements—even a syntactically-correct IaC program may violate cloud-level expectations. To bridge this gap, we develop Zodiac, a tool that can unearth IaC-level semantic checks on cloud-level requirements. It provides an automated pipeline to mine these checks from online IaC repositories and validate them using deployment-based testing. We have applied Zodiac to Terraform resources offered by Microsoft Azure—a leading IaC framework and a leading cloud vendor—where it found 500+ semantic checks where violation would produce deployment failures. With these checks, we have identified 200+ buggy Terraform projects and helped fix errors within official Azure provider usage examples.},
	booktitle = {Proceedings of the {ACM} {SIGOPS} 30th {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {Association for Computing Machinery},
	author = {Qiu, Yiming and Kon, Patrick Tser Jern and Beckett, Ryan and Chen, Ang},
	year = {2024},
	note = {event-place: Austin, TX, USA},
	keywords = {cloud management, configuration mining, infrastructure as code, program analysis},
	pages = {574--589},
}

@inproceedings{nayak_experimental_2024,
	address = {New York, NY, USA},
	series = {{WWW} '24},
	title = {Experimental {Security} {Analysis} of {Sensitive} {Data} {Access} by {Browser} {Extensions}},
	isbn = {979-8-4007-0171-9},
	url = {https://doi.org/10.1145/3589334.3645683},
	doi = {10.1145/3589334.3645683},
	abstract = {Browser extensions offer a variety of valuable features and functionalities. They also pose a significant security risk if not properly designed or reviewed. Prior works have shown that browser extensions can access and manipulate data fields, including sensitive data such as passwords, credit card numbers, and Social Security numbers. In this paper, we present an empirical study of the security risks posed by browser extensions. Specifically, we first build a proof-of-concept extension that can steal sensitive user information. We find that the extension passes the Chrome Webstore review process. We then perform a measurement study on the top 10K website login pages to check if the extension access to password fields via JS. We find that none of the password fields are actively protected, and can be accessed using JS. Moreover, we found that 1K websites store passwords in plaintext in their page source, including popular websites like Google.com and Cloudflare.com. We also analyzed over 160K Chrome Web Store extensions for malicious behavior, finding that 28K have permission to access sensitive fields and 190 store password fields in variables. To analyze the behavioral workflow of the potentially malicious extensions, we propose an LLM-driven framework, Extension Reviewer. Finally, we discuss two countermeasures to address these risks: a bolt-on JavaScript package for immediate adoption by website developers allowing them to protect sensitive input fields, and a browser-level solution that alerts users when an extension accesses sensitive input fields. Our research highlights the urgent need for improved security measures to protect sensitive user information online.},
	booktitle = {Proceedings of the {ACM} {Web} {Conference} 2024},
	publisher = {Association for Computing Machinery},
	author = {Nayak, Asmit and Khandelwal, Rishabh and Fernandes, Earlence and Fawaz, Kassem},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	keywords = {browser extensions, browser vulnerabilities, chrome web store, data privacy, sensitive data access},
	pages = {1283--1294},
}

@inproceedings{tang_retrieval_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {Retrieval {Augmented} {Cross}-{Domain} {LifeLong} {Behavior} {Modeling} for {Enhancing} {Click}-through {Rate} {Prediction}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737261},
	doi = {10.1145/3711896.3737261},
	abstract = {Lifelong behavior modeling for single-domain has been widely investigated in industry click-through (CTR) prediction. However, some domains do not always have rich historical behaviors in online platforms, so cross-domain lifelong behavior modeling is overlooked. This paper proposes a novel retrieval augmented lifelong cross-domain net (RAL-CDNet) to address the challenges in cross-domain lifelong behavior modeling. There are three components in RAL-CDNet, i.e., cross-domain retrieval unit, cross-domain alignment unit, and cross-net. As the general search unit in the previous study, a cross-domain retrieval unit features a retrieval augmented paradigm that utilizes a pre-trained language model to learn the intrinsic textual information of user behaviors and generates the sequential behaviors from the source domain based on sequential behaviors in the target domain. The retrieval augmented behaviors can achieve consistency and capture accurate hidden interest for target domain CTR prediction. Furthermore, we propose the cross-domain alignment unit to align the embeddings across domains by adding a semantic-guided contrastive loss and auxiliary task loss in the source domain. This allows the embeddings to be consistent across domains and have enough source information to capture the cross-domain relation. Finally, the cross-net utilizes two-level attention techniques to enhance the final prediction in the target domain. We conduct extensive experiments on both a public dataset and an industrial dataset from the WeChat advertising platform to demonstrate the effectiveness of RAL-CDNet in terms of offline and online metrics.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Tang, Xing and Yang, Chaohua and Fu, Yuwen and Ao, Dongyang and Li, Shiwei and Lyu, Fuyuan and Liu, Dugang and He, Xiuqiang},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {click-through rate prediction, cross-domain, lifelong user behavior},
	pages = {4891--4900},
}

@inproceedings{zhong_screenaudit_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{ScreenAudit}: {Detecting} {Screen} {Reader} {Accessibility} {Errors} in {Mobile} {Apps} {Using} {Large} {Language} {Models}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713797},
	doi = {10.1145/3706598.3713797},
	abstract = {Many mobile apps are inaccessible, thereby excluding people from their potential benefits. Existing rule-based accessibility checkers aim to mitigate these failures by identifying errors early during development but are constrained in the types of errors they can detect. We present ScreenAudit, an LLM-powered system designed to traverse mobile app screens, extract metadata and transcripts, and identify screen reader accessibility errors overlooked by existing checkers. We recruited six accessibility experts including one screen reader user to evaluate ScreenAudit’s reports across 14 unique app screens. Our findings indicate that ScreenAudit achieves an average coverage of 69.2\%, compared to only 31.3\% with a widely-used accessibility checker. Expert feedback indicated that ScreenAudit delivered higher-quality feedback and addressed more aspects of screen reader accessibility compared to existing checkers, and that ScreenAudit would benefit app developers in real-world settings.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhong, Mingyuan and Chen, Ruolin and Chen, Xia and Fogarty, James and Wobbrock, Jacob O.},
	year = {2025},
	keywords = {accessibility audit., large language models, Mobile accessibility},
}

@inproceedings{nandi_enhancing_2025,
	address = {New York, NY, USA},
	series = {{CODS}-{COMAD} '24},
	title = {Enhancing {Customer} {Service} {Chatbots} with {Context}-{Aware} {NLU} through {Selective} {Attention} and {Multi}-task {Learning}},
	isbn = {979-8-4007-1124-4},
	url = {https://doi.org/10.1145/3703323.3703723},
	doi = {10.1145/3703323.3703723},
	abstract = {Customer service chatbots are conversational systems aimed at addressing customer queries, often by directing them to automated workflows. A crucial aspect of this process is the classification of the customer’s intent. Presently, most intent classification models for customer care utilise only customer query for intent prediction. This may result in low-accuracy models, which cannot handle ambiguous queries. An ambiguous query like “I didn’t receive my package” could indicate a delayed order, or an order that was delivered but the customer failed to receive it. Resolution of each of these scenarios requires the execution of very different sequence of steps. Utilizing additional information, such as the customer’s order delivery status, in the right manner can help identify the intent for such ambiguous queries. In this paper, we have introduced a context-aware NLU model that incorporates both, the customer query and contextual information from the customer’s order status for predicting customer intent. A novel selective attention module is used to extract relevant context features. We have also proposed a multi-task learning paradigm for the effective utilization of different label types available in our training data. Our suggested method, Multi-Task Learning Contextual NLU with Selective Attention Weighted Context (MTL-CNLU-SAWC), yields a 4.8\% increase in top 2 accuracy score over the baseline model which only uses user queries, and a 3.5\% improvement over existing state-of-the-art models that combine query and context. We have deployed our model to production for Walmart’s customer care domain. Accurate intent prediction through MTL-CNLU-SAWC helps to better direct customers to automated workflows, thereby significantly reducing escalations to human agents, leading to almost a million dollars in yearly savings for the company.},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Data} {Science} and {Management} of {Data} (12th {ACM} {IKDD} {CODS} and 30th {COMAD})},
	publisher = {Association for Computing Machinery},
	author = {Nandi, Subhadip and Agrawal, Neeraj and Singh, Anshika and Bhatt, Priyanka},
	year = {2025},
	pages = {220--228},
}

@inproceedings{platis_lion_2024,
	address = {New York, NY, USA},
	series = {{FSE} 2024},
	title = {The {Lion}, the {Ecologist} and the {Plankton}: {A} {Classification} of {Species} in {Multi}-bot {Ecosystems}},
	isbn = {979-8-4007-0658-5},
	url = {https://doi.org/10.1145/3663529.3663782},
	doi = {10.1145/3663529.3663782},
	abstract = {The vast majority of state-of-the-art and practice have, so far, focused on understanding and developing individual bots that support software development (DevBots), while the interactions and collaborations between those DevBots introduce intriguing challenges and synergies that can both disrupt and enhance development cycles. In this vision paper we propose a taxonomy for DevBot roles in an ecosystem, based on how they interact. Much like biology, DevBots ecosystems rely on a balance between the creation, usage and maintenance of DevBots, particularly, on how they depend on one another. Further we contribute with reflections on how these interactions affect multi-bot projects.},
	booktitle = {Companion {Proceedings} of the 32nd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Platis, Dimitrios and Erlenhov, Linda and Neto, Francisco Gomes de Oliveira},
	year = {2024},
	note = {event-place: Porto de Galinhas, Brazil},
	keywords = {Bots in Software Engineering, DevBots, Empirical Software Engineering, Software Development Bots},
	pages = {482--486},
}

@inproceedings{crossley_exploratory_2025,
	address = {New York, NY, USA},
	series = {L@{S} '25},
	title = {Exploratory {Assessment} of {Learning} in an {Intelligent} {Text} {Framework}: i℡{L} {RCT}},
	isbn = {979-8-4007-1291-3},
	url = {https://doi.org/10.1145/3698205.3729548},
	doi = {10.1145/3698205.3729548},
	abstract = {This study explores users' learning gains and experiences from reading within three versions of the same text. The versions included 1) a traditional digital text, 2) a productive text that required participants to produce knowledge about what they read, but without any feedback on the knowledge produced, and 3) an interactive text that required participants to produce knowledge and provided AI feedback and interaction. Learning gains were assessed in a randomized control trial where crowd-sourced users were assigned to one of the three versions and were examined based on the quality of constructed responses and summaries provided as well as through differences from a pre-test and a post-test. User experiences were investigated using survey results. Results indicated that users were generally satisfied with interacting with all versions the text, except the summary portion of the interactive text. Conversely, results indicated that users of the interactive text consistently wrote better summaries than in the productive condition, and they revised summaries to a greater degree and to a greater success. Lastly, results showed that knowledge gains occurred in all reading conditions and that readers in the interactive condition who spent more time reading the text showed stronger test scores overall.},
	booktitle = {Proceedings of the {Twelfth} {ACM} {Conference} on {Learning} @ {Scale}},
	publisher = {Association for Computing Machinery},
	author = {Crossley, Scott and Morris, Wesley and Choi, Joon Suh and Holmes, Langdon},
	year = {2025},
	note = {event-place: Palermo, Italy},
	keywords = {intelligent texts, natural language processing, reading assessment},
	pages = {2--12},
}

@inproceedings{meng_bridging_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Bridging the {Gap}: {From} {Ad}-hoc to {Proactive} {Search} in {Conversations}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3729915},
	doi = {10.1145/3726302.3729915},
	abstract = {Proactive search in conversations (PSC) aims to reduce user effort in formulating explicit queries by proactively retrieving useful relevant information given conversational context. Previous work in PSC either directly uses this context as input to off-the-shelf ad-hoc retrievers or further fine-tunes them on PSC data. However, ad-hoc retrievers are pre-trained on short and concise queries, while the PSC input is longer and noisier. This input mismatch between ad-hoc search and PSC limits retrieval quality. While fine-tuning on PSC data helps, its benefits remain constrained by this input gap. In this work, we propose Conv2Query, a novel conversation-to-query framework that adapts ad-hoc retrievers to PSC by bridging the input gap between ad-hoc search and PSC. Conv2Query maps conversational context into ad-hoc queries, which can either be used as input for off-the-shelf ad-hoc retrievers or for further fine-tuning on PSC data. Extensive experiments on two PSC datasets show that Conv2Query significantly improves ad-hoc retrievers' performance, both when used directly and after fine-tuning on PSC.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Meng, Chuan and Tonolini, Francesco and Mo, Fengran and Aletras, Nikolaos and Yilmaz, Emine and Kazai, Gabriella},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {conversational search, proactive search, query prediction},
	pages = {64--74},
}

@inproceedings{grimm_authoring_2024,
	address = {New York, NY, USA},
	series = {{HT} '24},
	title = {Authoring {Educational} {Hypercomics} assisted by {Large} {Language} {Models}},
	isbn = {979-8-4007-0595-3},
	url = {https://doi.org/10.1145/3648188.3675124},
	doi = {10.1145/3648188.3675124},
	abstract = {Interactive stories can be an effective approach for teaching purposes. One shortcoming is the effort necessary to author and create these stories, especially complex storylines with choices for the readers. Based on recent advances in Natural Language Processing (NLP), new opportunities arise for assistance systems in the context of interactive stories. In our work, we present an authoring approach and prototypical tool for the creation of visual comic-strip like interactive stories, a type of hypercomics, that integrate an Artificial Intelligence (AI) assistance. Such comics are already used in our Gekonnt hanDeln web platform. The AI assistance provides suggestions for the overall story outline as well as how to design and write individual story frames. We provide a detailed description about the approach and its prototypical implementation. Furthermore, we present a study evaluating the prototype with student groups and how the prototype evolved in an iterative style based on the students’ feedback.},
	booktitle = {Proceedings of the 35th {ACM} {Conference} on {Hypertext} and {Social} {Media}},
	publisher = {Association for Computing Machinery},
	author = {Grimm, Valentin and Rubart, Jessica},
	year = {2024},
	note = {event-place: Poznan, Poland},
	keywords = {Authoring, GPT, Hypercomics, Large Language Models, Storytelling},
	pages = {88--97},
}

@inproceedings{mittal_wavepulse_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {{WavePulse}: {Real}-time {Content} {Analytics} of {Radio} {Livestreams}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714810},
	doi = {10.1145/3696410.3714810},
	abstract = {Radio remains a pervasive medium for mass information dissemination, with AM/FM stations reaching more Americans than either smartphone-based social networking or live television. Increasingly, radio broadcasts are also streamed online and accessed over the Internet. We present WavePulse, a framework that records, documents, and analyzes radio content in real-time. While our framework is generally applicable, we showcase the efficacy of WavePulse in a collaborative project with a team of political scientists focusing on the 2024 Presidential Election. We use WavePulse to monitor livestreams of 396 news radio stations over a period of three months, processing close to 500,000 hours of audio streams. These streams were converted into time-stamped, diarized transcripts and analyzed to answer key political science questions at both the national and state levels. Our analysis revealed how local issues interacted with national trends, providing insights into information flow. Our results demonstrate WavePulse's efficacy in capturing and analyzing content from radio livestreams sourced from the Web. Code and dataset can be accessed at https://wave-pulse.io},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Mittal, Govind and Gupta, Sarthak and Wagle, Shruti and Chopra, Chirag and DeMattee, Anthony J. and Memon, Nasir and Ahamad, Mustaque and Hegde, Chinmay},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {large language models, radio livestreams, web content analytics},
	pages = {3731--3750},
}

@inproceedings{fischer_evaluation_2025,
	address = {New York, NY, USA},
	series = {{ECSEE} '25},
	title = {Evaluation of a {Node}-based {Automatic} {Short} {Answer} {Tool} “{NodeGrade}”},
	isbn = {979-8-4007-1282-1},
	url = {https://doi.org/10.1145/3723010.3723021},
	doi = {10.1145/3723010.3723021},
	abstract = {NodeGrade tries to provide a suitable solution for the problem of time-intensive short answer grading. This research focuses simultaneously on performance, functionality and user experience, which is underlined by a triangulated approach. The evaluation results show comparable performance of NodeGrade on public datasets, even outperforming GPT-4 on the SemEval 2013 Task 7. Matching of NodeGrade’s output with multiple human expert raters reveals some weaknesses regarding cases at the lower and upper boundary. In terms of user experience, the interviewed and observed students recognized both positive facets, like better learning support and helpful feedback, and negative sides, including technical limitations and lack of transparency. Overall, NodeGrade promises high potential for further practical use and testing in the field of software engineering education and automatic short answer grading.},
	booktitle = {Proceedings of the 6th {European} {Conference} on {Software} {Engineering} {Education}},
	publisher = {Association for Computing Machinery},
	author = {Fischer, David Vincent and Haug, Jim and Schoppel, Paul and Abke, Jörg and Becker, Matthias and Hagel, Georg},
	year = {2025},
	keywords = {AI in Education, ASAG, Automatic Short Answer Grading, Large Language Models, Natural Language Processing, Short Answer Scoring, Software Engineering Education},
	pages = {20--29},
}

@inproceedings{kambhamettu_explainable_2024,
	address = {New York, NY, USA},
	series = {{CHI} '24},
	title = {Explainable {Notes}: {Examining} {How} to {Unlock} {Meaning} in {Medical} {Notes} with {Interactivity} and {Artificial} {Intelligence}},
	isbn = {979-8-4007-0330-0},
	url = {https://doi.org/10.1145/3613904.3642573},
	doi = {10.1145/3613904.3642573},
	abstract = {Medical progress notes have recently become available to patients at an unprecedented scale. Progress notes offer patients insight into their care that they cannot find elsewhere. That said, reading a note requires patients to contend with the language, unspoken assumptions, and clutter common to clinical documentation. As the health system reinvents many of its interfaces to incorporate AI assistance, this paper examines what intelligent interfaces could do to help patients read their progress notes. In a qualitative study, we examine the needs of patients as they read a progress note. We then formulate a vision for the explainable note, an augmented progress note that provides support for directing attention, phrase-level understanding, and tracing lines of reasoning. This vision manifests in a set of patient-inspired opportunities for advancing intelligent interfaces for writing and reading progress notes.},
	booktitle = {Proceedings of the 2024 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kambhamettu, Hita and Metaxa, Danaë and Johnson, Kevin and Head, Andrew},
	year = {2024},
	note = {event-place: Honolulu, HI, USA},
	keywords = {attention, augmented medical texts, intelligent reading and writing, lines of reasoning, patient-provider communication, phrase-level understanding, progress notes},
}

@inproceedings{zhang_cse-sfp_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{CSE}-{SFP}: {Enabling} {Unsupervised} {Sentence} {Representation} {Learning} via a {Single} {Forward} {Pass}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3729938},
	doi = {10.1145/3726302.3729938},
	abstract = {As a fundamental task in Information Retrieval and Computational Linguistics, sentence representation has profound implications for a wide range of practical applications such as text clustering, content analysis, question-answering systems, and web search. Recent advances in pre-trained language models (PLMs) have driven remarkable progress in this field, particularly through unsupervised embedding derivation methods centered on discriminative PLMs like BERT. However, due to time and computational constraints, few efforts have attempted to integrate unsupervised sentence representation with generative PLMs, which typically possess much larger parameter sizes. Given that state-of-the-art models in both academia and industry are predominantly based on generative architectures, there is a pressing need for an efficient unsupervised text representation framework tailored to decoder-only PLMs. To address this concern, we propose CSE-SFP, an innovative method that exploits the structural characteristics of generative models. Compared to existing strategies, CSE-SFP requires only a single forward pass to perform effective unsupervised contrastive learning. Rigorous experimentation demonstrates that CSE-SFP not only produces higher-quality embeddings but also significantly reduces both training time and memory consumption. Furthermore, we introduce two ratio metrics that jointly assess alignment and uniformity, thereby providing a more robust means for evaluating the semantic spatial properties of encoding models. Our code and checkpoints are available at https://github.com/ZBWpro/CSE-SFP.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Bowen and Song, Zixin and Li, Chunping},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {contrastive learning, large language models, sentence representation, text embedding, text retrieval, unsupervised learning},
	pages = {1402--1412},
}

@inproceedings{dow_ar-based_2025,
	address = {New York, NY, USA},
	series = {{DIS} '25},
	title = {{AR}-{Based} {Embodied} {Avatar} {Assistance} for {Nonspeaking} {Autistic} {People}? {Design} and {Feasibility} {Study}},
	isbn = {979-8-4007-1485-6},
	url = {https://doi.org/10.1145/3715336.3735807},
	doi = {10.1145/3715336.3735807},
	abstract = {Many nonspeaking autistic individuals rely on Communication and Regulation Partners (CRPs) to develop spelling-based communication using physical letterboards, but this support is often geographically inaccessible. We developed a remote presence system using Augmented Reality (AR) to enable immersive, collaborative spelling instruction. The system features holographic letterboards and fully embodied avatars with real-time head and hand tracking, allowing remote interaction between students and CRPs. In a study with 18 nonspeaking autistic participants, 15 (83\%) successfully completed avatar-supported sessions. Interaction was higher, and participants reported a preference for the avatar condition over voice-only support. These findings demonstrate the feasibility of avatar-based AR telepresence for remote communication training. The system provides a demonstration of AR-supported interaction designed with nonspeaking autistic individuals—an underrepresented group in HCI—and offers design insights for inclusive telepresence technologies that address geographic and accessibility barriers.},
	booktitle = {Proceedings of the 2025 {ACM} {Designing} {Interactive} {Systems} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Dow, Travis and Pratishtha, Pratishtha and Alabood, Lorans and Jaswal, Vikram K. and Krishnamurthy, Diwakar},
	year = {2025},
	keywords = {Accessibility, Assistive Technology, Augmented Reality, Mixed Reality, Nonspeaking Autistic People},
	pages = {423--440},
}

@inproceedings{wilhelm_how_2025,
	address = {New York, NY, USA},
	series = {{CUI} '25},
	title = {How {Managers} {Perceive} {AI}-{Assisted} {Conversational} {Training} for {Workplace} {Communication}},
	isbn = {979-8-4007-1527-3},
	url = {https://doi.org/10.1145/3719160.3736639},
	doi = {10.1145/3719160.3736639},
	abstract = {Effective workplace communication is essential for managerial success, yet many managers lack access to tailored and sustained training. Although AI-assisted communication systems may offer scalable training solutions, little is known about how managers envision the role of AI in helping them improve their communication skills. To investigate this, we designed a conversational role-play system, CommCoach, as a functional probe to understand how managers anticipate using AI to practice their communication skills. Through semi-structured interviews, participants emphasized the value of adaptive, low-risk simulations for practicing difficult workplace conversations. They also highlighted opportunities, including human-AI teaming, transparent and context-aware feedback, and greater control over AI-generated personas. AI-assisted communication training should balance personalization, structured learning objectives, and adaptability to different user styles and contexts. However, achieving this requires carefully navigating tensions between adaptive and consistent AI feedback, realism and potential bias, and the open-ended nature of AI conversations versus structured workplace discourse.},
	booktitle = {Proceedings of the 7th {ACM} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Wilhelm, Lance T and Ding, Xiaohan and Knutsen, Kirk McInnis and Carik, Buse and Rho, Eugenia H},
	year = {2025},
	keywords = {adaptive systems, communication training, computational social science, conversational system, human-AI interaction, large language models, leadership, management, role-play, system design, workplace communication},
}

@inproceedings{lee_sensible_2025,
	address = {New York, NY, USA},
	series = {{UIST} '25},
	title = {Sensible {Agent}: {A} {Framework} for {Unobtrusive} {Interaction} with {Proactive} {AR} {Agents}},
	isbn = {979-8-4007-2037-6},
	url = {https://doi.org/10.1145/3746059.3747748},
	doi = {10.1145/3746059.3747748},
	abstract = {Proactive AR agents promise context-aware assistance, but their interactions often rely on explicit voice prompts or responses, which can be disruptive or socially awkward. We introduce Sensible Agent, a framework designed for unobtrusive interaction with these proactive agents. Sensible Agent dynamically adapts both “what” assistance to offer and, crucially, “how” to deliver it, based on real-time multimodal context sensing. Informed by an expert workshop (n=12) and a data annotation study (n=40), the framework leverages egocentric cameras, multimodal sensing, and Large Multimodal Models (LMMs) to infer context and suggest appropriate actions delivered via minimally intrusive interaction modes. We demonstrate our prototype on an XR headset through a user study (n=10) in both AR and VR scenarios. Results indicate that Sensible Agent significantly reduces perceived interaction effort compared to voice-prompted baseline, while maintaining high usability and achieving higher preference.},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Lee, Geonsun and Xia, Min and Numan, Nels and Qian, Xun and Li, David and Chen, Yanhe and Kulshrestha, Achin and Chatterjee, Ishan and Zhang, Yinda and Manocha, Dinesh and Kim, David and Du, Ruofei},
	year = {2025},
	keywords = {Adaptive Interfaces, Augmented Reality, Context-Awareness, Human-Agent Interaction, Large Multimodal Models, Multimodal Interaction, Proactive Agents, Unobtrusive Interaction},
}

@inproceedings{wang_collaboration_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Collaboration and {Controversy} {Among} {Experts}: {Rumor} {Early} {Detection} by {Tuning} a {Comment} {Generator}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3729928},
	doi = {10.1145/3726302.3729928},
	abstract = {Over the past decade, social media platforms have been key in spreading rumors, leading to significant negative impacts. To counter this, the community has developed various Rumor Detection (RD) algorithms to automatically identify them using user comments as evidence. However, these RD methods often fail in the early stages of rumor propagation when only limited user comments are available, leading the community to focus on a more challenging topic named Rumor Early Detection (RED). Typically, existing RED methods learn from limited semantics in early comments. However, our preliminary experiment reveals that the RED models always perform best when the number of training and test comments is consistent and extensive. This inspires us to address the RED issue by generating more human-like comments to support this hypothesis. To implement this idea, we tune a comment generator by simulating expert collaboration and controversy and propose a new RED framework named CAMERED. Specifically, we integrate a mixture-of-expert structure into a generative language model and present a novel routing network for expert collaboration. Additionally, we synthesize a knowledgeable dataset and design an adversarial learning strategy to align the style of generated comments with real-world comments. We further integrate generated and original comments with a mutual controversy fusion module. Experimental results show that CAMERED outperforms state-of-the-art RED baseline models and generation methods, demonstrating its effectiveness.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Bing and Zhao, Bingrui and Li, Ximing and Li, Changchun and Gao, Wanfu and Wang, Shengsheng},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {adversarial training, language model, mixture-of-expert, rumor detection, social media, text generation},
	pages = {468--478},
}

@inproceedings{venkatraman_you_2024,
	address = {New York, NY, USA},
	series = {{HT} '24},
	title = {You {Shall} {Know} a {Forum} by the {Words} they {Keep}: {Analyzing} {Language} {Use} in {Accessibility} {Forums} for {Blind} {Users}},
	isbn = {979-8-4007-0595-3},
	url = {https://doi.org/10.1145/3648188.3675151},
	doi = {10.1145/3648188.3675151},
	abstract = {Discussion forums are one of the favored platforms for knowledge sharing. Given their popularity, copious research exists on understanding linguistic and behavioral characteristics of forum conversations. However, prior investigations have mainly focused on general forums designed primarily for sighted users, and as such the applicability of their findings to the dedicated accessibility discussion forums frequented by blind individuals remains unanswered. To bridge this knowledge gap, and facilitate the development of better-informed assistive technologies for blind people, we investigated language use and identified the key semantic and cognitive characteristics of online accessibility forums. To aid our investigation, we collected a dataset of 1000 accessibility forum threads and a baseline of 1000 general forum threads. These threads were carefully curated to ensure similarity of topics discussed. We found the language in accessibility forum conversations to be more task-oriented and less abstract, with significantly higher number of descriptive action words than in general forum conversations. Results also showed an emphasis on sharing first-hand personal experiences in accessibility forums, relative to the general forums.},
	booktitle = {Proceedings of the 35th {ACM} {Conference} on {Hypertext} and {Social} {Media}},
	publisher = {Association for Computing Machinery},
	author = {Venkatraman, Nithiya and Aiyer, Anand and Prakash, Yash and Ashok, Vikas},
	year = {2024},
	note = {event-place: Poznan, Poland},
	keywords = {accessibility online forums, blind, discussion forums, language usage, linguistic analysis, screen readers, Social media},
	pages = {230--238},
}

@inproceedings{qiu_simplifying_2023,
	address = {New York, NY, USA},
	series = {{HotNets} '23},
	title = {Simplifying {Cloud} {Management} with {Cloudless} {Computing}},
	isbn = {979-8-4007-0415-4},
	url = {https://doi.org/10.1145/3626111.3628206},
	doi = {10.1145/3626111.3628206},
	abstract = {Cloud computing has transformed the IT industry, but managing cloud infrastructures remains a difficult task. We make a case for putting today's management practices, known as "Infrastructure-as-Code," on a firmer ground via a principled design. We call this end goal Cloudless Computing: it aims to simplify cloud infrastructure management tasks by supporting them "as-a-service," analogous to serverless computing that relieves users of the burden of managing server instances. By assisting tenants with these tasks, cloud resources will be presented to their users more readily without the undue burden of complex control. We describe the research problems by examining the typical lifecycle of today's cloud infrastructure management, and identify places where a cloudless approach will advance the state of the art.},
	booktitle = {Proceedings of the 22nd {ACM} {Workshop} on {Hot} {Topics} in {Networks}},
	publisher = {Association for Computing Machinery},
	author = {Qiu, Yiming and Kon, Patrick Tser Jern and Xing, Jiarong and Huang, Yibo and Liu, Hongyi and Wang, Xinyu and Huang, Peng and Chowdhury, Mosharaf and Chen, Ang},
	year = {2023},
	note = {event-place: Cambridge, MA, USA},
	keywords = {cloud management, Infrastructure as code},
	pages = {95--101},
}

@inproceedings{bai_kgquiz_2024,
	address = {New York, NY, USA},
	series = {{WWW} '24},
	title = {{KGQuiz}: {Evaluating} the {Generalization} of {Encoded} {Knowledge} in {Large} {Language} {Models}},
	isbn = {979-8-4007-0171-9},
	url = {https://doi.org/10.1145/3589334.3645623},
	doi = {10.1145/3589334.3645623},
	abstract = {Large language models (LLMs) demonstrate remarkable performance on knowledge-intensive tasks, suggesting that real-world knowledge is encoded in their model parameters. However, besides explorations on a few probing tasks in limited knowledge domains, it is not well understood how to evaluate LLMs' knowledge systematically and how well their knowledge abilities generalize, across a spectrum of knowledge domains and progressively complex task formats. To this end, we propose KGQuiz, a knowledge-intensive benchmark to comprehensively investigate the knowledge generalization abilities of LLMs. KGQuiz is a scalable framework constructed from triplet-based knowledge, which covers three knowledge domains and consists of five tasks with increasing complexity: true-or-false, multiple-choice QA, blank filling, factual editing, and open-ended knowledge generation. To gain a better understanding of LLMs' knowledge abilities and their generalization, we evaluate 10 open-source and black-box LLMs on the KGQuiz benchmark across the five knowledge-intensive tasks and knowledge domains. Extensive experiments demonstrate that LLMs achieve impressive performance in straightforward knowledge QA tasks, while settings and contexts requiring more complex reasoning or employing domain-specific facts still present significant challenges. We envision KGQuiz as a testbed to analyze such nuanced variations in performance across domains and task formats, and ultimately to understand, evaluate, and improve LLMs' knowledge abilities across a wide spectrum of knowledge domains and tasks.},
	booktitle = {Proceedings of the {ACM} {Web} {Conference} 2024},
	publisher = {Association for Computing Machinery},
	author = {Bai, Yuyang and Feng, Shangbin and Balachandran, Vidhisha and Tan, Zhaoxuan and Lou, Shiqi and He, Tianxing and Tsvetkov, Yulia},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	keywords = {knowledge probing, large language models},
	pages = {2226--2237},
}

@inproceedings{zou_pscon_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{PSCon}: {Product} {Search} {Through} {Conversations}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730278},
	doi = {10.1145/3726302.3730278},
	abstract = {Conversational Product Search ( CPS ) systems interact with users via natural language to offer personalized and context-aware product lists. However, most existing research on CPS is limited to simulated conversations, due to the lack of a real CPS dataset driven by human-like language. Moreover, existing conversational datasets for e-commerce are constructed for a particular market or a particular language and thus can not support cross-market and multi-lingual usage. In this paper, we propose a CPS data collection protocol and create a new CPS dataset, called PSCon, which assists product search through conversations with human-like language. The dataset is collected by a coached human-human data collection protocol and is available for dual markets and two languages. By formulating the task of CPS, the dataset allows for comprehensive and in-depth research on six subtasks: user intent detection, keyword extraction, system action prediction, question selection, item ranking, and response generation. Moreover, we present a concise analysis of the dataset and propose a benchmark model on the proposed CPS dataset. Our proposed dataset and model will be helpful for facilitating future research on CPS.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Zou, Jie and Aliannejadi, Mohammad and Kanoulas, Evangelos and Han, Shuxi and Ma, Heli and Wang, Zheng and Yang, Yang and Shen, Heng Tao},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {conversational product search, dataset, product search},
	pages = {3659--3669},
}

@inproceedings{yao_rtlrewriter_2025,
	address = {New York, NY, USA},
	series = {{ICCAD} '24},
	title = {{RTLRewriter}: {Methodologies} for {Large} {Models} aided {RTL} {Code} {Optimization}},
	isbn = {979-8-4007-1077-3},
	url = {https://doi.org/10.1145/3676536.3676775},
	doi = {10.1145/3676536.3676775},
	abstract = {Register Transfer Level (RTL) code optimization is crucial for enhancing the efficiency and performance of digital circuits during early synthesis stages. Currently, optimization relies heavily on manual efforts by skilled engineers, often requiring multiple iterations based on synthesis feedback. In contrast, existing compiler-based methods fall short in addressing complex designs. This paper introduces RTLRewriter, an innovative framework that leverages large models to optimize RTL code. A circuit partition pipeline is utilized for fast synthesis and efficient rewriting. A multi-modal program analysis is proposed to incorporate vital visual diagram information as optimization cues. A specialized search engine is designed to identify useful optimization guides, algorithms, and code snippets that enhance the model's ability to generate optimized RTL. Additionally, we introduce a Cost-aware Monte Carlo Tree Search (C-MCTS) algorithm for efficient rewriting, managing diverse retrieved contents and steering the rewriting results. Furthermore, a fast verification pipeline is proposed to reduce verification cost. To cater to the needs of both industry and academia, we propose two benchmarking suites: the long Rewriter benchmark, targeting complex scenarios with extensive circuit partitioning, optimization trade-offs, and verification challenges, and the short Rewriter benchmark, designed for a wider range of scenarios and patterns. Our comparative analysis with established compilers such as Yosys and E-graph demonstrates significant improvements, highlighting the benefits of integrating large models into the early stages of circuit design. We provide our benchmarks at https://github.com/yaoxufeng/RTLRewriter-Bench.},
	booktitle = {Proceedings of the 43rd {IEEE}/{ACM} {International} {Conference} on {Computer}-{Aided} {Design}},
	publisher = {Association for Computing Machinery},
	author = {Yao, Xufeng and Wang, Yiwen and Li, Xing and Lian, Yingzhao and Chen, Ran and Chen, Lei and Yuan, Mingxuan and Xu, Hong and Yu, Bei},
	year = {2025},
	note = {event-place: Newark Liberty International Airport Marriott, New York, NY, USA},
}

@inproceedings{sun_harnessing_2024,
	address = {New York, NY, USA},
	series = {{WWW} '24},
	title = {Harnessing {Multi}-{Role} {Capabilities} of {Large} {Language} {Models} for {Open}-{Domain} {Question} {Answering}},
	isbn = {979-8-4007-0171-9},
	url = {https://doi.org/10.1145/3589334.3645670},
	doi = {10.1145/3589334.3645670},
	abstract = {Open-domain question answering (ODQA) has emerged as a pivotal research spotlight in information systems. Existing methods follow two main paradigms to collect evidence: (1) Theretrieve-then-read paradigm retrieves pertinent documents from an external corpus; and (2) thegenerate-then-read paradigm employs large language models (LLMs) to generate relevant documents. However, neither can fully address multifaceted requirements for evidence. To this end, we propose LLMQA, a generalized framework that formulates the ODQA process into three basic steps: query expansion, document selection, and answer generation, combining the superiority of both retrieval-based and generation-based evidence. Since LLMs exhibit their excellent capabilities to accomplish various tasks, we instruct LLMs to play multiple roles as generators, rerankers, and evaluators within our framework, integrating them to collaborate in the ODQA process. Furthermore, we introduce a novel prompt optimization algorithm to refine role-playing prompts and steer LLMs to produce higher-quality evidence and answers. Extensive experimental results on widely used benchmarks (NQ, WebQ, and TriviaQA) demonstrate that LLMQA achieves the best performance in terms of both answer accuracy and evidence quality, showcasing its potential for advancing ODQA research and applications.},
	booktitle = {Proceedings of the {ACM} {Web} {Conference} 2024},
	publisher = {Association for Computing Machinery},
	author = {Sun, Hongda and Liu, Yuxuan and Wu, Chengwei and Yan, Haiyu and Tai, Cheng and Gao, Xin and Shang, Shuo and Yan, Rui},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	keywords = {prompt optimization, question answering, role-playing llms},
	pages = {4372--4382},
}

@inproceedings{uchkempirov_survey_2025,
	address = {New York, NY, USA},
	series = {{NLPIR} '24},
	title = {Survey of {Graph}-based text summarization for {HRM} tasks},
	isbn = {979-8-4007-1738-3},
	url = {https://doi.org/10.1145/3711542.3711572},
	doi = {10.1145/3711542.3711572},
	abstract = {This study provides a comprehensive overview of graph-based algorithms and techniques for automatic text summarization, with a particular emphasis on their application in human resource management activities such as CV summarization, motivational letter summarization, and cover letter summarization. Furthermore, the paper discusses the advantages and limitations of graph-based algorithms and techniques in natural language processing based on 22 highly visible and open access articles, while also suggesting potential avenues for future research in this domain. The review highlights the importance of graph theory for automatic text summarization where it can significantly improve the quality and precision of derived information. This survey offers critical insights for researchers and practitioners in the area who seek innovative human resources text analytics approaches and techniques that helps to accelerate decision-making processes by providing informative and concise summaries of large documents.},
	booktitle = {Proceedings of the 2024 8th {International} {Conference} on {Natural} {Language} {Processing} and {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Uchkempirov, Murataly and Tajeddini, Omid and Maliha Proma, Mayesha and Kulkarni, Parag},
	year = {2025},
	keywords = {Automatic text summarization, Graph theory, Graph-based summarization, Human resources management},
	pages = {380--387},
}

@inproceedings{yan_when_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {When {Graph} {Meets} {Multimodal}: {Benchmarking} and {Meditating} on {Multimodal} {Attributed} {Graph} {Learning}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737404},
	doi = {10.1145/3711896.3737404},
	abstract = {Multimodal Attributed Graphs (MAGs) are ubiquitous in real-world applications, encompassing extensive knowledge through multimodal attributes attached to nodes (e.g., texts and images) and topological structure representing node interactions. Despite its potential to advance diverse research fields like social networks and e-commerce, MAG representation learning (MAGRL) remains underexplored due to the lack of standardized datasets and evaluation frameworks. In this paper, we first propose MAGB, a comprehensive MAG benchmark dataset, featuring curated graphs from various domains with both textual and visual attributes. Based on the MAGB dataset, we further systematically evaluate two mainstream MAGRL paradigms: GNN-as-Predictor, which integrates multimodal attributes via Graph Neural Networks (GNNs), and VLM-as-Predictor, which harnesses Vision Language Models (VLMs) for zero-shot reasoning. Extensive experiments on MAGB reveal the following critical insights: (i) Modality significances fluctuate drastically with specific domain characteristics. (ii) Multimodal embeddings can elevate the performance ceiling of GNNs. However, intrinsic biases among modalities may impede effective training, particularly in low-data scenarios. (iii) VLMs are highly effective at generating multimodal embeddings that alleviate the imbalance between textual and visual attributes. These discoveries, which illuminate the synergy between multimodal attributes and graph topologies, contribute to reliable benchmarks, paving the way for future research.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Yan, Hao and Li, Chaozhuo and Yin, Jun and Yu, Zhigang and Han, Weihao and Li, Mingzheng and Zeng, Zhengxin and Sun, Hao and Wang, Senzhang},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {graph data mining, graph neural networks, multimodal attributed graphs, multimodal large language models},
	pages = {5842--5853},
}

@inproceedings{foukas_future_2025,
	address = {New York, NY, USA},
	series = {{HotMobile} '25},
	title = {The future of the industrial {AI} edge is cellular},
	isbn = {979-8-4007-1403-0},
	url = {https://doi.org/10.1145/3708468.3711887},
	doi = {10.1145/3708468.3711887},
	abstract = {Ensuring reliable and high-bandwidth wireless connectivity and local processing at the edge are crucial enablers for emerging industrial AI applications. In this work, we argue that the recent trends in cellular networking make the technology the ideal connectivity solution for these applications, due to its virtualization and support for open APIs. We foresee the emergence of a converged industrial AI edge encompassing both compute and connectivity, in which application developers leverage the API to implement advanced functionalities. We demonstrate the usefulness of this approach through a case study evaluated on an enterprise-grade 5G testbed deployed in our lab.},
	booktitle = {Proceedings of the 26th {International} {Workshop} on {Mobile} {Computing} {Systems} and {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Foukas, Xenofon and Radunovic, Bozidar},
	year = {2025},
	note = {event-place: La Quinta, CA, USA},
	pages = {61--66},
}

@inproceedings{cui_nlctables_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{nlcTables}: {A} {Dataset} for {Marrying} {Natural} {Language} {Conditions} with {Table} {Discovery}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730296},
	doi = {10.1145/3726302.3730296},
	abstract = {With the growing abundance of repositories containing tabular data, discovering relevant tables for in-depth analysis remains a challenging task. Existing table discovery methods primarily retrieve desired tables based on a query table or several vague keywords, leaving users to manually filter large result sets. To address this limitation, we propose a new task: NL-conditional table discovery (nlcTD), where users combine a query table with natural language (NL) requirements to refine search results. To advance research in this area, we present nlcTables, a comprehensive benchmark dataset comprising 627 diverse queries spanning NL-only, union, join, and fuzzy conditions, 22,080 candidate tables, and 21,200 relevance annotations. Our evaluation of six state-of-the-art table discovery methods on nlcTables reveals substantial performance gaps, highlighting the need for advanced techniques to tackle this challenging nlcTD scenario. The dataset, construction framework, and baseline implementations are publicly available at https://github.com/SuDIS-ZJU/nlcTables to foster future research.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Cui, Lingxi and Li, Huan and Chen, Ke and Shou, Lidan and Chen, Gang},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {joinable tables, semantic search, table search, unionable tables},
	pages = {3638--3647},
}

@inproceedings{yin_panns_2025,
	address = {New York, NY, USA},
	series = {{PPoPP} '25},
	title = {{PANNS}: {Enhancing} {Graph}-based {Approximate} {Nearest} {Neighbor} {Search} through {Recency}-aware {Construction} and {Parameterized} {Search}},
	isbn = {979-8-4007-1443-6},
	url = {https://doi.org/10.1145/3710848.3710867},
	doi = {10.1145/3710848.3710867},
	abstract = {Approximate Nearest-Neighbor Search (ANNS) has become the standard querying method in vector databases, especially with the recent surge in large-scale, high-dimensional data driven by LLM-based applications. Recently, graph-based ANNS has shown improved throughput by constructing a graph from the dataset, with edges representing the distances between data points, and using best-first or beam search algorithms for query evaluation.This work highlights that key aspects of the design space for both graph construction and search in graph-based ANNS remain under-explored. Specifically, the construction phase often neglects the potential temporal correlation between input queries and their results, while the search phase lacks a thorough exploration of beam search parameterization. To address these gaps, we present PANNS, a system that embeds temporal information in the proximity graph construction to capture query-result correlations. Moreover, it introduces a fully parameterized beam search algorithm, enabling extensive performance optimization. PANNS achieves up to a 3.7× improvement in query throughput over state-of-the-art graph-based ANNS methods, while maintaining equivalent recall levels. Furthermore, it reduces graph size by up to 30\% without degrading query quality.},
	booktitle = {Proceedings of the 30th {ACM} {SIGPLAN} {Annual} {Symposium} on {Principles} and {Practice} of {Parallel} {Programming}},
	publisher = {Association for Computing Machinery},
	author = {Yin, Xizhe and Gao, Chao and Zhao, Zhijia and Gupta, Rajiv},
	year = {2025},
	note = {event-place: Las Vegas, NV, USA},
	keywords = {graph processing, nearest neighbor search, vector search},
	pages = {369--381},
}

@inproceedings{vu_towards_2025,
	address = {Atlanta, GA, USA},
	series = {{SC}-{W} '24},
	title = {Towards {Generating} {Contracts} for {Scientific} {Data} {Analysis} {Workflows}},
	isbn = {979-8-3503-5554-3},
	url = {https://doi.org/10.1109/SCW63240.2024.00256},
	doi = {10.1109/SCW63240.2024.00256},
	abstract = {To increase the dependability and portability of scientific data analysis workflows (DAWs), recent work has proposed contract-driven design of DAWs, providing verifiable expectations and obligations to ensure that tasks run in a proper environment and produce correct results. However, the specification of suitable contracts is still left to the discretion of DAW developers, imposing labor-intensive manual work which likely hampers the widespread adoption of contracts in scientific practice. We report about work-in-progress of developing a pipeline empowered by Large Language Models for automatically generating code contracts from logical workflow descriptions. We instantiate this pipeline within the workflow system Nextflow, and evaluate its contract generation capabilities in an experiment using real-world Nextflow modules. Our findings indicate that we generate a substantial amount of contracts serving as starting point for DAW developers. Our approach demonstrates potential in assisting domain scientists with contract-driven design of DAWs, laying the groundwork for its future adoption.},
	booktitle = {Proceedings of the {SC} '24 {Workshops} of the {International} {Conference} on {High} {Performance} {Computing}, {Network}, {Storage}, and {Analysis}},
	publisher = {IEEE Press},
	author = {Vu, Anh Duc and Kehrer, Timo},
	year = {2025},
	pages = {2048--2055},
}

@inproceedings{aung_demand_2025,
	address = {New York, NY, USA},
	series = {{ADMIT} '24},
	title = {Demand {Forecasting}: {Integrating} {Textual} and {Market} {Data} to {Navigate} {Irregular} {Market} {Disruption}},
	isbn = {979-8-4007-1812-0},
	url = {https://doi.org/10.1145/3701100.3701158},
	doi = {10.1145/3701100.3701158},
	abstract = {Demand forecasting in the B2B sector is challenging due to complex supply chains and variable influences such as economic conditions and market trends. Traditional forecasting techniques rely on stable but often delayed data sources like government and industry reports, which struggle to provide timely and accurate predictions during volatile market conditions. This study introduces an enhanced forecasting methodology integrating high-frequency indicators from social media platforms and the stock market. Our novel approach consists of two components: the High-Frequency Textual Event Disruption Analyzer (HFT-EDA), which leverages advanced natural language processing techniques to analyze online trends and news data for immediate market insights, and the market health analyzer (MHA), which statistically combines hard, soft, and high-frequency economic indicators for a comprehensive market assessment. In this study, our methodology significantly improved monthly forecasts, surpassing existing models by up to 8.5\% for specific products, including electronic devices used in home and industrial appliances. This capability is particularly crucial during crises such as the COVID-19 lockdown, where rapid market shifts significantly impact demand dynamics. Our dual approach provides precise and actionable demand forecasts, enabling businesses to adapt quickly to market changes and stay attuned to immediate market fluctuations in the dynamic B2B landscape.},
	booktitle = {Proceedings of the 2024 3rd {International} {Conference} on {Algorithms}, {Data} {Mining}, and {Information} {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Aung, Nway Nway and Mao, Yuejingxian and Wijaya, Chandra Suwandi and Beck, Aryel and Koji, Miura and Yosuke, Tajika},
	year = {2025},
	keywords = {B2B Sector, Economic Indicators, High-Frequency Indicator, Textual Trends Insight, Time-Series Forecasting},
	pages = {270--280},
}

@inproceedings{gao_preference-guided_2024,
	address = {New York, NY, USA},
	series = {{ASE} '24},
	title = {Preference-{Guided} {Refactored} {Tuning} for {Retrieval} {Augmented} {Code} {Generation}},
	isbn = {979-8-4007-1248-7},
	url = {https://doi.org/10.1145/3691620.3694987},
	doi = {10.1145/3691620.3694987},
	abstract = {Retrieval-augmented code generation utilizes Large Language Models as the generator and significantly expands their code generation capabilities by providing relevant code, documentation, and more via the retriever. The current approach suffers from two primary limitations: 1) information redundancy. The indiscriminate inclusion of redundant information can result in resource wastage and may misguide generators, affecting their effectiveness and efficiency. 2) preference gap. Due to different optimization objectives, the retriever strives to procure code with higher ground truth similarity, yet this effort does not substantially benefit the generator. The retriever and the generator may prefer different golden code, and this gap in preference results in a suboptimal design. Additionally, differences in parameterization knowledge acquired during pre-training result in varying preferences among different generators.To address these limitations, in this paper, we propose RRG (Retrieve, Refactor, Generate), a novel framework for effective and efficient code generation. This framework introduces a code refactorer module between the retriever and the generator to bridge them. The refactoring process transforms the raw retrieved code into a more concise, efficient, and model-friendly version. It eliminates redundant information and noise, reducing the input length. Consequently, the generator receives higher-quality context, enabling it to produce more accurate results with lower inference costs. We conducted comprehensive experiments on multiple datasets. In the experiments, we confirmed the existence of a preference gap between the retriever and the generator, and RRG effectively bridges this gap. Specifically, RRG achieved significant performance improvements, with increases of up to 28\% on EM, 13\% on BLEU, and 6.8\% on CodeBLEU.},
	booktitle = {Proceedings of the 39th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Gao, Xinyu and Xiong, Yun and Wang, Deze and Guan, Zhenhan and Shi, Zejian and Wang, Haofen and Li, Shanshan},
	year = {2024},
	note = {event-place: Sacramento, CA, USA},
	keywords = {deep reinforcement learning, preference-guided refactorer, retrieval-augmented code generation},
	pages = {65--77},
}

@inproceedings{zhao_enhancing_2024,
	address = {New York, NY, USA},
	series = {{ASE} '24},
	title = {Enhancing {Automated} {Program} {Repair} with {Solution} {Design}},
	isbn = {979-8-4007-1248-7},
	url = {https://doi.org/10.1145/3691620.3695537},
	doi = {10.1145/3691620.3695537},
	abstract = {Automatic Program Repair (APR) endeavors to autonomously rectify issues within specific projects, which generally encompasses three categories of tasks: bug resolution, new feature development, and feature enhancement. Despite extensive research proposing various methodologies, their efficacy in addressing real issues remains unsatisfactory. It's worth noting that, typically, engineers have design rationales (DR) on solution— planed solutions and a set of underlying reasons—before they start patching code. In open-source projects, these DRs are frequently captured in issue logs through project management tools like Jira. This raises a compelling question: How can we leverage DR scattered across the issue logs to efficiently enhance APR?To investigate this premise, we introduce DRCodePilot, an approach designed to augment GPT-4-Turbo's APR capabilities by incorporating DR into the prompt instruction. Furthermore, given GPT-4's constraints in fully grasping the broader project context and occasional shortcomings in generating precise identifiers, we have devised a feedback-based self-reflective framework, in which we prompt GPT-4 to reconsider and refine its outputs by referencing a provided patch and suggested identifiers. We have established a benchmark comprising 938 issue-patch pairs sourced from two open-source repositories hosted on GitHub and Jira. Our experimental results are impressive: DRCodePilot achieves a full-match ratio that is a remarkable 4.7x higher than when GPT-4 is utilized directly. Additionally, the CodeBLEU scores also exhibit promising enhancements. Moreover, our findings reveal that the standalone application of DR can yield promising increase in the full-match ratio across CodeLlama, GPT-3.5, and GPT-4 within our benchmark suite. We believe that our DRCodePilot initiative heralds a novel human-in-the-loop avenue for advancing the field of APR.},
	booktitle = {Proceedings of the 39th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Zhao, Jiuang and Yang, Donghao and Zhang, Li and Lian, Xiaoli and Yang, Zitian and Liu, Fang},
	year = {2024},
	note = {event-place: Sacramento, CA, USA},
	keywords = {automated program repair, design rationale, developer discussion, issue logs},
	pages = {1706--1718},
}

@inproceedings{huang_dca-bench_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{DCA}-{Bench}: {A} {Benchmark} for {Dataset} {Curation} {Agents}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737422},
	doi = {10.1145/3711896.3737422},
	abstract = {The quality of datasets plays an increasingly crucial role in the research and development of modern artificial intelligence (AI). Despite the proliferation of open dataset platforms nowadays, data quality issues, such as incomplete documentation, inaccurate labels, ethical concerns, and outdated information, remain common in widely used datasets. Furthermore, these issues are often subtle and difficult to be detected by rule-based scripts, therefore requiring identification and verification by dataset users or maintainers-a process that is both time-consuming and prone to human mistakes. With the surging ability of large language models (LLM), it's promising to streamline the discovery of hidden dataset issues with LLM agents. To achieve this, one significant challenge is enabling LLM agents to detect issues in the wild rather than simply fixing known ones. In this work, we establish a benchmark to measure LLM agent's ability to tackle this challenge. We carefully curate 221 real-world test cases from eight popular dataset platforms and propose an automatic evaluation framework using GPT-4o. Our proposed framework shows strong empirical alignment with expert evaluations, validated through extensive comparisons with human annotations. Without any hints, most competitive Curator agent can only reveal 30\% of the data quality issues in the proposed dataset, highlighting the complexity of this task and indicating that applying LLM agents to real-world dataset curation still requires further in-depth exploration and innovation. The data and code is available at https://github.com/TRAIS-Lab/dca-bench.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Huang, Benhao and Yu, Yingzhuo and Huang, Jin and Zhang, Xingjian and Ma, Jiaqi W.},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {automatic evaluation, dataset curation, large language models},
	pages = {5482--5492},
}

@inproceedings{longwell_triple_2024,
	address = {New York, NY, USA},
	series = {{SIGIR}-{AP} 2024},
	title = {Triple {Augmented} {Generative} {Language} {Models} for {SPARQL} {Query} {Generation} from {Natural} {Language} {Questions}},
	isbn = {979-8-4007-0724-7},
	url = {https://doi.org/10.1145/3673791.3698426},
	doi = {10.1145/3673791.3698426},
	abstract = {Knowledge Graph Question Answering (KGQA) leverages structured Knowledge Graphs (KG) to respond to Natural Language Questions (NLQ). This paper explores integrating Generative Language Models (GLMs) augmented with knowledge graph triple retrievers into the KGQA framework to generate accurate SPARQL queries from NLQs. Specifically, we evaluate the effectiveness of integrating triple retriever models with the SPARQL-generating capabilities of GLMs by investigating: (1) the standalone capabilities of GLMs independent of retriever performance, (2) the impact of incorporating a base retriever (BM25), and (3) a comparative analysis with state-of-the-art KGQA methods. Our experiments demonstrate that by incorporating a triple retrieval module, GLMs can generate accurate SPARQL queries and outperform current end-to-end KGQA methods, particularly when paired with an optimal retriever.},
	booktitle = {Proceedings of the 2024 {Annual} {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval} in the {Asia} {Pacific} {Region}},
	publisher = {Association for Computing Machinery},
	author = {Longwell, Jack and Ali Akbar Alavi, Mahdiyar and Zarrinkalam, Fattane and Ensan, Faezeh},
	year = {2024},
	note = {event-place: Tokyo, Japan},
	keywords = {generative language models, knowledge graph question answering, sparql},
	pages = {269--273},
}

@inproceedings{feng_citygpt_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {{CityGPT}: {Empowering} {Urban} {Spatial} {Cognition} of {Large} {Language} {Models}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3736878},
	doi = {10.1145/3711896.3736878},
	abstract = {Large language models(LLMs), with their powerful language generation and reasoning capabilities, have already achieved notable success in many domains, e.g., math and code generation. However, they often fall short when tackling real-life geospatial tasks within urban environments. This limitation stems from a lack of physical world knowledge and relevant data during training. To address this gap, we propose CityGPT, a systematic framework designed to enhance LLMs' understanding of urban space and improve their ability to solve the related urban tasks by integrating a city-scale 'world model' into the model. Firstly, we construct a diverse instruction tuning dataset, CityInstruction, for injecting urban knowledge into LLMs and effectively boosting their spatial reasoning capabilities. Using a combination of CityInstruction and open source general instruction data, we introduce a novel and easy-to-use self-weighted fine-tuning method (SWFT) to train various LLMs (including ChatGLM3-6B, Llama3-8B, and Qwen2.5-7B) to enhance their urban spatial capabilities without compromising, or even improving, their general abilities. Finally, to validate the effectiveness of our proposed framework, we develop a comprehensive text-based spatial benchmark CityEval for evaluating the performance of LLMs across a wide range of urban scenarios and geospatial tasks. Extensive evaluation results demonstrate that smaller LLMs trained with CityInstruction by SWFT method can achieve performance that is competitive with, and in some cases superior to, proprietary LLMs when assessed using CityEval. Our work highlights the potential for integrating spatial knowledge into LLMs, thereby expanding their spatial cognition abilities and applicability to the real-world physical environments. The dataset, benchmark, and source code are open-sourced and can be accessed through https://github.com/tsinghua-fib-lab/CityGPT.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Feng, Jie and Liu, Tianhui and Du, Yuwei and Guo, Siqi and Lin, Yuming and Li, Yong},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {large language models, spatial cognition, urban system},
	pages = {591--602},
}

@inproceedings{sanca_efficient_2024,
	address = {New York, NY, USA},
	series = {{DaMoN} '24},
	title = {Efficient {Data} {Access} {Paths} for {Mixed} {Vector}-{Relational} {Search}},
	isbn = {979-8-4007-0667-7},
	url = {https://doi.org/10.1145/3662010.3663448},
	doi = {10.1145/3662010.3663448},
	abstract = {The rapid growth of machine learning capabilities and the adoption of data processing methods using vector embeddings sparked a great interest in creating systems for vector data management. While the predominant approach of vector data management is to use specialized index structures for fast search over the entirety of the vector embeddings, once combined with other (meta)data, the search queries can also become selective on relational attributes - typical for analytical queries. As using vector indexes differs from traditional relational data access, we revisit and analyze alternative access paths for efficient mixed vector-relational search.We first evaluate the accurate but exhaustive scan-based search and propose hardware optimizations and alternative dense vector-based formulation and batching to offset the cost. We outline the complex access-path design space, primarily driven by relational selectivity, and the decisions to consider when selecting an exhaustive scan-based search against an approximate index-based approach. Since the vector index primarily avoids expensive computation across the entire dataset, contrary to the common relational knowledge, it is better to scan at lower relational selectivity and probe at higher, with a cross-point between the two approaches dictated by data dimensionality, vector index parameters, and the number of concurrent search queries.},
	booktitle = {Proceedings of the 20th {International} {Workshop} on {Data} {Management} on {New} {Hardware}},
	publisher = {Association for Computing Machinery},
	author = {Sanca, Viktor and Ailamaki, Anastasia},
	year = {2024},
	note = {event-place: Santiago, AA, Chile},
	keywords = {Access Methods, Index Structures, Query Optimization, Vector Databases, Vector-Relational Databases},
}

@inproceedings{xiao_c-pack_2024,
	address = {New York, NY, USA},
	series = {{SIGIR} '24},
	title = {C-{Pack}: {Packed} {Resources} {For} {General} {Chinese} {Embeddings}},
	isbn = {979-8-4007-0431-4},
	url = {https://doi.org/10.1145/3626772.3657878},
	doi = {10.1145/3626772.3657878},
	abstract = {We introduce C-Pack, a package of resources that significantly advances the field of general text embeddings for Chinese. C-Pack includes three critical resources. 1) C-MTP is a massive training dataset for text embedding, which is based on the curation of vast unlabeled corpora and the integration of high-quality labeled corpora. 2) C-MTEB is a comprehensive benchmark for Chinese text embeddings covering 6 tasks and 35 datasets. 3) BGE is a family of embedding models covering multiple sizes. Our models outperform all prior Chinese text embeddings on C-MTEB by more than +10\% upon the time of the release. We also integrate and optimize the entire suite of training methods for BGE. Along with our resources on general Chinese embedding, we release our data and models for English text embeddings. The English models also achieve state-of-the-art performance on the MTEB benchmark; meanwhile, our released English data is 2 times larger than the Chinese data. Both Chinese and English datasets are the largest public release of training data for text embeddings. All these resources are made publicly available at https://github.com/FlagOpen/FlagEmbedding.},
	booktitle = {Proceedings of the 47th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Xiao, Shitao and Liu, Zheng and Zhang, Peitian and Muennighoff, Niklas and Lian, Defu and Nie, Jian-Yun},
	year = {2024},
	note = {event-place: Washington DC, USA},
	keywords = {benchmark, pre-trained models, text embeddings, training data},
	pages = {641--649},
}

@inproceedings{khanal_fathomgpt_2024,
	address = {New York, NY, USA},
	series = {{UIST} '24},
	title = {{FathomGPT}: {A} natural language interface for interactively exploring ocean science data},
	isbn = {979-8-4007-0628-8},
	url = {https://doi.org/10.1145/3654777.3676462},
	doi = {10.1145/3654777.3676462},
	abstract = {We introduce FathomGPT, an open source system for the interactive investigation of ocean science data via a natural language interface. FathomGPT was developed in close collaboration with marine scientists to enable researchers to explore and analyze the FathomNet image database. FathomGPT provides a custom information retrieval pipeline that leverages OpenAI’s large language models to enable: the creation of complex queries to retrieve images, taxonomic information, and scientific measurements; mapping common names and morphological features to scientific names; generating interactive charts on demand; and searching by image or specified patterns within an image. In designing FathomGPT, particular emphasis was placed on enhancing the user’s experience by facilitating free-form exploration and optimizing response times. We present an architectural overview and implementation details of FathomGPT, along with a series of ablation studies that demonstrate the effectiveness of our approach to name resolution, fine tuning, and prompt modification. We also present usage scenarios of interactive data exploration sessions and document feedback from ocean scientists and machine learning experts.},
	booktitle = {Proceedings of the 37th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Khanal, Nabin and Yu, Chun Meng and Chiu, Jui-Cheng and Chaudhary, Anav and Zhang, Ziyue and Katija, Kakani and Forbes, Angus G.},
	year = {2024},
	note = {event-place: Pittsburgh, PA, USA},
	keywords = {Natural Language Interfaces, Ocean Science, Scientific Databases},
}

@inproceedings{shrestha_espn_2024,
	address = {New York, NY, USA},
	series = {{ISMM} 2024},
	title = {{ESPN}: {Memory}-{Efficient} {Multi}-vector {Information} {Retrieval}},
	isbn = {979-8-4007-0615-8},
	url = {https://doi.org/10.1145/3652024.3665515},
	doi = {10.1145/3652024.3665515},
	abstract = {Recent advances in large language models have demonstrated remarkable effectiveness in information retrieval (IR) tasks. While many neural IR systems encode queries and documents into single-vector representations, multi-vector models elevate the retrieval quality by producing multi-vector representations and facilitating similarity searches at the granularity of individual tokens. However, these models significantly amplify memory requirements for retrieval indices by an order of magnitude. This escalation in index size renders the scalability of multi-vector IR models progressively challenging due to their substantial memory demands. We introduce Embedding from Storage Pipelined Network (ESPN) where we offload the entire re-ranking embedding tables to SSDs and reduce the memory requirements by 5−16×. We design a flexible software prefetcher applicable to any hierarchical clustering based search, achieving hit rates exceeding 90\%. ESPN improves SSD based retrieval up to 6.4× and end-to-end throughput by 68\% to maintain near-memory levels of query latency even for large query batch sizes. The code is available at https://github.com/susavlsh10/ESPN-v1.},
	booktitle = {Proceedings of the 2024 {ACM} {SIGPLAN} {International} {Symposium} on {Memory} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Shrestha, Susav and Reddy, Narasimha and Li, Zongwang},
	year = {2024},
	note = {event-place: Copenhagen, Denmark},
	keywords = {Approximate Nearest Neighbor Search, GPUDirect Storage, Memory \&amp, Multi-vector, Neural Information Retrieval, Software Prefetching, Storage System},
	pages = {95--107},
}

@inproceedings{rashik_ai-enabled_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {{AI}-{Enabled} {Conversational} {Journaling} for {Advancing} {Parkinson}'s {Disease} {Symptom} {Tracking}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3714280},
	doi = {10.1145/3706598.3714280},
	abstract = {Journaling plays a crucial role in managing chronic conditions by allowing patients to document symptoms and medication intake, providing essential data for long-term care. While valuable, traditional journaling methods often rely on static, self-directed entries, lacking interactive feedback and real-time guidance. This gap can result in incomplete or imprecise information, limiting its usefulness for effective treatment. To address this gap, we introduce Patrika, an AI-enabled prototype designed specifically for people with Parkinson’s disease (PwPD). The system incorporates cooperative conversation principles, clinical interview simulations, and personalization to create a more effective and user-friendly journaling experience. Through two user studies with PwPD and iterative refinement of Patrika, we demonstrate conversational journaling’s significant potential in patient engagement and collecting clinically valuable information. Our results showed that generating probing questions Patrika turned journaling into a bi-directional interaction. Additionally, we offer insights for designing journaling systems for healthcare and future directions for promoting sustained journaling.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Rashik, Mashrur and Sweth, Shilpa and Agrawal, Nishtha and Kochar, Saiyyam and Smith, Kara M and Rajabiyazdi, Fateme and Setlur, Vidya and Mahyar, Narges and Sarvghad, Ali},
	year = {2025},
	keywords = {context, Conversational implicature, Gricean maxims, healthcare., journaling},
}

@inproceedings{gomes_nudge_2024,
	address = {New York, NY, USA},
	series = {{IHC} '24},
	title = {Nudge {Evidence} {Briefing}: {A} {Proposal} for {Transferring} {Scientific} {Knowledge} about {Nudges}},
	isbn = {979-8-4007-1224-1},
	url = {https://doi.org/10.1145/3702038.3702073},
	doi = {10.1145/3702038.3702073},
	abstract = {A nudge is a concept from Behavioral Economics and Psychology that refers to any small change or intervention designed to influence people's behavior predictably, without restricting their options or significantly altering their incentives. The research follows the Design Science Research methodology, introducing Nudge Evidence Briefing (NEB) to facilitate the understanding, access, application of academic findings on nudges for non-academic professionals, considering the gap between academic research on nudges and their practical application. Leveraging insights from the Evidence-Based Medicine framework, NEBs distill key findings from primary research into concise, accessible documents. Through a systematic review of the literature on nudge integration into software privacy and security, 12 primary studies were selected and the data extracted from them was formatted into NEBs. Participants, specialists and non-specialists, were invited to evaluate the NEB through online questionnaires. Feedback highlighted the clarity and structured format of the NEB, with particular praise for its ability to communicate complex scientific evidence in an accessible way. Overall, the NEB demonstrates significant promise in making nudge-related research more accessible and feasible. Ongoing refinements based on participant feedback will be crucial to realizing its full potential, contributing to the advancement of Human-Computer Interaction (HCI) and the practical application of nudges in professional environments. Future work will focus on evaluating the practical applicability of the NEB with non-academic professionals, exploring more reliable alternatives for generating NEBs through LLM, and developing a comprehensive repository of NEBs.},
	booktitle = {Proceedings of the {XXIII} {Brazilian} {Symposium} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Gomes, Vinicius and Cunha, José Adson and Lima, Kássio and Moura, Hermano Perrelli},
	year = {2024},
	keywords = {Evidence Briefing, Knowledge Transfer, Nudge, Privacy, Security},
}

@inproceedings{mikriukov_ai_2025,
	address = {New York, NY, USA},
	series = {{SECA} '25},
	title = {{AI} {Tools} for {Automating} {Systematic} {Literature} {Reviews}},
	isbn = {979-8-4007-1513-6},
	url = {https://doi.org/10.1145/3747912.3747962},
	doi = {10.1145/3747912.3747962},
	abstract = {Systematic literature reviews (SLRs) are becoming increasingly time-consuming due to the rapid growth of scientific publications. Modern artificial intelligence—based tools, especially large language models (LLM), make it possible to automate individual review stages, from screening to data synthesis. The article examines more than 20 sources and suggests a classification of such solutions according to four parameters. Comparative metrics (F1, recall) are given, and key limitations are discussed: hallucinations, reproducibility, and domain adaptation. The work is aimed at researchers who introduce AI into the practice of evidence-based analysis.},
	booktitle = {Proceedings of the 2025 {International} {Conference} on {Software} {Engineering} and {Computer} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Mikriukov, Andrei and Senokosov, Artsiom and Succi, Giancarlo and Tormasov, Alexander and Plaksin, Yaroslav and Trofimova, Ekaterina and Sitnikov, Vladimir},
	year = {2025},
	keywords = {Artificial Intelligence, Data Extraction, Large Language Models, Reproducibility, Screening, Systematic Literature Review},
	pages = {25--30},
}

@inproceedings{abbas_pitch_2025,
	address = {New York, NY, USA},
	series = {{CUI} '25},
	title = {{PITCH}: {Designing} {Agentic} {Conversational} {Support} for {Planning} and {Self}-reflection},
	isbn = {979-8-4007-1527-3},
	url = {https://doi.org/10.1145/3719160.3736634},
	doi = {10.1145/3719160.3736634},
	abstract = {Effective planning and reflection are essential for knowledge workers’ productivity and well-being, yet many struggle with them. While conversational agents (CAs) have shown promise, existing approaches rely on repetitive check-in without variance. We designed PITCH, a CA that checks in twice daily for morning planning and evening reflection while considering the morning conversation. A two-week field study with 12 graduate students demonstrated that engagement with PITCH increased their perceived well-being over time. We also evaluated a rotation strategy, which cycles through diverse topics every day, hypothesizing that rotation would mitigate wear-out effects and offer new perspectives. The results revealed that the specificity of a randomly chosen goal was perceived as being out of context and authoritarian, with most preferring the non-rotation version for consistency and flexibility. These findings highlight the potential of CAs to support knowledge workers and offer design considerations for varying conversations to provide topical diversity.},
	booktitle = {Proceedings of the 7th {ACM} {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Abbas, Adnan and Wohn, Caleb and Hu, Donghan and Rho, Eugenia H and Lee, Sang Won},
	year = {2025},
	keywords = {behavior change, conversational agents, field studies, planning, self-reflection},
}

@inproceedings{ko_subgraph-aware_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Subgraph-{Aware} {Training} of {Language} {Models} for {Knowledge} {Graph} {Completion} {Using} {Structure}-{Aware} {Contrastive} {Learning}},
	isbn = {979-8-4007-1274-6},
	url = {https://doi.org/10.1145/3696410.3714946},
	doi = {10.1145/3696410.3714946},
	abstract = {Fine-tuning pre-trained language models (PLMs) has recently shown a potential to improve knowledge graph completion (KGC). However, most PLM-based methods focus solely on encoding textual information, neglecting the long-tailed nature of knowledge graphs and their various topological structures, e.g., subgraphs, shortest paths, and degrees. We claim that this is a major obstacle to achieving higher accuracy of PLMs for KGC. To this end, we propose a Subgraph-Aware Training framework for KGC (SATKGC) with two ideas: (i) subgraph-aware mini-batching to encourage hard negative sampling and to mitigate an imbalance in the frequency of entity occurrences during training, and (ii) new contrastive learning to focus more on harder in-batch negative triples and harder positive triples in terms of the structural properties of the knowledge graph. To the best of our knowledge, this is the first study to comprehensively incorporate the structural inductive bias of the knowledge graph into fine-tuning PLMs. Extensive experiments on three KGC benchmarks demonstrate the superiority of SATKGC. Our code is available.https://github.com/meaningful96/SATKGC},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Ko, Youmin and Yang, Hyemin and Kim, Taeuk and Kim, Hyunjoon},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {contrastive learning, hard negative sampling, knowledge graph completion},
	pages = {72--85},
}

@inproceedings{lee_peerspective_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Peerspective: {A} {Study} on {Reciprocal} {Tracking} for {Self}-awareness and {Relational} {Insight}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713404},
	doi = {10.1145/3706598.3713404},
	abstract = {Personal informatics helps individuals understand themselves, but it often struggles to capture non-conscious behaviors such as stress responses, habitual actions, and communication styles. Incorporating social aspects into PI systems offers new perspectives on self-understanding, yet prior research has largely focused on unidirectional approaches that center benefits on the primary tracker. To address this gap, we introduce the Peerspective study, which explores reciprocal tracking—a bidirectional practice where two participants observe and provide feedback to each other, fostering mutual self-understanding and collaboration. In a week-long study with eight peer dyads, we explored how reciprocal observation and feedback influence self-awareness and interpersonal relationships. Our findings reveal that reciprocal tracking not only helps participants uncover blind spots and expand their self-concepts but also enhances empathy, deepens communication, and promotes sustained engagement. We discuss key facilitators and challenges of integrating reciprocity into personal informatics systems and offer design considerations for supporting collaborative tracking in everyday contexts.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Lee, Kwangyoung and Jung, Yeohyun and Jung, Gyuwon and Lu, Xi and Hong, Hwajung},
	year = {2025},
	keywords = {Blind Spots, Peerspective, Personal Informatics, Reciprocal Tracking, Self-Understanding, Social Features in Tracking},
}

@inproceedings{flokas_towards_2025,
	address = {New York, NY, USA},
	series = {{DEEM} '25},
	title = {Towards a {Framework} for {Hierarchical} {Text} {Segmentation} using {Large} {Language} {Models}},
	isbn = {979-8-4007-1924-0},
	url = {https://doi.org/10.1145/3735654.3735941},
	doi = {10.1145/3735654.3735941},
	abstract = {Thanks to the in context learning abilities of LLMs, building a text classifier without access to labeled data is easier than ever. However, for more complex tasks than simple classification, the difficulties remain. One such task is hierarchical segmentation where a model needs to break down an input document in an hierarchy of segments each annotated with a label from a taxonomy of classes. The long input documents, the large input class taxonomies as well as the increased number of outputs make the problem challenging to solve with a single LLM call. While hierarchical segmentation is amenable to splitting in smaller more manageable tasks, there is a huge design space of such approaches making the process tedious and time consuming. To reduce the amount of ad hoc exploration and implementation, we propose the first framework for hierarchical text segmentation using LLMs. The key idea behind our framework is that hierarchical segmentation can be viewed as a join between document and taxonomy. Inspired by join operator design, we propose two highly configurable hierarchical segmentation algorithms based on index and merge sort joins. Our experiments highlight the existence of trade offs across algorithms and their configurations, indicating that machine learning engineers may benefit from quickly exploring the design space using our framework.},
	booktitle = {Proceedings of the {Workshop} on {Data} {Management} for {End}-to-{End} {Machine} {Learning}},
	publisher = {Association for Computing Machinery},
	author = {Flokas, Lampros and Cao, Jeffery and Xu, Yujian and Wu, Eugene and Chu, Xu and Yu, Cong},
	year = {2025},
	note = {event-place: Berlin, Germany},
}

@inproceedings{mozafari_wikihint_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{WikiHint}: {A} {Human}-{Annotated} {Dataset} for {Hint} {Ranking} and {Generation}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730284},
	doi = {10.1145/3726302.3730284},
	abstract = {The use of Large Language Models (LLMs) has increased significantly with users frequently asking questions to chatbots. In the time when information is readily accessible, it is crucial to stimulate and preserve human cognitive abilities and maintain strong reasoning skills. This paper addresses such challenges by promoting the use of hints as an alternative or a supplement to direct answers. We first introduce a manually constructed hint dataset, WikiHint, which is based on Wikipedia and includes 5,000 hints created for 1,000 questions. We then finetune open-source LLMs for hint generation in answer-aware and answer-agnostic contexts. We assess the effectiveness of the hints with human participants who answer questions with and without the aid of hints. Additionally, we introduce a lightweight evaluation method, HintRank, to evaluate and rank hints in both answer-aware and answer-agnostic settings. Our findings show that (a) the dataset helps generate more effective hints (b) including answer information along with questions generally improves the quality of generated hints, and (c) encoder-based models perform better than decoder-based models in hint ranking.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Mozafari, Jamshid and Gerhold, Florian and Jatowt, Adam},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {hint dataset, hint evaluation, hint generation, hint ranking},
	pages = {3821--3831},
}

@inproceedings{wang_exploiting_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {Exploiting {Student} {Parallelism} for {Low}-latency {GPU} {Inference} of {BERT}-like {Models} in {Online} {Services}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3736949},
	doi = {10.1145/3711896.3736949},
	abstract = {BERT-like models have been widely adopted in text mining and web search due to their high accuracy. However, large BERT-like models suffer from inefficient online inference on GPUs for two main reasons. First, their high accuracy relies on large model depth, which linearly increases sequential computation on GPUs. Second, stochastic and dynamic online workloads lead to extra costs due to batching and padding. To address the problem, we present Student Parallelism for efficient GPU inference of BERT-like models under real-world online workloads. At its core, Student Parallelism adopts stacking distillation and boosting ensemble, distilling the original deep model into a group of shallow but virtually stacked student models running in parallel. This enables Student Parallelism to achieve a low model depth (e.g., two layers), and thus low inference latency while maintaining accuracy. In addition, we design adaptive student pruning to adjust the number of students according to the dynamic online workloads. For example, during workload bursts, it can temporarily decrease the number of students with minimal accuracy loss to improve system throughput. Extensive experiments on real-world datasets and workloads show that Student Parallelism achieves up to 4.1× lower latency while maintaining accuracy and up to 22.27× higher throughput during workload bursts.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Wang, Weiyan and Jin, Yilun and Zhang, Yiming and Wei, Victor Junqiu and Tian, Han and Chen, Li and Xue, Jinbao and Tao, Yangyu and Wang, Di and Chen, Kai},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {distillation, efficient inference, information retrieval, text mining},
	pages = {3055--3066},
}

@inproceedings{pavlenko_vertically_2024,
	address = {New York, NY, USA},
	series = {{SIGMOD} '24},
	title = {Vertically {Autoscaling} {Monolithic} {Applications} with {CaaSPER}: {Scalable} {Container}-as-a-{Service} {Performance} {Enhanced} {Resizing} {Algorithm} for the {Cloud}},
	isbn = {979-8-4007-0422-2},
	url = {https://doi.org/10.1145/3626246.3653378},
	doi = {10.1145/3626246.3653378},
	abstract = {Kubernetes has emerged as a prominent open-source platform for managing cloud applications, including stateful databases. These monolithic applications rely on vertical scaling, adjusting CPU cores based on load fluctuations. However, our analysis of Kubernetes-based Database-as-a-Service (DBaaS) offerings at Microsoft revealed that many customers consistently over-provision resources for peak workloads, neglecting cost-saving opportunities through resource scale-down. We found that there is a gap in the ability of existing vertical autoscaling tools to minimize resource slack and respond promptly to throttling, leading to increased costs and impacting crucial metrics such as throughput and availability.To address this challenge, we propose CaaSPER, a vertical autoscaling algorithm that blends reactive and proactive strategies. By dynamically adjusting CPU resources, CaaSPER minimizes resource slack, maintains optimal CPU utilization, and reduces throttling. Importantly, customers have the flexibility to prioritize either cost savings or high performance based on their preferences. Extensive testing demonstrates that CaaSPER effectively reduces throttling and keeps CPU utilization within target levels. CaaSPER is designed to be application-agnostic and platform-agnostic, with potential for extension to other applications requiring vertical autoscaling.},
	booktitle = {Companion of the 2024 {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {Pavlenko, Anna and Cahoon, Joyce and Zhu, Yiwen and Kroth, Brian and Nelson, Michael and Carter, Andrew and Liao, David and Wright, Travis and Camacho-Rodríguez, Jesús and Saur, Karla},
	year = {2024},
	note = {event-place: Santiago AA, Chile},
	keywords = {containers, kubernetes, resource optimization, vertical auto-scaling},
	pages = {241--254},
}

@inproceedings{may_sap_2025,
	address = {New York, NY, USA},
	series = {{SIGMOD}/{PODS} '25},
	title = {{SAP} {HANA} {Cloud}: {Data} {Management} for {Modern} {Enterprise} {Applications}},
	isbn = {979-8-4007-1564-8},
	url = {https://doi.org/10.1145/3722212.3724452},
	doi = {10.1145/3722212.3724452},
	abstract = {Cloud Computing environments are a fantastic foundation for unprecedented opportunities in the context of data management. Scalability and availability can be achieved by consequently disaggregating compute and storage and leveraging different data centers around the globe. Although conceptually infinitely available resources promise an easy game for database systems, leveraging those opportunities on the one side and providing enterprise-scale data management solutions for a wide range of extremely challenging business applications on the other side is by far not trivial. Within this paper we share the fundamental principles of SAP HANA Cloud—the data management backbone for all SAP applications—by providing insights into design criteria and technological centerpieces of SAP HANA Cloud as a result of a stringent evolutionary shift from a purely on-premise, in-memory database engine to an on-Cloud, memory-storage hierarchy-aware data management platform. We will motivate the transition and the decision of certain developments by sharing key characteristics of some key applications run by SAP, which require enterprise qualities like availability, cloud-capabilities like resource elasticity, while managing overall costs and the flexibility to adapt the underlying data management system to their specific needs. The overall goal of the paper is to provide insights into the ”story of SAP HANA Cloud” by sharing challenges and lessons learned within the evolution towards a composable cloud-based data platform, thus strongly arguing for a ”one size fits all” solution, if done right.},
	booktitle = {Companion of the 2025 {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {May, Norman and Böhm, Alexander and Ritter, Daniel and Renkes, Frank and Andrei, Mihnea and Lehner, Wolfgang},
	year = {2025},
	note = {event-place: Berlin, Germany},
	keywords = {cloud architecture patterns, cloud data management, data lake, multi-model, multi-tenancy, SAP HANA cloud},
	pages = {580--592},
}

@inproceedings{wang_bingo_2025,
	address = {New York, NY, USA},
	series = {{EuroSys} '25},
	title = {Bingo: {Radix}-based {Bias} {Factorization} for {Random} {Walk} on {Dynamic} {Graphs}},
	isbn = {979-8-4007-1196-1},
	url = {https://doi.org/10.1145/3689031.3717456},
	doi = {10.1145/3689031.3717456},
	abstract = {Random walks are a primary means for extracting information from large-scale graphs. While most real-world graphs are inherently dynamic, state-of-the-art random walk engines failed to efficiently support such a critical use case. This paper takes the initiative to build a general random walk engine for dynamically changing graphs with two key principles: (i) This system should support both low-latency streaming updates and high-throughput batched updates. (ii) This system should achieve fast sampling speed while maintaining acceptable space consumption to support dynamic graph updates. Upholding both standards, we introduce Bingo, a GPU-based random walk engine for dynamically changing graphs. First, we propose a novel radix-based bias factorization algorithm to support constant time sampling complexity while supporting fast streaming updates. Second, we present a group-adaption design to reduce space consumption dramatically. Third, we incorporate GPU-aware designs to support high-throughput batched graph updates on massively parallel platforms. Together, Bingo outperforms existing efforts across various applications, settings, and datasets, achieving up to a 271.11x speedup compared to the state-of-the-art efforts.},
	booktitle = {Proceedings of the {Twentieth} {European} {Conference} on {Computer} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Pinhuan and Huan, Chengying and Wang, Zhibin and Tian, Chen and Ji, Yuede and Liu, Hang},
	year = {2025},
	note = {event-place: Rotterdam, Netherlands},
	keywords = {GPUs, Monte Carlo Sampling, Random Walk},
	pages = {605--620},
}

@inproceedings{chen_emotion-aware_2025,
	address = {New York, NY, USA},
	series = {{CHI} '25},
	title = {Emotion-aware {Design} in {Automobiles}: {Embracing} {Technology} {Advancements} to {Enhance} {Human}-vehicle {Interaction}},
	isbn = {979-8-4007-1394-1},
	url = {https://doi.org/10.1145/3706598.3713571},
	doi = {10.1145/3706598.3713571},
	abstract = {The integration of emotion-aware systems in vehicles is accelerated by new technologies, including advancements in AI and ubiquitous sensing technologies. As the automotive industry shifts from technology-centred, feature-driven approaches to human-centred design, this research focuses on how to effectively incorporate emotion features into user-centred design to enhance effective human-vehicle interaction in practices. By conducting an interview study with 31 industrial design practitioners, supplemented by insights from engineers and AI experts involved in the early-stage design and development of novel in-vehicle user interfaces and systems, we examined current practices, and sampled their challenges, attitudes and expectations related to emotion-aware systems. Our findings provide critical insights to the design space of emotion-aware systems from both user and AI perspectives, inform efforts to support design practices in this evolving area, and identify opportunities for future innovation in emotion-aware in-vehicle design. Based on our findings, we propose adaptations to design practices and recommendations for further research.},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Xingtong and Wang, Xia and Fang, Cong and Fang, Le and Gong, Wei and Liu, Chengzhong and Wang, Stephen Jia},
	year = {2025},
	keywords = {Emotion, Human-centred Design, Human-vehicle Interaction},
}

@inproceedings{liu_tsconnect_2025,
	address = {New York, NY, USA},
	series = {{IUI} '25},
	title = {{TSConnect}: {An} {Enhanced} {MOOC} {Platform} for {Bridging} {Communication} {Gaps} {Between} {Instructors} and {Students} in {Light} of the {Curse} of {Knowledge}},
	isbn = {979-8-4007-1306-4},
	url = {https://doi.org/10.1145/3708359.3712108},
	doi = {10.1145/3708359.3712108},
	abstract = {Knowledge dissemination in educational settings is profoundly influenced by the curse of knowledge, a cognitive bias that causes experts to underestimate the challenges faced by learners due to their own in-depth understanding of the subject. This bias can hinder effective knowledge transfer and pedagogical effectiveness, and may be exacerbated by inadequate instructor-student communication. To encourage more effective feedback and promote empathy, we introduce TSConnect, a bias-aware, adaptable interactive MOOC (Massive Open Online Course) learning system, informed by a need-finding survey involving 129 students and 6 instructors. TSConnect integrates instructors, students, and Artificial Intelligence (AI) into a cohesive platform, facilitating diverse and targeted communication channels while addressing previously overlooked information needs. A notable feature is its dynamic knowledge graph, which enhances learning support and fosters a more interconnected educational experience. We conducted a between-subjects user study with 30 students comparing TSConnect to a baseline system. Results indicate that TSConnect significantly encourages students to provide more feedback to instructors. Additionally, interviews with 4 instructors reveal insights into how they interpret and respond to this feedback, potentially leading to improvements in teaching strategies and the development of broader pedagogical skills.},
	booktitle = {Proceedings of the 30th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Qianyu and Li, Xinran and Du, Xiaocong and Li, Quan},
	year = {2025},
	keywords = {bias-aware design, communication gap, curse of knowledge, MOOC platform, student-instrutor communication},
	pages = {1335--1353},
}

@inproceedings{kalirai_toward_2024,
	address = {New York, NY, USA},
	series = {{IUI} '24},
	title = {Toward {Faceted} {Skill} {Recommendation} in {Intelligent} {Personal} {Assistants}},
	isbn = {979-8-4007-0508-3},
	url = {https://doi.org/10.1145/3640543.3645201},
	doi = {10.1145/3640543.3645201},
	abstract = {Research continuously shows that, despite the wide range of skills developed for Intelligent Personal Assistants (IPAs), users tend to engage with only a small number of them. One reason for this discrepancy is the issue of skill discoverability, which is commonly addressed through conversational recommendations. Current recommendation strategies, however, are limited due to information asymmetry, lack of interactivity, and an underdeveloped understanding of appropriate grouping of available skills. In this paper, we explore opportunities for interactive faceted skill recommendations using voice interfaces. Through an open card sort user study and semi-structured interviews, we identify and describe five facets driving users’ natural grouping of IPA skills (Thematic, Procedural, Cross-system, Environmental, and Recipient), and demonstrate the need for simultaneous support of these facets. We then discuss the implications of these findings for advancing the discoverability of IPA skills through the design of interactive conversational recommendations.},
	booktitle = {Proceedings of the 29th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Kalirai, Manveer and Williams, Alex C. and Kuzminykh, Anastasia},
	year = {2024},
	note = {event-place: Greenville, SC, USA},
	keywords = {conversational recommendation, discoverability, Intelligent personal assistants, skills, voice interface},
	pages = {640--649},
}

@inproceedings{de_la_rua_martinez_hopsworks_2024,
	address = {New York, NY, USA},
	series = {{SIGMOD} '24},
	title = {The {Hopsworks} {Feature} {Store} for {Machine} {Learning}},
	isbn = {979-8-4007-0422-2},
	url = {https://doi.org/10.1145/3626246.3653389},
	doi = {10.1145/3626246.3653389},
	abstract = {Data management is the most challenging aspect of building Machine Learning (ML) systems. ML systems can read large volumes of historical data when training models, but inference workloads are more varied, depending on whether it is a batch or online ML system. The feature store for ML has recently emerged as a single data platform for managing ML data throughout the ML lifecycle, from feature engineering to model training to inference. In this paper, we present the Hopsworks feature store for machine learning as a highly available platform for managing feature data with API support for columnar, row-oriented, and similarity search query workloads. We introduce and address challenges solved by the feature stores related to feature reuse, how to organize data transformations, and how to ensure correct and consistent data between feature engineering, model training, and model inference. We present the engineering challenges in building high-performance query services for a feature store and show how Hopsworks outperforms existing cloud feature stores for training and online inference query workloads.},
	booktitle = {Companion of the 2024 {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {de la Rúa Martínez, Javier and Buso, Fabio and Kouzoupis, Antonios and Ormenisan, Alexandru A. and Niazi, Salman and Bzhalava, Davit and Mak, Kenneth and Jouffrey, Victor and Ronström, Mikael and Cunningham, Raymond and Zangis, Ralfs and Mukhedkar, Dhananjay and Khazanchi, Ayushman and Vlassov, Vladimir and Dowling, Jim},
	year = {2024},
	note = {event-place: Santiago AA, Chile},
	keywords = {arrow flight, duckdb, feature store, mlops, rondb},
	pages = {135--147},
}

@inproceedings{liu_compeer_2024,
	address = {New York, NY, USA},
	series = {{UIST} '24},
	title = {{ComPeer}: {A} {Generative} {Conversational} {Agent} for {Proactive} {Peer} {Support}},
	isbn = {979-8-4007-0628-8},
	url = {https://doi.org/10.1145/3654777.3676430},
	doi = {10.1145/3654777.3676430},
	abstract = {Conversational Agents (CAs) acting as peer supporters have been widely studied and demonstrated beneficial for people’s mental health. However, previous peer support CAs either are user-initiated or follow predefined rules to initiate the conversations, which may discourage users to engage and build relationships with the CAs for long-term benefits. In this paper, we develop ComPeer , a generative CA that can proactively offer adaptive peer support to users. ComPeer leverages large language models to detect and reflect significant events in the dialogue, enabling it to strategically plan the timing and content of proactive care. In addition, ComPeer incorporates peer support strategies, conversation history, and its persona into the generative messages. Our one-week between-subjects study (N=24) demonstrates ComPeer ’s strength in providing peer support over time and boosting users’ engagement compared to a baseline user-initiated CA. We report users’ interaction patterns with ComPeer and discuss implications for designing proactive generative agents to promote people’s well-being.},
	booktitle = {Proceedings of the 37th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Tianjian and Zhao, Hongzheng and Liu, Yuheng and Wang, Xingbo and Peng, Zhenhui},
	year = {2024},
	note = {event-place: Pittsburgh, PA, USA},
	keywords = {Generative conversational agents, human-AI interaction, peer support, proactivity},
}

@inproceedings{dong_reasoning_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {Reasoning and {Retrieval} for {Complex} {Semi}-structured {Tables} via {Reinforced} {Relational} {Data} {Transformation}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3730071},
	doi = {10.1145/3726302.3730071},
	abstract = {We introduce TabFormer, a framework that normalizes diverse semi-structured tables into relational data via large language models to facilitate various table retrieval and reasoning tasks. Our approach employs a chain-of-thought methodology, transforming one or multiple tables through a sequence of soft operations. Compared to existing operators that are sensitive and brittle to human-induced artifacts in real-world tables, soft operators are designed with greater flexibility to accommodate diverse formatting variations. To address the lack of ground-truth labels for table transformation, we propose a reinforced fine-tuning strategy that sequentially and jointly optimizes table transformation and symbolic reasoning within a single LLM call. This process is guided by two novel reward functions without requiring human annotations on table transformation: (1) relational normalization quality and (2) symbolic reasoning accuracy. TabFormer is a scalable, one-time framework that leverages LLMs to transform one ore multiple tables in a single inference step, thereby enhancing both retrieval and reasoning for a wide range of tabular data tasks. Experimental evaluations on datasets such as WTQ, HiTab, MultiHiertt, and TabFact demonstrate significant gains in accuracy-improvements ranging from 4\% to 17\%-when applied to state-of-the-art methods, including GPT-4-based E5, Chain-of-Table, TableLlama, and others.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Dong, Haoyu and Hu, Yue and Cao, Yanan},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {information retrieval, symbolic reasoning, table generation},
	pages = {1382--1391},
}

@inproceedings{dumitru_evaluating_2025,
	address = {New York, NY, USA},
	series = {{ICTIR} '25},
	title = {Evaluating {List} {Construction} and {Temporal} {Understanding} capabilities of {Large} {Language} {Models}},
	isbn = {979-8-4007-1861-8},
	url = {https://doi.org/10.1145/3731120.3744606},
	doi = {10.1145/3731120.3744606},
	abstract = {Large Language Models (LLMs) have demonstrated immense advances in a wide range of natural language tasks. However, these models are susceptible to hallucinations and errors on particularly temporal understanding tasks involving multiple entities in answers. In such tasks, they fail to associate entities with accurate time intervals, generate a complete list of entities in answers or reason about events associated with specific temporal bounds. Existing works do not extensively evaluate the abilities of the model to perform implicit and explicit temporal understanding in a list answer construction setup. To bridge this gap, we propose the Time referenced List based Question Answering or TLQA benchmark that requires structured answers in list format aligned with corresponding time periods. Our TLQA benchmark, requires both list construction and temporal understanding simultaneously, which to the best of our knowledge has not been explored in prior benchmarks. We investigate the temporal understanding and list construction capabilities of state-of-the-art generative models on TLQA in closed-book and open-domain settings. Our findings reveal significant shortcomings in current models, particularly their inability to provide complete answers and temporally align facts in a closed-book setup and the need to improve retrieval in open-domain setup, providing clear future directions for research on TLQA. The benchmark and code can be publicly accessed at https://github.com/elixir-research-group/TLQA.},
	booktitle = {Proceedings of the 2025 {International} {ACM} {SIGIR} {Conference} on {Innovative} {Concepts} and {Theories} in {Information} {Retrieval} ({ICTIR})},
	publisher = {Association for Computing Machinery},
	author = {Dumitru, Alexandru and V, Venktesh and Jatowt, Adam and Anand, Avishek},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {retrieval, temporal question answering, temporal understanding},
	pages = {369--379},
}

@inproceedings{li_tex2py-45k_2025,
	address = {New York, NY, USA},
	series = {{CSAI} '24},
	title = {{Tex2Py}-{45K}: {A} {Parallel} {Corpus} {Dataset} for {Bidirectional} {Conversion} {Between} {LaTeX} and {Python}},
	isbn = {979-8-4007-1818-2},
	url = {https://doi.org/10.1145/3709026.3709044},
	doi = {10.1145/3709026.3709044},
	abstract = {LaTeX and Python, integral to the scientific research workflow, each offers specialized capabilities. Bidirectional LaTeX-Python conversion models could augment the efficacy and precision of scientific research. In this paper, we release the Tex2Py-45K dataset1, containing 45,668 LaTeX-Python pairs. Based on the Tex2Py-45K dataset, we propose SMML format and Hybrid training mode, which trained effective LaTeX-Python bidirectional conversion models. At last, we analyze failure cases of the LaTeX-Python bidirectional conversion, providing direction for future research.},
	booktitle = {Proceedings of the 2024 8th {International} {Conference} on {Computer} {Science} and {Artificial} {Intelligence}},
	publisher = {Association for Computing Machinery},
	author = {Li, Lei and Duan, Manni and Wang, Yongheng},
	year = {2025},
	keywords = {Bidirectional conversion, Code LLM, LaTeX, Parallel corpus, Python},
	pages = {197--203},
}

@inproceedings{lin_knowledge-injected_2024,
	address = {New York, NY, USA},
	series = {{WWW} '24},
	title = {A {Knowledge}-{Injected} {Curriculum} {Pretraining} {Framework} for {Question} {Answering}},
	isbn = {979-8-4007-0171-9},
	url = {https://doi.org/10.1145/3589334.3645406},
	doi = {10.1145/3589334.3645406},
	abstract = {Knowledge-based question answering (KBQA) is a key task in natural language processing research, and also an approach to access the web data and knowledge, which requires exploiting knowledge graphs (KGs) for reasoning. In the literature, one promising solution for KBQA is to incorporate the pretrained language model (LM) with KGs by generating KG-centered pretraining corpus, which has shown its superiority. However, these methods often depend on specific techniques and resources to work, which may not always be available and restrict its application. Moreover, existing methods focus more on improving language understanding with KGs, while neglect the more important human-like complex reasoning. To this end, in this paper, we propose a general K nowledge-I njected C urriculum P retraining framework (KICP) to achieve comprehensive KG learning and exploitation for KBQA tasks, which is composed of knowledge injection (KI), knowledge adaptation (KA) and curriculum reasoning (CR). Specifically, the KI module first injects knowledge into the LM by generating KG-centered pretraining corpus, and generalizes the process into three key steps that could work with different implementations for flexible application. Next, the KA module learns knowledge from the generated corpus with LM equipped with an adapter as well as keeps its original natural language understanding ability to reduce the negative impacts of the difference between the generated and natural corpus. Last, to enable the LM with complex reasoning, the CR module follows human reasoning patterns to construct three corpora with increasing difficulties of reasoning, and further trains the LM from easy to hard in a curriculum manner to promote model learning. We provide an implementation of the general framework, and evaluate the proposed KICP on four real-word datasets. The results demonstrate that our framework can achieve higher performances, and have good generalization ability to other QA tasks.},
	booktitle = {Proceedings of the {ACM} {Web} {Conference} 2024},
	publisher = {Association for Computing Machinery},
	author = {Lin, Xin and Su, Tianhuang and Huang, Zhenya and Xue, Shangzi and Liu, Haifeng and Chen, Enhong},
	year = {2024},
	note = {event-place: Singapore, Singapore},
	keywords = {curriculum learning, knowledge-injected pretraining, question answering},
	pages = {1986--1997},
}

@inproceedings{yamakawa_direct_2024,
	address = {New York, NY, USA},
	series = {{ICIIT} '24},
	title = {Direct {Backpropagation} {Realization} for {A} {Neural} {Network} including a {Database}},
	isbn = {979-8-4007-1671-3},
	url = {https://doi.org/10.1145/3654522.3654555},
	doi = {10.1145/3654522.3654555},
	abstract = {The Retrieval Augmented Language Model, which is a model that combines a language model and a database, has various advantages from having knowledge in the form of a database and has been actively studied, especially in the Question Answering task. Since the Retrieval Augmented Language Model cannot define the derivative in the database retrieval process, it generally performs backpropagation using a path that does not go through the database, which makes learning of the model inefficient. To realize backpropagation using a path through the database, we propose a method that can perform backpropagation by adding a derivative value to the database data. Before applying our method to the Retrieval Augmented Language Model, we conducted experiments on a simple recursive task to confirm its effectiveness. The results showed that the model that learned using direct paths through the database was more efficient than the model that learned using indirect paths.},
	booktitle = {Proceedings of the 2024 9th {International} {Conference} on {Intelligent} {Information} {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Yamakawa, Yuto and Kimura, Masaomi},
	year = {2024},
	note = {event-place: Ho Chi Minh City, Vietnam},
	keywords = {artificial neural networks, black-box backpropagation, database, Retrieval Augmented Language Model},
	pages = {340--345},
}

@inproceedings{verma_matryoshka_2025,
	address = {New York, NY, USA},
	series = {{KDD} '25},
	title = {Matryoshka {Model} {Learning} for {Improved} {Elastic} {Student} {Models}},
	isbn = {979-8-4007-1454-2},
	url = {https://doi.org/10.1145/3711896.3737245},
	doi = {10.1145/3711896.3737245},
	abstract = {Industry-grade ML models are carefully designed to meet rapidly evolving serving constraints, which requires significant resources for model development. In this paper, we propose MatTA, a framework for training multiple accurate Student models using a novel Teacher-TA-Student recipe. TA models are larger versions of the Student models with higher capacity, and thus allow Student models to better relate to the Teacher model and also bring in more domain-specific expertise. Furthermore, multiple accurate Student models can be extracted from the TA model. Therefore, despite only one training run, our methodology provides multiple servable options to trade off accuracy for lower serving cost. We demonstrate the proposed method, MatTA, on proprietary datasets and models. Its practical efficacy is underscored by live A/B tests within a production ML system, demonstrating 20\% improvement on a key metric. We also demonstrate our method on GPT-2 Medium, a public model, and achieve relative improvements of over 24\% on SAT Math and over 10\% on the LAMBADA benchmark.},
	booktitle = {Proceedings of the 31st {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} {V}.2},
	publisher = {Association for Computing Machinery},
	author = {Verma, Chetan and Timmaraju, Aditya Srinivas and Hsieh, Cho-Jui and Damle, Suyash and Bui, Ngot and Zhang, Yang and Chen, Wen and Liu, Xin and Jain, Prateek and Dhillon, Inderjit},
	year = {2025},
	note = {event-place: Toronto ON, Canada},
	keywords = {elastic inference, matryoshka representations, online distillation},
	pages = {4935--4944},
}

@inproceedings{sakhovskiy_bali_2025,
	address = {New York, NY, USA},
	series = {{SIGIR} '25},
	title = {{BALI}: {Enhancing} {Biomedical} {Language} {Representations} through {Knowledge} {Graph} and {Language} {Model} {Alignment}},
	isbn = {979-8-4007-1592-1},
	url = {https://doi.org/10.1145/3726302.3729901},
	doi = {10.1145/3726302.3729901},
	abstract = {In recent years, there has been substantial progress in using pretrained Language Models (LMs) on a range of tasks aimed at improving the understanding of biomedical texts. Nonetheless, existing biomedical LLMs show limited comprehension of complex, domain-specific concept structures and the factual information encoded in biomedical Knowledge Graphs (KGs). In this work, we propose BALI (Biomedical Knowledge Graph and Language Model Ali gnment), a novel joint LM and KG pre-training method that augments an LM with external knowledge by the simultaneous learning of a dedicated KG encoder and aligning the representations of both the LM and the graph. For a given textual sequence, we link biomedical concept mentions to the Unified Medical Language System (UMLS) KG and utilize local KG subgraphs as cross-modal positive samples for these mentions. Our empirical findings indicate that implementing our method on several leading biomedical LMs, such as PubMedBERT and BioLinkBERT, improves their performance on a range of language understanding tasks and the quality of entity representations, even with minimal pre-training on a small alignment dataset sourced from PubMed scientific abstracts.},
	booktitle = {Proceedings of the 48th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Sakhovskiy, Andrey and Tutubalina, Elena},
	year = {2025},
	note = {event-place: Padua, Italy},
	keywords = {biomedical knowledge graph, biomedical language model, biomedical natural language processing, contrastive learning, natural language processing, representation learning},
	pages = {1152--1164},
}

@inproceedings{argyrou_prompt2fashion_2024,
	address = {New York, NY, USA},
	series = {{SETN} '24},
	title = {{Prompt2Fashion}: {An} automatically generated fashion dataset},
	isbn = {979-8-4007-0982-1},
	url = {https://doi.org/10.1145/3688671.3690604},
	doi = {10.1145/3688671.3690604},
	abstract = {Despite the rapid evolution and increasing efficacy of language and vision generative models, there remains a lack of comprehensive datasets that bridge the gap between personalized fashion needs and AI-driven design, limiting the potential for truly inclusive and customized fashion solutions. In this work, we leverage generative models to automatically construct a fashion image dataset tailored to various occasions, styles, and body types as instructed by users. We use different Large Language Models (LLMs) and prompting strategies to offer personalized outfits of high aesthetic quality, detail, and relevance to both expert and non-expert users’ requirements, as demonstrated by qualitative analysis. Up until now the evaluation of the generated outfits has been conducted by non-expert human subjects. Despite the provided fine-grained insights on the quality and relevance of generation, we extend the discussion on the importance of expert knowledge for the evaluation of artistic AI-generated datasets such as this one. Our dataset is publicly available on GitHub at https://github.com/georgiarg/Prompt2Fashion.},
	booktitle = {Proceedings of the 13th {Hellenic} {Conference} on {Artificial} {Intelligence}},
	publisher = {Association for Computing Machinery},
	author = {Argyrou, Georgia and Dimitriou, Angeliki and Lymperaiou, Maria and Filandrianos, Giorgos and Stamou, Giorgos},
	year = {2024},
	keywords = {fashion synthesis, human evaluation, image dataset},
}

@inproceedings{wang_hierarchical_2025,
	address = {New York, NY, USA},
	series = {{WWW} '25},
	title = {Hierarchical {Prompt} {Decision} {Transformer}: {Improving} {Few}-{Shot} {Policy} {Generalization} with {Global} and {Adaptive} {Guidance}},
	isbn = {979-8-4007-1331-6},
	url = {https://doi.org/10.1145/3701716.3715233},
	doi = {10.1145/3701716.3715233},
	abstract = {Decision transformers recast reinforcement learning as a conditional sequence generation problem, offering a simple but effective alternative to traditional value or policy-based methods. A recent key development in this area is the integration of prompting in decision transformers to facilitate few-shot policy generalization. However, current methods mainly use static prompt segments to guide rollouts, limiting their ability to provide context-specific guidance. Addressing this, we introduce a hierarchical prompting approach enabled by retrieval augmentation. Our method learns two layers of soft tokens as guiding prompts: (1) global tokens encapsulating task-level information about trajectories, and (2) adaptive tokens that deliver focused, timestep-specific instructions. The adaptive tokens are dynamically retrieved from a curated set of demonstration segments, ensuring context-aware guidance. Experiments across seven benchmark tasks in the MuJoCo and MetaWorld environments demonstrate the proposed approach consistently outperforms all baseline methods, suggesting that hierarchical prompting for decision transformers is an effective strategy to enable few-shot policy generalization.},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	publisher = {Association for Computing Machinery},
	author = {Wang, Zhe and Wang, Haozhu and Qi, Yanjun},
	year = {2025},
	note = {event-place: Sydney NSW, Australia},
	keywords = {decision transformer, few-shot learning, reinforcement learning},
	pages = {520--529},
}

@inproceedings{han_fair-co2_2025,
	address = {New York, NY, USA},
	series = {{ISCA} '25},
	title = {Fair-{CO2}: {Fair} {Attribution} for {Cloud} {Carbon} {Emissions}},
	isbn = {979-8-4007-1261-6},
	url = {https://doi.org/10.1145/3695053.3731023},
	doi = {10.1145/3695053.3731023},
	abstract = {Fair-CO2 is a system for fairly attributing operational and embodied carbon in cloud data centers to user workloads. It leverages the Shapley value, a game theory solution for fair shared cost attribution with theoretical fairness guarantees. We propose the standard Shapley value solution as a ground truth for attribution in cloud data centers, addressing two key gaps in existing carbon attribution methods that lead to unfair attributions: the effect of dynamic demand on embodied carbon, and interference effects in colocated scenarios. However, the computational cost of the Shapley value solution scales exponentially with the number of workloads and becomes intractable for large systems. Fair-CO2 addresses the scalability challenges of the Shapley value while preserving its fairness benefits via two core components: demand-aware embodied carbon attribution and interference-aware resource cost attribution. Using Monte Carlo simulations of workload schedules and colocation scenarios, we show that Fair-CO2 can approximate the ground truth Shapley attribution solution at scale. We also show how users, once provided a fair way of estimating their workload carbon footprint, can dynamically optimize workload deployment for carbon savings.},
	booktitle = {Proceedings of the 52nd {Annual} {International} {Symposium} on {Computer} {Architecture}},
	publisher = {Association for Computing Machinery},
	author = {Han, Leo and Kakadia, Jash and Lee, Benjamin C. and Gupta, Udit},
	year = {2025},
	keywords = {carbon accounting, cloud computing, sustainable computing},
	pages = {646--663},
}

@inproceedings{kim_lapis_2024,
	address = {New York, NY, USA},
	series = {{CIKM} '24},
	title = {{LAPIS}: {Language} {Model}-{Augmented} {Police} {Investigation} {System}},
	isbn = {979-8-4007-0436-9},
	url = {https://doi.org/10.1145/3627673.3680044},
	doi = {10.1145/3627673.3680044},
	abstract = {Crime situations are race against time. An AI-assisted criminal investigation system, providing prompt but precise legal counsel is in need for police officers. We introduce LAPIS (Language Model Augmented Police Investigation System), an automated system that assists police officers to perform rational and legal investigative actions. We constructed a finetuning dataset and retrieval knowledgebase specialized in crime investigation legal reasoning task. We extended the dataset's quality by incorporating manual curation efforts done by a group of domain experts. We then finetuned the pretrained weights of a smaller Korean language model to the newly constructed dataset and integrated it with the crime investigation knowledgebase retrieval approach. Experimental results show LAPIS' potential in providing reliable legal guidance for police officers, even better than the proprietary GPT-4 model. Qualitative analysis on the rationales generated by LAPIS demonstrate the model's reasoning ability to leverage the premises and derive legally correct conclusions.},
	booktitle = {Proceedings of the 33rd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {Association for Computing Machinery},
	author = {Kim, Heedou and Kim, Dain and Lee, Jiwoo and Yoon, Chanwoong and Choi, Donghee and Gim, Mogan and Kang, Jaewoo},
	year = {2024},
	note = {event-place: Boise, ID, USA},
	keywords = {crime investigation, large language models, police investigation},
	pages = {4637--4644},
}

@inproceedings{grafberger_towards_2024,
	address = {New York, NY, USA},
	series = {{DEEM} '24},
	title = {Towards {Interactively} {Improving} {ML} {Data} {Preparation} {Code} via "{Shadow} {Pipelines}"},
	isbn = {979-8-4007-0611-0},
	url = {https://doi.org/10.1145/3650203.3663327},
	doi = {10.1145/3650203.3663327},
	abstract = {Data scientists develop ML pipelines in an iterative manner: they repeatedly screen a pipeline for potential issues, debug it, and then revise and improve its code according to their findings. However, this manual process is tedious and error-prone. Therefore, we propose to support data scientists during this development cycle with automatically derived interactive suggestions for pipeline improvements. We discuss our vision to generate these suggestions with so-called shadow pipelines, hidden variants of the original pipeline that modify it to auto-detect potential issues, try out modifications for improvements, and suggest and explain these modifications to the user. We envision to apply incremental view maintenance-based optimisations to ensure low-latency computation and maintenance of the shadow pipelines. We conduct preliminary experiments to showcase the feasibility of our envisioned approach and the potential benefits of our proposed optimisations.},
	booktitle = {Proceedings of the {Eighth} {Workshop} on {Data} {Management} for {End}-to-{End} {Machine} {Learning}},
	publisher = {Association for Computing Machinery},
	author = {Grafberger, Stefan and Groth, Paul and Schelter, Sebastian},
	year = {2024},
	note = {event-place: Santiago, AA, Chile},
	pages = {7--11},
}

@inproceedings{wampfler_platform_2025,
	address = {New York, NY, USA},
	series = {{SIGGRAPH} {Conference} {Papers} '25},
	title = {A {Platform} for {Interactive} {AI} {Character} {Experiences}},
	isbn = {979-8-4007-1540-2},
	url = {https://doi.org/10.1145/3721238.3730762},
	doi = {10.1145/3721238.3730762},
	abstract = {From movie characters to modern science fiction — bringing characters into interactive, story-driven conversations has captured imaginations across generations. Achieving this vision is highly challenging and requires much more than just language modeling. It involves numerous complex AI challenges, such as conversational AI, maintaining character integrity, managing personality and emotions, handling knowledge and memory, synthesizing voice, generating animations, enabling real-world interactions, and integration with physical environments. Recent advancements in the development of foundation models, prompt engineering, and fine-tuning for downstream tasks have enabled researchers to address these individual challenges. However, combining these technologies for interactive characters remains an open problem. We present a system and platform for conveniently designing believable digital characters, enabling a conversational and story-driven experience while providing solutions to all of the technical challenges. As a proof-of-concept, we introduce Digital Einstein, which allows users to engage in conversations with a digital representation of Albert Einstein about his life, research, and persona. While Digital Einstein exemplifies our methods for a specific character, our system is flexible and generalizes to any story-driven or conversational character. By unifying these diverse AI components into a single, easy-to-adapt platform, our work paves the way for immersive character experiences, turning the dream of lifelike, story-based interactions into a reality.},
	booktitle = {Proceedings of the {Special} {Interest} {Group} on {Computer} {Graphics} and {Interactive} {Techniques} {Conference} {Conference} {Papers}},
	publisher = {Association for Computing Machinery},
	author = {Wampfler, Rafael and Yang, Chen and Elste, Dillon and Kovacevic, Nikola and Witzig, Philine and Gross, Markus},
	year = {2025},
	keywords = {Character Consistency, Conversational AI, Digital Characters, Embodied Conversational Agents, Interactive Storytelling, Large Language Models, Memory Systems, Multimodal Interaction, Personality Modeling, Speech Synthesis, Speech‑Driven Animation},
}

@inproceedings{jang_accelerating_2025,
	address = {New York, NY, USA},
	series = {{MICRO} '25},
	title = {Accelerating {Retrieval} {Augmented} {Language} {Model} via {PIM} and {PNM} {Integration}},
	isbn = {979-8-4007-1573-0},
	url = {https://doi.org/10.1145/3725843.3756020},
	doi = {10.1145/3725843.3756020},
	abstract = {Retrieval-Augmented Language Models (RALMs) integrate a language model with an external database to generate high-quality outputs utilizing up-to-date information. However, both components of a RALM system, the language model and the retriever, suffer from distinct memory-bound bottlenecks. In particular, the attention mechanism of the language model heavily relies on General Matrix-Vector Multiplication (GEMV) operations using unique K/V matrices per request, complicating batch parallelization and exacerbating memory bandwidth constraints. Conversely, the retriever encounters performance bottlenecks due to frequent LUT lookups and intensive sorting operations, characterized by low arithmetic intensity and limited data reuse, making GPU acceleration challenging. To address these distinctive characteristics, this paper proposes MNM, a hardware architecture integrating Processing In Memory (PIM) within the HBM core die and Processing Near Memory (PNM) on the HBM logic die. The PIM module leverages the high internal bandwidth of HBM to accelerate GEMV operations in the language model, while the PNM module optimizes retrieval-specific tasks. Furthermore, this work introduces a novel RALM scheduling strategy combining selective batching and early generation to exploit the performance improvements achieved by the MNM architecture. By strategically overlapping retrieval and generation phases, the proposed scheduling scheme reduces idle cycles in a batched RALM system. Experimental results demonstrate that the proposed techniques achieve up to 29.2 × performance speedup compared to a conventional GPU-based RALM system. In addition, the proposed PIM/PNM-integrated approach saves up to 71.5\% of energy consumption, highlighting its applicability for memory-bound RALM workloads.},
	booktitle = {Proceedings of the 58th {IEEE}/{ACM} {International} {Symposium} on {Microarchitecture}},
	publisher = {Association for Computing Machinery},
	author = {Jang, Je-Woo and Oh, Junyong and Kong, Youngbae and Hong, Jae-Youn and Cho, Sung-Hyuk and Lee, Jeongyeol and Yang, Hoeseok and Yang, Joon-Sung},
	year = {2025},
	keywords = {High Bandwidth Memory, Processing in Memory, Processing near memory, Retrieval augmented language model, Vector Search},
	pages = {246--262},
}

@inproceedings{tran_memoriqa_2024,
	address = {New York, NY, USA},
	series = {{AIQAM} '24},
	title = {{MemoriQA}: {A} {Question}-{Answering} {Lifelog} {Dataset}},
	isbn = {979-8-4007-0547-2},
	url = {https://doi.org/10.1145/3643479.3662050},
	doi = {10.1145/3643479.3662050},
	abstract = {Lifelogging can be referred to as the process of passively collecting data on an individual's daily life. Lifelog data provides a large amount of information which can be used to understand the lifelogger's lifestyle and preferences. This data can also support the lifeloggers in saving their memories and important moments. Question-answering (QA) is a common task in natural language processing (NLP) and can be extended to multi-modal such as the visual question-answering task. QA for lifelog data can be described as the task of answering questions about a lifelogger's past using lifelog data, which can significantly help lifeloggers understand their life by asking questions about their lifelog. QA for lifelogs can also provide useful insights into lifelogger's life for those exploring their lifelog. This paper presents the MemoriQA lifelog dataset designed to explore the question-answering task for lifelogs. This dataset provides 61-day lifelog images and other lifelog data such as internet activity, health metrics, music listening history and GPS. A comprehensive annotation process is performed to create the description as well as question-answer pairs. We propose some methods to address the QA in lifelog problem in this paper.},
	booktitle = {Proceedings of the 1st {ACM} {Workshop} on {AI}-{Powered} {Q}\&amp;{A} {Systems} for {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Tran, Quang-Linh and Nguyen, Binh and Jones, Gareth J. F. and Gurrin, Cathal},
	year = {2024},
	note = {event-place: Phuket, Thailand},
	keywords = {Lifelog Dataset, Personal Lifelog Archive, Question Answering},
	pages = {7--12},
}

@inproceedings{ferracani_personalized_2024,
	address = {New York, NY, USA},
	series = {{SUMAC} '24},
	title = {Personalized {Generative} {Storytelling} with {AI}-{Visual} {Illustrations} for the {Promotion} of {Knowledge} in {Cultural} {Heritage} {Tourism}},
	isbn = {979-8-4007-1205-0},
	url = {https://doi.org/10.1145/3689094.3689465},
	doi = {10.1145/3689094.3689465},
	abstract = {This paper presents a mobile application that exploits interactive narrative storytelling through GPT-4 and a custom image generative pipeline to improve cultural tourism experiences. The application helps tourists visiting cities to program and personalize cultural city tours creating stories with the user as the protagonist. The app guides the users to choose Point-Of-Interests (POIs) and narrative genres of the narrative while the image generation pipeline provides them with visual and coherent representations of their actions in the story contributing to a more immersive and personalized experience. Technical challenges include producing coherent stories and real-time and quality images, maintaining visual composition and person identity, including multiple concepts, through prompt engineering. We validate the effectiveness of the application and the image generative pipeline through users studies which evaluate the educational potential of our approach.},
	booktitle = {Proceedings of the 6th {Workshop} on the {AnalySis}, {Understanding} and {ProMotion} of {HeritAge} {Contents}},
	publisher = {Association for Computing Machinery},
	author = {Ferracani, Andrea and Bertini, Marco and Pala, Pietro and Nannotti, Gabriele and Principi, Filippo and Becchi, Giuseppe},
	year = {2024},
	note = {event-place: Melbourne VIC, Australia},
	keywords = {ai, cultural heritage, cultural tourism, gpt-4, image generation, personalization, stable diffusion, storytelling},
	pages = {28--32},
}

@inproceedings{zhang_copilot---loop_2024,
	address = {New York, NY, USA},
	series = {{ASE} '24},
	title = {Copilot-in-the-{Loop}: {Fixing} {Code} {Smells} in {Copilot}-{Generated} {Python} {Code} using {Copilot}},
	isbn = {979-8-4007-1248-7},
	url = {https://doi.org/10.1145/3691620.3695290},
	doi = {10.1145/3691620.3695290},
	abstract = {As one of the most popular dynamic languages, Python experiences a decrease in readability and maintainability when code smells are present. Recent advancements in Large Language Models have sparked growing interest in AI-enabled tools for both code generation and refactoring. GitHub Copilot is one such tool that has gained widespread usage. Copilot Chat, released in September 2023, functions as an interactive tool aimed at facilitating natural language-powered coding. However, limited attention has been given to understanding code smells in Copilot-generated Python code and Copilot Chat's ability to fix the code smells. To this end, we built a dataset comprising 102 code smells in Copilot-generated Python code. Our aim is to first explore the occurrence of code smells in Copilot-generated Python code and then evaluate the effectiveness of Copilot Chat in fixing these code smells employing different prompts. The results show that 8 out of 10 types of code smells can be detected in Copilot-generated Python code, among which Multiply-Nested Container is the most common one. For these code smells, Copilot Chat achieves a highest fixing rate of 87.1\%, showing promise in fixing Python code smells generated by Copilot itself. In addition, the effectiveness of Copilot Chat in fixing these smells can be improved by providing more detailed prompts.},
	booktitle = {Proceedings of the 39th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Beiqi and Liang, Peng and Feng, Qiong and Fu, Yujia and Li, Zengyang},
	year = {2024},
	note = {event-place: Sacramento, CA, USA},
	keywords = {code quality, code refactoring, code smell, GitHub copilot},
	pages = {2230--2234},
}

@inproceedings{gsteiger_caribou_2024,
	address = {New York, NY, USA},
	series = {{SOSP} '24},
	title = {Caribou: {Fine}-{Grained} {Geospatial} {Shifting} of {Serverless} {Applications} for {Sustainability}},
	isbn = {979-8-4007-1251-7},
	url = {https://doi.org/10.1145/3694715.3695954},
	doi = {10.1145/3694715.3695954},
	abstract = {Sustainability in computing is critical as environmental concerns rise. The cloud industry's carbon footprint is significant and rapidly growing. We show that dynamic geospatial shifting of cloud workloads to regions with lower carbon emission energy sources, particularly for more portable cloud workloads such as serverless applications, has a high potential to lower operational carbon emissions. To make the case, we build a comprehensive framework called Caribou that offloads serverless workflows across geo-distributed regions. Caribou requires no change in the application logic, nor on the provider side. It dynamically determines the best deployment plans, automatically (re-) deploys functions to appropriate regions, and redirects traffic to new endpoints. In reducing operational carbon through fine-grained, function-level offloading, Caribou does not undermine standard metrics such as performance and cost. We show how this approach can reduce the carbon footprint by an average of 22.9\% to 66.6\% across the North American continent. We demonstrate how a detailed specification of location constraints (e.g., to ensure compliance of one stage) can allow emission reductions for workflows (e.g., by offloading other stages). By showcasing the feasibility of carbon-aware geospatial application deployment, Caribou aims to push the boundaries of system techniques available to curtail cloud carbon emissions and provide a framework for future research.},
	booktitle = {Proceedings of the {ACM} {SIGOPS} 30th {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {Association for Computing Machinery},
	author = {Gsteiger, Viktor Urban and Long, Pin Hong (Daniel) and Sun, Yiran (Jerry) and Javanrood, Parshan and Shahrad, Mohammad},
	year = {2024},
	note = {event-place: Austin, TX, USA},
	keywords = {carbon-aware scheduling, cloud computing, geospatial shifting, serverless computing, sustainability},
	pages = {403--420},
}

@inproceedings{legtchenko_storage_2025,
	address = {New York, NY, USA},
	series = {{HotOS} '25},
	title = {Storage {Class} {Memory} is {Dead}, {All} {Hail} {Managed}-{Retention} {Memory}: {Rethinking} {Memory} for the {AI} {Era}},
	isbn = {979-8-4007-1475-7},
	url = {https://doi.org/10.1145/3713082.3730381},
	doi = {10.1145/3713082.3730381},
	abstract = {AI clusters today are one of the major uses of High Bandwidth Memory (HBM). However, HBM is suboptimal for AI workloads for several reasons. Analysis shows HBM is overprovisioned on write performance, but underprovisioned on density and read bandwidth, and also has significant energy per bit overheads. It is also expensive, with lower yield than DRAM due to manufacturing complexity. We propose a new memory class: Managed-Retention Memory (MRM), which is more optimized to store key data structures for AI inference workloads. We believe that MRM may finally provide a path to viability for technologies that were originally proposed to support Storage Class Memory (SCM). These technologies traditionally offered long-term persistence (10+ years) but provided poor IO performance and/or endurance. MRM makes different trade-offs, and by understanding the workload IO patterns, MRM foregoes long-term data retention and write performance for better potential performance on the metrics important for these workloads.},
	booktitle = {Proceedings of the 2025 {Workshop} on {Hot} {Topics} in {Operating} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Legtchenko, Sergey and Stefanovici, Ioan and Black, Richard and Rowstron, Antony and Liu, Junyi and Costa, Paolo and Canakci, Burcu and Narayanan, Dushyanth and Wu, Xingbo},
	year = {2025},
	note = {event-place: Banff, AB, Canada},
	keywords = {AI Inference, AI Infrastructure, Managed-Retention Memory, Memory},
	pages = {111--118},
}

@inproceedings{sui_pre-warming_2024,
	address = {New York, NY, USA},
	series = {{SoCC} '24},
	title = {Pre-{Warming} is {Not} {Enough}: {Accelerating} {Serverless} {Inference} {With} {Opportunistic} {Pre}-{Loading}},
	isbn = {979-8-4007-1286-9},
	url = {https://doi.org/10.1145/3698038.3698509},
	doi = {10.1145/3698038.3698509},
	abstract = {Serverless computing has rapidly prospered as a new cloud computing paradigm with agile scalability, pay-as-you-go pricing, and ease-to-use features for Machine Learning (ML) inference tasks. Users package their ML code into lightweight serverless functions and execute them using containers. Unfortunately, a notorious problem, called cold-starts, hinders serverless computing from providing low-latency function executions. To mitigate cold-starts, pre-warming, which keeps containers warm predictively, has been widely accepted by academia and industry. However, pre-warming fails to eliminate the unique latency incurred by loading ML artifacts. We observed that for ML inference functions, the loading of libraries and models takes significantly more time than container warming. Consequently, pre-warming alone is not enough to mitigate the ML inference function's cold-starts.This paper introduces InstaInfer, an opportunistic preloading technique to achieve instant inference by eliminating the latency associated with loading ML artifacts, thereby achieving minimal time cost in function execution. InstaInfer fully utilizes the memory of warmed containers to preload the function's libraries and model, striking a balance between maximum acceleration and resource wastage. We design InstaInfer to be transparent to providers and compatible with existing pre-warming solutions. Experiments on OpenWhisk with real-world workloads show that InstaInfer reduces up to 93\% loading latency and achieves up to 8× speedup compared to state-of-the-art pre-warming solutions.},
	booktitle = {Proceedings of the 2024 {ACM} {Symposium} on {Cloud} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Sui, Yifan and Yu, Hanfei and Hu, Yitao and Li, Jianxun and Wang, Hao},
	year = {2024},
	note = {event-place: Redmond, WA, USA},
	keywords = {Cloud Computing, Cold-Start, Machine Learning, Serverless Computing},
	pages = {178--195},
}

@article{lu_hsg-rag_2025,
	title = {{HSG}-{RAG}: {Hierarchical} {Knowledge} {Base} {Construction} for {Embedded} {System} {Development}},
	volume = {30},
	issn = {1084-4309},
	url = {https://doi.org/10.1145/3731680},
	doi = {10.1145/3731680},
	abstract = {Customization is a fundamental aspect of embedded system development, requiring developers to acquire extensive domain-specific knowledge from technical documents. However, the sheer volume of these documents, coupled with the intricate relationships between their contents, makes it challenging to efficiently retrieve the necessary information. This challenge highlights the need for a structured approach to organize domain knowledge, with explicit representation of interrelationships. Moreover, while advanced large language models (LLMs) show promise in aiding embedded system development, they often lack the specialized knowledge needed to address domain-specific queries effectively. In this article, we present HSG-RAG, a knowledge base construction and retrieval method tailored for embedded system development that leverages knowledge graphs to represent the hierarchical structure within technical documentation. Unlike prior retrieval-augmented generation (RAG) or GraphRAG-based approaches, which build the index either rely on semantic similarity or keyword co-occurrence, HSG-RAG captures the inherited dependency and hierarchical relationships in the documents, which benefits the retrieval in both performance and efficiency. We also introduce a benchmark for evaluating the effectiveness of RAG systems in solving real-world challenges in embedded systems, particularly for multi-hop question answering. Experimental results show that HSG-RAG outperforms both RAG and GraphRAG, generating more specific and concise responses.},
	number = {6},
	journal = {ACM Trans. Des. Autom. Electron. Syst.},
	author = {Lu, Zhouyang and Xu, Hailin and Chen, Anrui and Tang, Siyuan and Zhang, Junyi and Feng, Yifei and Pan, Wentao and Huang, Jiangli},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {embedded system, Knowledge base, large language model, retrieval augmented generation},
}

@article{xiao_eda-copilot_2025,
	title = {{EDA}-{Copilot}: {A} {RAG}-{Powered} {Intelligent} {Assistant} for {EDA} {Tools}},
	volume = {30},
	issn = {1084-4309},
	url = {https://doi.org/10.1145/3715326},
	doi = {10.1145/3715326},
	abstract = {With the rise of Large Language Models (LLMs), researchers have become increasingly interested in their applications in EDA flows, particularly in specific subdomains such as serving as knowledge assistants and generating RTL code. In this study, we present a Retrieval-Augmented Generation (RAG) framework tailored to EDA task processing, named EDA-Adaptive RAG. This framework addresses the implicit semantics of EDA data and facilitates efficient knowledge acquisition through classification and enhanced retrieval, significantly enhancing LLMs ability to acquire EDA knowledge. Furthermore, we aim to integrate RAG into the design process as an EDA assistant application. Using RTL code generation as a case study, we demonstrate that the performance of RTL code generation can be enhanced through highly relevant retrievals provided by our RAG. The experimental analysis involves EDA Q\&amp;A tasks and RTL code generation evaluation. It is shown that our method outperforms the latest works in terms of both answer stability and code quality.},
	number = {6},
	journal = {ACM Trans. Des. Autom. Electron. Syst.},
	author = {Xiao, Zhe and He, Xu and Wu, Haoying and Yu, Bei and Guo, Yang},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {electronic design automation, Large language models, retrieval-augmented generation, RTL-to-GDSII},
}

@article{xu_muralagent_2025,
	title = {{MuralAgent}: {Enhancing} {Ancient} {Mural} {Outpainting} with {RAG}-{Based} {Texts} and {Multimodal} {Integration}},
	volume = {21},
	issn = {1551-6857},
	url = {https://doi.org/10.1145/3743679},
	doi = {10.1145/3743679},
	abstract = {In the context of the digital age, utilizing cutting-edge technology for the digitization and creative expansion of ancient murals is crucial, aimed at preserving and passing on cultural heritage. Existing image outpainting techniques suffer from a lack of semantic guidance. This article introduces MuralAgent, a multimodal model based on Retrieval-Augmented Generation (RAG) technology. It precisely extracts key information from mural images and integrates it with a constructed ancient texts knowledge base to ensure the cultural and semantic consistency of the expanded images. Moreover, fine-tuning the Stable Diffusion model ensures the fidelity of the generated image styles. Specifically, this study involves constructing an ancient texts knowledge base for accurate matching, designing specific prompts for GPT-4V(ision) to extract key information, and innovatively expanding artworks through Stable Diffusion, providing a novel way for the public to reinterpret ancient murals.},
	number = {9},
	journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
	author = {Xu, Zishan and Zhang, Xiaofeng and Yang, Yuqing and Chen, Wei and Liu, Jueting and Xu, Tingting and Wang, Zehua and El Saddik, Abdulmotaleb},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {GPT-4V(ision), Mural, Outpainting, Retrieval-Augmented Generation, Stable Diffusion},
}

@article{arazzi_rag-ioe_2025,
	title = {{RAG}-{IoE}: {IoT} context-aware information retrieval with {Large} {Language} {Models} in {Industry} 5.0},
	url = {https://doi.org/10.1145/3762669},
	doi = {10.1145/3762669},
	abstract = {Human-centric design, intelligence, and seamless interconnectivity are key pillars of the Industry 5.0. A critical challenge in these scenarios is the efficient retrieval of relevant, context-aware information for workers within Internet of Everything (IoE) networks. Traditional information retrieval techniques struggle with the heterogeneous, dynamic data generated in industrial settings. To address this, we define a context-aware data model for IoE scenarios, on top of which we propose RAG-IoE, a novel Retrieval-Augmented Generation (RAG) solution to enable adaptive, scalable, and context-based information retrieval from both structured and unstructured data sources. Our approach organizes IoE data within a semantic framework, integrating hybrid retrieval methods. It combines structured search on a Knowledge Graph with unstructured data retrieval using embeddings stored in a vector database, followed by LLM-driven reasoning to refine results. This architecture enhances decision-making, reduces cognitive overload, and ensures precise guidance for industrial operators. We validate the efficiency and effectiveness of RAG-IoE using a novel dataset through both a user study and quantitative analysis, demonstrating its potential to optimize human-machine collaboration in Industry 5.0 environments.},
	journal = {ACM Trans. Internet Things},
	author = {Arazzi, Marco and Marconi Sciarroni, Monica and Nocera, Antonino and Storti, Emanuele},
	month = aug,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Context-aware, Industry 5.0, IoE, IoT, Knowledge Graph, Large Language Model, Retrieval-Augmented Generation},
	annote = {Just Accepted},
}

@article{lyu_crud-rag_2025,
	title = {{CRUD}-{RAG}: {A} {Comprehensive} {Chinese} {Benchmark} for {Retrieval}-{Augmented} {Generation} of {Large} {Language} {Models}},
	volume = {43},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/3701228},
	doi = {10.1145/3701228},
	abstract = {Retrieval-augmented generation (RAG) is a technique that enhances the capabilities of large language models (LLMs) by incorporating external knowledge sources. This method addresses common LLM limitations, including outdated information and the tendency to produce inaccurate “hallucinated” content. However, evaluating RAG systems is a challenge. Most benchmarks focus primarily on question-answering applications, neglecting other potential scenarios where RAG could be beneficial. Accordingly, in the experiments, these benchmarks often assess only the LLM components of the RAG pipeline or the retriever in knowledge-intensive scenarios, overlooking the impact of external knowledge base construction and the retrieval component on the entire RAG pipeline in non-knowledge-intensive scenarios. To address these issues, this article constructs a large-scale and more comprehensive benchmark and evaluates all the components of RAG systems in various RAG application scenarios. Specifically, we refer to the CRUD actions that describe interactions between users and knowledge bases and also categorize the range of RAG applications into four distinct types—create, read, update, and delete (CRUD). “Create” refers to scenarios requiring the generation of original, varied content. “Read” involves responding to intricate questions in knowledge-intensive situations. “Update” focuses on revising and rectifying inaccuracies or inconsistencies in pre-existing texts. “Delete” pertains to the task of summarizing extensive texts into more concise forms. For each of these CRUD categories, we have developed different datasets to evaluate the performance of RAG systems. We also analyze the effects of various components of the RAG system, such as the retriever, context length, knowledge base construction, and LLM. Finally, we provide useful insights for optimizing the RAG technology for different scenarios. The source code is available at GitHub: .},
	number = {2},
	journal = {ACM Trans. Inf. Syst.},
	author = {Lyu, Yuanjie and Li, Zhiyu and Niu, Simin and Xiong, Feiyu and Tang, Bo and Wang, Wenjin and Wu, Hao and Liu, Huanyong and Xu, Tong and Chen, Enhong},
	month = jan,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Evaluation, Large Language Models, Retrieval-Augmented Generation},
}

@article{zhao_chat2data_2024,
	title = {{Chat2Data}: {An} {Interactive} {Data} {Analysis} {System} with {RAG}, {Vector} {Databases} and {LLMs}},
	volume = {17},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3685800.3685905},
	doi = {10.14778/3685800.3685905},
	abstract = {Traditional data analysis methods require users to write programming codes or issue SQL queries to analyze the data, which are inconvenient for ordinary users. Large language models (LLMs) can alleviate these limitations by enabling users to interact with the data with natural language (NL), e.g., result retrieval and summarization for unstructured data and transforming the NL text to SQL queries or codes for structured data. However, existing LLMs have three limitations: hallucination (due to lacking domain knowledge for vertical domains), high cost for LLM reasoning, and low accuracy for complicated tasks. To address these problems, we propose a prototype, Chat2Data, to interactively analyze the data with natural language. Chat2Data adopts a three-layer method, where the first layer uses Retrieval-Augmented Generation (RAG) to embed domain knowledge in order to address the hallucination problem, the second layer utilizes vector databases to reduce the number of interactions with LLMs so as to improve the performance, and the third layer designs a pipeline agent to decompose a complex task to multiple subtasks and use multiple round reasoning to generate the results in order to improve the accuracy of LLMs. We demonstrate Chat2Data with two real scenarios, unstructured data retrieval and summarization, and natural language-based structured data analysis. The online demo is available at http://vdemo.dbmind.cn.},
	number = {12},
	journal = {Proc. VLDB Endow.},
	author = {Zhao, Xinyang and Zhou, Xuanhe and Li, Guoliang},
	month = aug,
	year = {2024},
	note = {Publisher: VLDB Endowment},
	pages = {4481--4484},
}

@article{ang_tsgassist_2024,
	title = {{TSGAssist}: {An} {Interactive} {Assistant} {Harnessing} {LLMs} and {RAG} for {Time} {Series} {Generation} {Recommendations} and {Benchmarking}},
	volume = {17},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3685800.3685862},
	doi = {10.14778/3685800.3685862},
	abstract = {Time Series Generation (TSG) is essential in many industries for generating synthetic data that mirrors real-world characteristics. TSGBench has advanced the field by offering comprehensive evaluations and unique insights for selecting suitable TSG methods. However, translating these advancements to industry applications is hindered by a cognitive gap among professionals and the absence of a dynamic platform for method comparison and evaluation. To address these issues, we introduce TSGAssist, an interactive assistant that integrates the strengths of TSGBench and harnesses Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) for TSG recommendations and benchmarking. Our demonstration highlights its effectiveness in (1) enhancing TSG understanding, (2) providing industry-specific recommendations, and (3) offering a comprehensive benchmarking platform, illustrating its potential to ease industry professionals' navigation through the TSG landscape and encourage broader application across industries.},
	number = {12},
	journal = {Proc. VLDB Endow.},
	author = {Ang, Yihao and Bao, Yifan and Huang, Qiang and Tung, Anthony K. H. and Huang, Zhiyong},
	month = aug,
	year = {2024},
	note = {Publisher: VLDB Endowment},
	pages = {4309--4312},
}

@article{wei_modelgen_2025,
	title = {{ModelGen}: {Automating} {Semiconductor} {Parameter} {Extraction} with {Large} {Language} {Model} {Agents}},
	volume = {30},
	issn = {1084-4309},
	url = {https://doi.org/10.1145/3736165},
	doi = {10.1145/3736165},
	abstract = {Device models require large numbers of parameters to characterize complex physical effects. Although the latest advancements in machine learning and automated tools have drastically improved efficiency over the classic methods, they still demand a considerable amount of human intervention in the loop to gain accuracy. This drastically limits further automation. Inspired by the success of Multimodal Large Language Models (MLLMs) in addressing tasks across diverse fields, we propose ModelGen, the first in-depth study to leverage MLLMs with RAG (Retrieval-Augmented Generation) to significantly reduce human effort in parameter extraction for compact model. Our contributions include (1) Automated Agentic Workflow Construction that learns to build and refine extraction workflows through iterative optimization, (2) MLLM Judge, a visual scoring mechanism that evaluates fitting quality using actual device characteristic plots rather than simple numerical metrics, and (3) Model-specific RAG for providing relevant domain knowledge during the extraction process. Experimental results demonstrate that ModelGen achieves a 26.8\%–33.1\% improvement in pass@1,3,5 compared to base LLM methods. The system completes complex model extractions for BSIMs and ASM-HEMT in hours (up to 168× faster) rather than days or weeks, making parameter extraction more accessible to non-experts while maintaining professional engineer-level accuracy.},
	number = {6},
	journal = {ACM Trans. Des. Autom. Electron. Syst.},
	author = {Wei, Yangbo and Huang, Li and Feng, Qi and Chen, Zhanfei and Yan, Jinlong and Lin, Ting-Jung and Huang, Zhen and Ren, Kun and Xing, Wei and He, Lei},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {AI agent, bayesian optimization, device model, electronic design automation, large language models, Parameter extraction},
}

@article{ke_large_2025,
	title = {Large {Language} {Models} in {Document} {Intelligence}: {A} {Comprehensive} {Survey}, {Recent} {Advances}, {Challenges} and {Future} {Trends}},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/3768156},
	doi = {10.1145/3768156},
	abstract = {The rapid proliferation of documents has made document intelligence increasingly critical across various industries. In recent years, large language models (LLMs) have dramatically transformed the field of document intelligence, allowing for more advanced and accurate document processing solutions. Despite these advancements, most existing surveys have failed to focus on these breakthroughs, instead concentrating on traditional methods and earlier machine learning techniques. This survey seeks to fill that gap by offering an in-depth analysis of approximately 300 papers published between 2021 and mid-2025, thus providing a comprehensive overview of the impact of LLMs in document intelligence. The key topics explored include retrieval-augmented generation (RAG), long context processing, and fine-tuning LLMs for document comprehension. Furthermore, the survey highlights essential datasets, practical applications, current challenges, and future research directions, offering critical insights for both researchers and industry practitioners looking to advance the field.},
	journal = {ACM Trans. Inf. Syst.},
	author = {Ke, Wenjun and Zheng, Yifan and Li, Yining and Xu, Hengyuan and Nie, Dong and Wang, Peng and He, Yao},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Document Intelligence, Large Language Models, Long Context, RAG},
	annote = {Just Accepted},
}

@article{ouyang_dynagraph_2025,
	title = {{DynaGraph}: {Towards} {Dynamic} {Graph} {Learning} for {Multi}-scale {Traffic} {Generation} with {Spatial}-temporal {Agent} {Framework}},
	volume = {9},
	url = {https://doi.org/10.1145/3749542},
	doi = {10.1145/3749542},
	abstract = {The precise prediction of multi-scale traffic is a ubiquitous challenge in the urbanization process for car owners, road administrators, and governments. In the case of complex road networks, current and past traffic information from both upstream and downstream roads are crucial since various road networks have different semantic information about traffic. Rationalizing the utilization of semantic information can realize short-term, long-term, and unseen road traffic prediction. As the demands of multi-scale traffic analysis increase, on-demand interactions and visualizations are expected to be available for transportation participants. We have designed a multi-scale traffic generation system, namely DynaGraph, using a multi-agent framework to process multi-scale traffic data, conduct multi-scale traffic analysis, and present multi-scale visualization results. DynaGraph consists of three essential AI agents: 1) a text-to-demand agent with deep thinking ability to interact with users and extract prediction tasks through texts or voice; 2) a traffic prediction agent that leverages multi-scale traffic data to generate temporal features and similarity, and fuse them with limited spatial features and similarity, to achieve accurate prediction of three tasks; and 3) a suggestion and visualization agent that uses the prediction results to generate suggestions and visualizations, providing users with a comprehensive understanding of traffic conditions. Our DynaGraph as a generic system focuses on addressing concerns about traffic prediction from transportation participants, and conducted extensive experiments on five real-world road datasets to demonstrate its competitive prediction accuracy, scalability, and superior interactive performance.},
	number = {3},
	journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
	author = {Ouyang, Jinhui and Zhu, Yijie and Deng, Hanhui and He, Jialyu and Wu, Di},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {AI Agent System, Spatial-Temporal Intelligence, Transportation Traffic Forecasting},
}

@article{yu_cxxcrafter_2025,
	title = {{CXXCrafter}: {An} {LLM}-{Based} {Agent} for {Automated} {C}/{C}++ {Open} {Source} {Software} {Building}},
	volume = {2},
	url = {https://doi.org/10.1145/3729386},
	doi = {10.1145/3729386},
	abstract = {Project building is pivotal to support various program analysis tasks, such as generating intermediate representation code for static analysis and preparing binary code for vulnerability reproduction. However, automating the building process for C/C++ projects is a highly complex endeavor, involving tremendous technical challenges, such as intricate dependency management, diverse build systems, varied toolchains, and multifaceted error handling mechanisms. Consequently, building C/C++ projects often proves to be difficult in practice, hindering the progress of downstream applications. Unfortunately, research on facilitating the building of C/C++ projects remains to be inadequate. The emergence of Large Language Models (LLMs) offers promising solutions to automated software building. Trained on extensive corpora, LLMs can help unify diverse build systems through their comprehension capabilities and address complex errors by leveraging tacit knowledge storage. Moreover, LLM-based agents can be systematically designed to dynamically interact with the environment, effectively managing dynamic building issues. Motivated by these opportunities, we first conduct an empirical study to systematically analyze the current challenges in the C/C++ project building process. Particularly, we observe that most popular C/C++ projects encounter an average of five errors when relying solely on the default build systems. Based on our study, we develop an automated build system called CXXCrafter to specifically address the above-mentioned challenges, such as dependency resolution. Our evaluation on open-source software demonstrates that CXXCrafter achieves a success rate of 78\% in project building. Specifically, among the Top100 dataset, 72 projects are built successfully by both CXXCrafter and manual efforts, 3 by CXXCrafter only, and 14 manually only. Despite the slightly lower performance,CXXCrafter can save tremendous manual efforts and can also be easily applied to a wider range of applications automatically.},
	number = {FSE},
	journal = {Proc. ACM Softw. Eng.},
	author = {Yu, Zhengmin and Zhang, Yuan and Wen, Ming and Nie, Yinan and Zhang, Wenhui and Yang, Min},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Agent, Software Building},
}

@article{xia_demystifying_2025,
	title = {Demystifying {LLM}-{Based} {Software} {Engineering} {Agents}},
	volume = {2},
	url = {https://doi.org/10.1145/3715754},
	doi = {10.1145/3715754},
	abstract = {Recent advancements in large language models (LLMs) have significantly advanced the automation of software development tasks, including code synthesis, program repair, and test generation. More recently, researchers and industry practitioners have developed various autonomous LLM agents to perform end-to-end software development tasks. These agents are equipped with the ability to use tools, run commands, observe feedback from the environment, and plan for future actions. However, the complexity of these agent-based approaches, together with the limited abilities of current LLMs, raises the following question: Do we really have to employ complex autonomous software agents? To attempt to answer this question, we build Agentless – an agentless approach to automatically resolve software development issues. Compared to the verbose and complex setup of agent-based approaches, Agentless employs a simplistic three-phase process of localization, repair, and patch validation, without letting the LLM decide future actions or operate with complex tools. Our results on the popular SWE-bench Lite benchmark show that surprisingly the simplistic Agentless is able to achieve both the highest performance (32.00\%, 96 correct fixes) and low cost (\$0.70) compared with all existing open-source software agents at the time of paper submission! Agentless also achieves more than 50\% solve rate when using Claude 3.5 Sonnet on the new SWE-bench Verified benchmark. In fact, Agentless has already been adopted by OpenAI as the go-to approach to showcase the real-world coding performance of both GPT-4o and the new o1 models; more recently, Agentless has also been used by DeepSeek to evaluate their newest DeepSeek V3 and R1 models. Furthermore, we manually classified the problems in SWE-bench Lite and found problems with exact ground truth patches or insufficient/misleading issue descriptions. As such, we construct SWE-bench Lite-𝑆 by excluding such problematic issues to perform more rigorous evaluation and comparison. Our work highlights the currently overlooked potential of a simplistic, cost-effective technique in autonomous software development. We hope Agentless will help reset the baseline, starting point, and horizon for autonomous software agents, and inspire future work along this crucial direction. We have open-sourced Agentless at: https://github.com/OpenAutoCoder/Agentless},
	number = {FSE},
	journal = {Proc. ACM Softw. Eng.},
	author = {Xia, Chunqiu Steven and Deng, Yinlin and Dunn, Soren and Zhang, Lingming},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {AI Software Engineer, Automated Program Repair, Autonomous Programming, Large Language Model},
}

@article{lambiase_motivations_2024,
	title = {Motivations, {Challenges}, {Best} {Practices}, and {Benefits} for {Bots} and {Conversational} {Agents} in {Software} {Engineering}: {A} {Multivocal} {Literature} {Review}},
	volume = {57},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3704806},
	doi = {10.1145/3704806},
	abstract = {Bots are software systems designed to support users by automating specific processes, tasks, or activities. When these systems implement a conversational component to interact with users, they are also known as conversational agents or chatbots. Bots—particularly in their conversation-oriented version and AI-powered—have seen increased adoption over time for software development and engineering purposes. Despite their exciting potential, which has been further enhanced by the advent of Generative AI and Large Language Models, bots still face challenges in terms of development and integration into the development cycle, as practitioners report that bots can add difficulties rather than provide improvements. In this work, we aim to provide a taxonomy for characterizing bots, as well as a series of challenges for their adoption in software engineering, accompanied by potential mitigation strategies. To achieve our objectives, we conducted a multivocal literature review, examining both research and practitioner literature. Through such an approach, we hope to contribute to both researchers and practitioners by providing (i) a series of future research directions to pursue, (ii) a list of strategies to adopt for improving the use of bots for software engineering purposes, and (iii) fostering technology and knowledge transfer from the research field to practice—one of the primary goals of multivocal literature reviews.},
	number = {4},
	journal = {ACM Comput. Surv.},
	author = {Lambiase, Stefano and Catolino, Gemma and Palomba, Fabio and Ferrucci, Filomena},
	month = dec,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Bot, chatbot, literature review, software engineering},
}

@article{qayyum_llm-assisted_2025,
	title = {{LLM}-assisted {Bug} {Identification} and {Correction} for {Verilog} {HDL}},
	volume = {30},
	issn = {1084-4309},
	url = {https://doi.org/10.1145/3733237},
	doi = {10.1145/3733237},
	abstract = {As technology continues to advance, it becomes increasingly integrated into daily life facilitating complex tasks across a range of environments. While some applications such as smartphones and smartwatches are less critical, others like healthcare devices and autonomous vehicles demand bug-free performance to prevent financial loss or harm. Traditionally, simulation-based testing and formal verification played a major role in ensuring a bug-free device. However, the simulation of bigger systems is limited to a definite number of scenarios on the Design under Verification\&nbsp;(DUV). Hence, it is unable to explore all possible inputs that can occur. Formal verification, on the other hand, offers a higher level of assurance through mathematical proofs but is both time-consuming and suffers from scalability issues, especially as designs grow in complexity. Recently, Large Language Models\&nbsp;(LLMs) have shown promise in tasks previously limited to human expertise. Their natural language processing capabilities can assist in handling extensive specifications and source code, particularly in debugging hardware descriptions and analyzing security and functionality. The utilization of Retrieval Augmented Generation\&nbsp;(RAG) has further enhanced LLMs by incorporating large specification or source code bases, thereby improving their bug-identification and correction capabilities. While recent advancements in LLMs, particularly with RAG, have yielded promising results in bug identification and correction for a small class of hardware bugs, significant gaps remain in their full potential for systematically addressing a wide range of hardware bugs. For instance, existing LLM methodologies struggle to detect bugs involving incorrect constant values, i.e., the use of wrong constants in source code. This limitation underscores the need for further exploration in utilizing LLMs to fully optimize the verification process. To bridge this gap, we propose a 3-phased 4-stage LLM-assisted systematic bug closure methodology that focuses on functional bugs in Verilog HDL rather than structural or syntactic issues. Our approach extracts functional properties of the DUV and systematically breaks down complex expressions into smaller sub-expressions to facilitate bug detection and correction. By employing RAG, the LLM is guided using the functional specifications and source code to identify and correct bugs. If the initial guidance through RAG is insufficient, our methodology initiates an iterative bug closure process. This includes incorporating more extensive information from the specifications, fetching additional lines of code for bug localization, and breaking down complex Verilog HDL expressions. In our comprehensive evaluation, we assess the LLM’s capabilities using 9 different categories of bugs. As benchmarks, we use 5 OpenTitan Intellectual Property\&nbsp;(IP) cores to demonstrate the scalability and effectiveness of our bug closure methodology where ≈ 60\% of the bugs were corrected. Specifically, we evaluate OpenAI’s GPT-4 in its ability to identify and correct functional bugs in Verilog HDL code.},
	number = {6},
	journal = {ACM Trans. Des. Autom. Electron. Syst.},
	author = {Qayyum, Khushboo and Jha, Chandan Kumar and Ahmadi-Pour, Sallar and Hassan, Muhammad and Drechsler, Rolf},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {bug fixing, bug identification, hardware description language, Large language model},
}

@article{chen_decentralized_2024,
	title = {Decentralized natural policy gradient with variance reduction for collaborative multi-agent reinforcement learning},
	volume = {25},
	issn = {1532-4435},
	abstract = {This paper studies a policy optimization problem arising from collaborative multi-agent reinforcement learning in a decentralized setting where agents communicate with their neighbors over an undirected graph to maximize the sum of their cumulative rewards. A novel decentralized natural policy gradient method, dubbed Momentum-based Decentralized Natural Policy Gradient (MDNPG), is proposed, which incorporates natural gradient, momentum-based variance reduction, and gradient tracking into the decentralized stochastic gradient ascent framework. The O(n-1ε-3) sample complexity for MDNPG to converge to an ε-stationary point has been established under standard assumptions, where n is the number of agents. It indicates that MDNPG can achieve the optimal convergence rate for decentralized policy gradient methods and possesses a linear speedup in contrast to centralized optimization methods. Moreover, superior empirical performance of MDNPG over other state-of-the-art algorithms has been demonstrated by extensive numerical experiments.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Chen, Jinchi and Feng, Jie and Gao, Weiguo and Wei, Ke},
	month = jan,
	year = {2024},
	note = {Publisher: JMLR.org},
	keywords = {decentralized optimization, multi-agent reinforcement learning, natural policy gradient, variance reduction},
}

@article{liu_how_2024,
	title = {How {Can} {Generative} {Artificial} {Intelligence} {Techniques} {Facilitate} {Intelligent} {Research} into {Ancient} {Books}?},
	volume = {17},
	issn = {1556-4673},
	url = {https://doi.org/10.1145/3690391},
	doi = {10.1145/3690391},
	abstract = {Generative AI changes the paradigm of natural language processing research, sets off a new trend of research in computational humanities and computational social sciences, and provides unique perspectives on digital intelligence-enabled ancient book revitalization and intelligent applications. The article explores the role of multimodal large models in image processing and OCR of ancient books. We discuss and exemplify how to use Large Language Models for intelligent information processing of ancient texts and explore combining prompt engineering, retrieval augmented generation (RAG), supervised fine-tuning, LangChain, and other techniques to improve performance in ancient text mining and applications. This article also looks forward to the broad prospect of intelligent agent technology combined with the Large Language Model in the innovative application of ancient book revitalization. The research focuses on digitizing ancient books, intelligent processing of ancient texts, and intelligent application of ancient book revitalization. It demonstrates the feasibility, advancement, and creativity of the application of generative AI and its derivative technologies in the field of computational humanities, especially in the field of ancient book preservation, to provide intelligent solutions for the dissemination of traditional thought and culture, from the perspective of the whole process of the technology of digital humanities and computational humanities research. The article also gives examples of the intelligent application of AI in the restoration of ancient books and the annotation of ancient texts. Although Large Language Models demonstrate transformative potential in advancing the field of ancient text research toward intelligent analysis, there remain certain limitations. This article points out their shortcomings in areas such as knowledge completion for ancient texts, understanding emotions and cultural nuances, as well as ethical and accountability issues. It emphasizes the need for a more balanced perspective on the role that generative AI plays in the exploration and utilization of cultural heritage.},
	number = {4},
	journal = {J. Comput. Cult. Herit.},
	author = {Liu, Jiangfeng and Ma, Xueliang and Wang, Lanyu and Pei, Lei},
	month = dec,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {AIGC, Ancient Book Revitalization, ChatGPT, Computational Humanities, Generative AI, Intelligent Information Processing of Ancient Texts},
}

@article{choube_gloss_2025,
	title = {{GLOSS}: {Group} of {LLMs} for {Open}-ended {Sensemaking} of {Passive} {Sensing} {Data} for {Health} and {Wellbeing}},
	volume = {9},
	url = {https://doi.org/10.1145/3749474},
	doi = {10.1145/3749474},
	abstract = {The ubiquitous presence of smartphones and wearables has enabled researchers to build prediction and detection models for various health and behavior outcomes using passive sensing data from these devices. Achieving a high-level, holistic understanding of an individual's behavior and context, however, remains a significant challenge. Due to the nature of the passive sensing data, sensemaking — the process of interpreting and extracting insights - requires both domain knowledge and technical expertise, creating barriers for different stakeholders. Existing systems designed to support sensemaking are not open-ended or cannot perform complex data triangulation. In this paper, we present a novel sensemaking system, Group of LLMs for Open-ended Sensemaking (GLOSS), for open-ended sensemaking capable of performing complex multimodal triangulation to derive insights. We demonstrate that GLOSS significantly outperforms commonly used Retrieval-Augmented Generation (RAG) technique, achieving 87.93\% accuracy and 66.19\% consistency compared to RAG's 29.31\% accuracy and 52.85\% consistency. Furthermore, we showcase the promise of GLOSS using four use cases inspired by prior and ongoing work in UbiComp and HCI communities. Finally, we discuss the potential of GLOSS, the broader implications, and the limitations of our work.},
	number = {3},
	journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
	author = {Choube, Akshat and Le, Ha and Li, Jiachen and Ji, Kaixin and Swain, Vedant Das and Mishra, Varun},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {digital health \&amp, large language models, mobile sensing, sensemaking, wearables, wellbeing},
}

@article{hadadi_llm_2025,
	title = {{LLM} meets {ML}: {Data}-efficient {Anomaly} {Detection} on {Unstable} {Logs}},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3771283},
	doi = {10.1145/3771283},
	abstract = {Most log-based anomaly detectors assume logs are stable, though in reality they are often unstable due to software or environmental changes. Anomaly detection on unstable logs (ULAD) is therefore a more realistic, yet under-investigated challenge. Current approaches predominantly employ machine learning (ML) models, which often require extensive labeled data for training. To mitigate data insufficiency, we propose FlexLog, a novel hybrid approach for ULAD that combines ML models — decision tree, k-nearest neighbors, and a feedforward neural network — with a Large Language Model (Mistral) through ensemble learning. FlexLog also incorporates a cache and retrieval-augmented generation (RAG) to further enhance efficiency and effectiveness. To evaluate FlexLog, we configured four datasets for ULAD, namely ADFA-U, LOGEVOL-U, SynHDFS-U, and SYNEVOL-U. FlexLog outperforms all baselines by at least 1.2 percentage points (pp) in F1 score while using much less labeled data (62.87 pp reduction). When trained on the same amount of data as the baselines, FlexLog achieves up to a 13 pp increase in F1 score on ADFA-U across varying training dataset sizes. Additionally, FlexLog maintains inference time under one second per log sequence, making it suitable for most applications, except latency-sensitive systems. Further analysis reveals the positive impact of FlexLog’s key components: cache, RAG, and ensemble learning.},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Hadadi, Fatemeh and Xu, Qinghua and Bianculli, Domenico and Briand, Lionel},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {anomaly detection, data efficiency, ensemble learning, large language models, unstable logs},
	annote = {Just Accepted},
}

@article{omar_dialogue_2025,
	title = {Dialogue {Benchmark} {Generation} from {Knowledge} {Graphs} with {Cost}-{Effective} {Retrieval}-{Augmented} {LLMs}},
	volume = {3},
	url = {https://doi.org/10.1145/3709681},
	doi = {10.1145/3709681},
	abstract = {Dialogue benchmarks are crucial in training and evaluating chatbots engaging in domain-specific conversations. Knowledge graphs (KGs) represent semantically rich and well-organized data spanning various domains, such as DBLP, DBpedia, and YAGO. Traditionally, dialogue benchmarks have been manually created from documents, neglecting the potential of KGs in automating this process. Some question-answering benchmarks are automatically generated using extensive preprocessing from KGs, but they do not support dialogue generation. This paper introduces Chatty-Gen, a novel multi-stage retrieval-augmented generation platform for automatically generating high-quality dialogue benchmarks tailored to a specific domain using a KG. Chatty-Gen decomposes the generation process into manageable stages and uses assertion rules for automatic validation between stages. Our approach enables control over intermediate results to prevent time-consuming restarts due to hallucinations. It also reduces reliance on costly and more powerful commercial LLMs. Chatty-Gen eliminates upfront processing of the entire KG using efficient query-based retrieval to find representative subgraphs based on the dialogue context. Our experiments with several real and large KGs demonstrate that Chatty-Gen significantly outperforms state-of-the-art systems and ensures consistent model and system performance across multiple LLMs of diverse capabilities, such as GPT-4o, Gemini 1.5, Llama 3, and Mistral.},
	number = {1},
	journal = {Proc. ACM Manag. Data},
	author = {Omar, Reham and Mangukiya, Omij and Mansour, Essam},
	month = feb,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {assertion-based validation, benchmarking, conversational question answering, cost-effecive inference, graph serialization, knowledge graphs (kgs), large language models (llms), retrieval-augumented generation (rag)},
}

@article{wang_unique_2025,
	title = {Unique {Security} and {Privacy} {Threats} of {Large} {Language} {Models}: {A} {Comprehensive} {Survey}},
	volume = {58},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3764113},
	doi = {10.1145/3764113},
	abstract = {With the rapid development of artificial intelligence, large language models (LLMs) have made remarkable advancements in natural language processing. These models are trained on vast datasets to exhibit powerful language understanding and generation capabilities across various applications, including chatbots and agents. However, LLMs have revealed a variety of privacy and security issues throughout their life cycle, drawing significant academic and industrial attention. Moreover, the risks faced by LLMs differ significantly from those encountered by traditional language models. Given that current surveys lack a clear taxonomy of unique threat models across diverse scenarios, we emphasize the unique privacy and security threats associated with four specific scenarios: pre-training, fine-tuning, deployment, and LLM-based agents. Addressing the characteristics of each risk, this survey outlines and analyzes potential countermeasures. Research on attack and defense situations can offer feasible research directions, enabling more areas to benefit from LLMs.},
	number = {4},
	journal = {ACM Comput. Surv.},
	author = {Wang, Shang and Zhu, Tianqing and Liu, Bo and Ding, Ming and Ye, Dayong and Zhou, Wanlei and Yu, Philip},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {agent, Large language models, model robustness, security and privacy risks},
}

@article{torre_effect_2021,
	title = {The {Effect} of {Audio}-{Visual} {Smiles} on {Social} {Influence} in a {Cooperative} {Human}–{Agent} {Interaction} {Task}},
	volume = {28},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/3469232},
	doi = {10.1145/3469232},
	abstract = {Emotional expressivity is essential for human interactions, informing both perception and decision-making. Here, we examine whether creating an audio-visual emotional channel mismatch influences decision-making in a cooperative task with a virtual character. We created a virtual character that was either congruent in its emotional expression (smiling in the face and voice) or incongruent (smiling in only one channel). People (N = 98) evaluated the character in terms of valence and arousal in an online study; then, visitors in a museum played the “lunar survival task” with the character over three experiments (N = 597, 78, 101, respectively). Exploratory results suggest that multi-modal expressions are perceived, and reacted upon, differently than unimodal expressions, supporting previous theories of audio-visual integration.},
	number = {6},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	author = {Torre, Ilaria and Carrigan, Emma and Domijan, Katarina and McDonnell, Rachel and Harte, Naomi},
	month = nov,
	year = {2021},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {artificial agent, Multimodal emotional expression, smiling, social influence},
}

@article{wang_netconfeval_2024,
	title = {{NetConfEval}: {Can} {LLMs} {Facilitate} {Network} {Configuration}?},
	volume = {2},
	url = {https://doi.org/10.1145/3656296},
	doi = {10.1145/3656296},
	abstract = {This paper explores opportunities to utilize Large Language Models (LLMs) to make network configuration human-friendly, simplifying the configuration of network devices \&amp; development of routing algorithms and minimizing errors. We design a set of benchmarks (NetConfEval) to examine the effectiveness of different models in facilitating and automating network configuration. More specifically, we focus on the scenarios where LLMs translate high-level policies, requirements, and descriptions (i.e., specified in natural language) into low-level network configurations \&amp; Python code. NetConfEval considers four tasks that could potentially facilitate network configuration, such as (i) generating high-level requirements into a formal specification format, (ii) generating API/function calls from high-level requirements, (iii) developing routing algorithms based on high-level descriptions, and (iv) generating low-level configuration for existing and new protocols based on input documentation. Learning from the results of our study, we propose a set of principles to design LLM-based systems to configure networks. Finally, we present two GPT-4-based prototypes to (i) automatically configure P4-enabled devices from a set of high-level requirements and (ii) integrate LLMs into existing network synthesizers.},
	number = {CoNEXT2},
	journal = {Proc. ACM Netw.},
	author = {Wang, Changjie and Scazzariello, Mariano and Farshin, Alireza and Ferlin, Simone and Kostić, Dejan and Chiesa, Marco},
	month = jun,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {benchmark, code generation, function calling, large language models (llms), network configuration, network synthesizer, p4, rag, routing algorithms},
}

@article{balaka_pneuma_2025,
	title = {Pneuma: {Leveraging} {LLMs} for {Tabular} {Data} {Representation} and {Retrieval} in an {End}-to-{End} {System}},
	volume = {3},
	url = {https://doi.org/10.1145/3725337},
	doi = {10.1145/3725337},
	abstract = {Finding relevant tables among databases, lakes, and repositories is the first step in extracting value from data. Such a task remains difficult because assessing whether a table is relevant to a problem does not always depend only on its content but also on the context, which is usually tribal knowledge known to the individual or team. While tools like data catalogs and academic data discovery systems target this problem, they rely on keyword search or more complex interfaces, limiting non-technical users' ability to find relevant data. The advent of large language models (LLMs) offers a unique opportunity for users to ask questions directly in natural language, making dataset discovery more intuitive, accessible, and efficient.In this paper, we introduce Pneuma, a retrieval-augmented generation (RAG) system designed to efficiently and effectively discover tabular data. Pneuma leverages large language models (LLMs) for both table representation and table retrieval. For table representation, Pneuma preserves schema and row-level information to ensure comprehensive data understanding. For table retrieval, Pneuma augments LLMs with traditional information retrieval techniques, such as full-text and vector search, harnessing the strengths of both to improve retrieval performance. To evaluate Pneuma, we generate comprehensive benchmarks that simulate table discovery workload on six real-world datasets including enterprise data, scientific databases, warehousing data, and open data. Our results demonstrate that Pneuma outperforms widely used table search systems (such as full-text search and state-of-the-art RAG systems) in accuracy and resource efficiency.},
	number = {3},
	journal = {Proc. ACM Manag. Data},
	author = {Balaka, Muhammad Imam Luthfi and Alexander, David and Wang, Qiming and Gong, Yue and Krisnadhi, Adila and Castro Fernandez, Raul},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {data discovery, large language models, natural-language questions},
}

@article{chen_automatic_2025,
	title = {Automatic {Database} {Configuration} {Debugging} using {Retrieval}-{Augmented} {Language} {Models}},
	volume = {3},
	url = {https://doi.org/10.1145/3709663},
	doi = {10.1145/3709663},
	abstract = {Database management system (DBMS) configuration debugging, e.g., diagnosing poorly configured DBMS knobs and generating troubleshooting recommendations, is crucial in optimizing DBMS performance. However, the configuration debugging process is tedious and, sometimes challenging, even for seasoned database administrators (DBAs) with sufficient experience in DBMS configurations and good understandings of the DBMS internals (e.g., MySQL or Oracle). To address this difficulty, we propose Andromeda, a framework that utilizes large language models (LLMs) to enable automatic DBMS configuration debugging. Andromeda serves as a natural surrogate of DBAs to answer a wide range of natural language (NL) questions on DBMS configuration issues, and to generate diagnostic suggestions to fix these issues. Nevertheless, directly prompting LLMs with these professional questions may result in overly generic and often unsatisfying answers. To this end, we propose a retrieval-augmented generation (RAG) strategy that effectively provides matched domain-specific contexts for the question from multiple sources. They come from related historical questions, troubleshooting manuals and DBMS telemetries, which significantly improve the performance of configuration debugging. To support the RAG strategy, we develop a document retrieval mechanism addressing heterogeneous documents and design an effective method for telemetry analysis. Extensive experiments on real-world DBMS configuration debugging datasets show that Andromeda significantly outperforms existing solutions.},
	number = {1},
	journal = {Proc. ACM Manag. Data},
	author = {Chen, Sibei and Fan, Ju and Wu, Bin and Tang, Nan and Deng, Chao and Wang, Pengyi and Li, Ye and Tan, Jian and Li, Feifei and Zhou, Jingren and Du, Xiaoyong},
	month = feb,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {database configuration debugging, retrieval-augmented generation},
}

@article{zhang_llm_2025,
	title = {{LLM} {Hallucinations} in {Practical} {Code} {Generation}: {Phenomena}, {Mechanism}, and {Mitigation}},
	volume = {2},
	url = {https://doi.org/10.1145/3728894},
	doi = {10.1145/3728894},
	abstract = {Code generation aims to automatically generate code from input requirements, significantly enhancing development efficiency. Recent large language models (LLMs) based approaches have shown promising results and revolutionized code generation task. Despite the promising performance, LLMs often generate contents with hallucinations, especially for the code generation scenario requiring the handling of complex contextual dependencies in practical development process. Although previous study has analyzed hallucinations in LLM-powered code generation, the study is limited to standalone function generation. In this paper, we conduct an empirical study to study the phenomena, mechanism, and mitigation of LLM hallucinations within more practical and complex development contexts in repository-level generation scenario. First, we manually examine the code generation results from six mainstream LLMs to establish a hallucination taxonomy of LLM-generated code. Next, we elaborate on the phenomenon of hallucinations, analyze their distribution across different models. We then analyze causes of hallucinations and identify four potential factors contributing to hallucinations. Finally, we propose an RAG-based mitigation method, which demonstrates consistent effectiveness in all studied LLMs.},
	number = {ISSTA},
	journal = {Proc. ACM Softw. Eng.},
	author = {Zhang, Ziyao and Wang, Chong and Wang, Yanlin and Shi, Ensheng and Ma, Yuchi and Zhong, Wanjun and Chen, Jiachi and Mao, Mingzhi and Zheng, Zibin},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Hallucination, Large Language Models, Repository-Level Code Generation},
}

@article{li_llm_2024,
	title = {{LLM} for {Data} {Management}},
	volume = {17},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3685800.3685838},
	doi = {10.14778/3685800.3685838},
	abstract = {Machine learning techniques have been verified to be effective in optimizing data management systems and are widely researched in recent years. However, traditional small-sized ML models often struggle to generalize to new scenarios, and have limited context understanding ability (e.g., inputting discrete features only). The emergence of LLMs offers a promising solution to these challenges. LLMs have been trained over a vast number of scenarios and tasks and acquire human-competitive capabilities like context understanding and summarization, which can be highly beneficial for data management tasks (e.g., natural language based data analytics). In this tutorial, we present how to utilize LLMs to optimize data management systems and review new techniques for addressing these technical challenges, including hallucination of LLMs, high cost of interacting with LLMs, and low accuracy for processing complicated tasks. First, we discuss retrieval augmented generation (RAG) techniques to address the hallucination problem. Second, we present vector database techniques to improve the latency. Third, we present LLM agent techniques for processing complicated tasks by generating multi-round pipelines. We also showcase some real-world data management scenarios that can be well optimized by LLMs, including query rewrite, database diagnosis and data analytics. Finally, we summarize some open research challenges.},
	number = {12},
	journal = {Proc. VLDB Endow.},
	author = {Li, Guoliang and Zhou, Xuanhe and Zhao, Xinyang},
	month = aug,
	year = {2024},
	note = {Publisher: VLDB Endowment},
	pages = {4213--4216},
}

@article{chi_reaccept_2025,
	title = {{REACCEPT}: {Automated} {Co}-evolution of {Production} and {Test} {Code} {Based} on {Dynamic} {Validation} and {Large} {Language} {Models}},
	volume = {2},
	url = {https://doi.org/10.1145/3728930},
	doi = {10.1145/3728930},
	abstract = {Synchronizing production and test code, known as PT co-evolution, is critical for software quality. Given the significant manual effort involved, researchers have tried automating PT co-evolution using predefined heuristics and machine learning models. However, existing solutions are still incomplete. Most approaches only detect and flag obsolete test cases, leaving developers to manually update them. Meanwhile, existing solutions may suffer from low accuracy, especially when applied to real-world software projects. In this paper, we propose ReAccept, a novel approach leveraging large language models (LLMs), retrievalaugmented generation (RAG), and dynamic validation to fully automate PT co-evolution with high accuracy. ReAccept employs an experience-guided approach to generate prompt templates for the identification and subsequent update processes. After updating a test case, ReAccept performs dynamic validation by checking syntax, verifying semantics, and assessing test coverage. If the validation fails, ReAccept leverages the error messages to iteratively refine the patch. To evaluate ReAccept's effectiveness, we conducted extensive experiments with a dataset of 537 Java projects and compared ReAccept's performance with several stateof-the-art methods. The evaluation results show that ReAccept achieved an update accuracy of 60.16\% on the correctly identified obsolete test code, surpassing the state-of-the-art technique CEPROT by 90\%. These findings demonstrate that ReAccept can effectively maintain test code, improve overall software quality, and significantly reduce maintenance effort.},
	number = {ISSTA},
	journal = {Proc. ACM Softw. Eng.},
	author = {Chi, Jianlei and Wang, Xiaotian and Huang, Yuhan and Yu, Lechen and Cui, Di and Sun, Jianguo and Sun, Jun},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Dynamic Validation, Large Language Model, Product-Test Co-evolution, Test Generation},
}

@article{chamotra_sage_2025,
	title = {{SAGE}: {An} {Adaptive} {IoT} {Honeypot} with {FSM}-{Driven} {Protocol} {Emulation} and {GraphRAG}-{Powered} {Response} {Generation}},
	url = {https://doi.org/10.1145/3769011},
	doi = {10.1145/3769011},
	abstract = {Increasing security threats in Internet of Things (IoT) ecosystems necessitate advanced deception mechanisms that can engage adversaries and generate realistic interactions. Traditional IoT honeypots suffer from limited protocol emulation, static response mechanisms, and susceptibility to fingerprinting, making them ineffective against sophisticated attacks. To address these challenges, this paper introduces SAGE (State-Aware Graph-Enhanced Honeypot), an adaptive IoT honeypot that integrates Finite-State Machine (FSM)-driven protocol emulation with GraphRAG-enhanced retrieval. Unlike conventional honeypots, SAGE dynamically models stateful IoT protocols, ensuring structured and realistic request-response interactions. For undefined requests, GraphRAG retrieval selects relevant protocol knowledge from knowledge graphs and integrates it with FSM-derived contextual information, enabling the Large Language Model (LLM) to generate coherent and deception-resilient responses. Additionally, a fact-checking engine and feedback mechanism refine responses, mitigating hallucinations and ensuring protocol fidelity. A key feature of SAGE is its ability to create an IoT honeypot with limited protocol knowledge while progressively evolving its emulation depth by dynamically expanding its state-response mappings based on observed adversarial interactions. Experimental evaluation demonstrates that SAGE enhances deception robustness, improves adversary engagement, and mitigates honeypot fingerprinting risks. By combining FSM-based protocol modeling, GraphRAG-enhanced retrieval, and adaptive LLM-generated responses, SAGE establishes a scalable, intelligence-driven security framework that significantly advances IoT honeypot technology.},
	journal = {ACM Trans. Internet Things},
	author = {Chamotra, Saurabh and Barbhuiya, Ferdous},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Finite State Machines (FSMs), GraphRAG, Honeypots, IoT Security, Large Language Models (LLM), LLM-Powered IoT Honeypots, RAGs},
	annote = {Just Accepted},
}

@article{xu_hlsrewriter_2025,
	title = {{HLSRewriter}: {Efficient} {Refactoring} and {Optimization} of {C}/{C}++ {Code} with {LLMs} for {High}-{Level} {Synthesis}},
	issn = {1084-4309},
	url = {https://doi.org/10.1145/3749986},
	doi = {10.1145/3749986},
	abstract = {In High-Level Synthesis (HLS), refactoring a standard C/C++ code into its HLS-compatible version (HLS-C) still requires significant human effort. While various program scripts have been introduced to automate this process, the resulting code still contains many HLS-incompatible issues that need to be manually refactored and optimized by developers. Since Large Language Models (LLMs) have the ability to automate code generation, they can also be used for automated code refactoring and optimization in HLS. However, due to the limited training of LLMs, considering hardware and software simultaneously, hallucinations may occur when using LLMs for HLS, leading to synthesis failures. To address these challenges, we introduce HLSRewriter, an LLM-aided code refactoring and optimization framework that takes regular C/C++ code as input and automatically generates its corresponding optimized HLS-C code for hardware synthesis with minimal human intervention. To mitigate LLM hallucinations, a step-wise reasoning process is employed to analyze and detect HLS-incompatible errors. Afterwards, a repair library containing reference templates is efficiently created by scanning the HLS tool manual, followed by cooperation with a Retrieval-Augmented Generation (RAG) paradigm to guide the LLMs toward correct refactoring. In addition, a pipeline-aware decomposition strategy is introduced to progressively break down complex loop structures into smaller tasks with a balanced trade-off between latency and area, thereby enabling efficient pipelining and parallel execution. To further improve hardware efficiency, a bit width adjuster module is incorporated into this framework to optimize the precision of floating-point variables. Moreover, LLM-aided HLS optimization strategies are introduced to add/tune hardware directives in HLS-C code, thereby enhancing the performance of the final synthesized hardware. Experimental results demonstrate that the proposed LLM-aided framework can achieve higher refactoring pass rates and superior hardware performance in 24 real-world tasks compared with traditional approaches and the direct application of LLMs for code refactoring and optimization. The codes are open-sourced at this link: https://github.com/code-source1/catapult.},
	journal = {ACM Trans. Des. Autom. Electron. Syst.},
	author = {Xu, Kangwei and Zhang, Grace Li and Yin, Xunzhao and Zhuo, Cheng and Schlichtmann, Ulf and Li, Bing},
	month = jul,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {electronic design automation, high-level synthesis, Large language models},
	annote = {Just Accepted},
}

@article{chen_standing_2025,
	title = {Standing on the {Shoulders} of {Giants}: {Bug}-{Aware} {Automated} {GUI} {Testing} via {Retrieval} {Augmentation}},
	volume = {2},
	url = {https://doi.org/10.1145/3715755},
	doi = {10.1145/3715755},
	abstract = {In software development, similar apps often encounter similar bugs due to shared functionalities and implementation methods. However, current automated GUI testing methods mainly focus on generating test scripts to cover more pages by analyzing the internal structure of the app, without targeted exploration of paths that may trigger bugs, resulting in low efficiency in bug discovery. Considering that a large number of bug reports on open source platforms can provide external knowledge for testing, this paper proposes BugHunter, a novel bug-aware automated GUI testing approach that generates exploration paths guided by bug reports from similar apps, utilizing a combination of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG). Instead of focusing solely on coverage, BugHunter dynamically adapts the testing process to target bug paths, thereby increasing bug detection efficiency. BugHunter first builds a high-quality bug knowledge base from historical bug reports. Then it retrieves relevant reports from this large bug knowledge base using a two-stage retrieval process, and generates test paths based on similar apps’ bug reports. BugHunter also introduces a local and global path-planning mechanism to handle differences in functionality and UI design across apps, and the ambiguous behavior or missing steps in the online bug reports. We evaluate BugHunter on 121 bugs across 71 apps and compare its performance against 16 state-of-the-art baselines. BugHunter achieves 60\% improvement in bug detection over the best baseline, with comparable or higher coverage against the baselines. Furthermore, BugHunter successfully detects 49 new crash bugs in real-world apps from Google Play, with 33 bugs fixed, 9 confirmed, and 7 pending feedback.},
	number = {FSE},
	journal = {Proc. ACM Softw. Eng.},
	author = {Chen, Mengzhuo and Liu, Zhe and Chen, Chunyang and Wang, Junjie and Wu, Boyu and Hu, Jun and Wang, Qing},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {GUI testing, Large language model, Mobile App},
}

@article{rashid_monotonic_2020,
	title = {Monotonic value function factorisation for deep multi-agent reinforcement learning},
	volume = {21},
	issn = {1532-4435},
	abstract = {In many real-world settings, a team of agents must coordinate its behaviour while acting in a decentralised fashion. At the same time, it is often possible to train the agents in a centralised fashion where global state information is available and communication constraints are lifted. Learning joint action-values conditioned on extra state information is an attractive way to exploit centralised learning, but the best strategy for then extracting decentralised policies is unclear. Our solution is QMIX, a novel value-based method that can train decentralised policies in a centralised end-to-end fashion. QMIX employs a mixing network that estimates joint action-values as a monotonic combination of per-agent values. We structurally enforce that the joint-action value is monotonic in the per-agent values, through the use of non-negative weights in the mixing network, which guarantees consistency between the centralised and decentralised policies. To evaluate the performance of QMIX, we propose the StarCraft Multi-Agent Challenge (SMAC) as a new benchmark for deep multi-agent reinforcement learning. We evaluate QMIX on a challenging set of SMAC scenarios and show that it significantly outperforms existing multi-agent reinforcement learning methods.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
	month = jan,
	year = {2020},
	note = {Publisher: JMLR.org},
	keywords = {multi-agent coordination, multi-agent learning, reinforcement learning},
}

@article{xie_opensearch-sql_2025,
	title = {{OpenSearch}-{SQL}: {Enhancing} {Text}-to-{SQL} with {Dynamic} {Few}-shot and {Consistency} {Alignment}},
	volume = {3},
	url = {https://doi.org/10.1145/3725331},
	doi = {10.1145/3725331},
	abstract = {Although multi-agent collaborative Large Language Models (LLMs) have achieved significant breakthroughs in the Text-to-SQL task, their performance is still constrained by various factors. These factors include the incompleteness of the framework, failure to follow instructions, and model hallucinations. To address these problems, we propose OpenSearch-SQL, which divides the Text-to-SQL task into four main modules: Preprocessing, Extraction, Generation, and Refinement, along with an Alignment module based on a consistency alignment mechanism. This architecture aligns the inputs and outputs of agents through the Alignment module, reducing failures in instruction following and hallucination. Furthermore, we introduce SQL-Like (an intermediate language), optimize the structured Chain-of-Thought (CoT) based on SQL-Like, and develop a dynamic few-shot strategy via self-taught Query-CoT-SQL. In terms of model selection, we directly applied the base LLMs without any post-training, thereby simplifying the task chain and enhancing the framework's portability. Experimental results show that OpenSearch-SQL achieves an execution accuracy(EX) of 69.3\% on the BIRD development set, 72.28\% on the test set, and a reward-based validity efficiency score (R-VES) of 69.36\%, with all three metrics ranking first at the time of submission. These results demonstrate the comprehensive advantages of the proposed method in both effectiveness and efficiency.},
	number = {3},
	journal = {Proc. ACM Manag. Data},
	author = {Xie, Xiangjin and Xu, Guangwei and Zhao, Lingyan and Guo, Ruijie},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {multi-agent, retrieval, text-to-sql},
}

@article{tan_prompt-based_2025,
	title = {Prompt-based {Code} {Completion} via {Multi}-{Retrieval} {Augmented} {Generation}},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3725812},
	doi = {10.1145/3725812},
	abstract = {Automated code completion, aiming at generating subsequent tokens from unfinished code, has significantly benefited from recent progress in pre-trained Large Language Models (LLMs). However, these models often suffer from coherence issues and hallucinations when dealing with complex code logic or extrapolating beyond their training data. Existing Retrieval Augmented Generation (RAG) techniques partially address these issues by retrieving relevant code with a separate encoding model where the retrieved snippet serves as contextual reference for code completion. However, their retrieval scope is subject to a singular perspective defined by the encoding model, which largely overlooks the complexity and diversity inherent in code semantics. To address this limitation, we propose ProCC, a code completion framework leveraging prompt engineering and the contextual multi-armed bandits algorithm to flexibly incorporate and adapt to multiple perspectives of code. ProCC first employs a prompt-based multi-retriever system which crafts prompt templates to elicit LLM knowledge to understand code semantics with multiple retrieval perspectives. Then, it adopts the adaptive retrieval selection algorithm to incorporate code similarity into the decision-making process to determine the most suitable retrieval perspective for the LLM to complete the code. Experimental results demonstrate that ProCC outperforms a widely-studied code completion technique RepoCoder by 7.92\% on the public benchmark CCEval, 3.19\% in HumanEval-Infilling, 2.80\% on our collected open-source benchmark suite, and 4.48\% on the private-domain benchmark suite collected from Kuaishou Technology in terms of Exact Match. ProCC also allows augmenting fine-tuned techniques in a plug-and-play manner, yielding an averaged 6.5\% improvement over the fine-tuned model.},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Tan, Hanzhuo and Luo, Qi and Jiang, Ling and Zhan, Zizheng and Li, Jing and Zhang, Haotian and Zhang, Yuqun},
	month = mar,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Code Completion, Multi-Retriever, Prompting},
	annote = {Just Accepted},
}

@article{ma_swe-gpt_2025,
	title = {{SWE}-{GPT}: {A} {Process}-{Centric} {Language} {Model} for {Automated} {Software} {Improvement}},
	volume = {2},
	url = {https://doi.org/10.1145/3728981},
	doi = {10.1145/3728981},
	abstract = {Large language models (LLMs) have demonstrated remarkable performance in code generation, significantly enhancing the coding efficiency of developers. Recent advancements in LLM-based agents have led to significant progress in end-to-end automatic software engineering (ASE), particularly in software maintenance (e.g., fixing software issues) and evolution (e.g., adding new features). Despite these encouraging advances, current research faces two major challenges. First, state-of-the-art performance primarily depends on closed-source models like GPT-4, which significantly limits the technology’s accessibility, and potential for customization in diverse software engineering tasks. This dependence also raises concerns about data privacy, particularly when handling sensitive codebases. Second, these models are predominantly trained on static code data, lacking a deep understanding of the dynamic interactions, iterative problem-solving processes, and evolutionary characteristics inherent in software development. Consequently, they may face challenges in navigating complex project structures and generating contextually relevant solutions, which can affect their practical utility in real-world scenarios. To address these challenges, our study adopts a software engineering perspective. We recognize that real-world software maintenance and evolution processes encompass not only static code data but also developers’ thought processes, utilization of external tools, and the interaction between different functional personnel. Our objective is to develop an open-source large language model specifically optimized for software improvement, aiming to match the performance of closed-source alternatives while offering greater accessibility and customization potential. Consequently, we introduce the Lingma SWE-GPT series, comprising Lingma SWE-GPT 7B and Lingma SWE-GPT 72B. By learning from and simulating real-world code submission activities, Lingma SWE-GPT systematically incorporates the dynamic interactions and iterative problem-solving inherent in software development process—such as repository understanding, fault localization, and patch generation—thereby achieving a more comprehensive understanding of software improvement processes. We conducted experimental evaluations using SWE-bench-Verified benchmark (comprising 500 real GitHub issues), recently proposed by OpenAI. The results demonstrate that Lingma SWE-GPT 72B successfully resolves 30.20\% of the GitHub issues, marking a significant improvement in automatic issue resolution (22.76\% relative improvement compared to Llama 3.1 405B), approaching the performance of closed-source models (31.80\% issues of GPT-4o resolved). Notably, Lingma SWE-GPT 7B resolves 18.20\% of the issues, surpassing the 17.20\% resolution rate of Llama 3.1 70B, highlighting the potential for applying smaller models to ASE tasks.},
	number = {ISSTA},
	journal = {Proc. ACM Softw. Eng.},
	author = {Ma, Yingwei and Cao, Rongyu and Cao, Yongchang and Zhang, Yue and Chen, Jue and Liu, Yibo and Liu, Yuchen and Li, Binhua and Huang, Fei and Li, Yongbin},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Automated Program Repair, Automatic Software Engineering (ASE), Fault Localization, Large Language Models (LLMs), Software Engineering Agents},
}

@article{he_large_2025,
	title = {Large {Language} {Models} for {EDA}: {Future} or {Mirage}?},
	volume = {30},
	issn = {1084-4309},
	url = {https://doi.org/10.1145/3736167},
	doi = {10.1145/3736167},
	abstract = {In this article, we explore the burgeoning intersection of large language models (LLMs) and electronic design automation (EDA). We critically assess whether LLMs represent a transformative future for EDA or merely a fleeting mirage. By organizing existing research into four critical domains of EDA—code generation, verification and debugging, knowledge representation and retrieval, and optimization/modeling—we provide a comprehensive overview of the current state-of-the-art. The survey concludes with a 5-level roadmap to guide the progressive integration and advancement of LLMs in EDA. Ultimately, this article aims to provide a comprehensive, evidence-based perspective on the role of LLMs in shaping the future of EDA.},
	number = {6},
	journal = {ACM Trans. Des. Autom. Electron. Syst.},
	author = {He, Zhuolun and Pu, Yuan and Wu, Haoyuan and Qiu, Tairu and Yu, Bei},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Large Language Model},
}

@article{zhou_malib_2023,
	title = {{MALib}: a parallel framework for population-based multi-agent reinforcement learning},
	volume = {24},
	issn = {1532-4435},
	abstract = {Population-based multi-agent reinforcement learning (PB-MARL) encompasses a range of methods that merge dynamic population selection with multi-agent reinforcement learning algorithms (MARL). While PB-MARL has demonstrated notable achievements in complex multi-agent tasks, its sequential execution is plagued by low computational efficiency due to the diversity in computing patterns and policy combinations. We propose a solution involving a stateless central task dispatcher and stateful workers to handle PB-MARL's subroutines, thereby capitalizing on parallelism across various components for efficient problem-solving. In line with this approach, we introduce MALib, a parallel framework that incorporates a task control model, independent data servers, and an abstraction of MARL training paradigms. The framework has undergone extensive testing and is available under the MIT license (https://github.com/sjtu-marl/malib).},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Zhou, Ming and Wan, Ziyu and Wang, Hanjing and Wen, Muning and Wu, Runzhe and Wen, Ying and Yang, Yaodong and Yu, Yong and Wang, Jun and Zhang, Weinan},
	month = jan,
	year = {2023},
	note = {Publisher: JMLR.org},
	keywords = {multi-agent learning, open-source, Python, ray, software},
}

@article{grunde-mclaughlin_designing_2025,
	title = {Designing {LLM} {Chains} by {Adapting} {Techniques} from {Crowdsourcing} {Workflows}},
	volume = {32},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/3716134},
	doi = {10.1145/3716134},
	abstract = {LLM chains enable complex tasks by decomposing work into a sequence of subtasks. Similarly, the more established techniques of crowdsourcing workflows decompose complex tasks into smaller tasks for human crowdworkers. Chains address LLM errors analogously to the way crowdsourcing workflows address human error. To characterize opportunities for LLM chaining, we survey 107 papers across the crowdsourcing and chaining literature to construct a design space for chain development. The design space covers a designer’s objectives and the tactics used to build workflows. We then surface strategies that mediate how workflows use tactics to achieve objectives. To explore how techniques from crowdsourcing may apply to chaining, we adapt crowdsourcing workflows to implement LLM chains across three case studies: creating a taxonomy, shortening text, and writing a short story. From the design space and our case studies, we identify takeaways for effective chain design and raise implications for future research and development.},
	number = {3},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	author = {Grunde-McLaughlin, Madeleine and Lam, Michelle S. and Krishna, Ranjay and Weld, Daniel S. and Heer, Jeffrey},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {case studies, Crowdsourcing workflows, design space, large language model chains},
}

@article{lan_warpdrive_2022,
	title = {{WarpDrive}: fast end-to-end deep multi-agent reinforcement learning on a {GPU}},
	volume = {23},
	issn = {1532-4435},
	abstract = {WarpDrive is a flexible, lightweight, and easy-to-use open-source framework for end-to-end deep multi-agent reinforcement learning (MARL) on a Graphics Processing Unit (GPU), available at https://github.com/salesforce/warp-drive. It addresses key system bottlenecks when applying MARL to complex environments with high-dimensional state, observation, or action spaces. For example, WarpDrive eliminates data copying between the CPU and GPU and runs thousands of simulations and agents in parallel. It also enables distributed training on multiple GPUs and scales to millions of agents. In all, WarpDrive enables orders-of-magnitude faster MARL compared to common CPU-GPU implementations. For example, WarpDrive yields 2.9 million environment steps/second with 2000 environments and 1000 agents (at least 100× faster than a CPU version) in a 2d-Tag simulation. It is user-friendly: e.g., it provides a lightweight, extendable Python interface and flexible environment wrappers. It is also compatible with PyTorch. In all, WarpDrive offers a platform to significantly accelerate reinforcement learning research and development.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Lan, Tian and Srinivasa, Sunil and Wang, Huan and Zheng, Stephan},
	month = jan,
	year = {2022},
	note = {Publisher: JMLR.org},
	keywords = {deep reinforcement learning, GPU acceleration, multi-agent systems},
}

@article{li_autosilicon_2025,
	title = {{AutoSilicon}: {Scaling} {Up} {RTL} {Design} {Generation} {Capability} of {Large} {Language} {Models}},
	volume = {30},
	issn = {1084-4309},
	url = {https://doi.org/10.1145/3737286},
	doi = {10.1145/3737286},
	abstract = {Hardware description language (HDL) code designing is a critical component of the chip design process, requiring substantial engineering and time resources. Recent advancements in large language models (LLMs), such as GPT series, have shown promise in automating HDL code generation. However, current LLM-based approaches face significant challenges in meeting real-world hardware design requirements, particularly in handling complex designs and ensuring code correctness. Our evaluations reveal that the functional correctness rate of LLM-generated HDL code significantly decreases as design complexity increases. In this article, we propose the AutoSilicon framework, which aims to scale up the hardware design capability of LLMs. AutoSilicon incorporates an agent system, which (1) allows for the decomposition of large-scale, complex code design tasks into smaller, simpler tasks; (2) provides a compilation and simulation environment that enables LLMs to compile and test each piece of code it generates; and (3) introduces a series of optimization strategies. Experimental results demonstrate that AutoSilicon can scale hardware designs to projects with code equivalent to over 10,000 tokens. In terms of design quality, it further improves the syntax correctness rate and functional correctness rate compared with approaches that do not employ any extensions. For example, compared to directly generating HDL code using GPT-4-turbo, AutoSilicon enhances the syntax correctness rate by an average of 35.8\% and improves functional correctness by an average of 35.6\%.},
	number = {6},
	journal = {ACM Trans. Des. Autom. Electron. Syst.},
	author = {Li, Cangyuan and Chen, Chujie and Pan, Yudong and Xu, Wenjun and Liu, Yiqi and Chang, Kaiyan and Wang, Yujie and Wang, Mengdi and Li, Huawei and Han, Yinhe and Wang, Ying},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {agent, LLM, verilog, Verilog code generation},
}

@article{li_f2a2_2023,
	title = {{F2A2}: flexible fully-decentralized approximate actor-critic for cooperative multi-agent reinforcement learning},
	volume = {24},
	issn = {1532-4435},
	abstract = {Traditional centralized multi-agent reinforcement learning (MARL) algorithms are sometimes unpractical in complicated applications due to non-interactivity between agents, the curse of dimensionality, and computation complexity. Hence, several decentralized MARL algorithms are motivated. However, existing decentralized methods only handle the fully cooperative setting where massive information needs to be transmitted in training. The block coordinate gradient descent scheme they used for successive independent actor and critic steps can simplify the calculation, but it causes serious bias. This paper proposes a exible fully decentralized actor-critic MARL framework, which can combine most of the actor-critic methods and handle large-scale general cooperative multi-agent settings. A primal-dual hybrid gradient descent type algorithm framework is designed to learn individual agents separately for decentralization. From the perspective of each agent, policy improvement and value evaluation are jointly optimized, which can stabilize multi-agent policy learning. Furthermore, the proposed framework can achieve scalability and stability for the large-scale environment. This framework also reduces information transmission by the parameter sharing mechanism and novel modeling-other-agents methods based on theory-of-mind and online supervised learning. Sufficient experiments in cooperative Multi-agent Particle Environment and StarCraft II show that the proposed decentralized MARL instantiation algorithms perform competitively against conventional centralized and decentralized methods.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Li, Wenhao and Jin, Bo and Wang, Xiangfeng and Yan, Junchi and Zha, Hongyuan},
	month = jan,
	year = {2023},
	note = {Publisher: JMLR.org},
	keywords = {actor-critic, cooperative MARL, decentralized, primal-dual method},
}

@article{zhu_large_2025,
	title = {Large {Language} {Models} for {Information} {Retrieval}: {A} {Survey}},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/3748304},
	doi = {10.1145/3748304},
	abstract = {As a primary means of information acquisition, information retrieval (IR) systems, such as search engines, have integrated themselves into our daily lives. These systems also serve as components of dialogue, question-answering, and recommender systems. The trajectory of IR has evolved dynamically from its origins in term-based methods to its integration with advanced neural models. While the neural models excel at capturing complex contextual signals and semantic nuances, they still face challenges such as data scarcity, interpretability, and the generation of contextually plausible yet potentially inaccurate responses. This evolution requires a combination of traditional methods (such as term-based sparse retrieval methods with rapid response) and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile, the emergence of large language models (LLMs) has revolutionized natural language processing due to their remarkable language understanding, generation, and reasoning abilities. Consequently, recent research has sought to leverage LLMs to improve IR systems. Given the rapid evolution of this research trajectory, it is necessary to consolidate existing methodologies and provide nuanced insights through a comprehensive overview. In this survey, we delve into the confluence of LLMs and IR systems, including crucial aspects such as query rewriters, retrievers, rerankers, readers, and search agents.},
	journal = {ACM Trans. Inf. Syst.},
	author = {Zhu, Yutao and Yuan, Huaying and Wang, Shuting and Liu, Jiongnan and Liu, Wenhan and Deng, Chenlong and Chen, Haonan and Liu, Zheng and Dou, Zhicheng and Wen, Ji-Rong},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Fine-tuning, Information Retrieval, Large Language Models, Prompting, Query Rewriter, Reader, Reranking},
	annote = {Just Accepted},
}

@article{hoey_social_2025,
	title = {Social organization as the collective management of uncertainty},
	volume = {4},
	url = {https://doi.org/10.1177/26339137251324131},
	doi = {10.1177/26339137251324131},
	abstract = {This paper explores the notion of complementarity in the modeling of social systems. Complementary variables in physics exhibit a duality, and similar dualities are found in the analysis of social, political, cultural, and neurophysiological structures. In this paper, I show that the management of uncertainty in a hierarchical model exhibits certain dualities that closely parallel those observed in social systems. I argue that, due to the necessity of coordination within collectives, agents will mirror each other to a large extent, and will develop heuristics and tactics that are aligned with how each agent is managing uncertainty dualities. I connect sociological literature on social structures with neuroscientific, economic, and psychological developments, and show a simplified derivation of these connections from free energy principles. I then explore how these connections can be used to gain insights into observable socio-cultural processes.},
	number = {1},
	journal = {Collective Intelligence},
	author = {Hoey, Jesse},
	month = mar,
	year = {2025},
	note = {Place: USA
Publisher: Sage Publications, Inc.},
	keywords = {Bayesian learning, Complementarity, cultural structure, duality, free energy},
}

@article{su_automated_2025,
	title = {Automated {Soap} {Opera} {Testing} {Directed} by {LLMs} and {Scenario} {Knowledge}: {Feasibility}, {Challenges}, and {Road} {Ahead}},
	volume = {2},
	url = {https://doi.org/10.1145/3715752},
	doi = {10.1145/3715752},
	abstract = {Exploratory testing (ET) harnesses tester's knowledge, creativity, and experience to create varying tests that uncover unexpected bugs from the end-user's perspective. Although ET has proven effective in system-level testing of interactive systems, the need for manual execution has hindered large-scale adoption. In this work, we explore the feasibility, challenges and road ahead of automated scenario-based ET (a.k.a soap opera testing). We conduct a formative study, identifying key insights for effective manual soap opera testing and challenges in automating the process. We then develop a multi-agent system leveraging LLMs and a Scenario Knowledge Graph (SKG) to automate soap opera testing. The system consists of three multi-modal agents, Planner, Player, and Detector that collaborate to execute tests and identify potential bugs. Experimental results demonstrate the potential of automated soap opera testing, but there remains a significant gap compared to manual execution, especially under-explored scenario boundaries and incorrectly identified bugs. Based on the observation, we envision road ahead for the future of automated soap opera testing, focusing on three key aspects: the synergy of neural and symbolic approaches, human-AI co-learning, and the integration of soap opera testing with broader software engineering practices. These insights aim to guide and inspire the future research.},
	number = {FSE},
	journal = {Proc. ACM Softw. Eng.},
	author = {Su, Yanqi and Xing, Zhenchang and Wang, Chong and Chen, Chunyang and Xu, Sherry (Xiwei) and Lu, Qinghua and Zhu, Liming},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Knowledge Graph, Large Language Models, Soap Opera Testing},
}

@article{yuan_improving_2025,
	title = {Improving {Workplace} {Well}-being in {Modern} {Organizations}: {A} {Review} of {Large} {Language} {Model}-based {Mental} {Health} {Chatbots}},
	volume = {16},
	issn = {2158-656X},
	url = {https://doi.org/10.1145/3701041},
	doi = {10.1145/3701041},
	abstract = {The global rise in mental disorders, particularly in workplaces, necessitated innovative and scalable solutions for delivering therapy. Large Language Model (LLM)-based mental health chatbots have rapidly emerged as a promising tool for overcoming the time, cost, and accessibility constraints often associated with traditional mental health therapy. However, LLM-based mental health chatbots are in their nascency, with significant opportunities to enhance their capabilities to operate within organizational contexts. To this end, this research seeks to examine the role and development of LLMs in mental health chatbots over the past half-decade. Through our review, we identified over 50 mental health-related chatbots, including 22 LLM-based models targeting general mental health, depression, anxiety, stress, and suicide ideation. These chatbots are primarily used for emotional support and guidance but often lack capabilities specifically designed for workplace mental health, where such issues are increasingly prevalent. The review covers their development, applications, evaluation, ethical concerns, integration with traditional services, LLM-as-a-Service, and various other business implications in organizational settings. We provide a research illustration of how LLM-based approaches could overcome the identified limitations and also offer a system that could help facilitate systematic evaluation of LLM-based mental health chatbots. We offer suggestions for future research tailored to workplace mental health needs.},
	number = {1},
	journal = {ACM Trans. Manage. Inf. Syst.},
	author = {Yuan, Aijia and Garcia Colato, Edlin and Pescosolido, Bernice and Song, Hyunju and Samtani, Sagar},
	month = feb,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {chatbots, conversational agents, Large language models, mental health, well-being, workplace},
}

@article{xue_demonstration_2024,
	title = {Demonstration of {DB}-{GPT}: {Next} {Generation} {Data} {Interaction} {System} {Empowered} by {Large} {Language} {Models}},
	volume = {17},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3685800.3685876},
	doi = {10.14778/3685800.3685876},
	abstract = {The recent breakthroughs in large language models (LLMs) are positioned to transition many areas of software. In this paper, we present DB-GPT, a revolutionary and product-ready Python library that integrates LLMs into traditional data interaction tasks to enhance user experience and accessibility. DB-GPT is designed to understand data interaction tasks described by natural language and provide context-aware responses powered by LLMs, making it an indispensable tool for users ranging from novice to expert. Its system design supports deployment across local, distributed, and cloud environments. Beyond handling basic data interaction tasks like Text-to-SQL with LLMs, it can handle complex tasks like generative data analysis through a Multi-Agents framework and the Agentic Workflow Expression Language (AWEL). The Service-oriented Multi-model Management Framework (SMMF) ensures data privacy and security, enabling users to employ DB-GPT with private LLMs. Additionally, DB-GPT offers a series of product-ready features designed to enable users to integrate DB-GPT within their product environments easily. The code of DB-GPT is available at Github.},
	number = {12},
	journal = {Proc. VLDB Endow.},
	author = {Xue, Siqiao and Qi, Danrui and Jiang, Caigao and Cheng, Fangyin and Chen, Keting and Zhang, Zhiping and Zhang, Hongyang and Wei, Ganglin and Zhao, Wang and Zhou, Fan and Yi, Hong and Liu, Shaodong and Yang, Hongjun and Chen, Faqiang},
	month = aug,
	year = {2024},
	note = {Publisher: VLDB Endowment},
	pages = {4365--4368},
}

@article{yao_hdldebugger_2025,
	title = {{HDLdebugger}: {Streamlining} {HDL} debugging with {Large} {Language} {Models}},
	volume = {30},
	issn = {1084-4309},
	url = {https://doi.org/10.1145/3735638},
	doi = {10.1145/3735638},
	abstract = {In the domain of chip design, hardware description languages (HDLs) play a pivotal role. However, due to the inherent complexity of HDLs and the scarcity of high-quality debugging resources, HDL bug fixing remains a challenging and time-consuming task, even for seasoned engineers. Consequently, there is a pressing need to develop automated HDL code debugging models, which can alleviate the burden on hardware engineers. Despite the strong capabilities of large language models (LLMs) in generating, completing, and debugging software code, their utilization in the specialized field of HDL debugging has been limited and, to date, has not yielded satisfactory results. In this paper, we propose an LLM-assisted HDL debugging framework, namely HDLdebugger, which consists of HDL debugging data generation via a reverse engineering approach, a search engine for retrieval-augmented generation, and a retrieval-augmented LLM fine-tuning approach. Through the integration of these components, HDLdebugger can automate and streamline HDL debugging for chip design. Our comprehensive experiments, conducted on an HDL code dataset sourced from Industry, reveal that HDLdebugger outperforms 13 cutting-edge LLM baselines, displaying exceptional effectiveness in HDL code debugging.},
	number = {6},
	journal = {ACM Trans. Des. Autom. Electron. Syst.},
	author = {Yao, Xufeng and Li, Haoyang and Chan, Tsz Ho and Xiao, Wenyi and Yuan, Mingxuan and Huang, Yu and Chen, Lei and Yu, Bei},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Code Debugging, Large Language Model, Retrieval Augmented Generation},
}

@article{xu_large_2025-1,
	title = {Large {Language} {Models} for {Cyber} {Security}: {A} {Systematic} {Literature} {Review}},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3769676},
	doi = {10.1145/3769676},
	abstract = {The rapid advancement of Large Language Models (LLMs) has opened up new opportunities for leveraging artificial intelligence in a variety of application domains, including cybersecurity. As the volume and sophistication of cyber threats continue to grow, there is an increasing need for intelligent systems that can automatically detect vulnerabilities, analyze malware, and respond to attacks. In this survey, we conduct a comprehensive review of the literature on the application of LLMs in cybersecurity\&nbsp;(LLM4Security). By comprehensively collecting over 40K relevant papers and systematically analyzing 185 papers from top security and software engineering venues, we aim to provide a holistic view of how LLMs are being used to solve diverse problems across the cybersecurity domain.Through our analysis, we identify several key findings. First, we observe that LLMs are being applied to an expanding range of cybersecurity tasks, including vulnerability detection, malware analysis, and network intrusion detection. Second, we analyze application trends of different LLM architectures (such as encoder-only, encoder-decoder, and decoder-only) across security domains. Third, we identify increasingly sophisticated techniques for adapting LLMs to cybersecurity, such as advanced fine-tuning, prompt engineering, and external augmentation strategies. A significant emerging trend is the use of LLM-based autonomous agents, which represent a paradigm shift from single-task execution to orchestrating complex, multi-step security workflows. Furthermore, we find that the datasets used for training and evaluating LLMs are often limited, highlighting the need for more comprehensive datasets and the use of LLMs for data augmentation. Finally, we discuss the main challenges and opportunities for future research, including the need for more interpretable models, addressing the inherent security risks of LLMs, and their potential for proactive defense.Overall, our survey provides a comprehensive overview of the current state-of-the-art in LLM4Security and identifies several promising directions for future research. We believe that the insights and findings presented in this survey will contribute to the growing body of knowledge on the application of LLMs in cybersecurity and provide valuable guidance for researchers and practitioners working in this field.},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Xu, Hanxiang and Wang, Shenao and Li, Ningke and Wang, Kailong and Zhao, Yanjie and Chen, Kai and Yu, Ting and Liu, Yang and Wang, Haoyu},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Cybersecurity, Large language model, Software security},
	annote = {Just Accepted},
}

@article{sun_script-strategy_2025,
	title = {Script-{Strategy} {Aligned} {Generation}: {Aligning} {LLMs} with {Expert}-{Crafted} {Dialogue} {Scripts} and {Therapeutic} {Strategies} for {Psychotherapy}},
	volume = {9},
	url = {https://doi.org/10.1145/3757655},
	doi = {10.1145/3757655},
	abstract = {Chatbots or conversational agents (CAs) are increasingly used to improve access to digital psychotherapy. Many current systems rely on rigid, rule-based designs, heavily dependent on expert-crafted dialogue scripts for guiding therapeutic conversations. Although advances in large language models (LLMs) offer potential for more flexible interactions, their lack of controllability and explanability poses challenges in high-stakes contexts like psychotherapy. To address this, we conducted two studies in this work to explore how aligning LLMs with expert-crafted scripts can enhance psychotherapeutic chatbot performance. In Study 1 (N=43), an online experiment with a within-subjects design, we compared rule-based, pure LLM, and LLMs aligned with expert-crafted scripts via fine-tuning and prompting. Results showed that aligned LLMs significantly outperformed the other types of chatbots in empathy, dialogue relevance, and adherence to therapeutic principles. Building on findings, we proposed ”Script-Strategy Aligned Generation (SSAG)”, a more flexible alignment approach that reduces reliance on fully scripted content while maintaining LLMs' therapeutic adherence and controllability. In a 10-day field Study 2 (N=21), SSAG achieved comparable therapeutic effectiveness to full-scripted LLMs while requiring less than 40\% of expert-crafted dialogue content. Beyond these results, this work advances LLM applications in psychotherapy by providing a controllable and scalable solution, reducing reliance on expert effort. By enabling domain experts to align LLMs through high-level strategies rather than full scripts, SSAG supports more efficient co-development and expands access to a broader context of psychotherapy.},
	number = {7},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Sun, Xin and de Wit, Jan and Li, Zhuying and Pei, Jiahuan and El Ali, Abdallah and Bosch, Jos A.},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {alignment, chatbot-delivered psychotherapy, large language model},
}

@article{yang_autoverus_2025,
	title = {{AutoVerus}: {Automated} {Proof} {Generation} for {Rust} {Code}},
	volume = {9},
	url = {https://doi.org/10.1145/3763174},
	doi = {10.1145/3763174},
	abstract = {Generative AI has shown its value for many software engineering tasks. Still in its infancy, large language model (LLM)-based proof generation lags behind LLM-based code generation. In this paper, we present AutoVerus. AutoVerus uses LLMs to automatically generate correctness proof for Rust code. AutoVerus is designed to match the unique features of Verus, a verification tool that can prove the correctness of Rust code using proofs and specifications also written in Rust. AutoVerus consists of a network of agents that are crafted and orchestrated to mimic human experts' three phases of proof construction: preliminary proof generation, proof refinement guided by generic tips, and proof debugging guided by verification errors. To thoroughly evaluate AutoVerus and help foster future research in this direction, we have built a benchmark suite of 150 non-trivial proof tasks, based on existing code-generation benchmarks and verification benchmarks. Our evaluation shows that AutoVerus can automatically generate correct proof for more than 90\% of them, with more than half of them tackled in less than 30 seconds or 3 LLM calls.},
	number = {OOPSLA2},
	journal = {Proc. ACM Program. Lang.},
	author = {Yang, Chenyuan and Li, Xuheng and Misu, Md Rakib Hossain and Yao, Jianan and Cui, Weidong and Gong, Yeyun and Hawblitzel, Chris and Lahiri, Shuvendu and Lorch, Jacob R. and Lu, Shuai and Yang, Fan and Zhou, Ziqiao and Lu, Shan},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Large Language Models, Program Synthesis, Program Verification, Verus},
}

@article{wang_survey_2025,
	title = {Survey on {Factuality} in {Large} {Language} {Models}},
	volume = {58},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3742420},
	doi = {10.1145/3742420},
	abstract = {This survey addresses the crucial issue of factuality in Large Language Models (LLMs). As LLMs find applications across diverse domains, the reliability and accuracy of their outputs become vital. We define the “factuality issue” as the probability of LLMs to produce content inconsistent with established facts. We first delve into the implications of these inaccuracies. Subsequently, we analyze the mechanisms through which LLMs store and process facts, seeking the primary causes of factual errors. Our discussion then transitions to methodologies for evaluating LLM factuality, emphasizing key metrics, benchmarks, and studies. We further explore strategies for enhancing LLM factuality. Our survey offers a structured guide for researchers aiming to fortify the factual reliability of LLMs. We consistently maintain and update the related open-source materials at .},
	number = {1},
	journal = {ACM Comput. Surv.},
	author = {Wang, Cunxiang and Liu, Xiaoze and Yue, Yuanhao and Guo, Qipeng and Hu, Xiangkun and Tang, Xiangru and Zhang, Tianhang and Jiayang, Cheng and Yao, Yunzhi and Hu, Xuming and Qi, Zehan and Gao, Wenyang and Wang, Yidong and Yang, Linyi and Wang, Jindong and Xie, Xing and Zhang, Zheng and Zhang, Yue},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Factuality, knowledge, large language models, retrieval augmentation},
}

@article{dick_introduction_2025,
	title = {Introduction to {Special} {Issue} on {Large} {Language} {Models} for {Electronic} {System} {Design} {Automation}},
	volume = {30},
	issn = {1084-4309},
	url = {https://doi.org/10.1145/3746636},
	doi = {10.1145/3746636},
	abstract = {Large Language Models are having a substantial impact on electronic design automation in areas ranging from hardware architecture to verification and optimization. The special issue provides a snapshot of work on this topic. This introduction describes and provides context for the research area, describes the organization of the special issue, and provides terse summaries of each of its papers.},
	number = {6},
	journal = {ACM Trans. Des. Autom. Electron. Syst.},
	author = {Dick, Robert Paul and Pearce, Hammond and Shang, Li and Yang, Fan},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {artificial intelligence, Design automation, hardware, large language models, machine learning, software},
}

@article{pernici_sustainable_2025,
	title = {Sustainable quality in data preparation},
	issn = {1936-1955},
	url = {https://doi.org/10.1145/3769120},
	doi = {10.1145/3769120},
	abstract = {Data preparation is crucial for achieving good data management following the four foundational FAIR principles — Findability, Accessibility, Interoperability, and Reusability. Processing datasets to achieve high data (and metadata) quality is mandatory in modern applications. However, the data preparation activities that are needed to reach such levels may easily become unsustainable due to, for example, resource intensity or scalability challenges. Moreover, some preparation efforts may become unnecessary if they result in negligible improvements or duplicate actions. This paper examines the sustainability aspects of data preparation through the lens of a circular economy. Within the data landscape, this perspective encourages practices that minimize waste, extend the data life cycle, and maximize reuse in alignment with the FAIR principles. We explore these practices and their impact on selecting and configuring effective data preparation strategies to design sustainable, high-quality pipelines. To this end, we propose an evaluation model that integrates data quality metrics with sustainability parameters for human and computational tasks. Finally, we apply the model in a comparative analysis of key data preparation methods, demonstrating its effectiveness in assessing sustainability and quality trade-offs.},
	journal = {J. Data and Information Quality},
	author = {Pernici, Barbara and Cappiello, Cinzia and Bono, Carlo Alberto and Sancricca, Camilla and Catarci, Tiziana and Angelini, Marco and Filosa, Matteo and Palmonari, Matteo and De Paoli, Flavio and Bergamaschi, Sonia and Simonini, Giovanni and Mozzillo, Angelo and Zecchini, Luca},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Data preparation, Data quality, Sustainability},
	annote = {Just Accepted},
}

@article{chen_llm_2025,
	title = {{LLM} for {Mobile}: {An} {Initial} {Roadmap}},
	volume = {34},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3708528},
	doi = {10.1145/3708528},
	abstract = {When mobile meets LLMs, mobile app users deserve to have more intelligent usage experiences. For this to happen, we argue that there is a strong need to apply LLMs for the mobile ecosystem. We therefore provide a research roadmap for guiding our fellow researchers to achieve that as a whole. In this roadmap, we sum up six directions that we believe are urgently required for research to enable native intelligence in mobile devices. In each direction, we further summarize the current research progress and the gaps that still need to be filled by our fellow researchers.},
	number = {5},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Chen, Daihang and Liu, Yonghui and Zhou, Mingyi and Zhao, Yanjie and Wang, Haoyu and Wang, Shuai and Chen, Xiao and Bissyandé, Tegawendé F. and Klein, Jacques and Li, Li},
	month = may,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {LLM, Mobile, On-device model, Security},
}

@article{sheng_llms_2025,
	title = {{LLMs} in {Software} {Security}: {A} {Survey} of {Vulnerability} {Detection} {Techniques} and {Insights}},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3769082},
	doi = {10.1145/3769082},
	abstract = {Large Language Models (LLMs) are emerging as transformative tools for software vulnerability detection. Traditional methods, including static and dynamic analysis, face limitations in efficiency, false-positive rates, and scalability with modern software complexity. Through code structure analysis, pattern identification, and repair suggestion generation, LLMs demonstrate a novel approach to vulnerability mitigation. This survey examines LLMs in vulnerability detection, analyzing problem formulation, model selection, application methodologies, datasets, and evaluation metrics. We investigate current research challenges, emphasizing cross-language detection, multimodal integration, and repository-level analysis. Based on our findings, we propose solutions addressing dataset scalability, model interpretability, and low-resource scenarios. Our contributions include: (1) a systematic analysis of LLM applications in vulnerability detection; (2) a unified framework examining patterns and variations across studies; and (3) identification of key challenges and research directions. This work advances the understanding of LLM-based vulnerability detection. The latest findings are maintained at https://github.com/OwenSanzas/LLM-For-Vulnerability-Detection},
	journal = {ACM Comput. Surv.},
	author = {Sheng, Ze and Chen, Zhicheng and Gu, Shuning and Huang, Heqing and Gu, Guofei and Huang, Jeff},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Cybersecurity, Large Language Models, Vulnerability Detection},
	annote = {Just Accepted},
}

@article{yang_patch_2025,
	title = {Patch {Generation} in {APR}: {A} {Survey} from the {Perspectives} of {Utilizing} {LLMs} and {Using} {APR}-{Specific} {Information}},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3764584},
	doi = {10.1145/3764584},
	abstract = {Automated Program Repair (APR) is a crucial task in software development and maintenance, aiming to patch software bugs automatically without human intervention. The rise of Large Language Models (LLMs) has significantly advanced APR. However, as researchers delve deeper into APR as a downstream task for LLMs, a key challenge remains: how to effectively integrate APR-specific information to complement LLMs capabilities. This survey revisits 124 existing APR studies, most from 2021 to 2024, from two perspectives: Utilizing LLMs and APR-specific Information. First, we define the concept of APR-specific information. Then, we summarize techniques for utilizing LLMs in patch generation in four dimensions. Next, we explore critical factors influencing the effectiveness of generating patches by LLMs, such as prompting context and fine-tuning configurations. After that, we focus on the evaluation of generated patches, including benchmarks, reasoning cost scaling, etc. Furthermore, we distill all APR-specific information (e.g., bug-fix pairs and error messages), highlighting their unique importance and features. Finally, we comprehensively outline challenges, limitations, and potential future research directions in APR in the LLM era. To conclude, by adopting the two perspectives, we aim to provide valuable insights into mining and leveraging APR-specific information in utilizing LLMs process for the APR community.},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Yang, Yaopeng and Li, Chuanyi and Han, Zhifeng and Li, Rui and Xu, Kui and Li, Qingyuan and Zhong, Wenkang and Shen, Zongwen and Fei, Zhiwei and Ge, Jidong and Luo, Bin},
	month = aug,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {APR-specific information, Automated Program Repair, Large Language Model},
	annote = {Just Accepted},
}

@article{cao_lego-graphrag_2025,
	title = {{LEGO}-{GraphRAG}: {Modularizing} {Graph}-{Based} {Retrieval}-{Augmented} {Generation} for {Design} {Space} {Exploration}},
	volume = {18},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3748191.3748194},
	doi = {10.14778/3748191.3748194},
	abstract = {GraphRAG integrates (knowledge) graphs with large language models (LLMs) to improve reasoning accuracy and contextual relevance. Despite its promising applications and strong relevance to multiple research communities, such as databases and natural language processing, GraphRAG currently lacks modular workflow analysis, systematic solution frameworks, and insightful empirical studies. To bridge these gaps, we propose LEGO-GraphRAG, a modular framework that enables: 1) fine-grained decomposition of the GraphRAG workflow, 2) systematic classification of existing techniques and implemented GraphRAG instances, and 3) creation of new GraphRAG instances. Our framework facilitates comprehensive empirical studies of GraphRAG on large-scale real-world graphs and diverse query sets, revealing insights into balancing reasoning quality, runtime efficiency, and token or GPU cost, that are essential for building advanced GraphRAG systems.},
	number = {10},
	journal = {Proc. VLDB Endow.},
	author = {Cao, Yukun and Gao, Zengyi and Li, Zhiyang and Xie, Xike and Zhou, S. Kevin and Xu, Jianliang},
	month = sep,
	year = {2025},
	note = {Publisher: VLDB Endowment},
	pages = {3269--3283},
}

@article{levin_chatdbg_2025,
	title = {{ChatDBG}: {Augmenting} {Debugging} with {Large} {Language} {Models}},
	volume = {2},
	url = {https://doi.org/10.1145/3729355},
	doi = {10.1145/3729355},
	abstract = {Debugging is a critical but challenging task for programmers. This paper proposes ChatDBG, an AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like "why is x null?". To handle these queries, ChatDBG grants the LLM autonomy to "take the wheel": it can act as an independent agent capable of querying and controlling the debugger to navigate through stacks and inspect program state. It then reports its findings and yields back control to the programmer. By leveraging the real-world knowledge embedded in LLMs, ChatDBG can diagnose issues identifiable only through the use of domain-specific reasoning. Our ChatDBG prototype integrates with standard debuggers including LLDB and GDB for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code including standalone scripts and Jupyter notebooks, demonstrates that ChatDBG can successfully analyze root causes, explain bugs, and generate accurate fixes for a wide range of real-world errors. For the Python programs, a single query led to an actionable bug fix 67\% of the time; one additional follow-up query increased the success rate to 85\%. ChatDBG has seen rapid uptake; it has already been downloaded more than 75,000 times.},
	number = {FSE},
	journal = {Proc. ACM Softw. Eng.},
	author = {Levin, Kyla H. and van Kempen, Nicolas and Berger, Emery D. and Freund, Stephen N.},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Artificial Intelligence, Debugging, Software Engineering},
}

@article{li_matching_2025,
	title = {From {Matching} to {Generation}: {A} {Survey} on {Generative} {Information} {Retrieval}},
	volume = {43},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/3722552},
	doi = {10.1145/3722552},
	abstract = {Information Retrieval (IR) systems are crucial tools for users to access information, which have long been dominated by traditional methods relying on similarity matching. With the advancement of pre-trained language models, Generative Information Retrieval (GenIR) emerges as a novel paradigm, attracting increasing attention. Based on the form of information provided to users, current research in GenIR can be categorized into two aspects: (1) Generative Retrieval (GR) leverages the generative model’s parameters for memorizing documents, enabling retrieval by directly generating relevant document identifiers without explicit indexing. (2) Reliable Response Generation employs language models to directly generate information users seek, breaking the limitations of traditional IR in terms of document granularity and relevance matching while offering flexibility, efficiency, and creativity to meet practical needs. This article aims to systematically review the latest research progress in GenIR. We will summarize the advancements in GR regarding model training and structure, document identifier, incremental learning, and so on, as well as progress in reliable response generation in aspects of internal knowledge memorization, external knowledge augmentation, and so on. We also review the evaluation, challenges, and future developments in GenIR systems. This review aims to offer a comprehensive reference for researchers, encouraging further development in the GenIR field (Github Repository: ).},
	number = {3},
	journal = {ACM Trans. Inf. Syst.},
	author = {Li, Xiaoxi and Jin, Jiajie and Zhou, Yujia and Zhang, Yuyao and Zhang, Peitian and Zhu, Yutao and Dou, Zhicheng},
	month = may,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Generative Document Retrieval, Generative Information Retrieval, Reliable Response Generation},
}

@article{zhou_large_2025,
	title = {Large {Language} {Model} for {Vulnerability} {Detection} and {Repair}: {Literature} {Review} and the {Road} {Ahead}},
	volume = {34},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3708522},
	doi = {10.1145/3708522},
	abstract = {The significant advancements in Large Language Models (LLMs) have resulted in their widespread adoption across various tasks within Software Engineering (SE), including vulnerability detection and repair. Numerous studies have investigated the application of LLMs to enhance vulnerability detection and repair tasks. Despite the increasing research interest, there is currently no existing survey that focuses on the utilization of LLMs for vulnerability detection and repair. In this paper, we aim to bridge this gap by offering a systematic literature review of approaches aimed at improving vulnerability detection and repair through the utilization of LLMs. The review encompasses research work from leading SE, AI, and Security conferences and journals, encompassing 43 papers published across 25 distinct venues, along with 15 high-quality preprint papers, bringing the total to 58 papers. By answering three key research questions, we aim to (1) summarize the LLMs employed in the relevant literature, (2) categorize various LLM adaptation techniques in vulnerability detection, and (3) classify various LLM adaptation techniques in vulnerability repair. Based on our findings, we have identified a series of limitations of existing studies. Additionally, we have outlined a roadmap highlighting potential opportunities that we believe are pertinent and crucial for future research endeavors.},
	number = {5},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Zhou, Xin and Cao, Sicong and Sun, Xiaobing and Lo, David},
	month = may,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {large language models, Literature review, vulnerability detection, vulnerability repair},
}

@article{assi_llm-cure_2025,
	title = {{LLM}-{Cure}: {LLM}-based {Competitor} {User} {Review} {Analysis} for {Feature} {Enhancement}},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3744644},
	doi = {10.1145/3744644},
	abstract = {The exponential growth of the mobile app market underscores the importance of constant innovation and rapid response to user demands. As user satisfaction is paramount to the success of a mobile application (app), developers typically rely on user reviews, which represent user feedback that includes ratings and comments to identify areas for improvement. However, the sheer volume of user reviews poses challenges in manual analysis, necessitating automated approaches. Existing automated approaches either analyze only the target app's reviews, neglecting the comparison of similar features to competitors or fail to provide suggestions for feature enhancement. To address these gaps, we propose a Large Language Model (LLM)-based Competitive User Review Analysis for Feature Enhancement) (LLM-Cure), an approach powered by LLMs to automatically generate suggestions for mobile app feature improvements. More specifically, LLM-Cure identifies and categorizes features within reviews by applying LLMs. When provided with a complaint in a user review, LLM-Cure curates highly rated (4 and 5 stars) reviews in competing apps related to the complaint and proposes potential improvements tailored to the target application. We evaluate LLM-Cure on 1,056,739 reviews of 70 popular Android apps. Our evaluation demonstrates that LLM-Cure significantly outperforms the state-of-the-art approaches in assigning features to reviews by up to 13\% in F1-score, up to 16\% in recall and up to 11\% in precision. Additionally, LLM-Cure demonstrates its capability to provide suggestions for resolving user complaints. We verify the suggestions using the release notes that reflect the changes of features in the target mobile app. LLM-Cure achieves a promising average of 73\% of the implementation of the provided suggestions, demonstrating its potential for competitive feature enhancement.},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Assi, Maram and Hassan, Safwat and Zou, Ying},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Competitor analysis, Feature Enhancement, LLM, Mobile applications, User reviews},
	annote = {Just Accepted},
}

@article{yu_cashift_2025,
	title = {{CAShift}: {Benchmarking} {Log}-{Based} {Cloud} {Attack} {Detection} under {Normality} {Shift}},
	volume = {2},
	url = {https://doi.org/10.1145/3729346},
	doi = {10.1145/3729346},
	abstract = {With the rapid advancement of cloud-native computing, securing cloud environments has become an important task. Log-based Anomaly Detection (LAD) is the most representative technique used in different systems for attack detection and safety guarantee, where multiple LAD methods and relevant datasets have been proposed. However, even though some of these datasets are specifically prepared for cloud systems, they only cover limited cloud behaviors and lack information from a whole-system perspective. Another critical issue to consider is normality shift, which implies that the test distribution could differ from the training distribution and highly affect the performance of LAD. Unfortunately, existing works only focus on simple shift types such as chronological changes, while other cloud-specific shift types are ignored, e.g., different deployed cloud architectures. Therefore, a dataset that captures diverse cloud system behaviors and various types of normality shifts is essential. To fill this gap, we construct a dataset CAShift to evaluate the performance of LAD in cloud, which considers different roles of software in cloud systems, supports three real-world normality shift types (application shift, version shift, and cloud architecture shift), and features 20 different attack scenarios in various cloud system components. Based on CAShift, we conduct a comprehensive empirical study to investigate the effectiveness of existing LAD methods in normality shift scenarios. Additionally, to explore the feasibility of shift adaptation, we further investigate three continuous learning approaches, which are the most common methods to mitigate the impact of distribution shift. Results demonstrated that 1) all LAD methods suffer from normality shift where the performance drops up to 34\%, and 2) existing continuous learning methods are promising to address shift drawbacks, but the ratio of data used for model retraining and the selection of algorithms highly affect the shift adaptation, with an increase in the F1-Score of up to 27\%. Based on our findings, we offer valuable implications for future research in designing more robust LAD models and methods for LAD shift adaptation.},
	number = {FSE},
	journal = {Proc. ACM Softw. Eng.},
	author = {Yu, Jiongchi and Xie, Xiaofei and Hu, Qiang and Zhang, Bowen and Zhao, Ziming and Lin, Yun and Ma, Lei and Feng, Ruitao and Liauw, Frank},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Anomaly Detection, Cloud Native Systems, Intrusion Detection, Log Analysis, Normality Shift, Software Vulnerabilities},
}

@article{li_urban_2025,
	title = {Urban {Computing} in the {Era} of {Large} {Language} {Models}},
	issn = {2157-6904},
	url = {https://doi.org/10.1145/3768163},
	doi = {10.1145/3768163},
	abstract = {Urban computing has emerged as a multidisciplinary field that harnesses data-driven technologies to address challenges and improve urban living. Traditional approaches, while beneficial, often face challenges with generalization, scalability, and contextual understanding. The advent of Large Language Models (LLMs) offers transformative potential in this domain. This survey explores the intersection of LLMs and urban computing, emphasizing the impact of LLMs in processing and analyzing urban data, enhancing decision-making, and fostering citizen engagement. We provide a concise overview of the evolution and core technologies of LLMs. Additionally, we survey their applications across key urban domains, such as transportation, public safety, and environmental monitoring, summarizing essential tasks and prior works in various urban contexts, while highlighting LLMs’ functional roles and implementation patterns. Building on this, we propose potential LLM-based solutions to address unresolved challenges. To facilitate in-depth research, we compile a list of available datasets and tools applicable to diverse urban scenarios. Finally, we discuss the limitations of current approaches and outline future directions for advancing LLMs in urban computing.},
	journal = {ACM Trans. Intell. Syst. Technol.},
	author = {Li, Zhonghang and Xia, Lianghao and Ren, Xubin and Tang, Jiabin and Chen, Tianyi and Xu, Yong and Huang, Chao},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Large Language Models (LLMs), Spatio-Temporal Data Mining, Transportation, Urban Computing},
	annote = {Just Accepted},
}

@article{xie_chatts_2025,
	title = {{ChatTS}: {Aligning} {Time} {Series} with {LLMs} via {Synthetic} {Data} for {Enhanced} {Understanding} and {Reasoning}},
	volume = {18},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3742728.3742735},
	doi = {10.14778/3742728.3742735},
	abstract = {Understanding time series is crucial for its application in real-world scenarios. Recently, large language models (LLMs) have been increasingly applied to time series tasks, leveraging their strong language capabilities to enhance various applications. However, research on multimodal LLMs (MLLMs) for time series understanding and reasoning remains limited, primarily due to the scarcity of high-quality datasets that align time series with textual information. This paper introduces ChatTS, a novel MLLM designed for time series analysis. ChatTS treats time series as a modality, similar to how vision MLLMs process images, enabling it to perform both understanding and reasoning with time series. To address the scarcity of training data, we propose an attribute-based method for generating synthetic time series and Time Series Evol-Instruct to generates diverse Q\&amp;As for enhanced reasoning capabilities. To the best of our knowledge, ChatTS is the first MLLM that takes multivariate time series as input for understanding and reasoning, which is fine-tuned exclusively on synthetic datasets. We evaluate its performance using benchmark datasets with real-world data, including six alignment tasks and four reasoning tasks. Our results show that ChatTS significantly outperforms existing vision-based MLLMs (e.g., GPT-4o) and text/agent-based LLMs, achieving a 46.0\% improvement in alignment tasks and a 25.8\% improvement in reasoning tasks. We have open-sourced the source code, model checkpoint and datasets at https://github.com/NetManAIOps/ChatTS.},
	number = {8},
	journal = {Proc. VLDB Endow.},
	author = {Xie, Zhe and Li, Zeyan and He, Xiao and Xu, Longlong and Wen, Xidao and Zhang, Tieying and Chen, Jianjun and Shi, Rui and Pei, Dan},
	month = sep,
	year = {2025},
	note = {Publisher: VLDB Endowment},
	pages = {2385--2398},
}

@article{arakawa_prism-qamp_2024,
	title = {{PrISM}-{Q}\&amp;{A}: {Step}-{Aware} {Voice} {Assistant} on a {Smartwatch} {Enabled} by {Multimodal} {Procedure} {Tracking} and {Large} {Language} {Models}},
	volume = {8},
	url = {https://doi.org/10.1145/3699759},
	doi = {10.1145/3699759},
	abstract = {Voice assistants capable of answering user queries during various physical tasks have shown promise in guiding users through complex procedures. However, users often find it challenging to articulate their queries precisely, especially when unfamiliar with the specific terminologies required for machine-oriented tasks. We introduce PrISM-Q\&amp;A, a novel question-answering (Q\&amp;A) interaction termed step-aware Q\&amp;A, which enhances the functionality of voice assistants on smartwatches by incorporating Human Activity Recognition (HAR) and providing the system with user context. It continuously monitors user behavior during procedural tasks via audio and motion sensors on the watch and estimates which step the user is performing. When a question is posed, this contextual information is supplied to Large Language Models (LLMs) as part of the context used to generate a response, even in the case of inherently vague questions like "What should I do next with this?" Our studies confirmed that users preferred the convenience of our approach compared to existing voice assistants. Our real-time assistant represents the first Q\&amp;A system that provides contextually situated support during tasks without camera use, paving the way for the ubiquitous, intelligent assistant.},
	number = {4},
	journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
	author = {Arakawa, Riku and Lehman, Jill Fain and Goel, Mayank},
	month = nov,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {context-aware, large language models, procedure tracking, question answering, task assistance},
}

@article{wang_graph_2025,
	title = {Graph {Machine} {Learning} in the {Era} of {Large} {Language} {Models} ({LLMs})},
	volume = {16},
	issn = {2157-6904},
	url = {https://doi.org/10.1145/3732786},
	doi = {10.1145/3732786},
	abstract = {Graphs play an important role in representing complex relationships in various domains like social networks, knowledge graphs, and molecular discovery. With the advent of deep learning, Graph Neural Networks (GNNs) have emerged as a cornerstone in Graph Machine Learning (Graph ML), facilitating the representation and processing of graphs. Recently, LLMs have demonstrated unprecedented capabilities in language tasks and are widely adopted in a variety of applications, such as computer vision and recommender systems. This remarkable success has also attracted interest in applying LLMs to the graph domain. Increasing efforts have been made to explore the potential of LLMs in advancing Graph ML’s generalization, transferability, and few-shot learning ability. Meanwhile, graphs, especially knowledge graphs, are rich in reliable factual knowledge, which can be utilized to enhance the reasoning capabilities of LLMs and potentially alleviate their limitations, such as hallucinations and the lack of explainability. Given the rapid progress of this research direction, a systematic review summarizing the latest advancements for Graph ML in the era of LLMs is necessary to provide an in-depth understanding to researchers and practitioners. Therefore, in this survey, we first review the recent developments in Graph ML. We then explore how LLMs can be utilized to enhance the quality of graph features, alleviate the reliance on labeled data, and address challenges such as graph Heterophily and Out-of-Distribution (OOD) generalization. Afterward, we delve into how graphs can enhance LLMs, highlighting their abilities to enhance LLM pre-training and inference. Furthermore, we investigate various applications and discuss the potential future directions in this promising field.},
	number = {5},
	journal = {ACM Trans. Intell. Syst. Technol.},
	author = {Wang, Shijie and Huang, Jiani and Chen, Zhikai and Song, Yu and Tang, Wenzhuo and Mao, Haitao and Fan, Wenqi and Liu, Hui and Liu, Xiaorui and Yin, Dawei and Li, Qing},
	month = aug,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {and Representation Learning, Graph Machine Learning, Large Language Models (LLMs), Pre-training and Fine-tuning, Prompting},
}

@article{vanbrabant_echo_2025,
	title = {{ECHO}: {Enhancing} {Conversational} {Explainable} {AI} through {Tool}-{Augmented} {Language} {Models}},
	volume = {9},
	url = {https://doi.org/10.1145/3734191},
	doi = {10.1145/3734191},
	abstract = {This paper introduces ECHO, an LLM-powered system framework to explore and interrogate the internals of AI models through tool-augmented language models. While traditional XAI methods typically offer a small and technical set of explanation types, ECHO advances the accessibility and usability of AI explanations through a conversational approach, combining LLMs with a collection of tools and a human-in-the-loop process. We identify various explanation types from the literature, for which we create a set of predefined tools for tabular data. Using a modular architecture, ECHO integrates these predefined tools with dynamically generated tools to interact with AI models, facilitating tailored explanations for a large variety of user queries. This paper details ECHO’s design, implementation, and use cases, demonstrating its capabilities in the context of a movie recommender, healthcare decision tree and neural network for educational classification.},
	number = {4},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Vanbrabant, Sebe and Eerlings, Gilles and Rovelo Ruiz, Gustavo Alberto and Vanacken, Davy},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Artificial Intelligence, Explainability, Explainable AI, Human-AI Interaction, Intelligibility, Interpretability, Large Language Models, Machine Learning},
}

@article{kreikemeyer_using_2025,
	title = {Using ({Not}-so) {Large} {Language} {Models} to {Generate} {Simulation} {Models} in a {Formal} {DSL}: {A} {Study} on {Reaction} {Networks}},
	volume = {35},
	issn = {1049-3301},
	url = {https://doi.org/10.1145/3733719},
	doi = {10.1145/3733719},
	abstract = {Formal languages are an integral part of modeling and simulation. They allow the distillation of knowledge into concise simulation models amenable to automatic execution, interpretation, and analysis. However, the arguably most humanly accessible means of expressing models is through natural language, which is not easily interpretable by computers. Here, we evaluate how a Large Language Model (LLM) might be used for formalizing natural language into simulation models. Existing studies only explored using very large LLMs, like the commercial GPT models, without fine-tuning model weights. To close this gap, we show how an open-weights, 7B-parameter Mistral model can be fine-tuned to translate natural language descriptions to reaction network models in a domain-specific language, offering a self-hostable, compute-efficient, and memory efficient alternative. To this end, we develop a synthetic data generator to serve as the basis for fine-tuning and evaluation. Our quantitative evaluation shows that our fine-tuned Mistral model can recover the ground truth simulation model in up to 84.5\% of cases. In addition, our small-scale user study demonstrates the model’s practical potential for one-time generation as well as interactive modeling in various domains. While promising, in its current form, the fine-tuned small LLM cannot catch up with large LLMs. We conclude that higher-quality training data are required, and expect future small and open-source LLMs to offer new opportunities.},
	number = {4},
	journal = {ACM Trans. Model. Comput. Simul.},
	author = {Kreikemeyer, Justin Noah and Jankowski, Miłosz and Wilsdorf, Pia and Uhrmacher, Adelinde M.},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {constrained decoding, knowledge extraction, language model, natural language processing, Simulation model generation},
}

@article{sun_when_2025,
	title = {When {Traditional} {Medicine} {Meets} {AI}: {Critical} {Considerations} for {AI}-{Empowered} {Clinical} {Support} in {Traditional} {Medicine}},
	volume = {9},
	url = {https://doi.org/10.1145/3757705},
	doi = {10.1145/3757705},
	abstract = {Traditional Medicine (TM) is the oldest healthcare form and has been increasingly adopted as the primary or complementary medical therapy in the world. However, TM's practical development remains highly challenging. While artificial intelligence (AI) has become powerful in advancing modern medicine, limited attention has been paid to its potential and usage in TM. This study addresses this gap through a probe-based interview study with 16 TM clinicians, examining their experiences, perceptions, and expectations of AI-empowered clinical support systems. Our findings reveal that despite numerous AI-CDS systems, their practical usage in TM settings was still limited. We identify a series of practical challenges when integrating AI-CDS into TM clinical scenarios, largely due to TM's unique features and the significant data work challenges these features present. We end by critically discussing the potential issues that may arise when integrating AI into practical TM scenarios, and proposing a series of practical recommendations for future studies.},
	number = {7},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Sun, Yuling and Yue, Wenjing and Jin, Xiaofu and Ma, Shuai and Ma, Xiaojuan and Wang, Xiaoling},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {adoption, artificial intelligence, clinical decision-making, clinician, qualitative, traditional Chinese medicine, traditional medicine, usability},
}

@article{sakib_genai_2025,
	title = {A {GenAI} {System} for {Improved} {FAIR} {Independent} {Biological} {Database} {Integration}},
	issn = {1936-1955},
	url = {https://doi.org/10.1145/3770753},
	doi = {10.1145/3770753},
	abstract = {Life sciences research increasingly requires identifying, accessing, and effectively processing data from an ever-evolving array of information sources on the Linked Open Data (LOD) network. This dynamic landscape places a significant burden on researchers, as the quality of query responses depends heavily on the selection and semantic integration of data sources –processes that are often labor-intensive, error-prone, and costly. While the adoption of FAIR (Findable, Accessible, Interoperable, and Reusable) data principles has aimed to address these challenges, barriers to efficient and accurate scientific data processing persist. In this paper, we introduce FAIRBridge, an experimental natural language-based query processing system designed to empower scientists to discover, access, and query biological databases, even when they are not FAIR-compliant. FAIRBridge harnesses the capabilities of AI to interpret query intents, map them to relevant databases described in scientific literature, and generate executable queries via intelligent resource access plans. The system also includes robust tools for mitigating low-quality query processing, ensuring high fidelity and responsiveness in the information delivered. FAIRBridge’s autonomous query processing framework enables users to explore alternative data sources, make informed choices at every step, and leverage community-driven crowd curation when needed. By providing a user-friendly, automated hypothesis-testing platform in natural English, FAIRBridge significantly enhances the integration and processing of scientific data, offering researchers a powerful new tool for advancing their inquiries.},
	journal = {J. Data and Information Quality},
	author = {Sakib, Syed N and Naha, Kallol and Rubaiat, Sajratul Y and Jamil, Hasan M},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Computational Biology, Data Integration, Deep Web Database, FAIR, Information Retrieval, Knowledge Representation, Large Language Model, Natural Language Processing, Scientific Inquiries},
	annote = {Just Accepted},
	annote = {Just Accepted},
}

@article{zhang_beyond_2025,
	title = {Beyond {Texts}: {Incorporating} {Co}-occurrences into the {Review}-based {Conversation} {Recommendation} {Systems}.},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/3771276},
	doi = {10.1145/3771276},
	abstract = {Conversational recommender systems (CRSs) interact with users through natural language to provide recommendations and generate responses. Due to limited information in conversation, existing works utilize KGs or reviews to improve CRS. Despite achievements, they overlook co-occurrence relations which have shown effectiveness in collaborative filtering systems. In this work, we first propose a novel framework named CoCRS, aiming to incorporate Co-occurrences into the review-based Conversation Recommendation Systems. In CoCRS, we mine co-occurrences from two aspects: (1) item and entity, (2) user and item. For the first one, we extract entities from redundant review texts by KG and construct a relation-aware item-entity heterogeneous graph. In the second aspect, we analyze review sentiments and construct a sentiment-aware user-item bipartite graph. We encode two graphs to obtain user and entity embeddings. Since users in CRS are anonymous, we generate a virtual similar user representation to match reviews with users. Besides, we capture time-aware preference representation from two time dimensions. Finally, we generate word-level user representation with word-oriented KG and model user preference by integrating the above representations. Extensive experiments demonstrate that CoCRS outperforms baselines and the cold-start experiment highlights its robustness. The LLM experiment illustrates the significant role of co-occurrence relationships in LLM-based CRS. Our code are available at https://github.com/Qin-lab-code/CoCRS.},
	journal = {ACM Trans. Inf. Syst.},
	author = {Zhang, Haoyao and Qin, Zhida and Liang, Xufeng and Guo, Jing and Li, Shuang and Huang, Tianyu and Lui, John C.S.},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Conversational recommendation, Recommender systems},
	annote = {Just Accepted},
}

@article{blinn_statically_2024,
	title = {Statically {Contextualizing} {Large} {Language} {Models} with {Typed} {Holes}},
	volume = {8},
	url = {https://doi.org/10.1145/3689728},
	doi = {10.1145/3689728},
	abstract = {Large language models (LLMs) have reshaped the landscape of program synthesis. However, contemporary LLM-based code completion systems often hallucinate broken code because they lack appropriate code context, particularly when working with definitions that are neither in the training data nor near the cursor. This paper demonstrates that tighter integration with the type and binding structure of the programming language in use, as exposed by its language server, can help address this contextualization problem in a token-efficient manner. In short, we contend that AIs need IDEs, too! In particular, we integrate LLM code generation into the Hazel live program sketching environment. The Hazel Language Server is able to identify the type and typing context of the hole that the programmer is filling, with Hazel's total syntax and type error correction ensuring that a meaningful program sketch is available whenever the developer requests a completion. This allows the system to prompt the LLM with codebase-wide contextual information that is not lexically local to the cursor, nor necessarily in the same file, but that is likely to be semantically local to the developer's goal. Completions synthesized by the LLM are then iteratively refined via further dialog with the language server, which provides error localization and error messages. To evaluate these techniques, we introduce MVUBench, a dataset of model-view-update (MVU) web applications with accompanying unit tests that have been written from scratch to avoid data contamination, and that can easily be ported to new languages because they do not have large external library dependencies. These applications serve as challenge problems due to their extensive reliance on application-specific data structures. Through an ablation study, we examine the impact of contextualization with type definitions, function headers, and errors messages, individually and in combination. We find that contextualization with type definitions is particularly impactful. After introducing our ideas in the context of Hazel, a low-resource language, we duplicate our techniques and port MVUBench to TypeScript in order to validate the applicability of these methods to higher-resource mainstream languages. Finally, we outline ChatLSP, a conservative extension to the Language Server Protocol (LSP) that language servers can implement to expose capabilities that AI code completion systems of various designs can use to incorporate static context when generating prompts for an LLM.},
	number = {OOPSLA2},
	journal = {Proc. ACM Program. Lang.},
	author = {Blinn, Andrew and Li, Xiang and Kim, June Hyung and Omar, Cyrus},
	month = oct,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Large Language Models, Program Repair, Program Synthesis},
}

@article{reddy_lhs_2025,
	title = {{LHS}: {LLM} {Assisted} {Efficient} {High}-level {Synthesis} of {Deep} {Learning} {Tasks}},
	volume = {30},
	issn = {1084-4309},
	url = {https://doi.org/10.1145/3734523},
	doi = {10.1145/3734523},
	abstract = {Deep learning tasks, especially those involving complex convolution neural networks (CNNs), are computationally intensive and pose significant challenges when implemented on hardware. Accelerating these tasks is critical for improving performance. High-level Synthesis (HLS) has the potential to automate the efficient hardware accelerator designs directly from high-level C/C++ specification of trained machine learning (ML) models. Traditional HLS tools cannot synthesize certain high-level constructs, which require manual intervention. Many source code optimizations and the selection of pragmas for HLS optimizations are crucial for generating efficient hardware accelerators with HLS. However, both of these tasks are mostly manual efforts. Recently, Large Language Models (LLMs) have shown remarkable capabilities in various generative tasks. In this work, we explore the application of LLMs to remove these manual efforts in adapting HLS for ML accelerator designs. Our framework called LLM-assisted HLS, i.e., LHS, uses LLMs to automate the resolution of synthesis issues, ensuring compatibility with HLS tools. Furthermore, our framework automates the source code modification and optimization selection through pragma insertion steps, which are crucial for optimizing the synthesized design. Our experimental results with LHS demonstrate a significant improvement in latency for deep learning tasks with underlying complex CNN models without much area overhead. Our LHS allows us to achieve up to 2690 × latency improvement. Promisingly, LHS performs better than the state-of-the-art ML accelerator design tool hls4ml in 4 out of 6 cases in the context of latency improvement at the expense of area overhead (i.e., performance to hardware gain). This work highlights the potential of LLMs to assist and accelerate the HLS process, thereby creating more efficient hardware implementation for deep learning models.},
	number = {6},
	journal = {ACM Trans. Des. Autom. Electron. Syst.},
	author = {Reddy, E Bhawani Eswar and Bhattacharyya, Sutirtha and Sarmah, Ankur and Nongpoh, Fedrick and Maddala, Karthik and Karfa, Chandan},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {CNN, high-level synthesis, LLM},
}

@article{wang_large_2025,
	title = {Large {Language} {Model} {Supply} {Chain}: {A} {Research} {Agenda}},
	volume = {34},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3708531},
	doi = {10.1145/3708531},
	abstract = {The rapid advancement of large language models (LLMs) has revolutionized artificial intelligence, introducing unprecedented capabilities in natural language processing and multimodal content generation. However, the increasing complexity and scale of these models have given rise to a multifaceted supply chain that presents unique challenges across infrastructure, foundation models, and downstream applications. This article provides the first comprehensive research agenda of the LLM supply chain, offering a structured approach to identify critical challenges and opportunities through the dual lenses of software engineering (SE) and security and privacy (S\&amp;P). We begin by establishing a clear definition of the LLM supply chain, encompassing its components and dependencies. We then analyze each layer of the supply chain, presenting a vision for robust and secure LLM development, reviewing the current state of practices and technologies, and identifying key challenges and research opportunities. This work aims to bridge the existing research gap in systematically understanding the multifaceted issues within the LLM supply chain, offering valuable insights to guide future efforts in this rapidly evolving domain.},
	number = {5},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Wang, Shenao and Zhao, Yanjie and Hou, Xinyi and Wang, Haoyu},
	month = may,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Large Language Models, LLM Supply Chain},
}

@article{zheng_towards_2025,
	title = {Towards {Lifelong} {Learning} of {Large} {Language} {Models}: {A} {Survey}},
	volume = {57},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3716629},
	doi = {10.1145/3716629},
	abstract = {As the applications of large language models (LLMs) expand across diverse fields, their ability to adapt to ongoing changes in data, tasks, and user preferences becomes crucial. Traditional training methods with static datasets are inadequate for coping with the dynamic nature of real-world information. Lifelong learning, or continual learning, addresses this by enabling LLMs to learn continuously and adapt over their operational lifetime, integrating new knowledge while retaining previously learned information and preventing catastrophic forgetting. Our survey explores the landscape of lifelong learning, categorizing strategies into two groups based on how new knowledge is integrated: Internal Knowledge, where LLMs absorb new knowledge into their parameters through full or partial training, and External Knowledge, which incorporates new knowledge as external resources such as Wikipedia or APIs without updating model parameters. The key contributions of our survey include: (1) introducing a novel taxonomy to categorize the extensive literature of lifelong learning into 12 scenarios; (2) identifying common techniques across all lifelong learning scenarios and classifying existing literature into various technique groups; (3) highlighting emerging techniques such as model expansion and data selection, which were less explored in the pre-LLM era. Resources are available at .},
	number = {8},
	journal = {ACM Comput. Surv.},
	author = {Zheng, Junhao and Qiu, Shengjie and Shi, Chengming and Ma, Qianli},
	month = mar,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {catastrophic forgetting, continual learning, incremental learning, large language models, Lifelong learning},
}

@article{su_scene-aware_2023,
	title = {Scene-{Aware} {Activity} {Program} {Generation} with {Language} {Guidance}},
	volume = {42},
	issn = {0730-0301},
	url = {https://doi.org/10.1145/3618338},
	doi = {10.1145/3618338},
	abstract = {We address the problem of scene-aware activity program generation, which requires decomposing a given activity task into instructions that can be sequentially performed within a target scene to complete the activity. While existing methods have shown the ability to generate rational or executable programs, generating programs with both high rationality and executability still remains a challenge. Hence, we propose a novel method where the key idea is to explicitly combine the language rationality of a powerful language model with dynamic perception of the target scene where instructions are executed, to generate programs with high rationality and executability. Our method iteratively generates instructions for the activity program. Specifically, a two-branch feature encoder operates on a language-based and graph-based representation of the current generation progress to extract language features and scene graph features, respectively. These features are then used by a predictor to generate the next instruction in the program. Subsequently, another module performs the predicted action and updates the scene for perception in the next iteration. Extensive evaluations are conducted on the VirtualHome-Env dataset, showing the advantages of our method over previous work. Key algorithmic designs are validated through ablation studies, and results on other types of inputs are also presented to show the generalizability of our method.},
	number = {6},
	journal = {ACM Trans. Graph.},
	author = {Su, Zejia and Fan, Qingnan and Chen, Xuelin and Van Kaick, Oliver and Huang, Hui and Hu, Ruizhen},
	month = dec,
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {activity program generation, dynamic scene graph, language guidance},
}

@article{guo_omnigirl_2025,
	title = {{OmniGIRL}: {A} {Multilingual} and {Multimodal} {Benchmark} for {GitHub} {Issue} {Resolution}},
	volume = {2},
	url = {https://doi.org/10.1145/3728871},
	doi = {10.1145/3728871},
	abstract = {The GitHub issue resolution task aims to resolve issues reported in repositories automatically. With advances in large language models (LLMs), this task has gained increasing attention, and several benchmarks are proposed to evaluate the issue resolution ability of LLMs. However, existing benchmarks have three main limitations. First, current benchmarks focus on a single programming language, limiting the evaluation of issues from repositories across different languages. Second, they usually cover a narrow range of domains, which may fail to represent the diversity of real-world issues. Third, existing benchmarks rely solely on textual information in issue descriptions, overlooking multimodal information such as images in issues. In this paper, we propose OmniGIRL, a GitHub Issue ResoLution benchmark that is multilingual, multimodal, and multi-domain. OmniGIRL includes 959 task instances, which are collected from repositories across four programming languages (i.e., Python, JavaScript, TypeScript, and Java) and eight different domains. Our evaluation shows that current LLMs show limited performances on OmniGIRL. Notably, the best-performing model, GPT-4o, resolves only 8.6\% of the issues. Besides, we find that current LLMs struggle to resolve issues requiring understanding images. The best performance is achieved by Claude-3.5-Sonnet, which resolves only 10.5\% of the issues with image information. Finally, we analyze the reasons behind current LLMs’ failure on OmniGIRL, providing insights for future improvements.},
	number = {ISSTA},
	journal = {Proc. ACM Softw. Eng.},
	author = {Guo, Lianghong and Tao, Wei and Jiang, Runhan and Wang, Yanlin and Chen, Jiachi and Liu, Xilin and Ma, Yuchi and Mao, Mingzhi and Zhang, Hongyu and Zheng, Zibin},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Benchmark, Github Issue Resolution, Large Language Models},
}

@article{das_security_2025,
	title = {Security and {Privacy} {Challenges} of {Large} {Language} {Models}: {A} {Survey}},
	volume = {57},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3712001},
	doi = {10.1145/3712001},
	abstract = {Large language models (LLMs) have demonstrated extraordinary capabilities and contributed to multiple fields, such as generating and summarizing text, language translation, and question-answering. Today, LLMs have become quite popular tools in natural language processing tasks, with the capability to analyze complicated linguistic patterns and provide relevant responses depending on the context. While offering significant advantages, these models are also vulnerable to security and privacy attacks, such as jailbreaking attacks, data poisoning attacks, and personally identifiable information leakage attacks. This survey provides a thorough review of the security and privacy challenges of LLMs, along with the application-based risks in various domains, such as transportation, education, and healthcare. We assess the extent of LLM vulnerabilities, investigate emerging security and privacy attacks against LLMs, and review potential defense mechanisms. Additionally, the survey outlines existing research gaps and highlights future research directions.},
	number = {6},
	journal = {ACM Comput. Surv.},
	author = {Das, Badhan Chandra and Amini, M. Hadi and Wu, Yanzhao},
	month = feb,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {attack and defense mechanisms, Large language models},
}

@article{zhou_conformal_2025,
	title = {Conformal {Prediction}: {A} {Data} {Perspective}},
	volume = {58},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3736575},
	doi = {10.1145/3736575},
	abstract = {Conformal prediction (CP), a distribution-free uncertainty quantification (UQ) framework, reliably provides valid predictive inference for black-box models. CP constructs prediction sets or intervals that contain the true output with a specified probability. However, modern data science’s diverse modalities, along with increasing data and model complexity, challenge traditional CP methods. These developments have spurred novel approaches to address evolving scenarios. This survey reviews the foundational concepts of CP and recent advancements from a data-centric perspective, including applications to structured, unstructured, and dynamic data. We also discuss the challenges and opportunities CP faces in large-scale data and models.},
	number = {2},
	journal = {ACM Comput. Surv.},
	author = {Zhou, Xiaofan and Chen, Baiting and Gui, Yu and Cheng, Lu},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Computer vision, Natural language processing, Time series},
}

@article{kaniwa_chitchatguide_2024,
	title = {{ChitChatGuide}: {Conversational} {Interaction} {Using} {Large} {Language} {Models} for {Assisting} {People} with {Visual} {Impairments} to {Explore} a {Shopping} {Mall}},
	volume = {8},
	url = {https://doi.org/10.1145/3676492},
	doi = {10.1145/3676492},
	abstract = {To enable people with visual impairments (PVI) to explore shopping malls, it is important to provide information for selecting destinations and obtaining information based on the individual's interests. We achieved this through conversational interaction by integrating a large language model (LLM) with a navigation system. ChitChatGuide allows users to plan a tour through contextual conversations, receive personalized descriptions of surroundings based on transit time, and make inquiries during navigation. We conducted a study in a shopping mall with 11 PVI, and the results reveal that the system allowed them to explore the facility with increased enjoyment. The LLM-based conversational interaction, by understanding vague and context-based questions, enabled the participants to explore unfamiliar environments effectively. The personalized and in-situ information generated by the LLM was both useful and enjoyable. Considering the limitations we identified, we discuss the criteria for integrating LLMs into navigation systems to enhance the exploration experiences of PVI.},
	number = {MHCI},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Kaniwa, Yuka and Kuribayashi, Masaki and Kayukawa, Seita and Sato, Daisuke and Takagi, Hironobu and Asakawa, Chieko and Morishima, Shigeo},
	month = sep,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {large language model, orientation and mobility, visual impairment},
}

@article{kharkwal_university_2021,
	title = {University {Operations} {During} a {Pandemic}: {A} {Flexible} {Decision} {Analysis} {Toolkit}},
	volume = {12},
	issn = {2158-656X},
	url = {https://doi.org/10.1145/3460125},
	doi = {10.1145/3460125},
	abstract = {Modeling infection spread during pandemics is not new, with models using past data to tune simulation parameters for predictions. These help in understanding of the healthcare burden posed by a pandemic and responding accordingly. However, the problem of how college/university campuses should function during a pandemic is new for the following reasons: (i) social contact in colleges are structured and can be engineered for chosen objectives; (ii) the last pandemic to cause such societal disruption was more than 100 years ago, when higher education was not a critical part of society; (iii) not much was known about causes of pandemics, and hence effective ways of safe operations were not known; and (iv) today with distance learning, remote operation of an academic institution is possible. As one of the first to address this problem, our approach is unique in presenting a flexible simulation system, containing a suite of model libraries, one for each major component. The system integrates agent-based modeling and the stochastic network approach, and models the interactions among individual entities (e.g., students, instructors, classrooms, residences) in great detail. For each decision to be made, the system can be used to predict the impact of various choices, and thus enables the administrator to make informed decisions. Although current approaches are good for infection modeling, they lack accuracy in social contact modeling. Our agent-based modeling approach, combined with ideas from Network Science, presents a novel approach to contact modeling. A detailed case study of the University of Minnesota’s Sunrise Plan is presented. For each decision made, its impact was assessed, and results were used to get a measure of confidence. We believe that this flexible tool can be a valuable asset for various kinds of organizations to assess their infection risks in pandemic-time operations, including middle and high schools, factories, warehouses, and small/medium-sized businesses.},
	number = {4},
	journal = {ACM Trans. Manage. Inf. Syst.},
	author = {Kharkwal, Himanshu and Olson, Dakota and Huang, Jiali and Mohan, Abhiraj and Mani, Ankur and Srivastava, Jaideep},
	month = sep,
	year = {2021},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Agent based modeling, bipartite networks, COVID-19, decision analysis, simulation},
}

@article{li_graph_2024,
	title = {Graph and {Sequential} {Neural} {Networks} in {Session}-based {Recommendation}: {A} {Survey}},
	volume = {57},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3696413},
	doi = {10.1145/3696413},
	abstract = {Recent years have witnessed the remarkable success of recommendation systems (RSs) in alleviating the information overload problem. As a new paradigm of RSs, session-based recommendation (SR) specializes in users’ short-term preferences and aims at providing a more dynamic and timely recommendation based on ongoing interactions. This survey presents a comprehensive overview of the recent works on SR. First, we clarify the key definitions within SR and compare the characteristics of SR against other recommendation tasks. Then, we summarize the existing methods in two categories: sequential neural network based methods and graph neural network (GNN) based methods. The relevant frameworks and technical details are further introduced. Finally, we discuss the challenges of SR and new research directions in this area.},
	number = {2},
	journal = {ACM Comput. Surv.},
	author = {Li, Zihao and Yang, Chao and Chen, Yakun and Wang, Xianzhi and Chen, Hongxu and Xu, Guandong and Yao, Lina and Sheng, Michael},
	month = nov,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {graph neural networks, Recommendation survey, sequential neural networks, session-based recommendation},
}

@article{stalnaker_developer_2025,
	title = {Developer {Perspectives} on {Licensing} and {Copyright} {Issues} {Arising} from {Generative} {AI} for {Software} {Development}},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3743133},
	doi = {10.1145/3743133},
	abstract = {Despite the utility that Generative AI (GenAI) tools provide for tasks such as writing code, the use of these tools raises important legal questions and potential risks, particularly those associated with copyright law. As lawmakers and regulators respond to these questions, the views of users can offer relevant perspectives. In this paper, we provide: (1) a survey of 574 developers on the licensing and copyright aspects of GenAI for coding, as well as follow-up interviews; (2) a snapshot of developers’ views at a time when GenAI and perceptions of it were rapidly evolving; and (3) an analysis of developers’ perspectives, yielding insights and recommendations that can inform future regulatory decisions in this evolving field. Our results show the benefits developers derive from GenAI, how they view the use of AI-generated code as similar to using other existing code, the varied opinions they have on who should own or be compensated for such code, that they are concerned about data leakage via GenAI, and other findings, providing organizations and policymakers with valuable insights into how the technology is being used and the concerns that stakeholders believe warrant attention.},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Stalnaker, Trevor and Wintersgill, Nathan and Chaparro, Oscar and Heymann, Laura A. and Di Penta, Massimiliano and German, Daniel M and Poshyvanyk, Denys},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {generative ai, large language models, machine learning, open-source software, qualitative research},
	annote = {Just Accepted},
}

@article{qiao_multi-view_2025,
	title = {Multi-view {Intent} {Learning} and {Alignment} with {Large} {Language} {Models} for {Session}-based {Recommendation}},
	volume = {43},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/3719344},
	doi = {10.1145/3719344},
	abstract = {Session-based recommendation (SBR) methods often rely on user behavior data, which can struggle with the sparsity of session data, limiting performance. Researchers have identified that beyond behavioral signals, rich semantic information in item descriptions is crucial for capturing hidden user intent. While Large Language Models (LLMs) offer new ways to leverage this semantic data, the challenges of session anonymity, short-sequence nature, and high LLM training costs have hindered the development of a lightweight, efficient LLM framework for SBR.To address the above challenges, we propose an LLM-enhanced SBR framework that integrates semantic and behavioral signals from multiple views. This two-stage framework leverages the strengths of both LLMs and traditional SBR models while minimizing training costs. In the first stage, we use multi-view prompts to infer latent user intentions at the session semantic level, supported by an intent localization module to alleviate LLM hallucinations. In the second stage, we align and unify these semantic inferences with behavioral representations, effectively merging insights from both large and small models. Extensive experiments on two real datasets demonstrate that the LLM4SBR framework can effectively improve model performance. We release our codes along with the baselines at .},
	number = {4},
	journal = {ACM Trans. Inf. Syst.},
	author = {Qiao, Shutong and Zhou, Wei and Wen, Junhao and Gao, Chen and Luo, Qun and Chen, Peixuan and Li, Yong},
	month = may,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Data Augmentation, Large Language Models, Recommender System, Session-based Recommendation},
}

@article{gomes_lopes_exploring_2025,
	title = {Exploring {Large} {Language} {Models} for {Hierarchical} {Hardware} {Circuit} and {Testbench} {Generation}},
	volume = {30},
	issn = {1084-4309},
	url = {https://doi.org/10.1145/3742430},
	doi = {10.1145/3742430},
	abstract = {Designing and verifying hardware circuits using a Hardware Description Language (HDL) is an essential but time-consuming part of hardware design. Generating the desired correct circuit and testbench code usually requires a significant engineering effort. Recently, Large Language Models (LLMs) have claimed to have strong code generation capabilities to reduce such engineering costs. Existing work has provided quantitative evaluations using LLMs for single-module, simple circuit generation. However, it is still unclear whether modern LLMs are useful in production workflows, e.g., generating correct hierarchical circuits with testbenches. And if they are capable, what are the best prompt engineering practices for hardware design? In this article, we evaluate LLMs for HDL generation by exploring a 3-dimensional design space: commercial and open-source language models, single-module and hierarchical circuits, and prompting methods with varying complexity. We propose a 3-step design space exploration methodology to answer the two aforementioned questions. First, we explore the best prompt engineering practices across generating simple, middle, and hard single-module circuits with testbenches on CodeLLama-34B. We also define two fine-grained checklists to evaluate the circuit and testbench quality from a user’s perspective. Second, we benchmark 11 LLMs with prompt adaptation on 4 single-module circuits that CodeLLama-34B has trouble with to further find models that may be useful in a production workflow. Third, we apply the learned prompt practices on four top-level models to generate simple 2 to 4-module and more complex multi-module hierarchical circuits and testbenches. As a result, we find that some of the latest LLMs can generate correct simple hierarchical circuits and testbenches with given proper prompts, but still struggle with complex hierarchical circuits. We further provide useful guidelines from an end-user’s perspective on leveraging LLMs for hardware design.},
	number = {6},
	journal = {ACM Trans. Des. Autom. Electron. Syst.},
	author = {Gomes Lopes, Samuel and Zhu, Shien and Alonso, Gustavo},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {electronic design automation (EDA), hardware description language (HDL), Large language models (LLMs)},
}

@article{raza_improving_2023,
	title = {Improving {Clinical} {Decision} {Making} {With} a {Two}-{Stage} {Recommender} {System}},
	volume = {21},
	issn = {1545-5963},
	url = {https://doi.org/10.1109/TCBB.2023.3318209},
	doi = {10.1109/TCBB.2023.3318209},
	abstract = {Clinical decision-making is complex and time-intensive. To help in this effort, clinical recommender systems (RS) have been designed to facilitate healthcare practitioners with personalized advice. However, designing an effective clinical RS poses challenges due to the multifaceted nature of clinical data and the demand for tailored recommendations. In this article, we introduce a 2-Stage Recommendation framework for clinical decision-making, which leverages a publicly accessible dataset of electronic health records. In the first stage, a deep neural network-based model is employed to extract a set of candidate items, such as diagnoses, medications, and prescriptions, from a patient's electronic health records. Subsequently, the second stage utilizes a deep learning model to rank and pinpoint the most relevant items for healthcare providers. Both retriever and ranker are based on pre-trained transformer models that are stacked together as a pipeline. To validate our model, we compared its performance against several baseline models using different evaluation metrics. The results reveal that our proposed model attains a performance gain of approximately 12.3\% macro-average F1 compared to the second best performing baseline. Qualitative analysis across various dimensions also confirms the model's high performance. Furthermore, we discuss challenges like data availability, privacy concerns, and shed light on future exploration in this domain.},
	number = {5},
	journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
	author = {Raza, Shaina and Ding, Chen},
	month = sep,
	year = {2023},
	note = {Place: Washington, DC, USA
Publisher: IEEE Computer Society Press},
	pages = {1180--1190},
}

@article{pereira_inacia_2025,
	title = {{INACIA}: {Integrating} {Large} {Language} {Models} in {Brazilian} {Audit} {Courts}: {Opportunities} and {Challenges}},
	volume = {6},
	url = {https://doi.org/10.1145/3652951},
	doi = {10.1145/3652951},
	abstract = {This article introduces Instrução Assistida com Inteligência Artificial (INACIA), a groundbreaking system designed to integrate Large Language Models (LLMs) into the operational framework of Brazilian Federal Court of Accounts. The system automates various stages of case analysis, including basic information extraction, admissibility examination, Periculum in mora and Fumus boni iuris analyses, and recommendations generation. Through a series of experiments, we demonstrate INACIA’s potential in extracting relevant information from case documents, evaluating its legal plausibility, and formulating propositions for judicial decision-making. Utilizing a validation dataset alongside LLMs, our evaluation methodology, to the best of our knowledge, presents a novel approach to assessing system performance, correlating highly with human judgment. These results underscore INACIA’s potential in complex legal task handling while also acknowledging the current limitations. This study discusses possible improvements and the broader implications of applying Artificial Intelligence (AI) in legal contexts, suggesting that INACIA represents a significant step toward integrating AI in legal systems globally, albeit with cautious optimism grounded in the empirical findings.},
	number = {1},
	journal = {Digit. Gov.: Res. Pract.},
	author = {Pereira, Jayr and Assumpcao, Andre and Trecenti, Julio and Airosa, Luiz and Lente, Caio and Cléto, Jhonatan and Dobins, Guilherme and Nogueira, Rodrigo and Mitchell, Luis and Lotufo, Roberto},
	month = feb,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {AI in Legal Systems, Artificial Intelligence-Assisted Legal Instruction, Brazilian Federal Court of Accounts (TCU), Large Language Models (LLMs)},
}

@article{bayram_healthcare-focused_2025,
	title = {Healthcare-{Focused} {Turkish} {Medical} {LLM}: {Training} on {Real} {Patient}-{Doctor} {Question}-{Answer} {Data} for {Enhanced} {Medical} {Insight}},
	issn = {2375-4699},
	url = {https://doi.org/10.1145/3772000},
	doi = {10.1145/3772000},
	abstract = {The development of a Turkish-specific Large Language Model (LLM) for healthcare presents a unique opportunity to enhance AI’s accessibility and relevance for Turkish-speaking medical practitioners and patients. This study introduces a specialized Turkish Medical LLM fine-tuned on over 167,732 real patient-doctor question-answer pairs sourced from a trusted medical platform and capturing authentic linguistics in Turkish medical language. Utilizing models like LLAMA 3, the fine-tuning process was supported by Low-Rank Adaptation (LoRA) and involved innovative methods to mitigate catastrophic forgetting, including spherical linear interpolation (Slerp) merging. Evaluation of the model’s performance through similarity scores, GPT-3.5 assessments, and expert reviews indicates significant improvement in the model’s ability to generate medically accurate responses. This Turkish Medical LLM demonstrates potential to support medical decision-making and patient interaction in Turkish healthcare settings, offering an essential resource for enhancing AI inclusivity across languages.},
	journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
	author = {Bayram, M. Ali and Diri, Banu and Yildirim, Savas},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {catastrophic forgetting, healthcare AI, Low-Rank Adaptation, model fine-tuning, patient-doctor interactions, Turkish Medical LLM},
	annote = {Just Accepted},
}

@article{jones_shred_2022,
	title = {{SHRED}: {3D} {Shape} {Region} {Decomposition} with {Learned} {Local} {Operations}},
	volume = {41},
	issn = {0730-0301},
	url = {https://doi.org/10.1145/3550454.3555440},
	doi = {10.1145/3550454.3555440},
	abstract = {We present SHRED, a method for 3D SHape REgion Decomposition. SHRED takes a 3D point cloud as input and uses learned local operations to produce a segmentation that approximates fine-grained part instances. We endow SHRED with three decomposition operations: splitting regions, fixing the boundaries between regions, and merging regions together. Modules are trained independently and locally, allowing SHRED to generate high-quality segmentations for categories not seen during training. We train and evaluate SHRED with fine-grained segmentations from PartNet; using its merge-threshold hyperparameter, we show that SHRED produces segmentations that better respect ground-truth annotations compared with baseline methods, at any desired decomposition granularity. Finally, we demonstrate that SHRED is useful for downstream applications, out-performing all baselines on zero-shot fine-grained part instance segmentation and few-shot finegrained semantic segmentation when combined with methods that learn to label shape regions.},
	number = {6},
	journal = {ACM Trans. Graph.},
	author = {Jones, R. Kenny and Habib, Aalia and Ritchie, Daniel},
	month = nov,
	year = {2022},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {fine-grained components, shape analysis, shape segmentation},
}

@article{cuevas_collecting_2025,
	title = {Collecting {Qualitative} {Data} at {Scale} with {Large} {Language} {Models}: {A} {Case} {Study}},
	volume = {9},
	url = {https://doi.org/10.1145/3710947},
	doi = {10.1145/3710947},
	abstract = {Chatbots have shown promise as tools to scale qualitative data collection. Recent advances in Large Language Models (LLMs) could accelerate this process by allowing researchers to easily deploy sophisticated interviewing chatbots. We test this assumption by conducting a large-scale user study (n=399) evaluating 3 different chatbots, two of which are LLM-based and a baseline which employs hard-coded questions. We evaluate the results with respect to participant engagement and experience, established metrics of chatbot quality grounded in theories of effective communication, and a novel scale evaluating ”richness” or the extent to which responses capture the complexity and specificity of the social context under study. We find that, while the chatbots were able to elicit high-quality responses based on established evaluation metrics, the responses rarely capture participants' specific motives or personalized examples, and thus perform poorly with respect to richness. We further find low inter-rater reliability between LLMs and humans in the assessment of both quality and richness metrics. Our study offers a cautionary tale for scaling and evaluating qualitative research with LLMs.},
	number = {2},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Cuevas, Alejandro and Scurrell, Jennifer V. and Brown, Eva M. and Entenmann, Jason and Daepp, Madeleine I. G.},
	month = may,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {chatbots, gpt, language models, qualitative research},
}

@article{sicari_open-ethical_2024,
	title = {Open-{Ethical} {AI}: {Advancements} in {Open}-{Source} {Human}-{Centric} {Neural} {Language} {Models}},
	volume = {57},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3703454},
	doi = {10.1145/3703454},
	abstract = {This survey summarises the most recent methods for building and assessing helpful, honest, and harmless neural language models, considering small, medium, and large-size models. Pointers to open-source resources that help to align pre-trained models are given, including methods that use parameter-efficient techniques, specialized prompting frameworks, adapter modules, case-specific knowledge injection, and adversarially robust training techniques. Special care is given to evidencing recent progress on value alignment, commonsense reasoning, factuality enhancement, and abstract reasoning of language models. Most reviewed works in this survey publicly shared their code and related data and were accepted in world-leading Machine Learning venues. This work aims at helping researchers and practitioners accelerate their entrance into the field of human-centric neural language models, which might be a cornerstone of the contemporary and near-future industrial and societal revolution.},
	number = {4},
	journal = {ACM Comput. Surv.},
	author = {Sicari, Sabrina and Cevallos M., Jesus F. and Rizzardi, Alessandra and Coen-Porisini, Alberto},
	month = dec,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {human-centric AI, large-language models, Neural language models, open-source},
}

@article{ren_conversations_2021,
	title = {Conversations with {Search} {Engines}: {SERP}-based {Conversational} {Response} {Generation}},
	volume = {39},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/3432726},
	doi = {10.1145/3432726},
	abstract = {In this article, we address the problem of answering complex information needs by conducting conversations with search engines, in the sense that users can express their queries in natural language and directly receive the information they need from a short system response in a conversational manner. Recently, there have been some attempts towards a similar goal, e.g., studies on Conversational Agents (CAs) and Conversational Search (CS). However, they either do not address complex information needs in search scenarios or they are limited to the development of conceptual frameworks and/or laboratory-based user studies.We pursue two goals in this article: (1)the creation of a suitable dataset, the Search as a Conversation (SaaC) dataset, for the development of pipelines for conversations with search engines, and(2)the development of a state-of-the-art pipeline for conversations with search engines, Conversations with Search Engines (CaSE), using this dataset. SaaC is built based on a multi-turn conversational search dataset, where we further employ workers from a crowdsourcing platform to summarize each relevant passage into a short, conversational response. CaSE enhances the state-of-the-art by introducing a supporting token identification module and a prior-aware pointer generator, which enables us to generate more accurate responses.We carry out experiments to show that CaSE is able to outperform strong baselines. We also conduct extensive analyses on the SaaC dataset to show where there is room for further improvement beyond CaSE. Finally, we release the SaaC dataset and the code for CaSE and all models used for comparison to facilitate future research on this topic.},
	number = {4},
	journal = {ACM Trans. Inf. Syst.},
	author = {Ren, Pengjie and Chen, Zhumin and Ren, Zhaochun and Kanoulas, Evangelos and Monz, Christof and De Rijke, Maarten},
	month = aug,
	year = {2021},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Conversational modeling, dataset, neural model, search engine},
}

@article{formosa_generative_2025,
	title = {Generative {AI} and the {Future} of {Democratic} {Citizenship}},
	volume = {6},
	url = {https://doi.org/10.1145/3674844},
	doi = {10.1145/3674844},
	abstract = {Generative Artificial Intelligence (AI) technologies have the potential to be socially and politically transformative. In this article, we focus on exploring the potential impacts that Generative AI could have on the functioning of our democracies and the nature of citizenship. We do so by drawing on accounts of deliberative democracy and the deliberative virtues associated with it, as well as the reciprocal impacts that social media and Generative AI will have on each other and the broader information landscape. Drawing on this background theory, we outline some of the key positive and negative impacts that Generative AI is likely to have on democratic citizenship. The political significance of these impacts suggests the need for further regulation.},
	number = {2},
	journal = {Digit. Gov.: Res. Pract.},
	author = {Formosa, Paul and Kashyap, Bhanuraj and Sahebi, Siavosh},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {citizenship, deliberative democracy, Generative AI, Large Language Models (LLM), social media},
}

@article{pinckney_revisiting_2025,
	title = {Revisiting {VerilogEval}: {A} {Year} of {Improvements} in {Large}-{Language} {Models} for {Hardware} {Code} {Generation}},
	volume = {30},
	issn = {1084-4309},
	url = {https://doi.org/10.1145/3718088},
	doi = {10.1145/3718088},
	abstract = {The application of large language models (LLMs) to digital hardware code generation is an emerging field, with most LLMs primarily trained on natural language and software code. Hardware code like Verilog constitutes a small portion of training data, and few hardware benchmarks exist. The open-source VerilogEval benchmark, released in November 2023, provided a consistent evaluation framework for LLMs on code completion tasks. Since then, both commercial and open models have seen significant development.In this work, we evaluate new commercial and open models since VerilogEval’s original release—including GPT-4o, GPT-4 Turbo, Llama3.1 (8B/70B/405B), Llama3 70B, Mistral Large, DeepSeek Coder (33B and 6.7B), CodeGemma 7B, and RTL-Coder—against an improved VerilogEval benchmark suite. We find measurable improvements in state-of-the-art models: GPT-4o achieves a 63\% pass rate on specification-to-RTL tasks. The recently released and open Llama3.1 405B achieves a 58\% pass rate, almost matching GPT-4o, while the smaller domain-specific RTL-Coder 6.7B models achieve an impressive 34\% pass rate.Additionally, we enhance VerilogEval’s infrastructure by automatically classifying failures, introducing in-context learning support, and extending the tasks to specification-to-RTL translation. We find that prompt engineering remains crucial for achieving good pass rates and varies widely with model and task. A benchmark infrastructure that allows for prompt engineering and failure analysis is essential for continued model development and deployment.},
	number = {6},
	journal = {ACM Trans. Des. Autom. Electron. Syst.},
	author = {Pinckney, Nathaniel and Batten, Christopher and Liu, Mingjie and Ren, Haoxing and Khailany, Brucek},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {benchmarks, Large language models, RTL code generation},
}

@article{esterle_loosening_2022,
	title = {Loosening {Control}—{A} {Hybrid} {Approach} to {Controlling} {Heterogeneous} {Swarms}},
	volume = {16},
	issn = {1556-4665},
	url = {https://doi.org/10.1145/3502725},
	doi = {10.1145/3502725},
	abstract = {Large pervasive systems, deployed in dynamic environments, require flexible control mechanisms to meet the demands of chaotic state changes while accomplishing system goals. As centralized control approaches may falter in environments where centralized communication and knowledge may be impossible to implement, researchers have proposed decentralized control methods that leverage agent-driven, self-organizing behaviors, to achieve reliable, flexible systems. This article presents and compares the performance of three decentralized control approaches in the online multi-object k-assignment problem. In this domain, a set of sensors is tasked to detect and track an unknown and changing set of targets. Results show that a proposed hybrid approach that incorporates supervisory devices within the population while allowing semi-autonomous operations in non-supervisory devices produces a flexible and reliable system capable of both high detection and coverage rates.},
	number = {2},
	journal = {ACM Trans. Auton. Adapt. Syst.},
	author = {Esterle, Lukas and King, David W.},
	month = mar,
	year = {2022},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {autonomous systems, decentralized control, distributed control, fog computing, hybrid control, mobile pervasive systems, online multi-object k-assignment, Self-organisation},
}

@article{bonifati_versatile_2025,
	title = {Versatile {Property} {Graph} {Transformations}},
	volume = {18},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3750601.3760517},
	doi = {10.14778/3750601.3760517},
	abstract = {Property graphs are key components of modern graph database systems as well as graph analytical systems. They support highly expressive data models consisting of multi-labeled nodes and edges, along with properties represented as key/value pairs. Property graphs serve as versatile data integration paradigms, enabling data in any format to be seamlessly transformed into this model. Moreover, they are at the core of an active standardization effort led by ISO/IEC, which aims to establish standardized declarative graph query languages such as GQL and SQL/PGQ. In addition to these standards for data manipulation languages, other languages have emerged for property graph schemas and constraints as part of future data definition languages.In this paper, we introduce a new declarative paradigm for expressing property graph transformations, supporting both graph data integration and data cleaning tasks. We discuss the properties of these transformations, along with algorithmic issues and considerations for efficiency and scalability. Furthermore, we showcase the utility of property graph transformations for causal analysis and elaborate on a research agenda aimed at designing analytical extensions of graph languages to support property graph transformations for advanced analytical workloads on heterogeneous data.},
	number = {12},
	journal = {Proc. VLDB Endow.},
	author = {Bonifati, Angela},
	month = sep,
	year = {2025},
	note = {Publisher: VLDB Endowment},
	pages = {5516--5526},
}

@article{zhou_d-bot_2024,
	title = {D-{Bot}: {Database} {Diagnosis} {System} using {Large} {Language} {Models}},
	volume = {17},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3675034.3675043},
	doi = {10.14778/3675034.3675043},
	abstract = {Database administrators (DBAs) play an important role in managing database systems. However, it is hard and tedious for DBAs to manage vast database instances and give timely response (waiting for hours is intolerable in many online cases). In addition, existing empirical methods only support limited diagnosis scenarios, which are also labor-intensive to update the diagnosis rules for database version updates. Recently large language models (LLMs) have shown great potential in various fields. Thus, we propose D-Bot, an LLM-based database diagnosis system that can automatically acquire knowledge from diagnosis documents, and generate reasonable and well-founded diagnosis report (i.e., identifying the root causes and solutions) within acceptable time (e.g., under 10 minutes compared to hours by a DBA). The techniques in D-Bot include (i) offline knowledge extraction from documents, (ii) automatic prompt generation (e.g., knowledge matching, tool retrieval), (iii) root cause analysis using tree search algorithm, and (iv) collaborative mechanism for complex anomalies with multiple root causes. We verify D-Bot on real benchmarks (including 539 anomalies of six typical applications), and the results show D-Bot can effectively identify root causes of unseen anomalies and significantly outperforms traditional methods and vanilla models like GPT-4.},
	number = {10},
	journal = {Proc. VLDB Endow.},
	author = {Zhou, Xuanhe and Li, Guoliang and Sun, Zhaoyan and Liu, Zhiyuan and Chen, Weize and Wu, Jianming and Liu, Jiesi and Feng, Ruohang and Zeng, Guoyang},
	month = jun,
	year = {2024},
	note = {Publisher: VLDB Endowment},
	pages = {2514--2527},
}

@article{wang_knowledge_2024,
	title = {Knowledge {Editing} for {Large} {Language} {Models}: {A} {Survey}},
	volume = {57},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3698590},
	doi = {10.1145/3698590},
	abstract = {Large Language Models (LLMs) have recently transformed both the academic and industrial landscapes due to their remarkable capacity to understand, analyze, and generate texts based on their vast knowledge and reasoning ability. Nevertheless, one major drawback of LLMs is their substantial computational cost for pre-training due to their unprecedented amounts of parameters. The disadvantage is exacerbated when new knowledge frequently needs to be introduced into the pre-trained model. Therefore, it is imperative to develop effective and efficient techniques to update pre-trained LLMs. Traditional methods encode new knowledge in pre-trained LLMs through direct fine-tuning. However, naively re-training LLMs can be computationally intensive and risks degenerating valuable pre-trained knowledge irrelevant to the update in the model. Recently, Knowledge-based Model Editing (KME), also known as Knowledge Editing or Model Editing, has attracted increasing attention, which aims at precisely modifying the LLMs to incorporate specific knowledge, without negatively influencing other irrelevant knowledge. In this survey, we aim at providing a comprehensive and in-depth overview of recent advances in the field of KME. We first introduce a general formulation of KME to encompass different KME strategies. Afterward, we provide an innovative taxonomy of KME techniques based on how the new knowledge is introduced into pre-trained LLMs, and investigate existing KME strategies while analyzing key insights, advantages, and limitations of methods from each category. Moreover, representative metrics, datasets, and applications of KME are introduced accordingly. Finally, we provide an in-depth analysis regarding the practicality and remaining challenges of KME and suggest promising research directions for further advancement in this field.},
	number = {3},
	journal = {ACM Comput. Surv.},
	author = {Wang, Song and Zhu, Yaochen and Liu, Haochen and Zheng, Zaiyi and Chen, Chen and Li, Jundong},
	month = nov,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {fine-tuning, knowledge update, large language models, Model editing},
}

@article{madden_databases_2024,
	title = {Databases {Unbound}: {Querying} {All} of the {World}'s {Bytes} with {AI}},
	volume = {17},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3685800.3685916},
	doi = {10.14778/3685800.3685916},
	abstract = {Over the past five decades, the relational database model has proven to be a scaleable and adaptable model for querying a variety of structured data, with use cases in analytics, transactions, graphs, streaming and more. However, most of the world's data is unstructured. Thus, despite their success, the reality is that the vast majority of the world's data has remained beyond the reach of relational systems.The rise of deep learning and generative AI offers an opportunity to change this. These models provide a stunning capability to extract semantic understanding from almost any type of document, including text, images, and video, which can extend the reach of databases to all the world's data. In this paper we explore how these new technologies will transform the way we build database management software, creating new that systems that can ingest, store, process, and query all data. Building such systems presents many opportunities and challenges. In this paper we focus on three: scalability, correctness, and reliability, and argue that the declarative programming paradigm that has served relational systems so well offers a path forward in the new world of AI data systems as well. To illustrate this, we describe several examples of such declarative AI systems we have built in document and video processing, and provide a set of research challenges and opportunities to guide research in this exciting area going forward.And lovely apparitions, -dim at first,Then radiant, as the mind arising brightFrom the embrace of beauty (whence the formsOf which these are the phantoms) casts on themThe gathered rays which are reality-Shall visit us the progeny immortalOf Painting, Sculpture, and rapt Poesy,And arts, though unimagined, yet to be;Prometheus Unbound, Percy Bysshe Shelley},
	number = {12},
	journal = {Proc. VLDB Endow.},
	author = {Madden, Samuel and Cafarella, Michael and Franklin, Michael and Kraska, Tim},
	month = aug,
	year = {2024},
	note = {Publisher: VLDB Endowment},
	pages = {4546--4554},
}

@article{sun_gaussdb-vector_2025,
	title = {{GaussDB}-{Vector}: {A} {Large}-{Scale} {Persistent} {Real}-{Time} {Vector} {Database} for {LLM} {Applications}},
	volume = {18},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3750601.3750619},
	doi = {10.14778/3750601.3750619},
	abstract = {Vector databases are widely used as a fundamental tool for addressing the weaknesses of large language model (LLM) applications, specifically hallucinations and the high cost of inference. However, existing vector databases either cater to niche applications with low-latency in-memory search, or offer sophisticated data management capabilities but at the cost of low performance.To address these limitations, we propose GaussDB-Vector, a high-performance, real-time persistent vector database that excels in low-latency scalable search, real-time inserts and deletes, high availability, large-scale distributed search, and hybrid scalar-vector filtered search capabilities. These features are primarily achieved through an innovative storage architecture designed for a graph-based vector index, optimized for I/O operations and adaptable across various dataset sizes and dimensions, complemented by novel buffering strategies to further reduce I/O burdens. GaussDB-Vector supports product quantization, parallel search, and hardware acceleration via SIMD, GPUs, and NPUs in order to further accelerate queries. Experimental results show that GaussDB-Vector outperforms competitive baselines by a factor of 1 to 5 times.},
	number = {12},
	journal = {Proc. VLDB Endow.},
	author = {Sun, Ji and Li, Guoliang and Pan, James and Wang, Jiang and Xie, Yongqing and Liu, Ruicheng and Nie, Wen},
	month = sep,
	year = {2025},
	note = {Publisher: VLDB Endowment},
	pages = {4951--4963},
}

@article{thulke_task-oriented_2023,
	title = {Task-{Oriented} {Document}-{Grounded} {Dialog} {Systems} by {HLTPR}@{RWTH} for {DSTC9} and {DSTC10}},
	volume = {32},
	issn = {2329-9290},
	url = {https://doi.org/10.1109/TASLP.2023.3267832},
	doi = {10.1109/TASLP.2023.3267832},
	abstract = {This paper summarizes our contributions to the document-grounded dialog tasks at the 9th and 10th Dialog System Technology Challenges (DSTC9 and DSTC10). In both iterations the task consists of three subtasks: first detect whether the current turn is knowledge seeking, second select a relevant knowledge document, and third generate a response grounded on the selected document. For DSTC9 we proposed different approaches to make the selection task more efficient. The best method, Hierarchical Selection, actually improves the results compared to the original baseline and gives a speedup of 24x. In the DSTC10 iteration of the task, the challenge was to adapt systems trained on written dialogs to perform well on noisy automatic speech recognition transcripts. Therefore, we proposed data augmentation techniques to increase the robustness of the models as well as methods to adapt the style of generated responses to fit well into the proceeding dialog. Additionally, we proposed a noisy channel model that allows for increasing the factuality of the generated responses. In addition to summarizing our previous contributions, in this work, we also report on a few small improvements and reconsider the automatic evaluation metrics for the generation task which have shown a low correlation to human judgments.},
	journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
	author = {Thulke, David and Daheim, Nico and Dugast, Christian and Ney, Hermann},
	month = apr,
	year = {2023},
	note = {Publisher: IEEE Press},
	pages = {733--741},
}

@article{happe_can_2025,
	title = {Can {LLMs} {Hack} {Enterprise} {Networks}? {Autonomous} {Assumed} {Breach} {Penetration}-{Testing} {Active} {Directory} {Networks}},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3766895},
	doi = {10.1145/3766895},
	abstract = {Traditional enterprise penetration-testing, while critical for validating defenses and uncovering vulnerabilities, is often limited by high operational costs and the scarcity of human expertise. This paper investigates the feasibility and effectiveness of using Large Language Model (LLM)-driven autonomous systems to address these challenges in real-world Active Directory (AD) enterprise networks.We introduce a novel prototype, cochise, designed to employ LLMs to autonomously perform Assumed Breach penetration-testing against enterprise networks. Our system represents the first demonstration of a fully autonomous, LLM-driven framework capable of compromising accounts within a real-life Microsoft Active Directory testbed, the Game of Active Directory (GOAD). The evaluation deliberately utilizes GOAD to capture the intricate interactions and sometimes nondeterministic outcomes of live network penetration-testing, moving beyond the limitations of synthetic benchmarks.We perform our empirical evaluation using five LLMs, comparing reasoning to non-reasoning models as well as including open-weight models. Through comprehensive quantitative and qualitative analysis, incorporating insights from cybersecurity experts, we demonstrate that autonomous LLMs can effectively conduct Assumed Breach simulations. Key findings highlight their ability to dynamically adapt attack strategies, perform inter-context attacks (e.g., web application audits, social engineering, and unstructured data analysis for credentials), and generate scenario-specific attack parameters like realistic password candidates. The prototype also exhibits robust self-correction mechanisms, automatically installing missing tools and rectifying invalid command generations.Critically, we find that the associated costs are competitive with, and often significantly lower than, those incurred by professional human penetration testers, suggesting a path toward democratizing access to essential security testing for organizations with budgetary constraints. However, our research also illuminates existing limitations, including instances of LLM “going down rabbit holes”, challenges in comprehensive information transfer between planning and execution modules, and critical safety concerns that necessitate human oversight. Our findings lay foundational groundwork for future software engineering research into LLM-driven cybersecurity automation, emphasizing that the prototype's underlying LLM-driven architecture and techniques are domain-agnostic and hold promise for improving autonomous LLM usage in broader software engineering domains. The source code, traces, and analyzed logs are open-sourced to foster collective cybersecurity and future research.},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Happe, Andreas and Cito, Jürgen},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Enterprise Networks, Large Language Models, Security Capability Evaluation},
	annote = {Just Accepted},
}

@article{li_generative_2024,
	title = {Generative {AI} for {Self}-{Adaptive} {Systems}: {State} of the {Art} and {Research} {Roadmap}},
	volume = {19},
	issn = {1556-4665},
	url = {https://doi.org/10.1145/3686803},
	doi = {10.1145/3686803},
	abstract = {Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this article aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI’s within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.†},
	number = {3},
	journal = {ACM Trans. Auton. Adapt. Syst.},
	author = {Li, Jialong and Zhang, Mingyue and Li, Nianyu and Weyns, Danny and Jin, Zhi and Tei, Kenji},
	month = sep,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {diffusion model, Generative AI, Large Language Model, MAPE, Self-Adaptive Systems, survey},
}

@article{gruetzemacher_deep_2022,
	title = {Deep {Transfer} {Learning} \&amp; {Beyond}: {Transformer} {Language} {Models} in {Information} {Systems} {Research}},
	volume = {54},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3505245},
	doi = {10.1145/3505245},
	abstract = {AI is widely thought to be poised to transform business, yet current perceptions of the scope of this transformation may be myopic. Recent progress in natural language processing involving transformer language models (TLMs) offers a potential avenue for AI-driven business and societal transformation that is beyond the scope of what most currently foresee. We review this recent progress as well as recent literature utilizing text mining in top IS journals to develop an outline for how future IS research can benefit from these new techniques. Our review of existing IS literature reveals that suboptimal text mining techniques are prevalent and that the more advanced TLMs could be applied to enhance and increase IS research involving text data, and to enable new IS research topics, thus creating more value for the research community. This is possible because these techniques make it easier to develop very powerful custom systems and their performance is superior to existing methods for a wide range of tasks and applications. Further, multilingual language models make possible higher quality text analytics for research in multiple languages. We also identify new avenues for IS research, like language user interfaces, that may offer even greater potential for future IS research.},
	number = {10s},
	journal = {ACM Comput. Surv.},
	author = {Gruetzemacher, Ross and Paradice, David},
	month = sep,
	year = {2022},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {artificial intelligence, deep learning, language models, Natural language processing, text mining, transfer learning},
}

@article{xu_tapping_2025,
	title = {Tapping the {Potential} of {Large} {Language} {Models} as {Recommender} {Systems}: {A} {Comprehensive} {Framework} and {Empirical} {Analysis}},
	volume = {19},
	issn = {1556-4681},
	url = {https://doi.org/10.1145/3726871},
	doi = {10.1145/3726871},
	abstract = {Recently, Large Language Models (LLMs) such as ChatGPT have showcased remarkable abilities in solving general tasks, demonstrating the potential for applications in recommender systems. To assess how effectively LLMs can be used in recommendation tasks, our study primarily focuses on employing LLMs as recommender systems through prompt engineering. We propose a general framework for leveraging LLMs in recommendation tasks, focusing on the capabilities of LLMs as recommenders. To conduct our analysis, we formalize the input of LLMs for recommendation into natural language prompts with two key aspects and explain how our framework can be generalized to various recommendation scenarios. As for the use of LLMs as recommenders, we analyze the impact of public availability, tuning strategies, model architecture, parameter scale, and context length on recommendation results based on the classification of LLMs. As for prompt engineering, we further analyze the impact of four important components of prompts, i.e., task descriptions, user interest modeling, candidate items construction, and prompting strategies. In each section, we first define and categorize concepts in line with the existing literature. Then, we propose inspiring research questions followed by detailed experiments on two public datasets, in order to systematically analyze the impact of different factors on recommendation performance. Based on our empirical analysis, we finally summarize promising directions to shed lights on future research.},
	number = {5},
	journal = {ACM Trans. Knowl. Discov. Data},
	author = {Xu, Lanling and Zhang, Junjie and Li, Bingqian and Wang, Jinpeng and Chen, Sheng and Zhao, Wayne Xin and Wen, Ji-Rong},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Empirical Study, Large Language Models, Recommender Systems},
}

@article{duan_pgtuner_2025,
	title = {{PGTuner}: {An} {Efficient} {Framework} for {Automatic} and {Transferable} {Configuration} {Tuning} of {Proximity} {Graphs}},
	volume = {3},
	url = {https://doi.org/10.1145/3749179},
	doi = {10.1145/3749179},
	abstract = {Approximate Nearest Neighbor Search (ANNS) plays a crucial role in many key areas. Proximity graphs (PGs) are the leading method for ANNS, offering the best balance between query efficiency and accuracy. However, their performance heavily depends on various construction and query parameters, which are difficult to optimize due to their complex interdependencies. Given that users often prioritize specific accuracy levels, efficiently identifying the optimal PG configurations to meet these targets is essential. Although some studies have explored automatic configuration tuning for PGs, they are limited by inefficiencies and suboptimal results. These issues stem from the need to construct numerous PGs for searching and re-tuning from scratch whenever the dataset changes, as well as the failure to capture the complex dependencies between configurations, query performance, and tuning objectives. To address these challenges, we propose PGTuner, an efficient framework for automatic PG configuration tuning leveraging pre-training knowledge and model transfer techniques. PGTuner improves efficiency through a pre-trained query performance prediction (QPP) model, eliminating the need to build multiple PGs. It also features a deep reinforcement learning-based parameter configuration recommendation (PCR) model to recommend optimal configurations for specific datasets and accuracy targets. Additionally, PGTuner incorporates out-of-distribution detection and deep active learning for efficient tuning in dynamic scenarios and transferring to new datasets. Extensive experiments demonstrate that PGTuner can stably achieve the top-level tuning effect across different datasets while significantly improving tuning efficiency by up to 14.69X, with a 14.64X boost in dynamic scenarios. The code and data for PGTuner are available online at https://github.com/hao-duan/PGTuner.},
	number = {4},
	journal = {Proc. ACM Manag. Data},
	author = {Duan, Hao and Song, Yitong and Yao, Bin and Liang, Anqi},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {approximate nearest neighbor search, configuration tuning, model transfer, proximity graph},
}

@article{lang_leveraging_2025,
	title = {Leveraging {LLMs} for {Memory} {Forensics}: {A} {Comparative} {Analysis} of {Malware} {Detection}},
	url = {https://doi.org/10.1145/3748263},
	doi = {10.1145/3748263},
	abstract = {Memory forensics plays an important role in modern digital investigations in terms of detecting stealthy, fileless malware, and advanced persistent threats. Moreover, large language models (LLMs) have shown promise in different cybersecurity tasks. In this paper, we integrate intelligence based on LLM into memory forensic workflows and evaluate multiple LLMs, including OpenAI GPT4o, OpenAI o1, Gemini 2.0 Flash, Gemini 2.0 Flash-Thinking, Grok 3, and Grok 3 with thinking mode enabled. We collect memory dumps encompassing a variety of attack scenarios such as process injection (using msfvenom), a PowerShell Empire-based attack, and real-world malware such as Quasar RAT, MassLogger, DarkCloud, LockBit, and LockiBot. Our evaluation includes accuracy, precision, recall and F1 score metrics and statistical analyses (ANOVA and correlation tests). The findings show that the reasoning-based (’thinking’) LLM models outperform standard models. OpenAI o1 and Gemini Flash-Thinking excel at decoding base64 obfuscated payloads, while Grok3 leads in detecting network anomalies. All LLM-based approaches suffer from high false-positive (FP) rates, reflected in low precision (often \&lt;20\%). This tendency appears to stem from the precautionary principle in AI safety orientation, leading to models erring on the side of caution and occasionally hallucinating plausible threats when faced with ambiguous or incomplete evidence. The LockBit indicator of compromise (IoC) could not be detected with the LLM because the IoCs lie beyond the Volatility3 modules used. Due to this reason and the limited size of the context window from the LLM, it is essential to select appropriate data. Despite limitations, the study demonstrates the practical viability of integrating LLM-driven intelligence into a forensic system. The study lays the foundation for hybrid forensic systems combining symbolic analysis, domain-specific heuristics, and LLM-driven intelligence.},
	journal = {Digital Threats},
	author = {Lang, Jan-Hendrik and Schreck, Thomas},
	month = jul,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Digital Forensics, LLM, Malware, Memory Forensics, Volatility3},
	annote = {Just Accepted},
}

@article{hrckova_autonomation_2025,
	title = {Autonomation, {Not} {Automation}: {Activities} and {Needs} of {European} {Fact}-checkers as a {Basis} for {Designing} {Human}-centered {AI} {Systems}},
	url = {https://doi.org/10.1145/3764592},
	doi = {10.1145/3764592},
	abstract = {To mitigate the negative effects of false information more effectively, the development of Artificial Intelligence\&nbsp;(AI)\&nbsp;systems to assist fact-checkers is needed. Nevertheless, the lack of focus on the needs of these stakeholders results in their limited acceptance and skepticism toward automating the whole fact-checking process. In this study, we conducted semi-structured in-depth interviews with Central European fact-checkers. Their activities and problems were analyzed using iterative content analysis. The most significant problems were validated with a survey of European fact-checkers, in which we collected 24 responses from 20 countries, i.e., 62\% of active European signatories of the International Fact-Checking Network (IFCN). Our contributions include an in-depth examination of the variability of fact-checking work in non-English-speaking regions, which still remained largely uncovered. By aligning them with the knowledge from prior studies, we created conceptual models that help to understand the fact-checking processes. In addition, we mapped our findings on the fact-checkers’ activities and needs to the relevant tasks for AI research, while providing a discussion on three AI tasks that were not covered by previous similar studies. The new opportunities identified for AI researchers and developers have implications for the focus of AI research in this domain.},
	journal = {ACM J. Responsib. Comput.},
	author = {Hrckova, Andrea and Moro, Robert and Srba, Ivan and Simko, Jakub and Bielikova, Maria},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {disinformation, fact-checkers, human-centered artificial intelligence, human-information interaction, misinformation},
	annote = {Just Accepted},
}

@article{bai_kinet_2023,
	title = {{KINet}: {Incorporating} {Relevant} {Facts} {Into} {Knowledge}-{Grounded} {Dialog} {Generation}},
	volume = {31},
	issn = {2329-9290},
	url = {https://doi.org/10.1109/TASLP.2023.3240654},
	doi = {10.1109/TASLP.2023.3240654},
	abstract = {Knowledge-grounded conversation has led to great progress in producing informative dialog responses by leveraging external knowledge. This work focuses on two affiliated knowledge grounded conversation tasks: \&lt;italic\&gt;Knowledge Selection\&lt;/italic\&gt; and \&lt;italic\&gt;Response Generation\&lt;/italic\&gt;. Previous work followed the paradigm of selecting the most optimal knowledge piece to guide the conversation towards generating the proper response. However, some knowledge pieces, which are not recognized as optimal, may still benefit response generation. How to effectively leverage these relevant knowledge pieces for response generation still remain a tricky issue. To address this problem, we propose \&lt;sc\&gt;\&lt;bold\&gt;KINet\&lt;/bold\&gt;\&lt;/sc\&gt;, a \&lt;bold\&gt;K\&lt;/bold\&gt;nowledge \&lt;bold\&gt;I\&lt;/bold\&gt;ncorporation \&lt;bold\&gt;Net\&lt;/bold\&gt;work, which deals with the problem by boosting both the knowledge selection and the response generation. The proposed model contains a negative enhanced knowledge approximator which improves knowledge selection by enhancing the dense representation of knowledge pieces, and a curriculum knowledge sampler which improves generated responses by incorporating more relevant knowledge pieces in an easy-to-hard manner. We conduct the experiment on two datasets of knowledge-grounded conversations, the results show that the proposed model significantly outperforms state-of-the-art methods in terms of both automatic and human evaluations.},
	journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
	author = {Bai, Jiaqi and Yang, Ze and Yang, Jian and Guo, Hongcheng and Li, Zhoujun},
	month = jan,
	year = {2023},
	note = {Publisher: IEEE Press},
	pages = {1213--1222},
}

@article{ling_domain_2025,
	title = {Domain {Specialization} as the {Key} to {Make} {Large} {Language} {Models} {Disruptive}: {A} {Comprehensive} {Survey}},
	volume = {58},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3764579},
	doi = {10.1145/3764579},
	abstract = {Large language models (LLMs) have significantly advanced the field of natural language processing (NLP), providing a highly useful, task-agnostic foundation for a wide range of applications. However, directly applying LLMs to solve sophisticated problems in specific domains meets many hurdles, caused by the heterogeneity of domain data, the sophistication of domain knowledge, the uniqueness of domain objectives, and the diversity of the constraints (e.g., various social norms, cultural conformity, religious beliefs, and ethical standards in the domain applications). Domain specification techniques are key to making large language models disruptive in many applications. Specifically, to solve these hurdles, there has been a notable increase in research and practices conducted in recent years on the domain specialization of LLMs. This emerging field of study, with its substantial potential for impact, necessitates a comprehensive and systematic review to summarize better and guide ongoing work in this area. In this article, we present a comprehensive survey on domain specification techniques for large language models, an emerging direction critical for large language model applications. First, we propose a systematic taxonomy that categorizes the LLM domain-specialization techniques based on the accessibility to LLMs and summarizes the framework for all the subcategories as well as their relations and differences to each other. Second, we present an extensive taxonomy of critical application domains that can benefit dramatically from specialized LLMs, discussing their practical significance and open challenges. Last, we offer our insights into the current research status and future trends in this area.},
	number = {3},
	journal = {ACM Comput. Surv.},
	author = {Ling, Chen and Zhao, Xujiang and Lu, Jiaying and Deng, Chengyuan and Zheng, Can and Wang, Junxiang and Chowdhury, Tanmoy and Li, Yun and Cui, Hejie and Zhang, Xuchao and Zhao, Tianjiao and Panalkar, Amit and Mehta, Dhagash and Pasquali, Stefano and Cheng, Wei and Wang, Haoyu and Liu, Yanchi and Chen, Zhengzhang and Chen, Haifeng and White, Chris and Gu, Quanquan and Pei, Jian and Yang, Carl and Zhao, Liang},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {domain specialization, Large language models, natural language processing},
}

@article{fu_should_2025,
	title = {Should {ChatGPT} {Write} {Your} {Breakup} {Text}? {Exploring} the {Role} of {AI} in {Relationship} {Dissolution}},
	volume = {9},
	url = {https://doi.org/10.1145/3757424},
	doi = {10.1145/3757424},
	abstract = {Relationships are essential to our happiness and wellbeing, yet their dissolution-the final stage of a relationship's lifecycle-is among the most stressful events individuals can experience, often leading to profound and lasting impacts. With the breakup process increasingly facilitated by technology, such as computer-mediated communication, and the likely future influence of generative AI tools, we conducted a semi-structured interview study with 21 participants. We aim to understand: 1) the current role of technology in the breakup process, 2) the needs and support individuals seek during this time, and 3) how GenAI might address or undermine these needs. Our findings show that people have distinct needs at various stages of breakups. While currently technology plays an important role, it falls short in supporting users' unmet needs. Participants envision that GenAI could: 1) aid in prompting self-reflection, providing neutral second opinions, and assisting with planning leading up to a breakup; 2) serve as a communication mediator, supporting wording and tone to facilitate emotional expression during breakup conversations; and 3) support personal growth and offer companionship after a breakup. However, our findings also reveal participants' various concerns about involving GenAI in this process. Based on our results, we discuss the potential opportunities, harms, and design implications of GenAI tools in facilitating people's relationship dissolution.},
	number = {7},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Fu, Yue and Chen, Yixin and Gomes Da Costa Lai, Zelia and Hiniker, Alexis},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {ai-mediated relationship, breakup, generative ai, interview, mental health, recovery},
}

@article{ecormier-nocca_authoring_2021,
	title = {Authoring consistent landscapes with flora and fauna},
	volume = {40},
	issn = {0730-0301},
	url = {https://doi.org/10.1145/3450626.3459952},
	doi = {10.1145/3450626.3459952},
	abstract = {We present a novel method for authoring landscapes with flora and fauna while considering their mutual interactions. Our algorithm outputs a steady-state ecosystem in the form of density maps for each species, their daily circuits, and a modified terrain with eroded trails from a terrain, climatic conditions, and species with related biological information. We introduce the Resource Access Graph, a new data structure that encodes both interactions between food chain levels and animals traveling between resources over the terrain. A novel competition algorithm operating on this data progressively computes a steady-state solution up the food chain, from plants to carnivores. The user can explore the resulting landscape, where plants and animals are instantiated on the fly, and interactively edit it by over-painting the maps. Our results show that our system enables the authoring of consistent landscapes where the impact of wildlife is visible through animated animals, clearings in the vegetation, and eroded trails. We provide quantitative validation with existing ecosystems and a user-study with expert paleontologist end-users, showing that our system enables them to author and compare different ecosystems illustrating climate changes over the same terrain while enabling relevant visual immersion into consistent landscapes.},
	number = {4},
	journal = {ACM Trans. Graph.},
	author = {Ecormier-Nocca, Pierre and Cordonnier, Guillaume and Carrez, Philippe and Moigne, Anne-Marie and Memari, Pooran and Benes, Bedrich and Cani, Marie-Paule},
	month = jul,
	year = {2021},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {ecosystems, natural phenomena},
}

@article{zhang_recommendation_2025,
	title = {Recommendation as {Instruction} {Following}: {A} {Large} {Language} {Model} {Empowered} {Recommendation} {Approach}},
	volume = {43},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/3708882},
	doi = {10.1145/3708882},
	abstract = {In the past few decades, recommender systems have attracted much attention in both research and industry communities. Existing recommendation models mainly learn the underlying user preference from historical behavior data (typically in the forms of item IDs), and then estimate the user–item matching relationships for recommendations. Inspired by the recent progress on large language models (LLMs), we develop a different recommendation paradigm, considering recommendation as instruction following by LLMs. The key idea is that the needs of a user can be expressed in natural language descriptions (called instructions), so that LLMs can understand and further execute the instruction for fulfilling the recommendation. For this purpose, we instruction tune the 3B Flan-T5-XL, to better adapt LLMs to recommender systems. We first design a general instruction format for describing the preference, intention, and task form of a user in natural language. Then we manually design 39 instruction templates and automatically generate large amounts of user-personalized instruction data with varying types of preferences and intentions. To demonstrate the effectiveness of our approach, we instantiate the instructions into several widely studied recommendation (or search) tasks, and conduct extensive experiments with real-world datasets. Experiment results show that our approach can outperform several competitive baselines, including the powerful GPT-3.5, on these evaluation tasks. Our approach sheds light on developing user-friendly recommender systems, in which users can freely communicate with the system and obtain accurate recommendations via natural language instructions.},
	number = {5},
	journal = {ACM Trans. Inf. Syst.},
	author = {Zhang, Junjie and Xie, Ruobing and Hou, Yupeng and Zhao, Xin and Lin, Leyu and Wen, Ji-Rong},
	month = jul,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Instruction Tuning, Large Language Models, Recommender Systems},
}

@article{wong_decllm_2025,
	title = {{DecLLM}: {LLM}-{Augmented} {Recompilable} {Decompilation} for {Enabling} {Programmatic} {Use} of {Decompiled} {Code}},
	volume = {2},
	url = {https://doi.org/10.1145/3728958},
	doi = {10.1145/3728958},
	abstract = {Decompilers are widely used in reverse engineering (RE) to convert compiled executables into human-readable pseudocode and support various security analysis tasks. Existing decompilers, such as IDA Pro and Ghidra, focus on enhancing the readability of decompiled code rather than its recompilability, which limits further programmatic use, such as for CodeQL-based vulnerability analysis that requires compilable versions of the decompiled code. Recent LLM-based approaches for enhancing decompilation results, while useful for human RE analysts, unfortunately also follow the same path. In this paper, we explore, for the first time, how off-the-shelf large language models (LLMs) can be used to enable recompilable decompilation—automatically correcting decompiler outputs into compilable versions. We first show that this is non-trivial through a pilot study examining existing rule-based and LLM-based approaches. Based on the lessons learned, we design DecLLM, an iterative LLM-based repair loop that utilizes both static recompilation and dynamic runtime feedback as oracles to iteratively fix decompiler outputs. We test DecLLM on popular C benchmarks and real-world binaries using two mainstream LLMs, GPT-3.5 and GPT-4, and show that off-the-shelf LLMs can achieve an upper bound of around 70\% recompilation success rate, i.e., 70 out of 100 originally non-recompilable decompiler outputs are now recompilable. We also demonstrate the practical applicability of the recompilable code for CodeQL-based vulnerability analysis, which is impossible to perform directly on binaries. For the remaining 30\% of hard cases, we further delve into their errors to gain insights for future improvements in decompilation-oriented LLM design.},
	number = {ISSTA},
	journal = {Proc. ACM Softw. Eng.},
	author = {Wong, Wai Kin and Wu, Daoyuan and Wang, Huaijin and Li, Zongjie and Liu, Zhibo and Wang, Shuai and Tang, Qiyi and Nie, Sen and Wu, Shi},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Large Language Model, Recompilable Decompilation, Reverse Engineering},
}

@article{chung_is_2025,
	title = {Is {Long} {Context} {All} {You} {Need}? {Leveraging} {LLM}'s {Extended} {Context} for {NL2SQL}},
	volume = {18},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3742728.3742761},
	doi = {10.14778/3742728.3742761},
	abstract = {Large Language Models (LLMs) have demonstrated impressive capabilities across a range of natural language processing tasks. In particular, improvements in reasoning abilities and the expansion of context windows have opened new avenues for leveraging these powerful models. NL2SQL is challenging in that the natural language question is inherently ambiguous, while the SQL generation requires a precise understanding of complex data schema and semantics. One approach to this semantic ambiguous problem is to provide more and sufficient contextual information.In this work, we explore the performance and the latency tradeoffs of the extended context window (a.k.a., long context) offered by Google's state-of-the-art LLM (gemini-1.5-pro). We study the impact of various contextual information, including column example values, question and SQL query pairs, user-provided hints, SQL documentation, and schema. To the best of our knowledge, this is the first work to study how the extended context window and extra contextual information can help NL2SQL generation with respect to both accuracy and latency cost. We show that long context LLMs are robust and do not get lost in the extended contextual information. Additionally, our long-context NL2SQL pipeline based on Google's Gemini-pro-1.5 achieves strong performance across multiple benchmark datasets without fine-tuning or expensive self-consistency based techniques.},
	number = {8},
	journal = {Proc. VLDB Endow.},
	author = {Chung, Yeounoh and Kakkar, Gaurav T. and Gan, Yu and Milne, Brenton and Özcan, Fatma},
	month = sep,
	year = {2025},
	note = {Publisher: VLDB Endowment},
	pages = {2735--2747},
}

@article{xi_efficient_2025,
	title = {Efficient and {Deployable} {Knowledge} {Infusion} for {Open}-{World} {Recommendations} via {Large} {Language} {Models}},
	volume = {4},
	url = {https://doi.org/10.1145/3725894},
	doi = {10.1145/3725894},
	abstract = {Recommender system plays a pervasive role in today’s online services, yet its closed-loop nature, i.e., training and deploying within a specific closed domain, constrains its access to open-world knowledge. Recently, the emergence of large language models (LLMs) has shown promise in bridging this gap by encoding extensive world knowledge and demonstrating advanced reasoning capabilities. However, previous attempts to directly implement LLMs as recommenders fall short in meeting the demanding requirements of industrial recommender systems, particularly in terms of online inference latency and offline resource efficiency. In this work, we propose an Open-World Recommendation Framework with Efficient and Deployable Knowledge Infusion from Large Language Models, dubbed REKI, to acquire two types of external knowledge about users and items from LLMs. Specifically, we introduce factorization prompting to elicit accurate knowledge reasoning on user preferences and items. With factorization prompting, we develop individual knowledge extraction and collective knowledge extraction tailored for different scales of recommendation scenarios, effectively reducing offline resource consumption. Subsequently, the generated user and item knowledge undergoes efficient transformation and condensation into augmented vectors through a hybridized expert-integrated network, ensuring its compatibility with the recommendation task. The obtained vectors can then be directly used to enhance the performance of any conventional recommendation model. We also ensure efficient inference by preprocessing and prestoring the knowledge from the LLM. Extensive experiments demonstrate that REKI significantly outperforms the state-of-the-art baselines and is compatible with a diverse array of recommendation algorithms and tasks. Now, REKI has been deployed to Huawei’s news and music recommendation platforms and gained a 7\% and 1.99\% improvement during the online A/B test.},
	number = {1},
	journal = {ACM Trans. Recomm. Syst.},
	author = {Xi, Yunjia and Liu, Weiwen and Lin, Jianghao and Weng, Muyan and Cai, Xiaoling and Zhu, Hong and Zhu, Jieming and Chen, Bo and Tang, Ruiming and Yu, Yong and Zhang, Weinan},
	month = jul,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {knowledge augmentation, large language models, Recommender systems},
}

@article{yang_requirements-based_2025,
	title = {Requirements-{Based} {Test} {Generation}: {A} {Comprehensive} {Survey}},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3771727},
	doi = {10.1145/3771727},
	abstract = {As an important way of assuring software quality, software testing generates and executes test cases to identify software failures. Many strategies have been proposed to guide test-case generation, such as source-code-based approaches and methods based on bug reports. Requirements-based test generation (RBTG) constructs test cases based on specified requirements, aligning with user needs and expectations, without requiring access to the source code. Since its introduction in 1994, there have been many contributions to the development of RBTG, including various approaches, implementations, tools, assessment and evaluation methods, and applications. This paper provides a comprehensive survey on RBTG, categorizing requirements types, classifying approaches, investigating types of test cases, summarizing available tools, and analyzing experimental evaluations. This paper also summarizes the domains and industrial applications of RBTG, and discusses some open research challenges and potential future work.},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Yang, Zhenzhen and Huang, Rubing and Cui, Chenhui and Niu, Nan and Towey, Dave},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {software requirements, Software testing, survey, test generation},
	annote = {Just Accepted},
}

@article{liu_improving_2025-1,
	title = {Improving {Emotional} {Support} {Delivery} in {Text}-{Based} {Community} {Safety} {Reporting} {Using} {Large} {Language} {Models}},
	volume = {9},
	url = {https://doi.org/10.1145/3711012},
	doi = {10.1145/3711012},
	abstract = {Emotional support is a crucial aspect of communication between community members and police dispatchers during incident reporting. However, there is a lack of understanding about how emotional support is delivered through text-based systems, especially in various non-emergency contexts. In this study, we analyzed two years of chat logs comprising 57,114 messages across 8,239 incidents from 130 higher education institutions. Our empirical findings revealed significant variations in emotional support provided by dispatchers, influenced by the type of incident, service time, and a noticeable decline in support over time across multiple organizations. To improve the consistency and quality of emotional support, we developed and implemented a fine-tuned Large Language Model (LLM), named dispatcherLLM, designed to suggest replies through simulating human dispatchers' languages with appropriate emotional support. We evaluated dispatcherLLM by comparing its generated responses to those of human dispatchers and other off-the-shelf models using real chat messages. Additionally, we conducted a human evaluation to assess the perceived effectiveness of the support provided by dispatcherLLM. This study not only contributes new empirical understandings of emotional support in text-based dispatch systems but also demonstrates the significant potential of generative AI in improving service delivery.},
	number = {2},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Liu, Yiren and Li, Yerong and Mayfield, Ryan and Huang, Yun},
	month = may,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {emotion classification, event argument extraction, large language models, live chat, safety reporting, text-based reporting system},
}

@article{iannuzzi_improving_2025,
	title = {Improving {Accessibility} of {Public} {Administrations} {Web} {Sites} through {Large}-{Scale} {Automatic} {Validations}},
	volume = {2},
	url = {https://doi.org/10.1145/3762815},
	doi = {10.1145/3762815},
	abstract = {Digital accessibility is considered an important aspect to allow all people, including those with permanent or temporary disabilities, to access the continuously increasing number of digital services. This raises the need for tools able to provide support for monitoring the accessibility of many websites, to understand their level of accessibility, and identify the areas that need more interventions for their improvement. The primary objectives of this work are to describe the challenges that have been faced in extending the MAUVE++ tool to carry out web accessibility validation in the context of large-scale assessments and provide an up-to-date view of the accessibility landscape of public administration websites. We discuss how the tool was adapted to analyse more than four million web pages and associated PDF documents from Italian public administration websites, assessing their compliance with WCAG guidelines. The results of this large-scale analysis have been utilised to provide insights on the state of accessibility at the national level, through a dedicated public dashboard updated quarterly, and stimulate its improvement. This research identifies the most violated success criteria, thus highlighting areas that should require attention from web developers and designers. Finally, we highlight some broader as well as practical implications of this research, and to what extent it can stimulate a more responsible approach and attention to accessibility aspects.},
	number = {3},
	journal = {ACM J. Responsib. Comput.},
	author = {Iannuzzi, Nicola and Manca, Marco and Paterno', Fabio and Santoro, Carmen},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Accessibility, Automatic Validation Tools, Large-scale validations},
}

@article{izacard_atlas_2023,
	title = {Atlas: few-shot learning with retrieval augmented language models},
	volume = {24},
	issn = {1532-4435},
	abstract = {Large language models have shown impressive few-shot results on a wide range of tasks. However, when knowledge is key for such results, as is the case for tasks such as question answering and fact checking, massive parameter counts to store knowledge seem to be needed. Retrieval-augmented models are known to excel at knowledge intensive tasks without the need for as many parameters, but it is unclear whether they work in few-shot settings. In this work we present Atlas, a carefully designed and pre-trained retrieval-augmented language model able to learn knowledge intensive tasks with very few training examples. We perform evaluations on a wide range of tasks, including MMLU, KILT and Natural Questions, and study the impact of the content of the document index, showing that it can easily be updated. Notably, Atlas reaches over 42\% accuracy on Natural Questions using only 64 examples, outperforming a 540B parameter model by 3\% despite having 50x fewer parameters.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Izacard, Gautier and Lewis, Patrick and Lomeli, Maria and Hosseini, Lucas and Petroni, Fabio and Schick, Timo and Dwivedi-Yu, Jane and Joulin, Armand and Riedel, Sebastian and Grave, Edouard},
	month = jan,
	year = {2023},
	note = {Publisher: JMLR.org},
	keywords = {information retrieval, language models, retrieval augmented language models},
}

@article{kuang_natural_2025,
	title = {Natural {Language} {Understanding} and {Inference} with {MLLM} in {Visual} {Question} {Answering}: {A} {Survey}},
	volume = {57},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3711680},
	doi = {10.1145/3711680},
	abstract = {Visual Question Answering (VQA) is a challenge task that combines natural language processing and computer vision techniques and gradually becomes a benchmark test task in multimodal large language models (MLLMs). The goal of our survey is to provide an overview of the development of VQA and a detailed description of the latest models with high timeliness. This survey gives an up-to-date synthesis of natural language understanding of images and text, as well as the knowledge reasoning module based on image-question information on the core VQA tasks. In addition, we elaborate on recent advances in extracting and fusing modal information with vision-language pretraining models and multimodal large language models in VQA. We also exhaustively review the progress of knowledge reasoning in VQA by detailing the extraction of internal knowledge and the introduction of external knowledge. Finally, we present the datasets of VQA and different evaluation metrics and discuss possible directions for future work.},
	number = {8},
	journal = {ACM Comput. Surv.},
	author = {Kuang, Jiayi and Shen, Ying and Xie, Jingyou and Luo, Haohao and Xu, Zhe and Li, Ronghao and Li, Yinghui and Cheng, Xianfeng and Lin, Xika and Han, Yu},
	month = mar,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {multimodal large language models, multimodal representation and reasoning, Visual question answering},
}

@article{khanshan_evaluation_2024,
	title = {Evaluation of {Code} {Generation} for {Simulating} {Participant} {Behavior} in {Experience} {Sampling} {Method} by {Iterative} {In}-{Context} {Learning} of a {Large} {Language} {Model}},
	volume = {8},
	url = {https://doi.org/10.1145/3661143},
	doi = {10.1145/3661143},
	abstract = {The Experience Sampling Method (ESM) is commonly used to understand behaviors, thoughts, and feelings in the wild by collecting self-reports. Sustaining sufficient response rates, especially in long-running studies remains challenging. To avoid low response rates and dropouts, experimenters rely on their experience, proposed methodologies from earlier studies, trial and error, or the scarcely available participant behavior data from previous ESM protocols. This approach often fails in finding the acceptable study parameters, resulting in redesigning the protocol and repeating the experiment. Research has shown the potential of machine learning to personalize ESM protocols such that ESM prompts are delivered at opportune moments, leading to higher response rates. The corresponding training process is hindered due to the scarcity of open data in the ESM domain, causing a cold start, which could be mitigated by simulating participant behavior. Such simulations provide training data and insights for the experimenters to update their study design choices. Creating this simulation requires behavioral science, psychology, and programming expertise. Large language models (LLMs) have emerged as facilitators for information inquiry and programming, albeit random and occasionally unreliable. We aspire to assess the readiness of LLMs in an ESM use case. We conducted research using GPT-3.5 turbo-16k to tackle an ESM simulation problem. We explored several prompt design alternatives to generate ESM simulation programs, evaluated the output code in terms of semantics and syntax, and interviewed ESM practitioners. We found that engineering LLM-enabled ESM simulations have the potential to facilitate data generation, but they perpetuate trust and reliability challenges.},
	number = {EICS},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Khanshan, Alireza and Van Gorp, Pieter and Markopoulos, Panos},
	month = jun,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Behavior Simulation, Experience Sampling Method, Large Language Model, Prompt Engineering},
}

@article{sun_exploring_2024,
	title = {Exploring {Parent}'s {Needs} for {Children}-{Centered} {AI} to {Support} {Preschoolers}' {Interactive} {Storytelling} and {Reading} {Activities}},
	volume = {8},
	url = {https://doi.org/10.1145/3687035},
	doi = {10.1145/3687035},
	abstract = {Interactive storytelling is vital for preschooler development. While children's interactive partners have traditionally been their parents and teachers, recent advances in artificial intelligence (AI) have sparked a surge of AI-based storytelling and reading technologies. As these technologies become increasingly ubiquitous in preschoolers' lives, questions arise regarding how they function in practical storytelling and reading scenarios and, how parents, the most critical stakeholders, experience and perceive these technologies. This paper investigates these questions through a qualitative study with 17 parents of children aged 3-6. Our findings suggest that even though AI-based storytelling and reading technologies provide more immersive and engaging interaction, they still cannot meet parents' expectations due to a series of interactive and algorithmic challenges. We elaborate on these challenges and discuss the possible implications of future AI-based interactive storytelling technologies for preschoolers.},
	number = {CSCW2},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Sun, Yuling and Chen, Jiaju and Yao, Bingsheng and Liu, Jiali and Wang, Dakuo and Ma, Xiaojuan and Lu, Yuxuan and Xu, Ying and He, Liang},
	month = nov,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {ai, artificial intelligence, interactive, parents, preschoolers, storybook reading, storytelling},
}

@article{yang_socialmind_2025,
	title = {{SocialMind}: {LLM}-based {Proactive} {AR} {Social} {Assistive} {System} with {Human}-like {Perception} for {In}-situ {Live} {Interactions}},
	volume = {9},
	url = {https://doi.org/10.1145/3712286},
	doi = {10.1145/3712286},
	abstract = {Social interactions are fundamental to human life. The recent emergence of large language models (LLMs)-based virtual assistants has demonstrated their potential to revolutionize human interactions and lifestyles. However, existing assistive systems mainly provide reactive services to individual users, rather than offering in-situ assistance during live social interactions with conversational partners. In this study, we introduce SocialMind, the first LLM-based proactive AR social assistive system that provides users with in-situ social assistance. SocialMind employs human-like perception leveraging multi-modal sensors to extract both verbal and nonverbal cues, social factors, and implicit personas, incorporating these social cues into LLM reasoning for social suggestion generation. Additionally, SocialMind employs a multi-tier collaborative generation strategy and proactive update mechanism to display social suggestions on Augmented Reality (AR) glasses, ensuring that suggestions are timely provided to users without disrupting the natural flow of conversation. Evaluations on three public datasets and a user study with 20 participants show that SocialMind achieves 38.3\% higher engagement compared to baselines, and 95\% of participants are willing to use SocialMind in their live social interactions.},
	number = {1},
	journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
	author = {Yang, Bufang and Guo, Yunqi and Xu, Lilin and Yan, Zhenyu and Chen, Hongkai and Xing, Guoliang and Jiang, Xiaofan},
	month = mar,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {AR Glasses, Augmented Reality, Internet of Things, LLMs, Multi-modal Sensor Data, Proactive Assistive Systems, Social Interaction},
}

@article{ben_chaaben_utility_2025,
	title = {On the {Utility} of {Domain} {Modeling} {Assistance} with {Large} {Language} {Models}},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3744920},
	doi = {10.1145/3744920},
	abstract = {Model-driven engineering (MDE) simplifies software development through abstraction, yet challenges such as time constraints, incomplete domain understanding, and adherence to syntactic constraints hinder the design process. This paper presents a study to evaluate the usefulness of a novel approach utilizing large language models (LLMs) and few-shot prompt learning to assist in domain modeling. The aim of this approach is to overcome the need for extensive training of traditional AI-based completion algorithms on domain-specific datasets and to offer versatile support for various modeling activities, providing valuable recommendations to software modelers. To support this approach, we developed MAGDA, a user-friendly tool, through which we conduct a user study and assess the real-world applicability of our approach in the context of domain modeling, offering valuable insights into its usability and effectiveness.},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Ben Chaaben, Meriem and Burgueño, Lola and David, Istvan and Sahraoui, Houari},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {domain modeling, generative AI, language models, model-driven engineering, prompt learning, user study},
	annote = {Just Accepted},
}

@article{xu_reimagining_2025,
	title = {Reimagining {Digital} {Well}-being: {A} {Theoretical} {Framework} {Based} on the {Psychology} of {Felt} {Structure} and {Illustrated} through {Creative} {Storytelling}},
	volume = {9},
	url = {https://doi.org/10.1145/3757396},
	doi = {10.1145/3757396},
	abstract = {Digital environments today often lack affordances that cultivate a sense of place and embodied being and acting. We develop a theoretical framework for embodied place-making based on people's psychological tendency to balance structure (clarity, predictability, and certainty) with unstructuredness (openness and possibility). This framework provides a unified theoretical foundation for examining continuity and discontinuity in social psychological processes and behaviors across digital, physical, and natural environments. We illustrate this framework through an original story (NewsWood ) that reconceptualizes digital news reading as an experience akin to wandering through woods. We hope to inspire radical reimagining of how future digital environments can foster well-being across individuals, communities, societies, and the natural world within their interconnected relationships.},
	number = {7},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Xu, Chunchen and Ge, Xiao},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {behavior, behavioral sciences, creative storytelling, digital and natural environments, embodied place-making, human-nature connection, meaning-making, psychology, social media design, well-being},
}

@article{yang_drhouse_2024,
	title = {{DrHouse}: {An} {LLM}-empowered {Diagnostic} {Reasoning} {System} through {Harnessing} {Outcomes} from {Sensor} {Data} and {Expert} {Knowledge}},
	volume = {8},
	url = {https://doi.org/10.1145/3699765},
	doi = {10.1145/3699765},
	abstract = {Large language models (LLMs) have the potential to transform digital healthcare, as evidenced by recent advances in LLM-based virtual doctors. However, current approaches rely on patient's subjective descriptions of symptoms, causing increased misdiagnosis. Recognizing the value of daily data from smart devices, we introduce a novel LLM-based multi-turn consultation virtual doctor system, DrHouse, which incorporates three significant contributions: 1) It utilizes sensor data from smart devices in the diagnosis process, enhancing accuracy and reliability. 2) DrHouse leverages continuously updating medical knowledge bases to ensure its model remains at diagnostic standard's forefront. 3) DrHouse introduces a novel diagnostic algorithm that concurrently evaluates potential diseases and their likelihood, facilitating more nuanced and informed medical assessments. Through multi-turn interactions, DrHouse determines the next steps, such as accessing daily data from smart devices or requesting in-lab tests, and progressively refines its diagnoses. Evaluations on three public datasets and our self-collected datasets show that DrHouse can achieve up to an 31.5\% increase in diagnosis accuracy over the state-of-the-art baselines. The results of a 32-participant user study show that 75\% medical experts and 91.7\% test subjects are willing to use DrHouse.},
	number = {4},
	journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
	author = {Yang, Bufang and Jiang, Siyang and Xu, Lilin and Liu, Kaiwei and Li, Hai and Xing, Guoliang and Chen, Hongkai and Jiang, Xiaofan and Yan, Zhenyu},
	month = nov,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Diagnostic Reasoning Systems, Internet of Things, Knowledge Retrieval, LLMs, Proactive Conversational Systems, Sensor Data, Up-to-Date},
}

@article{miao_towards_2025,
	title = {Towards {Efficient} {Generative} {Large} {Language} {Model} {Serving}: {A} {Survey} from {Algorithms} to {Systems}},
	volume = {58},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3754448},
	doi = {10.1145/3754448},
	abstract = {In the rapidly evolving landscape of artificial intelligence (AI), generative large language models (LLMs) stand at the forefront, revolutionizing how we interact with our data. However, the computational intensity and memory consumption of deploying these models present substantial challenges in terms of serving efficiency, particularly in scenarios demanding low latency and high throughput. This survey addresses the imperative need for efficient LLM serving methodologies from a machine learning system (MLSys) research perspective, standing at the crux of advanced AI innovations and practical system optimizations. We provide in-depth analysis, covering a spectrum of solutions, ranging from cutting-edge algorithmic modifications to groundbreaking changes in system designs. The survey aims to provide a comprehensive understanding of the current state and future directions in efficient LLM serving, offering valuable insights for researchers and practitioners in overcoming the barriers of effective LLM deployment, thereby reshaping the future of AI.},
	number = {1},
	journal = {ACM Comput. Surv.},
	author = {Miao, Xupeng and Oliaro, Gabriele and Zhang, Zhihao and Cheng, Xinhao and Jin, Hongyi and Chen, Tianqi and Jia, Zhihao},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {algorithm, efficiency, inference, Large language model, serving, system},
}

@article{karinshak_working_2023,
	title = {Working {With} {AI} to {Persuade}: {Examining} a {Large} {Language} {Model}'s {Ability} to {Generate} {Pro}-{Vaccination} {Messages}},
	volume = {7},
	url = {https://doi.org/10.1145/3579592},
	doi = {10.1145/3579592},
	abstract = {Artificial Intelligence (AI) is a transformative force in communication and messaging strategy, with potential to disrupt traditional approaches. Large language models (LLMs), a form of AI, are capable of generating high-quality, humanlike text. We investigate the persuasive quality of AI-generated messages to understand how AI could impact public health messaging. Specifically, through a series of studies designed to characterize and evaluate generative AI in developing public health messages, we analyze COVID-19 pro-vaccination messages generated by GPT-3, a state-of-the-art instantiation of a large language model. Study 1 is a systematic evaluation of GPT-3's ability to generate pro-vaccination messages. Study 2 then observed peoples' perceptions of curated GPT-3-generated messages compared to human-authored messages released by the CDC (Centers for Disease Control and Prevention), finding that GPT-3 messages were perceived as more effective, stronger arguments, and evoked more positive attitudes than CDC messages. Finally, Study 3 assessed the role of source labels on perceived quality, finding that while participants preferred AI-generated messages, they expressed dispreference for messages that were labeled as AI-generated. The results suggest that, with human supervision, AI can be used to create effective public health messages, but that individuals prefer their public health messages to come from human institutions rather than AI sources. We propose best practices for assessing generative outputs of large language models in future social science research and ways health professionals can use AI systems to augment public health messaging.},
	number = {CSCW1},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Karinshak, Elise and Liu, Sunny Xun and Park, Joon Sung and Hancock, Jeffrey T.},
	month = apr,
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {AI-mediated communication, large language models, message factors, natural language processing, persuasion, public health messaging},
}

@article{zheng_understanding_2023,
	title = {Understanding {Safety} {Risks} and {Safety} {Design} in {Social} {VR} {Environments}},
	volume = {7},
	url = {https://doi.org/10.1145/3579630},
	doi = {10.1145/3579630},
	abstract = {Understanding emerging safety risks in nuanced social VR spaces and how existing safety features are used is crucial for the future development of safe and inclusive 3D social worlds. Prior research on safety risks in social VR is mainly based on interview or survey data about social VR users' experiences and opinions, which lacks "in-situ observations" of how individuals react to these risks. Using two empirical studies, this paper seeks to understand safety risks and safety design in social VR. In Study 1, we investigated 212 YouTube videos and their transcripts that document social VR users' immediate experiences of safety risks as victims, attackers, or bystanders. We also analyzed spectators' reactions to these risks shown in comments to the videos. In Study 2, we summarized 13 safety features across various social VR platforms and mapped how each existing safety feature in social VR can mitigate the risks identified in Study 1. Based on the uniqueness of social VR interaction dynamics and users' multi-modal simulated reactions, we call for further re-thinking and re-approaching safety designs for future social VR environments and propose potential design implications for future safety protection mechanisms in social VR.},
	number = {CSCW1},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Zheng, Qingxiao and Xu, Shengyang and Wang, Lingqing and Tang, Yiliu and Salvi, Rohan C. and Freeman, Guo and Huang, Yun},
	month = apr,
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {online harassment, safety design, safety risks, social virtual reality},
}

@article{poon_computer-mediated_2023,
	title = {Computer-{Mediated} {Sharing} {Circles} for {Intersectional} {Peer} {Support} with {Home} {Care} {Workers}},
	volume = {7},
	url = {https://doi.org/10.1145/3579472},
	doi = {10.1145/3579472},
	abstract = {Home care workers (HCWs) provide essential care in patients' homes but are often underappreciated and work in stressful and isolated environments with diverse and intersecting support needs. This paper describes a computer-mediated peer support program that centers around sharing circles: spaces for personal, narrative storytelling to encourage HCWs to collaboratively reflect on their home care experiences and build rapport and shared identity with their peers. We describe the design of this program and a 12-week deployment that we conducted to evaluate the program with 42 HCWs in New York City. Our findings show that participants engaged in multiple types of peer support including emotional validation, learning how to navigate the workplace and patient care, defining and enabling good home care praxis, and building understanding around purpose and identity as HCWs. We discuss how these findings inform the design of technology and use of holistic pedagogies, such as storytelling, to enable this support in computer-mediated peer support programs. Such programs can help researchers and practitioners interested in addressing diverse needs that occur in intersectional contexts, such as that of HCWs and other marginalized populations.},
	number = {CSCW1},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Poon, Anthony and Luebke, Matthew and Loughman, Julia and Lee, Ann and Guerrero, Lourdes and Sterling, Madeline and Dell, Nicola},
	month = apr,
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {healthcare, home care workers, mutual help, peer support, practitioners, professionalization, safe spaces, sharing circles, support groups},
}

@article{alvarado_towards_2022,
	title = {Towards {Tangible} {Algorithms}: {Exploring} the {Experiences} of {Tangible} {Interactions} with {Movie} {Recommender} {Algorithms}},
	volume = {6},
	url = {https://doi.org/10.1145/3555757},
	doi = {10.1145/3555757},
	abstract = {Artificial Intelligence (AI) supports many of our everyday activities and decisions. However, personalized algorithmic recommendations often produce adverse experiences due to a lack of awareness, control, or transparency. While research has directed solutions on graphical user interfaces (GUIs), there are no explorations of Tangible User Interfaces (TUIs) to improve the experience with such systems, despite the valid existing academic arguments in favor of this exploration. Therefore, centering on transparency and control, we analyzed how 18 users of movie recommender systems perceived four different TUIs using individual co-design sessions and post-interview questionnaires. Through thematic analysis, we identified seven design considerations while designing TUIs to interact with algorithmic movie recommender systems: (1) Distinctions between TUIs and GUIs; (2) TUIs replacing predominant interfaces; (3) Preference for single-device TUIs; (4) The relevance of granular control for TUIs; (5) Apparent transparency limitations of TUIs; (6) TUIs and algorithmic social computing; and (7) Overview of specific design choices, including advantages and disadvantages of soft, hard, rounded, cubic, and humanoid interfaces. These findings inspired Recffy: the first functional TUI designed to enhance awareness and control in personalized movie recommendations. Based on this study, we propose the concept of Tangible Algorithms: TUIs dedicated to enhancing the interaction of algorithmic systems and their profiling processes or decisions in a specific context. Furthermore, we describe the relevance of tangible algorithms and design guidelines to promote them in diverse AI contexts. Finally, we invite the HCI and CSCW community to continue exploring tangible algorithms to address the interaction with algorithmic systems, including the collaborative and social computing dynamics they can promote in diverse AI contexts.},
	number = {CSCW2},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Alvarado, Oscar and Vanden Abeele, Vero and Geerts, David and Verbert, Katrien},
	month = nov,
	year = {2022},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {algorithmic experience, recommender systems, social computing, tangible algorithms, tangible interfaces},
}

@article{lalapura_recurrent_2021,
	title = {Recurrent {Neural} {Networks} for {Edge} {Intelligence}: {A} {Survey}},
	volume = {54},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3448974},
	doi = {10.1145/3448974},
	abstract = {Recurrent Neural Networks are ubiquitous and pervasive in many artificial intelligence applications such as speech recognition, predictive healthcare, creative art, and so on. Although they provide accurate superior solutions, they pose a massive challenge “training havoc.” Current expansion of IoT demands intelligent models to be deployed at the edge. This is precisely to handle increasing model sizes and complex network architectures. Design efforts to meet these for greater performance have had inverse effects on portability on edge devices with real-time constraints of memory, latency, and energy. This article provides a detailed insight into various compression techniques widely disseminated in the deep learning regime. They have become key in mapping powerful RNNs onto resource-constrained devices. While compression of RNNs is the main focus of the survey, it also highlights challenges encountered while training. The training procedure directly influences model performance and compression alongside. Recent advancements to overcome the training challenges with their strengths and drawbacks are discussed. In short, the survey covers the three-step process, namely, architecture selection, efficient training process, and suitable compression technique applicable to a resource-constrained environment. It is thus one of the comprehensive survey guides a developer can adapt for a time-series problem context and an RNN solution for the edge.},
	number = {4},
	journal = {ACM Comput. Surv.},
	author = {Lalapura, Varsha S. and Amudha, J. and Satheesh, Hariramn Selvamuruga},
	month = may,
	year = {2021},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {artificial intelligence (AI), compression, edge intelligence (EI), low-rank, Recurrent neural networks (RNNs), resource constrained modeling, sequence modeling, sparsity, training},
}

@article{sparrow_towards_2024,
	title = {Towards {Ethical} {AI} {Moderation} in {Multiplayer} {Games}},
	volume = {8},
	url = {https://doi.org/10.1145/3677109},
	doi = {10.1145/3677109},
	abstract = {AI is increasingly being used to moderate player behaviour in online multiplayer games, working to identify and respond to toxic and problematic conduct with greater efficiency and accuracy than existing automated systems. However, little work has explored the application of AI moderation in the gaming ecosystem, despite growing ethical concerns about AI applications in other domains. In this study, we conducted 2 expert workshops and interviewed 26 players and industry professionals on their understandings, perceptions and experiences with AI moderation in multiplayer games. Applying a metaphorical frame via template analysis, we outline four metaphors that capture participants' views on the roles of AI and automation in moderation: the Unreliable Police Force, the Unscrupulous Governor, the Uncaring Judge, and the Untiring Assistant. We discuss these roles as exacerbating a top-down, punitive online justice system and identify ethical concerns around transparency, fairness and inclusion, privacy, and human-AI collaboration. To address these concerns, we put forward a set of ethical design considerations and alternative roles for AI moderation in multiplayer games.},
	number = {CHI PLAY},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Sparrow, Lucy A. and Galwey, Ren and Jovic, Dahlia and Hardwick, Taylor and Butt, Mahli-Ann},
	month = oct,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {artificial intelligence, metaphors, moderation, multiplayer games, toxicity},
}

@article{asperti_syllabification_2021,
	title = {Syllabification of the {Divine} {Comedy}},
	volume = {14},
	issn = {1556-4673},
	url = {https://doi.org/10.1145/3459011},
	doi = {10.1145/3459011},
	abstract = {We provide a syllabification algorithm for the Divine Comedy using techniques from probabilistic and constraint programming. We particularly focus on the synalephe, addressed in terms of the "propensity" of a word to take part in a synalephe with adjacent words. We jointly provide an online vocabulary containing, for each word, information about its syllabification, the location of the tonic accent, and the aforementioned synalephe propensity, on the left and right sides. The algorithm is intrinsically nondeterministic, producing different possible syllabifications for each verse, with different likelihoods; metric constraints relative to accents on the 10th, 4th, and 6th syllables are used to further reduce the solution space. The most likely syllabification is hence returned as output. We believe that this work could be a major milestone for a lot of different investigations. From the point of view of digital humanities it opens new perspectives on computer-assisted analysis of digital sources, comprising automated detection of anomalous and problematic cases, metric clustering of verses and their categorization, or more foundational investigations addressing, e.g., the phonetic roles of consonants and vowels. From the point of view of text processing and deep learning, information about syllabification and the location of accents opens a wide range of exciting perspectives, from the possibility of automatic learning syllabification of words and verses to the improvement of generative models, aware of metric issues, and more respectful of the expected musicality.},
	number = {3},
	journal = {J. Comput. Cult. Herit.},
	author = {Asperti, Andrea and Bianco, Stefano Dal},
	month = jul,
	year = {2021},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Dante Alighieri, Divina Commedia, Divine comedy, hendecasyllable, syllabification, Synalephe},
}

@article{kokosza_scintilla_2024,
	title = {Scintilla: {Simulating} {Combustible} {Vegetation} for {Wildfires}},
	volume = {43},
	issn = {0730-0301},
	url = {https://doi.org/10.1145/3658192},
	doi = {10.1145/3658192},
	abstract = {Wildfires are a complex physical phenomenon that involves the combustion of a variety of flammable materials ranging from fallen leaves and dried twigs to decomposing organic material and living flora. All these materials can potentially act as fuel with different properties that determine the progress and severity of a wildfire. In this paper, we propose a novel approach for simulating the dynamic interaction between the varying components of a wildfire, including processes of convection, combustion and heat transfer between vegetation, soil and atmosphere. We propose a novel representation of vegetation that includes detailed branch geometry, fuel moisture, and distribution of grass, fine fuel, and duff. Furthermore, we model the ignition, generation, and transport of fire by firebrands and embers. This allows simulating and rendering virtual 3D wildfires that realistically capture key aspects of the process, such as progressions from ground to crown fires, the impact of embers carried by wind, and the effects of fire barriers and other human intervention methods. We evaluate our approach through numerous experiments and based on comparisons to real-world wildfire data.},
	number = {4},
	journal = {ACM Trans. Graph.},
	author = {Kokosza, Andrzej and Wrede, Helge and Gonzalez Esparza, Daniel and Makowski, Milosz and Liu, Daoming and Michels, Dominik L. and Pirk, Soren and Palubicki, Wojtek},
	month = jul,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {branch litter, combustion, fire spotting, fire spread, fluid dynamics, grass, level of detail, numerical simulation, physics-based modeling, understory, vegetation, wildfires},
}

@article{gupta_first_2024,
	title = {The {First} {Principles}: {Setting} the {Context} for a {Safe} and {Secure} {Metaverse}},
	volume = {56},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3665495},
	doi = {10.1145/3665495},
	abstract = {The metaverse delivered through converged and amalgamated technologies holds promise. No wonder technology heavyweights, large corporates, research organizations and businesses cutting across industry verticals are racing to put in place a metaverse-first strategy. The bets on consumers rapidly migrating from traditional social networks and collaborative applications to more immersive digital experiences have been placed. However, the transition is not expected to be seamless. Privacy, safety and security concerns abound in the early versions of the metaverse. Increased regulatory oversight and diverse national laws threaten to derail the hype around the metaverse. It is increasingly clear that the final iteration of the metaverse will need to assuage the concerns of individual users while addressing complex legal and regulatory requirements. Thus, a multi-perspective approach needs to be adopted to help set the agenda for the evolution of the metaverse. This research paper examines the different aspects and challenges which the future metaverse will need to address. A set of “first principles” are formulated, which if implemented will lead to the development of an equitable, inclusive, safe and secure metaverse.},
	number = {11},
	journal = {ACM Comput. Surv.},
	author = {Gupta, Ankur and Sawhney, Sahil and Kompella, Kashyap},
	month = jul,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {first principles for the metaverse, Metaverse, metaverse security},
}

@article{xu_can_2024,
	title = {Can {Large} {Language} {Models} {Be} {Good} {Companions}? {An} {LLM}-{Based} {Eyewear} {System} with {Conversational} {Common} {Ground}},
	volume = {8},
	url = {https://doi.org/10.1145/3659600},
	doi = {10.1145/3659600},
	abstract = {Developing chatbots as personal companions has long been a goal of artificial intelligence researchers. Recent advances in Large Language Models (LLMs) have delivered a practical solution for endowing chatbots with anthropomorphic language capabilities. However, it takes more than LLMs to enable chatbots that can act as companions. Humans use their understanding of individual personalities to drive conversations. Chatbots also require this capability to enable human-like companionship. They should act based on personalized, real-time, and time-evolving knowledge of their users. We define such essential knowledge as the common ground between chatbots and their users, and we propose to build a common-ground-aware dialogue system from an LLM-based module, named OS-1, to enable chatbot companionship. Hosted by eyewear, OS-1 can sense the visual and audio signals the user receives and extract real-time contextual semantics. Those semantics are categorized and recorded to formulate historical contexts from which the user's profile is distilled and evolves over time, i.e., OS-1 gradually learns about its user. OS-1 combines knowledge from real-time semantics, historical contexts, and user-specific profiles to produce a common-ground-aware prompt input into the LLM module. The LLM's output is converted to audio, spoken to the wearer when appropriate. We conduct laboratory and in-field studies to assess OS-1's ability to build common ground between the chatbot and its user. The technical feasibility and capabilities of the system are also evaluated. Our results show that by utilizing personal context, OS-1 progressively develops a better understanding of its users. This enhances user satisfaction and potentially leads to various personal service scenarios, such as emotional support and assistance.},
	number = {2},
	journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
	author = {Xu, Zhenyu and Xu, Hailin and Lu, Zhouyang and Zhao, Yingying and Zhu, Rui and Wang, Yujiang and Dong, Mingzhi and Chang, Yuhu and Lv, Qin and Dick, Robert P. and Yang, Fan and Lu, Tun and Gu, Ning and Shang, Li},
	month = may,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {common ground, context-aware, large language model, Smart eyewear},
}

@article{smith_strategic_2023,
	title = {Strategic knowledge transfer},
	volume = {24},
	issn = {1532-4435},
	abstract = {In the course of playing or solving a game, it is common to face a series of changing other-agent strategies. These strategies often share elements: the set of possible policies to play has overlap, and the policies are sampled at the beginning of play by possibly differing distributions. As it faces the series of strategies, therefore, an agent has the opportunity to transfer its learned play against the previously encountered other-agent policies. We tackle two problems: (1) how can learned responses transfer across changing opponent strategies, and (2) how can this transfer be used to reduced the cumulative cost of learning in game solving. The first problem we characterize as the strategic knowledge transfer problem. For value-based response policies, we demonstrate that Q-Mixing approximately solves this problem by appropriately averaging the component Q-values. Solutions to the first problem can be applied to reduce the computational cost of learning-based game solving algorithms. We offer two algorithms that operate within the Policy-Space Response Oracles (PSRO) framework. Mixed-Oracles reduces the per-policy construction cost by transferring responses from previously encountered opponents. Mixed-Opponents performs strategic knowledge transfer by combining the previously encountered opponents into a single novel policy. Experimental evaluation of these methods on general-sum grid-world games provide evidence about their advantages and limitations in comparison to standard PSRO.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Smith, Max Olan and Anthony, Thomas and Wellman, Michael P.},
	month = jan,
	year = {2023},
	note = {Publisher: JMLR.org},
	keywords = {empirical game theoretic analysis, multiagent learning, reinforcement learning, transfer learning},
}

@article{rahman_general_2023,
	title = {A general learning framework for open ad hoc teamwork {Using} graph-based policy learning},
	volume = {24},
	issn = {1532-4435},
	abstract = {Open ad hoc teamwork is the problem of training a single agent to efficiently collaborate with an unknown group of teammates whose composition may change over time. A variable team composition creates challenges for the agent, such as the requirement to adapt to new team dynamics and dealing with changing state vector sizes. These challenges are aggravated in real-world applications in which the controlled agent only has a partial view of the environment. In this work, we develop a class of solutions for open ad hoc teamwork under full and partial observability. We start by developing a solution for the fully observable case that leverages graph neural network architectures to obtain an optimal policy based on reinforcement learning. We then extend this solution to partially observable scenarios by proposing different methodologies that maintain belief estimates over the latent environment states and team composition. These belief estimates are combined with our solution for the fully observable case to compute an agent's optimal policy under partial observability in open ad hoc teamwork. Empirical results demonstrate that our solution can learn efficient policies in open ad hoc teamwork in fully and partially observable cases. Further analysis demonstrates that our methods' success is a result of effectively learning the effects of teammates' actions while also inferring the inherent state of the environment under partial observability.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Rahman, Arrasy and Carlucho, Ignacio and Höpner, Niklas and Albrecht, Stefano V.},
	month = jan,
	year = {2023},
	note = {Publisher: JMLR.org},
	keywords = {ad hoc teamwork, graph neural networks, partial observability, particle filter, reinforcement learning},
}

@article{kordyaka_its_2025,
	title = {“{It}’s {Not} {My} {Fault}”: {Exploring} {Attributional} {Patterns} in {eSports} {Player} {Toxicity}},
	volume = {9},
	url = {https://doi.org/10.1145/3748622},
	doi = {10.1145/3748622},
	abstract = {Toxicity is a widespread challenge in various esports titles that continues to grow despite implementing various countermeasures. Attribution theory, consisting of the dimensions of locus of causality, stability, and internal and external control, offers a promising way to understand toxicity better, as how players interpret events in the game influences their perceptions and, ultimately, their toxic behavior. Given that attribution to external factors can reinforce and normalize toxic behavior in esports, this study investigates the timely topic of associations between toxic behavior and player attributions. To do so, we conducted an online survey with 217 League of Legends players. Our stepwise regression analysis indicates that players’ perceptions of external causality play a role in normalizing toxic behavior, whereas the perception that such behaviors are temporary enhances their execution. Additionally, the age of participants showed a substantial negative relationship with toxic normalization and toxic perpetration, indicating that older participants were significantly less likely to accept or engage in toxic behavior. In summary, players do not perceive toxic behavior as their responsibility, which explains the challenge of deriving effective intervention strategies against toxicity.},
	number = {6},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Kordyaka, Bastian},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {attribution, esports, normalization, perpetration, Toxic behavior, toxicity},
}

@article{parker-holder_automated_2022,
	title = {Automated {Reinforcement} {Learning} ({AutoRL}): {A} {Survey} and {Open} {Problems}},
	volume = {74},
	issn = {1076-9757},
	url = {https://doi.org/10.1613/jair.1.13596},
	doi = {10.1613/jair.1.13596},
	abstract = {The combination of Reinforcement Learning (RL) with deep learning has led to a series of impressive feats, with many believing (deep) RL provides a path towards generally capable agents. However, the success of RL agents is often highly sensitive to design choices in the training process, which may require tedious and error-prone manual tuning. This makes it challenging to use RL for new problems and also limits its full potential. In many other areas of machine learning, AutoML has shown that it is possible to automate such design choices, and AutoML has also yielded promising initial results when applied to RL. However, Automated Reinforcement Learning (AutoRL) involves not only standard applications of AutoML but also includes additional challenges unique to RL, that naturally produce a different set of methods. As such, AutoRL has been emerging as an important area of research in RL, providing promise in a variety of applications from RNA design to playing games, such as Go. Given the diversity of methods and environments considered in RL, much of the research has been conducted in distinct subfields, ranging from meta-learning to evolution. In this survey, we seek to unify the field of AutoRL, provide a common taxonomy, discuss each area in detail and pose open problems of interest to researchers going forward.},
	journal = {J. Artif. Int. Res.},
	author = {Parker-Holder, Jack and Rajan, Raghu and Song, Xingyou and Biedenkapp, André and Miao, Yingjie and Eimer, Theresa and Zhang, Baohe and Nguyen, Vu and Calandra, Roberto and Faust, Aleksandra and Hutter, Frank and Lindauer, Marius},
	month = sep,
	year = {2022},
	note = {Place: El Segundo, CA, USA
Publisher: AI Access Foundation},
}

@article{cui_senselens_2021,
	title = {{SenseLens}: {An} {Efficient} {Social} {Signal} {Conditioning} {System} for {True} {Event} {Detection}},
	volume = {18},
	issn = {1550-4859},
	url = {https://doi.org/10.1145/3485047},
	doi = {10.1145/3485047},
	abstract = {This article narrows the gap between physical sensing systems that measure physical signals and social sensing systems that measure information signals by (i) defining a novel algorithm for extracting information signals (building on results from text embedding) and (ii) showing that it increases the accuracy of truth discovery—the separation of true information from false/manipulated one. The work is applied in the context of separating true and false facts on social media, such as Twitter and Reddit, where users post predominantly short microblogs. The new algorithm decides how to aggregate the signal across words in the microblog for purposes of clustering the miscroblogs in the latent information signal space, where it is easier to separate true and false posts. Although previous literature extensively studied the problem of short text embedding/representation, this article improves previous work in three important respects: (1) Our work constitutes unsupervised truth discovery, requiring no labeled input or prior training. (2) We propose a new distance metric for efficient short text similarity estimation, we call Semantic Subset Matching, that improves our ability to meaningfully cluster microblog posts in the latent information signal space. (3) We introduce an iterative framework that jointly improves miscroblog clustering and truth discovery. The evaluation shows that the approach improves the accuracy of truth-discovery by 6.3\%, 2.5\%, and 3.8\% (constituting a 38.9\%, 14.2\%, and 18.7\% reduction in error, respectively) in three real Twitter data traces.},
	number = {2},
	journal = {ACM Trans. Sen. Netw.},
	author = {Cui, Hang and Abdelzaher, Tarek},
	month = oct,
	year = {2021},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {active learning, maximum likelihood estimation, semi supervision, Social sensing, truth discovery},
}

@article{bak-coleman_collective_2022,
	title = {Collective wisdom in polarized groups},
	volume = {1},
	url = {https://doi.org/10.1177/26339137221104788},
	doi = {10.1177/26339137221104788},
	abstract = {The potential for groups to outperform the cognitive capabilities of even highly skilled individuals, known as the “wisdom of the crowd”, is crucial to the functioning of democratic institutions. In recent years, increasing polarization has led to concern about its effects on the accuracy of electorates, juries, courts, and congress. While there is empirical evidence of collective wisdom in partisan crowds, a general theory has remained elusive. Central to the challenge is the difficulty of disentangling the effect of limited interaction between opposing groups (homophily) from their tendency to hold opposing viewpoints (partisanship). To overcome this challenge, we develop an agent-based model of collective wisdom parameterized by the experimentally-measured behaviour of participants across the political spectrum. In doing so, we reveal that differences across the political spectrum in how individuals express and respond to knowledge interact with the structure of the network to either promote or undermine wisdom. We verify these findings experimentally and construct a more general theoretical framework. Finally, we provide evidence that incidental, context-specific differences across the political spectrum likely determine the impact of polarization. Overall, our results show that whether polarized groups benefit from collective wisdom is generally predictable but highly context-specific.},
	number = {1},
	journal = {Collective Intelligence},
	author = {Bak-Coleman, Joseph B and Tokita, Christopher K and Morris, Dylan H and Rubenstein, Daniel I and Couzin, Iain D},
	month = sep,
	year = {2022},
	note = {Place: USA
Publisher: Sage Publications, Inc.},
	keywords = {collective wisdom, polarization, wisdom of the crowds},
}

@article{di_foraging_2022,
	title = {A {Foraging} {Strategy} with {Risk} {Response} for {Individual} {Robots} in {Adversarial} {Environments}},
	volume = {13},
	issn = {2157-6904},
	url = {https://doi.org/10.1145/3514499},
	doi = {10.1145/3514499},
	abstract = {As an essential problem in robotics, foraging means that robots collect objects from a given environment and return them to a specified location. On many occasions, robots are required to perform foraging tasks in adversarial environments, such as battlefield rescue, where potential adversaries may damage robots with a certain probability. The longer an individual robot moves through adversarial environments, the higher the probability of being damaged by adversaries. The robot system can gain utility only when the robot brings carried objects back to a predetermined home station. Such a risk of being damaged makes returning home at different locations potentially relevant to the expected utility produced by the robot. Thus, the individual robot faces a dilemma when it responds to the potential risks in adversarial environments: whether to return the carried resources home or continue foraging tasks. In this article, two fundamental environment settings are discussed, homogeneous cases and heterogeneous cases. The former is analyzed as having both the optimal substructure property and the non-aftereffect property. Then, we present a dynamic programming (DP) algorithm that can find an optimal solution with polynomial time complexity. For the latter, it is proven that finding an optimal solution is ( mathcal NP ) -hard. We then propose a heuristic algorithm: A division hierarchical path planning (DHPP) algorithm that is based on the idea of dividing the foraging routes generated initially into a certain number of subroutes to dilute risks. Finally, these algorithms are extensively evaluated in simulations, concluding that in adversarial environments, they can significantly improve the productivity of an individual robot before it is damaged.},
	number = {5},
	journal = {ACM Trans. Intell. Syst. Technol.},
	author = {Di, Kai and Zhou, Yifeng and Yan, Fuhan and Jiang, Jiuchuan and Yang, Shaofu and Jiang, Yichuan},
	month = jun,
	year = {2022},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {dynamic programming, heuristic, integer programming, Mobile robot foraging, path planning, robotics in adversarial environments},
}

@article{alvarez_de_la_vega_understanding_2023,
	title = {Understanding {Platform} {Mediated} {Work}-{Life}: {A} {Diary} {Study} with {Gig} {Economy} {Freelancers}},
	volume = {7},
	url = {https://doi.org/10.1145/3579539},
	doi = {10.1145/3579539},
	abstract = {Online freelancing platforms, such as Upwork, hold great promise in enabling flexible work opportunities where freelancers can combine their work with other life responsibilities, hereafter work-life. However, prior research suggests that platform features and self-managing demands of freelance work can jeopardise this apparent flexibility. In this paper, we report findings from a qualitative study, combining a 14-diary and semi-structured interview with 15 Upwork freelancers. We explored online freelancers' work practices, challenges, and the impact of platform features on their everyday lives. Our qualitative data suggest that platform features and individual context shape online freelancers' work-life practices. Freelancers develop strategies to mitigate platforms' constraints and balance their individual preferences and responsibilities. Further, our findings illustrate how platform features challenge freelancers' availability expectations, work autonomy, and work detachment. This paper contributes an empirical understanding of the factors influencing online freelancers' work-life practices by drawing upon Wanda J. Orlikowski's Structuration Model of Technology. This theoretical lens renders the interplay of freelancers, platforms, and instituted norms of freelance work.},
	number = {CSCW1},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Alvarez de la Vega, Juan Carlos and Cecchinato, Marta E. and Rooksby, John and Newbold, Joseph},
	month = apr,
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {gig economy, online freelancing, Upwork, work practices, work-life balance},
}

@article{ornik_learning_2021,
	title = {Learning and planning for time-varying {MDPs} using maximum likelihood estimation},
	volume = {22},
	issn = {1532-4435},
	abstract = {This paper proposes a formal approach to online learning and planning for agents operating in a priori unknown, time-varying environments. The proposed method computes the maximally likely model of the environment, given the observations about the environment made by an agent earlier in the system run and assuming knowledge of a bound on the maximal rate of change of system dynamics. Such an approach generalizes the estimation method commonly used in learning algorithms for unknown Markov decision processes with time-invariant transition probabilities, but is also able to quickly and correctly identify the system dynamics following a change. Based on the proposed method, we generalize the exploration bonuses used in learning for time-invariant Markov decision processes by introducing a notion of uncertainty in a learned time-varying model, and develop a control policy for time-varying Markov decision processes based on the exploitation and exploration trade-off. We demonstrate the proposed methods on four numerical examples: a patrolling task with a change in system dynamics, a two-state MDP with periodically changing outcomes of actions, a wind ow estimation task, and a multi-armed bandit problem with periodically changing probabilities of different rewards.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Ornik, Melkior and Topcu, Ufuk},
	month = jan,
	year = {2021},
	note = {Publisher: JMLR.org},
	keywords = {changing environment, Markov decision processes, maximum likelihood estimation, online learning, uncertainty quantification},
}

@article{ba_keep_2024,
	title = {Keep {It} {Simple}: {Testing} {Databases} via {Differential} {Query} {Plans}},
	volume = {2},
	url = {https://doi.org/10.1145/3654991},
	doi = {10.1145/3654991},
	abstract = {Query optimizers perform various optimizations, many of which have been proposed to optimize joins. It is pivotal that these optimizations are correct, meaning that they should be extensively tested. Besides manually written tests, automated testing approaches have gained broad adoption. Such approaches semi-randomly generate databases and queries. More importantly, they provide a so-called test oracle that can deduce whether the system's result is correct. Recently, researchers have proposed a novel testing approach called Transformed Query Synthesis (TQS) specifically designed to find logic bugs in join optimizations. TQS is a sophisticated approach that splits a given input table into several sub-tables and validates the results of the queries that join these sub-tables by retrieving the given table. We studied TQS's bug reports, and found that 14 of 15 unique bugs were reported by showing discrepancies in executing the same query with different query plans. Therefore, in this work, we propose a simple alternative approach to TQS. Our approach enforces different query plans for the same query and validates that the results are consistent. We refer to this approach as Differential Query Plan (DQP) testing. DQP can reproduce 14 of the 15 unique bugs found by TQS, and found 26 previously unknown and unique bugs. These results demonstrate that a simple approach with limited novelty can be as effective as a complex, conceptually appealing approach. Additionally, DQP is complementary to other testing approaches for finding logic bugs. 81\% of the logic bugs found by DQP cannot be found by NoREC and TLP, whereas DQP overlooked 86\% of the bugs found by NoREC and TLP. We hope that the practicality of our approach—we implemented in less than 100 lines of code per system—will lead to its wide adoption.},
	number = {3},
	journal = {Proc. ACM Manag. Data},
	author = {Ba, Jinsheng and Rigger, Manuel},
	month = may,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {join, logic bug},
}

@article{ramos_forsense_2022,
	title = {{ForSense}: {Accelerating} {Online} {Research} {Through} {Sensemaking} {Integration} and {Machine} {Research} {Support}},
	volume = {12},
	issn = {2160-6455},
	url = {https://doi.org/10.1145/3532853},
	doi = {10.1145/3532853},
	abstract = {Online research is a frequent and important activity people perform on the Internet, yet current support for this task is basic, fragmented and not well integrated into web browser experiences. Guided by sensemaking theory, we present ForSense, a browser extension for accelerating people’s online research experience. The two primary sources of novelty of ForSense\&nbsp; are the integration of multiple stages of online research and providing machine assistance to the user by leveraging recent advances in neural-driven machine reading. We use ForSense\&nbsp; as a design probe to explore (1) the benefits of integrating multiple stages of online research, (2) the opportunities to accelerate online research using current advances in machine reading, (3) the opportunities to support online research tasks in the presence of imprecise machine suggestions, and (4) insights about the behaviors people exhibit when performing online research, the pages they visit, and the artifacts they create. Through our design probe, we observe people performing online research tasks, and see that they benefit from ForSense’s integration and machine support for online research. From the information and insights we collected, we derive and share key recommendations for designing and supporting imprecise machine assistance for research tasks.},
	number = {4},
	journal = {ACM Trans. Interact. Intell. Syst.},
	author = {Ramos, Gonzalo and Rachatasumrit, Napol and Suh, Jina and Ng, Rachel and Meek, Christopher},
	month = nov,
	year = {2022},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Human-AI collaboration, sensemaking},
}

@article{chakraborty_experiences_2024,
	title = {Experiences from {Running} a {Participatory} {Media} {Platform} for {Women} and {Led} by {Women} in {Rural} {North} {India}},
	volume = {8},
	url = {https://doi.org/10.1145/3653685},
	doi = {10.1145/3653685},
	abstract = {Patriarchal practices and other socio-cultural norms in rural North India often prevent women from participating in digital platforms. In this paper we present a voice-based participatory community media platform that runs over simple voice-based phone calls. The platform is meant for women users and is led by women and has been used by 12,222 women users over the course of 20 months. We conduct a qualitative study and present several innovations, such as creating a safe space for women, which have contributed to more participation of women on the platform. We present a framework which can serve as a guidance for researchers and practitioners who want to set up digital platforms for women users.},
	number = {CSCW1},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Chakraborty, Dipanjan and Chatterjee, Sayonee and Tripathi, Rajeshwari and Gupta, Akshay and Seth, Aaditeshwar, Seth},
	month = apr,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {digital divide, ivr, participatory media, platform for women},
}

@article{ibrahim_understanding_2024,
	title = {Understanding {Online} {Parental} {Help}-{Seeking} and {Help}-{Giving} in {Early} {Childhood}: {The} {Design} {Challenges} of {Supporting} {Complex} {Parenting} {Questions}},
	volume = {8},
	url = {https://doi.org/10.1145/3653690},
	doi = {10.1145/3653690},
	abstract = {Early parenting is one of the strongest predictors of child well-being. Online social communities have shown promise in supporting parents across a range of contexts. However, we only have a limited understanding of how posters and commenters interact within a forum, or how well commenter responses can support complex parenting questions, such as attempts to change a child's behaviour or to apply new parenting approaches. We start addressing this gap by combining an empirical analysis of 1 year of parent posts from an exemplar online forum (Mumsnet) with literature on parenting interventions from psychology. In particular, we examine the types of question parents of 2-5 year olds seek help for around their children's behaviour, and the challenges with the support that they do (or do not) receive from the Mumsnet community. Combining empirical and theory-driven insights, we outline an 'information-to-application' gap that conceptually underpins the difficulties observed, and suggest plausible research directions that could address such design problems.},
	number = {CSCW1},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Ibrahim, Seray and Ang, Jazz Rui Xia and Petsolari, Melina and Michelson, Rebecca and Dong, Yuzhen and Theofanopoulou, Nikki and Van Kleek, Max and Davis, Katie and Slovák, Petr},
	month = apr,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {online support systems, parenting, parenting interventions, socio-technical design},
}

@article{seeman_between_2024,
	title = {Between {Privacy} and {Utility}: {On} {Differential} {Privacy} in {Theory} and {Practice}},
	volume = {1},
	url = {https://doi.org/10.1145/3626494},
	doi = {10.1145/3626494},
	abstract = {Differential privacy (DP) aims to confer data processing systems with inherent privacy guarantees, offering strong protections for personal data. But DP’s approach to privacy carries with it certain assumptions about how mathematical abstractions will be translated into real-world systems, which—if left unexamined and unrealized in practice—could function to shield data collectors from liability and criticism, rather than substantively protect data subjects from privacy harms. This article investigates these assumptions and discusses their implications for using DP to govern data-driven systems. In Parts 1 and 2, we introduce DP as, on one hand, a mathematical framework and, on the other hand, a kind of real-world sociotechnical system, using a hypothetical case study to illustrate how the two can diverge. In Parts 3 and 4, we discuss the way DP frames privacy loss, data processing interventions, and data subject participation, arguing it could exacerbate existing problems in privacy regulation. In part 5, we conclude with a discussion of DP’s potential interactions with the endogeneity of privacy law, and we propose principles for best governing DP systems. In making such assumptions and their consequences explicit, we hope to help DP succeed at realizing its promise for better substantive privacy protections.},
	number = {1},
	journal = {ACM J. Responsib. Comput.},
	author = {Seeman, Jeremy and Susser, Daniel},
	month = mar,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {critical code studies, Differential privacy, science and technology studies},
}

@article{li_mmhsv_2023,
	title = {{mmHSV}: {In}-{Air} {Handwritten} {Signature} {Verification} via {Millimeter}-{Wave} {Radar}},
	volume = {4},
	url = {https://doi.org/10.1145/3614443},
	doi = {10.1145/3614443},
	abstract = {Electronic signatures are widely used in financial business, telecommuting, and identity authentication. Offline electronic signatures are vulnerable to copy or replay attacks. Contact-based online electronic signatures are limited by indirect contact such as handwriting pads and may threaten the health of users. Consider combining hand shape features and writing process features to form electronic signatures, the article proposes an in-air handwritten signature verification system with millimeter-wave(mmWave) radar, namely mmHSV. First, the biometrics of the handwritten signature process are modeled, and phase-dependent biometrics and behavioral features are extracted from the mmWave radar mixture signal. Secondly, a handwritten feature recognition network based on few-sample learning is presented to fuse multi-dimensional features and determine user legitimacy. Finally, mmHSV is implemented and evaluated with commercial mmWave devices in different scenarios and attack mode conditions. Experimental results show that the mmHSV can achieve accurate, efficient, robust and scalable handwritten signature verification. Area Under Curve (AUC) is 98.96\%, False Acceptance Rate (FAR) is 5.1\% at the fixed threshold, AUC is 97.79\% for untrained users.},
	number = {4},
	journal = {ACM Trans. Internet Things},
	author = {Li, Wanqing and He, Tongtong and Jing, Nan and Wang, Lin},
	month = nov,
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {authentication, Handwritten, millimeter-wave radar, siamese network, signature verification},
}

@article{kapp_data-driven_2020,
	title = {Data-driven authoring of large-scale ecosystems},
	volume = {39},
	issn = {0730-0301},
	url = {https://doi.org/10.1145/3414685.3417848},
	doi = {10.1145/3414685.3417848},
	abstract = {In computer graphics populating a large-scale natural scene with plants in a fashion that both reflects the complex interrelationships and diversity present in real ecosystems and is computationally efficient enough to support iterative authoring remains an open problem. Ecosystem simulations embody many of the botanical influences, such as sunlight, temperature, and moisture, but require hours to complete, while synthesis from statistical distributions tends not to capture fine-scale variety and complexity.Instead, we leverage real-world data and machine learning to derive a canopy height model (CHM) for unseen terrain provided by the user. Trees in the canopy layer are then fitted to the resulting CHM through a constrained iterative process that optimizes for a given distribution of species, and, finally, an understorey layer is synthesised using distributions derived from biome-specific undergrowth simulations. Such a hybrid data-driven approach has the advantage that it incorporates subtle biotic, abiotic, and disturbance factors implicitly encoded in the source data and evidences accepted biological behaviour, such as self-thinning, climatic adaptation, and gap dynamics.},
	number = {6},
	journal = {ACM Trans. Graph.},
	author = {Kapp, Konrad and Gain, James and Guérin, Eric and Galin, Eric and Peytavie, Adrien},
	month = nov,
	year = {2020},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {ecosystem simulation, natural phenomena},
}

@article{reid_feeling_2022,
	title = {Feeling {Good} and {In} {Control}: {In}-game {Tools} to {Support} {Targets} of {Toxicity}},
	volume = {6},
	url = {https://doi.org/10.1145/3549498},
	doi = {10.1145/3549498},
	abstract = {Game developers, researchers, and players recognize the harm of toxic behaviour in online games-yet toxicity persists. Players' coping strategies are limited to tools that focus on punishing toxic players (e.g., muting, blocking, reporting), which are inadequate and often misused. To address the needs of players experiencing toxicity, we took inspiration from research in other online spaces that provide support tools for targets of harassment. We iteratively designed and evaluated in-game tools to support targets of toxicity. While we found that most players prefer tools that explicitly address toxicity and increase feelings of control, we also found that tools that solely provide social or emotional support also decrease stress, increase feelings of control, and increase positive affect. Our findings suggest that players may benefit from variety in toxicity support tools that both explicitly address toxicity in the moment and help players cope after it has occurred.},
	number = {CHI PLAY},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Reid, Elizabeth and Mandryk, Regan L. and Beres, Nicole A. and Klarkowski, Madison and Frommel, Julian},
	month = oct,
	year = {2022},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {control, games, griefing, harassment, mood, report, support, toxic, toxicity},
}

@article{stojkovski_unless_2022,
	title = {“{Unless} {One} {Does} the {Research}, {It} {May} {Seem} as {Just} a {Useless} {Battery}-consuming {App}” – {Field} {Notes} on {COVID}-19 {Contact} {Tracing} {Applications}},
	volume = {3},
	url = {https://doi.org/10.1145/3480466},
	doi = {10.1145/3480466},
	abstract = {Globally, countries have been developing contact tracing applications to control the spread of the coronavirus (COVID-19) disease. In this work, we present the findings of eight focus groups we conducted with participants living in France and Germany, to explore why they decided to adopt, or not adopt, a contact tracing application as well as understand how they perceived the benefits, drawbacks, and threat model of a contact tracing application.},
	number = {3},
	journal = {Digital Threats},
	author = {Stojkovski, Borce and Abu-Salma, Ruba and Triquet, Karen and Lenzini, Gabriele},
	month = mar,
	year = {2022},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {contact tracing, COVID-19, human factors, proximity tracing, user adoption},
}

@article{wang_tdefsi_2020,
	title = {{TDEFSI}: {Theory}-guided {Deep} {Learning}-based {Epidemic} {Forecasting} with {Synthetic} {Information}},
	volume = {6},
	issn = {2374-0353},
	url = {https://doi.org/10.1145/3380971},
	doi = {10.1145/3380971},
	abstract = {Influenza-like illness (ILI) places a heavy social and economic burden on our society. Traditionally, ILI surveillance data are updated weekly and provided at a spatially coarse resolution. Producing timely and reliable high-resolution spatiotemporal forecasts for ILI is crucial for local preparedness and optimal interventions. We present Theory-guided Deep Learning-based Epidemic Forecasting with Synthetic Information (TDEFSI),1 an epidemic forecasting framework that integrates the strengths of deep neural networks and high-resolution simulations of epidemic processes over networks. TDEFSI yields accurate high-resolution spatiotemporal forecasts using low-resolution time-series data.During the training phase, TDEFSI uses high-resolution simulations of epidemics that explicitly model spatial and social heterogeneity inherent in urban regions as one component of training data. We train a two-branch recurrent neural network model to take both within-season and between-season low-resolution observations as features and output high-resolution detailed forecasts. The resulting forecasts are not just driven by observed data but also capture the intricate social, demographic, and geographic attributes of specific urban regions and mathematical theories of disease propagation over networks.We focus on forecasting the incidence of ILI and evaluate TDEFSI’s performance using synthetic and real-world testing datasets at the state and county levels in the USA. The results show that, at the state level, our method achieves comparable/better performance than several state-of-the-art methods. At the county level, TDEFSI outperforms the other methods. The proposed method can be applied to other infectious diseases as well.},
	number = {3},
	journal = {ACM Trans. Spatial Algorithms Syst.},
	author = {Wang, Lijing and Chen, Jiangzhuo and Marathe, Madhav},
	month = apr,
	year = {2020},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {causal model, deep neural network, Epidemic forecasting, LSTM, physical consistency, synthetic information},
}

@article{schott_terrain_2024,
	title = {Terrain {Amplification} using {Multi} {Scale} {Erosion}},
	volume = {43},
	issn = {0730-0301},
	url = {https://doi.org/10.1145/3658200},
	doi = {10.1145/3658200},
	abstract = {Modeling high-resolution terrains is a perennial challenge in the creation of virtual worlds. In this paper, we focus on the amplification of a low-resolution input terrain into a high-resolution, hydrologically consistent terrain featuring complex patterns by a multi-scale approach. Our framework combines the best of both worlds, relying on physics-inspired erosion models producing consistent erosion landmarks and introducing control at different scales, thus bridging the gap between physics-based erosion simulations and multi-scale procedural modeling. The method uses a fast and accurate approximation of different simulations, including thermal, stream power erosion and deposition performed at different scales to obtain a range of effects. Our approach provides landscape designers with tools for amplifying mountain ranges and valleys with consistent details.},
	number = {4},
	journal = {ACM Trans. Graph.},
	author = {Schott, Hugo and Galin, Eric and Guérin, Eric and Paris, Axel and Peytavie, Adrien},
	month = jul,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {erosion simulation, landscapes},
}

@article{li_blockchain_2025,
	title = {Blockchain in the {Digital} {Twin} {Context}: {A} {Comprehensive} {Survey}},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3772366},
	doi = {10.1145/3772366},
	abstract = {Digital twin (DT) technology integrates Internet of Things (IoT), communication networks, and sensor systems through high-fidelity modeling and multi-dimensional simulation, enabling dynamic mapping and real-time optimization of physical objects. However, DT development still faces several challenges, including cross-platform interoperability limitations, excessive latency in real-time scenarios, security vulnerabilities in distributed deployments, and the complexity of accurately modeling multi-modal systems. Blockchain (BC) enhances the security and functional scope of DTs across diverse applications. This survey begins by introducing the core principles of BC and DT, and then investigates the rationale and benefits behind their integration. From a data-centric perspective, we explore how Blockchain-empowered Digital Twins (BCDTs) enhance data storage, secure exchange, privacy protection, and system interoperability. The survey further explores the architecture of BCDT systems, covering network topology, functional modules, platform design, and representative prototypes, offering insights into real-world applications. In addition, we survey how BCDT supports the convergence of key Industry 4.0 technologies, including the Internet of Things, vehicle networks, unmanned aerial systems, artificial intelligence, federated learning, 5G mobile networks, and software-defined networking. Industrial-grade quality BCDT-supported applications are highlighted, providing a solid foundation for further research. Finally, we analyze the challenges faced by BCDT and offer some optimistic suggestions for further research in the field of BCDT.},
	journal = {ACM Comput. Surv.},
	author = {Li, Dun and Han, Dezhi and Crespi, Noel and Minerva, Roberto and Raza, Syed Mohsan and Farahbakhsh, Reza and Liang, Wei and Zheng, Zibin},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Blockchain, Digital twin, Industrial applications., Industry 4.0, Smart contract},
	annote = {Just Accepted},
}

@article{chang_designing_2025,
	title = {Designing {Authoritative} {Presence} in {Social} {Robots}},
	volume = {15},
	url = {https://doi.org/10.1145/3748262},
	doi = {10.1145/3748262},
	abstract = {We define authoritative presence as letting people experience authority through human-made technology in sensory or non-sensory ways. Our goal is to design a robot that creates the impression of possessing capabilities worthy of respect as a source of authority, thereby enhancing compliance without attributing that authority to external sources, such as a specific person or organization. We hypothesized that strategies commonly used in the Wizard-of-Oz method could help manipulate authoritative presence as it strives to ensure that the robot is not perceived as having additional abilities beyond those introduced by the manipulations. Wizards typically need to maintain the robot’s functionality and abilities at an appropriate level to minimize unwanted influence on participants’ perceptions and interactions. By interviewing HRI researchers who have wizarded, we summarized their usual strategies and implemented the opposite behaviors in a robot to investigate if this would contribute to authoritative presence. Based on the findings, we designed four behaviors that include (1) let the robot have an open-ended conversation with people, (2) randomize the robot’s reaction delay timing, (3) let the robot move with inconsistent velocity, and (4) let the robot perceive people’s status without looking at them. To evaluate the impact of these behaviors, we conducted a video-based online experiment with 942 participants, using a between-subjects design. The experiment aimed to determine whether the behaviors conveying authoritative presence would make people perceive the robot as having more authority and increase their likelihood of complying with its requests. A mediation analysis indicated that despite a decrease in perceived authority, the imply authoritative presence condition had a positive effect on participant compliance. Our study formally introduces the concept of authoritative presence, providing a proof-of-concept for how robots can create authoritative presence through specific behaviors. This work lays the groundwork for future research on authority and robotics.},
	number = {1},
	journal = {J. Hum.-Robot Interact.},
	author = {Chang, Yuan-Chia and Rea, Daniel J. and Lee, Chi-Jung and Kanda, Takayuki and Chen, Bing-Yu},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {authoritative presence, authority, compliance, Human-robot interaction, presence},
}

@article{norihama_examining_2025,
	title = {Examining {Input} {Modalities} and {Visual} {Feedback} {Designs} in {Mobile} {Expressive} {Writing}},
	volume = {9},
	url = {https://doi.org/10.1145/3743723},
	doi = {10.1145/3743723},
	abstract = {Expressive writing is an established approach for stress management. Recently, information technologies, such as smartphones, have also been explored for expressive writing. Although mobile interfaces have the potential to support various daily writing activities, interface designs for mobile expressive writing and their effects on stress relief still lack empirical understanding. We examined the interface design of mobile expressive writing by investigating the influence of input modalities and visual feedback designs on usability and perceived cathartic effects through field studies. While our studies confirmed the stress-relieving effects of mobile expressive writing, our results offer important insights into interface design. We found keyboard-based text entry more suited and preferred over voice messages for its privacy and reflective nature. Participants expressed different reasons for preferring different post-writing visual feedback depending on the cause and type of stress. This work advances interface design for mobile expressive writing and deepens understanding of its effects.},
	number = {5},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Norihama, Shunpei and Geng, Shixian and Miyazaki, Kakeru and Sato, Arissa J. and Hirano, Mari and Hosio, Simo and Yatani, Koji},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {cathartic effect, digital micro-interventions, expressive writing, mental self-care, stress coping},
}

@article{chen_bridging_2025,
	title = {Bridging {Cultural} {Representation} and {Game} {Making}: {Analyzing} the {Experiences}, {Outcomes}, and {Lessons} of {Early}-{Stage} {Game} {Developers} in a {Professional} {Development} {Program}},
	volume = {9},
	url = {https://doi.org/10.1145/3748627},
	doi = {10.1145/3748627},
	abstract = {As the game industry expands, an increasing number of students and hobbyists are entering the game development field, eager to create their own titles. However, there is a lack of structured training programs that effectively prepare them for industry demands. Games convey meaningful messages through stories, assets, and mechanics, yet how early-stage developers make creative decisions while building production skills remains unclear. We explored skill development and cultural representation in game design during a 10-week professional development program at MassDigi with early-stage developers from the United Arab Emirates (UAE). Our findings reveal three observed strategies as themes through which developers incorporate their personal experiences and cultural backgrounds into game development to achieve cultural representation, as well as four themes that address developers' skill set improvement and personal growth during this process. We recommend structuring programs by considering these themes to enhance self-expressive game design and support skill development through a peer learning community.},
	number = {6},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Chen, Max and Smith, Gillian},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {cultural representation, game design, game development education, professional development program, situated learning},
}

@article{franco_integrating_2025,
	title = {Integrating {Content} {Moderation} {Systems} with {Large} {Language} {Models}},
	volume = {19},
	issn = {1559-1131},
	url = {https://doi.org/10.1145/3700789},
	doi = {10.1145/3700789},
	abstract = {Online Social Networks (OSNs) rely on content moderation systems to ensure platform and user safety by preventing malicious activities such as the spread of harmful content. However, there is a growing consensus suggesting that such systems are unfair to historically marginalized individuals, fragile users, and minorities. Additionally, OSN policies are often hardcoded in artificial intelligence–based violation classifiers, making personalized content moderation challenging. In addition, there is a need for more communication between users and platform administrators, especially in the case of disagreement about a moderation decision. To address these issues, we propose integrating content moderation systems with Large Language Models (LLMs) to enhance support for personal content moderation and improve user–platform communication. We also evaluate the content moderation capabilities of GPT 3.5 and LLaMa 2, comparing them with commercial products, as well as discuss the limitations of our approach and the open research directions.},
	number = {2},
	journal = {ACM Trans. Web},
	author = {Franco, Mirko and Gaggi, Ombretta and Palazzi, Claudio E.},
	month = may,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Content moderation, large language models, online social networks},
}

@article{keyes_reimagining_2020,
	title = {Reimagining ({Women}’s) {Health}: {HCI}, {Gender} and {Essentialised} {Embodiment}},
	volume = {27},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/3404218},
	doi = {10.1145/3404218},
	abstract = {An ever-increasing body of work within HCI investigates questions of around “Women’s Health” with the aim to disrupt the status quo of defaulting to an implicit norm of cis-male bodies. This laudable and feminist project has the potential to drastically improve the inclusivity and availability of health care. To explore how this research attends to gender, embodiment and identity, we conducted a critical discourse analysis of 17 publications explicitly positioning themselves as works concerned with “Women’s Health”. We find essentialised articulations of embodiment and gender, though little discussion on the intersections of race, class, sexuality and cultural contexts. Through two speculative designs, we illustrate potential responses to our analysis: The Shadow Zine, a reflection of self and the Compass, a token for community care.1 Our work provides an opportunity to develop a broader frame of gender and health, one that centers (gendered) marginalised health by attending to the power structures of existing medical practices and norms.},
	number = {4},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	author = {Keyes, Os and Peil, Burren and Williams, Rua M. and Spiel, Katta},
	month = aug,
	year = {2020},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {critical theory, embodiment, essentialism, Gender, health, marginalisation, speculative design, women’s health},
}

@article{stuhn_hidden_2024,
	title = {The {Hidden} {Threat}: {Analysis} of {Linux} {Rootkit} {Techniques} and {Limitations} of {Current} {Detection} {Tools}},
	volume = {5},
	url = {https://doi.org/10.1145/3688808},
	doi = {10.1145/3688808},
	abstract = {This article addresses the significant threat posed by rootkits as part of the diverse malware landscape of today. Rootkits enable an attacker to regain access to an already comprised system at root-level making their prompt identification and removal crucial. However, rootkits implement advanced stealth features, enabling them to evade detection by conventional measures during analysis. Consequently, analysts generally rely on customized tools to detect the presence of a rootkit. However, our research highlights significant deficits in the tools available for the detection of rootkits on the Linux operating system, which is frequently encountered in investigations of server environments. Recognizing the need for improved awareness and capabilities among investigators, we conducted an in-depth analysis of 21 distinct Linux rootkits allowing us to dive into their techniques and features. Furthermore, we critically assessed the effectiveness of standard detection tools, revealing their limitations. Based on these insights, we propose best practices for investigators to effectively identify and detect signs of rootkit infections. Additionally, we provide a repository of indicators of compromise we extracted during our analyses to facilitate the detection of the analyzed rootkits on compromised systems along with a utility to detect rootkits via hidden files on a live system.},
	number = {3},
	journal = {Digital Threats},
	author = {Stühn, Jakob and Hilgert, Jan-Niclas and Lambertz, Martin},
	month = oct,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Detection, Incident Response, Linux, Malware, Rootkits},
}

@article{cordonnier_forming_2023,
	title = {Forming {Terrains} by {Glacial} {Erosion}},
	volume = {42},
	issn = {0730-0301},
	url = {https://doi.org/10.1145/3592422},
	doi = {10.1145/3592422},
	abstract = {We introduce the first solution for simulating the formation and evolution of glaciers, together with their attendant erosive effects, for periods covering the combination of glacial and inter-glacial cycles. Our efficient solution includes both a fast yet accurate deep learning-based estimation of highorder ice flows and a new, multi-scale advection scheme enabling us to account for the distinct time scales at which glaciers reach equilibrium compared to eroding the terrain. We combine the resulting glacial erosion model with finer-scale erosive phenomena to account for the transport of debris flowing from cliffs. This enables us to model the formation of terrain shapes not previously adequately modeled in Computer Graphics, ranging from U-shaped and hanging valleys to fjords and glacial lakes.},
	number = {4},
	journal = {ACM Trans. Graph.},
	author = {Cordonnier, Guillaume and Jouvet, Guillaume and Peytavie, Adrien and Braun, Jean and Cani, Marie-Paule and Benes, Bedrich and Galin, Eric and Guérin, Eric and Gain, James},
	month = jul,
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {erosion, glacial erosion, landscape, simulation of natural phenomena, terrain},
}

@article{shrestha_no_2025,
	title = {No {Country} for {Indie} {Developers}: {A} {Study} of {Google} {Play}’s {Closed} {Testing} {Requirements} for {New} {Personal} {Developer} {Accounts}},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3736578},
	doi = {10.1145/3736578},
	abstract = {In November 2023, Google Play introduced new closed testing requirements for apps submitted by developers operating with personal accounts, or indie app developers. These requirements mandate that at least 20 testers must remain opted-in (use the app) for at least 14 consecutive days before the app can be published on the Play Store. According to Google, these new requirements aim to ensure the quality and security of submitted apps. However, for individual developers operating without organizational support, adhering to such requirements can pose logistical challenges and lead to production delays. To understand these challenges, in this paper, we qualitatively analyze app developers’ discussions of Google Play’s new closed testing requirements on Reddit. Additionally, we report insights from a survey of 14 indie app developers who recently passed the requirements or are actively seeking compliance. Our results show that Google Play’s closed testing requirements for indie apps are commonly perceived as discriminatory, imposing logistical and bureaucratic barriers on small-scale creators in their quest to compete in the mobile app market. Our analysis also uncovers the strategies the Android developer community has adapted to navigate such requirements. Based on our findings, we propose several guidelines to help indie app developers integrate the testing requirements into their workflow. We further suggest design strategies to mitigate the impact of such requirements on innovation, fairness, and competition in the mobile app market.},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Shrestha, Grishma and Shrestha, Shristi and Mahmoud, Anas},
	month = may,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {closed testing, Google Play, indie developers},
	annote = {Just Accepted},
}

@article{liu_envisioning_2025,
	title = {Envisioning {AI} {Support} during {Semi}-{Structured} {Interviews} {Across} the {Expertise} {Spectrum}},
	volume = {9},
	url = {https://doi.org/10.1145/3710909},
	doi = {10.1145/3710909},
	abstract = {Semi-structured interviews are a critical qualitative method in many areas, including CSCW and HCI, enabling researchers to uncover deep contextualized insights. Using this flexible method, interviewers must adapt to interviewees' responses while adhering to the protocol, necessitating strong active listening and real-time analytical skills. While recent studies have explored how AI can support researchers in qualitative analysis, to our knowledge, no research has investigated AI's role in supporting semi-structured interviews while they are underway. Taking one step toward filling this gap, we interviewed 16 researchers with a range of prior interviewing expertise. Our inductive thematic analysis reveals that interviewers expect real-time AI assistance to support research objectives and facilitate interpersonal communication, but also have concerns about its impact on long-term skill development. We discuss how semi-structured interviews differ from other problem-solving or creative human-AI collaboration contexts, highlighting the time constraints, multimodal collaboration, and the triangular dynamic among interviewers, interviewees, and AI. We also delve into how interviewers' levels of expertise affect their envisioned interviewer-AI collaboration. We then propose design challenges for future CSCW work on AI-driven assistants in interview contexts.},
	number = {2},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Liu, Zhe and Dai, Jiamin and Conati, Cristina and McGrenere, Joanna},
	month = may,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {AI, human-AI collaboration, interview, qualitative research},
}

@article{liu_gsfl_2025,
	title = {{GSFL}: {A} {Privacy}-preserving {Grouping}-{Split} {Federated} {Learning} {Approach} in {Resource}-constrained {Edge} {Computing} {Scenarios}},
	issn = {1556-4665},
	url = {https://doi.org/10.1145/3725221},
	doi = {10.1145/3725221},
	abstract = {The advancement of mobile multimedia communications, 5G, and Internet of Things (IoT) has led to the widespread use of edge devices, including sensors, smartphones, and wearables. This has generated in a large amount of distributed data, leading to new prospects for deep learning. However, this data is confined within data silos and contains sensitive information, making it difficult to be processed in a centralized manner, particularly under stringent data privacy regulations. Federated learning (FL) offers a solution by enabling collaborative learning while ensuring privacy. Nonetheless, data and device heterogeneity complicate FL implementation. This research presents a specialized FL algorithm for heterogeneous edge computing. It integrates a lightweight grouping strategy for homogeneous devices, a scheduling algorithm within groups, and a Split Learning (SL) approach. These contributions enhance model accuracy and training speed, alleviate the burden on resource-constrained devices, and strengthen privacy. Experimental results demonstrate that the GSFL outperforms FedAvg and SplitFed by 6.53× and 1.18×. Under experimental conditions with (alpha=0.05) , representing a highly heterogeneous data distribution typical of extreme Non-IID scenarios, GSFL showed better accuracy compared to FedAvg by 10.64\%, HACCS by 4.53\%, and Cluster-HSFL by 1.16\%. GSFL effectively balances privacy protection and computational efficiency for real-world applications in mobile multimedia communications.},
	journal = {ACM Trans. Auton. Adapt. Syst.},
	author = {Liu, Qi and Wang, Zhilu and Zhou, Xiaokang and Zhang, Yonghong and Liu, Xiaodong and Lin, Haiyang},
	month = mar,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Clustering, Federated learning, Non-IID, Split learning},
	annote = {Just Accepted},
}

@article{cohen_this_2024,
	title = {This {Is} {Going} on {Your} {Permanent} {Record}: {A} {Legal} {Analysis} of {Educational} {Data} in the {Cloud}},
	volume = {1},
	url = {https://doi.org/10.1145/3675230},
	doi = {10.1145/3675230},
	abstract = {Moving operations to the cloud has become a way of life for many educational institutions. Much of the information these institutions store in the cloud is protected by the Family Educational Rights and Privacy Act (FERPA), which was last amended in 2002, well before cloud computing became ubiquitous. The application of a 1974 law to 21st-century technology presents a plethora of legal and technical questions. In this article, we present an interdisciplinary analysis of these issues. We examine both existing statutes and case law and contemporary research into cloud security, focusing on the impact of the latter on the former. We find that FERPA excludes information that students and faculty often believe is protected and that lower-court decisions have created further ambiguity. We additionally find that given current technology, the statute is no longer sufficient to protect student data, and we present recommendations for revisions.},
	number = {3},
	journal = {ACM J. Responsib. Comput.},
	author = {Cohen, Ben and Hu, Ashley and Patino, Deisy and Coffman, Joel},
	month = aug,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {cloud computing, computer security, law, NIST Cybersecurity Framework, privacy, standards, student records, The Family Educational Rights and Privacy Act (FERPA)},
}

@article{mostafa_modality_2024,
	title = {Modality {Deep}-learning {Frameworks} for {Fake} {News} {Detection} on {Social} {Networks}: {A} {Systematic} {Literature} {Review}},
	volume = {57},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3700748},
	doi = {10.1145/3700748},
	abstract = {Fake news on social networks is a challenging problem due to the rapid dissemination and volume of information, as well as the ease of creating and sharing content anonymously. Fake news stories are problematic not only for the credibility of online journalism, but also due to their detrimental real-world consequences. The primary research objective of this study is to identify recent state-of-the-art deep learning methods used to detect fake news in social networks. This article presents a systematic literature review of deep learning-based fake news detection models in social networks. The methodology followed a rigorous approach, including predefined criteria for study selection of deep learning modalities. This study focuses on the types of deep learning modalities: unimodal (refers to the use of a single model for analysis or modeling purposes) and multimodal models (refers to the integration of multiple models). The results of this review reveal the strengths and weaknesses of modalities approaches, as well as the limitations of low-resource languages datasets. Furthermore, it provides insights into future directions for deep learning models and different fact-checking techniques. At the end of this study, we discuss the problem of fake news detection in the era of large language models in terms of advantages, drawbacks, and challenges.},
	number = {3},
	journal = {ACM Comput. Surv.},
	author = {Mostafa, Mohamed and Almogren, Ahmad S and Al-Qurishi, Muhammad and Alrubaian, Majed},
	month = nov,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {deep learning, fake news detection, modality architectures, multimodal, Social computing, text classification, unimodal},
}

@article{chavan_global-local_2025,
	title = {Global-{Local} {Dynamics}: {Strategies} for {Cross}-{Cultural} {UX} {Design} in a {Globalized} {World}},
	volume = {19},
	issn = {1931-3357},
	abstract = {We live in a connected world in which people and places are closer than ever, thanks to advances in technology and transportation. This interconnectedness has opened huge global markets for products and services which, for designers, presents both exciting opportunities and tough challenges. Designing for people from different cultures is difficult because it involves catering to a need—the core characteristic of the product—but in a way that aligns with their cultural expectations. It is a careful balance because excessive localization, or too little of it, can result in failure. Notable examples are American companies such as Mattel®, Home Depot®, and Best Buy™, which struggled in China due to differences in how people shop there. Even as big a player as Google™ has faced tough competition in places like South Korea.},
	number = {3},
	journal = {J. User Exper.},
	author = {Chavan, Apala Lahiri and Sivasubramaniam, Revathy},
	month = feb,
	year = {2025},
	note = {Place: Bloomingdale, IL
Publisher: Usability Professionals' Association},
	pages = {115--122},
}

@article{cutler_stochastic_2024,
	title = {Stochastic {Approximation} with {Decision}-{Dependent} {Distributions}: asymptotic {Stochastic} approximation with decision-dependent normality and optimality},
	volume = {25},
	issn = {1532-4435},
	abstract = {We analyze a stochastic approximation algorithm for decision-dependent problems, wherein the data distribution used by the algorithm evolves along the iterate sequence. The primary examples of such problems appear in performative prediction and its multiplayer extensions. We show that under mild assumptions, the deviation between the average iterate of the algorithm and the solution is asymptotically normal, with a covariance that clearly decouples the effects of the gradient noise and the distributional shift. Moreover, building on the work of Hájek and Le Cam, we show that the asymptotic performance of the algorithm with averaging is locally minimax optimal.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Cutler, Joshua and Díaz, Mateo and Drusvyatskiy, Dmitriy},
	month = jan,
	year = {2024},
	note = {Publisher: JMLR.org},
	keywords = {asymptotic normality, decision-dependent distributions, local asymptotic minimax optimality, performative prediction, stochastic approximation},
}

@article{chalumeau_qdax_2024,
	title = {{QDax}: a library for quality-diversity and population-based algorithms with hardware acceleration},
	volume = {25},
	issn = {1532-4435},
	abstract = {qdax is an open-source library with a streamlined and modular API for Quality-Diversity (QD) optimisation algorithms in jax. The library serves as a versatile tool for optimisation purposes, ranging from black-box optimisation to continuous control. QDAX offers implementations of popular QD, Neuroevolution, and Reinforcement Learning (RL) algorithms, supported by various examples. All the implementations can be just-in-time compiled with JAX, facilitating efficient execution across multiple accelerators, including GPUs and TPUs. These implementations effectively demonstrate the framework's flexibility and user-friendliness, easing experimentation for research purposes. Furthermore, the library is thoroughly documented and has 93\% test coverage.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Chalumeau, Felix and Lim, Bryan and Boige, Raphaël and Allard, Maxime and Grillotti, Luca and Flageat, Manon and Macé, Valentin and Richard, Guillaume and Flajolet, Arthur and Pierrot, Thomas and Cully, Antoine},
	month = jan,
	year = {2024},
	note = {Publisher: JMLR.org},
	keywords = {evolutionary computation, JAX, open-source, population-based learning, Python, quality diversity},
}

@article{mensonge_historically_2023,
	title = {Historically {Informed} {HCI}: {Reflecting} on {Contemporary} {Technology} through {Anachronistic} {Fiction}},
	volume = {29},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/3517144},
	doi = {10.1145/3517144},
	abstract = {As computing technology comes to dominate every aspect of social and political life, HCI must take greater account of History. The article considers four different historical periods impacted by division and denunciation: the European Witch Hunts, the Soviet Purges, the McCarthy Era, and the Chinese Cultural Revolution. Historians have identified patterns common to such periods including: the unity of accusation and action; condemnation as a show of virtue, and defense of the accused as collusion with enemies. These patterns are mapped to findings from social media research such as: impulsive shares are easy to make but difficult to retract; angry posts travel fastest and furthest; likes and retweets express group identity and solidarity. Anachronistic memes, tweets and selfies explore what previous eras might have looked like if contemporary technology had existed in the past. It is argued that such anachronistic fiction may be a useful method for exploring the potential impact of particular design choices.},
	number = {6},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	author = {Mensonge, Kien},
	month = apr,
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Design fiction, history, research fiction, thought experiment},
}

@article{narang_multiplayer_2023,
	title = {Multiplayer performative prediction: learning in decision-dependent games},
	volume = {24},
	issn = {1532-4435},
	abstract = {Learning problems commonly exhibit an interesting feedback mechanism wherein the population data reacts to competing decision makers' actions. This paper formulates a new game theoretic framework for this phenomenon, called multi-player performative prediction. We focus on two distinct solution concepts, namely (i) performatively stable equilibria and (ii) Nash equilibria of the game. The latter equilibria are arguably more informative, but are generally computationally difficult to find since they are solutions of nonmonotone games. We show that under mild assumptions, the performatively stable equilibria can be found efficiently by a variety of algorithms, including repeated retraining and the repeated (stochastic) gradient method. We then establish transparent sufficient conditions for strong monotonicity of the game and use them to develop algorithms for finding Nash equilibria. We investigate derivative free methods and adaptive gradient algorithms wherein each player alternates between learning a parametric description of their distribution and gradient steps on the empirical risk. Synthetic and semi-synthetic numerical experiments illustrate the results.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Narang, Adhyyan and Faulkner, Evan and Drusvyatskiy, Dmitriy and Fazel, Maryam and Ratliff, Lillian J.},
	month = jan,
	year = {2023},
	note = {Publisher: JMLR.org},
	keywords = {distributional shift, performative prediction, stochastic games, stochastic gradient method, stochastic optimization},
}

@article{nicol_revealing_2022,
	title = {Revealing {Cumulative} {Risks} in {Online} {Personal} {Information}: {A} {Data} {Narrative} {Study}},
	volume = {6},
	url = {https://doi.org/10.1145/3555214},
	doi = {10.1145/3555214},
	abstract = {When pieces from an individual's personal information available online are connected over time and across multiple platforms, this more complete digital trace can give unintended insights into their life and opinions. In a data narrative interview study with 26 currently employed participants, we examined risks and harms to individuals and employers when others joined the dots between their online information. We discuss the themes of visibility and self-disclosure, unintentional information leakage and digital privacy literacies constructed from our analysis. We contribute insights not only into people's difficulties in recalling and conceptualising their digital traces but of subsequently envisioning how their online information may be combined, or (re)identified across their traces and address a current gap in research by showing that awareness is lacking around the potential for personal information to be correlated by and made coherent to/by others, posing risks to individuals, employers, and even the state. We touch on inequalities of privacy, freedom and legitimacy that exist for different groups with regard to what they make (or feel compelled to make) available online and we contribute to current methodological work on the use of sketching to support visual sense making in data narrative interviews. We conclude by discussing the need for interventions that support personal reflection on the potential visibility of combined digital traces to spotlight hidden vulnerabilities, and promote more proactive action about what is shared and not shared online.},
	number = {CSCW2},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Nicol, Emma and Briggs, Jo and Moncur, Wendy and Htait, Amal and Carey, Daniel Paul and Azzopardi, Leif and Schafer, Burkhard},
	month = nov,
	year = {2022},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {cybersecurity, digital traces, human computer interaction, personal data, research design},
}

@article{brito_scpp_2020,
	title = {{SCPP}: {A} {Point} {Process}–based {Clustering} of {Spatial} {Visiting} {Patterns}},
	volume = {7},
	issn = {2374-0353},
	url = {https://doi.org/10.1145/3423405},
	doi = {10.1145/3423405},
	abstract = {A collection of individuals is represented by point patterns. Each individual is a finite set of geographical locations representing their visiting pattern to places in a region. We present SCPP, an algorithm for clustering these individuals considering the spatial patterns of their visiting locations. We adopted a probabilistic framework based on the theory of point processes that allows us to derive a non-obvious distance metric between each individual point pattern and the underlying, unobserved continuous intensity function. This metric is the Kullback-Leibler divergence between the true data-generating point process distribution and the model-generating distribution. We also introduce a theoretically based framework for the cost function to be minimized, a functional T(P) taking as arguments the probability distributions underlying the unknown clusters. We present an extensive experimental analysis to show SCPP’s effectiveness using several synthetic datasets and spatial mobility patterns from geo-tagged social media.},
	number = {1},
	journal = {ACM Trans. Spatial Algorithms Syst.},
	author = {Brito, Denise E. F. and Assunção, Renato M. and Souza, Roberto C. S. N. P. and JR., Wagner Meira},
	month = oct,
	year = {2020},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {point process-based spatial clustering, spatial behavior, Spatial patterns},
}

@article{nourani_importance_2022,
	title = {On the {Importance} of {User} {Backgrounds} and {Impressions}: {Lessons} {Learned} from {Interactive} {AI} {Applications}},
	volume = {12},
	issn = {2160-6455},
	url = {https://doi.org/10.1145/3531066},
	doi = {10.1145/3531066},
	abstract = {While EXplainable Artificial Intelligence (XAI) approaches aim to improve human-AI collaborative decision-making by improving model transparency and mental model formations, experiential factors associated with human users can cause challenges in ways system designers do not anticipate. In this article, we first showcase a user study on how anchoring bias can potentially affect mental model formations when users initially interact with an intelligent system and the role of explanations in addressing this bias. Using a video activity recognition tool in cooking domain, we asked participants to verify whether a set of kitchen policies are being followed, with each policy focusing on a weakness or a strength. We controlled the order of the policies and the presence of explanations to test our hypotheses. Our main finding shows that those who observed system strengths early on were more prone to automation bias and made significantly more errors due to positive first impressions of the system, while they built a more accurate mental model of the system competencies. However, those who encountered weaknesses earlier made significantly fewer errors, since they tended to rely more on themselves, while they also underestimated model competencies due to having a more negative first impression of the model. Motivated by these findings and similar existing work, we formalize and present a conceptual model of user’s past experiences that examine the relations between user’s backgrounds, experiences, and human factors in XAI systems based on usage time. Our work presents strong findings and implications, aiming to raise the awareness of AI designers toward biases associated with user impressions and backgrounds.},
	number = {4},
	journal = {ACM Trans. Interact. Intell. Syst.},
	author = {Nourani, Mahsan and Roy, Chiradeep and Block, Jeremy E. and Honeycutt, Donald R. and Rahman, Tahrima and Ragan, Eric D. and Gogate, Vibhav},
	month = dec,
	year = {2022},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {cognitive biases, conceptual models, Explainable AI, HCI, user studies},
}

@article{pescetelli_benefits_2022,
	title = {Benefits of spontaneous confidence alignment between dyad members},
	volume = {1},
	url = {https://doi.org/10.1177/26339137221126915},
	doi = {10.1177/26339137221126915},
	abstract = {In many domains, imitating others’ behaviour can help individuals to solve problems that would be too difficult or too complex for the individuals. In collective decision making tasks, people have been shown to use confidence as a means to communicate the uncertainty surrounding internal noisy estimates. Here, we show that confidence alignment, namely, shifting average confidence between dyad members towards each other, naturally emerges when interacting with others’ opinions. This alignment has a measurable impact on group performance as well as the accuracy of individual members following information exchange. It is suggested that confidence alignment arises among individuals from the necessity of minimising confidence variation arising from task-unrelated variables (trait confidence), while at the same time maximising variation arising from stimulus characteristics (state confidence).},
	number = {2},
	journal = {Collective Intelligence},
	author = {Pescetelli, Niccolò and Yeung, Nick},
	month = dec,
	year = {2022},
	note = {Place: USA
Publisher: Sage Publications, Inc.},
	keywords = {confidence, confidence alignment, decision-making, dyads, metacognition},
}

@article{uma_learning_2022,
	title = {Learning from {Disagreement}: {A} {Survey}},
	volume = {72},
	issn = {1076-9757},
	url = {https://doi.org/10.1613/jair.1.12752},
	doi = {10.1613/jair.1.12752},
	abstract = {Many tasks in Natural Language Processing (NLP) and Computer Vision (CV) offer evidence that humans disagree, from objective tasks such as part-of-speech tagging to more subjective tasks such as classifying an image or deciding whether a proposition follows from certain premises. While most learning in artificial intelligence (AI) still relies on the assumption that a single (gold) interpretation exists for each item, a growing body of research aims to develop learning methods that do not rely on this assumption. In this survey, we review the evidence for disagreements on NLP and CV tasks, focusing on tasks for which substantial datasets containing this information have been created. We discuss the most popular approaches to training models from datasets containing multiple judgments potentially in disagreement. We systematically compare these different approaches by training them with each of the available datasets, considering several ways to evaluate the resulting models. Finally, we discuss the results in depth, focusing on four key research questions, and assess how the type of evaluation and the characteristics of a dataset determine the answers to these questions. Our results suggest, first of all, that even if we abandon the assumption of a gold standard, it is still essential to reach a consensus on how to evaluate models. This is because the relative performance of the various training methods is critically affected by the chosen form of evaluation. Secondly, we observed a strong dataset effect. With substantial datasets, providing many judgments by high-quality coders for each item, training directly with soft labels achieved better results than training from aggregated or even gold labels. This result holds for both hard and soft evaluation. But when the above conditions do not hold, leveraging both gold and soft labels generally achieved the best results in the hard evaluation. All datasets and models employed in this paper are freely available as supplementary materials.},
	journal = {J. Artif. Int. Res.},
	author = {Uma, Alexandra N. and Fornaciari, Tommaso and Hovy, Dirk and Paun, Silviu and Plank, Barbara and Poesio, Massimo},
	month = jan,
	year = {2022},
	note = {Place: El Segundo, CA, USA
Publisher: AI Access Foundation},
	keywords = {machine learning, natural language, uncertainty, vision},
	pages = {1385--1470},
}

@article{hang_under-bagging_2022,
	title = {Under-bagging nearest neighbors for imbalanced classification},
	volume = {23},
	issn = {1532-4435},
	abstract = {In this paper, we propose an ensemble learning algorithm called under-bagging k-nearest neighbors (under-bagging k-NN) for imbalanced classification problems. On the theoretical side, by developing a new learning theory analysis, we show that with properly chosen parameters, i.e., the number of nearest neighbors k, the expected sub-sample size s, and the bagging rounds B, optimal convergence rates for under-bagging k-NN can be achieved under mild assumptions w.r.t. the arithmetic mean (AM) of recalls. Moreover, we show that with a relatively small B, the expected sub-sample size s can be much smaller than the number of training data n at each bagging round, and the number of nearest neighbors k can be reduced simultaneously, especially when the data are highly imbalanced, which leads to substantially lower time complexity and roughly the same space complexity. On the practical side, we conduct numerical experiments to verify the theoretical results on the benefits of the under-bagging technique by the promising AM performance and efficiency of our proposed algorithm.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Hang, Hanyuan and Cai, Yuchao and Yang, Hanfang and Lin, Zhouchen},
	month = jan,
	year = {2022},
	note = {Publisher: JMLR.org},
	keywords = {arithmetic mean measure, bagging, ensemble learning, imbalanced classification, k-nearest neighbors, learning theory, optimal convergence rates, under-sampling},
}

@article{sengers_speculation_2021,
	title = {Speculation and the {Design} of {Development}},
	volume = {5},
	url = {https://doi.org/10.1145/3449195},
	doi = {10.1145/3449195},
	abstract = {This paper examines the role of technoscientific speculation in large-scale development projects in postcolonial spaces, building on recent work in STS, design research, and postcolonial studies in and beyond CSCW. We analyze two historical cases of technology-infused development projects in the Canadian province of Newfoundland and Labrador and in Jamaica. We find that speculation in these contexts remixes the constructive stance toward speculation typical for normative technoscience with the critical, contesting orientation of speculative design. Conflicts between these stances are resolved by leveraging fantasy for pragmatic ends, grounding audacious fictions in imported realities, unmooring from conventional understandings of linear technological progress, and using even conservative futures to trouble colonial conventions.},
	number = {CSCW1},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Sengers, Phoebe and Williams, Kaiton and Khovanskaya, Vera},
	month = apr,
	year = {2021},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {development, futures, history, jamaica, newfoundland and labrador, postcolonial computing, speculation, speculative design},
}

@article{patterson_generalized_2022,
	title = {A generalized projected bellman error for off-policy value estimation in reinforcement learning},
	volume = {23},
	issn = {1532-4435},
	abstract = {Many reinforcement learning algorithms rely on value estimation, however, the most widely used algorithms–namely temporal difference algorithms–can diverge under both off-policy sampling and nonlinear function approximation. Many algorithms have been developed for off-policy value estimation based on the linear mean squared projected Bellman error (PBE) and are sound under linear function approximation. Extending these methods to the nonlinear case has been largely unsuccessful. Recently, several methods have been introduced that approximate a different objective–the mean-squared Bellman error (BE)– which naturally facilitate nonlinear approximation. In this work, we build on these insights and introduce a new generalized PBE that extends the linear PBE to the nonlinear setting. We show how this generalized objective unifies previous work and obtain new bounds for the value error of the solutions of the generalized objective. We derive an easy-to-use, but sound, algorithm to minimize the generalized objective, and show that it is more stable across runs, is less sensitive to hyperparameters, and performs favorably across four control domains with neural network function approximation.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Patterson, Andrew and White, Adam and White, Martha},
	month = jan,
	year = {2022},
	note = {Publisher: JMLR.org},
	keywords = {off-policy learning, reinforcement learning, temporal difference learning},
}

@article{zhang_global_2022,
	title = {Global optimality and finite sample analysis of softmax off-policy actor critic under state distribution mismatch},
	volume = {23},
	issn = {1532-4435},
	abstract = {In this paper, we establish the global optimality and convergence rate of an off-policy actor critic algorithm in the tabular setting without using density ratio to correct the discrepancy between the state distribution of the behavior policy and that of the target policy. Our work goes beyond existing works on the optimality of policy gradient methods in that existing works use the exact policy gradient for updating the policy parameters while we use an approximate and stochastic update step. Our update step is not a gradient update because we do not use a density ratio to correct the state distribution, which aligns well with what practitioners do. Our update is approximate because we use a learned critic instead of the true value function. Our update is stochastic because at each step the update is done for only the current state action pair. Moreover, we remove several restrictive assumptions from existing works in our analysis. Central to our work is the finite sample analysis of a generic stochastic approximation algorithm with time-inhomogeneous update operators on time-inhomogeneous Markov chains, based on its uniform contraction properties.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Zhang, Shangtong and Des Combes, Remi Tachet and Laroche, Romain},
	month = jan,
	year = {2022},
	note = {Publisher: JMLR.org},
	keywords = {actor-critic, density ratio, distribution Mismatch, off-policy learning, policy gradient},
}

@article{zhang_truncated_2022,
	title = {Truncated emphatic temporal difference methods for prediction and control},
	volume = {23},
	issn = {1532-4435},
	abstract = {Emphatic Temporal Diérence (TD) methods are a class of off-policy Reinforcement Learning (RL) methods involving the use of followon traces. Despite the theoretical success of emphatic TD methods in addressing the notorious deadly triad of off-policy RL, there are still two open problems. First, followon traces typically suffer from large variance, making them hard to use in practice. Second, though Yu (2015) confirms the asymptotic convergence of some emphatic TD methods for prediction problems, there is still no finite sample analysis for any emphatic TD method for prediction, much less control. In this paper, we address those two open problems simultaneously via using truncated followon traces in emphatic TD methods. Unlike the original followon traces, which depend on all previous history, truncated followon traces depend on only finite history, reducing variance and enabling the finite sample analysis of our proposed emphatic TD methods for both prediction and control.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Zhang, Shangtong and Whiteson, Shimon},
	month = jan,
	year = {2022},
	note = {Publisher: JMLR.org},
	keywords = {approximate value iteration, emphatic methods, finite sample analysis, off-policy learning, reinforcement learning},
}

@article{chen_sdnshield_2021,
	title = {{SDNShield}: {NFV}-{Based} {Defense} {Framework} {Against} {DDoS} {Attacks} on {SDN} {Control} {Plane}},
	volume = {30},
	issn = {1063-6692},
	url = {https://doi.org/10.1109/TNET.2021.3105187},
	doi = {10.1109/TNET.2021.3105187},
	abstract = {Software-defined networking (SDN) is increasingly popular in today’s information technology industry, but existing SDN control plane is insufficiently scalable to support on-demand, high-frequency flow requests. Weaknesses along SDN control paths can be exploited by malicious third parties to launch distributed denial-of-service (DDoS) attacks against the SDN control plane. Recently proposed solutions only partially solve the problem, by protecting either the SDN network edges or the centralized controller. We propose SDNShield, a solution based on emerging network function virtualization (NFV) technologies, which enforces more comprehensive defense against potential DDoS attacks on SDN control plane. SDNShield incorporates a three-stage overload control scheme. The first stage statistically identifies legitimate flows with low complexity and performance overhead. The second stage further performs in-depth TCP handshake verification to ensure good flows are eventually served. The third stage intellectually salvages the misclassified legitimate flows that are falsely dropped from the first two stages. Prototype tests and real data-driven simulation results show that SDNShield can achieve high resilience against brute-force attacks, and maintain good flow-level service quality at the same time.},
	number = {1},
	journal = {IEEE/ACM Trans. Netw.},
	author = {Chen, Kuan-Yin and Liu, Sen and Xu, Yang and Siddhrau, Ishant Kumar and Zhou, Siyu and Guo, Zehua and Chao, H. Jonathan},
	month = aug,
	year = {2021},
	note = {Publisher: IEEE Press},
	pages = {1--17},
}

@article{zhang_edge_2021,
	title = {Edge {Learning}: {The} {Enabling} {Technology} for {Distributed} {Big} {Data} {Analytics} in the {Edge}},
	volume = {54},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3464419},
	doi = {10.1145/3464419},
	abstract = {Machine Learning (ML) has demonstrated great promise in various fields, e.g., self-driving, smart city, which are fundamentally altering the way individuals and organizations live, work, and interact. Traditional centralized learning frameworks require uploading all training data from different sources to a remote data server, which incurs significant communication overhead, service latency, and privacy issues.To further extend the frontiers of the learning paradigm, a new learning concept, namely, Edge Learning (EL) is emerging. It is complementary to the cloud-based methods for big data analytics by enabling distributed edge nodes to cooperatively training models and conduct inferences with their locally cached data. To explore the new characteristics and potential prospects of EL, we conduct a comprehensive survey of the recent research efforts on EL. Specifically, we first introduce the background and motivation. We then discuss the challenging issues in EL from the aspects of data, computation, and communication. Furthermore, we provide an overview of the enabling technologies for EL, including model training, inference, security guarantee, privacy protection, and incentive mechanism. Finally, we discuss future research opportunities on EL. We believe that this survey will provide a comprehensive overview of EL and stimulate fruitful future research in this field.},
	number = {7},
	journal = {ACM Comput. Surv.},
	author = {Zhang, Jie and Qu, Zhihao and Chen, Chenxi and Wang, Haozhao and Zhan, Yufeng and Ye, Baoliu and Guo, Song},
	month = jul,
	year = {2021},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {edge computing, Edge learning, federated learning, machine learning, security and privacy},
}

@article{contreras_integrating_2021,
	title = {Integrating {Collaboration} and {Leadership} in {Conversational} {Group} {Recommender} {Systems}},
	volume = {39},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/3462759},
	doi = {10.1145/3462759},
	abstract = {Recent observational studies highlight the importance of considering the interactions between users in the group recommendation process, but to date their integration has been marginal. In this article, we propose a collaborative model based on the social interactions that take place in a web-based conversational group recommender system. The collaborative model allows the group recommender to implicitly infer the different roles within the group, namely, collaborative and leader user(s). Moreover, it serves as the basis of several novel collaboration-based consensus strategies that integrate both individual and social interactions in the group recommendation process. A live-user evaluation confirms that our approach accurately identifies the collaborative and leader users in a group and produces more effective recommendations.},
	number = {4},
	journal = {ACM Trans. Inf. Syst.},
	author = {Contreras, David and Salamó, Maria and Boratto, Ludovico},
	month = aug,
	year = {2021},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {collaboration, Group recommendation, interactions, leadership, live-user evaluation},
}

@article{kelly_emergent_2021,
	title = {Emergent {Tangled} {Program} {Graphs} in {Partially} {Observable} {Recursive} {Forecasting} and {ViZDoom} {Navigation} {Tasks}},
	volume = {1},
	url = {https://doi.org/10.1145/3468857},
	doi = {10.1145/3468857},
	abstract = {Modularity represents a recurring theme in the attempt to scale evolution to the design of complex systems. However, modularity rarely forms the central theme of an artificial approach to evolution. In this work, we report on progress with the recently proposed Tangled Program Graph (TPG) framework in which programs are modules. The combination of the TPG representation and its variation operators enable both teams of programs and graphs of teams of programs to appear in an emergent process. The original development of TPG was limited to tasks with, for the most part, complete information. This work details two recent approaches for scaling TPG to tasks that are dominated by partially observable sources of information using different formulations of indexed memory. One formulation emphasizes the incremental construction of memory, again as an emergent process, resulting in a distributed view of state. The second formulation assumes a single global instance of memory and develops it as a communication medium, thus a single global view of state. The resulting empirical evaluation demonstrates that TPG equipped with memory is able to solve multi-task recursive time-series forecasting problems and visual navigation tasks expressed in two levels of a commercial first-person shooter environment.},
	number = {3},
	journal = {ACM Trans. Evol. Learn. Optim.},
	author = {Kelly, Stephen and Smith, Robert J. and Heywood, Malcolm I. and Banzhaf, Wolfgang},
	month = aug,
	year = {2021},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Coevolution, modularity, partial observability, time series},
}

@article{schlegel_general_2021,
	title = {General {Value} {Function} {Networks}},
	volume = {70},
	issn = {1076-9757},
	url = {https://doi.org/10.1613/jair.1.12105},
	doi = {10.1613/jair.1.12105},
	abstract = {State construction is important for learning in partially observable environments. A general purpose strategy for state construction is to learn the state update using a Recurrent Neural Network (RNN), which updates the internal state using the current internal state and the most recent observation. This internal state provides a summary of the observed sequence, to facilitate accurate predictions and decision-making. At the same time, specifying and training RNNs is notoriously tricky, particularly as the common strategy to approximate gradients back in time, called truncated Back-prop Through Time (BPTT), can be sensitive to the truncation window. Further, domain-expertise—which can usually help constrain the function class and so improve trainability—can be difficult to incorporate into complex recurrent units used within RNNs. In this work, we explore how to use multi-step predictions to constrain the RNN and incorporate prior knowledge. In particular, we revisit the idea of using predictions to construct state and ask: does constraining (parts of) the state to consist of predictions about the future improve RNN trainability? We formulate a novel RNN architecture, called a General Value Function Network (GVFN), where each internal state component corresponds to a prediction about the future represented as a value function. We first provide an objective for optimizing GVFNs, and derive several algorithms to optimize this objective. We then show that GVFNs are more robust to the truncation level, in many cases only requiring one-step gradient updates.},
	journal = {J. Artif. Int. Res.},
	author = {Schlegel, Matthew and Jacobsen, Andrew and Abbas, Zaheer and Patterson, Andrew and White, Adam and White, Martha},
	month = may,
	year = {2021},
	note = {Place: El Segundo, CA, USA
Publisher: AI Access Foundation},
	pages = {497--543},
}

@article{wu_influences_2025,
	title = {Influences of precollege out-of-school time computer science experiences on students’ career interest in computer science},
	url = {https://doi.org/10.1145/3770069},
	doi = {10.1145/3770069},
	abstract = {Background and context: Although out-of-school time (OST) computer science (CS) experiences during the high school years have been considered an efficacious means to cultivate students’ career interest in CS, there has been a paucity of rigorous research on the topic.Objective: Examine the effects of a wide variety of OST activities on students’ career interest in CS.Method: We carried out a retrospective cohort study, collecting data from a nationally representative sample of 6,044 U.S. first year university students. From 27 survey items about OST CS-related activities during high school, we first selected a list of top-ranking influential variables through machine learning. Then, a multinomial logistic regression was used to examine the relationship between these top-ranking variables and students’ career interests at the end of high school.Findings: The analysis showed that high school aged students’ participation in unstructured CS-related activities (e.g., talking about CS with family or friends); structured CS-related activities (e.g., CS-related summer camps or programs); along with the opportunities that students experienced during OST CS programs/activities (e.g., designing their own CS projects) boosted interest in a CS career vis-à-vis careers in other-STEM or non-STEM fields. It also showed that engaging in some activities (e.g., using social media) was associated with a decreased likelihood of intending a CS career, compared to a career in other-STEM or non-STEM fields. An interaction effect between having a prior career interest in CS and creating blogs/podcasts/video was also observed.Implications: First large-scale analysis of CS OST related activities on CS career interest.},
	journal = {ACM Trans. Comput. Educ.},
	author = {Wu, Rongxiu and Sunbury, Susan and Sadler, Philip and Sonnert, Gerhard},
	month = sep,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Career interest, computer science, high school, OST CS-related activities},
	annote = {Just Accepted},
}

@article{stephenson_legal_2025,
	title = {Legal {Evidence} of {Technology}-{Facilitated} {Abuse} in {Wisconsin}: {Surfacing} {Barriers} {Within} and {Beyond} the {Courtroom}},
	volume = {9},
	url = {https://doi.org/10.1145/3757622},
	doi = {10.1145/3757622},
	abstract = {Abusers routinely use technology to spy on and harass their targets. This harmful behavior is known as technology-facilitated abuse, or tech abuse. Survivors of tech abuse may turn to the legal system for safety and security, and to do so, they need evidence of tech abuse. However, prior work indicates challenges to collecting evidence of tech abuse and using it in legal proceedings. Thus, in this work, we study legal evidence used by survivors of tech abuse in Wisconsin, USA. We report on qualitative interviews and focus groups with 19 legal support providers who work with survivors seeking protective orders, divorces, and criminal charges. Our findings surface current practices that survivors and legal support providers use to prepare and present evidence of tech abuse in Wisconsin and the challenges they face. For example, survivors struggle to collect evidence of covert monitoring and surveillance. When they can collect evidence, it is often difficult to connect that evidence to the abuser due to the anonymous nature of many forms of tech abuse. In court, evidence of tech abuse is frequently challenged and vulnerable to objections and counter-evidence. And at the end of a proceeding, it's not uncommon for a judge to determine that the tech abuse does not meet the statutes. Informed by these results, we encourage CSCW and HCI researchers to work towards designing and deploying sociotechnical solutions that support survivors' use of evidence, in careful collaboration with advocates, legal experts, and survivors.},
	number = {7},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Stephenson, Sophie and Gupta, Naman and Polamarasetty, Akhil and Huang, Kyle and Youssef, David and Cowan, Kayleigh and Chatterjee, Rahul},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {at-risk users, digital safety, technology-facilitated abuse},
}

@article{varela-vaca_smart_2021,
	title = {Smart {Contract} {Languages}: {A} {Multivocal} {Mapping} {Study}},
	volume = {54},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3423166},
	doi = {10.1145/3423166},
	abstract = {Blockchain is a disruptive technology that has attracted the attention of the scientific community and companies, as proven by the exponential growth of publications on this topic in recent years. This growing interest is mainly due to the promise that the use of blockchain enables it to be verified, without including any trusted intermediaries, that the information received from the network is authentic and up-to-date. In this respect, blockchain is a distributed database that can be seen as a ledger that records all transactions that have ever been executed. In this context, smart contracts are pieces of software used to facilitate, verify, and enforce the negotiation of a transaction on a blockchain platform. These pieces of software are implemented by using programming languages, which are sometimes provided by the blockchain platforms themselves. This study aims to (1) identify and categorise the state-of-the-art related to smart contract languages, in terms of the existing languages and their main features, and (2) identify new research opportunities. The review has been conducted as a multivocal mapping study that follows the guidelines proposed by Garousi et\&nbsp;al. for conducting multivocal literature reviews, as well as the guidelines proposed by Kitchenham and Charters for conducting mapping studies. As a result of the implementation of the review protocol, 4,119 papers were gathered, and 109 of them were selected for extraction. The contributions of this article are twofold: (1) 101 different smart contract languages have been identified and classified according to a variety of criteria; (2) a discussion on the findings and their implications for future research have been outlined. As a conclusion, it could be stated that a rigorous and replicable overview of the state-of-the-art of smart contract languages has been provided that can benefit not only researchers but also practitioners in the field, thanks to its multivocal nature.},
	number = {1},
	journal = {ACM Comput. Surv.},
	author = {Varela-Vaca, Ángel Jesús and Quintero, Antonia M. Reina},
	month = jan,
	year = {2021},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {blockchain, multivocal literature mapping study, Smart contract language, systematic literature review},
}

@article{zhang_dynamic_2021,
	title = {Dynamic tensor recommender systems},
	volume = {22},
	issn = {1532-4435},
	abstract = {Recommender systems have been extensively used by the entertainment industry, business marketing and the biomedical industry. In addition to its capacity of providing preference-based recommendations as an unsupervised learning methodology, it has been also proven useful in sales forecasting, product introduction and other production related businesses. Since some consumers and companies need a recommendation or prediction for future budget, labor and supply chain coordination, dynamic recommender systems for precise forecasting have become extremely necessary. In this article, we propose a new recommendation method, namely the dynamic tensor recommender system (DTRS), which aims particularly at forecasting future recommendation. The proposed method utilizes a tensor-valued function of time to integrate time and contextual information, and creates a time-varying coefficient model for temporal tensor factorization through a polynomial spline approximation. Major advantages of the proposed method include competitive future recommendation predictions and effective prediction interval estimations. In theory, we establish the convergence rate of the proposed tensor factorization and asymptotic normality of the spline coefficient estimator. The proposed method is applied to simulations, IRI marketing data and Last.fm data. Numerical studies demonstrate that the proposed method outperforms existing methods in terms of future time forecasting.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Zhang, Yanqing and Bi, Xuan and Tang, Niansheng and Qu, Annie},
	month = jan,
	year = {2021},
	note = {Publisher: JMLR.org},
	keywords = {contextual information, dynamic recommender systems, polynomial spline approximation, prediction interval, product sales forecasting},
}

@article{esterle_i_2020,
	title = {I {Think} {Therefore} {You} {Are}: {Models} for {Interaction} in {Collectives} of {Self}-aware {Cyber}-physical {Systems}},
	volume = {4},
	issn = {2378-962X},
	url = {https://doi.org/10.1145/3375403},
	doi = {10.1145/3375403},
	abstract = {Cyber-physical systems operate in our real world, constantly interacting with the environment and collaborating with other systems. The increasing number of devices will make it infeasible to control each one individually. It will also be infeasible to prepare each of them for every imaginable rapidly unfolding situation. Therefore, we must increase the autonomy of future Cyber-physical Systems. Making these systems self-aware allows them to reason about their own capabilities and their immediate environment. In this article, we extend the idea of the self-awareness of individual systems toward networked self-awareness. This gives systems the ability to reason about how they are being affected by the actions and interactions of others within their perceived environment, as well as in the extended environment that is beyond their direct perception. We propose that different levels of networked self-awareness can develop over time in systems as they do in humans. Furthermore, we propose that this could have the same benefits for networks of systems that it has had for communities of humans, increasing performance and adaptability.},
	number = {4},
	journal = {ACM Trans. Cyber-Phys. Syst.},
	author = {Esterle, Lukas and Brown, John N. A.},
	month = jun,
	year = {2020},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {artificial intelligence, autonomous systems, collaborative systems, networked self-awareness, Self-aware systems},
}

@article{sahin_linspector_2020,
	title = {{LINSPECTOR}: {Multilingual} {Probing} {Tasks} for {Word} {Representations}},
	volume = {46},
	issn = {0891-2017},
	url = {https://doi.org/10.1162/coli_a_00376},
	doi = {10.1162/coli_a_00376},
	abstract = {Despite an ever-growing number of word representation models introduced for a large number of languages, there is a lack of a standardized technique to provide insights into what is captured by these models. Such insights would help the community to get an estimate of the downstream task performance, as well as to design more informed neural architectures, while avoiding extensive experimentation that requires substantial computational resources not all researchers have access to. A recent development in NLP is to use simple classification tasks, also called probing tasks, that test for a single linguistic feature such as part-of-speech. Existing studies mostly focus on exploring the linguistic information encoded by the continuous representations of English text. However, from a typological perspective the morphologically poor English is rather an outlier: The information encoded by the word order and function words in English is often stored on a subword, morphological level in other languages. To address this, we introduce 15 type-level probing tasks such as case marking, possession, word length, morphological tag count, and pseudoword identification for 24 languages. We present a reusable methodology for creation and evaluation of such tests in a multilingual setting, which is challenging because of a lack of resources, lower quality of tools, and differences among languages. We then present experiments on several diverse multilingual word embedding models, in which we relate the probing task performance for a diverse set of languages to a range of five classic NLP tasks: POS-tagging, dependency parsing, semantic role labeling, named entity recognition, and natural language inference. We find that a number of probing tests have significantly high positive correlation to the downstream tasks, especially for morphologically rich languages. We show that our tests can be used to explore word embeddings or black-box neural models for linguistic cues in a multilingual setting. We release the probing data sets and the evaluation suite LINSPECTOR with .},
	number = {2},
	journal = {Comput. Linguist.},
	author = {Şahin, Gözde Gül and Vania, Clara and Kuznetsov, Ilia and Gurevych, Iryna},
	month = jun,
	year = {2020},
	note = {Place: Cambridge, MA, USA
Publisher: MIT Press},
	pages = {335--385},
}

@article{oguine_how_2025,
	title = {How the {Internet} {Facilitates} {Adverse} {Childhood} {Experiences} for {Youth} {Who} {Self}-{Identify} as in {Need} of {Services}},
	volume = {9},
	url = {https://doi.org/10.1145/3710995},
	doi = {10.1145/3710995},
	abstract = {Youth implicated in the child welfare and juvenile justice systems, as well as those with an incarcerated parent, are considered the most vulnerable Children in Need of Services (CHINS). We identified 1,160 of these at-risk youth (ages 13-17) who sought support via an online peer support platform to understand their adverse childhood experiences and explore how the internet played a role in providing an outlet for support, as well as potentially facilitating risks. We first analyzed posts from 1,160 youth who self-identified as CHINS while sharing about their adverse experiences. Then, we retrieved all 239,929 posts by these users to identify salient topics within their support-seeking posts: 1) Urges to self-harm due to social drama, 2) desire for social connection, 3) struggles with family, and 4) substance use and sexual risks. We found that the internet often helped facilitate these problems; for example, the desperation for social connection often led to meeting unsafe people online, causing additional trauma. Family members and other unsafe people used the internet to perpetrate cyberabuse, while CHINS themselves leveraged online channels to engage in illegal and risky behavior. Our study calls for tailored support systems that address the unique needs of CHINS to promote safe online spaces and foster resilience to break the cycle of adversity. Empowering CHINS requires amplifying their voices and acknowledging the challenges they face as a result of their adverse childhood experiences.},
	number = {2},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Oguine, Ozioma C. and Park, Jinkyung Katie and Akter, Mamtaj and Olesk, Johanna and Alluhidan, Abdulmalik and Wisniewski, Pamela and Badillo-Urquiola, Karla},
	month = may,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {adolescent online safety, adverse childhood experiences, child welfare, children in need of services, juvenile justice, online support seeking, vulnerable youth},
}

@article{henderson_towards_2020,
	title = {Towards the systematic reporting of the energy and carbon footprints of machine learning},
	volume = {21},
	issn = {1532-4435},
	abstract = {Accurate reporting of energy and carbon usage is essential for understanding the potential climate impacts of machine learning research. We introduce a framework that makes this easier by providing a simple interface for tracking realtime energy consumption and carbon emissions, as well as generating standardized online appendices. Utilizing this framework, we create a leaderboard for energy efficient reinforcement learning algorithms to incentivize responsible research in this area as an example for other areas of machine learning. Finally, based on case studies using our framework, we propose strategies for mitigation of carbon emissions and reduction of energy consumption. By making accounting easier, we hope to further the sustainable development of machine learning experiments and spur more research into energy efficient algorithms.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Henderson, Peter and Hu, Jieru and Romoff, Joshua and Brunskill, Emma and Jurafsky, Dan and Pineau, Joelle},
	month = jan,
	year = {2020},
	note = {Publisher: JMLR.org},
	keywords = {climate change, deep learning, energy efficiency, green computing, reinforcement learning},
}

@article{tome_i_2024,
	title = {"{I} {Found} it {Cathartic}": {Exploring} {Empathy} and {Mental} {Health} {Awareness} in {Psychological} {Horror} {Video} {Games}},
	volume = {8},
	url = {https://doi.org/10.1145/3677083},
	doi = {10.1145/3677083},
	abstract = {Horror video games have often been criticized for their negative and unrealistic depiction of mental health, primarily through their portrayal of characters with mental illnesses. Such representations can perpetuate stigma and misconceptions about mental health issues. However, there has recently been a growing interest in accurate portrayals of these characters and how playing these video games could also elicit empathy and mental health awareness. In our study, we explored how a psychological horror game such as Silent Hill 2 could foster empathy and mental health awareness through individual interviews with 11 participants. Our findings revealed that participants gained a deeper understanding of mental health issues and empathy towards characters struggling with mental illnesses by interacting and controlling them. Participants had a greater attachment to the characters' inner struggles and their gameplay was experienced as cathartic. Moreover, our findings highlighted the potential of psychological horror to serve as a platform for character-driven narratives, showcasing how engagement with such games elicited empathy among participants. We contribute to an exploratory understanding that can assist game designers and writers in crafting narratives within the Psychological Horror genre that foster empathy and mental health awareness.},
	number = {CHI PLAY},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Tomé, Filipe and Pires, Ana and Jiskrová, Anna and Saial, Ana and Campos, Pedro F.},
	month = oct,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {empathy, mental health awareness, narrative, psychological horror video games},
}

@article{hu_openmae_2025,
	title = {{OpenMAE}: {Efficient} {Masked} {Autoencoder} for {Vibration} {Sensing} with {Open}-domain {Data} {Enrichment}},
	volume = {9},
	url = {https://doi.org/10.1145/3729485},
	doi = {10.1145/3729485},
	abstract = {This paper introduces OpenMAE, a novel data enrichment framework utilizing open-world sensor data streams to facilitate efficient masked autoencoder (MAE) pretraining on vibration signals. Due to highly sparse event occurrences and inevitable distributional shifts from downstream tasks, directly concatenating large-scale open-domain data with limited in-domain data during pretraining leads to degraded downstream task performance. The problem is further complicated by missing knowledge of open-world sensor environments and associated physical event semantics. Against these challenges, OpenMAE makes the following contributions to vibration MAE pretraining with open-domain data: First, it automatically filters out uninformative samples based on the event activeness and information consistency without relying on human annotations; Second, to mind the gap between open-domain and in-domain distributions, OpenMAE develops a novel data mixing method, FreqCutMix, that combines two data types in the frequency domain as augmented pretraining samples, preserving both events-of-interest semantics from in-domain data and real-world diversity from open-domain data. The open-domain data scale in data mixing is dynamically increased as pretraining progresses to stabilize the model convergence. We download over 5 million open-world vibration samples from the Raspberry Shake datacenter1 and conduct extensive experiments with two applications (i.e., indoor activity and outdoor transportation analysis). The evaluation results show OpenMAE improves downstream task accuracies by up to 23\% and achieves enhanced generalizability into diverse downstream tasks, domain variations, and sensor-to-target distances.},
	number = {2},
	journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
	author = {Hu, Chenzhi and Chen, Yatong and Kara, Denizhan and Liu, Shengzhong and Abdelzaher, Tarek and Wu, Fan and Chen, Guihai},
	month = jun,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Self-Supervised Learning, Time-Series Signals, Vibration Sensing},
}

@article{russo_towards_2025,
	title = {Towards an {Ontology}-{Driven} {Approach} to {Document} {Bias}},
	volume = {83},
	issn = {1076-9757},
	url = {https://doi.org/10.1613/jair.1.19388},
	doi = {10.1613/jair.1.19388},
	abstract = {Machine learning (ML)-powered systems are capable of reproducing and often amplifying undesired biases embedded in society, emphasizing the importance of operating under practices that enable the study and understanding of the intrinsic characteristics of ML pipelines. This supports the emergence of documentation frameworks with the idea that “any remedy for bias starts with awareness of its existence.” However, a resource that can formally describe ML pipelines in terms of detected biases is still missing. To address this gap, we present the Doc-BiasO ontology, a resource that sets out to create an integrated vocabulary of biases defined in the Trustworthy AI literature and their measures, as well as to incorporate relevant domain terminology and relationships between them. Overseeing ontology engineering best practices, we reuse existing vocabularies on machine learning and AI to foster knowledge sharing and interoperability between the actors concerned with its research, development, regulation, and others. In addition, we demonstrate the potential of Doc-BiasO with an experiment on an existing benchmark and as part of a neuro-symbolic system. Overall, our main objective is to contribute towards clarifying existing terminology on bias research as it rapidly expands to all areas of AI and to improve the interpretation of bias in data and downstream impact through its documentation.},
	journal = {J. Artif. Int. Res.},
	author = {Russo, Mayra and Vidal, Maria-Esther},
	month = aug,
	year = {2025},
	note = {Place: El Segundo, CA, USA
Publisher: AI Access Foundation},
	keywords = {AI in Healthcare, Explainable AI, Trustworthy AI},
}

@article{chander_toward_2025,
	title = {Toward {Trustworthy} {Artificial} {Intelligence} ({TAI}) in the {Context} of {Explainability} and {Robustness}},
	volume = {57},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3675392},
	doi = {10.1145/3675392},
	abstract = {From the innovation, Artificial Intelligence (AI) materialized as one of the noticeable research areas in various technologies and has almost expanded into every aspect of modern human life. However, nowadays, the development of AI is unpredictable with the stated values of those developing them; hence, the risk of misbehaving AI increases continuously. Therefore, there are uncertainties about endorsing that the development and deploying of AI are favorable and not unfavorable to humankind. In addition, AI holds a black-box pattern, which results in a lack of understanding of how systems can work based on the raised concerns. From the above discussion, trustworthy AI is vital for the extensive adoption of AI in many applications, with strong attention to humankind and the need to focus on AI systems developing into the system outline at the time of system design. In this survey, we discuss compound materials on trustworthy AI and the present state-of-the-art of trustworthy AI technologies, revealing new perspectives, bridging knowledge gaps, and paving the way for potential advances of robustness, and explainability rules which play a proactive role in designing AI systems. Systems that are reliable and secure and mimic human behavior significantly impact the technological AI ecosystem. We provide various contemporary technologies to build explainability and robustness for AI-based solutions, so AI works in a safer and more trustworthy manner. Finally, we conclude our survey article with high-end opportunities, challenges, and future research directions for trustworthy AI to investigate in the future.},
	number = {6},
	journal = {ACM Comput. Surv.},
	author = {chander, Bhanu and John, Chinju and Warrier, Lekha and Gopalakrishnan, Kumaravelan},
	month = feb,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Artificial intelligence, data privacy, decision-making, deep learning, explainability, fairness, machine learning, robustness, trustworthy AI},
}

@article{namer_what_2025,
	title = {What 96 {Designers} {Taught} {Us} {About} {Harm}: {The} {Behaviors} {Around} {Considering} {Harm} in {Digital} {Products}},
	volume = {20},
	issn = {1931-3357},
	abstract = {Potential harm within digital product design has long been underexplored, despite the growing influence that consumer-facing digital products exert on individuals' daily lives. This paper presents the methodology and findings from an online survey conducted with 96 US-based UX- and product-designers working on customer-facing digital products. The survey focused on the attitudes, behaviors, challenges, and needs that designers encounter while considering harm in their daily work. Our findings resulted in several recommendations for future research to develop practice-based design solutions that enable designers to more effectively identify, discuss, and mitigate potential harm stemming from their work.},
	number = {3},
	journal = {J. User Exper.},
	author = {Namer, Lexi and Joines, Sharon},
	month = may,
	year = {2025},
	note = {Place: Bloomingdale, IL
Publisher: Usability Professionals' Association},
	keywords = {digital product design, ethical awareness, harm reduction, harm-aware design, survey, user experience design},
	pages = {125--142},
}

@article{chen_semicmt_2024,
	title = {{SemiCMT}: {Contrastive} {Cross}-{Modal} {Knowledge} {Transfer} for {IoT} {Sensing} with {Semi}-{Paired} {Multi}-{Modal} {Signals}},
	volume = {8},
	url = {https://doi.org/10.1145/3699779},
	doi = {10.1145/3699779},
	abstract = {This paper proposes a novel contrastive cross-modal knowledge transfer framework, SemiCMT, for multi-modal IoT sensing applications. It effectively transfers the feature extraction capability (also called knowledge) learned from a source modality (e.g., acoustic signals) with abundant unlabeled training data, to a target modality (e.g., seismic signals) that lacks enough training data, in a self-supervised manner with the help of only a small set of synchronized multi-modal pairs. The transferred model can be quickly finetuned to downstream target-modal tasks with only limited labels. The key design constitutes of three aspects: First, we factorize the latent embedding of each modality into shared and private components and perform knowledge transfer considering both the modality information commonality and gaps. Second, we enforce structural correlation constraints between the source modality and the target modality, to push the target modal embedding space symmetric to the source modal embedding space, with the anchoring of additional source-modal samples, which expands the existing modal-matching objective in current multi-modal contrastive frameworks. Finally, we conduct downstream task finetuning in the spherical space with a KNN classifier to better align with the structured modality embedding space. Extensive evaluations on five multimodal IoT datasets are performed to validate the effectiveness of SemiCMT in cross-modal knowledge transfer, including a new self-collected dataset using seismic and acoustic signals for office activity monitoring. SemiCMT consistently outperforms existing self-supervised and knowledge transfer approaches by up to 36.47\% in the finetuned target-modal classification tasks. The code and the self-collected dataset will be released at https://github.com/SJTU-RTEAS/SemiCMT.},
	number = {4},
	journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
	author = {Chen, Yatong and Hu, Chenzhi and Kimura, Tomoyoshi and Li, Qinya and Liu, Shengzhong and Wu, Fan and Chen, Guihai},
	month = nov,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Contrastive Learning, Cross-Modal Knowledge Transfer, Multi-Modal Time-Series Signals},
}

@article{alsoubai_profiling_2024,
	title = {Profiling the {Offline} and {Online} {Risk} {Experiences} of {Youth} to {Develop} {Targeted} {Interventions} for {Online} {Safety}},
	volume = {8},
	url = {https://doi.org/10.1145/3637391},
	doi = {10.1145/3637391},
	abstract = {We conducted a study with 173 adolescents (ages 13-21), who self-reported their offline and online risk experiences and uploaded their Instagram data to our study website to flag private conversations as unsafe. Risk profiles were first created based on the survey data and then compared with the risk-flagged social media data. Five risk profiles emerged: Low Risks (51\% of the participants), Medium Risks (29\%), Increased Sexting (8\%), Increased Self-Harm (8\%), and High Risk Perpetration (4\%). Overall, the profiles correlated well with the social media data with the highest level of risk occurring in the three smallest profiles. Youth who experienced increased sexting and self-harm frequently reported engaging in unsafe sexual conversations. Meanwhile, high risk perpetration was characterized by increased violence, threats, and sales/promotion of illegal activities. A key insight from our study was that offline risk behavior sometimes manifested differently in online contexts (i.e., offline self-harm as risky online sexual interactions). Our findings highlight the need for targeted risk prevention strategies for youth online safety.},
	number = {CSCW1},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Alsoubai, Ashwaq and Razi, Afsaneh and Agha, Zainab and Ali, Shiza and Stringhini, Gianluca and De Choudhury, Munmun and Wisniewski, Pamela J.},
	month = apr,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {human-computer interaction, mixture factor, youth online safety, youth risk profiles},
}

@article{tao_multimodal_2024,
	title = {Multimodal {Consistency} {Suppression} {Factor} for {Fake} {News} {Detection}},
	issn = {1551-6857},
	url = {https://doi.org/10.1145/3699959},
	doi = {10.1145/3699959},
	abstract = {Recent multi-modal fake news detection methods often use the consistency between textual and visual contents to determine the truth or fake of a news information. Higher levels of textual-visual consistency typically lead to a greater likelihood of classifying a news item as real. However, a critical observation reveals that creators of most fake news intentionally select images that align with the textual content, thereby enhancing the credibility of the news. Consequently, high consistency between textual and visual contents alone cannot guarantee the authenticity of the information. To address this problem, we introduce a novel approach termed Multimodal Consistency-based Suppression Factor to modulate the significance of textual-visual consistency in information assessment. When the textual-visual matching is high, this suppression factor reduces the influence of consistency during the judgment process. Moreover, we use Contrastive Language-Image Pre-training (CLIP) model to extract features and measure the consistency level between modalities to guide multimodal fusion. In addition, we also use a method of compressing and fusing modal information based on Variational Autoencoder (VAE) to reconstruct CLIP features, learning the shared representation of different modal information of CLIP. Finally, extensive experiments were conducted on three publicly datasets, Weibo, Twitter and Weibo21, and the results confirmed that our method outperformed the state-of-the-art methods in the field, and had 0.8\%, 2.6\% and 4.1\% effect improvement on the accuracy rate.},
	journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
	author = {Tao, Zhulin and Zhao, Runze and Shi, Xin and Gao, Xingyu and Wang, Xi and Huang, Xianglin},
	month = oct,
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Fake news detection, Multi-modal learning, Social media},
	annote = {Just Accepted},
}

@article{robledo_yamamoto_we_2023,
	title = {“{We} are {Researchers}, but we are also {Humans}”: {Creating} a {Design} {Space} for {Managing} {Graduate} {Student} {Stress}},
	volume = {30},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/3589956},
	doi = {10.1145/3589956},
	abstract = {Graduate students are facing a mental health crisis due to a combination of individual, community, and societal factors. Many existing stress management interventions engage with one factor at a time, typically focusing on providing a user with data about their stress state. We conducted co-design workshops with graduate students who work closely together to explore their strategies for managing stress and to learn about what types of technologies they envision to help address their stress. Using Ecological Systems Theory as an conceptual framework, our analysis of the designs and discussions from these workshops contributes an expanded design space for stress management—one that foregrounds the affordances and challenges of designing interventions that cut across ecological systems levels along with designs that approach stress management using a broader diversity of strategies: controlling, disconnecting, and normalizing stress. We argue that this expanded design space embraces a more holistic and human approach to designing stress management technologies.},
	number = {5},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	author = {Robledo Yamamoto, Fujiko and Cho, Janghee and Voida, Amy and Voida, Stephen},
	month = sep,
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {digital mental health, graduate students, Self-care, stress management},
}

@article{ramokapane_what_2022,
	title = {What {Users} {Want} {From} {Cloud} {Deletion} and the {Information} {They} {Need}: {A} {Participatory} {Action} {Study}},
	volume = {26},
	issn = {2471-2566},
	url = {https://doi.org/10.1145/3546578},
	doi = {10.1145/3546578},
	abstract = {Current cloud deletion mechanisms fall short in meeting users’ various deletion needs. They assume all data is deleted the same way—data is temporally removed (or hidden) from users’ cloud accounts before being completely deleted. This assumption neglects users’ desire to have data completely deleted instantly or their preference to have it recoverable for a more extended period. To date, these preferences have not been explored. To address this gap, we conducted a participatory study with four groups of active cloud users (five subjects per group). We examined their deletion preferences and the information they require to aid deletion. In particular, we explored how users want to delete cloud data and identify what information about cloud deletion they consider essential, the time it should be made available to them, and the communication channel that should be used. We show that cloud deletion preferences are complex and multi-dimensional, varying between subjects and groups. Information about deletion should be within reach when needed, for instance, be part of deletion controls. Based on these findings, we discuss the implications of our study in improving the current deletion mechanism to accommodate these preferences.},
	number = {1},
	journal = {ACM Trans. Priv. Secur.},
	author = {Ramokapane, Kopo Marvin and Such, Jose and Rashid, Awais},
	month = nov,
	year = {2022},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {cloud computing, cloud deletion, cloud deletion mechanisms, cloud storage, data deletion, Deletion, deletion preferences, participatory design, preferences, user studies},
}

@article{lin_detecting_2021,
	title = {On detecting cherry-picked generalizations},
	volume = {15},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3485450.3485457},
	doi = {10.14778/3485450.3485457},
	abstract = {Generalizing from detailed data to statements in a broader context is often critical for users to make sense of large data sets. Correspondingly, poorly constructed generalizations might convey misleading information even if the statements are technically supported by the data. For example, a cherry-picked level of aggregation could obscure substantial sub-groups that oppose the generalization. We present a framework for detecting and explaining cherry-picked generalizations by refining aggregate queries. We present a scoring method to indicate the appropriateness of the generalizations. We design efficient algorithms for score computation. For providing a better understanding of the resulting score, we also formulate practical explanation tasks to disclose significant counterexamples and provide better alternatives to the statement. We conduct experiments using real-world data sets and examples to show the effectiveness of our proposed evaluation metric and the efficiency of our algorithmic framework.},
	number = {1},
	journal = {Proc. VLDB Endow.},
	author = {Lin, Yin and Youngmann, Brit and Moskovitch, Yuval and Jagadish, H. V. and Milo, Tova},
	month = sep,
	year = {2021},
	note = {Publisher: VLDB Endowment},
	pages = {59--71},
}

@article{agadakos_large-scale_2020,
	title = {Large-scale {Debloating} of {Binary} {Shared} {Libraries}},
	volume = {1},
	url = {https://doi.org/10.1145/3414997},
	doi = {10.1145/3414997},
	abstract = {Developers nowadays have access to an arsenal of toolkits and libraries for rapid application prototyping. However, when an application loads a library, the entirety of that library’s code is mapped into the process address space, even if only a single function is actually needed. The unused portion is bloat that can negatively impact software defenses by unnecessarily inflating their overhead or increasing the attack surface. In this article, we investigate whether debloating is possible and practical at the binary level. To this end, we present Nibbler: a system that identifies and erases unused functions within dynamic shared libraries. Nibbler works in tandem with defenses such as continuous code re-randomization and control-flow integrity, enhancing them without incurring additional run-time overhead. We developed and tested a prototype of Nibbler on x86-64 Linux; Nibbler reduces the size of shared libraries and the number of available functions, for real-world binaries and the SPEC CINT2006 suite, by up to 56\% and 82\%, respectively. We also demonstrate that Nibbler benefits defenses by showing that: (i) it improves the deployability of a continuous re-randomization system for binaries, namely, Shuffler, by increasing its efficiency by 20\%, and (ii) it improves certain fast but coarse and context-insensitive control-flow integrity schemes by reducing the number of gadgets reachable through indirect branch instructions by 75\% and 49\%, on average. Last, we apply Nibbler on ≈30K C/C++ binaries and ≈5K unique dynamic shared libraries (i.e., almost the complete set of the Debian sid distribution), as well as on nine official Docker images (with millions of downloads in Docker Hub), reporting entrancing findings regarding code bloat at large.},
	number = {4},
	journal = {Digital Threats},
	author = {Agadakos, Ioannis and Demarinis, Nicholas and Jin, Di and Williams-King, Kent and Alfajardo, Jearson and Shteinfeld, Benjamin and Williams-King, David and Kemerlis, Vasileios P. and Portokalidis, Georgios},
	month = dec,
	year = {2020},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Code debloating, software security, static binary analysis},
}

@article{moitra_parsing_2021,
	title = {Parsing the '{Me}' in \#{MeToo}: {Sexual} {Harassment}, {Social} {Media}, and {Justice} {Infrastructures}},
	volume = {5},
	url = {https://doi.org/10.1145/3449185},
	doi = {10.1145/3449185},
	abstract = {India's \#MeToo movement began in late-2018, and was largely a platform for some privileged women sharing their accounts of sexual harassment. Beyond issues of access to digital technology, our paper investigates why various sections of India's female and LGBTQ+ population chose not to engage with the \#MeToo movement. Focusing on experiences with sexual harassment, we conducted 44 qualitative interviews with middle-class working women, feminist and queer activists, academics, and other stakeholders working against gender-based violence, to understand their perspectives on \#MeToo. Our paper explores why some survivors bypass the legal infrastructure to speak out against sexual harassment using \#MeToo, while others choose not to participate despite having access to social media platforms. Using the lens of infrastructure, we outline the imbrication of social media movements with existing social norms and legal infrastructures. Further, we highlight how infrastructural politics are connected to patriarchy, colonialism, caste, class, and gender struggles.},
	number = {CSCW1},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Moitra, Aparna and Ahmed, Syed Ishtiaque and Chandra, Priyank},
	month = apr,
	year = {2021},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {feminism, infrastructure, intersectionality, justice, lgbtq+, sexual harassment},
}

@article{feuston_conformity_2020,
	title = {Conformity of {Eating} {Disorders} through {Content} {Moderation}},
	volume = {4},
	url = {https://doi.org/10.1145/3392845},
	doi = {10.1145/3392845},
	abstract = {For individuals with mental illness, social media platforms are considered spaces for sharing and connection. However, not all expressions of mental illness are treated equally on these platforms. Different aggregates of human and technical control are used to report and ban content, accounts, and communities. Through two years of digital ethnography, including online observation and interviews, with people with eating disorders, we examine the experience of content moderation. We use a constructivist grounded theory approach to analysis that shows how practices of moderation across different platforms have particular consequences for members of marginalized groups, who are pressured to conform and compelled to resist. Above all, we argue that platform moderation is enmeshed with wider processes of conformity to specific versions of mental illness. Practices of moderation reassert certain bodies and experiences as 'normal' and valued, while rejecting others. At the same time, navigating and resisting these normative pressures further inscribes the marginal status of certain individuals. We discuss changes to the ways that platforms handle content related to eating disorders by drawing on the concept of multiplicity to inform design.},
	number = {CSCW1},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Feuston, Jessica L. and Taylor, Alex S. and Piper, Anne Marie},
	month = may,
	year = {2020},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {conformity, content moderation, digital ethnography, eating disorders, mental illness, multiplicity, online communities, social media},
}

@article{sharma_blockchain_2020,
	title = {Blockchain {Technology} for {Cloud} {Storage}: {A} {Systematic} {Literature} {Review}},
	volume = {53},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3403954},
	doi = {10.1145/3403954},
	abstract = {The demand for Blockchain innovation and the significance of its application has inspired ever-progressing exploration in various scientific and practical areas. Even though it is still in the initial testing stage, the blockchain is being viewed as a progressive solution to address present-day technology concerns, such as decentralization, identity, trust, character, ownership of data, and information-driven choices. Simultaneously, the world is facing an increase in the diversity and quantity of digital information produced by machines and users. While effectively looking for the ideal approach to storing and processing cloud data, the blockchain innovation provides significant inputs. This article reviews the application of blockchain technology for securing cloud storage.},
	number = {4},
	journal = {ACM Comput. Surv.},
	author = {Sharma, Pratima and Jindal, Rajni and Borah, Malaya Dutta},
	month = aug,
	year = {2020},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Blockchain technology, cloud computing, cloud security, cloud storage, decentralization},
}

@article{heldens_landscape_2020,
	title = {The {Landscape} of {Exascale} {Research}: {A} {Data}-{Driven} {Literature} {Analysis}},
	volume = {53},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3372390},
	doi = {10.1145/3372390},
	abstract = {The next generation of supercomputers will break the exascale barrier. Soon we will have systems capable of at least one quintillion (billion billion) floating-point operations per second (1018 FLOPS). Tremendous amounts of work have been invested into identifying and overcoming the challenges of the exascale era. In this work, we present an overview of these efforts and provide insight into the important trends, developments, and exciting research opportunities in exascale computing. We use a three-stage approach in which we (1) discuss various exascale landmark studies, (2) use data-driven techniques to analyze the large collection of related literature, and (3) discuss eight research areas in depth based on influential articles. Overall, we observe that great advancements have been made in tackling the two primary exascale challenges: energy efficiency and fault tolerance. However, as we look forward, we still foresee two major concerns: the lack of suitable programming tools and the growing gap between processor performance and data bandwidth (i.e., memory, storage, networks). Although we will certainly reach exascale soon, without additional research, these issues could potentially limit the applicability of exascale computing.},
	number = {2},
	journal = {ACM Comput. Surv.},
	author = {Heldens, Stijn and Hijma, Pieter and Werkhoven, Ben Van and Maassen, Jason and Belloum, Adam S. Z. and Van Nieuwpoort, Rob V.},
	month = mar,
	year = {2020},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {data-driven analysis, Exascale computing, extreme-scale computing, high-performance computing, literature review},
}
