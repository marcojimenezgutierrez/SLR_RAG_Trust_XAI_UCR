@article{chakraborty_scalable_2025,
	title = {A scalable framework for evaluating multiple language models through cross-domain generation and hallucination detection},
	volume = {15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013393825&doi=10.1038%2Fs41598-025-15203-5&partnerID=40&md5=0bbade452a91a9b6bdd59d75beb0c865},
	doi = {10.1038/s41598-025-15203-5},
	number = {1},
	journal = {Scientific Reports},
	author = {Chakraborty, Sorup and Chowdhury, Rajesh and Shuvo, Sourov Roy and Chatterjee, Rajdeep and Roy, Satyabrata},
	year = {2025},
	note = {Type: Article},
	annote = {3 cites: https://scholar.google.com/scholar?cites=16377295747167734662\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Cited by: 1; All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lahiri_alzheimerrag_2025,
	title = {{AlzheimerRAG}: {Multimodal} {Retrieval}-{Augmented} {Generation} for {Clinical} {Use} {Cases}},
	volume = {7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017482418&doi=10.3390%2Fmake7030089&partnerID=40&md5=6a25bcf2b2c792618fdc9985d425922d},
	doi = {10.3390/make7030089},
	number = {3},
	journal = {Machine Learning and Knowledge Extraction},
	author = {Lahiri, Aritra Kumar and Hu, Qinmin Vivian},
	year = {2025},
	note = {Type: Article},
	annote = {2 cites: https://scholar.google.com/scholar?cites=18130119784755461945\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Cited by: 0; All Open Access; Gold Open Access},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mohammed_aftina_2025,
	title = {Aftina: enhancing stability and preventing hallucination in {AI}-based {Islamic} fatwa generation using {LLMs} and {RAG}},
	volume = {37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007154634&doi=10.1007%2Fs00521-025-11229-y&partnerID=40&md5=939b7edf1cdf6d33d9cb91be55b37879},
	doi = {10.1007/s00521-025-11229-y},
	number = {25},
	journal = {Neural Computing and Applications},
	author = {Mohammed, Marryam Yahya and Ali, Sama Ayman and Ali, Salma Khaled and Majeed, Ayad Abdul and Mohamed, Ensaf Hussein},
	year = {2025},
	note = {Type: Article},
	pages = {20957 -- 20982},
	annote = {6 cites: https://scholar.google.com/scholar?cites=1423186443048372558\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Cited by: 1; All Open Access; Hybrid Gold Open Access},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ahn_guide_2025,
	title = {A guide to evade hallucinations and maintain reliability when using large language models for medical research: a narrative review},
	volume = {30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010891665&doi=10.6065%2Fapem.2448278.139&partnerID=40&md5=7f0296d63a1792c3c8b7003e273d75a7},
	doi = {10.6065/apem.2448278.139},
	number = {3},
	journal = {Annals of Pediatric Endocrinology and Metabolism},
	author = {Ahn, Sangzin},
	year = {2025},
	note = {Type: Review},
	pages = {115 -- 118},
	annote = {3 cites: https://scholar.google.com/scholar?cites=17826633806691165993\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Cited by: 3; All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gokcimen_novel_2025,
	title = {A novel system for strengthening security in large language models against hallucination and injection attacks with effective strategies},
	volume = {123},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000800325&doi=10.1016%2Fj.aej.2025.03.030&partnerID=40&md5=882d2f82c8505110215a1699df506bf1},
	doi = {10.1016/j.aej.2025.03.030},
	journal = {Alexandria Engineering Journal},
	author = {Gokcimen, Tunahan and Daş, Bihter},
	year = {2025},
	note = {Type: Article},
	pages = {71 -- 90},
	annote = {6 cites: https://scholar.google.com/scholar?cites=13380834882110768059\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Cited by: 2; All Open Access; Gold Open Access},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{vrdoljak_review_2025,
	title = {A {Review} of {Large} {Language} {Models} in {Medical} {Education}, {Clinical} {Decision} {Support}, and {Healthcare} {Administration}},
	volume = {13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001405937&doi=10.3390%2Fhealthcare13060603&partnerID=40&md5=dd715e9162b67bf1cb3758893edd8024},
	doi = {10.3390/healthcare13060603},
	number = {6},
	journal = {Healthcare (Switzerland)},
	author = {Vrdoljak, Josip and Boban, Zvonimir and Vilović, Marino and Kumrić, Marko and Božić, Joško},
	year = {2025},
	note = {Type: Review},
	annote = {60 cites: https://scholar.google.com/scholar?cites=2744191307680405441\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Cited by: 28; All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ma_knowledge-graph_2025,
	title = {A knowledge-graph enhanced large language model-based fault diagnostic reasoning and maintenance decision support pipeline towards industry 5.0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000216854&doi=10.1080%2F00207543.2025.2472298&partnerID=40&md5=04acbd45047d0a68492338b6023f4875},
	doi = {10.1080/00207543.2025.2472298},
	journal = {International Journal of Production Research},
	author = {Ma, Yunfei and Zheng, Shuai and Yang, Zheng and Pan, Hongcheng and Hong, Jun},
	year = {2025},
	note = {Type: Article},
	annote = {11 cites: https://scholar.google.com/scholar?cites=11962484849429615187\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Cited by: 6},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bhattacharya_study_2025,
	title = {A {Study} on {Effect} of {Reference} {Knowledge} {Choice} in {Generating} {Technical} {Content} {Relevant} to {SAPPhIRE} {Model} {Using} {Large} {Language} {Model}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016902121&doi=10.1007%2F978-981-96-5511-3_39&partnerID=40&md5=1e900499748dc339d5305d9a5d0708b1},
	doi = {10.1007/978-981-96-5511-3_39},
	journal = {Lecture Notes in Mechanical Engineering},
	author = {Bhattacharya, Kausik and Majumder, Anubhab and Chakrabarti, Amaresh},
	year = {2025},
	note = {Type: Conference paper},
	pages = {505 -- 519},
	annote = {4 cites: https://scholar.google.com/scholar?cites=884979058723137955\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Cited by: 0},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{malin_review_2025,
	title = {A review of faithfulness metrics for hallucination assessment in {Large} {Language} {Models}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008028613&doi=10.1109%2FJSTSP.2025.3579203&partnerID=40&md5=80dc25e9b2c849f554bfdfe35d33a51f},
	doi = {10.1109/JSTSP.2025.3579203},
	journal = {IEEE Journal on Selected Topics in Signal Processing},
	author = {Malin, Ben and Kalganova, Tatiana G. and Boulgouris, Nikolaos V.},
	year = {2025},
	note = {Type: Review},
	annote = {5 cites: https://scholar.google.com/scholar?cites=10063492800142697664\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Cited by: 3},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{rajapaksha_rag-based_2025,
	title = {A {RAG}-{Based} {Question}-{Answering} {Solution} for {Cyber}-{Attack} {Investigation} and {Attribution}},
	volume = {15264 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002726829&doi=10.1007%2F978-3-031-82362-6_15&partnerID=40&md5=4e09a56488b8a016cdb17d9e976156a8},
	doi = {10.1007/978-3-031-82362-6_15},
	journal = {Lecture Notes in Computer Science},
	author = {Rajapaksha, Sampath and Rani, Ruby and Karafili, Erisa},
	year = {2025},
	note = {Type: Conference paper},
	pages = {238 -- 256},
	annote = {16 cites: https://scholar.google.com/scholar?cites=17534397634464150543\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Cited by: 1},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ieva_retrieval-augmented_2024,
	title = {A {Retrieval}-{Augmented} {Generation} {Approach} for {Data}-{Driven} {Energy} {Infrastructure} {Digital} {Twins}},
	volume = {7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213473949&doi=10.3390%2Fsmartcities7060121&partnerID=40&md5=ed95679d5b330936d91975a50883f42d},
	doi = {10.3390/smartcities7060121},
	number = {6},
	journal = {Smart Cities},
	author = {Ieva, Saverio and Loconte, Davide and Loseto, Giuseppe and Ruta, Michele and Scioscia, Floriano and Marche, Davide and Notarnicola, Marianna},
	year = {2024},
	note = {Type: Article},
	pages = {3095 -- 3120},
	annote = {20 cites: https://scholar.google.com/scholar?cites=17372842220837478108\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Cited by: 9; All Open Access; Gold Open Access},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{parmanto_reliable_2024,
	title = {A {Reliable} and {Accessible} {Caregiving} {Language} {Model} ({CaLM}) to {Support} {Tools} for {Caregivers}: {Development} and {Evaluation} {Study}},
	volume = {8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201209010&doi=10.2196%2F54633&partnerID=40&md5=5f32ba5d87f4ef405446ed6369450ecd},
	doi = {10.2196/54633},
	journal = {JMIR Formative Research},
	author = {Parmanto, Bambang and Aryoyudanta, Bayu and Soekinto, Timothius Wilbert and Setiawan, I. Made Agus and Wang, Yuhan and Hu, Haomin and Saptono, Andi and Choi, Yong K.},
	year = {2024},
	note = {Type: Article},
	annote = {18 cites: https://scholar.google.com/scholar?cites=16924225732617869910\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Cited by: 11; All Open Access; Gold Open Access; Green Final Open Access; Green Open Access},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ghanbari_haez_retrieval-augmented_2024,
	title = {A {Retrieval}-{Augmented} {Generation} {Strategy} to {Enhance} {Medical} {Chatbot} {Reliability}},
	volume = {14844 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200788990&doi=10.1007%2F978-3-031-66538-7_22&partnerID=40&md5=1f8150a51a1fcf22a212abac293b39df},
	doi = {10.1007/978-3-031-66538-7_22},
	journal = {Lecture Notes in Computer Science},
	author = {Ghanbari Haez, Saba and Segala, Marina and Bellan, Patrizio and Magnolini, Simone and Sanna, Leonardo and Consolandi, Monica and Dragoni, Mauro},
	year = {2024},
	note = {Type: Conference paper},
	pages = {213 -- 223},
	annote = {10 cites: https://scholar.google.com/scholar?cites=14223972115477384120\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Cited by: 7},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{shi_amsnet-kg_2025,
	title = {{AMSnet}-{KG}: {A} {Netlist} {Dataset} for {LLM}-based {AMS} {Circuit} {Auto}-design {Using} {Knowledge} {Graph} {RAG}},
	volume = {30},
	issn = {1084-4309},
	url = {https://doi.org/10.1145/3736166},
	doi = {10.1145/3736166},
	abstract = {High-performance analog and mixed-signal (AMS) circuits are mainly full-custom designed, which is time-consuming and labor-intensive. A significant portion of the effort is experience-driven, which makes the automation of AMS circuit design a formidable challenge. Large language models (LLMs) have emerged as powerful tools for electronic design automation (EDA) applications, fostering advancements in the automatic design process for large-scale AMS circuits. However, the absence of high-quality datasets has led to issues such as model hallucination, which undermines the robustness of automatically generated circuit designs. To address this issue, this article introduces AMSnet-KG, a dataset encompassing various AMS circuit schematics and netlists. We construct a knowledge graph with annotations on detailed functional and performance characteristics. Facilitated by AMSnet-KG, we propose an automated AMS circuit generation framework that utilizes the comprehensive knowledge embedded in LLMs. The flow first formulate a design strategy (e.g., circuit architecture using a number of circuit components) based on required specifications. Next, matched subcircuits are retrieved and assembled into a complete topology, and transistor sizing is obtained through Bayesian optimization. Simulation results of the netlist are automatically fed back to the LLM for further topology refinement, ensuring the circuit design specifications are met. We perform case studies of operational amplifier and comparator design to verify the automatic design flow from specifications to netlists with minimal human effort. The dataset used in this article is available at .},
	number = {6},
	journal = {ACM Trans. Des. Autom. Electron. Syst.},
	author = {Shi, Yichen and Tao, Zhuofu and Gao, YuHao and Zhou, Tianjia and Chang, Cheng and Wang, Yaxin and Chen, Bingyu and Zhang, Genhao and Liu, Alvin and Yu, Zhiping and Lin, Ting-Jung and He, Lei},
	month = oct,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {AMSnet, EDA, knowledge graph, LLM, RAG, topology design},
	annote = {8 cites: https://scholar.google.com/scholar?cites=18096057598545424232\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{qiang_agent-om_2024,
	title = {Agent-{OM}: {Leveraging} {LLM} {Agents} for {Ontology} {Matching}},
	volume = {18},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3712221.3712222},
	doi = {10.14778/3712221.3712222},
	abstract = {Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM agents have revolutionised data engineering and have been applied creatively in many domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With consideration of several specific challenges in leveraging LLM agents for OM, we propose a generic framework, namely Agent-OM (Agent for Ontology Matching), consisting of two Siamese agents for retrieval and matching, with a set of OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAEI) tracks over state-of-the-art OM systems show that our system can achieve results very close to the long-standing best performance on simple OM tasks and can significantly improve the performance on complex and few-shot OM tasks.},
	number = {3},
	journal = {Proc. VLDB Endow.},
	author = {Qiang, Zhangcheng and Wang, Weiqing and Taylor, Kerry},
	month = nov,
	year = {2024},
	note = {Publisher: VLDB Endowment},
	pages = {516--529},
	annote = {19 cites: https://scholar.google.com/scholar?cites=11537150885406125790\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{huang_survey_2025,
	title = {A {Survey} on {Hallucination} in {Large} {Language} {Models}: {Principles}, {Taxonomy}, {Challenges}, and {Open} {Questions}},
	volume = {43},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/3703155},
	doi = {10.1145/3703155},
	abstract = {The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), fueling a paradigm shift in information acquisition. Nevertheless, LLMs are prone to hallucination, generating plausible yet nonfactual content. This phenomenon raises significant concerns over the reliability of LLMs in real-world information retrieval (IR) systems and has attracted intensive research to detect and mitigate such hallucinations. Given the open-ended general-purpose attributes inherent to LLMs, LLM hallucinations present distinct challenges that diverge from prior task-specific models. This divergence highlights the urgency for a nuanced understanding and comprehensive overview of recent advances in LLM hallucinations. In this survey, we begin with an innovative taxonomy of hallucination in the era of LLM and then delve into the factors contributing to hallucinations. Subsequently, we present a thorough overview of hallucination detection methods and benchmarks. Our discussion then transfers to representative methodologies for mitigating LLM hallucinations. Additionally, we delve into the current limitations faced by retrieval-augmented LLMs in combating hallucinations, offering insights for developing more robust IR systems. Finally, we highlight the promising research directions on LLM hallucinations, including hallucination in large vision-language models and understanding of knowledge boundaries in LLM hallucinations.},
	number = {2},
	journal = {ACM Trans. Inf. Syst.},
	author = {Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and Liu, Ting},
	month = jan,
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {Factuality, Faithfulness, Hallucination, Large Language Models},
	annote = {2979 cites: https://scholar.google.com/scholar?cites=12755344437467074574\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_enhancing_2024,
	title = {Enhancing llm factual accuracy with rag to counter hallucinations: {A} case study on domain-specific queries in private knowledge-bases},
	url = {https://arxiv.org/abs/2403.10446},
	abstract = {… RAG pipeline with upstream datasets processing and downstream performance evaluation. Addressing the challenge of LLM hal… This research highlights the potential of RAG systems in …},
	journal = {arXiv preprint arXiv:2403.10446},
	author = {Li, J. and Yuan, Y. and Zhang, Z.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {147 cites: https://scholar.google.com/scholar?cites=18401788701620548490\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kang_c-rag_2024,
	title = {C-rag: {Certified} generation risks for retrieval-augmented language models},
	url = {https://arxiv.org/abs/2402.03181},
	abstract = {… C-RAG, a novel framework to certify generation risks for RAG … for RAG models and certify an upper confidence bound of … of RAG is lower than that of the corresponding vanilla LLM in …},
	journal = {arXiv preprint arXiv:2402.03181},
	author = {Kang, M. and Gürel, N. M. and Yu, N. and Song, D. and Li, B.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {39 cites: https://scholar.google.com/scholar?cites=5800676365446233247\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{essafi_genai_2025,
	title = {{GenAI}, {LLM}/{MLLM}, {RAG}, and {Their} {Impacts} on {Hallucination}, {Reliability} and {Trustworthiness}},
	url = {https://link.springer.com/chapter/10.1007/978-3-032-05607-8_3},
	doi = {10.1007/978-3-032-05607-8_3},
	abstract = {… Our aim is to highlight the key elements leading to the hallucination and impacting the reliability and trustworthiness of LLM-based AI. We will also discuss the mitigation solutions. …},
	journal = {International Conference on Flexible Query Answering …},
	author = {Essafi, H.},
	year = {2025},
	note = {Publisher: Springer},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{martin_semantic_2024,
	title = {Semantic verification in large language model-based retrieval augmented generation},
	url = {https://ojs.aaai.org/index.php/AAAI-SS/article/view/31199},
	abstract = {… verification in Large Language Model-based Retrieval Augmented Generation (LLM-RAG) … Large Language Models (LLMs) in maintaining factual integrity, this research proposes an …},
	journal = {Proceedings of the AAAI …},
	author = {Martin, A. and Witschel, H. F. and Mandl, M. and {...}},
	year = {2024},
	note = {Publisher: ojs.aaai.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=12923520028004769111\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{niu_ragtruth_2023,
	title = {Ragtruth: {A} hallucination corpus for developing trustworthy retrieval-augmented language models},
	url = {https://arxiv.org/abs/2401.00396},
	abstract = {… in identifying hallucinations by fine-tuning LLM with … wordlevel hallucination evaluation dataset specifically for the RAG … method of fine-tuning LLM for hallucination detection. It is shown …},
	journal = {arXiv preprint arXiv …},
	author = {Niu, C. and Wu, Y. and Zhu, J. and Xu, S. and Shum, K. and Zhong, R. and {...}},
	year = {2023},
	note = {Publisher: arxiv.org},
	annote = {172 cites: https://scholar.google.com/scholar?cites=3609316933688380015\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_use_2025,
	title = {Use of {Retrieval}-{Augmented} {Large} {Language} {Model} for {COVID}-19 {Fact}-{Checking}: {Development} and {Usability} {Study}},
	url = {https://www.jmir.org/2025/1/e66098/},
	abstract = {… By addressing the challenges of LLM inaccuracies and the high costs of traditional fact-checking methods, our RAG-enhanced approach improves the factual correctness of outputs. It …},
	journal = {Journal of medical Internet research},
	author = {Li, H. and Huang, J. and Ji, M. and Yang, Y. and An, R.},
	year = {2025},
	note = {Publisher: jmir.org
Type: HTML},
	annote = {10 cites: https://scholar.google.com/scholar?cites=4610967429469974473\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lee_enhancing_2024,
	title = {Enhancing large language model reliability: minimizing hallucinations with dual retrieval-augmented generation based on the latest diabetes guidelines},
	url = {https://www.mdpi.com/2075-4426/14/12/1131},
	abstract = {… novel retrieval system to enhance LLM reliability in diabetes … a dual retrieval-augmented generation (RAG) system … an effective dual RAG system that enhances LLM reliability in …},
	journal = {Journal of Personalized Medicine},
	author = {Lee, J. and Cha, H. and Hwangbo, Y. and Cheon, W.},
	year = {2024},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {10 cites: https://scholar.google.com/scholar?cites=7602178544602545405\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{su_implementing_2024,
	title = {Implementing retrieval-augmented generation (rag) for large language models to build confidence in traditional chinese medicine},
	url = {https://files.osf.io/v1/resources/ns2v3_v1/providers/osfstorage/66678b7a65e1de5555893ab1?action=download\&direct\&version=1},
	abstract = {… [14] MI Rafat, “Ai-powered legal virtual assistant: Utilizing rag-optimized llm for housing dispute resolution in finland.” 2024. [15] K. Krishna, “Towards robust long-form text generation …},
	publisher = {files.osf.io},
	author = {Su, X. and Gu, Y.},
	year = {2024},
	note = {Type: PDF},
	annote = {74 cites: https://scholar.google.com/scholar?cites=15427979219594072122\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gao_retrieval-augmented_2023,
	title = {Retrieval-augmented generation for large language models: {A} survey},
	url = {https://simg.baai.ac.cn/paperfile/25a43194-c74c-4cd3-b60f-0a1f27f8b8af.pdf},
	abstract = {… , such as hallucinations, slow … RAG The Naive RAG research paradigm represents the earliest methodology gained prominence shortly after the widespread adoption of ChatGPT…},
	journal = {arXiv preprint arXiv …},
	author = {Gao, Y. and Xiong, Y. and Gao, X. and Jia, K. and Pan, J. and Bi, Y. and {...}},
	year = {2023},
	note = {Publisher: simg.baai.ac.cn
Type: PDF},
	annote = {3486 cites: https://scholar.google.com/scholar?cites=9082880950785936523\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{fan_survey_2024,
	title = {A survey on rag meeting llms: {Towards} retrieval-augmented large language models},
	url = {https://dl.acm.org/doi/abs/10.1145/3637528.3671470},
	doi = {10.1145/3637528.3671470},
	abstract = {… ing inherent limitations such as hallucinations and out-of-… RAG to enhance the in-context learning ability of ChatGPT for molecular discovery [68]. It is also been demonstrated that RAG …},
	journal = {Proceedings of the 30th …},
	author = {Fan, W. and Ding, Y. and Ning, L. and Wang, S. and Li, H. and Yin, D. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {832 cites: https://scholar.google.com/scholar?cites=4439195171371337250\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_evaluating_2024,
	title = {Evaluating quality of answers for retrieval-augmented generation: {A} strong llm is all you need},
	url = {https://arxiv.org/abs/2406.18064},
	abstract = {… of answer quality evaluation in Retrieval-Augmented Generation (RAG) applications using vRAG… grading hallucinations, we fix the temperature parameter for each LLM call at T = 0.0. …},
	journal = {arXiv preprint arXiv …},
	author = {Wang, Y. and Hernandez, A. G. and Kyslyi, R. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {20 cites: https://scholar.google.com/scholar?cites=567568926671679355\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{amugongo_retrieval_2025,
	title = {Retrieval augmented generation for large language models in healthcare: {A} systematic review},
	url = {https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000877},
	abstract = {… With RAG, the LLM performance is contextually bolstered without performing computationally … enhance the properties of RAG, it is not clear how this can reduce hallucination. A recent …},
	journal = {PLOS Digital …},
	author = {Amugongo, L. M. and Mascheroni, P. and Brooks, S. and {...}},
	year = {2025},
	note = {Publisher: journals.plos.org
Type: HTML},
	annote = {57 cites: https://scholar.google.com/scholar?cites=11887182342671734315\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{fink_retrieval-augmented_2025,
	title = {Retrieval-augmented generation improves precision and trust of a {GPT}-4 model for emergency radiology diagnosis and classification: a proof-of-concept …},
	url = {https://link.springer.com/article/10.1007/s00330-025-11445-z},
	doi = {10.1007/s00330-025-11445-z},
	abstract = {… Even correct chatbot answers can be subject to inaccuracies and hallucinations [10], and the … Retrieval-augmented generation (RAG) is an approach that increases LLM performance by …},
	journal = {European …},
	author = {Fink, A. and Nattenmüller, J. and Rau, S. and Rau, A. and Tran, H. and {...}},
	year = {2025},
	note = {Publisher: Springer
Type: HTML},
	annote = {7 cites: https://scholar.google.com/scholar?cites=10561146850836683278\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ozaki_understanding_2024,
	title = {Understanding the impact of confidence in retrieval augmented generation: {A} case study in the medical domain},
	url = {https://arxiv.org/abs/2412.20309},
	abstract = {… We evaluate if RAG boosts LLM confidence using entropy, best probability, accuracy, and Adaptive Calibration Error. In our multiple-choice QA task, each question has one correct …},
	journal = {arXiv preprint arXiv …},
	author = {Ozaki, S. and Kato, Y. and Feng, S. and Tomita, M. and Hayashi, K. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=10089283873825702865\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhou_trustworthiness_2024,
	title = {Trustworthiness in retrieval-augmented generation systems: {A} survey},
	url = {https://arxiv.org/abs/2409.10102},
	abstract = {… the RAG context: As shown in Figure 1, we define trustworthiness across six dimensions: (1) … scenarios, we focus on assessing the correctness of the intermediate steps in the LLM’s …},
	journal = {arXiv preprint arXiv …},
	author = {Zhou, Y. and Liu, Y. and Li, X. and Jin, J. and Qian, H. and Liu, Z. and Li, C. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {82 cites: https://scholar.google.com/scholar?cites=8987613846345750009\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{agrawal_scmrag_2025,
	title = {Scmrag: {Self}-corrective multihop retrieval augmented generation system for llm agents},
	url = {https://www.ifaamas.org/Proceedings/aamas2025/pdfs/p50.pdf},
	abstract = {… For each factual chunk, we prompt a large language model (LLM) to generate a ‘claim’. A ‘claim’ is defined as a statement or assertion that expresses a belief, opinion, or fact, devoid of …},
	journal = {Proceedings of the 24th …},
	author = {Agrawal, R. and Asrani, M. and Youssef, H. and {...}},
	year = {2025},
	note = {Publisher: ifaamas.org
Type: PDF},
	annote = {2 cites: https://scholar.google.com/scholar?cites=13739667046554411380\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{song_rag-hat_2024,
	title = {{RAG}-{HAT}: {A} hallucination-aware tuning pipeline for {LLM} in retrieval-augmented generation},
	url = {https://aclanthology.org/2024.emnlp-industry.113/},
	abstract = {… While Tian’s work aims to enable language models to produce more factual answers, our research specifically focuses on enhancing LLM capabilities in RAG scenarios. …},
	journal = {Proceedings of the …},
	author = {Song, J. and Wang, X. and Zhu, J. and Wu, Y. and Cheng, X. and {...}},
	year = {2024},
	note = {Publisher: aclanthology.org},
	annote = {27 cites: https://scholar.google.com/scholar?cites=3163369204065586323\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mansurova_qa-rag_2024,
	title = {{QA}-{RAG}: {Exploring} {LLM} reliance on external knowledge},
	url = {https://www.mdpi.com/2504-2289/8/9/115},
	abstract = {… This makes it harder for users to trust and verify LLM-generated … QA-RAG for constructing question-answering systems empowered by LLMs to handle the occurrence of hallucination. …},
	journal = {Big Data and Cognitive …},
	author = {Mansurova, A. and Mansurova, A. and {...}},
	year = {2024},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {38 cites: https://scholar.google.com/scholar?cites=3899755970899623759\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{chidipothu_improving_2024,
	title = {Improving large language model (llm) performance with retrieval augmented generation (rag): {Development} of a transparent generative artificial intelligence (gen ai) …},
	url = {https://scholarship.libraries.rutgers.edu/esploro/outputs/preprint/Improving-large-language-model-LLM-performance/991032165917804646?institution=01RUT_INST},
	abstract = {… significantly greater than 1 will result in hallucinations. In our design, we choose a low temperature so that the LLM prioritizes factuality during the response process rather than …},
	publisher = {scholarship.libraries.rutgers.edu},
	author = {Chidipothu, N. and Samuel, J. and Esguerra, J. and Anderson, R. and {...}},
	year = {2024},
	annote = {8 cites: https://scholar.google.com/scholar?cites=16877552683721152667\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mortaheb_rag-check_2025,
	title = {Rag-check: {Evaluating} multimodal retrieval augmented generation performance},
	url = {https://arxiv.org/abs/2501.03995},
	abstract = {… In particular, multi-modal RAG systems process each … provided to the LLM in the final stage of the RAG system along … that provide hallucination scores specifically for multi-modal RAG …},
	journal = {arXiv preprint arXiv …},
	author = {Mortaheb, M. and Khojastepour, M. A. A. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=10254921453134223155\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wu_medical_2024,
	title = {Medical graph rag: {Towards} safe medical large language model via graph retrieval-augmented generation},
	url = {https://arxiv.org/abs/2408.04187},
	abstract = {… RAG data to credible medical papers and foundational medical dictionaries. This process generates triples [RAG … It enhances LLM reasoning and ensures responses are traceable to …},
	journal = {arXiv preprint arXiv …},
	author = {Wu, J. and Zhu, J. and Qi, Y. and Chen, J. and Xu, M. and Menolascina, F. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {144 cites: https://scholar.google.com/scholar?cites=17183034335062469017\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wu_multirag_2025,
	title = {Multirag: a knowledge-guided framework for mitigating hallucination in multi-source retrieval augmented generation},
	url = {https://ieeexplore.ieee.org/abstract/document/11113128/},
	abstract = {… a promising solution to address hallucination issues in Large … hallucination in multi-source retrieval-augmented generation … context of the LLM to generate a credible retrieval answer. …},
	journal = {2025 IEEE 41st …},
	author = {Wu, W. and Wang, H. and Li, B. and Huang, P. and Zhao, X. and {...}},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=16538395722157752160\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hwang_retrieval-augmented_2024,
	title = {Retrieval-{Augmented} {Generation} with {Estimation} of {Source} {Reliability}},
	url = {https://arxiv.org/abs/2410.22954},
	abstract = {… RAG enhances LLM performance by retrieving information from external databases, reducing hallucinations, and improving access to up-to-date knowledge (Lewis et al.…},
	journal = {arXiv preprint arXiv …},
	author = {Hwang, J. and Park, J. and Park, H. and Kim, D. and Park, S. and Ok, J.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=3251552246372497675\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{njeh_enhancing_2024,
	title = {Enhancing rag-retrieval to improve llms robustness and resilience to hallucinations},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-74186-9_17},
	doi = {10.1007/978-3-031-74186-9_17},
	abstract = {… the LLM. This augmented prompt effectively incorporates the retrieved text chunks as context, thereby empowering the LLM … text chunks, the RAG system significantly bolsters the LLM’s …},
	journal = {International Conference on Hybrid Artificial …},
	author = {Njeh, C. and Nakouri, H. and Jaafar, F.},
	year = {2024},
	note = {Publisher: Springer},
	annote = {15 cites: https://scholar.google.com/scholar?cites=2677994216701710356\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{han_automating_2024,
	title = {Automating systematic literature reviews with retrieval-augmented generation: a comprehensive overview},
	url = {https://www.mdpi.com/2076-3417/14/19/9103},
	abstract = {… RAG enhances LLM performance by grounding responses in dynamically updated and … citations based on context; RAG models tested on this benchmark outperformed ChatGPT-4. In …},
	journal = {Applied Sciences},
	author = {Han, B. and Susnjak, T. and Mathrani, A.},
	year = {2024},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {38 cites: https://scholar.google.com/scholar?cites=6240994090275982885\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{oche_systematic_2025,
	title = {A systematic review of key retrieval-augmented generation (rag) systems: {Progress}, gaps, and future directions},
	url = {https://arxiv.org/abs/2507.18910},
	abstract = {… RAG architecture is illustrated in Figure 1 below. A key distinction between RAG and pure large language model (LLM… Overall, RAG became a cornerstone for credible LLM deployments …},
	journal = {arXiv preprint arXiv …},
	author = {Oche, A. J. and Folashade, A. G. and Ghosal, T. and Biswas, A.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {11 cites: https://scholar.google.com/scholar?cites=1635735593323768918\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{song_measuring_2024,
	title = {Measuring and enhancing trustworthiness of {LLMs} in {RAG} through grounded attributions and learning to refuse},
	url = {https://arxiv.org/abs/2409.11242},
	abstract = {… We define hallucination as an erroneous LLM response, categorized into five types: (1) … We aim to measure two aspects of an LLM in RAG: 1) the Correctness of the generated …},
	journal = {arXiv preprint arXiv …},
	author = {Song, M. and Sim, S. H. and Bhardwaj, R. and Chieu, H. L. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {17 cites: https://scholar.google.com/scholar?cites=14261566534983479602\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{gai_achieving_2024,
	title = {Achieving higher factual accuracy in llama llm with weighted distribution of retrieval-augmented generation},
	url = {https://files.osf.io/v1/resources/ctw8v_v1/providers/osfstorage/664c901d2f167d17c20e7d42?action=download\&direct\&version=1},
	abstract = {… Retrieval-Augmented Generation (RAG) with the Llama Large language model significantly enhances factual … the effectiveness of the weighted RAG mechanism in prioritizing high-…},
	publisher = {files.osf.io},
	author = {Gai, Z. and Tong, L. and Ge, Q.},
	year = {2024},
	note = {Type: PDF},
	annote = {74 cites: https://scholar.google.com/scholar?cites=4266316317150886718\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{amarnath_intelligent_2024,
	title = {An {Intelligent} {Retrieval} {Augmented} {Generation} {Chatbot} for {Contextually}-{Aware} {Conversations} to {Guide} {High} {School} {Students}},
	url = {https://ieeexplore.ieee.org/abstract/document/10762977/},
	abstract = {… By integrating a high school course guide with a RAG system… educational paths with greater confidence and precision. … an RAG chatbot to address this gap by leveraging the LLM's …},
	journal = {2024 4th International …},
	author = {Amarnath, N. S. and Nagarajan, R.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=16874919490639647377\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_mitigating_2024,
	title = {Mitigating {Hallucinations} in {Large} {Language} {Models}: {A} {Comparative} {Study} of {RAG}-enhanced vs. {Human}-{Generated} {Medical} {Templates}},
	url = {https://www.medrxiv.org/content/10.1101/2024.09.27.24314506.abstract},
	doi = {10.1101/2024.09.27.24314506.abstract},
	abstract = {… This study aims to assess the accuracy and effectiveness of RAG-integrated ChatGPT responses in organizing medical information. The information will be organized in a consultation …},
	journal = {medRxiv},
	author = {Li, A. and Shrestha, R. and Jegatheeswaran, T. and Chan, H. O. and Hong, C. and {...}},
	year = {2024},
	note = {Publisher: medrxiv.org},
	annote = {11 cites: https://scholar.google.com/scholar?cites=11887936041973308306\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kirchenbauer_hallucination_2024,
	title = {Hallucination reduction in large language models with retrieval-augmented generation using wikipedia knowledge},
	url = {https://files.osf.io/v1/resources/pv7r5/providers/osfstorage/6657166cd835c421594ce333?format=pdf\&action=download\&direct\&version=1},
	abstract = {… Retrieval-augmented generation (RAG) has been widely recognized for its potential to enhance the factual accuracy of LLM … Implementations of RAG combined a retrieval module with …},
	journal = {ArXiv Preprint. https://doi. org/10.31219/osf. io …},
	author = {Kirchenbauer, J. and Barns, C.},
	year = {2024},
	note = {Publisher: files.osf.io
Type: PDF},
	annote = {75 cites: https://scholar.google.com/scholar?cites=18289936496904035159\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_retrieval-augmented_2025,
	title = {Retrieval-augmented generation with conflicting evidence},
	url = {https://arxiv.org/abs/2504.13079},
	abstract = {… using the parametric knowledge of the LLM (ie, the No RAG baseline which does not see … , making it harder for the LLM to distinguish factual documents from inaccurate ones. These …},
	journal = {arXiv preprint arXiv …},
	author = {Wang, H. and Prasad, A. and Stengel-Eskin, E. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {17 cites: https://scholar.google.com/scholar?cites=11383659473294935796\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lyu_crud-rag_2025,
	title = {Crud-rag: {A} comprehensive chinese benchmark for retrieval-augmented generation of large language models},
	url = {https://dl.acm.org/doi/abs/10.1145/3701228},
	doi = {10.1145/3701228},
	abstract = {… system, such as the retriever, context length, knowledge base construction, and LLM. Finally… Triad as an innovative approach to evaluate hallucination issues within the RAG architecture…},
	journal = {ACM Transactions on …},
	author = {Lyu, Y. and Li, Z. and Niu, S. and Xiong, F. and Tang, B. and Wang, W. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {137 cites: https://scholar.google.com/scholar?cites=1055973339222941591\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_benchmarking_2024,
	title = {Benchmarking large language models in retrieval-augmented generation},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/29728},
	abstract = {… use ChatGPT to conduct additional evaluation of the responses. Specifically, we prompt ChatGPT … can reflect information that is not present in the document or identify any factual errors. …},
	journal = {Proceedings of the AAAI Conference on …},
	author = {Chen, J. and Lin, H. and Han, X. and Sun, L.},
	year = {2024},
	note = {Publisher: ojs.aaai.org},
	annote = {776 cites: https://scholar.google.com/scholar?cites=3946244813554043217\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ng_rag_2025,
	title = {{RAG} in health care: a novel framework for improving communication and decision-making by addressing {LLM} limitations},
	url = {https://ai.nejm.org/doi/abs/10.1056/AIra2400380},
	doi = {10.1056/AIra2400380},
	abstract = {… decisions is essential to building trust and accountability. Lastly, by grounding the LLM’s output in retrieved context, RAG can reduce the risks of hallucination and improve the accuracy …},
	journal = {Nejm Ai},
	author = {Ng, K. K. Y. and Matsuba, I. and Zhang, P. C.},
	year = {2025},
	note = {Publisher: ai.nejm.org},
	annote = {60 cites: https://scholar.google.com/scholar?cites=6549315426020192129\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_retrieval-augmented_2025,
	title = {Retrieval-augmented generation for educational application: {A} systematic survey},
	url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000578},
	abstract = {… Retrieval-Augmented Generation (RAG) enhances LLMs by retrieving relevant information … it into the LLM's generation process. This approach improves factual accuracy and enables …},
	journal = {Computers and Education …},
	author = {Li, Z. and Wang, Z. and Wang, W. and Hung, K. and Xie, H. and {...}},
	year = {2025},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {14 cites: https://scholar.google.com/scholar?cites=2552583327213639\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_hallucination_2025,
	title = {Hallucination mitigation for retrieval-augmented large language models: a review},
	url = {https://www.mdpi.com/2227-7390/13/5/856},
	abstract = {… Investigating the root causes of hallucinations in the RAG paradigm helps to understand the mechanisms of its components at different stages and how their limitations affect LLM-…},
	journal = {Mathematics},
	author = {Zhang, W. and Zhang, J.},
	year = {2025},
	note = {Publisher: mdpi.com},
	annote = {31 cites: https://scholar.google.com/scholar?cites=10259911133790956861\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{woo_custom_2025,
	title = {Custom large language models improve accuracy: comparing retrieval augmented generation and artificial intelligence agents to noncustom models for evidence …},
	url = {https://www.sciencedirect.com/science/article/pii/S0749806324008831},
	abstract = {… RAG improved accuracy by an average of 39.7\%, with the highest accuracy rate of 94\% in … RAG-augmented LLM improved ChatGPT4 accuracy rate to 95\%. Thus, Agentic and RAG …},
	journal = {… : The Journal of …},
	author = {Woo, J. J. and Yang, A. J. and Olsen, R. J. and Hasan, S. S. and {...}},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {37 cites: https://scholar.google.com/scholar?cites=16564615683741352911\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tyndall_impact_2025,
	title = {Impact of retrieval augmented generation and large language model complexity on undergraduate exams created and taken by {AI} agents},
	url = {https://www.cambridge.org/core/journals/data-and-policy/article/impact-of-retrieval-augmented-generation-and-large-language-model-complexity-on-undergraduate-exams-created-and-taken-by-ai-agents/498B8CB29AA37695AC5EACBE1B2089B4},
	abstract = {… allows it to leverage RAG and the textbook … ChatGPT-4 Turbo model, which did not have access to the college textbook. While this study did not directly test for hallucinations, citations …},
	journal = {Data \&Policy},
	author = {Tyndall, E. and Gayheart, C. and Some, A. and Genz, J. and Wagner, T. and {...}},
	year = {2025},
	note = {Publisher: cambridge.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sharma_og-rag_2024,
	title = {Og-rag: {Ontology}-grounded retrieval-augmented generation for large language models},
	url = {https://arxiv.org/abs/2412.15235},
	abstract = {… Through extensive experiments on two agriculture datasets and a news dataset, we demonstrate that OG-RAG significantly improves the factual accuracy of LLM-generated responses, …},
	journal = {arXiv preprint arXiv:2412.15235},
	author = {Sharma, K. and Kumar, P. and Li, Y.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=13573475367967687009\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{amirshahi_evaluating_2025,
	title = {Evaluating the {Robustness} of {Retrieval}-{Augmented} {Generation} to {Adversarial} {Evidence} in the {Health} {Domain}},
	url = {https://arxiv.org/abs/2509.03787},
	abstract = {… Retrieval augmented generation (RAG) systems provide a method for factually grounding the responses of a Large Language Model (LLM… , RAG systems can reduce hallucinations and …},
	journal = {arXiv preprint arXiv …},
	author = {Amirshahi, S. and Bigdeli, A. and Clarke, C. L. A. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=14545318095950271101\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{prabhune_deploying_2024,
	title = {Deploying large language models with retrieval augmented generation},
	url = {https://arxiv.org/abs/2411.11895},
	abstract = {… (LLM) are sometimes hampered by tendencies to hallucinate or create non-factual responses, … have increasingly focused on methods to ground generated outputs in factual data. …},
	journal = {arXiv preprint arXiv:2411.11895},
	author = {Prabhune, S. and Berndt, D. J.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=6395007018287577997\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{yan_corrective_2024,
	title = {Corrective retrieval augmented generation},
	url = {https://openreview.net/forum?id=JnWJbrnaUE},
	abstract = {… (LLMs) inevitably exhibit hallucinations since the accuracy … LLM ChatGPT on the document retrieval results was shown in Table 4. The prompts of ChatGPT, ChatGPT-CoT, and ChatGPT…},
	publisher = {openreview.net},
	author = {Yan, S. Q. and Gu, J. C. and Zhu, Y. and Ling, Z. H.},
	year = {2024},
	annote = {302 cites: https://scholar.google.com/scholar?cites=5586825707265380735\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{liu_improving_2025,
	title = {Improving large language model applications in biomedicine with retrieval-augmented generation: a systematic review, meta-analysis, and clinical …},
	journal = {Journal of the American Medical …},
	author = {Liu, S. and McCoy, A. B. and Wright, A.},
	year = {2025},
	note = {Publisher: Oxford Academic
Type: CITATION},
	annote = {53 cites: https://scholar.google.com/scholar?cites=14289693404588094897\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{asbai_mitigating_2024,
	title = {Mitigating {Hallucination} in {Large} {Language} {Model} {Code} {Generation} for {Higher} {Education}: {An} {Evaluation} of {Retrieval} {Augmented} {Generation}},
	url = {https://www.diva-portal.org/smash/record.jsf?pid=diva2:1887431},
	abstract = {… This study evaluated the RAG hallucination mitigation strategy on ChatGPT and Gemini to … More specifically, the study evaluated the RAG techniques’ ability to mitigate hallucination in …},
	publisher = {diva-portal.org},
	author = {Asbai, A.},
	year = {2024},
	annote = {4 cites: https://scholar.google.com/scholar?cites=965489537270893557\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{low_answering_2025,
	title = {Answering real-world clinical questions using large language model, retrieval-augmented generation, and agentic systems},
	url = {https://journals.sagepub.com/doi/abs/10.1177/20552076251348850},
	doi = {10.1177/20552076251348850},
	abstract = {… Additionally, to facilitate evaluation and understand LLM reasoning, we specifically asked the models to cite any referenced studies and respond with “I do not know the answer” when …},
	journal = {Digital …},
	author = {Low, Y. S. and Jackson, M. L. and Hyde, R. J. and Brown, R. E. and {...}},
	year = {2025},
	note = {Publisher: journals.sagepub.com},
	annote = {12 cites: https://scholar.google.com/scholar?cites=13290717302845040516\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{rahman_hallucination_2025,
	title = {Hallucination to truth: {A} review of fact-checking and factuality evaluation in large language models},
	url = {https://arxiv.org/abs/2508.03860},
	abstract = {… This review systematically analyzes how LLM-generated content is evaluated for factual … [30] introduce Fact-CheckThen-RAG which improves LLM factual accuracy by evaluating each …},
	journal = {arXiv preprint arXiv …},
	author = {Rahman, S. S. and Islam, M. A. and Alam, M. M. and Zeba, M. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=449068971138611609\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{islam_open-rag_2024,
	title = {Open-rag: {Enhanced} retrieval-augmented reasoning with open-source large language models},
	url = {https://arxiv.org/abs/2410.01782},
	abstract = {… tokens and measure the confidence of outputs conditioned on … that our OPENRAG significantly improves the overall factual ac… We define OPEN-RAG LLM as a model MG that, given an …},
	journal = {arXiv preprint arXiv …},
	author = {Islam, S. B. and Rahman, M. A. and Hossain, K. S. M. and Hoque, E. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {43 cites: https://scholar.google.com/scholar?cites=5728474907788135047\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kluibenschadl_fiction_2024,
	title = {{FROM} {FICTION} {TO} {FACT}: {MAKING} {LLM} {STUDY} {AIDS} {MORE} {RELIABLE} {WITH} {OPEN}-{SOURCE} {RAG}},
	url = {https://library.iated.org/view/KLUIBENSCHADL2024FRO},
	abstract = {… Our work has outlined how a RAG-augmented educational LLM can be built using various … We have furthermore shown how the RAG-augmentation helped improve factual accuracy, …},
	journal = {ICERI2024 Proceedings},
	author = {Kluibenschädl, S. and Schlögl, S. and Kruschel, S.},
	year = {2024},
	note = {Publisher: library.iated.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=15701308974179597740\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kumar_improving_2025,
	title = {Improving the reliability of {LLMs}: {Combining} {CoT}, {RAG}, self-consistency, and self-verification},
	url = {https://arxiv.org/abs/2505.09031},
	abstract = {… retrieval-augmented generation (RAG), as well as applying self-consistency and selfverification strategies, can reduce hallucinations and improve factual … to tackle LLM Hallucinations. …},
	journal = {arXiv preprint arXiv:2505.09031},
	author = {Kumar, A. and Kim, H. and Nathani, J. S. and Roy, N.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=13363082870840263208\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{es_ragas_2024,
	title = {Ragas: {Automated} evaluation of retrieval augmented generation},
	url = {https://aclanthology.org/2024.eacl-demo.16/},
	abstract = {… factual answers are more stable: when an answer is factual, we … this is less likely to be the case for hallucinated answers. … To estimate faithfulness, we first use an LLM to extract a set of …},
	journal = {Proceedings of the 18th …},
	author = {Es, S. and James, J. and Anke, L. E. and {...}},
	year = {2024},
	note = {Publisher: aclanthology.org},
	annote = {784 cites: https://scholar.google.com/scholar?cites=17519873998219892733\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhao_retrieval_2024,
	title = {Retrieval augmented generation (rag) and beyond: {A} comprehensive survey on how to make your llms use external data more wisely},
	url = {https://arxiv.org/abs/2409.14924},
	abstract = {… tailoring LLM applications to meet specific industry needs. Through techniques like RAG and fine tuning, data augmented LLM … • Reduction in Model Hallucination: Data augmented LLM …},
	journal = {arXiv preprint arXiv …},
	author = {Zhao, S. and Yang, Y. and Wang, Z. and He, Z. and Qiu, L. K. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {108 cites: https://scholar.google.com/scholar?cites=1367863433047780472\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{klesel_retrieval-augmented_2025,
	title = {Retrieval-{Augmented} {Generation} ({RAG}) {M}. {Klesel}, {HF} {Wittmann}},
	url = {https://link.springer.com/article/10.1007/s12599-025-00945-3},
	doi = {10.1007/s12599-025-00945-3},
	abstract = {… LLM Fine-Tuning, and RAG. In the first scenario (Foundation Model), all training data results in an LLM … hallucinations in this manuscript to ensure consistency with the relevant literature. …},
	journal = {Business \&Information Systems Engineering},
	author = {Klesel, M. and Wittmann, H. F.},
	year = {2025},
	note = {Publisher: Springer
Type: HTML},
	annote = {6 cites: https://scholar.google.com/scholar?cites=10975962689024303582\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhao_retrieval-augmented_2024,
	title = {Retrieval-augmented generation for ai-generated content: {A} survey},
	url = {https://arxiv.org/abs/2402.19473},
	abstract = {… -based RAG is also applicable to scenarios that use LLM … iteratively by employing a static LLM for document ranking and … -to-end RAG system, enhancing the retrieval quality and factual …},
	journal = {arXiv preprint arXiv …},
	author = {Zhao, P. and Zhang, H. and Yu, Q. and Wang, Z. and Geng, Y. and Fu, F. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {529 cites: https://scholar.google.com/scholar?cites=14452718092018481370\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sardana_real-time_2025,
	title = {Real-{Time} {Evaluation} {Models} for {RAG}: {Who} {Detects} {Hallucinations} {Best}?},
	url = {https://arxiv.org/abs/2503.21157},
	abstract = {… between 0 and 1 indicating how confident we can be that the … while hallucination sometimes refers to specific types of LLM … (ie what ultimately matters to users of a real RAG system). …},
	journal = {arXiv preprint arXiv:2503.21157},
	author = {Sardana, A.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=14824683102105162817\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ge_development_2024,
	title = {Development of a liver disease–specific large language model chat interface using retrieval-augmented generation},
	url = {https://journals.lww.com/hep/fulltext/2024/11000/development_of_a_liver_disease_specific_large.20.aspx},
	abstract = {… the LLM by layering it on top of the LLM information retrieval and output processes. The theoretical advantages of RAG … ” for the LLM, and (2) Decreasing hallucinations by limiting the …},
	journal = {Hepatology},
	author = {Ge, J. and Sun, S. and Owens, J. and Galvez, V. and Gologorskaya, O. and {...}},
	year = {2024},
	note = {Publisher: journals.lww.com},
	annote = {141 cites: https://scholar.google.com/scholar?cites=16259437680016769457\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{miao_integrating_2024,
	title = {Integrating retrieval-augmented generation with large language models in nephrology: advancing practical applications},
	url = {https://www.mdpi.com/1648-9144/60/3/445},
	abstract = {… factual data, the RAG approach effectively reduces the occurrence of inaccuracy or hallucinations… To illustrate the process of creating a customized ChatGPT model with a RAG …},
	journal = {Medicina},
	author = {Miao, J. and Thongprayoon, C. and Suppadungsuk, S. and {...}},
	year = {2024},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {135 cites: https://scholar.google.com/scholar?cites=11571656069933439938\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ke_development_2024,
	title = {Development and testing of retrieval augmented generation in large language models–a case study report},
	url = {https://arxiv.org/abs/2402.01733},
	abstract = {… LLM-RAG pipeline, tailored specifically for preoperative medicine. The primary objective is to evaluate the accuracy of the LLM-RAG … Both models have similar hallucination rates of 1.2\%…},
	journal = {arXiv preprint arXiv …},
	author = {Ke, Y. H. and Jin, L. and Elangovan, K. and Abdullah, H. R. and Liu, N. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {69 cites: https://scholar.google.com/scholar?cites=1370628942759145071\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{da_evidencechat_2024,
	title = {Evidencechat: {A} rag enhanced llm framework for trustworthy and evidential response generation},
	url = {https://www.researchgate.net/profile/Parth-Shah-142/publication/385173895_EvidenceChat_A_RAG_Enhanced_LLM_Framework_for_Trustworthy_and_Evidential_Response_Generation/links/671983dadf4b534d4eeddf46/EvidenceChat-A-RAG-Enhanced-LLM-Framework-for-Trustworthy-and-Evidential-Response-Generation.pdf},
	abstract = {… upon the retrieval augmented generation agent (RAG agent), … the process of constructing the RAG agent, and then explain … Towards mitigating LLM hallucination via self reflection. In …},
	journal = {… A RAG Enhanced LLM …},
	author = {Da, L. and Shah, P. M. and Singh, A. and Wei, H.},
	year = {2024},
	note = {Publisher: researchgate.net
Type: PDF},
	annote = {3 cites: https://scholar.google.com/scholar?cites=14764703580072583073\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_unims-rag_2024,
	title = {Unims-rag: {A} unified multi-source retrieval-augmented generation for personalized dialogue systems},
	url = {https://arxiv.org/abs/2401.13256},
	abstract = {… as hallucinations [36], factuality [37] … -RAG w/ GPT4o is much better than UniMS-RAG w/ ChatGPT due to more accurate similarity labels provided by GPT4o, we believe that UniMS-RAG …},
	journal = {arXiv preprint arXiv …},
	author = {Wang, H. and Huang, W. and Deng, Y. and Wang, R. and Wang, Z. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {47 cites: https://scholar.google.com/scholar?cites=7590569489078912193\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ke_retrieval_2025,
	title = {Retrieval augmented generation for 10 large language models and its generalizability in assessing medical fitness},
	url = {https://www.nature.com/articles/s41746-025-01519-z},
	abstract = {… Additionally, the model exhibited an absence of hallucinations and … LLM-RAG models into healthcare workflows, such as preoperative medicine. Our findings indicate that the LLM-RAG …},
	journal = {npj Digital …},
	author = {Ke, Y. H. and Jin, L. and Elangovan, K. and Abdullah, H. R. and Liu, N. and {...}},
	year = {2025},
	note = {Publisher: nature.com
Type: HTML},
	annote = {35 cites: https://scholar.google.com/scholar?cites=2975196663660171404\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sok_metarag_2025,
	title = {{MetaRAG}: {Metamorphic} {Testing} for {Hallucination} {Detection} in {RAG} {Systems}},
	url = {https://arxiv.org/abs/2509.09360},
	abstract = {… We obtain F using an LLM-based extractor with a fixed prompt that enforces one proposition per line, prohibits paraphrasing or inference beyond A, and co-reference resolution. The full …},
	journal = {arXiv preprint arXiv:2509.09360},
	author = {Sok, C. and Luz, D. and Haddam, Y.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{fink_retrieval-augmented_2025-1,
	title = {Retrieval-{Augmented} {Generation} with {Large} {Language} {Models} in {Radiology}: {From} {Theory} to {Practice}},
	url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.240790},
	doi = {10.1148/ryai.240790},
	abstract = {… hallucinations and opacity in sources for LLM responses. Retrievalaugmented Generation (RAG… overview of RAG applications that enable knowledge-based LLM responses in radiology…},
	journal = {Radiology: Artificial …},
	author = {Fink, A. and Rau, A. and Reisert, M. and Bamberg, F. and {...}},
	year = {2025},
	note = {Publisher: pubs.rsna.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=15666770555386251011\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hou_improving_2025,
	title = {Improving dietary supplement information retrieval: {Development} of a retrieval-augmented generation system with large language models},
	url = {https://www.jmir.org/2025/1/e67677/},
	abstract = {… An RAG system operates in two phases: first, it retrieves relevant data from a … LLM to generate responses [20,21]. By integrating iDISK with an RAG system, we mitigate the hallucination …},
	journal = {Journal of medical Internet research},
	author = {Hou, Y. and Bishop, J. R. and Liu, H. and Zhang, R.},
	year = {2025},
	note = {Publisher: jmir.org
Type: HTML},
	annote = {6 cites: https://scholar.google.com/scholar?cites=14974919809604922188\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gan_retrieval_2025,
	title = {Retrieval {Augmented} {Generation} {Evaluation} in the {Era} of {Large} {Language} {Models}: {A} {Comprehensive} {Survey}},
	url = {https://arxiv.org/abs/2504.14891},
	abstract = {… for RAG evaluation, bridging traditional and LLM-driven methods, and serves as a critical resource for advancing RAG … method to measure the hallucination in RAG, which indicates the …},
	journal = {arXiv preprint arXiv …},
	author = {Gan, A. and Yu, H. and Zhang, K. and Liu, Q. and Yan, W. and Huang, Z. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {12 cites: https://scholar.google.com/scholar?cites=18415684155385766912\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gargari_enhancing_2025,
	title = {Enhancing medical {AI} with retrieval-augmented generation: {A} mini narrative review},
	url = {https://journals.sagepub.com/doi/abs/10.1177/20552076251337177},
	doi = {10.1177/20552076251337177},
	abstract = {… The study evaluated Almanac against ChatGPT using a … Almanac significantly outperformed ChatGPT in factuality, with an … clinical calculation scenarios, whereas ChatGPT failed all. In …},
	journal = {Digital health},
	author = {Gargari, O. K. and Habibi, G.},
	year = {2025},
	note = {Publisher: journals.sagepub.com},
	annote = {20 cites: https://scholar.google.com/scholar?cites=4484457635521238923\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wu_medical_2025,
	title = {Medical graph rag: {Evidence}-based medical large language model via graph retrieval-augmented generation},
	url = {https://aclanthology.org/2025.acl-long.1381/},
	abstract = {… RAG data to credible medical papers and foundational medical dictionaries. This process generates triples [RAG … It enhances LLM reasoning and ensures responses are traceable to …},
	journal = {Proceedings of the …},
	author = {Wu, J. and Zhu, J. and Qi, Y. and Chen, J. and Xu, M. and {...}},
	year = {2025},
	note = {Publisher: aclanthology.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=121888457436838556\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hu_rag_2024,
	title = {Rag and rau: {A} survey on retrieval-augmented language model in natural language processing},
	url = {https://arxiv.org/abs/2404.19543},
	abstract = {… (NLP), yet they encounter challenges such as hallucination and the need for domain-specific … In Sections 6 and 7, we presented some evaluation criteria for large language model tasks …},
	journal = {arXiv preprint arXiv:2404.19543},
	author = {Hu, Y. and Lu, Y.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {70 cites: https://scholar.google.com/scholar?cites=4971034713770142627\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{shi_ask-eda_2024,
	title = {Ask-eda: {A} design assistant empowered by llm, hybrid rag and abbreviation de-hallucination},
	url = {https://ieeexplore.ieee.org/abstract/document/10691824/},
	abstract = {… exhibits noticeable enhancements over both sparse-only and dense-only RAG. One of our … models to enhance RAG even further. We will also explore improving the LLM model further …},
	journal = {2024 IEEE LLM Aided …},
	author = {Shi, L. and Kazda, M. and Sears, B. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {30 cites: https://scholar.google.com/scholar?cites=6995404391618070672\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lala_paperqa_2023,
	title = {Paperqa: {Retrieval}-augmented generative agent for scientific research},
	url = {https://arxiv.org/abs/2312.07559},
	abstract = {… Nevertheless, standard RAG models follow a fixed, linear flow, … breaking RAG into modular pieces, allowing an agent LLM to … We assessed citation hallucinations from GPT-3.5, GPT4, …},
	journal = {arXiv preprint arXiv …},
	author = {Lála, J. and O'Donoghue, O. and Shtedritski, A. and Cox, S. and {...}},
	year = {2023},
	note = {Publisher: arxiv.org},
	annote = {156 cites: https://scholar.google.com/scholar?cites=15569385356224447096\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{das_two-layer_2025,
	title = {Two-layer retrieval-augmented generation framework for low-resource medical question answering using reddit data: proof-of-concept study},
	url = {https://www.jmir.org/2025/1/e66220/},
	abstract = {… the performance of a quantized large language model (Nous-… of relevance, length, hallucination, coverage, and coherence … issue with LLM-generated text for MQA is “hallucination”: …},
	journal = {Journal of Medical …},
	author = {Das, S. and Ge, Y. and Guo, Y. and Rajwal, S. and Hairston, J. M. and {...}},
	year = {2025},
	note = {Publisher: jmir.org
Type: HTML},
	annote = {15 cites: https://scholar.google.com/scholar?cites=8099964520725314212\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{agrawal_mindful-rag_2024,
	title = {Mindful-rag: {A} study of points of failure in retrieval augmented generation},
	url = {https://ieeexplore.ieee.org/abstract/document/10852457/},
	abstract = {… of ChatGPT without RAG on both datasets. The results, presented in Figure 1, show that Mindful-RAG, … Zhang, “Enhancing llm factual accuracy with rag to counter hallucinations: A case …},
	journal = {2024 2nd International …},
	author = {Agrawal, G. and Kumarage, T. and Alghamdi, Z. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {29 cites: https://scholar.google.com/scholar?cites=3814628639974309083\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hou_enhancing_2024,
	title = {Enhancing dietary supplement question answer via retrieval-augmented generation ({RAG}) with {LLM}},
	url = {https://www.medrxiv.org/content/10.1101/2024.09.11.24313513.abstract},
	doi = {10.1101/2024.09.11.24313513.abstract},
	abstract = {… data from multiple trusted sources, … with a RAG system, leveraging the strengths of large language models (LLMs) and a biomedical knowledge graph (BKG) to address the hallucination …},
	journal = {medRxiv},
	author = {Hou, Y. and Zhang, R.},
	year = {2024},
	note = {Publisher: medrxiv.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=408998763717071736\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kuo_automated_2025,
	title = {Automated {Clinical} {Trial} {Data} {Analysis} and {Report} {Generation} by {Integrating} {Retrieval}-{Augmented} {Generation} ({RAG}) and {Large} {Language} {Model} ({LLM}) …},
	url = {https://www.mdpi.com/2673-2688/6/8/188},
	abstract = {… We propose and implement a multimodal Retrieval-Augmented Generation (RAG)–LLM … retrieval—namely Retrieval-Augmented Generation (RAG)—to bolster factual consistency. …},
	journal = {AI},
	author = {Kuo, S. M. and Tai, S. K. and Lin, H. Y. and Chen, R. C.},
	year = {2025},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{abolghasemi_evaluation_2025,
	title = {Evaluation of attribution bias in generator-aware retrieval-augmented large language models},
	url = {https://aclanthology.org/2025.findings-acl.1087/},
	abstract = {… in RAG pipelines, namely attribution sensitivity and bias with respect to authorship information. We explicitly inform an LLM … number of relevant citations and total citations for the three …},
	journal = {Findings of the …},
	author = {Abolghasemi, A. and Azzopardi, L. and Hashemi, S. H. and {...}},
	year = {2025},
	note = {Publisher: aclanthology.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=12780831646524910648\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tozuka_application_2025,
	title = {Application of {NotebookLM}, a large language model with retrieval-augmented generation, for lung cancer staging},
	url = {https://link.springer.com/article/10.1007/s11604-024-01705-1},
	doi = {10.1007/s11604-024-01705-1},
	abstract = {… evaluate the reliability of NotebookLM’s responses and detect possible hallucinations. Overall, this study highlights the potential of NotebookLM, a RAG-LLM, in image diagnosis. …},
	journal = {Japanese Journal of …},
	author = {Tozuka, R. and Johno, H. and Amakawa, A. and Sato, J. and Muto, M. and {...}},
	year = {2025},
	note = {Publisher: Springer},
	annote = {32 cites: https://scholar.google.com/scholar?cites=6447498726620384406\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bechard_reducing_2024,
	title = {Reducing hallucination in structured outputs via {Retrieval}-{Augmented} {Generation}},
	url = {https://arxiv.org/abs/2404.08189},
	abstract = {… • We provide an application of RAG in workflow generation, a structured … RAG reduces hallucination and improves results. • We demonstrate that RAG allows deploying a smaller LLM …},
	journal = {arXiv preprint arXiv:2404.08189},
	author = {Béchard, P. and Ayala, O. M.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {153 cites: https://scholar.google.com/scholar?cites=12167490990174553790\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_astute_2024,
	title = {Astute rag: {Overcoming} imperfect retrieval augmentation and knowledge conflicts for large language models},
	url = {https://arxiv.org/abs/2410.07176},
	abstract = {… Second, we propose Astute RAG, which explicitly addresses conflicts between LLM-internal … accurate, relevant, and hallucinationfree. Moreover, we allow the LLM to perform adaptive …},
	journal = {arXiv preprint arXiv:2410.07176},
	author = {Wang, F. and Wan, X. and Sun, R. and Chen, J. and Arık, SÖ},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {62 cites: https://scholar.google.com/scholar?cites=4854243888531503174\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zou_poisonedrag_2025,
	title = {\{{PoisonedRAG}\}: {Knowledge} corruption attacks to \{{Retrieval}-{Augmented}\} generation of large language models},
	url = {https://www.usenix.org/conference/usenixsecurity25/presentation/zou-poisonedrag},
	abstract = {… database of a RAG system to induce an LLM to generate an … RAG enables an LLM to utilize external knowledge in a plug-and-play manner. Moreover, RAG can reduce hallucinations …},
	journal = {34th USENIX Security Symposium …},
	author = {Zou, W. and Geng, R. and Wang, B. and Jia, J.},
	year = {2025},
	note = {Publisher: usenix.org},
	annote = {236 cites: https://scholar.google.com/scholar?cites=16563456328112289907\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{patel_llm-based_2025,
	title = {{LLM}-{Based} {Automated} {Hallucination} {Detection} in {Multilingual} {Customer} {Service} {RAG} {Applications}},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-96235-6_26},
	doi = {10.1007/978-3-031-96235-6_26},
	abstract = {… domain, we explore LLM-based automatic hallucination detection methods—using an … to LLM hallucinations in enterprise settings and examine the effectiveness of existing hallucination …},
	journal = {IFIP International Conference on Artificial …},
	author = {Patel, N. and Mouratidis, H. and Zhi, K. N. K.},
	year = {2025},
	note = {Publisher: Springer},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kuppa_manipulating_2024,
	title = {Manipulating {Prompts} and {Retrieval}-{Augmented} {Generation} for {LLM} {Service} {Providers}},
	url = {https://www.scitepress.org/Papers/2024/128031/128031.pdf},
	abstract = {… We demonstrate empirically that is it possible to increase the citation score of LLM output to include erroneous or unnecessary sources of information to redirect a reader to a desired …},
	journal = {Proceedings of the 21st …},
	author = {Kuppa, A. and Nicholls, J. and Le-Khac, N. A.},
	year = {2024},
	note = {Publisher: scitepress.org
Type: PDF},
	annote = {2 cites: https://scholar.google.com/scholar?cites=1780189459174361996\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{pasquarelli__2024,
	title = {… {Utility}, {Preference}, and {Performance} of {Course} {Material} {Search} {Functionality} and {Retrieval}-{Augmented} {Generation} {Large} {Language} {Model} ({RAG}-{LLM}) {AI} {Chatbots} in …},
	url = {https://arxiv.org/abs/2410.13326},
	abstract = {… With RAG, search results can be traced back to the original source, providing the user with … the source of the LLM answers – RAG has also been found to reduce hallucination [18]1. …},
	journal = {arXiv preprint arXiv:2410.13326},
	author = {Pasquarelli, L. and Koutcheme, C. and Hellas, A.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=15412495475082270097\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{su_evaluation_2025,
	title = {Evaluation of retrieval-augmented generation and large language models in clinical guidelines for degenerative spine conditions},
	url = {https://link.springer.com/article/10.1007/s00586-025-08994-8},
	doi = {10.1007/s00586-025-08994-8},
	abstract = {… traditional LLM. Thus, this article aims to evaluate the concordance of ChatGPT-4o (a traditional LLM) and NotebookLM (a RAG-… of AI hallucinations, wherein LLMs such as ChatGPT-4o “…},
	journal = {European Spine …},
	author = {Su, A. Y. and Knebel, A. and Xu, A. Y. and Kaper, M. and Schmitt, P. and {...}},
	year = {2025},
	note = {Publisher: Springer},
	annote = {1 cites: https://scholar.google.com/scholar?cites=5917330240609528869\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xu_face4rag_2024,
	title = {Face4rag: {Factual} consistency evaluation for retrieval augmented generation in chinese},
	url = {https://dl.acm.org/doi/abs/10.1145/3637528.3671656},
	doi = {10.1145/3637528.3671656},
	abstract = {… RAG independent of the underlying LLM. Our benchmark consists of a synthetic dataset built upon a carefully designed typology for factuality … methods for factual inconsistency detection …},
	journal = {Proceedings of the 30th ACM SIGKDD …},
	author = {Xu, Y. and Cai, T. and Jiang, J. and Song, X.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=11680225129284728762\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yu_rag-kg-il_2025,
	title = {Rag-kg-il: {A} multi-agent hybrid framework for reducing hallucinations and enhancing llm reasoning through rag and incremental knowledge graph learning integration},
	url = {https://arxiv.org/abs/2503.13514},
	abstract = {… than RAG-only but generates significantly more hallucinations when measured against our provided ground truth. To summarise, RAG-KG-IL … In contrast, RAG-only shows the highest …},
	journal = {arXiv preprint arXiv:2503.13514},
	author = {Yu, H. Q. and McQuade, F.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=15728861733854673500\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sree_retrieval-augmented_2024,
	title = {Retrieval-augmented generation based large language model chatbot for improving diagnosis for physical and mental health},
	url = {https://ieeexplore.ieee.org/abstract/document/10815693/},
	abstract = {… be ingested in order for a Large Language Model (LLM) to be trained … By fine tuning an LLM we can engineer a specialized … This database - comprises more than 35 million citations for …},
	journal = {2024 6th International …},
	author = {Sree, Y. B. and Sathvik, A. and Akshit, D. S. H. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {11 cites: https://scholar.google.com/scholar?cites=15395755116339511416\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xue_badrag_2024,
	title = {Badrag: {Identifying} vulnerabilities in retrieval augmented generation of large language models},
	url = {https://arxiv.org/abs/2406.00083},
	abstract = {… LLM’s output by injecting real, biased articles into the RAG corpus. This method causes the … the LLM’s alignment because the selected passages are factual and likely included in the …},
	journal = {arXiv preprint arXiv …},
	author = {Xue, J. and Zheng, M. and Hu, Y. and Liu, F. and Chen, X. and Lou, Q.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {89 cites: https://scholar.google.com/scholar?cites=13163521361540245224\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhu_enhancing_2025,
	title = {Enhancing {Critical} {Thinking} with {AI}: {A} {Tailored} {Warning} {System} for {RAG} {Models}},
	url = {https://arxiv.org/abs/2504.16883},
	abstract = {… Retrieval-Augmented Generation (RAG) systems offer a powerful approach to enhancing large language model (LLM… influence reasoning and trust in RAG-based educational settings, …},
	journal = {arXiv preprint arXiv:2504.16883},
	author = {Zhu, X. and Chang, S. and Kuik, A.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{soong_improving_2024,
	title = {Improving accuracy of {GPT}-3/4 results on biomedical data using a retrieval-augmented language model},
	url = {https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000568},
	abstract = {… Here we presented application of a retrieval-augmented generation (RAG) LLM, which … to minimize inclusion of non-factual information from the LLM. This generated k answers which …},
	journal = {PLOS digital …},
	author = {Soong, D. and Sridhar, S. and Si, H. and Wagner, J. S. and Sá, A. C. C. and {...}},
	year = {2024},
	note = {Publisher: journals.plos.org
Type: HTML},
	annote = {46 cites: https://scholar.google.com/scholar?cites=16758036455185800555\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hindi_enhancing_2025,
	title = {Enhancing the precision and interpretability of retrieval-augmented generation (rag) in legal technology: {A} survey},
	url = {https://ieeexplore.ieee.org/abstract/document/10921633/},
	abstract = {… stages of the RAG process. However, robust RAG can enhance LLM generation with faithfulness and few hallucinations in responses. In this paper, we discuss the application of …},
	journal = {IEEE Access},
	author = {Hindi, M. and Mohammed, L. and Maaz, O. and Alwarafy, A.},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {13 cites: https://scholar.google.com/scholar?cites=6364774471650182582\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{weinert_enhancing_2025,
	title = {Enhancing large language models with retrieval-augmented generation: a radiology-specific approach},
	url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.240313},
	doi = {10.1148/ryai.240313},
	abstract = {… LLM with an updated corpus of knowledge that can be used for answer generation in real-time. RAG may improve LLM … questions with RadioGraphics citations, RAG-Systems achieved …},
	journal = {Radiology: Artificial Intelligence},
	author = {Weinert, D. A. and Rauschecker, A. M.},
	year = {2025},
	note = {Publisher: pubs.rsna.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=9546091227505351711\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{he_retrieving_2024,
	title = {Retrieving, rethinking and revising: {The} chain-of-verification can improve retrieval augmented generation},
	url = {https://arxiv.org/abs/2410.05801},
	abstract = {… introduce a novel mechanism for enhancing the factuality and consistency in RAG. … RAG Augmentation: To enhance the diversity and robustness of the training data, we utilize ChatGPT …},
	journal = {arXiv preprint arXiv …},
	author = {He, B. and Chen, N. and He, X. and Yan, L. and Wei, Z. and Luo, J. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {21 cites: https://scholar.google.com/scholar?cites=6552967342582064492\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xiao_retrieval-augmented_2025,
	title = {Retrieval-{Augmented} {Generation} by {Evidence} {Retroactivity} in {LLMs}},
	url = {https://arxiv.org/abs/2501.05475},
	abstract = {… credible evidence, our work builds an effective RAG framework to address the hallucination … Settings We choose GLM4-9B-chat(THUDM 2024) LLM as the base LLM for all baseline and …},
	journal = {arXiv preprint arXiv …},
	author = {Xiao, L. and Dai, W. and Chen, S. and Qin, B. and Shi, C. and Jing, H. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=5767657638372003230\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{brehme_can_2025,
	title = {Can {LLMs} {Be} {Trusted} for {Evaluating} {RAG} {Systems}? {A} {Survey} of {Methods} and {Datasets}},
	url = {https://arxiv.org/abs/2504.20119},
	abstract = {… We observe the feasibility of an automated evaluation approach for each component of a RAG system, leveraging an LLM capable of both generating evaluation datasets and …},
	journal = {arXiv preprint arXiv:2504.20119},
	author = {Brehme, L. and Ströhle, T. and Breu, R.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=11077515718575372675\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_rac_2024,
	title = {Rac: {Efficient} llm factuality correction with retrieval augmentation},
	url = {https://arxiv.org/abs/2410.15667},
	abstract = {… We report numbers with retrieval augmented generation (RAG) and without RAG. * indicates we reproduced a previous approach using the same retrieved documents and LLM as our …},
	journal = {arXiv preprint arXiv:2410.15667},
	author = {Li, C. and Flanigan, J.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=7891137671251351270\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wiratunga_cbr-rag_2024,
	title = {{CBR}-{RAG}: case-based reasoning for retrieval augmented generation in {LLMs} for legal question answering},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-63646-2_29},
	doi = {10.1007/978-3-031-63646-2_29},
	abstract = {… Retrieval-Augmented Generation (RAG) systems address this by presenting the LLM with factual … In this paper we have presented CBR-RAG, improving LLM output by augmenting input …},
	journal = {… Conference on Case …},
	author = {Wiratunga, N. and Abeyratne, R. and Jayawardena, L. and {...}},
	year = {2024},
	note = {Publisher: Springer},
	annote = {138 cites: https://scholar.google.com/scholar?cites=557687046801966440\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_enhanced_2024,
	title = {Enhanced large language models-based legal query responses through retrieval augmented generation},
	url = {https://books.google.com/books?hl=en\&lr=\&id=RpUjEQAAQBAJ\&oi=fnd\&pg=PA237\&dq=%22retrieval+augmented+generation%22%7C%22rag%22+%22large+language+model%22%7C%22llm%22%7C%22chatgpt%22+trust%7Cconfidence%7Ccredibility%7Challucination%7Cfactuality%7Ccitation\&ots=z7ads6N7Yw\&sig=ZddnJKk6QmuOAhvZUZpk_a_ZO4w},
	abstract = {… LLM solving law problems using RAG is proposed. RAG is used to overcome hallucination … evaluation, which indicates that the LLM’s hallucination problem is basically solved, and …},
	journal = {Proceedings of the 2024 International Conference on …},
	author = {Li, R.},
	year = {2024},
	note = {Publisher: books.google.com},
	annote = {3 cites: https://scholar.google.com/scholar?cites=2938345802139144495\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{nezafat_fake_2024,
	title = {Fake {News} {Detection} {With} {Retrieval} {Augmented} {Generative} {Artificial} {Intelligence}},
	url = {https://ieeexplore.ieee.org/abstract/document/10852474/},
	abstract = {… This experiment integrated the RAG framework with our LLM, … The RAG framework enhanced the LLM’s performance by … LLM factual accuracy with RAG to counter hallucinations: a case …},
	journal = {2024 2nd International Conference on …},
	author = {Nezafat, M. V. and Samet, S.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=5788952820010130780\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_survey_2025,
	title = {Survey on factuality in large language models},
	url = {https://dl.acm.org/doi/abs/10.1145/3742420},
	doi = {10.1145/3742420},
	abstract = {… We further explore strategies for enhancing LLM factuality. Our survey ofers a structured … generation, retrieval-augmented generation, inference-phase enhancements, as illustrated in …},
	journal = {ACM Computing …},
	author = {Wang, C. and Liu, X. and Yue, Y. and Guo, Q. and Hu, X. and Tang, X. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=9102924204263859925\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{efeoglu_retrieval-augmented_2024,
	title = {Retrieval-augmented generation-based relation extraction},
	url = {https://arxiv.org/abs/2404.13397},
	abstract = {… hallucination issues on these datasets, our RAG-… RAG-based LLM prompting approach. We also claim that RAG4RE has outperformed the performance of the simple query (Vanilla LLM …},
	journal = {arXiv preprint arXiv:2404.13397},
	author = {Efeoglu, S. and Paschke, A.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {22 cites: https://scholar.google.com/scholar?cites=13273343852070193311\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{welsh_custom-tailored_2025,
	title = {Custom-{Tailored} {Radiology} {Research} via {Retrieval}-{Augmented} {Generation}: {A} {Secure} {Institutionally} {Deployed} {Large} {Language} {Model} {System}},
	url = {https://www.mdpi.com/2411-5134/10/4/55},
	abstract = {… Our RAG system leverages a database of 167,028 radiology-related abstracts sourced from … RAG LLM and GPT-4-Consensus models were evaluated for factual accuracy (FA), citation …},
	journal = {Inventions},
	author = {Welsh, M. and Lopez-Rippe, J. and Alkhulaifat, D. and Khalkhali, V. and {...}},
	year = {2025},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jiang_rag-thief_2024,
	title = {Rag-thief: {Scalable} extraction of private data from retrieval-augmented generation applications with agent-based attacks},
	url = {https://arxiv.org/abs/2411.14110},
	abstract = {… RAG mitigates the issue of hallucinations in LLMs by incorporating realtime, domain-specific … In this experiment, we fix the LLM component of the RAG application as GLM-4-Plus, the …},
	journal = {arXiv preprint arXiv:2411.14110},
	author = {Jiang, C. and Pan, X. and Hong, G. and Bao, C. and Yang, M.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {37 cites: https://scholar.google.com/scholar?cites=1730405491972959855\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tamber_benchmarking_2025,
	title = {Benchmarking {LLM} {Faithfulness} in {RAG} with {Evolving} {Leaderboards}},
	url = {https://arxiv.org/abs/2505.04847},
	abstract = {… This paper presents our efforts to measure LLM hallucinations with a focus on … introduce hallucinations when summarizing documents. We discuss Vectara’s existing LLM hallucination …},
	journal = {arXiv preprint arXiv …},
	author = {Tamber, M. S. and Bao, F. S. and Xu, C. and Luo, G. and Kazi, S. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=1429636647992418092\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{procko_graph_2024,
	title = {Graph retrieval-augmented generation for large language models: {A} survey},
	url = {https://ieeexplore.ieee.org/abstract/document/10771030/},
	abstract = {… This paper surveys work incorporating KGs with LLM RAG, intending to equip scientists with a … to tasks from several domains and lessens LLM hallucination. Edge et al. present a Graph …},
	journal = {2024 Conference on AI, Science …},
	author = {Procko, T. T. and Ochoa, O.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {66 cites: https://scholar.google.com/scholar?cites=5850893199326798441\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{swacha_retrieval-augmented_2025,
	title = {Retrieval-{Augmented} {Generation} ({RAG}) {Chatbots} for {Education}: {A} {Survey} of {Applications}},
	url = {https://www.mdpi.com/2076-3417/15/8/4234},
	abstract = {… Retrieval-Augmented Generation (RAG) overcomes the main barrier for the adoption of LLM-based chatbots in education: hallucinations. The uncomplicated architecture of RAG …},
	journal = {Applied Sciences},
	author = {Swacha, J. and Gracel, M.},
	year = {2025},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {29 cites: https://scholar.google.com/scholar?cites=13213720980063319786\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{feldman_ragged_2024,
	title = {Ragged edges: {The} double-edged sword of retrieval-augmented chatbots},
	url = {https://arxiv.org/abs/2403.01193},
	abstract = {… nature of hallucinations and the need for more robust solutions to ensure LLM reliability in real-world applications. We offer practical recommendations for RAG deployment and discuss …},
	journal = {arXiv preprint arXiv:2403.01193},
	author = {Feldman, P. and Foulds, J. R. and Pan, S.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {27 cites: https://scholar.google.com/scholar?cites=15656017162029845851\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{muludi_retrieval-augmented_2024,
	title = {Retrieval-{Augmented} {Generation} {Approach}: {Document} {Question} {Answering} using {Large} {Language} {Model}.},
	url = {https://search.ebscohost.com/login.aspx?direct=true\&profile=ehost\&scope=site\&authtype=crawler\&jrnl=2158107X\&AN=176379076\&h=mmXDdbx%2FAKKXE5HxVbZop7XacHkdE6WLAF%2BzfxKas%2BXNrm8iN7hcr%2FcAbBl17BHfwst667MJ%2FM%2FG8lWuepC86w%3D%3D\&crl=c},
	abstract = {… for QA systems without modifications tend to generate hallucinatory answers, lacking … the large language model within the ChatGPT systems, gpt3.5-turbo within the framework of RAG. …},
	journal = {International Journal of …},
	author = {Muludi, K. and Fitria, K. M. and Triloka, J.},
	year = {2024},
	note = {Publisher: search.ebscohost.com},
	annote = {32 cites: https://scholar.google.com/scholar?cites=5481954434851242529\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zeng_worse_2025,
	title = {Worse than zero-shot? a fact-checking dataset for evaluating the robustness of rag against misleading retrievals},
	url = {https://arxiv.org/abs/2502.16101},
	abstract = {… Retrieval-augmented generation (RAG) systems have shown significant promise in mitigating LLM hallucination and enhancing trustworthiness. By combining the generative …},
	journal = {arXiv preprint arXiv …},
	author = {Zeng, L. and Gupta, R. and Motwani, D. and Yang, D. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=17816750890838725293\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhou_ihillm-rag_2025,
	title = {{IHILLM}-{RAG}: a safe and private medical large language model based on intelligent hardware interaction and retrieval-augmented generation ({RAG})},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13542/135423W/IHILLM-RAG--a-safe-and-private-medical-large-language/10.1117/12.3056789.short},
	doi = {10.1117/12.3056789.short},
	abstract = {… phenomenon of hallucination. … LLM, so as to enhance the LLM’s learning and memory of the user’s own habits and improve the degree of personalization. We evaluated IHILLM-RAG on …},
	journal = {Fourth International Computational …},
	author = {Zhou, Z. and Yang, Y. and Ren, T.},
	year = {2025},
	note = {Publisher: spiedigitallibrary.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=16936190826389426864\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gummadi_enhancing_2024,
	title = {Enhancing communication and data transmission security in rag using large language models},
	url = {https://ieeexplore.ieee.org/abstract/document/10763024/},
	abstract = {… RAG with LLM produces more accurate results and essential user information. This can gain more trust … This paper proposes a large language model (LLM) to secure data in RAG …},
	journal = {2024 4th …},
	author = {Gummadi, V. and Udayaraju, P. and Sarabu, V. R. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=16445523871347128368\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{friel_ragbench_2024,
	title = {Ragbench: {Explainable} benchmark for retrieval-augmented generation systems},
	url = {https://arxiv.org/abs/2407.11005},
	abstract = {… Thorough extensive benchmarking, we find that LLM-based RAG evaluation methods strug… outperforms LLM judges in hallucination/attribution detection but also excels on the new RAG …},
	journal = {arXiv preprint arXiv:2407.11005},
	author = {Friel, R. and Belyi, M. and Sanyal, A.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {51 cites: https://scholar.google.com/scholar?cites=16448585229500498104\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tang_multihop-rag_2024,
	title = {Multihop-rag: {Benchmarking} retrieval-augmented generation for multi-hop queries},
	url = {https://arxiv.org/abs/2401.15391},
	abstract = {… LLM) by retrieving relevant knowledge, showing promising potential in mitigating LLM hallucinations … However, we find that existing RAG systems are inadequate in answering multi-hop …},
	journal = {arXiv preprint arXiv:2401.15391},
	author = {Tang, Y. and Yang, Y.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {176 cites: https://scholar.google.com/scholar?cites=17413151929125040209\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_honest_2024,
	title = {Honest {AI}: {Fine}-{Tuning}" {Small}" {Language} {Models} to {Say}" {I} {Don}'t {Know}", and {Reducing} {Hallucination} in {RAG}},
	url = {https://arxiv.org/abs/2410.09699},
	abstract = {… out that RAG alone is not enough to alleviate hallucination in … Our results show that the hybrid approach using both RAG and … Great thanks to Ermo Wei, who shared invaluable LLM fine-…},
	journal = {arXiv preprint arXiv:2410.09699},
	author = {Chen, X. and Wang, L. and Wu, W. and Tang, Q. and Liu, Y.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {18 cites: https://scholar.google.com/scholar?cites=14599712074258686983\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jang_calibrated_2024,
	title = {Calibrated decision-making through llm-assisted retrieval},
	url = {https://arxiv.org/abs/2411.08891},
	abstract = {… response z and the LLM’s confidence c. Our goal is to align the model confidence with accuracy of … an unseen LLM as the RAG model for decision-making task. We use Mistral-7B for the …},
	journal = {arXiv preprint arXiv:2411.08891},
	author = {Jang, C. and Lee, H. and Lee, S. and Lee, J.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=16553911393074911668\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ko_rerag_2024,
	title = {{ReRag}: {A} {New} {Architecture} for {Reducing} the {Hallucination} by {Retrieval}-{Augmented} {Generation}},
	url = {https://ieeexplore.ieee.org/abstract/document/10773428/},
	abstract = {… Hence, the response of the LLM system depends on these … standard LLM model with an Agent module that optimizes the hyperparameters (l, o), ensuring the response of the LLM model …},
	journal = {2024 9th International …},
	author = {Ko, R. and Gürkan, M. K. and Vural, F. T. Y.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=14837199890647366495\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_application_2025,
	title = {Application of retrieval-augmented generation for interactive industrial knowledge management via a large language model},
	url = {https://www.sciencedirect.com/science/article/pii/S0920548925000248},
	abstract = {… model with a retrieval-augmented generation (RAG)-based LLM as a sustainable solution … RAG-based generative pretrained transformer (GPT) models for customized solutions. …},
	journal = {Computer Standards \&Interfaces},
	author = {Chen, L. C. and Pardeshi, M. S. and Liao, Y. X. and Pai, K. C.},
	year = {2025},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {11 cites: https://scholar.google.com/scholar?cites=10772995890527999302\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_knowledge-enhanced_2025,
	title = {A {Knowledge}-{Enhanced} {Platform} ({MetaSepsisKnowHub}) for {Retrieval} {Augmented} {Generation}–{Based} {Sepsis} {Heterogeneity} and {Personalized} {Management} …},
	url = {https://www.jmir.org/2025/1/e67201/},
	abstract = {… We curated a tailored LLM framework incorporating RAG … RAG-based LLM framework using the RAGAs evaluation tool and found that RAG integration significantly boosted the factual …},
	journal = {Journal of Medical …},
	author = {Zhang, C. and Yang, H. and Liu, X. and Wu, R. and Zong, H. and Wu, E. and {...}},
	year = {2025},
	note = {Publisher: jmir.org
Type: HTML},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chan_rq-rag_2024,
	title = {Rq-rag: {Learning} to refine queries for retrieval augmented generation},
	url = {https://arxiv.org/abs/2404.00610},
	abstract = {… prone to generating inaccurate or hallucinatory responses. This … these challenges, Retrieval-Augmented Generation (RAG) … while we train the LLM to refine queries by itself in this …},
	journal = {arXiv preprint arXiv …},
	author = {Chan, C. M. and Xu, C. and Yuan, R. and Luo, H. and Xue, W. and Guo, Y. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {157 cites: https://scholar.google.com/scholar?cites=6621501228410966682\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gupta_comprehensive_2024,
	title = {A comprehensive survey of retrieval-augmented generation (rag): {Evolution}, current landscape and future directions},
	url = {https://arxiv.org/abs/2410.12837},
	abstract = {… RAG systems utilize self-attention within the LLM to manage … the generation of coherent, factual outputs from incomplete or … a RAG system, BART has been shown to improve the factual …},
	journal = {arXiv preprint arXiv:2410.12837},
	author = {Gupta, S. and Ranjan, R. and Singh, S. N.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {132 cites: https://scholar.google.com/scholar?cites=4934459544633669508\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zimmerman_two-tiered_2024,
	title = {Two-tiered encoder-based hallucination detection for retrieval-augmented generation in the wild},
	url = {https://aclanthology.org/2024.emnlp-industry.2/},
	abstract = {… -tuned LLM … RAG, the model was given the input prompt including the user’s question, retrieved KBs, and a sentence from the LLM Response (the statement being classified for factual …},
	journal = {Proceedings of the 2024 …},
	author = {Zimmerman, I. and Tredup, J. and Selfridge, E. and {...}},
	year = {2024},
	note = {Publisher: aclanthology.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=6224580655699719845\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{barnett_seven_2024,
	title = {Seven failure points when engineering a retrieval augmented generation system},
	url = {https://dl.acm.org/doi/abs/10.1145/3644815.3644945},
	doi = {10.1145/3644815.3644945},
	abstract = {… using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from … serving a fine-tuned LLM; or b) use Retrieval-Augmented Generation (RAG) Systems that rely …},
	journal = {Proceedings of the …},
	author = {Barnett, S. and Kurniawan, S. and Thudumu, S. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {167 cites: https://scholar.google.com/scholar?cites=7363169033457600032\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{arasteh_radiorag_2024,
	title = {{RadioRAG}: {Online} {Retrieval}-augmented {Generation} for {Radiology} {Question} {Answering}},
	url = {https://www.researchgate.net/profile/Soroosh-Tayebi-Arasteh/publication/382459583_RadioRAG_Factual_large_language_models_for_enhanced_diagnostics_in_radiology_using_online_retrieval_augmented_generation/links/6782ac0f32c79152e3cd3b68/RadioRAG-Factual-large-language-models-for-enhanced-diagnostics-in-radiology-using-online-retrieval-augmented-generation.pdf},
	abstract = {… Secondly, LLMs can access up-to-date information through RAG, while conventional LLM … the occurrence of hallucinations and 2) RadioRAG improves the accuracy of LLM responses to …},
	journal = {arXiv preprint arXiv …},
	author = {Arasteh, S. T. and Lotfinia, M. and Bressem, K. and {...}},
	year = {2024},
	note = {Publisher: researchgate.net
Type: PDF},
	annote = {15 cites: https://scholar.google.com/scholar?cites=5665995222354075203\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{pham_towards_2024,
	title = {Towards reliable medical question answering: {Techniques} and challenges in mitigating hallucinations in language models},
	url = {https://arxiv.org/abs/2408.13808},
	abstract = {… Key methods covered in the paper include Retrieval-Augmented Generation (RAG)-based … LLM limitations in healthcare applications and provide insights into addressing hallucinations. …},
	journal = {arXiv preprint arXiv:2408.13808},
	author = {Pham, D. K. and Vo, B. Q.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {18 cites: https://scholar.google.com/scholar?cites=6385792091029148069\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yu_evaluation_2024,
	title = {Evaluation of retrieval-augmented generation: {A} survey},
	url = {https://link.springer.com/chapter/10.1007/978-981-96-1024-2_8},
	doi = {10.1007/978-981-96-1024-2_8},
	abstract = {… ReEval [66] specifically targets hallucination evaluation by employing a cost-effective LLM-based framework that utilizes prompt chaining to create dynamic test cases. …},
	journal = {CCF Conference on Big Data},
	author = {Yu, H. and Gan, A. and Zhang, K. and Tong, S. and Liu, Q. and Liu, Z.},
	year = {2024},
	note = {Publisher: Springer},
	annote = {233 cites: https://scholar.google.com/scholar?cites=3204868390346020966\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mokashi_analysis_2025,
	title = {Analysis of {Large} {Language} {Models} for {Company} {Annual} {Reports} {Based} on {Retrieval}-{Augmented} {Generation}},
	url = {https://www.mdpi.com/2078-2489/16/9/786},
	abstract = {… compare ChatGPT-4 responses before and after RAG integration, … that RAG improves the relevance and verifiability of LLM … on how RAG can mitigate biases and hallucinations inherent …},
	journal = {Information},
	author = {Mokashi, A. and Puthuparambil, B. and Daniel, C. and Hanne, T.},
	year = {2025},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{priola_addressing_2024,
	title = {Addressing hallucinations with rag and nmiss in italian healthcare llm chatbots},
	url = {https://arxiv.org/abs/2412.04235},
	abstract = {… I develop a RAG-based architecture to integrate external knowledge into the generation process, ensuring that models are grounded in factual data. The methodology leverages a …},
	journal = {arXiv preprint arXiv:2412.04235},
	author = {Priola, M. P.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=16776368590716814508\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{thakur_knowing_2024,
	title = {“{Knowing} {When} {You} {Don}'t {Know}”: {A} {Multilingual} {Relevance} {Assessment} {Dataset} for {Robust} {Retrieval}-{Augmented} {Generation}},
	url = {https://aclanthology.org/2024.findings-emnlp.730/},
	abstract = {… LLM hallucinations against first-stage retrieval errors in RAG. (… lenges in LLM robustness by often hallucinating an answer … on LLM’s generation results, and find several hallucination …},
	journal = {Findings of the …},
	author = {Thakur, N. and Bonifacio, L. and Zhang, C. and {...}},
	year = {2024},
	note = {Publisher: aclanthology.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=13273253745351185778\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kresevic_optimization_2024,
	title = {Optimization of hepatological clinical guidelines interpretation by large language models: a retrieval augmented generation-based framework},
	url = {https://www.nature.com/articles/s41746-024-01091-y},
	abstract = {… novel LLM framework integrating clinical guidelines with RAG, … significantly outperforms the baseline LLM model in producing … When inaccurate outputs were reviewed for hallucinations, …},
	journal = {NPJ digital …},
	author = {Kresevic, S. and Giuffrè, M. and Ajcevic, M. and Accardo, A. and {...}},
	year = {2024},
	note = {Publisher: nature.com
Type: HTML},
	annote = {148 cites: https://scholar.google.com/scholar?cites=12725699623582351355\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{praneeth_optimization_2025,
	title = {Optimization of {Customer} {Feedback} {Summarization} {Using} {Large} {Language} {Models} ({LLM}) and {Advanced} {Retrieval}-{Augmented} {Generation}},
	url = {https://ieeexplore.ieee.org/abstract/document/11078280/},
	abstract = {… coverage, and 9.9\% in factual consistency over traditional RAG. Further integration of DSPy … gain in factual alignment. Among the evaluated models, Gemini1.5-Pro combined with RAG …},
	journal = {IEEE …},
	author = {Praneeth, B. and Nattem, E. C. and Jetti, K. and Kavyashree, B. K. and {...}},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=9520546428622944575\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{azher_futuregen_2025,
	title = {{FutureGen}: {A} {RAG}-based {Approach} to {Generate} the {Future} {Work} of {Scientific} {Article}},
	url = {https://ieeexplore.ieee.org/abstract/document/11181539/},
	abstract = {… LLM with RAG Integration: We integrated RAG with GPT4o mini for … Overall, hallucination rates should be interpreted … is that RAG consistently reduces hallucination relative to LLM-only …},
	journal = {2025 IEEE …},
	author = {Azher, I. Al and Mokarrama, M. J. and Guo, Z. and {...}},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_black-box_2024,
	title = {Black-box opinion manipulation attacks to retrieval-augmented generation of large language models},
	url = {https://arxiv.org/abs/2407.13757},
	abstract = {… As RAG is designed to overcome the hallucination problem in LLMs and enhance their … of the RAG. Specially, the manipulator can only call the interface of the LLM in RAG instead of …},
	journal = {arXiv preprint arXiv …},
	author = {Chen, Z. and Liu, J. and Liu, H. and Cheng, Q. and Zhang, F. and Lu, W. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {17 cites: https://scholar.google.com/scholar?cites=11156862794231621917\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{abolghasemi_evaluation_2024,
	title = {Evaluation of {Attribution} {Bias} in {Retrieval}-{Augmented} {Large} {Language} {Models}},
	url = {https://ui.adsabs.harvard.edu/abs/2024arXiv241012380A/abstract},
	abstract = {… in RAG pipelines, namely attribution sensitivity and bias with respect to authorship information. We explicitly inform an LLM … documents can influence LLMs' trust, and how they attribute …},
	journal = {arXiv e …},
	author = {Abolghasemi, A. and Azzopardi, L. and Hashemi, S. Hadi and {...}},
	year = {2024},
	note = {Publisher: ui.adsabs.harvard.edu},
	annote = {7 cites: https://scholar.google.com/scholar?cites=3935972651750022941\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{pelletier_explainable_2024,
	title = {Explainable biomedical hypothesis generation via retrieval augmented generation enabled large language models},
	url = {https://arxiv.org/abs/2407.12888},
	abstract = {… Retrieval-Augmented Generation (RAG) is a system designed to minimize LLM hallucinations… reliable and trustworthy sources, RAG grounds LLM responses in evidence, enhancing …},
	journal = {arXiv preprint arXiv …},
	author = {Pelletier, A. R. and Ramirez, J. and Adam, I. and Sankar, S. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=11746516890667965834\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{dong_how_2023,
	title = {How to build an {AI} tutor that can adapt to any course and provide accurate answers using large language model and retrieval-augmented generation},
	url = {https://arxiv.org/abs/2311.17696},
	abstract = {… The system effectively utilizes LLMs and RAG techniques to create an adaptive knowledge base, delivering accurate and personalized responses to student queries. Citations are …},
	journal = {arXiv preprint arXiv:2311.17696},
	author = {Dong, C.},
	year = {2023},
	note = {Publisher: arxiv.org},
	annote = {31 cites: https://scholar.google.com/scholar?cites=16103600219848609886\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sankararaman_provenance_2024,
	title = {Provenance: {A} {Light}-weight {Fact}-checker for {Retrieval} {Augmented} {LLM} {Generation} {Output}},
	url = {https://arxiv.org/abs/2411.01022},
	abstract = {… retrievalaugmented generation (RAG). Given a context and putative output, we compute a factuality score that can be thresholded to yield a binary decision to check the results of LLM-…},
	journal = {arXiv preprint arXiv …},
	author = {Sankararaman, H. and Yasin, M. N. and Sorensen, T. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=7774390106509556605\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{anjum_halo_2025,
	title = {Halo: {Hallucination} analysis and learning optimization to empower llms with retrieval-augmented context for guided clinical decision making},
	url = {https://ieeexplore.ieee.org/abstract/document/11121104/},
	abstract = {… In LangChain, multiquery generation [8] utilizes an LLM to … integrates the LLM through an API, in our case, ChatGPT-3.5, … Retrieval augmented generation (RAG) is a novel framework …},
	journal = {2025 IEEE/ACM …},
	author = {Anjum, S. and Zhang, H. and Zhou, W. and Paek, E. J. and {...}},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=4060541514904393193\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{rani_enhance_2024,
	title = {To {Enhance} {Graph}-{Based} {Retrieval}-{Augmented} {Generation} ({RAG}) with {Robust} {Retrieval} {Techniques}},
	url = {https://ieeexplore.ieee.org/abstract/document/10871140/},
	abstract = {… Hallucinations in LLM often emerge due to unstructured and … RAG is used to fetch contextually relevant content for an LLM. The literature in RAG is more inclined towards Graph RAG…},
	journal = {2024 18th International …},
	author = {Rani, M. and Mishra, B. K. and Thakker, D. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=4353647076884646388\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{shi_retrieval_2025,
	title = {Retrieval augmented generation with collaborative filtering for personalized text generation},
	url = {https://dl.acm.org/doi/abs/10.1145/3726302.3730075},
	doi = {10.1145/3726302.3730075},
	abstract = {… RAG for LLM personalization and identified the challenges: how to introduce collaborative information and how to retrieve documents that support personalized LLM … LLM hallucinations […},
	journal = {Proceedings of the 48th …},
	author = {Shi, T. and Xu, J. and Zhang, X. and Zang, X. and Zheng, K. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {12 cites: https://scholar.google.com/scholar?cites=2762844694929663100\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{singhal_evidence-backed_2024,
	title = {Evidence-backed fact checking using {RAG} and few-shot in-context learning with {LLMs}},
	url = {https://arxiv.org/abs/2408.12060},
	abstract = {… Answer Generation: After generating the question, we provide a single document to an LLM … ments in retrieval-augmented generation (RAG) pipelines which alleviate hallucination and …},
	journal = {arXiv preprint arXiv …},
	author = {Singhal, R. and Patwa, P. and Patwa, P. and Chadha, A. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {30 cites: https://scholar.google.com/scholar?cites=17423692161634189410\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sun_redeep_2024,
	title = {Redeep: {Detecting} hallucination in retrieval-augmented generation via mechanistic interpretability},
	url = {https://arxiv.org/abs/2410.11414},
	abstract = {… , a novel method that detects hallucinations by decoupling LLM’s utilization of … RAG hallucination detection accuracy. Additionally, we introduce AARF, which mitigates hallucinations by …},
	journal = {arXiv preprint arXiv …},
	author = {Sun, Z. and Zang, X. and Zheng, K. and Song, Y. and Xu, J. and Zhang, X. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {49 cites: https://scholar.google.com/scholar?cites=482064140889272007\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_survey_2023,
	title = {Survey on factuality in large language models: {Knowledge}, retrieval and domain-specificity},
	url = {https://arxiv.org/abs/2310.07521},
	abstract = {… LLM factuality, emphasizing key metrics, benchmarks, and studies. We further explore strategies for enhancing LLM factuality… This framework primarily assesses the RAG system’s ability …},
	journal = {arXiv preprint arXiv …},
	author = {Wang, C. and Liu, X. and Yue, Y. and Tang, X. and Zhang, T. and {...}},
	year = {2023},
	note = {Publisher: arxiv.org},
	annote = {276 cites: https://scholar.google.com/scholar?cites=14854019000652979716\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yu_multi-source_2024,
	title = {Multi-source knowledge pruning for retrieval-augmented generation: {A} benchmark and empirical study},
	url = {https://arxiv.org/abs/2409.13694},
	abstract = {… on either the LLM’s internal knowledge or external knowledge. Another combines the LLM’s … the internal knowledge of LLM before retrieval tends to generate hallucinations due to the …},
	journal = {arXiv preprint arXiv …},
	author = {Yu, S. and Cheng, M. and Liu, Q. and Wang, D. and Yang, J. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=11489624159692230047\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mao_fit-rag_2025,
	title = {{FIT}-{RAG}: {Black}-box {RAG} with factual information and token reduction},
	url = {https://dl.acm.org/doi/abs/10.1145/3676957},
	doi = {10.1145/3676957},
	abstract = {… treat a LLM as a black-box (ie, freeze the parameters of the LLM) and augment it with a retrievalaugmented generation (RAG) system, namely black-box RAG. Recently, black-box …},
	journal = {ACM Transactions on …},
	author = {Mao, Y. and Dong, X. and Xu, W. and Gao, Y. and Wei, B. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {22 cites: https://scholar.google.com/scholar?cites=5373354942229789900\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cai_forag_2024,
	title = {Forag: {Factuality}-optimized retrieval augmented generation for web-enhanced long-form question answering},
	url = {https://dl.acm.org/doi/abs/10.1145/3637528.3672065},
	doi = {10.1145/3637528.3672065},
	abstract = {… LLM, each containing a single piece of factual information. After the decomposition, we evaluate each subclaim individually. Since the decomposition using LLM … evaluate the factuality …},
	journal = {Proceedings of the 30th …},
	author = {Cai, T. and Tan, Z. and Song, X. and Sun, T. and Jiang, J. and Xu, Y. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {16 cites: https://scholar.google.com/scholar?cites=12052445402216874781\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xie_weknow-rag_2024,
	title = {Weknow-rag: {An} adaptive approach for retrieval-augmented generation integrating web search and knowledge graphs},
	url = {https://arxiv.org/abs/2408.07611},
	abstract = {… level is below the threshold, we conclude that the LLM lacks sufficient confidence to answer the question and will output "I don’t know". Experiments on performance with various …},
	journal = {arXiv preprint arXiv …},
	author = {Xie, W. and Liang, X. and Liu, Y. and Ni, K. and Cheng, H. and Hu, Z.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {13 cites: https://scholar.google.com/scholar?cites=15143506346578512337\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{debellis_integrating_2024,
	title = {Integrating ontologies and large language models to implement retrieval augmented generation},
	url = {https://journals.sagepub.com/doi/abs/10.1177/15705838241296446},
	doi = {10.1177/15705838241296446},
	abstract = {… problems is retrieval augmented generation (RAG). In a RAG architecture, the LLM is utilized to … The RAG architecture prevents hallucinations by utilizing a nearest neighbor algorithm to …},
	journal = {Applied Ontology},
	author = {DeBellis, M. and Dutta, N. and Gino, J. and Balaji, A.},
	year = {2024},
	note = {Publisher: journals.sagepub.com},
	annote = {10 cites: https://scholar.google.com/scholar?cites=4181227073393677698\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sudhi_rag-ex_2024,
	title = {Rag-ex: {A} generic framework for explaining retrieval augmented generation},
	url = {https://dl.acm.org/doi/abs/10.1145/3626772.3657660},
	doi = {10.1145/3626772.3657660},
	abstract = {… trust and confidence of end users in LLM-based applications, including Retrieval Augmented Generation (RAG… hint at the accuracy of LLM generation in the RAG system in most cases. …},
	journal = {Proceedings of the 47th …},
	author = {Sudhi, V. and Bhat, S. R. and Rudat, M. and Teucher, R.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {37 cites: https://scholar.google.com/scholar?cites=17310624488148804463\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zheng_retrieval_2025,
	title = {Retrieval augmented generation and understanding in vision: {A} survey and new outlook},
	url = {https://arxiv.org/abs/2503.18016},
	abstract = {… [8] investigate the integration of knowledge graphs with LLM-based RAG systems. Zhou et al. [9] focus on … We divide it into RAG-related datasets and hallucination detection datasets. …},
	journal = {arXiv preprint arXiv …},
	author = {Zheng, X. and Weng, Z. and Lyu, Y. and Jiang, L. and Xue, H. and Ren, B. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {20 cites: https://scholar.google.com/scholar?cites=1424056158071537387\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{dong_chatiot_2025,
	title = {Chatiot: {Large} language model-based security assistant for internet of things with retrieval-augmented generation},
	url = {https://arxiv.org/abs/2502.09896},
	abstract = {… [13] proposed utilizing ChatGPT to enhance IoT trust semantics, aligning with W3C Web of Things (WoT) recommendations16. This work extends the TrUStAPIS framework [52]. Beyond …},
	journal = {arXiv preprint arXiv …},
	author = {Dong, Y. and Aung, Y. L. and Chattopadhyay, S. and Zhou, J.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=5142274321162754343\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{an_golden-retriever_2024,
	title = {Golden-retriever: high-fidelity agentic retrieval augmented generation for industrial knowledge base},
	url = {https://arxiv.org/abs/2408.00798},
	abstract = {… Despite its advantages, RAG also faces challenges to be … documents, RAG’s LLM backbone may hallucinate and … method with vanilla LLM (without RAG) and the vanilla RAG method. …},
	journal = {arXiv preprint arXiv:2408.00798},
	author = {An, Z. and Ding, X. and Fu, Y. C. and Chu, C. C. and Li, Y. and Du, W.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {15 cites: https://scholar.google.com/scholar?cites=15728928573187051422\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{pinna_integration_2025,
	title = {Integration of {Retrieval}-{Augmented} {Generation} {Technique} for {LLM}-based {Differential} {Diagnosis} {Assistant}},
	url = {https://dl.acm.org/doi/abs/10.1145/3733155.3733192},
	doi = {10.1145/3733155.3733192},
	abstract = {… RetrievalAugmented Generation (RAG) technique into a pre-trained Large Language Model (LLM… Future work suggests that integrating RAG will be crucial to mitigating the hallucination …},
	journal = {Proceedings of the 18th …},
	author = {Pinna, S. and Massa, S. M. and Fenu, M. and Casti, G. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{prahlad_personalizing_2025,
	title = {Personalizing {Large} {Language} {Models} using {Retrieval} {Augmented} {Generation} and {Knowledge} {Graph}},
	url = {https://dl.acm.org/doi/abs/10.1145/3701716.3715473},
	doi = {10.1145/3701716.3715473},
	abstract = {… timely, factual, and personalized information fed to the LLM. … (RAG) using knowledge graphs (KGs) to assist the LLM in … of storing continuously updated factual information in a …},
	journal = {… Proceedings of the ACM on Web …},
	author = {Prahlad, D. and Lee, C. and Kim, D. and Kim, H.},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=11896257370444015396\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{upadhyay_enhancing_2025,
	title = {Enhancing {Health} {Information} {Retrieval} with {RAG} by prioritizing topical relevance and factual accuracy},
	url = {https://link.springer.com/article/10.1007/s10791-025-09505-5},
	doi = {10.1007/s10791-025-09505-5},
	abstract = {… -driven model configurations, which consistently excel in both the top-5 and top-10 document retrieval categories, especially with regard to the RAG model led by the Llama LLM. These …},
	journal = {Discover Computing},
	author = {Upadhyay, R. and Viviani, M.},
	year = {2025},
	note = {Publisher: Springer
Type: HTML},
	annote = {17 cites: https://scholar.google.com/scholar?cites=10576789148143617481\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{danuarta_retrieval-augmented_2024,
	title = {Retrieval-{Augmented} {Generation} ({RAG}) {Large} {Language} {Model} {For} {Educational} {Chatbot}},
	url = {https://ieeexplore.ieee.org/abstract/document/10957676/},
	abstract = {… of the RetrievalAugmented Generation (RAG) method to … To evaluate the relevance of an answer, the LLM creates potential … To assess credibility, we first use an LLM to extract a set of …},
	journal = {2024 Ninth International …},
	author = {Danuarta, L. and Mawardi, V. C. and Lee, V.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=14611325703034756783\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ma_think--graph_2024,
	title = {Think-on-graph 2.0: {Deep} and faithful large language model reasoning with knowledge-guided retrieval augmented generation},
	url = {https://arxiv.org/abs/2407.10805},
	abstract = {Retrieval-augmented generation (RAG) has improved large language models (LLMs) by using knowledge retrieval to overcome knowledge deficiencies. However, current RAG … RAG …},
	journal = {arXiv preprint arXiv …},
	author = {Ma, S. and Xu, C. and Jiang, X. and Li, M. and Qu, H. and Yang, C. and Mao, J. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {58 cites: https://scholar.google.com/scholar?cites=16888333525236272421\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{azher_futuregen_2025-1,
	title = {Futuregen: {Llm}-rag approach to generate the future work of scientific article},
	url = {https://arxiv.org/abs/2503.16561},
	abstract = {… an LLM-as-a-judge approach for evaluation. Our results demonstrated that the RAGbased approach with LLM feedback … Hallucination Rate We evaluated hallucinations by treating each …},
	journal = {arXiv preprint arXiv …},
	author = {Azher, I. A. and Mokarrama, M. J. and Guo, Z. and Choudhury, S. R. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=5776455483408387806\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{addison_c-fedrag_2024,
	title = {C-fedrag: {A} confidential federated retrieval-augmented generation system},
	url = {https://arxiv.org/abs/2412.13163},
	abstract = {… RAG has emerged as a popular method that offers significant … for grounding LLMs in factual information (Shuster et al.… and impact of RAG-based systems in reducing LLM hallucinations, …},
	journal = {arXiv preprint arXiv …},
	author = {Addison, P. and Nguyen, M. T. H. and Medan, T. and Shah, J. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=5575254691326077495\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{krishna_fact_2024,
	title = {Fact, fetch, and reason: {A} unified evaluation of retrieval-augmented generation},
	url = {https://arxiv.org/abs/2409.12941},
	abstract = {… hallucinated questions and answers from the obtained set. We then evaluated the same LLM … while also mitigating the issues of hallucination present in LLM-generated content. Human …},
	journal = {arXiv preprint arXiv …},
	author = {Krishna, S. and Krishna, K. and Mohananey, A. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {58 cites: https://scholar.google.com/scholar?cites=2522903506311114096\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yazaki_emergency_2025,
	title = {Emergency patient triage improvement through a retrieval-augmented generation enhanced large-scale language model},
	url = {https://www.tandfonline.com/doi/abs/10.1080/10903127.2024.2374400},
	doi = {10.1080/10903127.2024.2374400},
	abstract = {… The purpose of this study was to control the hallucinations of … a LLM enhanced with Retrieval Augmented Generation (RAG… demonstrated that the LLM integrated with RAG is effective in …},
	journal = {Prehospital …},
	author = {Yazaki, M. and Maki, S. and Furuya, T. and Inoue, K. and {...}},
	year = {2025},
	note = {Publisher: Taylor \&Francis},
	annote = {13 cites: https://scholar.google.com/scholar?cites=12246263371409255380\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_survey_2025,
	title = {A survey of graph retrieval-augmented generation for customized large language models},
	url = {https://arxiv.org/abs/2501.13958},
	abstract = {… new hallucinations and even experiencing severe catastrophic forgetting [11]. Retrieval-Augmented generation (RAG… within RAG focuses on bolstering the quality and efficiency of LLM-…},
	journal = {arXiv preprint arXiv …},
	author = {Zhang, Q. and Chen, S. and Bei, Y. and Yuan, Z. and Zhou, H. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {92 cites: https://scholar.google.com/scholar?cites=1380982338903102120\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{alan_rag-based_2024,
	title = {A rag-based question answering system proposal for understanding islam: {Mufassirqas} llm},
	url = {https://arxiv.org/abs/2401.15378},
	abstract = {… LLM chatbots use NLP techniques to establish connections … false information, known as hallucination. Also, the chatbots' … -based Retrieval Augmented Generation (RAG) approach to …},
	journal = {arXiv preprint arXiv:2401.15378},
	author = {Alan, A. Y. and Karaarslan, E. and Aydin, Ö},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {29 cites: https://scholar.google.com/scholar?cites=7366679479660289373\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{spielberger_retrieval_2025,
	title = {Retrieval {Augmented} {Generation} for {Topic} {Modeling} in {Organizational} {Research}: {An} {Introduction} with {Empirical} {Demonstration}},
	url = {https://arxiv.org/abs/2502.20963},
	abstract = {… of LLM agents (in our case the ReAct agent) for Agentic RAG … (2024b) addressed the issue of hallucinations in LLM-based … reduced the number of hallucinated topics while producing …},
	journal = {arXiv preprint arXiv …},
	author = {Spielberger, G. and Artinger, F. M. and Reb, J. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=15615301018146044331\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_enhancing_2025,
	title = {Enhancing retrieval-augmented generation: a study of best practices},
	url = {https://arxiv.org/abs/2501.07391},
	abstract = {… LLM Size: As the generative LLM in our RAG system, we compare the MistralAI 7B instruction … (5) In terms of factuality (Table 3), we observe similar patterns: Contrastive InContext …},
	journal = {arXiv preprint arXiv …},
	author = {Li, S. and Stenzel, L. and Eickhoff, C. and Bahrainian, S. A.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {36 cites: https://scholar.google.com/scholar?cites=14529543501657408687\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_injury_2025,
	title = {Injury degree appraisal of large language model based on retrieval-augmented generation and deep learning},
	url = {https://www.sciencedirect.com/science/article/pii/S0160252725000032},
	abstract = {… a novel approach that combines Retrieval-Augmented Generation (RAG) with graph-based … By integrating this model with a graph-based knowledge base, our RAG strategy significantly …},
	journal = {International Journal of Law and Psychiatry},
	author = {Zhang, F. and Luo, Y. and Gao, Z. and Han, A.},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {2 cites: https://scholar.google.com/scholar?cites=6446813674899978352\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_llms_2024,
	title = {Llms are biased evaluators but not biased for retrieval augmented generation},
	url = {https://arxiv.org/abs/2410.20833},
	abstract = {… selfpreference effect in RAG frameworks. Instead, we observe that factual accuracy significantly … Our work extends the exploration of LLM’s self-preference to the RAG framework and …},
	journal = {arXiv preprint arXiv …},
	author = {Chen, Y. S. and Jin, J. and Kuo, P. T. and Huang, C. W. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=9752900427259902302\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{bergvall_reducing_2023,
	title = {Reducing {LLM} {Hallucinations} in {Product} {Q}\&{A} {Systems}: {A} {Retrieval}-{Augmented} {Generation} {Approach}},
	url = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5223641},
	abstract = {… in hallucinations, though we also explore the trade-offs between strict factual grounding and … This work highlights the potential of RAG pipelines to improve the reliability of LLM-powered …},
	publisher = {papers.ssrn.com},
	author = {Bergvall, P.},
	year = {2023},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{thakur_nomiracl_2023,
	title = {Nomiracl: {Knowing} when you don't know for robust multilingual retrieval-augmented generation},
	url = {https://arxiv.org/abs/2312.11361},
	abstract = {… LLM hallucinations against first-stage retrieval errors in RAG. (… lenges in LLM robustness by often hallucinating an answer … on LLM’s generation results, and find several hallucination …},
	journal = {arXiv preprint arXiv …},
	author = {Thakur, N. and Bonifacio, L. and Zhang, X. and Ogundepo, O. and {...}},
	year = {2023},
	note = {Publisher: arxiv.org},
	annote = {24 cites: https://scholar.google.com/scholar?cites=12688772212027279416\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yang_crag-comprehensive_2024,
	title = {Crag-comprehensive rag benchmark},
	url = {https://proceedings.neurips.cc/paper_files/paper/2024/hash/1435d2d0fca85a84d83ddcb754f58c29-Abstract-Datasets_and_Benchmarks_Track.html},
	abstract = {… Retrieval-Augmented Generation (RAG) has recently emerged as a promising solution to alleviate Large Language Model (LLM… the Comprehensive RAG Benchmark (CRAG), a factual …},
	journal = {Advances in …},
	author = {Yang, X. and Sun, K. and Xin, H. and Sun, Y. and Bhalla, N. and {...}},
	year = {2024},
	note = {Publisher: proceedings.neurips.cc},
	annote = {67 cites: https://scholar.google.com/scholar?cites=1563450633916724650\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_feb4rag_2024,
	title = {Feb4rag: {Evaluating} federated search in the context of retrieval augmented generation},
	url = {https://dl.acm.org/doi/abs/10.1145/3626772.3657853},
	doi = {10.1145/3626772.3657853},
	abstract = {… unsuitable of typical RAG pipelines applications, we created prompts for an LLM to generate … These results enhance our confidence in the reliability of LLMbased relevance judgments, …},
	journal = {Proceedings of the 47th …},
	author = {Wang, S. and Khramtsova, E. and Zhuang, S. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {35 cites: https://scholar.google.com/scholar?cites=7331330944969335801\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhao_longrag_2024,
	title = {Longrag: {A} dual-perspective retrieval-augmented generation paradigm for long-context question answering},
	url = {https://arxiv.org/abs/2410.18050},
	abstract = {… factual details due to substantial noise. To this end, we propose LongRAG, a general, dual-perspective, and robust LLM-based RAG system paradigm for LCQA to enhance RAG’s …},
	journal = {arXiv preprint arXiv …},
	author = {Zhao, Q. and Wang, R. and Cen, Y. and Zha, D. and Tan, S. and Dong, Y. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {32 cites: https://scholar.google.com/scholar?cites=7660772558187771643\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{salemi_evaluating_2024,
	title = {Evaluating retrieval quality in retrieval-augmented generation},
	url = {https://dl.acm.org/doi/abs/10.1145/3626772.3657957},
	doi = {10.1145/3626772.3657957},
	abstract = {… and the downstream performance of RAG. In this paper, … RAG systems, where we apply the LLM in RAG system on each document in the retrieval result list individually and use the LLM’…},
	journal = {Proceedings of the 47th International ACM SIGIR …},
	author = {Salemi, A. and Zamani, H.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {198 cites: https://scholar.google.com/scholar?cites=8558782959458313774\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wada_retrieval-augmented_2025,
	title = {Retrieval-augmented generation elevates local {LLM} quality in radiology contrast media consultation},
	url = {https://www.nature.com/articles/s41746-025-01802-z},
	abstract = {… Our findings reinforce RAG’s critical role in hallucination mitigation, a fundamental … The complete elimination of hallucinations (reducing incidence from 8\% to 0\%) in our RAG-enhanced …},
	journal = {npj Digital …},
	author = {Wada, A. and Tanaka, Y. and Nishizawa, M. and Yamamoto, A. and {...}},
	year = {2025},
	note = {Publisher: nature.com
Type: HTML},
	annote = {3 cites: https://scholar.google.com/scholar?cites=7416025264691301743\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{malik_assessing_2024,
	title = {Assessing {ChatGPT4} with and without retrieval-augmented generation in anticoagulation management for gastrointestinal procedures},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC11372545/},
	abstract = {… ChatGPT-4’s performance was also compared to that of ChatGPT-3.5 and ChatGPT4-RAG. … In addition, none of the gastroenterologists surveyed would trust ChatGPT to autonomously …},
	journal = {Annals of …},
	author = {Malik, S. and Kharel, H. and Dahiya, D. S. and Ali, H. and {...}},
	year = {2024},
	note = {Publisher: pmc.ncbi.nlm.nih.gov
Type: HTML},
	annote = {9 cites: https://scholar.google.com/scholar?cites=5554673741521822332\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lee_finetune-rag_2025,
	title = {Finetune-{RAG}: {Fine}-{Tuning} {Language} {Models} to {Resist} {Hallucination} in {Retrieval}-{Augmented} {Generation}},
	url = {https://arxiv.org/abs/2505.10792},
	abstract = {… , a simple and effective fine-tuning approach that features the first-of-its-kind RAG … -RAG improves factual accuracy by 21.2\% over the base model. We also propose Bench-RAG, an LLM-…},
	journal = {arXiv preprint arXiv:2505.10792},
	author = {Lee, Z. P. and Lin, A. and Tan, C.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=7180679661238930897\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lee_developing_2025,
	title = {Developing a computer-based tutor utilizing generative artificial intelligence ({GAI}) and retrieval-augmented generation ({RAG})},
	url = {https://link.springer.com/article/10.1007/s10639-024-13129-5},
	doi = {10.1007/s10639-024-13129-5},
	abstract = {… LLM to incorporate up-to-date information, mitigating the impact of a static knowledge base. Moreover, RAG helps alleviate the hallucination … RAG does not involve changing the LLM’s …},
	journal = {Education and Information Technologies},
	author = {Lee, Y.},
	year = {2025},
	note = {Publisher: Springer},
	annote = {14 cites: https://scholar.google.com/scholar?cites=16734439455425307397\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{meng_using_2025,
	title = {Using the {Retrieval}-{Augmented} {Generation} to {Improve} the {Question}-{Answering} {System} in {Human} {Health} {Risk} {Assessment}: {The} {Development} and {Application}},
	url = {https://www.mdpi.com/2079-9292/14/2/386},
	abstract = {… For factual accuracy (F c ), using the LLM, we can split the generated answer (A) and the … This study has demonstrated that retrieval-augmented generation can improve the LLM’s …},
	journal = {Electronics},
	author = {Meng, W. and Li, Y. and Chen, L. and Dong, Z.},
	year = {2025},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {7 cites: https://scholar.google.com/scholar?cites=11314548991859681159\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ding_retrieve_2024,
	title = {Retrieve only when it needs: {Adaptive} retrieval augmentation for hallucination mitigation in large language models},
	url = {https://arxiv.org/abs/2402.10612},
	abstract = {… Our objective is to enhance the factuality of LLM responses by integrating parametric and … ChatGPT language model. We re-implement all baselines, except Self-RAG, using ChatGPT to …},
	journal = {arXiv preprint arXiv:2402.10612},
	author = {Ding, H. and Pang, L. and Wei, Z. and Shen, H. and Cheng, X.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {77 cites: https://scholar.google.com/scholar?cites=9423915886660989154\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{bazzi_wonders_2025,
	title = {The {Wonders} of {RAG}: {Streamlining} {Knowledge} with {Advanced} {Techniques} {Systematic} literature review {Report}},
	url = {https://www.authorea.com/doi/full/10.22541/au.174197235.57492382},
	abstract = {… RAG goes beyond merely creating a smarter ChatGPT; it enables … hallucinations by augmenting with up-to-date knowledge. In summary, these instances highlight the power of RAG and …},
	publisher = {authorea.com},
	author = {Bazzi, W. and Gaith, M.},
	year = {2025},
	doi = {10.22541/au.174197235.57492382},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{roychowdhury_eratta_2024,
	title = {{ERATTA}: {Extreme} {RAG} for {Table} {To} {Answers} with {Large} {Language} {Models}},
	url = {https://arxiv.org/abs/2405.03963},
	abstract = {… Second, we present non-LLM hallucination detection metrics that evaluate the accuracy and reliability of each query response. Third, we present extensions to the extreme…},
	journal = {arXiv preprint arXiv …},
	author = {Roychowdhury, S. and Krema, M. and Mahammad, A. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=13076648343125853801\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yuan_rag-driver_2024,
	title = {Rag-driver: {Generalisable} driving explanations with retrieval-augmented in-context learning in multi-modal large language model},
	url = {https://arxiv.org/abs/2402.10828},
	abstract = {… Abstract—We need to trust robots that use often opaque AI methods. They need to explain … , we introduce RAG-Driver, a novel retrieval-augmented multi-modal large language model …},
	journal = {arXiv preprint arXiv …},
	author = {Yuan, J. and Sun, S. and Omeiza, D. and Zhao, B. and Newman, P. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {111 cites: https://scholar.google.com/scholar?cites=16030903054394019216\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{dong_journey_2024,
	title = {The journey to a knowledgeable assistant with retrieval-augmented generation (rag)},
	url = {https://dl.acm.org/doi/abs/10.1145/3626246.3655999},
	doi = {10.1145/3626246.3655999},
	abstract = {… LLM techniques. We start with our findings from a comprehensive set of experiments to assess LLM reliability in answering factual … our federated Retrieval-Augmented Generation (RAG) …},
	journal = {Companion of the 2024 International Conference on …},
	author = {Dong, X. L.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=6412488027882586880\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{liang_saferag_2025,
	title = {Saferag: {Benchmarking} security in retrieval-augmented generation of large language model},
	url = {https://arxiv.org/abs/2501.18636},
	abstract = {… RAG security. First, we classify attack tasks into silver noise, inter-context conflict, soft ad, and white Denial-of-Service. Next, we construct RAG … attack scenarios that RAG may encounter. …},
	journal = {arXiv preprint arXiv …},
	author = {Liang, X. and Niu, S. and Li, Z. and Zhang, S. and Wang, H. and Xiong, F. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=3231911126516214\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chang_detecting_2024,
	title = {Detecting hallucination and coverage errors in retrieval augmented generation for controversial topics},
	url = {https://arxiv.org/abs/2403.08904},
	abstract = {… In this paper, we investigate how LLMs can be used with retrieval augmented generation for … in the tuned LLM responses. In retrieval augmented generation, factual information is re…},
	journal = {arXiv preprint arXiv …},
	author = {Chang, T. A. and Tomanek, K. and Hoffmann, J. and Thain, N. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {16 cites: https://scholar.google.com/scholar?cites=17766092588679736190\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{qi_model_2024,
	title = {Model internals-based answer attribution for trustworthy retrieval-augmented generation},
	url = {https://arxiv.org/abs/2406.13663},
	abstract = {… 15For completeness, we also report MIRAGE results without self-citation prompting in … 16ALCE is an evaluation framework for RAG, evaluating LLM responses in terms of citation quality…},
	journal = {arXiv preprint arXiv:2406.13663},
	author = {Qi, J. and Sarti, G. and Fernández, R. and Bisazza, A.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {32 cites: https://scholar.google.com/scholar?cites=12390406060481921862\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wu_knowledge_2024,
	title = {Knowledge graph integration and self-verification for comprehensive retrieval-augmented generation},
	url = {https://openreview.net/forum?id=457wTt0ngj},
	abstract = {… contextual understanding and reduce hallucinations on RAG. LLM’s advanced capabilities … advanced capabilities of LLM to enhance the robustness and credibility of our information …},
	journal = {… Retrieval Augmented …},
	author = {Wu, C. and Shen, T. and Yan, R. and Wang, H. and Liu, Z. and {...}},
	year = {2024},
	note = {Publisher: openreview.net},
	annote = {2 cites: https://scholar.google.com/scholar?cites=3780927909298529251\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{su_dragin_2024,
	title = {{DRAGIN}: dynamic retrieval augmented generation based on the information needs of large language models},
	url = {https://arxiv.org/abs/2403.10081},
	abstract = {… RAG enhances LLMs by retrieving and incorporating relevant … of RAG typically rely on single-round retrieval, using the LLM’s … retrieval dynamically when the LLM’s confidence (ie, the …},
	journal = {arXiv preprint arXiv:2403.10081},
	author = {Su, W. and Tang, Y. and Ai, Q. and Wu, Z. and Liu, Y.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {130 cites: https://scholar.google.com/scholar?cites=7785718507369506206\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hu_lrp4rag_2024,
	title = {Lrp4rag: {Detecting} hallucinations in retrieval-augmented generation via layer-wise relevance propagation},
	url = {https://arxiv.org/abs/2408.15533},
	abstract = {… However, during the RAG process, we find that the LLM’s internal thoughts diverge significantly from the correct answer, leading to failure in answering "Who did John Evelyn support …},
	journal = {arXiv preprint arXiv:2408.15533},
	author = {Hu, H. and He, C. and Xie, X. and Zhang, Q.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=4980569429378351163\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{toukmaji_retrieval-augmented_2024,
	title = {Retrieval-augmented generation and llm agents for biomimicry design solutions},
	url = {https://ojs.aaai.org/index.php/AAAI-SS/article/view/31210},
	abstract = {… to mitigate hallucination issues in LLMs is LLM agents. … We evaluate the quality of LLM-generated biomimetic design … As a result, we opt to use the prompting LLM with RAG setting …},
	journal = {Proceedings of the AAAI Symposium Series},
	author = {Toukmaji, C. and Tee, A.},
	year = {2024},
	note = {Publisher: ojs.aaai.org},
	annote = {15 cites: https://scholar.google.com/scholar?cites=14179709102874850883\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ozmen_evidence-based_2025,
	title = {Evidence-based artificial intelligence: {Implementing} retrieval-augmented generation models to enhance clinical decision support in plastic surgery},
	url = {https://www.jprasurg.com/article/S1748-6815(25)00225-6/fulltext},
	abstract = {… In conclusion, RAG models represent a significant advancement in overcoming traditional LLM … may incorrectly describe microsurgical anastomosis techniques due to hallucinations, …},
	journal = {Journal of Plastic, Reconstructive \&Aesthetic …},
	author = {Ozmen, B. B. and Mathur, P.},
	year = {2025},
	note = {Publisher: jprasurg.com
Type: HTML},
	annote = {9 cites: https://scholar.google.com/scholar?cites=11253659507933200072\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bhattacharya_strategies_2024,
	title = {Strategies to mitigate hallucinations in large language models},
	url = {https://www.ingentaconnect.com/content/hsp/ama/2024/00000010/00000001/art00007},
	abstract = {… Human involvement, in addition to grounding the LLM with external data (RAG), will allow for the verification of responses against external data sources, ensuring that generated content …},
	journal = {Applied Marketing Analytics},
	author = {Bhattacharya, R.},
	year = {2024},
	note = {Publisher: ingentaconnect.com},
	annote = {10 cites: https://scholar.google.com/scholar?cites=856275378498039913\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{leschanowsky_transparent_2025,
	title = {Transparent nlp: {Using} rag and llm alignment for privacy q\&a},
	url = {https://arxiv.org/abs/2502.06652},
	abstract = {… However, because RAG systems are built on … LLM hallucination when providing such generated answers to data processing questions. This is a well-known problem of RAG and LLM …},
	journal = {arXiv preprint arXiv …},
	author = {Leschanowsky, A. and Kolagar, Z. and Çano, E. and Habernal, I. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=11475549983684404418\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{khaliq_ragar_2024,
	title = {Ragar, your falsehood radar: {Rag}-augmented reasoning for political fact-checking using multimodal large language models},
	url = {https://arxiv.org/abs/2404.12065},
	abstract = {… hallucination in text generation, current fact-checking pipelines often implement a RAG approach, wherein an LLM … pairs generated by our LLM-based and RAG-augmented reasoning …},
	journal = {arXiv preprint arXiv …},
	author = {Khaliq, M. A. and Chang, P. and Ma, M. and Pflugfelder, B. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {54 cites: https://scholar.google.com/scholar?cites=15432424327931876476\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cerqueira_mapping_2025,
	title = {Mapping trustworthiness in large language models: {A} bibliometric analysis bridging theory to practice},
	url = {https://arxiv.org/abs/2503.04785},
	abstract = {… To address this, we propose a structured mapping of 20 trust-enhancing techniques across the LLM lifecycle, including retrieval-augmented generation (RAG), explainability techniques, …},
	journal = {arXiv preprint arXiv …},
	author = {Cerqueira, JS de and Kemell, K. K. and Rousi, R. and Xi, N. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=12688301666818952264\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{eskenazi_evaluating_2025,
	title = {Evaluating retrieval augmented generation and {ChatGPT}'s accuracy on orthopaedic examination assessment questions},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC12082174/},
	abstract = {… hypothesized that ChatGPT-4 with RAG would outperform ChatGPT versions without RAG, … Second, ChatGPT-4 + RAG can cite the sources it uses when answering questions. Tracing …},
	journal = {Annals of …},
	author = {Eskenazi, J. and Krishnan, V. and Konarzewski, M. and {...}},
	year = {2025},
	note = {Publisher: pmc.ncbi.nlm.nih.gov
Type: HTML},
	annote = {2 cites: https://scholar.google.com/scholar?cites=18203991795004911765\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zeng_federated_2024,
	title = {Federated recommendation via hybrid retrieval augmented generation},
	url = {https://ieeexplore.ieee.org/abstract/document/10825302/},
	abstract = {… Our proposed hybrid retrieval mechanism and LLM-… LLM, overcoming data sparsity and heterogeneity in FR. Finally, the RAG nature of GPT-FedRec also prevents LLM hallucination, …},
	journal = {2024 IEEE International …},
	author = {Zeng, H. and Yue, Z. and Jiang, Q. and Wang, D.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {29 cites: https://scholar.google.com/scholar?cites=7545705814378599433\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_controlling_2024,
	title = {Controlling risk of retrieval-augmented generation: a counterfactual prompting framework},
	url = {https://arxiv.org/abs/2409.16146},
	abstract = {… latent factors affecting RAG’s confidence in its predictions: … To guide RAG models in assessing their own confidence based … We find that risk control works better with ChatGPT than with …},
	journal = {arXiv preprint arXiv …},
	author = {Chen, L. and Zhang, R. and Guo, J. and Fan, Y. and Cheng, X.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=14405891477587247943\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gokdemir_hiperrag_2025,
	title = {{HiPerRAG}: {High}-{Performance} {Retrieval} {Augmented} {Generation} for {Scientific} {Insights}},
	url = {https://dl.acm.org/doi/abs/10.1145/3732775.3733586},
	doi = {10.1145/3732775.3733586},
	abstract = {… hallucinations of LLMs through the integration of neural information retrieval with LLM-based … Quantifying relevance in this manner improves the factuality of LLM outputs by dynamically …},
	journal = {Proceedings of the …},
	author = {Gokdemir, O. and Siebenschuh, C. and Brace, A. and Wells, A. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=16158565134197057109\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{patel_comparative_2024,
	title = {A comparative analysis of large language models with retrieval-augmented generation based question answering system},
	url = {https://ieeexplore.ieee.org/abstract/document/10714814/},
	abstract = {… Zhang, “Enhancing llm factual accuracy with rag to counter hallucinations: A case study on domain-specific queries in private knowledge-bases,” arXiv preprint arXiv:2403.10446, 2024. …},
	journal = {… on I-SMAC (IoT in Social …},
	author = {Patel, H. N. and Surti, A. and Goel, P. and Patel, B.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {14 cites: https://scholar.google.com/scholar?cites=5571445302219510647\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bansal_understanding_2025,
	title = {Understanding and {Mitigating} {Strategies} for {Large} {Language} {Model} ({LLMs}) {Hallucinations} in {HR} {Chatbots}},
	url = {https://www.researchgate.net/profile/Rishab-Bansal-5/publication/392513063_Understanding_and_Mitigating_Strategies_for_Large_Language_Model_LLMs_Hallucinations_in_HR_Chatbots/links/68bdfa68c76fc271eb321a42/Understanding-and-Mitigating-Strategies-for-Large-Language-Model-LLMs-Hallucinations-in-HR-Chatbots.pdf},
	abstract = {… [19] Under a RAG system, the LLM is expected to base its response on relevant material obtained from a trustworthy knowledge source (such as a corporate HR policy database or …},
	journal = {International Journal of …},
	author = {Bansal, R. and Chandra, R. and Lulla, K.},
	year = {2025},
	note = {Publisher: researchgate.net
Type: PDF},
	annote = {1 cites: https://scholar.google.com/scholar?cites=13441263208363574241\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yu_llms_2024,
	title = {{LLMs} as {Collaborator}: {Demands}-{Guided} {Collaborative} {Retrieval}-{Augmented} {Generation} for {Commonsense} {Knowledge}-{Grounded} {Open}-{Domain} {Dialogue} {Systems}},
	url = {https://aclanthology.org/2024.findings-emnlp.794/},
	abstract = {… of LLM itself and then suffers from the hallucination and outdated knowledge, and 2) RAG … 2, this work proposes a novel LLM-based DCRAG, which regards LLM as Collaborator in …},
	journal = {Findings of the Association for …},
	author = {Yu, J. and Wu, S. and Chen, J. and Zhou, W.},
	year = {2024},
	note = {Publisher: aclanthology.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=12068592914461992858\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{william_text_2024,
	title = {Text {Embedding} {Implementation} {Using} {Retrieval} {Augmented} {Generation} ({RAG}) {Model} {Combined} {With} {Large} {Language} {Model}},
	url = {https://www.researchgate.net/profile/Mubarak-Altamimi/publication/381105654_Text_Embedding_Implementation_Using_Retrieval_Augmented_Generation_RAG_Model_Combined_With_Large_Language_Model/links/665c78e30b0d2845747c0fe8/Text-Embedding-Implementation-Using-Retrieval-Augmented-Generation-RAG-Model-Combined-With-Large-Language-Model.pdf},
	abstract = {… evaluation for tasks requiring factual accuracy, to assess the performance of your RAG model. We follow software engineering concepts and maintain excellent coding standards …},
	journal = {International Journal of Advanced Natural …},
	author = {William, I. O. and Altamimi, M.},
	year = {2024},
	note = {Publisher: researchgate.net
Type: PDF},
	annote = {10 cites: https://scholar.google.com/scholar?cites=174887056568810095\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jeon_chatcnc_2025,
	title = {{ChatCNC}: {Conversational} machine monitoring via large language model and real-time data retrieval augmented generation},
	url = {https://www.sciencedirect.com/science/article/pii/S0278612525000263},
	abstract = {… Leveraging LLM-based multi-agent collaboration and Retrieval-Augmented Generation (RAG… As ChatCNC allows rapid adaptation of LLM Application Programming Interfaces (APIs) via …},
	journal = {Journal of Manufacturing …},
	author = {Jeon, J. and Sim, Y. and Lee, H. and Han, C. and Yun, D. and Kim, E. and {...}},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {9 cites: https://scholar.google.com/scholar?cites=16227493112750189325\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{colverd_floodbrain_2023,
	title = {Floodbrain: {Flood} disaster reporting by web-based retrieval augmented generation with an llm},
	url = {https://arxiv.org/abs/2311.02597},
	abstract = {… Despite our efforts to curb hallucination risks via a human-in-the-loop inspect methodology, … This tool is designed for collaborative report writing between human and LLM, to be used …},
	journal = {arXiv preprint arXiv …},
	author = {Colverd, G. and Darm, P. and Silverberg, L. and {...}},
	year = {2023},
	note = {Publisher: arxiv.org},
	annote = {44 cites: https://scholar.google.com/scholar?cites=5306657255498490493\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{xiong_merging_2024,
	title = {Merging mixture of experts and retrieval augmented generation for enhanced information retrieval and reasoning},
	url = {https://assets-eu.researchsquare.com/files/rs-3978298/v1_covered_c16e21c8-7b04-448d-bc48-d44b0f430b4e.pdf},
	abstract = {… through research demonstrating RAG’s capacity to improve factual accuracy and relevance … to systematically integrate MoE and RAG into the Mistral Large Language Model (LLM), and …},
	publisher = {assets-eu.researchsquare.com},
	author = {Xiong, X. and Zheng, M.},
	year = {2024},
	note = {Type: PDF},
	annote = {60 cites: https://scholar.google.com/scholar?cites=5064603921848374961\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{fatehkia_t-rag_2024,
	title = {T-{RAG}: lessons from the {LLM} trenches},
	url = {https://arxiv.org/abs/2402.07483},
	abstract = {… of RAG with a finetuned open-source LLM. Additionally, our system, which we call Tree-RAG (T-RAG… As we observed earlier, finetuned models are still prone to hallucinations especially …},
	journal = {arXiv preprint arXiv:2402.07483},
	author = {Fatehkia, M. and Lucas, J. K. and Chawla, S.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {53 cites: https://scholar.google.com/scholar?cites=14862728401362406695\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{meng_kerag_r_2025,
	title = {{KERAG}\_R: {Knowledge}-{Enhanced} {Retrieval}-{Augmented} {Generation} for {Recommendation}},
	url = {https://arxiv.org/abs/2507.05863},
	abstract = {… to inaccuracies or hallucinations, … RAG by pre-training a graph attention network (GAT) to select the most relevant triple for the target users for the used LLM, thereby enhancing the LLM …},
	journal = {arXiv preprint arXiv:2507.05863},
	author = {Meng, Z. and Yi, Z. and Ounis, I.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=9087758060013882457\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_llm-based_2025,
	title = {{LLM}-based {Corroborating} and {Refuting} {Evidence} {Retrieval} for {Scientific} {Claim} {Verification}},
	url = {https://arxiv.org/abs/2503.07937},
	abstract = {… that can further reduce hallucination in LLM generation than a typical RAG. CIBER is unsupervised… stage of RAG where we systematically measure the uncertainty in LLM responses to …},
	journal = {arXiv preprint arXiv:2503.07937},
	author = {Wang, S. and Foulds, J. R. and Gani, M. O. and Pan, S.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=15443348012028659539\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sun_humanmod_2025,
	title = {{HumanMoD}: {A} multi-{RAG} collaborative {LLM} for inclusive urban public healthcare services},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494625009950},
	abstract = {… This paper introduces HumanMoD, a novel LLM framework designed to emulate … bases to mitigate LLM hallucinations, ensuring that recommendations are rooted in credible medical …},
	journal = {Applied Soft Computing},
	author = {Sun, S. and Zhong, Z. and Yu, N. and Gong, X. and Yang, K.},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {1 cites: https://scholar.google.com/scholar?cites=15288981255391220410\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{alan_improving_2025,
	title = {Improving {LLM} {Reliability} with {RAG} in {Religious} {Question}-{Answering}: {MufassirQAS}},
	url = {https://dergipark.org.tr/en/pub/tuje/issue/90109/1624773},
	abstract = {… RAG-based system designed to minimize hallucinations and misinformation in religious inquiries. To achieve this, we constructed a specialized RAG … is enhancing chatbot credibility by …},
	journal = {Turkish Journal of Engineering},
	author = {Alan, A. Y. and Karaarslan, E. and Aydın, Ö},
	year = {2025},
	note = {Publisher: dergipark.org.tr},
	annote = {3 cites: https://scholar.google.com/scholar?cites=17441018658493779189\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chirkova_retrieval-augmented_2024,
	title = {Retrieval-augmented generation in multilingual settings},
	url = {https://arxiv.org/abs/2407.01463},
	abstract = {… Retrieval-augmented generation (RAG) has recently emerged as a promising … LLM factuality, but is predominantly studied in English-only settings. In this work, we consider RAG in the …},
	journal = {arXiv preprint arXiv …},
	author = {Chirkova, N. and Rau, D. and Déjean, H. and Formal, T. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {33 cites: https://scholar.google.com/scholar?cites=5259656313022702322\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{nguyen_sfr-rag_2024,
	title = {Sfr-rag: {Towards} contextually faithful llms},
	url = {https://arxiv.org/abs/2409.09916},
	abstract = {… SFRRAG, a small LLM that is instruction-tuned with an emphasis on context-grounded generation and hallucination … on the generator LLM component of the RAG framework. Traditional …},
	journal = {arXiv preprint arXiv …},
	author = {Nguyen, X. P. and Pandit, S. and Purushwalkam, S. and Xu, A. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {16 cites: https://scholar.google.com/scholar?cites=13552621779248931677\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chang_main-rag_2024,
	title = {Main-rag: {Multi}-agent filtering retrieval-augmented generation},
	url = {https://arxiv.org/abs/2501.00332},
	abstract = {… This indicates that the LLM (here is Mistral-7B) is more confident … , suggesting that the LLM is less confident and may misjudge … We acknowledge that LLM inference under RAG workflow …},
	journal = {arXiv preprint arXiv …},
	author = {Chang, C. Y. and Jiang, Z. and Rakesh, V. and Pan, M. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {20 cites: https://scholar.google.com/scholar?cites=17163534002854058838\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yu_integrating_2025,
	title = {Integrating small language models with retrieval-augmented generation in computing education: {Key} takeaways, setup, and practical insights},
	url = {https://dl.acm.org/doi/abs/10.1145/3641554.3701844},
	doi = {10.1145/3641554.3701844},
	abstract = {… and hallucination reduction, as well as data privacy maintenance. We address the “Impossible Triangle" in RAG … While combining a LLM with RAG (LLM + RAG) techniques can also …},
	journal = {Proceedings of the 56th ACM …},
	author = {Yu, Z. and Liu, S. and Denny, P. and Bergen, A. and Liut, M.},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=127211140711091414\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{alkhalaf_applying_2024,
	title = {Applying generative {AI} with retrieval augmented generation to summarize and extract key clinical information from electronic health records},
	url = {https://www.sciencedirect.com/science/article/pii/S1532046424000807},
	abstract = {… their own and in combination with retrieval augmented generation (RAG), for the automating … RAG approach improved the model performance and mitigated the hallucination problem. …},
	journal = {Journal of biomedical informatics},
	author = {Alkhalaf, M. and Yu, P. and Yin, M. and Deng, C.},
	year = {2024},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {97 cites: https://scholar.google.com/scholar?cites=8576425453953983120\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{asai_self-rag_2023,
	title = {Self-rag: {Self}-reflective retrieval augmented generation},
	url = {https://openreview.net/forum?id=jbNjgmE0OP},
	abstract = {… This work aims to improve the factuality of LLM outputs, the lack of which continues to cause numerous real-world problems (eg, spread of misinformation and provision of incorrect and …},
	journal = {NeurIPS 2023 workshop on …},
	author = {Asai, A. and Wu, Z. and Wang, Y. and Sil, A. and {...}},
	year = {2023},
	note = {Publisher: openreview.net},
	annote = {34 cites: https://scholar.google.com/scholar?cites=12582157907525149340\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{joren_sufficient_2024,
	title = {Sufficient context: {A} new lens on retrieval augmented generation systems},
	url = {https://arxiv.org/abs/2411.06037},
	abstract = {… Building on our findings, we explore ways to reduce hallucinations in RAG systems, including a new selective … Another line of study aims to reduce LLM hallucinations in RAG settings. …},
	journal = {arXiv preprint arXiv …},
	author = {Joren, H. and Zhang, J. and Ferng, C. S. and Juan, D. C. and Taly, A. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {19 cites: https://scholar.google.com/scholar?cites=2193116398501643332\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_knowledge_2025,
	title = {Knowledge graph retrieval-augmented generation for llm-based recommendation},
	url = {https://arxiv.org/abs/2501.02226},
	abstract = {… advancements, LLM-… LLM backbones, particularly issues of hallucinations and the lack of up-todate and domain-specific knowledge. Recently, Retrieval-Augmented Generation (RAG) …},
	journal = {arXiv preprint arXiv …},
	author = {Wang, S. and Fan, W. and Feng, Y. and Lin, S. and Ma, X. and Wang, S. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {24 cites: https://scholar.google.com/scholar?cites=3462234415221687135\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lakatos_investigating_2025,
	title = {Investigating the performance of retrieval-augmented generation and domain-specific fine-tuning for the development of {AI}-driven knowledge-based systems},
	url = {https://www.mdpi.com/2504-4990/7/1/15},
	abstract = {… the performance of RAG and DFT on several LLM architectures, … RAG-based architecture that maximizes efficiency and reduces hallucination, underscoring the advantages of RAG …},
	journal = {Machine Learning and Knowledge …},
	author = {Lakatos, R. and Pollner, P. and Hajdu, A. and Joo, T.},
	year = {2025},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {39 cites: https://scholar.google.com/scholar?cites=13597662086452509415\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yang_knowledge_2024,
	title = {Knowledge {Graph} and {Large} {Language} {Model} {Co}-learning via {Structure}-oriented {Retrieval} {Augmented} {Generation}},
	url = {https://www.cs.emory.edu/~jyang71/files/klc.pdf},
	abstract = {… of KG and LLM co-learning, especially through a structure-oriented retrieval augmented generation (… facts from KGs during the LLM reasoning process, which are used to mitigate factual …},
	journal = {IEEE Data Engineering Bulletin},
	author = {Yang, C. and Xu, R. and Luo, L. and Pan, S.},
	year = {2024},
	note = {Publisher: cs.emory.edu
Type: PDF},
	annote = {2 cites: https://scholar.google.com/scholar?cites=12256288037171139489\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{su_towards_2024,
	title = {Towards more robust retrieval-augmented generation: {Evaluating} rag under adversarial poisoning attacks},
	url = {https://arxiv.org/abs/2412.16708},
	abstract = {… Retrieval-Augmented Generation (RAG) systems have emerged as a promising solution to mitigate LLM hallucinations … use the Non-RAG setting as a proxy to gauge an LLM’s internal …},
	journal = {arXiv preprint arXiv …},
	author = {Su, J. and Zhou, J. P. and Zhang, Z. and Nakov, P. and Cardie, C.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=13787022571833283978\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{hasan_llm_2025,
	title = {{LLM}: {Retreival} vs. {ParametricMemory} {Tradeoff}: {A} {Comparison} of {Retrieval}-{Augmented} {Generation} and {Standalone} {LargeLanguage} {Models} {Using} {RAGAS} {Answer} …},
	url = {https://www.diva-portal.org/smash/record.jsf?pid=diva2:1968861},
	abstract = {… this study is to compare factual accuracy, retrieval quality and hyperparameter sensitivity of a RAG system built on a relatively smaller LLM, against a state-of-the-art large LLM on open-…},
	publisher = {diva-portal.org},
	author = {Hasan, S. and Rezai, A.},
	year = {2025},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yu_retrieval_2024,
	title = {Retrieval {Augmented} {Generation} {Integrated} {Large} {Language} {Models} in {Smart} {Contract} {Vulnerability} {Detection}},
	url = {https://arxiv.org/abs/2407.14838},
	abstract = {… , we aim to foster greater trust in blockchain technologies. This trust is crucial for the widespread … In order to construct an expansive and robust dataset for our RAG-LLM pipeline, we …},
	journal = {arXiv preprint arXiv:2407.14838},
	author = {Yu, J.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=1199384289480647214\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{garcia_improving_2025,
	title = {Improving automated deep phenotyping through large language models using retrieval-augmented generation},
	url = {https://link.springer.com/article/10.1186/s13073-025-01521-w},
	doi = {10.1186/s13073-025-01521-w},
	abstract = {… and “hallucinations,” … of LLM choice on performance, we paired RAG-HPO with six different back-end models. With the sole exception of DeepSeek R1, every LLM configuration of RAG-…},
	journal = {Genome Medicine},
	author = {Garcia, B. T. and Westerfield, L. and Yelemali, P. and Gogate, N. and {...}},
	year = {2025},
	note = {Publisher: Springer
Type: HTML},
	annote = {11 cites: https://scholar.google.com/scholar?cites=4371041247273772099\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{pradeep_ragnarok_2025,
	title = {Ragnarök: {A} reusable {RAG} framework and baselines for {TREC} 2024 retrieval-augmented generation track},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-88708-6_9},
	doi = {10.1007/978-3-031-88708-6_9},
	abstract = {… Next, answer, provides the LLM-generated RAG answer to the user topic, presented as a top-to-bottom list of sentence-level texts with corresponding segment citations. All …},
	journal = {… on Information Retrieval},
	author = {Pradeep, R. and Thakur, N. and Sharifymoghaddam, S. and {...}},
	year = {2025},
	note = {Publisher: Springer},
	annote = {32 cites: https://scholar.google.com/scholar?cites=9223853038970483093\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bora_systematic_2024,
	title = {Systematic analysis of retrieval-augmented generation-based llms for medical chatbot applications},
	url = {https://www.mdpi.com/2504-4990/6/4/116},
	abstract = {… of RAG systems to mitigate hallucinations [13], a prevalent issue with LLMs. Hallucination … When an LLM receives a query, the RAG system employs the same embedding model used …},
	journal = {Machine Learning and Knowledge Extraction},
	author = {Bora, A. and Cuayáhuitl, H.},
	year = {2024},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {34 cites: https://scholar.google.com/scholar?cites=9362815266794873563\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mavromatis_gnn-rag_2024,
	title = {Gnn-rag: {Graph} neural retrieval for large language model reasoning},
	url = {https://arxiv.org/abs/2405.20139},
	abstract = {… The input given to the LLM contains the KG factual information along with the question and a prompt. For instance, the input becomes “Knowledge: Jamaica → language\_spoken → …},
	journal = {arXiv preprint arXiv:2405.20139},
	author = {Mavromatis, C. and Karypis, G.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {140 cites: https://scholar.google.com/scholar?cites=14132545932572362839\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mukhopadhyay_designing_2025,
	title = {Designing {Conversational} {Search} for {Libraries}: {Retrieval} {Augmented} {Generation} through {Open} {Source} {Large} {Language} {Models}},
	url = {https://www.academia.edu/download/121962532/psm202501_20206.pdf},
	abstract = {… hallucinated, outdated, or out of context. By examining the feasibility of an open-source RAG … objectives of this study are: 1) To select a suitable opensource LLM and a RAG framework …},
	journal = {DESIDOC Journal of Library \&Information …},
	author = {Mukhopadhyay, P.},
	year = {2025},
	note = {Publisher: academia.edu
Type: PDF},
	annote = {2 cites: https://scholar.google.com/scholar?cites=988669815207690926\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xu_evaluation_2024,
	title = {Evaluation of the integration of retrieval-augmented generation in large language model for breast cancer nursing care responses},
	url = {https://www.nature.com/articles/s41598-024-81052-3},
	abstract = {… , inherent hallucinations can lead to inaccurate responses. … revealed that RAG technology could improve LLM performance … These findings provide a theoretical basis for applying RAG …},
	journal = {Scientific Reports},
	author = {Xu, R. and Hong, Y. and Zhang, F. and Xu, H.},
	year = {2024},
	note = {Publisher: nature.com
Type: HTML},
	annote = {11 cites: https://scholar.google.com/scholar?cites=2577162414034272153\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{dong_leveraging_2025,
	title = {Leveraging {LLM}-{Assisted} {Query} {Understanding} for {Live} {Retrieval}-{Augmented} {Generation}},
	url = {https://arxiv.org/abs/2506.21384},
	abstract = {… , factuality, and relevance of generated text. Recent efforts [5, 7, 23, 24] have leveraged RAG to … better alignment with the information needs of the LLM. Additionally, some studies [2, 43] …},
	journal = {arXiv preprint arXiv:2506.21384},
	author = {Dong, G. and Li, X. and Zhang, Y. and Deng, M.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=7852305039245064044\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bhat_retrieval_2024,
	title = {Retrieval augmented generation (rag) based restaurant chatbot with ai testability},
	url = {https://ieeexplore.ieee.org/abstract/document/10730393/},
	abstract = {… of ChatGPT, the latest research focuses on utilizing Retrieval Augmented Generation (RAG) … Therefore, in this paper, we propose a multi-modal integration of the RAG model and LLM …},
	journal = {2024 IEEE 10th …},
	author = {Bhat, V. and Cheerla, S. D. and Mathew, J. R. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=16324907020677168104\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{nemeth_exploring_2025,
	title = {Exploring the use of retrieval-augmented generation models in higher education: {A} pilot study on artificial intelligence-based tutoring},
	url = {https://www.sciencedirect.com/science/article/pii/S2590291125004796},
	abstract = {… intelligence tutor like ChatGPT, enhanced with retrieval-augmented generation, in a pilot … large language model. We found that retrieval-augmented generation reduces hallucinations …},
	journal = {Social Sciences \& …},
	author = {Németh, R. and Tátrai, A. and Szabó, M. and Zaletnyik, P. T. and {...}},
	year = {2025},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{aboulela_exploring_2025,
	title = {Exploring {RAG} {Solutions} to {Reduce} {Hallucinations} in {LLMs}},
	url = {https://ieeexplore.ieee.org/abstract/document/11014810/},
	abstract = {… Although computing complexity remains a restriction, this study shows that RAG topologies might not consistently enhance LLM reliability in practical situations. Index Terms—…},
	journal = {2025 IEEE …},
	author = {AboulEla, S. and Zabihitari, P. and Ibrahim, N. and {...}},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=14954464694023093113\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_enhancing_2024,
	title = {Enhancing large language model performance to answer questions and extract information more accurately},
	url = {https://arxiv.org/abs/2402.01722},
	abstract = {… of the LLM to be a financial chatbot that does not hallucinate … to the LLM the same way it would be in a traditional RAG … finance LLM, we need to develop a strong RAG model too, or …},
	journal = {arXiv preprint arXiv …},
	author = {Zhang, L. and Jijo, K. and Setty, S. and Chung, E. and Javid, F. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {42 cites: https://scholar.google.com/scholar?cites=1162311915830449569\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bhayana_retrieval-augmented_2024,
	title = {Retrieval-augmented generation for large language models in radiology: another leap forward in board examination performance},
	url = {https://pubs.rsna.org/doi/abs/10.1148/radiol.241489},
	doi = {10.1148/radiol.241489},
	abstract = {… Thus, RAG is a powerful technique for enriching LLMs with domain-specific … factual responses are critical, like answering radiology questions. Using RAG to reduce LLM hallucinations …},
	journal = {Radiology},
	author = {Bhayana, R. and Fawzy, A. and Deng, Y. and Bleakney, R. R. and Krishna, S.},
	year = {2024},
	note = {Publisher: pubs.rsna.org},
	annote = {17 cites: https://scholar.google.com/scholar?cites=6617659898678560017\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_simple_2024,
	title = {Simple is effective: {The} roles of graphs and large language models in knowledge-graph-based retrieval-augmented generation},
	url = {https://arxiv.org/abs/2410.20724},
	abstract = {… To evaluate the capability of LLM reasoners in knowledge-grounded hallucination-free question answering, we introduce WebQSP-sub and CWQ-sub, where we remove samples …},
	journal = {arXiv preprint arXiv:2410.20724},
	author = {Li, M. and Miao, S. and Li, P.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {54 cites: https://scholar.google.com/scholar?cites=15714395544734432864\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sanmartin_kg-rag_2024,
	title = {Kg-rag: {Bridging} the gap between knowledge and creativity},
	url = {https://arxiv.org/abs/2405.12035},
	abstract = {… employs an LLM configured with a standard RAG prompt as … -RAG approach against vector RAG and no RAG specifically, … to quantify the incidence of hallucinations. These metrics allow …},
	journal = {arXiv preprint arXiv:2405.12035},
	author = {Sanmartin, D.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {86 cites: https://scholar.google.com/scholar?cites=14719498306778771835\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{deng_cram_2025,
	title = {Cram: {Credibility}-aware attention modification in llms for combating misinformation in rag},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/34547},
	abstract = {… In the following, we analyze the effect of varying the number of low-credibility documents fed into the LLM. We conduct experiments using Llama3-8B on the NQ dataset. Specifically, we …},
	journal = {Proceedings of the AAAI …},
	author = {Deng, B. and Wang, W. and Zhu, F. and Wang, Q. and Feng, F.},
	year = {2025},
	note = {Publisher: ojs.aaai.org},
	annote = {17 cites: https://scholar.google.com/scholar?cites=7421225227366020912\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{bouchard_building_2024,
	title = {Building {LLMs} for production: enhancing {LLM} abilities and reliability with prompting, fine-tuning, and {RAG}},
	url = {https://books.google.com/books?hl=en\&lr=\&id=olJTEQAAQBAJ\&oi=fnd\&pg=PT10\&dq=%22retrieval+augmented+generation%22%7C%22rag%22+%22large+language+model%22%7C%22llm%22%7C%22chatgpt%22+trust%7Cconfidence%7Ccredibility%7Challucination%7Cfactuality%7Ccitation\&ots=iZN1YUXqn6\&sig=TEn3lsT2U5bz7gb1CUGfOro1R7k},
	abstract = {… Reducing hallucinations by limiting the LLM to answer based on existing chosen data. 2. Helping with explainability, error checking, and copyright issues by clearly referencing its …},
	publisher = {books.google.com},
	author = {Bouchard, L. F. and Peters, L.},
	year = {2024},
	note = {Type: BOOK},
	annote = {12 cites: https://scholar.google.com/scholar?cites=13640602242222907326\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{berman_retrieval_2025,
	title = {Retrieval augmented therapy suggestion for molecular tumor boards: algorithmic development and validation study},
	url = {https://www.jmir.org/2025/1/e64364/},
	abstract = {… As shown in Table 1, we do not instruct the LLM to cite a specified number of sources. As a … In this study, we developed a RAG approach to LLM text generation to develop treatment …},
	journal = {Journal of Medical …},
	author = {Berman, E. and Malek, H. Sundberg and Bitzer, M. and Malek, N. and {...}},
	year = {2025},
	note = {Publisher: jmir.org
Type: HTML},
	annote = {2 cites: https://scholar.google.com/scholar?cites=10437538066879774929\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hu_cg-rag_2025,
	title = {Cg-rag: {Research} question answering by citation graph retrieval-augmented llms},
	url = {https://dl.acm.org/doi/abs/10.1145/3726302.3729920},
	doi = {10.1145/3726302.3729920},
	abstract = {… LLaMA and closed-source models such as ChatGPT, we first summarize the graph context … Specifically, for each contextual subgraph G𝑖 ∈ 𝑆( G;𝑞), we prompt the LLM to summarize …},
	journal = {Proceedings of the 48th …},
	author = {Hu, Y. and Lei, Z. and Dai, Z. and Zhang, A. and Angirekula, A. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=4266055919074930141\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{veturi_rag_2024,
	title = {Rag based question-answering for contextual response prediction system},
	url = {https://arxiv.org/abs/2409.03708},
	abstract = {… Overall, RAG LLM improves accuracy by reducing hallucinations … Evaluating RAG LLM and BERT-based models on … We thoroughly evaluate the quality of RAG LLM and BERT …},
	journal = {arXiv preprint arXiv …},
	author = {Veturi, S. and Vaichal, S. and Jagadheesh, R. L. and Tripto, N. I. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {20 cites: https://scholar.google.com/scholar?cites=17678621540145157393\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_traq_2023,
	title = {Traq: {Trustworthy} retrieval augmented question answering via conformal prediction},
	url = {https://arxiv.org/abs/2307.04642},
	abstract = {… RAG reduces hallucinations by retrieving passages from a knowledge base such as Wikipedia and then using an LLM to … rates of retriever and LLM sets (named Ret and LLM), and with …},
	journal = {arXiv preprint arXiv:2307.04642},
	author = {Li, S. and Park, S. and Lee, I. and Bastani, O.},
	year = {2023},
	note = {Publisher: arxiv.org},
	annote = {18 cites: https://scholar.google.com/scholar?cites=12569899222674034755\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{su_mitigating_2024,
	title = {Mitigating entity-level hallucination in large language models},
	url = {https://dl.acm.org/doi/abs/10.1145/3673791.3698403},
	doi = {10.1145/3673791.3698403},
	abstract = {… LLM hallucination doesn’t exist. To address these concerns, we evaluate existing dynamic RAG … detection of hallucinations in LLM’s outputs, utilizing an entity confidence metric derived …},
	journal = {Proceedings of the 2024 …},
	author = {Su, W. and Tang, Y. and Ai, Q. and Wang, C. and Wu, Z. and Liu, Y.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {34 cites: https://scholar.google.com/scholar?cites=17879385658863337890\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xu_crp-rag_2024,
	title = {Crp-rag: {A} retrieval-augmented generation framework for supporting complex logical reasoning and knowledge planning},
	url = {https://www.mdpi.com/2079-9292/14/1/47},
	abstract = {… CRP-RAG outperforms the best LLM and RAG baselines by 2.46 in open-… 4.2 in factual verification. Experiments also show the superior factual consistency and robustness of CRP-RAG …},
	journal = {Electronics},
	author = {Xu, K. and Zhang, K. and Li, J. and Huang, W. and Wang, Y.},
	year = {2024},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {16 cites: https://scholar.google.com/scholar?cites=12260263102260677211\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_beefbot_2025,
	title = {Beefbot: {Harnessing} advanced llm and rag techniques for providing scientific and technology solutions to beef producers},
	url = {https://aclanthology.org/2025.coling-demos.7/},
	abstract = {… Model fine-tuning can inject factual knowledge into LLM parameters and provide promising results for completing in-domain tasks. We finetune the Llama-3 which is the latest …},
	journal = {Proceedings of the …},
	author = {Zhang, Z. and Wilson, C. A. and Hay, R. and {...}},
	year = {2025},
	note = {Publisher: aclanthology.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=14151815011356752864\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_m-rag_2024,
	title = {M-{RAG}: {Reinforcing} large language model performance through retrieval-augmented generation with multiple partitions},
	url = {https://arxiv.org/abs/2405.16420},
	abstract = {… M-RAG, designed to facilitate RAG across multiple partitions of a database. M-RAG addresses … However, its quality faces significant challenges such as low precision, hallucination, and …},
	journal = {arXiv preprint arXiv:2405.16420},
	author = {Wang, Z. and Teo, S. X. and Ouyang, J. and Xu, Y. and Shi, W.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {40 cites: https://scholar.google.com/scholar?cites=2975881609935651006\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{iaroshev_evaluating_2024,
	title = {Evaluating {Retrieval}-{Augmented} {Generation} {Models} for {Financial} {Report} {Question} and {Answering}.},
	url = {https://search.ebscohost.com/login.aspx?direct=true\&profile=ehost\&scope=site\&authtype=crawler\&jrnl=20763417\&AN=180527932\&h=Da%2BRiJnQ7UNV4PIzmFYhccEg4jFGL7Ybu0QSPq0EhDBGH9Nr%2BCDw638fxxSx61eois5f3q%2FWqeKSqBaq7wal7A%3D%3D\&crl=c},
	abstract = {… , a selection of non-peer-reviewed papers with substantial citations and reputable authors was also integrated, acknowledging the rapid advancements in LLM and RAG research. …},
	journal = {Applied Sciences (2076 …},
	author = {Iaroshev, I. and Pillai, R. and Vaglietti, L. and {...}},
	year = {2024},
	note = {Publisher: search.ebscohost.com},
	annote = {23 cites: https://scholar.google.com/scholar?cites=7189289432202149734\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_potential_2024,
	title = {Potential for {GPT} technology to optimize future clinical decision-making using retrieval-augmented generation},
	url = {https://link.springer.com/article/10.1007/s10439-023-03327-6},
	doi = {10.1007/s10439-023-03327-6},
	abstract = {… Via RAG, future ChatGPT engines would automatically retrieve this … retrieval-augmented generation. Clinical guidelines released after ChatGPT’s cutoff of September 2021 and trusted …},
	journal = {Annals of biomedical …},
	author = {Wang, C. and Ong, J. and Wang, C. and Ong, H. and Cheng, R. and {...}},
	year = {2024},
	note = {Publisher: Springer},
	annote = {88 cites: https://scholar.google.com/scholar?cites=15761105778692086591\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bingol_accuracy_2025,
	title = {Accuracy of {Current} {Large} {Language} {Models} and the {Retrieval}-{Augmented} {Generation} {Model} in {Determining} {Dietary} {Principles} in {Chronic} {Kidney} {Disease}},
	url = {https://www.sciencedirect.com/science/article/pii/S1051227625000135},
	abstract = {… Customization of LLMs in specific areas such as nutrition or the development of a nutrition-specific RAG framework by improving LLM structures with current guidelines and articles may …},
	journal = {Journal of Renal Nutrition},
	author = {Bingöl, F. G. and Ağagündüz, D. and Bingol, M. C.},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {3 cites: https://scholar.google.com/scholar?cites=5960810541353018675\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ding_citations_2025,
	title = {Citations and trust in llm generated responses},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/34550},
	abstract = {… The widespread adoption of LLMs has led to the development of Retrieval Augmented Generation (RAG) systems. These systems generate explanations by incorporating external …},
	journal = {Proceedings of the …},
	author = {Ding, Y. and Facciani, M. and Joyce, E. and Poudel, A. and {...}},
	year = {2025},
	note = {Publisher: ojs.aaai.org},
	annote = {11 cites: https://scholar.google.com/scholar?cites=13510747714106267575\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{genovese_data_2025,
	title = {From {Data} to {Decisions}: {Leveraging} {Retrieval}-{Augmented} {Generation} to {Balance} {Citation} {Bias} in {Burn} {Management} {Literature}},
	url = {https://www.mdpi.com/2673-1991/6/2/28},
	abstract = {… the performance of the LLM, spanning foundational … LLM’s ability to navigate the literature effectively, simulate the demands of clinical practice, and highlight the potential of RAG …},
	journal = {European Burn …},
	author = {Genovese, A. and Prabha, S. and Borna, S. and {...}},
	year = {2025},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{meduri_efficient_2024,
	title = {Efficient {RAG} framework for large-scale knowledge bases},
	url = {https://www.researchgate.net/profile/Karthik-Meduri/publication/380265505_Efficient_RAG_Framework_for_Large-Scale_Knowledge_Bases/links/66330b9a08aa54017ad48c42/Efficient-RAG-Framework-for-Large-Scale-Knowledge-Bases.pdf},
	abstract = {… to maximize LLM efficiency and resource usage, whereas RAG combines external … the generating process, RAG generates replies that are rich in background and factual. The …},
	journal = {Efficient RAG …},
	author = {Meduri, K. and Nadella, G. S. and Gonaygunta, H. and {...}},
	year = {2024},
	note = {Publisher: researchgate.net
Type: PDF},
	annote = {13 cites: https://scholar.google.com/scholar?cites=8908421062796597959\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{su_parametric_2025,
	title = {Parametric retrieval augmented generation},
	url = {https://dl.acm.org/doi/abs/10.1145/3726302.3729957},
	doi = {10.1145/3726302.3729957},
	abstract = {… documents into the input context of the LLM, which we refer to as the in… To this end, we introduce Parametric RAG, a new RAG … encourages the LLM to internalize the factual details in the …},
	journal = {Proceedings of the 48th …},
	author = {Su, W. and Tang, Y. and Ai, Q. and Yan, J. and Wang, C. and Wang, H. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {28 cites: https://scholar.google.com/scholar?cites=17355577501383931776\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sohn_rationale-guided_2024,
	title = {Rationale-guided retrieval augmented generation for medical question answering},
	url = {https://arxiv.org/abs/2411.00300},
	abstract = {… the LLM prompt increases the confidence of the LLM’s rationale (or reduces its perplexity). tion), a novel framework that improves the reliability of RAG in … for the base LLM, selectively …},
	journal = {arXiv preprint arXiv …},
	author = {Sohn, J. and Park, Y. and Yoon, C. and Park, S. and Hwang, H. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {18 cites: https://scholar.google.com/scholar?cites=2373077447935531672\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_eyegpt_2024,
	title = {{EyeGPT} for patient inquiries and medical education: development and validation of an ophthalmology large language model},
	url = {https://www.jmir.org/2024/1/e60063/},
	abstract = {… into a general LLM using role-play, fine-tuning, and RAG methods, resulting in … LLM responses to Ophthalmic Knowledge Assessment Program style queries. In this study, hallucination …},
	journal = {Journal of medical …},
	author = {Chen, X. and Zhao, Z. and Zhang, W. and Xu, P. and Wu, Y. and Xu, M. and {...}},
	year = {2024},
	note = {Publisher: jmir.org
Type: HTML},
	annote = {21 cites: https://scholar.google.com/scholar?cites=14770104101123690356\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{budakoglu_unveiling_2025,
	title = {Unveiling the {Power} of {Large} {Language} {Models}: {A} {Comparative} {Study} of {Retrieval}-{Augmented} {Generation}, {Fine}-{Tuning} and {Their} {Synergistic} {Fusion} for {Enhanced} …},
	url = {https://ieeexplore.ieee.org/abstract/document/10887212/},
	abstract = {… The present work has shown that fine-tuned LLM integration in RAG pipelines is not without its … emphasis needs to be given to semantic and factual integrity in the generated text. Our …},
	journal = {IEEE Access},
	author = {Budakoglu, G. and Emekci, H.},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=7078464076792903383\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{knollmeyer_benchmarking_2024,
	title = {Benchmarking of retrieval augmented generation: {A} comprehensive systematic literature review on evaluation dimensions, evaluation metrics and datasets},
	url = {https://www.scitepress.org/Papers/2024/130657/130657.pdf},
	abstract = {… of Large Language Models (LLM), traditional benchmarks have … performance of Retrieval Augmented Generation (RAG) systems. … citation quality focuses on assessing whether an LLM …},
	journal = {Proceedings of the …},
	author = {Knollmeyer, S. and Caymazer, O. and Koval, L. and {...}},
	year = {2024},
	note = {Publisher: scitepress.org
Type: PDF},
	annote = {5 cites: https://scholar.google.com/scholar?cites=13151300286370976090\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{choi_malade_2024,
	title = {{MALADE}: orchestration of {LLM}-powered agents with retrieval augmented generation for pharmacovigilance},
	url = {https://arxiv.org/abs/2408.01869},
	abstract = {… a confidence score that indicates how confident an LLM is about its label assignment. These scores permit a rigorous quantitative evaluation against the well-established Observational …},
	journal = {arXiv preprint arXiv …},
	author = {Choi, J. and Palumbo, N. and Chalasani, P. and Engelhard, M. M. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {15 cites: https://scholar.google.com/scholar?cites=8912331488730439645\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ahmed_quality_2025,
	title = {Quality {Assurance} for {LLM}-{RAG} {Systems}: {Empirical} {Insights} from {Tourism} {Application} {Testing}},
	url = {https://ieeexplore.ieee.org/abstract/document/10962487/},
	abstract = {… A significant advance in treating LLM hallucination comes from Dhuliawala et al. [9], who … and reducing hallucination in LLM outputs, particularly crucial for RAG systems where factual …},
	journal = {… on Software Testing …},
	author = {Ahmed, B. S. and Baader, L. O. and Bayram, F. and {...}},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=4755405204503778208\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{pipitone_legalbench-rag_2024,
	title = {Legalbench-rag: {A} benchmark for retrieval-augmented generation in the legal domain},
	url = {https://arxiv.org/abs/2408.10343},
	abstract = {… the context window of an LLM, which poses a significant risk … of hallucinated content at the generation step of RAG systems… phase of the RAG pipeline, assessing how well the LLM can …},
	journal = {arXiv preprint arXiv:2408.10343},
	author = {Pipitone, N. and Alami, G. H.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {63 cites: https://scholar.google.com/scholar?cites=3269376913138154284\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{barry_graphrag_2025,
	title = {Graphrag: leveraging graph-based efficiency to minimize hallucinations in llm-driven rag for finance data},
	url = {https://hal.science/hal-04907346/},
	abstract = {… DeepEval relies on a strong LLM to automatically score RAG … In order to evaluate the propensity to hallucinate, we report in … a good proxy for hallucination because we expect the LLM’s …},
	journal = {… Knowledge Graph \& …},
	author = {Barry, M. and Caillaut, G. and Halftermeyer, P. and Qader, R. and {...}},
	year = {2025},
	note = {Publisher: hal.science},
	annote = {11 cites: https://scholar.google.com/scholar?cites=16485783523553183023\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hasegawa_rag_2024,
	title = {Rag certainty: {Quantifying} the certainty of context-based responses by llms},
	url = {https://ieeexplore.ieee.org/abstract/document/10903445/},
	abstract = {… • We propose a metric called RAG certainty to quantify the certainty of LLM outputs in a RAG … Since we use the RAG certainty to identify whether the output is hallucinated, prioritizing the …},
	journal = {… Conference on Machine …},
	author = {Hasegawa, K. and Hidano, S. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=7151079260216854628\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ecker_trust-informed_2025,
	title = {Trust-{Informed} {Large} {Language} {Models} via {Word} {Embedding}-{Knowledge} {Graph} {Alignment}},
	url = {https://ntrs.nasa.gov/citations/20240015650},
	abstract = {… of hallucinating non-existent information. While Retrieval Augmented Generation (RAG) … work seeks to explore methods to engender a LLM with an intrinsic capability to evaluate an …},
	journal = {AIAA SciTech Forum},
	author = {Ecker, J. E. and Allen, B. D.},
	year = {2025},
	note = {Publisher: ntrs.nasa.gov},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{arslan_business_2024,
	title = {Business insights using {RAG}–{LLMs}: a review and case study},
	url = {https://www.tandfonline.com/doi/abs/10.1080/12460125.2024.2410040},
	doi = {10.1080/12460125.2024.2410040},
	abstract = {… These hallucinations can arise from an overload of data, a lack of contextual relevance, or … This comprehensive review illustrates how RAG–LLM integration has revolutionised …},
	journal = {Journal of Decision Systems},
	author = {Arslan, M. and Munawar, S. and Cruz, C.},
	year = {2024},
	note = {Publisher: Taylor \&Francis},
	annote = {33 cites: https://scholar.google.com/scholar?cites=4288258667573817042\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_unveiling_2025,
	title = {Unveiling {Knowledge} {Utilization} {Mechanisms} in {LLM}-based {Retrieval}-{Augmented} {Generation}},
	url = {https://dl.acm.org/doi/abs/10.1145/3726302.3730112},
	doi = {10.1145/3726302.3730112},
	abstract = {… throughout the RAG process. At the microscopic level, we investigate the role of LLM modules in … and external information, and how it handles noisy information with factual errors. …},
	journal = {Proceedings of the 48th …},
	author = {Wang, Y. and Ren, R. and Wang, Y. and Zhao, W. X. and Liu, J. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{byun_design_2024,
	title = {Design and {Implementation} of an {Interactive} {Question}-{Answering} {System} with {Retrieval}-{Augmented} {Generation} for {Personalized} {Databases}},
	url = {https://www.mdpi.com/2076-3417/14/17/7995},
	abstract = {… A well-established semantic space is required for employing RAG to compensate for LLM hallucinations and ensure that appropriate and accurate answers are retrieved by the LLM …},
	journal = {Applied Sciences},
	author = {Byun, J. and Kim, B. and Cha, K. A. and Lee, E.},
	year = {2024},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {10 cites: https://scholar.google.com/scholar?cites=15014009244531370888\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{singh_chunkrag_2024,
	title = {Chunkrag: {Novel} llm-chunk filtering method for rag systems},
	url = {https://arxiv.org/abs/2410.19572},
	abstract = {… We introduced ChunkRAG, an LLM-driven chunk filtering method that enhances retrieval-augmented generation precision and factuality through dynamic greedy chunk aggregation. …},
	journal = {arXiv preprint arXiv …},
	author = {Singh, I. S. and Aggarwal, R. and Allahverdiyev, I. and Taha, M. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {14 cites: https://scholar.google.com/scholar?cites=9960157184735969752\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tonmoy_comprehensive_2024,
	title = {A comprehensive survey of hallucination mitigation techniques in large language models},
	url = {https://www.amanchadha.com/research/2401.01313.pdf},
	abstract = {… In essence, the contributions of this paper to the realm of LLM hallucination are threefold: … RAG effectively mitigates the issue of hallucination in LLMs by generating responses that are …},
	journal = {arXiv preprint arXiv …},
	author = {Tonmoy, S. and Zaman, S. M. and Jain, V. and Rani, A. and {...}},
	year = {2024},
	note = {Publisher: amanchadha.com
Type: PDF},
	annote = {541 cites: https://scholar.google.com/scholar?cites=13475689179453642140\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cheng_remoterag_2024,
	title = {{RemoteRAG}: {A} {Privacy}-{Preserving} {LLM} {Cloud} {RAG} {Service}},
	url = {https://arxiv.org/abs/2412.12775},
	abstract = {… into the context of prompts to improve the output of LLM (Izacard and Grave… LLM to provide answers with credible literature makes RAG an important technique in the application of LLM, …},
	journal = {arXiv preprint arXiv …},
	author = {Cheng, Y. and Zhang, L. and Wang, J. and Yuan, M. and Yao, Y.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=7162104873334849013\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhu_radio_2025,
	title = {Radio: {Real}-time hallucination detection with contextual index optimized query formulation for dynamic retrieval augmented generation},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/34809},
	abstract = {… enhanced real-time hallucination detection approach for triggering retrieval within dynamic RAG frameworks which takes into … The woRAG means the LLM does not apply any RAG. SR-…},
	journal = {Proceedings of the AAAI …},
	author = {Zhu, J. and Guo, H. and Shi, W. and Chen, Z. and Meo, P. De},
	year = {2025},
	note = {Publisher: ojs.aaai.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=7957615375470248687\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_credible_2025,
	title = {Credible plan-driven rag method for multi-hop question answering},
	url = {https://arxiv.org/abs/2504.16787},
	abstract = {… For example, RAP [39] establishes a dual-role framework in which a large language model (LLM) functions as a world model and a reasoning agent. During the reasoning process, the …},
	journal = {arXiv preprint arXiv …},
	author = {Zhang, N. and Zhang, C. and Tan, Z. and Yang, X. and Deng, W. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=9348010089581716414\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ren_retrieval-augmented_2025,
	title = {Retrieval-{Augmented} {Generation}-aided causal identification of aviation accidents: {A} large language model methodology},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417425009285},
	abstract = {… This paper proposed a novel Retrieval-Augmented Generation (RAG)-aided model to assist in identifying the causes of aviation safety incidents. The model consists of a retrieval …},
	journal = {Expert Systems with Applications},
	author = {Ren, T. and Zhang, Z. and Jia, B. and Zhang, S.},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {5 cites: https://scholar.google.com/scholar?cites=1565894628534438289\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhao_optimizing_2024,
	title = {Optimizing {LLM} based retrieval augmented generation pipelines in the financial domain},
	url = {https://aclanthology.org/2024.naacl-industry.23/},
	abstract = {… Instruction Following Ability Practical RAG deployments typically require the LLM returns answer in a specific language style and may require citations in certain structured format that …},
	journal = {Proceedings of the …},
	author = {Zhao, Y. and Singh, P. and Bhathena, H. and Ramos, B. and {...}},
	year = {2024},
	note = {Publisher: aclanthology.org},
	annote = {20 cites: https://scholar.google.com/scholar?cites=2946122530125876629\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{finsas_optimizing_2024,
	title = {Optimizing rag systems for technical support with llm-based relevance feedback and multi-agent patterns},
	url = {https://ntnuopen.ntnu.no/ntnu-xmlui/handle/11250/3160478},
	abstract = {… 3.5 we examine studies on mitigating hallucination in LLMs and multi-agent LLM design patterns, … current methods for evaluating LLM-based systems, including RAG-specific evaluation …},
	publisher = {ntnuopen.ntnu.no},
	author = {Finsås, M. and Maksim, J.},
	year = {2024},
	annote = {8 cites: https://scholar.google.com/scholar?cites=17412559342440855559\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bahaj_asthmabot_2024,
	title = {{AsthmaBot}: {Multi}-modal, {Multi}-{Lingual} {Retrieval} {Augmented} {Generation} {For} {Asthma} {Patient} {Support}},
	url = {https://arxiv.org/abs/2409.15815},
	abstract = {… from factual sources to augment the limited knowledge of the LLM and increase the likelihood of having a factual … We used the Google Gemini LLM to infer the results of different queries. …},
	journal = {arXiv preprint arXiv:2409.15815},
	author = {Bahaj, A. and Ghogho, M.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=8161179461907913446\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhao_towards_2024,
	title = {Towards understanding retrieval accuracy and prompt quality in rag systems},
	url = {https://arxiv.org/abs/2411.19463},
	abstract = {… We also observed that higher LLM confidence (perplexity) aligned with higher retrieval … In this paper, our study of LLMdriven RAG system design offers the first exploratory un…},
	journal = {arXiv preprint arXiv …},
	author = {Zhao, S. and Huang, Y. and Song, J. and Wang, Z. and Wan, C. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {14 cites: https://scholar.google.com/scholar?cites=7949541182645464692\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kumar_overcoming_2024,
	title = {Overcoming llm challenges using rag-driven precision in coffee leaf disease remediation},
	url = {https://ieeexplore.ieee.org/abstract/document/10543859/},
	abstract = {… Serving as a dynamic bridge, RAG minimizes the risk of hallucination, enhancing GenAI application … RAG’s role in overcoming LLM limitations is central to our research, promising a …},
	journal = {… in Computer Science …},
	author = {Kumar, S. S. and Khan, AKMA and Banday, I. A. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {18 cites: https://scholar.google.com/scholar?cites=12048505972583572951\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{aquino_rag_2025,
	title = {From {RAG} to {Multi}-{Agent} {Systems}: {A} {Survey} of {Modern} {Approaches} in {LLM} {Development}},
	url = {https://www.preprints.org/frontend/manuscript/12d92f418fc17b4bd3e6b6144acf951c/download_pub},
	abstract = {… in LLM development, ranging from traditional RAG techniques to … progression from traditional RAG to graph-based RAG, and … hallucinations and factual inconsistencies, diminishing user …},
	publisher = {preprints.org},
	author = {Aquino, GA e and Azevedo, NS de and Okimoto, L. Y. S. and {...}},
	year = {2025},
	note = {Type: PDF},
	annote = {4 cites: https://scholar.google.com/scholar?cites=17214927981069975766\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ren_large_2025,
	title = {Large language model for interpreting research policy using adaptive two-stage retrieval augmented fine-tuning method},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417425009522},
	abstract = {… However, current large language model (LLM)-based systems often generate responses … (AT-RAFT) method, a novel LLM-based approach specifically designed for science policy …},
	journal = {Expert Systems with Applications},
	author = {Ren, R. and Ma, J. and Zheng, Z.},
	year = {2025},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {4 cites: https://scholar.google.com/scholar?cites=13646082007691982471\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{martinon_towards_2025,
	title = {Towards a rigorous evaluation of {RAG} systems: the challenge of due diligence},
	url = {https://arxiv.org/abs/2507.21753},
	abstract = {… This study evaluates a RAG system used in due diligence for an investment fund. We … and LLM-Judge annotations to identify system failures, like hallucinations, off-topic, failed citations, …},
	journal = {arXiv preprint arXiv …},
	author = {Martinon, G. and Brionne, AL de and Bohard, J. and Lojou, A. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=2851645398410018955\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{dakshit_faculty_2024,
	title = {Faculty perspectives on the potential of rag in computer science higher education},
	url = {https://dl.acm.org/doi/abs/10.1145/3686852.3686864},
	doi = {10.1145/3686852.3686864},
	abstract = {… This study is the first to gather faculty feedback on the application of LLM-based RAG in … mented Generation (RAG), which has the added benefit of curbing hallucinations and limiting …},
	journal = {Proceedings of the 25th Annual Conference on …},
	author = {Dakshit, S.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {14 cites: https://scholar.google.com/scholar?cites=975943729380883620\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{putri_simplification_2024,
	title = {Simplification of {Embedding} {Process} in {Retrieval} {Augmented} {Generation} for {Optimizing} {Question} {Answering} {Chatbot} {Model}},
	url = {https://ieeexplore.ieee.org/abstract/document/10862926/},
	abstract = {… In this study, a QAC model is built using a Large Language Model (LLM) and the … can mitigate hallucinations in LLM. This research employs a Retrieval Augmented Generation (RAG) …},
	journal = {2024 IEEE International …},
	author = {Putri, M. R. and Husodo, A. Y. and Irmawati, B.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=6971644402727595315\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xu_development_2025,
	title = {Development and evaluation of a retrieval-augmented large language model framework for enhancing endodontic education},
	url = {https://www.sciencedirect.com/science/article/pii/S1386505625002230},
	abstract = {… impact of LLM technologies throughout the medical domain. … generation of hallucinations, instances where LLM produce … -KB platform with the RAG framework, combining the reasoning …},
	journal = {International Journal of …},
	author = {Xu, X. and Liu, S. and Zhu, L. and Long, Y. and Zeng, Y. and Lu, X. and Li, J. and {...}},
	year = {2025},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {1 cites: https://scholar.google.com/scholar?cites=13933694948271163285\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cuconasu_power_2024,
	title = {The power of noise: {Redefining} retrieval for rag systems},
	url = {https://dl.acm.org/doi/abs/10.1145/3626772.3657834},
	doi = {10.1145/3626772.3657834},
	abstract = {… be memorized in the LLM. We argue here that the retrieval component of RAG systems, be it … RAG is primarily designed to improve factual accuracy by providing the model access to …},
	journal = {Proceedings of the 47th …},
	author = {Cuconasu, F. and Trappolini, G. and Siciliano, F. and Filice, S. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {301 cites: https://scholar.google.com/scholar?cites=10874625275768061502\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{fayyazi_advancing_2024,
	title = {Advancing {TTP} analysis: {Harnessing} the power of large language models with retrieval augmented generation},
	url = {https://ieeexplore.ieee.org/abstract/document/10918057/},
	abstract = {… shown to be prone to hallucination in their generated responses [… and to provide factual knowledge, RAG was introduced [15]. … We design our d-LLM with RAG with an attempt to mimic a …},
	journal = {2024 Annual Computer …},
	author = {Fayyazi, R. and Taghdimi, R. and Yang, S. J.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {14 cites: https://scholar.google.com/scholar?cites=4655901728364383311\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{khan_developing_2024,
	title = {Developing retrieval augmented generation ({RAG}) based {LLM} systems from {PDFs}: an experience report},
	url = {https://arxiv.org/abs/2410.15944},
	abstract = {… RAG models enhance the factual grounding of their outputs from the up-to-date knowledge. A generic workflow of Retrieval Augmented Generation (RAG… knowledge, the RAG process is …},
	journal = {arXiv preprint arXiv …},
	author = {Khan, A. A. and Hasan, M. T. and Kemell, K. K. and Rasku, J. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {18 cites: https://scholar.google.com/scholar?cites=16567028617531744047\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yang_im-rag_2024,
	title = {Im-rag: {Multi}-round retrieval-augmented generation through learning inner monologues},
	url = {https://dl.acm.org/doi/abs/10.1145/3626772.3657760},
	doi = {10.1145/3626772.3657760},
	abstract = {… LLM-centric approach, IM-RAG, that integrates IR systems with LLMs to support multi-round RAG … by retrieving timely and relevant information, enhancing the factuality of responses. The …},
	journal = {Proceedings of the 47th …},
	author = {Yang, D. and Rao, J. and Chen, K. and Guo, X. and Zhang, Y. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {52 cites: https://scholar.google.com/scholar?cites=11461821700742920501\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{liu_detecting_2025,
	title = {Detecting emergencies in patient portal messages using large language models and knowledge graph-based retrieval-augmented generation},
	journal = {Journal of the …},
	author = {Liu, S. and Wright, A. P. and McCoy, A. B. and Huang, S. S. and {...}},
	year = {2025},
	note = {Publisher: Oxford Academic
Type: CITATION},
	annote = {4 cites: https://scholar.google.com/scholar?cites=13513919713096629003\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhu_graph-based_2025,
	title = {Graph-based {Approaches} and {Functionalities} in {Retrieval}-{Augmented} {Generation}: {A} {Comprehensive} {Survey}},
	url = {https://arxiv.org/abs/2504.10499},
	abstract = {… LLM capabilities but also provide actionable strategies for leveraging graph expertise to advance RAG … in many RAG systems by serving as structured repositories of factual knowledge. …},
	journal = {arXiv preprint arXiv …},
	author = {Zhu, Z. and Huang, T. and Wang, K. and Ye, J. and Chen, X. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=10347752080952277927\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{baumann_combining_2024,
	title = {Combining retrieval-augmented generation and few-shot learning for model synthesis of uncommon dsls},
	url = {https://dl.gi.de/items/2e7293bb-7e2b-4682-9c45-af6022ad9fa5},
	abstract = {… LLM’s context. Furthermore, we employ a technique known as ’retrieval-augmented generation’ (RAG) to assist the LLM … It has been used as way to mitigate LLM hallucinations [To24], …},
	journal = {… 2024 Satellite Events},
	author = {Baumann, N. and Diaz, J. S. and Michael, J. and Netz, L. and Nqiri, H. and {...}},
	year = {2024},
	note = {Publisher: dl.gi.de},
	annote = {19 cites: https://scholar.google.com/scholar?cites=8586252253174504187\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{clop_backdoored_2024,
	title = {Backdoored retrievers for prompt injection attacks on retrieval augmented generation of large language models},
	url = {https://arxiv.org/abs/2410.14479},
	abstract = {… LLM (3), which generates an answer based on the retrieved content (4). Since the LLM’s answer is grounded in recent and factual … understanding of LLM vulnerabilities to RAG prompt …},
	journal = {arXiv preprint arXiv:2410.14479},
	author = {Clop, C. and Teglia, Y.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {12 cites: https://scholar.google.com/scholar?cites=8415013114330953651\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhu_realm_2024,
	title = {Realm: {Rag}-driven enhancement of multimodal electronic health records analysis via large language models},
	url = {https://arxiv.org/abs/2402.07016},
	abstract = {… REALM, a Retrieval-Augmented Generation (RAG) driven … Firstly, we apply Large Language Model (LLM) to encode … Entities Refinement: To mitigate hallucination issues of LLM, we …},
	journal = {arXiv preprint arXiv …},
	author = {Zhu, Y. and Ren, C. and Xie, S. and Liu, S. and Ji, H. and Wang, Z. and Sun, T. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {60 cites: https://scholar.google.com/scholar?cites=2162020969134326003\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kamath_retrieval-augmented_2024,
	title = {Retrieval-augmented generation},
	url = {https://link.springer.com/content/pdf/10.1007/978-3-031-65647-7_7.pdf},
	doi = {10.1007/978-3-031-65647-7_7},
	abstract = {… This is the correct answer, which ChatGPT has now been able to report due to our RAG … , RAG systems may be as likely to hallucinate as normal LLM calls; to this end, RAG systems …},
	journal = {Large Language Models: A …},
	author = {Kamath, U. and Keenan, K. and Somers, G. and {...}},
	year = {2024},
	note = {Publisher: Springer},
	annote = {11 cites: https://scholar.google.com/scholar?cites=11067625297611852616\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{he_g-retriever_2024,
	title = {G-retriever: {Retrieval}-augmented generation for textual graph understanding and question answering},
	url = {https://proceedings.neurips.cc/paper_files/paper/2024/hash/efaf1c9726648c8ba363a5c927440529-Abstract-Conference.html},
	abstract = {… the LLM’s pretrained language capabilities, we freeze the LLM and use a soft prompting approach on the output of the GNN. Our RAG-based design mitigates hallucinations … the LLM’s …},
	journal = {Advances in …},
	author = {He, X. and Tian, Y. and Sun, Y. and Chawla, N. and {...}},
	year = {2024},
	note = {Publisher: proceedings.neurips.cc},
	annote = {320 cites: https://scholar.google.com/scholar?cites=11009481314175481361\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{dong_understand_2025,
	title = {Understand what {LLM} needs: {Dual} preference alignment for retrieval-augmented generation},
	url = {https://dl.acm.org/doi/abs/10.1145/3696410.3714717},
	doi = {10.1145/3696410.3714717},
	abstract = {… ) has effectively mitigated the hallucination problem of large language models (LLMs). How… developing a reliable RAG system. To address this issue, we propose DPARAG, a universal …},
	journal = {Proceedings of the ACM …},
	author = {Dong, G. and Zhu, Y. and Zhang, C. and Wang, Z. and Wen, J. R. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {50 cites: https://scholar.google.com/scholar?cites=4738668290193574246\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jayawardena_context_2025,
	title = {Context {Driven} {Multi}-query {Resolution} {Using} {LLM}-{RAG} to {Support} the {Revision} of {Explainability} {Needs}},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-96559-3_8},
	doi = {10.1007/978-3-031-96559-3_8},
	abstract = {… Explainable Artificial Intelligence (XAI) plays a key role in ensuring that we can place trust in AI decisions when they impact crucial areas, such as predicting the presence of a tumour [2]…},
	journal = {… Conference on Case …},
	author = {Jayawardena, L. and Liret, A. and Wiratunga, N. and Nkisi-Orji, I. and {...}},
	year = {2025},
	note = {Publisher: Springer},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{huang_embedding-informed_2024,
	title = {Embedding-{Informed} {Adaptive} {Retrieval}-{Augmented} {Generation} of {Large} {Language} {Models}},
	url = {https://arxiv.org/abs/2404.03514},
	abstract = {… Our approach reveals higher confidence in the LLM’s intrinsic knowledge than PARAG, resulting in fewer retrievals and more precise answers, demonstrating our method’s superior …},
	journal = {arXiv preprint arXiv …},
	author = {Huang, C. and Xia, Y. and Wang, R. and Xie, K. and Yu, T. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=16171808597036050041\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{voznyuk_advacheck_2025,
	title = {Advacheck at semeval-2025 task 3: {Combining} ner and rag to spot hallucinations in llm answers},
	url = {https://aclanthology.org/2025.semeval-1.160/},
	abstract = {… from LLM judges into initial answer. Through this method, we aim to detect and fix factual hallucinations from the text and thus contribute to ongoing efforts in hallucination detection and …},
	journal = {Proceedings of the 19th …},
	author = {Voznyuk, A. and Gritsai, G. and Grabovoy, A.},
	year = {2025},
	note = {Publisher: aclanthology.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=12851096267899072150\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{saxena_minimizing_2023,
	title = {Minimizing factual inconsistency and hallucination in large language models},
	url = {https://arxiv.org/abs/2311.13878},
	abstract = {… hallucination into input, context, and factconflicting. In particular, fact-conflicting hallucination … Existing approaches such as Retrieval-Augmented Generation (RAG) [10] augment LLM …},
	journal = {arXiv preprint arXiv …},
	author = {Saxena, S. and Prasad, S. and Prakash, M. V. and Shankar, A. and {...}},
	year = {2023},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=10788494724639521549\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{darji_enhancing_2024,
	title = {Enhancing financial risk analysis using rag-based large language models},
	url = {https://ieeexplore.ieee.org/abstract/document/10841711/},
	abstract = {… Zhang, “Enhancing LLM factual accuracy with RAG to counter hallucinations: A case study on domain-specific queries in private knowledge-bases,” arXiv preprint arXiv:2403.10446, …},
	journal = {2024 3rd …},
	author = {Darji, A. and Kheni, F. and Chodvadia, D. and Goel, P. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=8051177687116835773\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{maharana_retrieval_2025,
	title = {Retrieval augmented generation for building datasets from scientiﬁc literature.},
	url = {https://iopscience.iop.org/article/10.1088/2515-7639/ade1fa/meta},
	doi = {10.1088/2515-7639/ade1fa},
	abstract = {… within this article, their full citation and copyright line may not be … once published for full citation and copyright details, as … In this work we implement a RAG-LLM based approach to …},
	journal = {Journal of Physics: Materials},
	author = {Maharana, P. R. and Verma, A. and Joshi, K.},
	year = {2025},
	note = {Publisher: iopscience.iop.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=16496559283365918695\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bianchini_retrieval-augmented_2025,
	title = {Retrieval-{Augmented} {Generation}},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-92285-5_7},
	doi = {10.1007/978-3-031-92285-5_7},
	abstract = {… to cross-check factual accuracy. When an LLM powered by RAG receives a prompt or … Instead of generating an answer solely from its pre-trained language patterns, the LLM uses …},
	journal = {Engineering Information Systems with Large Language …},
	author = {Bianchini, F.},
	year = {2025},
	note = {Publisher: Springer},
	annote = {2 cites: https://scholar.google.com/scholar?cites=8459748252727557230\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kriman_measuring_2024,
	title = {Measuring text summarization factuality using atomic facts entailment metrics in the context of retrieval augmented generation},
	url = {https://arxiv.org/abs/2408.15171},
	abstract = {… In this section, we describe our approach for evaluating the factuality of summary texts with respect to their source texts. Our methodology leverages a large language model (LLM) to …},
	journal = {arXiv preprint arXiv:2408.15171},
	author = {Kriman, N. E.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=2668275073030177588\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{su_dynamic_2025,
	title = {Dynamic and parametric retrieval-augmented generation},
	url = {https://dl.acm.org/doi/abs/10.1145/3726302.3731692},
	doi = {10.1145/3726302.3731692},
	abstract = {… Dynamic RAG adaptively determines when and what to retrieve during the LLM’s … and even larger LLMs lacking retrieval capabilities, especially on tasks that require precise factual …},
	journal = {… of the 48th International ACM SIGIR …},
	author = {Su, W. and Ai, Q. and Zhan, J. and Dong, Q. and Liu, Y.},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=4874549117360105238\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{maruyama_retrieval-augmented_2025,
	title = {Retrieval-augmented generation enhances large language model performance on the {Japanese} orthopedic board examination},
	url = {https://www.sciencedirect.com/science/article/pii/S0949265825000776},
	abstract = {… The integration of Retrieval-Augmented Generation (RAG) has been proposed to improve these models by reducing hallucinations and enhancing domain-specific information access. …},
	journal = {Journal of Orthopaedic …},
	author = {Maruyama, J. and Maki, S. and Furuya, T. and Nagashima, Y. and {...}},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhou_gastrobot_2024,
	title = {{GastroBot}: a {Chinese} gastrointestinal disease chatbot based on the retrieval-augmented generation},
	url = {https://www.frontiersin.org/articles/10.3389/fmed.2024.1392555/full},
	doi = {10.3389/fmed.2024.1392555},
	abstract = {… To gauge credibility, we initially employ LLM to extract a set of statements S a s q . If the … Particularly, our evaluation of answer relevance does not account for factual accuracy but …},
	journal = {Frontiers in …},
	author = {Zhou, Q. and Liu, C. and Duan, Y. and Sun, K. and Li, Y. and Kan, H. and Gu, Z. and {...}},
	year = {2024},
	note = {Publisher: frontiersin.org},
	annote = {30 cites: https://scholar.google.com/scholar?cites=13353516283902828638\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{choi_empowering_2025,
	title = {Empowering {PET} imaging reporting with retrieval-augmented large language models and reading reports database: a pilot single center study},
	url = {https://link.springer.com/article/10.1007/s00259-025-07101-9},
	doi = {10.1007/s00259-025-07101-9},
	abstract = {… RAG on the performance of the LLM, we compared the appropriateness scores of the LLM with and without RAG … The introduction of RAG not only reduces the risk of hallucinations but …},
	journal = {European Journal of Nuclear Medicine …},
	author = {Choi, H. and Lee, D. and Kang, Y. and Suh, M.},
	year = {2025},
	note = {Publisher: Springer
Type: HTML},
	annote = {8 cites: https://scholar.google.com/scholar?cites=6528359225040740960\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{peng_graph_2024,
	title = {Graph retrieval-augmented generation: {A} survey},
	url = {https://arxiv.org/abs/2408.08921},
	abstract = {… knowledge base, RAG refines LLM outputs, effectively mitigating issues such as “hallucination”, lack … entities in databases presents challenges for RAG systems. In response, GraphRAG …},
	journal = {arXiv preprint arXiv …},
	author = {Peng, B. and Zhu, Y. and Liu, Y. and Bo, X. and Shi, H. and Hong, C. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {288 cites: https://scholar.google.com/scholar?cites=9398758468741961315\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{feridooni_development_2024,
	title = {Development of a vascular surgery-specific artificial intelligence chat interface using retrieval-augmented generation: {VASC}. {AI}, a specialized vascular …},
	url = {https://www.sciencedirect.com/science/article/pii/S2949912724000850},
	abstract = {… of RAG include handling extensive documents to provide grounding knowledge and in turn decreasing neural hallucinations by narrowing the LLM's … (B) Our RAG LLM model enhances …},
	journal = {JVS-Vascular …},
	author = {Feridooni, T. and Javidan, A. P. and Mahmood, D. N. and Gomes, Z. and {...}},
	year = {2024},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {5 cites: https://scholar.google.com/scholar?cites=11998546800793160878\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jeong_retrieval-augmented_2024,
	title = {Retrieval-{Augmented} {Generation}-based {Question} {Answering} {Technology} for {Construction} {Safety}},
	journal = {International …},
	author = {Jeong, M. and Kim, T. and Kim, S. and Kim, H.},
	year = {2024},
	note = {Publisher: Korea Institute of Construction …
Type: CITATION},
	annote = {1 cites: https://scholar.google.com/scholar?cites=2909835104097181662\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{liu_ctrla_2024,
	title = {{CtrlA}: {Adaptive} {Retrieval}-{Augmented} {Generation} via {Inherent} {Control}},
	url = {https://arxiv.org/abs/2405.18727},
	abstract = {… LLM toward honesty and monitor its confidence, we extract features aligned with the directions of honesty and confidence within LLM’s … —we can shift the LLM’s representation space to …},
	journal = {arXiv preprint arXiv …},
	author = {Liu, H. and Zhang, H. and Guo, Z. and Wang, J. and Dong, K. and Li, X. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=1633848296597621469\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lee_performance_2024,
	title = {Performance comparison of retrieval-augmented generation and fine-tuned large language models for construction safety management knowledge retrieval},
	url = {https://www.sciencedirect.com/science/article/pii/S092658052400582X},
	abstract = {… fine-tuned LLM was fine-… RAG model improving by 21.5 \% and the fine-tuned LLM by 26 \%. The findings highlight the relative strengths and weaknesses of the RAG and fine-tuned LLM …},
	journal = {Automation in Construction},
	author = {Lee, J. and Ahn, S. and Kim, D. and Kim, D.},
	year = {2024},
	note = {Publisher: Elsevier},
	annote = {44 cites: https://scholar.google.com/scholar?cites=13326944757969914235\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sharma_retrieval_2024,
	title = {Retrieval augmented generation for domain-specific question answering},
	url = {https://arxiv.org/abs/2404.14760},
	abstract = {… -aware finetuning of a Large Language model and use a query … Our overall approach reduces hallucinations during genera… the source credibility (Helpx {\textgreater}Community {\textgreater}YouTube {\textgreater}LLM-…},
	journal = {arXiv preprint arXiv …},
	author = {Sharma, S. and Yoon, D. S. and Dernoncourt, F. and Sultania, D. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {21 cites: https://scholar.google.com/scholar?cites=7264574267791379971\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{godinez_hysemrag_2025,
	title = {{HySemRAG}: {A} {Hybrid} {Semantic} {Retrieval}-{Augmented} {Generation} {Framework} for {Automated} {Literature} {Synthesis} and {Methodological} {Gap} {Analysis}},
	url = {https://arxiv.org/abs/2508.05666},
	abstract = {… citation data in the context, the system prevents the Large Language Model from generating its own citations, … limitations of standard RAG architectures, namely noisy retrieval and LLM …},
	journal = {arXiv preprint arXiv:2508.05666},
	author = {Godinez, A.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=7763792149537780809\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yuan_hybrid_2024,
	title = {A hybrid {RAG} system with comprehensive enhancement on complex reasoning},
	url = {https://arxiv.org/abs/2408.05141},
	abstract = {… hallucinations by integrating external knowledge bases. In this paper, we introduce a hybrid RAG … attribute predictors to reduce hallucinations, conducted LLM Knowledge Extractor and …},
	journal = {arXiv preprint arXiv …},
	author = {Yuan, Y. and Liu, C. and Yuan, J. and Sun, G. and Li, S. and Zhang, M.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {20 cites: https://scholar.google.com/scholar?cites=8311270380405311169\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cohn_personalizing_2025,
	title = {Personalizing {Student}-{Agent} {Interactions} {Using} {Log}-{Contextualized} {Retrieval} {Augmented} {Generation} ({RAG})},
	url = {https://arxiv.org/abs/2505.17238},
	abstract = {… hallucinations can undermine confidence, trust, and instructional value. Retrieval-augmented generation (RAG) grounds LLM … log-contextualized RAG (LC-RAG), which enhances RAG …},
	journal = {arXiv preprint arXiv …},
	author = {Cohn, C. and Rayala, S. and Snyder, C. and Fonteles, J. and Jain, S. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=2598256593245020438\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_improving_2025,
	title = {Improving knowledge management in building engineering with hybrid retrieval-augmented generation framework},
	url = {https://www.sciencedirect.com/science/article/pii/S2352710225004255},
	abstract = {… by several factors, including hallucinations, a lack of domain-… develop an improved retrieval augmented generation (RAG) … demonstrates the potential of LLM-RAG-based solutions for …},
	journal = {Journal of Building Engineering},
	author = {Wang, Z. and Liu, Z. and Lu, W. and Jia, L.},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {11 cites: https://scholar.google.com/scholar?cites=13170189091662281223\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{roychowdhury_confusedpilot_2024,
	title = {Confusedpilot: {Confused} deputy risks in rag-based llms},
	url = {https://arxiv.org/abs/2408.04870},
	abstract = {… of security vulnerabilities of RAG systems that confuse Copilot … in RAG, corrupting the responses generated by the LLM. … how malicious actors can exploit trust and shared access to …},
	journal = {arXiv preprint arXiv …},
	author = {RoyChowdhury, A. and Luo, M. and Sahu, P. and Banerjee, S. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {14 cites: https://scholar.google.com/scholar?cites=17287955363847516369\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ji_rag-rlrc-laysum_2024,
	title = {Rag-rlrc-laysum at biolaysumm: {Integrating} retrieval-augmented generation and readability control for layman summarization of biomedical texts},
	url = {https://arxiv.org/abs/2405.13179},
	abstract = {… (2023), which also serves as our baseline LLM. We aim to create … The RAG-RLRC-LaySum framework effectively simplifies complex biomedical texts, enhancing readability and factual …},
	journal = {arXiv preprint arXiv …},
	author = {Ji, Y. and Li, Z. and Meng, R. and Sivarajkumar, S. and Wang, Y. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {25 cites: https://scholar.google.com/scholar?cites=13856275050802896692\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{alinejad_evaluating_2024,
	title = {Evaluating the retrieval component in llm-based question answering systems},
	url = {https://arxiv.org/abs/2406.06458},
	abstract = {… erating inaccurate responses or hallucinations. Although the … retrievers in Retrieval-Augmented Generation (RAG)-based … well as potential errors and hallucinations in their responses. …},
	journal = {arXiv preprint arXiv:2406.06458},
	author = {Alinejad, A. and Kumar, K. and Vahdat, A.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {14 cites: https://scholar.google.com/scholar?cites=13482074879160505508\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{ammann_analysis_2024,
	title = {Analysis of {Risks} and {Mitigation} {Strategies} in {RAG}},
	publisher = {OST Ostschweizer Fachhochschule},
	author = {Ammann, L. and Ott, S.},
	year = {2024},
	note = {Type: CITATION},
	annote = {1 cites: https://scholar.google.com/scholar?cites=10191659403262404233\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{arslan_survey_2024,
	title = {A {Survey} on {RAG} with {LLMs}},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050924021860},
	abstract = {… generation, significantly reducing the risk of hallucinations and improving the overall quality of … how RAG integration with the LLM handles queries that fall outside the scope of the LLM’s …},
	journal = {Procedia computer science},
	author = {Arslan, M. and Ghanem, H. and Munawar, S. and Cruz, C.},
	year = {2024},
	note = {Publisher: Elsevier},
	annote = {100 cites: https://scholar.google.com/scholar?cites=12935880735755204425\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{shin_thyro-genai_2025,
	title = {Thyro-{GenAI}: {A} {Chatbot} {Using} {Retrieval}-{Augmented} {Generative} {Models} for {Personalized} {Thyroid} {Disease} {Management}},
	url = {https://www.mdpi.com/2077-0383/14/7/2450},
	abstract = {… , ChatGPT-4o [27] generates a final answer with citations to the … RAG has been shown to significantly enhance LLM … RAG-based LLMs have demonstrated improved accuracy and …},
	journal = {Journal of Clinical …},
	author = {Shin, M. and Song, J. and Kim, M. G. and Yu, H. W. and Choe, E. K. and {...}},
	year = {2025},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {5 cites: https://scholar.google.com/scholar?cites=6096644496500363038\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chandrasekhar_amgpt_2024,
	title = {{AMGPT}: a large language model for contextual querying in additive manufacturing},
	url = {https://www.sciencedirect.com/science/article/pii/S2772369024000409},
	abstract = {… We introduce “AMGPT”, a specialized LLM text generator … Hugging Face in a Retrieval-Augmented Generation (RAG) setup, … embeddings from the RAG setup accelerate response times …},
	journal = {Additive Manufacturing …},
	author = {Chandrasekhar, A. and Chan, J. and Ogoke, F. and {...}},
	year = {2024},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {37 cites: https://scholar.google.com/scholar?cites=3309166148886337902\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{henkel_retrieval-augmented_2024,
	title = {Retrieval-augmented generation to improve math question-answering: {Trade}-offs between groundedness and human preference},
	url = {https://educationaldatamining.org/edm2024/proceedings/2024.EDM-short-papers.28/},
	abstract = {… We identified 51 factual and conceptual questions that have sufficient context to be … RAG implementation - We adopted a chatbot context as the underlying LLM, generating all …},
	journal = {Proceedings of the …},
	author = {Henkel, O. and Levonian, Z. and Li, C. and {...}},
	year = {2024},
	note = {Publisher: educationaldatamining.org
Type: HTML},
	annote = {16 cites: https://scholar.google.com/scholar?cites=15326090975110523127\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{akbar_retrieval_2025,
	title = {Retrieval {Augmented} {Generation}-based {Large} {Language} {Models} for {Bridging} {Transportation} {Cybersecurity} {Legal} {Knowledge} {Gaps}},
	url = {https://arxiv.org/abs/2505.18426},
	abstract = {… LLM hallucination in legal contexts is critical due to: 1) the … Specifically, RAG mitigates LLM hallucinations by supplying … To this end, we develop a RAG-based LLM capable of …},
	journal = {arXiv preprint arXiv …},
	author = {Akbar, K. A. and Uddin, M. N. and Khan, L. and Hockstad, T. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ridder_hallurag_2024,
	title = {The {HalluRAG} {Dataset}: {Detecting} {Closed}-{Domain} {Hallucinations} in {RAG} {Applications} {Using} an {LLM}'s {Internal} {States}},
	url = {https://arxiv.org/abs/2412.17056},
	abstract = {… We aim to train an MLP to identify sentence-level hallucinations by analyzing specific internal states in RAG applications. In particular, we focus on closed-domain hallucinations, which …},
	journal = {arXiv preprint arXiv:2412.17056},
	author = {Ridder, F. and Schilling, M.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=13113888428879016281\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mandikal_ancient_2024,
	title = {Ancient {Wisdom}, {Modern} {Tools}: {Exploring} {Retrieval}-{Augmented} {LLMs} for {Ancient} {Indian} {Philosophy}},
	url = {https://arxiv.org/abs/2408.11903},
	abstract = {… is often hindered by factual inaccuracies and hallucinations, … potential of retrieval-augmented generation (RAG) models for … benchmark a RAG model against a standard, non-RAG LLM, …},
	journal = {arXiv preprint arXiv:2408.11903},
	author = {Mandikal, P.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=12834392828594673565\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chandrasekhar_nanogpt_2025,
	title = {{NANOGPT}: {A} {Query}-{Driven} {Large} {Language} {Model} {Retrieval}-{Augmented} {Generation} {System} for {Nanotechnology} {Research}},
	url = {https://arxiv.org/abs/2502.20541},
	abstract = {… , RAG significantly reduces the likelihood of hallucinations and inaccuracies compared to raw LLM … The LLM-RAG system presented in this work utilizes the LLaMA3.1-8b-Instruct model, …},
	journal = {arXiv preprint arXiv …},
	author = {Chandrasekhar, A. and Farimani, O. B. and Ajenifujah, O. T. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=1294977258798638154\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mei_survey_2025,
	title = {A survey of multimodal retrieval-augmented generation},
	url = {https://arxiv.org/abs/2504.08748},
	abstract = {… This approach enhances response accuracy and timeliness, particularly in domain-specific contexts, while reducing the risk of hallucinations common in LLM outputs. In multi-turn …},
	journal = {arXiv preprint arXiv:2504.08748},
	author = {Mei, L. and Mo, S. and Yang, Z. and Chen, C.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {20 cites: https://scholar.google.com/scholar?cites=12587163728394399721\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{maklad_retrieval_2025,
	title = {Retrieval augmented generation based llm evaluation for protocol state machine inference with chain-of-thought reasoning},
	url = {https://link.springer.com/chapter/10.1007/978-981-96-6441-2_27},
	doi = {10.1007/978-981-96-6441-2_27},
	abstract = {… of a RAG-based agentic Large Language Model (LLM) … Our method leverages RAG and text embeddings in two stages… of such approach, improving LLM-based protocol fuzzing …},
	journal = {International Congress on …},
	author = {Maklad, Y. and Wael, F. and Elsersy, W. and Hamdi, A.},
	year = {2025},
	note = {Publisher: Springer},
	annote = {6 cites: https://scholar.google.com/scholar?cites=14222797000638419963\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{thakur_support_2025,
	title = {Support {Evaluation} for the {TREC} 2024 {RAG} {Track}: {Comparing} {Human} versus {LLM} {Judges}},
	url = {https://arxiv.org/abs/2504.15205},
	abstract = {… In the TREC 2024 RAG Track, we allowed participants to provide citations for up to 20 passages per answer sentence. To judge each sentence and its cited passage, our protocol …},
	journal = {arXiv preprint arXiv …},
	author = {Thakur, N. and Pradeep, R. and Upadhyay, S. and Campos, D. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=1707431804364473085\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{arasteh_radiorag_2025,
	title = {{RadioRAG}: {Online} {Retrieval}-augmented {Generation} for {Radiology} {Question} {Answering}},
	url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.240476},
	doi = {10.1148/ryai.240476},
	abstract = {… RAG (RadioRAG), an end-to-end framework that retrieves data from authoritative radiologic online sources in real-time. RAG … to improve LLM accuracy and factuality in radiology …},
	journal = {Radiology: Artificial …},
	author = {Arasteh, S. Tayebi and Lotfinia, M. and Bressem, K. and {...}},
	year = {2025},
	note = {Publisher: pubs.rsna.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=16839556953589713819\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{benfenati_retrieval-augmented_2024,
	title = {A retrieval-augmented generation application for question-answering in nutrigenetics domain},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050924025092},
	abstract = {… Large Language Model, circumventing the exhaustive model fine-tuning process. As a result, our RAG … Towards mitigating llm hallucination via self reflection, in: The 2023 Conference …},
	journal = {Procedia Computer …},
	author = {Benfenati, D. and Filippis, GM De and Rinaldi, A. M. and {...}},
	year = {2024},
	note = {Publisher: Elsevier},
	annote = {6 cites: https://scholar.google.com/scholar?cites=2732793661054491532\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mala_hybrid_2025,
	title = {Hybrid {Retrieval} for {Hallucination} {Mitigation} in {Large} {Language} {Models}: {A} {Comparative} {Analysis}},
	url = {https://arxiv.org/abs/2504.05324},
	abstract = {… We have also evaluated our hybrid RAG pipeline by comparing it with the baseline LLM(Llama-3-instruct-8B) model, the results are illustrated in Appendix B. The results emphasize the …},
	journal = {arXiv preprint arXiv:2504.05324},
	author = {Mala, C. S. and Gezici, G. and Giannotti, F.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=291813072125265646\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jiao_pr-attack_2025,
	title = {Pr-attack: {Coordinated} prompt-rag attacks on retrieval-augmented generation in large language models via bilevel optimization},
	url = {https://dl.acm.org/doi/abs/10.1145/3726302.3730058},
	doi = {10.1145/3726302.3730058},
	abstract = {… , thereby reducing hallucinations and enhancing the reliability of LLM outputs. RAG essentially consists of three key components [104], ie, knowledge database, retriever, and LLM. A …},
	journal = {Proceedings of the 48th International ACM …},
	author = {Jiao, Y. and Wang, X. and Yang, K.},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=13532083370638242789\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{thus_exploring_2024,
	title = {Exploring generative {AI} in higher education: a {RAG} system to enhance student engagement with scientific literature},
	url = {https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1474892/full},
	doi = {10.3389/fpsyg.2024.1474892},
	abstract = {… learning to an LLM is retrieval augmented generation (RAG), where hallucinations can be … A RAG system involves searching and retrieving documents that semantically match a …},
	journal = {Frontiers in Psychology},
	author = {Thüs, D. and Malone, S. and Brünken, R.},
	year = {2024},
	note = {Publisher: frontiersin.org
Type: HTML},
	annote = {45 cites: https://scholar.google.com/scholar?cites=15319297716073835585\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cherumanal_walert_2024,
	title = {Walert: putting conversational information seeking knowledge into action by building and evaluating a large language model-powered chatbot},
	url = {https://dl.acm.org/doi/abs/10.1145/3627508.3638309},
	doi = {10.1145/3627508.3638309},
	abstract = {… of an open-source LLM; (ii) monitoring the problem of hallucinations (ie, the introduction of … of LLM-based conversational systems [18]. Finally, we plan to deploy RAG approaches to …},
	journal = {Proceedings of the …},
	author = {Cherumanal, S. Pathiyan and Tian, L. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {12 cites: https://scholar.google.com/scholar?cites=18273048115208640381\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{shojaee_federated_2025,
	title = {Federated retrieval augmented generation for multi-product question answering},
	url = {https://arxiv.org/abs/2501.14998},
	abstract = {… RAG-QA approaches either query all domains indiscriminately, increasing computational costs and LLM hallucinations, … significantly boosts multi-product RAG-QA performance in terms …},
	journal = {arXiv preprint arXiv …},
	author = {Shojaee, P. and Harsha, S. S. and Luo, D. and Maharaj, A. and Yu, T. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=7294914577890576496\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{nikishina_creating_2024,
	title = {Creating a {Taxonomy} for {Retrieval} {Augmented} {Generation} {Applications}},
	url = {https://arxiv.org/abs/2408.02854},
	abstract = {… for RAG applications, illustrating how RAG can be systematically implemented to improve LLM … Those papers already comprise over 2000 citations, resulting in more than twenty-eight …},
	journal = {arXiv preprint arXiv …},
	author = {Nikishina, I. and Sevgili, Ö and Li, M. M. and Biemann, C. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=10761849318364492978\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_refai_2024,
	title = {{RefAI}: a {GPT}-powered retrieval-augmented generative tool for biomedical literature recommendation and summarization},
	journal = {Journal of the …},
	author = {Li, Y. and Zhao, J. and Li, M. and Dang, Y. and Yu, E. and Li, J. and {...}},
	year = {2024},
	note = {Publisher: Oxford Academic
Type: CITATION},
	annote = {38 cites: https://scholar.google.com/scholar?cites=4406167193000597488\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kang_prompt-rag_2024,
	title = {Prompt-rag: {Pioneering} vector embedding-free retrieval-augmented generation in niche domains, exemplified by korean medicine},
	url = {https://arxiv.org/abs/2401.11246},
	abstract = {… ChatGPT and conventional vector embedding-based RAG models. This study not only highlights the challenges of conventional RAG … thereby aiming to minimize hallucination. In cases …},
	journal = {arXiv preprint arXiv:2401.11246},
	author = {Kang, B. and Kim, J. and Yun, T. R. and Kim, C. E.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {30 cites: https://scholar.google.com/scholar?cites=12008975732439295203\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{freitas_retail-gpt_2024,
	title = {Retail-gpt: leveraging retrieval augmented generation (rag) for building e-commerce chat assistants},
	url = {https://arxiv.org/abs/2408.08925},
	abstract = {… significant hallucination … RAG-based approach for building conversational chatbots for retail e-commerce. The system is built around a DIET classifier and a large language model (LLM) …},
	journal = {arXiv preprint arXiv:2408.08925},
	author = {Freitas, BAT de and Lotufo, R. A.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=7477589239745086637\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xiong_dr-rag_2025,
	title = {{DR}-{RAG}: {Domain}-{Rule}-based {Retrieval}-{Augmented} {Generation} for aviation digital model design},
	url = {https://www.sciencedirect.com/science/article/pii/S1474034625005816},
	abstract = {… data using a hybrid R2D-LLM approach. We create a rule … a retrieval-augmented generation pipeline with a binary classifier guides rule selection and prompt templates enhance LLM …},
	journal = {Advanced Engineering Informatics},
	author = {Xiong, X. and Cai, H. and Yu, H. and Shen, B. and Hu, P.},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {1 cites: https://scholar.google.com/scholar?cites=8995491462415770174\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{koo_optimizing_2024,
	title = {Optimizing query generation for enhanced document retrieval in rag},
	url = {https://arxiv.org/abs/2407.12325},
	abstract = {… hallucination of LLM continues to undermine user belief. Among the strategies to mitigate, the Retrieval-Augmented Generation (RAG… query, we utilize a Large Language Model (LLM) to …},
	journal = {arXiv preprint arXiv:2407.12325},
	author = {Koo, H. and Kim, M. and Hwang, S. J.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {17 cites: https://scholar.google.com/scholar?cites=13736188330873789911\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gopi_enhancing_2024,
	title = {Enhancing {Engineering} {Education} {Through} {LLM}-{Driven} {Adaptive} {Quiz} {Generation}: {A} {RAG}-{Based} {Approach}},
	url = {https://ieeexplore.ieee.org/abstract/document/10893146/},
	abstract = {… First, relevance could be assessed by measuring semantic similarity, factual accuracy, and … Retrieval Augmented Generation (RAG) models helps in reducing risks of LLM hallucinations …},
	journal = {2024 IEEE Frontiers in …},
	author = {Gopi, S. and Sreekanth, D. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=9485147802145093840\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chiang_llamp_2024,
	title = {{LLaMP}: {Large} language model made powerful for high-fidelity materials knowledge retrieval and distillation},
	url = {https://arxiv.org/abs/2401.17244},
	abstract = {… Our result indicates that without RAG, vanilla LLMs suffer from hallucinations and misclassify the magnetic orderings of materials. LLaMP with GPT-4 as backend can counteract the …},
	journal = {arXiv preprint arXiv …},
	author = {Chiang, Y. and Hsieh, E. and Chou, C. H. and Riebesell, J.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {34 cites: https://scholar.google.com/scholar?cites=4338090126689640325\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{maheshwari_citefix_2025,
	title = {{CiteFix}: {Enhancing} {RAG} {Accuracy} {Through} {Post}-{Processing} {Citation} {Correction}},
	url = {https://arxiv.org/abs/2504.15629},
	abstract = {… To address this, we present efficient post-processing algorithms to improve citation accuracy in LLM-generated responses, with minimal impact on latency and cost. Our approaches …},
	journal = {arXiv preprint arXiv:2504.15629},
	author = {Maheshwari, H. and Tenneti, S. and Nakkiran, A.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=8450836778839575321\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhao_tcaf_2024,
	title = {{TCAF}: a multi-agent approach of thought chain for retrieval augmented generation},
	url = {https://openreview.net/forum?id=nvjfWv7uGY},
	abstract = {… the LLM to cite the ID of the supporting document in its response, this design significantly reduces the incidence of hallucination, … LLM to match that of a 70B LLM in the RAG system. The …},
	journal = {… Cup Workshop for Retrieval Augmented Generation},
	author = {Zhao, J. and Liu, X.},
	year = {2024},
	note = {Publisher: openreview.net},
	annote = {2 cites: https://scholar.google.com/scholar?cites=8780170482473910913\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{amatriain_measuring_2024,
	title = {Measuring and mitigating hallucinations in large language models: amultifaceted approach},
	url = {https://amatria.in/blog/images/Mitigating_Hallucinations.pdf},
	abstract = {… A hallucination in an LLM is defined as ”the generation of content that is nonsensical … , RAG can be effectively utilized to ground LLM responses, reducing the likelihood of hallucinations …},
	publisher = {amatria.in},
	author = {Amatriain, X.},
	year = {2024},
	note = {Type: PDF},
	annote = {18 cites: https://scholar.google.com/scholar?cites=13057328178837030230\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhu_halueval-wild_2024,
	title = {Halueval-wild: {Evaluating} hallucinations of language models in the wild},
	url = {https://arxiv.org/abs/2403.04307},
	abstract = {… RAG during reference answer generation (discussed in Section 2.3). To further validate the effectiveness of RAG… a pioneering benchmark for evaluating LLM hallucinations in real-world …},
	journal = {arXiv preprint arXiv:2403.04307},
	author = {Zhu, Z. and Yang, Y. and Sun, Z.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {22 cites: https://scholar.google.com/scholar?cites=7663271529126912182\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gao_u-niah_2025,
	title = {U-niah: {Unified} rag and llm evaluation for long context needle-in-a-haystack},
	url = {https://arxiv.org/abs/2503.00353},
	abstract = {… We identify typical error patterns including omission due to noise, hallucination under high noise critical condition, and self-doubt behaviors. Our work not only highlights the …},
	journal = {arXiv preprint arXiv …},
	author = {Gao, Y. and Xiong, Y. and Wu, W. and Huang, Z. and Li, B. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=9201972514968274556\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tippins_domain-specific_2024,
	title = {Domain-specific retrieval-augmented generation through token factorization: {An} experimental study},
	url = {https://www.techrxiv.org/doi/full/10.36227/techrxiv.172902551.15233738},
	doi = {10.36227/techrxiv.172902551.15233738},
	abstract = {… RAG framework, leveraging Llama, an open-source LLM, to explore the effects of this combination. Llama, as an open-source LLM, … Mancinni, “Detecting llm hallucinations using monte …},
	journal = {Authorea …},
	author = {Tippins, O. and Alvarez, T. and Novak, J. and Martinez, R. and {...}},
	year = {2024},
	note = {Publisher: techrxiv.org},
	annote = {43 cites: https://scholar.google.com/scholar?cites=11050089629785809100\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gienapp_viability_2025,
	title = {The {Viability} of {Crowdsourcing} for {RAG} {Evaluation}},
	url = {https://dl.acm.org/doi/abs/10.1145/3726302.3730093},
	doi = {10.1145/3726302.3730093},
	abstract = {… LLM. In total, we collect 47,320 pairwise human judgments and 10,556 pairwise LLM judgments across 7 RAG-… human and LLM-generated content, as well as the documents they cite. …},
	journal = {Proceedings of the 48th …},
	author = {Gienapp, L. and Hagen, T. and Fröbe, M. and Hagen, M. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=2627373488697885213\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xu_retrieval-augmented_2024,
	title = {Retrieval-augmented generation with knowledge graphs for customer service question answering},
	url = {https://dl.acm.org/doi/abs/10.1145/3626772.3661370},
	doi = {10.1145/3626772.3661370},
	abstract = {… copies bear this notice and the full citation on the first page. … LLM-based customer service question answering system that seamlessly integrates retrieval-augmented generation (RAG…},
	journal = {Proceedings of the 47th …},
	author = {Xu, Z. and Cruz, M. J. and Guevara, M. and Wang, T. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {192 cites: https://scholar.google.com/scholar?cites=16579645722360031819\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sharma_enhancing_2025,
	title = {Enhancing {Security} {Insights} with {KnowGen}-{RAG}: {Combining} {Knowledge} {Graphs}, {LLMs}, and {Multimodal} {Interpretability}},
	url = {https://dl.acm.org/doi/abs/10.1145/3716815.3729012},
	doi = {10.1145/3716815.3729012},
	abstract = {… LLM hallucinations by incorporation of external knowledge sources ensuring responses are accurate and relevant. RAG … -RAG’s improved contextual information enhances an LLM’s …},
	journal = {Proceedings of the 2025 …},
	author = {Sharma, A. N. and Akbar, K. A. and Thuraisingham, B. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=12379377696539072385\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{saha_advancing_2024,
	title = {Advancing retrieval-augmented generation with inverted question matching for enhanced qa performance},
	url = {https://ieeexplore.ieee.org/abstract/document/10781379/},
	abstract = {… between our LLM-powered modified RAG system and a traditional RAG system, employing … A major challenge with RAG is its tendency to hallucinate with large text volumes. Our study …},
	journal = {IEEE Access},
	author = {Saha, B. and Saha, U. and Malik, M. Z.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {17 cites: https://scholar.google.com/scholar?cites=3287953069328465273\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{dodgson_establishing_2023,
	title = {Establishing performance baselines in fine-tuning, retrieval-augmented generation and soft-prompting for non-specialist llm users},
	url = {https://arxiv.org/abs/2311.05903},
	abstract = {… The LLM Deployer Module incorporates multi-model collaborative agents and instructional … LLM analysis engines. In this context, different LLMs are used to retrieve user-relevant factual …},
	journal = {arXiv preprint arXiv …},
	author = {Dodgson, J. and Nanzheng, L. and Peh, J. and Pattirane, A. R. J. and {...}},
	year = {2023},
	note = {Publisher: arxiv.org},
	annote = {13 cites: https://scholar.google.com/scholar?cites=18291879930401202441\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jiang_tc-rag_2024,
	title = {Tc-rag: turing-complete rag's case study on medical llm systems},
	url = {https://arxiv.org/abs/2408.09199},
	abstract = {… RAG not only mitigates hallucination issues during LLM inference but also provides up-to-date, task-specific knowledge, significantly boosting both interpretability and performance on …},
	journal = {arXiv preprint arXiv …},
	author = {Jiang, X. and Fang, Y. and Qiu, R. and Zhang, H. and Xu, Y. and Chen, H. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {29 cites: https://scholar.google.com/scholar?cites=3148051774107223862\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{stefano_rag_2024,
	title = {Rag and roll: {An} end-to-end evaluation of indirect prompt manipulations in llm-based application frameworks},
	url = {https://arxiv.org/abs/2408.05025},
	abstract = {… Traditional LLM applications generate responses based on factual … is LLM hallucinations, which are responses to users’ questions that are inconsistent or incoherent with the factual …},
	journal = {arXiv preprint arXiv:2408.05025},
	author = {Stefano, G. De and Schönherr, L. and Pellegrino, G.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {18 cites: https://scholar.google.com/scholar?cites=1666708417025330930\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{fazlija_toward_2024,
	title = {Toward optimising a retrieval augmented generation pipeline using large language model},
	url = {https://wwwmatthes.in.tum.de/file/1vzgjh1an34u0/Sebis-Public-Website/-/Master-s-Thesis-Gentrit-Fazlija/Master%20Thesis_Gentrit%20Fazlija_signed.pdf},
	abstract = {… This approach not only "shows" the LLM the anticipated quality and relevance of responses but also aids in mitigating issues of hallucination and inconsistency. By demonstrating …},
	publisher = {wwwmatthes.in.tum.de},
	author = {Fazlija, G.},
	year = {2024},
	note = {Type: PDF},
	annote = {8 cites: https://scholar.google.com/scholar?cites=8692312922479673805\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{shawon_retrieval_2025,
	title = {Retrieval {Augmented} {Generation} {Fine}-{Tuned} {LLM} {Model} for {Code} {Recommendations} to {Mitigate} {Lock} {Contention}},
	url = {https://dl.acm.org/doi/abs/10.1145/3680256.3721324},
	doi = {10.1145/3680256.3721324},
	abstract = {… This process also augments the original prompt using fine-tuned LLM with the … LLM to remove the hallucination or wrong recommendation by checking or verifying from the external RAG …},
	journal = {Companion of the 16th …},
	author = {Shawon, A. and Liscano, R. and Azim, A. and Sundaresan, V. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_enhanced_2024,
	title = {An {Enhanced} {Retrieval} {Scheme} for a {Large} {Language} {Model} with a {Joint} {Strategy} of {Probabilistic} {Relevance} and {Semantic} {Association} in the {Vertical} …},
	url = {https://www.mdpi.com/2076-3417/14/24/11529},
	abstract = {… for LLM processing was developed, named the BM-RAGAM (BM25 retrieval-augmented generation … This study addressed the problem of hallucinations and the lack of interpretability in …},
	journal = {Applied Sciences},
	author = {Chen, Q. and Zhou, W. and Cheng, J. and Yang, J.},
	year = {2024},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {2 cites: https://scholar.google.com/scholar?cites=1614070958235306410\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xiong_improving_2024,
	title = {Improving retrieval-augmented generation in medicine with iterative follow-up questions},
	url = {https://www.worldscientific.com/doi/abs/10.1142/9789819807024_0015},
	doi = {10.1142/9789819807024_0015},
	abstract = {… knowledge, but may still hallucinate and are inflexible in the … to combine LLM reasoning with external corpora is RAG, which … into LLM to augment its answer generation. Formally, the …},
	journal = {… 2025: Proceedings of …},
	author = {Xiong, G. and Jin, Q. and Wang, X. and Zhang, M. and Lu, Z. and {...}},
	year = {2024},
	note = {Publisher: World Scientific},
	annote = {56 cites: https://scholar.google.com/scholar?cites=9954838940812922197\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{levonian_retrieval-augmented_2023,
	title = {Retrieval-augmented generation to improve math question-answering: {Trade}-offs between groundedness and human preference},
	url = {https://arxiv.org/abs/2310.03184},
	abstract = {… implementation We adopted a commercially-realistic chatbot context as the underlying LLM, … We identified 51 factual and conceptual questions that have sufficient context to be …},
	journal = {arXiv preprint arXiv …},
	author = {Levonian, Z. and Li, C. and Zhu, W. and Gade, A. and Henkel, O. and {...}},
	year = {2023},
	note = {Publisher: arxiv.org},
	annote = {55 cites: https://scholar.google.com/scholar?cites=1997396796023507239\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lin_concept-based_2025,
	title = {Concept-{Based} {RAG} {Models}: {A} {High}-{Accuracy} {Fact} {Retrieval} {Approach}},
	url = {https://aclanthology.org/2025.finnlp-1.8/},
	abstract = {… Unlike traditional methods focused on reducing LLM hallucinations or modifying data structures, this approach evaluates inherent knowledge uncertainty from an LLM perspective. By …},
	journal = {Proceedings of the Joint Workshop of the 9th …},
	author = {Lin, C. Y. and Jang, J. S. R.},
	year = {2025},
	note = {Publisher: aclanthology.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tao_llm-r_2024,
	title = {{LLM}-{R}: {A} {Framework} for {Domain}-{Adaptive} {Maintenance} {Scheme} {Generation} {Combining} {Hierarchical} {Agents} and {RAG}},
	url = {https://arxiv.org/abs/2411.04476},
	abstract = {… for fine-tuning the LLM. This method … RetrievalAugmented Generation (RAG) technologies are adopted to optimize the generation steps and mitigate the phenomenon of hallucination …},
	journal = {arXiv preprint arXiv …},
	author = {Tao, L. and Huang, Q. and Wu, X. and Zhang, W. and Wu, Y. and Li, B. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=46504174936273342\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{adejumo__2024,
	title = {… {Care} {Quality} for {Atrial} {Fibrillation} {Across} {Non}-{Interoperable} {Electronic} {Health} {Record} {Data} using a {Retrieval}-{Augmented} {Generation}-enabled {Large} {Language} {Model}},
	url = {https://www.medrxiv.org/content/10.1101/2024.09.19.24313992.abstract},
	doi = {10.1101/2024.09.19.24313992.abstract},
	abstract = {… and bleeding risk when comparing structured versus the RAG-LLM approach. For all outcomes, we calculated 95\% confidence intervals using bootstrap resampling with 1,000 iterations …},
	journal = {medRxiv},
	author = {Adejumo, P. and Thangaraj, P. M. and Dhingra, L. S. and Biswas, D. and {...}},
	year = {2024},
	note = {Publisher: medrxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=5931493062672113629\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kang_ever_2023,
	title = {Ever: {Mitigating} hallucination in large language models through real-time verification and rectification},
	url = {https://mk322.github.io/papers/KangEVER2024.pdf},
	abstract = {… better preference data to essentially enhance the factuality LLM by preference tuning. Here, as … we’ve identified for RAG and post-hoc edit methods? (2) Can EVER effectively reduce …},
	journal = {arXiv preprint arXiv:2311.09114},
	author = {Kang, H. and Ni, J. and Yao, H.},
	year = {2023},
	note = {Publisher: mk322.github.io
Type: PDF},
	annote = {47 cites: https://scholar.google.com/scholar?cites=15545350352889170223\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kovacs_lettucedetect_2025,
	title = {Lettucedetect: {A} hallucination detection framework for rag applications},
	url = {https://arxiv.org/abs/2502.17125},
	abstract = {… both hallucinations and coverage errors in LLM-generated responses. Fine-tuned LLM … note that we were unable to compare our results with RAG-HAT on this task because they did not …},
	journal = {arXiv preprint arXiv:2502.17125},
	author = {Kovács, Á and Recski, G.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=11537607213316158874\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zelin_rare_2024,
	title = {Rare disease diagnosis using knowledge guided retrieval augmentation for {ChatGPT}},
	url = {https://www.sciencedirect.com/science/article/pii/S1532046424001205},
	abstract = {… ChatGPT’s suitability for rare disease diagnostic support with the enhancement provided by Retrieval Augmented Generation (RAG… hallucinations and improve the accuracy of ChatGPT, …},
	journal = {Journal of Biomedical …},
	author = {Zelin, C. and Chung, W. K. and Jeanne, M. and Zhang, G. and {...}},
	year = {2024},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {25 cites: https://scholar.google.com/scholar?cites=12903039815931758669\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_privacy-preserving_2024,
	title = {A {Privacy}-{Preserving} {Framework} for {Medical} {Chatbot} {Based} on {LLM} with {Retrieval} {Augmented} {Generation}},
	url = {https://link.springer.com/chapter/10.1007/978-981-97-9437-9_2},
	doi = {10.1007/978-981-97-9437-9_2},
	abstract = {… is zero, indicating that the LLM has successfully learned to distinguish similar information, thereby reducing the occurrence of erroneous outputs and hallucinations. Additionally, the …},
	journal = {CCF International Conference on Natural …},
	author = {Li, Y. and Li, C. and Wang, Z. and Sui, D. and Yan, J.},
	year = {2024},
	note = {Publisher: Springer},
	annote = {1 cites: https://scholar.google.com/scholar?cites=5460894107181097420\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@misc{pahwa_reliable_2024,
	title = {Reliable {Medical} {LLM} and {Vision}-{Language} {RAG} through {Multi}-{Agent} {Orchestration} and {Single}-{Step} {Preference} {Alignment}},
	author = {Pahwa, K.},
	year = {2024},
	note = {Type: CITATION},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{poliakov_multi-meta-rag_2024,
	title = {Multi-meta-rag: {Improving} rag for multi-hop queries using database filtering with llm-extracted metadata},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-81372-6_25},
	doi = {10.1007/978-3-031-81372-6_25},
	abstract = {… Multi-Meta-RAG, which uses database filtering with LLM-extracted metadata to improve the RAG selection of the relevant … RAG also helps mitigate generative hallucination and provides …},
	journal = {… on Information and Communication Technologies in …},
	author = {Poliakov, M. and Shvai, N.},
	year = {2024},
	note = {Publisher: Springer},
	annote = {20 cites: https://scholar.google.com/scholar?cites=3649689504086759082\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gumaan_expertrag_2025,
	title = {{ExpertRAG}: {Efficient} {RAG} with {Mixture} of {Experts}–{Optimizing} {Context} {Retrieval} for {Adaptive} {LLM} {Responses}},
	url = {https://arxiv.org/abs/2504.08744},
	abstract = {… Below, we detail the key components and cite their connections to existing methods. … RAG was shown to improve factuality in generation [22]; we’ll see if ExpertRAG can not only find …},
	journal = {arXiv preprint arXiv:2504.08744},
	author = {Gumaan, E.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_ratt_2025,
	title = {Ratt: {A} thought structure for coherent and correct llm reasoning},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/34876},
	abstract = {… LLM thought structures. With optimized tree structure and RAG, our method is capable of reducing factual … pθ with parameters θ, we aim to enhance the performance of LLM on task A …},
	journal = {Proceedings of the AAAI …},
	author = {Zhang, J. and Wang, X. and Ren, W. and Jiang, L. and Wang, D. and {...}},
	year = {2025},
	note = {Publisher: ojs.aaai.org},
	annote = {50 cites: https://scholar.google.com/scholar?cites=6920332139578561532\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ammann_securing_2025,
	title = {Securing rag: {A} risk assessment and mitigation framework},
	url = {https://arxiv.org/abs/2505.08728},
	abstract = {… Furthermore, the growing system complexity and the fast development of the LLM/RAG … M6: Evaluation improve the factual accuracy and reliability of RAG systems by identifying and (self…},
	journal = {arXiv preprint arXiv …},
	author = {Ammann, L. and Ott, S. and Landolt, C. R. and Lehmann, M. P.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=3271239853220314638\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cherumanal_walert_2024-1,
	title = {Walert: {Putting} conversational search knowledge into action by building and evaluating a large language model-powered chatbot},
	url = {https://arxiv.org/abs/2401.07216},
	abstract = {… of an open-source LLM; (ii) monitoring the problem of hallucinations (ie, the introduction of … of LLM-based conversational systems [18]. Finally, we plan to deploy RAG approaches to …},
	journal = {arXiv preprint arXiv …},
	author = {Cherumanal, S. P. and Tian, L. and Abushaqra, F. M. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=1024087705996561067\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{dhole_retrieve_2025,
	title = {To retrieve or not to retrieve? uncertainty detection for dynamic retrieval augmented generation},
	url = {https://arxiv.org/abs/2501.09292},
	abstract = {… Unlike traditional methods that rely on rigid heuristics or external classifiers, uncertainty detection leverages the inherent variability in LLM-generated responses to estimate confidence …},
	journal = {arXiv preprint arXiv:2501.09292},
	author = {Dhole, K. D.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=8683712254159125755\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{landolsi_caprag_2025,
	title = {{CAPRAG}: {A} {Large} {Language} {Model} {Solution} for {Customer} {Service} and {Automatic} {Reporting} using {Vector} and {Graph} {Retrieval}-{Augmented} {Generation}},
	url = {https://arxiv.org/abs/2501.13993},
	abstract = {… LLM to be more deterministic and not allowing it to be creative.In our use case, the LLM sticks to the provided context and reduces the hallucination as much as possible, see Table 3. …},
	journal = {arXiv preprint arXiv …},
	author = {Landolsi, H. and Letaief, K. and Taghouti, N. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=13070714515537372512\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ko_retrieval_2024,
	title = {Retrieval {Augmented} {Generation} for {Document} {Query} {Automation} using {Open} source {LLMs}},
	url = {https://ieeexplore.ieee.org/abstract/document/10754919/},
	abstract = {… By combining the power of RAG and the LLM, this document query system offers a robust … LIMITATION Hallucination is a key challenge in LLM. LLM hallucination occurs when the …},
	journal = {2024 5th International …},
	author = {Ko, K. and Nyein, T. Y. and Oo, K. K. and Oo, T. Z. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=16206564109707097757\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hu_prompt_2024,
	title = {Prompt perturbation in retrieval-augmented generation based large language models},
	url = {https://dl.acm.org/doi/abs/10.1145/3637528.3671932},
	doi = {10.1145/3637528.3671932},
	abstract = {… The robustness of RAG needs to be carefully … LLM’s neuron activation and introduce methods to improve the robustness of RAG-based LLMs by detecting perturbations and factual …},
	journal = {Proceedings of the 30th ACM …},
	author = {Hu, Z. and Wang, C. and Shu, Y. and Paik, H. Y. and Zhu, L.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {41 cites: https://scholar.google.com/scholar?cites=6063030354173138827\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wei_enhanced_2025,
	title = {Enhanced recommendation systems with retrieval-augmented large language model},
	url = {https://www.jair.org/index.php/jair/article/view/17809},
	abstract = {… that integrates RAG with LLMs to supplement missing data. By leveraging RAG techniques, … • Confidence Threshold θ: The confidence threshold θ determines the filtering quality of the …},
	journal = {Journal of Artificial …},
	author = {Wei, C. and Duan, K. and Zhuo, S. and Wang, H. and Huang, S. and {...}},
	year = {2025},
	note = {Publisher: jair.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=13077530055899423137\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{da_ge-chat_2025,
	title = {{GE}-{Chat}: {A} {Graph} {Enhanced} {RAG} {Framework} for {Evidential} {Response} {Generation} of {LLMs}},
	url = {https://arxiv.org/abs/2505.10143},
	abstract = {… trust issues among users. To tackle such issue, this paper proposes GE-Chat, a knowledge Graph enhanced retrieval-augmented generation … We compare with the direct LLM source …},
	journal = {arXiv preprint arXiv:2505.10143},
	author = {Da, L. and Shah, P. M. and Liou, K. R. and Zhang, J. and Wei, H.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{feng_optimizing_2024,
	title = {Optimizing microservice deployment in edge computing with large language models: {Integrating} retrieval augmented generation and chain of thought …},
	url = {https://www.mdpi.com/2073-8994/16/11/1470},
	abstract = {… Additionally, we prompted the LLM to generate code without the use of the RAG database … for the LLM to generate appropriate responses, significantly enhancing the factual accuracy …},
	journal = {Symmetry},
	author = {Feng, K. and Luo, L. and Xia, Y. and Luo, B. and He, X. and Li, K. and Zha, Z. and Xu, B. and {...}},
	year = {2024},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {8 cites: https://scholar.google.com/scholar?cites=8274658841610124917\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{proma_personalizing_2025,
	title = {Personalizing {LLM} {Responses} to {Combat} {Political} {Misinformation}},
	url = {https://dl.acm.org/doi/abs/10.1145/3699682.3728349},
	doi = {10.1145/3699682.3728349},
	abstract = {… We propose and evaluate a RAG-based LLM pipeline that personalizes information by considering user demographics, personalities, and trust in credible sources. Our evaluation of the …},
	journal = {Proceedings of the 33rd …},
	author = {Proma, A. and Pate, N. and Druckman, J. and Ghoshal, G. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{comendant_large_2024,
	title = {Large language model-based sport coaching system using retrieval-augmented generation and user models},
	publisher = {University of Twente},
	author = {Comendant, C.},
	year = {2024},
	note = {Type: CITATION},
	annote = {3 cites: https://scholar.google.com/scholar?cites=3661586894810276624\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mukherjee_documents_2025,
	title = {From {Documents} to {Dialogue}: {Building} {KG}-{RAG} {Enhanced} {AI} {Assistants}},
	url = {https://arxiv.org/abs/2502.15237},
	abstract = {… The confidence score allows us to filter the KG based on its … for confidence score for constructing the KG for the KG-RAG … our KG-RAG based retriever can be integrated with an LLM to …},
	journal = {arXiv preprint arXiv …},
	author = {Mukherjee, M. and Kim, S. and Chen, X. and Luo, D. and Yu, T. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=4856184728154053961\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{simoni_morse_2025,
	title = {{MoRSE}: {Bridging} the gap in cybersecurity expertise with retrieval augmented generation},
	url = {https://dl.acm.org/doi/abs/10.1145/3672608.3707898},
	doi = {10.1145/3672608.3707898},
	abstract = {… These hallucinations often occur when the model lacks … to ensure the relevance of LLM responses. As a result, … We validated these results with the LLM as a Judge method [33], which …},
	journal = {Proceedings of the 40th ACM …},
	author = {Simoni, M. and Saracino, A. and {VP} and Conti, M.},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {13 cites: https://scholar.google.com/scholar?cites=5897262354358209319\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{abootorabi_ask_2025,
	title = {Ask in any modality: {A} comprehensive survey on multimodal retrieval-augmented generation},
	url = {https://arxiv.org/abs/2502.08826},
	abstract = {… RetrievalAugmented Generation (RAG) mitigates these issues by integrating external dynamic information for improved factual … enhance ASR accuracy through LLM in-context learning. …},
	journal = {arXiv preprint arXiv …},
	author = {Abootorabi, M. M. and Zobeiri, A. and Dehghani, M. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {35 cites: https://scholar.google.com/scholar?cites=13944116911499498959\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{li_wiping_2024,
	title = {Wiping out the limitations of {Large} {Language} {Models}-{A} {Taxonomy} for {Retrieval} {Augmented} {Generation}},
	url = {https://www.alexandria.unisg.ch/entities/publication/e03dcba0-380a-4546-864a-c25f97c92fc9},
	abstract = {… for RAG applications, illustrating how RAG can be systematically implemented to improve LLM tasks and … shift roles of human workers?; How does RAGs foster trust in humans? …},
	publisher = {alexandria.unisg.ch},
	author = {Li, M. M. and Nikishina, I. and Sevgili, Ö and Semmann, M.},
	year = {2024},
	annote = {2 cites: https://scholar.google.com/scholar?cites=12861652327775383620\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yang_geometry_2024,
	title = {The {Geometry} of {Queries}: {Query}-{Based} {Innovations} in {Retrieval}-{Augmented} {Generation}},
	url = {https://arxiv.org/abs/2407.18044},
	abstract = {… Unlike relying solely on the LLM’s internal knowledge, RAG … knowledge base to inform the LLM’s answer generation … QB-RAG are more frequently grounded on our trusted source of …},
	journal = {arXiv preprint arXiv:2407.18044},
	author = {Yang, E. and Amar, J. and Lee, J. H. and Kumar, B. and Jia, Y.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=13277865435875597118\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{liu_preventing_2024,
	title = {Preventing and detecting misinformation generated by large language models},
	url = {https://dl.acm.org/doi/abs/10.1145/3626772.3661377},
	doi = {10.1145/3626772.3661377},
	abstract = {… prompt guardrails, retrieval-augmented generation (RAG), and … and limitations of detecting LLM-generated misinformation. … about the credibility and authenticity of LLMgenerated content …},
	journal = {Proceedings of the 47th International ACM SIGIR …},
	author = {Liu, A. and Sheng, Q. and Hu, X.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {44 cites: https://scholar.google.com/scholar?cites=15604437355720414550\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zou_weak--strong_2025,
	title = {Weak-to-{Strong} {GraphRAG}: {Aligning} {Weak} {Retrievers} with {Large} {Language} {Models} for {Graph}-based {Retrieval} {Augmented} {Generation}},
	url = {https://arxiv.org/abs/2506.22518},
	abstract = {… reduce hallucinations. However, LLMs often rely on a weak retriever in graph-based RAG: I) … Recent efforts in text-based RAG have explored using LLM feedback to directly optimize the …},
	journal = {arXiv preprint arXiv …},
	author = {Zou, D. and Chen, Y. and Li, M. and Miao, S. and Liu, C. and Han, B. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=16099229809185648068\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kim_enhancing_2024,
	title = {Enhancing {Scientific} {Reproducibility} {Through} {Automated} {BioCompute} {Object} {Creation} {Using} {Retrieval}-{Augmented} {Generation} from {Publications}},
	url = {https://arxiv.org/abs/2409.15076},
	abstract = {… Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs). We describe the development of the BCO assistant tool that leverages RAG … as LLM hallucination and long…},
	journal = {arXiv preprint arXiv:2409.15076},
	author = {Kim, S. and Mazumder, R.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=12598614874228210120\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_llm_2025,
	title = {Llm hallucinations in practical code generation: {Phenomena}, mechanism, and mitigation},
	url = {https://dl.acm.org/doi/abs/10.1145/3728894},
	doi = {10.1145/3728894},
	abstract = {… how hallucinations evolve before and after employing RAG-… lightweight RAG-based method to mitigate hallucinations in LLM… hallucinations such as undefined attributes, the potentials of …},
	journal = {Proceedings of the …},
	author = {Zhang, Z. and Wang, C. and Wang, Y. and Shi, E. and Ma, Y. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {71 cites: https://scholar.google.com/scholar?cites=9314563279130477957\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{misrahi_adapting_2025,
	title = {Adapting {Large} {Language} {Models} for {Multi}-{Domain} {Retrieval}-{Augmented}-{Generation}},
	url = {https://arxiv.org/abs/2504.02411},
	abstract = {… factuality, but multi-domain applications face challenges like lack of diverse benchmarks … for RAG. We show that commonly used tuning of an LLM for RAG on standard question …},
	journal = {arXiv preprint arXiv …},
	author = {Misrahi, A. and Chirkova, N. and Louis, M. and Nikoulina, V.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=14503720548547747396\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yang_cold-start_2025,
	title = {Cold-{Start} {Recommendation} with {Knowledge}-{Guided} {Retrieval}-{Augmented} {Generation}},
	url = {https://arxiv.org/abs/2505.20773},
	abstract = {… with sparse metadata and limited or hallucinated knowledge. We introduce ColdRAG, a retrieval-augmented generation framework that equips an LLM with a dynamically built, domain…},
	journal = {arXiv preprint arXiv …},
	author = {Yang, W. and Zhang, W. and Liu, Y. and Han, Y. and Wang, Y. and Lee, J. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=15071473744884222457\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ni_tp-rag_2025,
	title = {{TP}-{RAG}: {Benchmarking} {Retrieval}-{Augmented} {Large} {Language} {Model} {Agents} for {Spatiotemporal}-{Aware} {Travel} {Planning}},
	url = {https://arxiv.org/abs/2504.08694},
	abstract = {… may indicate hallucinations by the LLM agents. • Repetition Rate (RR): We measure the frequency of POI repetition in plans to assess basic commonsense awareness of the agents. …},
	journal = {arXiv preprint arXiv …},
	author = {Ni, H. and Liu, F. and Ma, X. and Su, L. and Wang, S. and Yin, D. and Xiong, H. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=12574426471093887121\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sobhan_llm-assisted_2025,
	title = {{LLM}-{Assisted} {Question}-{Answering} on {Technical} {Documents} {Using} {Structured} {Data}-{Aware} {Retrieval} {Augmented} {Generation}},
	url = {https://arxiv.org/abs/2506.23136},
	abstract = {… On the other hand, the typical RAG pipeline suffered from hallucination because the question was about transformer, and also the given document was about transformer, even though it …},
	journal = {arXiv preprint arXiv:2506.23136},
	author = {Sobhan, S. and Haque, M. A.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=12601697807509426942\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{palaniappan_enhancing_2024,
	title = {Enhancing {Enterprise}-{Wide} {Information} {Retrieval} through {RAG} {Systems} {Techniques}, {Evaluation}, and {Scalable} {Deployment}},
	url = {https://onepetro.org/SPEADIP/proceedings-abstract/24ADIP/24ADIP/585627},
	abstract = {… the occurrence of hallucinations. An application built with … We have commercially available RAG+LLM systems but it is … In this technical paper we present a RAG+LLM system with a …},
	journal = {Abu Dhabi …},
	author = {Palaniappan, S. and Mali, R. and Cuomo, L. and Vitale, M. and {...}},
	year = {2024},
	note = {Publisher: onepetro.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=18039876813826254138\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yu_large-language_2024,
	title = {Large-language models: {The} game-changers for materials science research},
	url = {https://www.sciencedirect.com/science/article/pii/S2949747724000344},
	abstract = {Large Language Models (LLMs), such as GPT-4, are precipitating a new "industrial revolution" by significantly enhancing productivity across various domains. These models encode an …},
	journal = {Artificial Intelligence Chemistry},
	author = {Yu, S. and Ran, N. and Liu, J.},
	year = {2024},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {39 cites: https://scholar.google.com/scholar?cites=671051668007085943\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ni_diras_2024,
	title = {Diras: {Efficient} llm annotation of document relevance in retrieval augmented generation},
	url = {https://arxiv.org/abs/2406.14162},
	abstract = {… ]; “Ask” means the result is calibrated by the generated confidence score in [Confidence] field; and “Tok” means we take the token-level probability of “Yes/No” after “[Guess]:” as the …},
	journal = {arXiv preprint arXiv …},
	author = {Ni, J. and Schimanski, T. and Lin, M. and Sachan, M. and Ash, E. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=838656302116349078\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{su_fast_2025,
	title = {Fast or better? balancing accuracy and cost in retrieval-augmented generation with flexible user control},
	url = {https://arxiv.org/abs/2502.12145},
	abstract = {… Retrieval-Augmented Generation (RAG) has emerged as a powerful approach to mitigate large language model (LLM) hallucinations … However, existing RAG frameworks often apply …},
	journal = {arXiv preprint arXiv:2502.12145},
	author = {Su, J. and Healey, J. and Nakov, P. and Cardie, C.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=18179075548277818578\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yu_simulated_2024,
	title = {Simulated patient systems are intelligent when powered by large language model-based {AI} agents},
	url = {https://www.researchgate.net/profile/Huizi-Yu/publication/384447372_AIPatient_Simulating_Patients_with_EHRs_and_LLM_Powered_Agentic_Workflow/links/66fd50b1869f1104c6c3dba0/AIPatient-Simulating-Patients-with-EHRs-and-LLM-Powered-Agentic-Workflow.pdf},
	abstract = {… Reasoning RAG leverages six LLM powered agents spanning tasks including retrieval, KG … Our Reasoning RAG agentic framework improves accuracy and minimizes hallucination risk…},
	journal = {arXiv preprint arXiv …},
	author = {Yu, H. and Zhou, J. and Li, L. and Chen, S. and Gallifant, J. and {...}},
	year = {2024},
	note = {Publisher: researchgate.net
Type: PDF},
	annote = {26 cites: https://scholar.google.com/scholar?cites=3527683902610994534\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{asai_self-rag_2024,
	title = {Self-rag: {Learning} to retrieve, generate, and critique through self-reflection},
	url = {https://par.nsf.gov/biblio/10539591},
	abstract = {… This work aims to improve the factuality of LLM outputs, the lack of which continues to cause numerous real-world problems (eg, spread of misinformation and provision of incorrect and …},
	publisher = {par.nsf.gov},
	author = {Asai, A. and Wu, Z. and Wang, Y. and Sil, A. and Hajishirzi, H.},
	year = {2024},
	annote = {1215 cites: https://scholar.google.com/scholar?cites=8270996695238041002\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yu_rag-guided_2024,
	title = {Rag-guided large language models for visual spatial description with adaptive hallucination corrector},
	url = {https://dl.acm.org/doi/abs/10.1145/3664647.3688990},
	doi = {10.1145/3664647.3688990},
	abstract = {… statements, and an LLM is employed to correct hallucinations in the generated responses. … that combines retrieval-augmented generation and hallucination corrector with large …},
	journal = {Proceedings of the …},
	author = {Yu, J. and Zhang, Y. and Zhang, Z. and Yang, Z. and Zhao, G. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=9318447478381996058\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xie_rag-based_2025,
	title = {A rag-based multi-agent llm system for natural hazard resilience and adaptation},
	url = {https://arxiv.org/abs/2504.17200},
	abstract = {… In this work we propose a retrieval-augmented generation (RAG)-based multi-agent LLM … datasets, and scientific literature through an RAG framework, the system ensures both the …},
	journal = {arXiv preprint arXiv …},
	author = {Xie, Y. and Jiang, B. and Mallick, T. and Bergerson, J. D. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=3750448913608574219\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bedi_xlr-kgdd_2025,
	title = {{XLR}-{KGDD}: leveraging {LLM} and {RAG} for knowledge graph-based explainable disease diagnosis using multimodal clinical information},
	url = {https://link.springer.com/article/10.1007/s10115-025-02465-8},
	doi = {10.1007/s10115-025-02465-8},
	abstract = {… We have used RAG with LLM to generate explanations and reduce the hallucinations. We … This study introduces a framework for diagnosing diseases using LLM and RAG. It also …},
	journal = {Knowledge and Information Systems},
	author = {Bedi, P. and Thukral, A. and Dhiman, S.},
	year = {2025},
	note = {Publisher: Springer},
	annote = {2 cites: https://scholar.google.com/scholar?cites=3535668006806707740\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hamed_knowledge_2025,
	title = {From knowledge generation to knowledge verification: examining the biomedical generative capabilities of {ChatGPT}},
	url = {https://www.cell.com/iscience/fulltext/S2589-0042(25)00753-9},
	abstract = {… , is the verification of the factuality of content generated by ChatGPT. Here, we extend our … directly or via retrieval-augmented generation (RAG) methods. RAG integrates contextual …},
	journal = {iScience},
	author = {Hamed, A. A. and Crimi, A. and Misiak, M. M. and Lee, B. S.},
	year = {2025},
	note = {Publisher: cell.com
Type: HTML},
	annote = {1 cites: https://scholar.google.com/scholar?cites=9546137807400107621\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{rouzrokh_conflare_2024,
	title = {Conflare: conformal large language model retrieval},
	url = {https://arxiv.org/abs/2404.04287},
	abstract = {… This mitigates hallucinations and allows updating the knowledge without retraining the LLM. … Despite the popularity of RAG, it does not guarantee that an LLM will generate a valid …},
	journal = {arXiv preprint arXiv …},
	author = {Rouzrokh, P. and Faghani, S. and Gamble, C. U. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=842893726210528124\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jin_ragcache_2024,
	title = {Ragcache: {Efficient} knowledge caching for retrieval-augmented generation},
	url = {https://dl.acm.org/doi/abs/10.1145/3768628},
	doi = {10.1145/3768628},
	abstract = {… that copies bear this notice and the full citation on the first page. Copyrights for components … findings using a production RAG dataset from Company-X, a leading LLM service provider, …},
	journal = {ACM Transactions on …},
	author = {Jin, C. and Zhang, Z. and Jiang, X. and Liu, F. and Liu, S. and Liu, X. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {249 cites: https://scholar.google.com/scholar?cites=3791721340204075467\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_tutorllm_2025,
	title = {{TutorLLM}: customizing learning recommendations with knowledge tracing and retrieval-augmented generation},
	url = {https://link.springer.com/chapter/10.1007/978-3-032-05005-2_8},
	doi = {10.1007/978-3-032-05005-2_8},
	abstract = {… and accuracy of the LLM’s responses. The third component is an RAG Enhanced LLM. This … The text content provided by Scraper mitigates hallucinations by dynamically retrieving and …},
	journal = {IFIP Conference on …},
	author = {Li, Z. and Wang, J. and Gu, W. and Yazdanpanah, V. and Shi, L. and {...}},
	year = {2025},
	note = {Publisher: Springer},
	annote = {4 cites: https://scholar.google.com/scholar?cites=10601737823262117939\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_llms_2024,
	title = {Llms know what they need: {Leveraging} a missing information guided framework to empower retrieval-augmented generation},
	url = {https://arxiv.org/abs/2404.14043},
	abstract = {… Retrieval-Augmented Generation (RAG) demonstrates great value in alleviating outdated knowledge or hallucination … fully utilize the LLM’s parametric knowledge, we prompt the LLM to …},
	journal = {arXiv preprint arXiv:2404.14043},
	author = {Wang, K. and Duan, F. and Li, P. and Wang, S. and Cai, X.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {17 cites: https://scholar.google.com/scholar?cites=17295569148566206203\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{matsumoto_kragen_2024,
	title = {{KRAGEN}: a knowledge graph-enhanced {RAG} framework for biomedical problem solving using large language models},
	url = {https://academic.oup.com/bioinformatics/article-abstract/40/6/btae353/7687047},
	abstract = {… relevant knowledge through the RAG framework, which limits the hallucinations, and finally, … , and feeding the prompt to the LLM. The LLM then uses the RAG system to retrieve relevant …},
	journal = {…},
	author = {Matsumoto, N. and Moran, J. and Choi, H. and Hernandez, M. E. and {...}},
	year = {2024},
	note = {Publisher: academic.oup.com},
	annote = {78 cites: https://scholar.google.com/scholar?cites=18384676815774931993\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{vidivelli_efficiency-driven_2024,
	title = {Efficiency-{Driven} {Custom} {Chatbot} {Development}: {Unleashing} {LangChain}, {RAG}, and {Performance}-{Optimized} {LLM} {Fusion}.},
	url = {https://file.sciopen.com/sciopen_public/1838514775850065922.pdf},
	abstract = {… RAG permits it to get to outer information for uncommon questions outside its pre-… and Factuality: Fine-tuning assists the LLM with learning area explicit wording and accurate data. RAG …},
	journal = {Computers, Materials \& …},
	author = {Vidivelli, S. and Ramachandran, M. and {...}},
	year = {2024},
	note = {Publisher: file.sciopen.com
Type: PDF},
	annote = {31 cites: https://scholar.google.com/scholar?cites=15283705187083595469\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hu_removal_2025,
	title = {Removal of {Hallucination} on {Hallucination}: {Debate}-{Augmented} {RAG}},
	url = {https://arxiv.org/abs/2505.18581},
	abstract = {… The capabilities of MAD align well with the second-order hallucination problem in RAG, and this … We provide detailed comparisons of average LLM and retrieval calls on StrategyQA, as …},
	journal = {arXiv preprint arXiv …},
	author = {Hu, W. and Zhang, W. and Jiang, Y. and Zhang, C. J. and Wei, X. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=13402166798329243457\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{joshi_robust_2024,
	title = {Robust multi model rag pipeline for documents containing text, table \&images},
	url = {https://ieeexplore.ieee.org/abstract/document/10574972/},
	abstract = {… Multimodal RAG over two different other multimodal LLM ie, … the proposed solution fits best with LLM in different cases. … also hallucinate because the context which is provided to LLM for …},
	journal = {2024 3rd International …},
	author = {Joshi, P. and Gupta, A. and Kumar, P. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {36 cites: https://scholar.google.com/scholar?cites=16720418937703498465\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{guerraoui_efficient_2025,
	title = {Efficient federated search for retrieval-augmented generation},
	url = {https://dl.acm.org/doi/abs/10.1145/3721146.3721942},
	doi = {10.1145/3721146.3721942},
	abstract = {… RAG integrates LLM text generation with external information retrieval, enabling models to ground their responses in credible … corporates them into the LLM prompt before response gen…},
	journal = {Proceedings of the 5th …},
	author = {Guerraoui, R. and Kermarrec, A. M. and Petrescu, D. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=6801166886844233096\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{qin_robust_2024,
	title = {Robust implementation of retrieval-augmented generation on edge-based computing-in-memory architectures},
	url = {https://dl.acm.org/doi/abs/10.1145/3676536.3676674},
	doi = {10.1145/3676536.3676674},
	abstract = {… LLM learning method, can improve the quality of the LLM-generated content without updating model parameters. However, the RAG-based LLM may … , the RAG performance for Citation …},
	journal = {Proceedings of the 43rd …},
	author = {Qin, R. and Yan, Z. and Zeng, D. and Jia, Z. and Liu, D. and Liu, J. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {15 cites: https://scholar.google.com/scholar?cites=13578830295913697902\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yusuf_rag-based_2024,
	title = {A {RAG}-based {Question} {Answering} {System} {Proposal} for {Understanding} {Islam}: {MufassirQAS} {LLM}},
	url = {https://www.techrxiv.org/doi/pdf/10.36227/techrxiv.170723304.41988020},
	doi = {10.36227/techrxiv.170723304.41988020},
	abstract = {… LLM chatbots use NLP techniques to establish connections … false information, known as hallucination. Also, the chatbots' … -based Retrieval Augmented Generation (RAG) approach to …},
	journal = {Authorea Preprints},
	author = {Yusuf, A. and Karaarslan, E. and Aydin, O.},
	year = {2024},
	note = {Publisher: techrxiv.org
Type: PDF},
	annote = {1 cites: https://scholar.google.com/scholar?cites=5931311753236732654\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{nemeth_using_2024,
	title = {Using a {RAG}-enhanced large language model in a virtual teaching assistant role: {Experiences} from a pilot project in statistics education.},
	url = {https://www.ksh.hu/statszemle_archive/en/2024/2024_02/2024_02_003.pdf},
	abstract = {… They were asked whether they used ChatGPT or had used a similar tool during their undergraduate studies, and we also asked them about their trust in these tools. Notably, user and …},
	journal = {Hungarian Statistical Review},
	author = {Németh, R. and Tátrai, A. and Szabó, M. and Tamási, Á},
	year = {2024},
	note = {Publisher: ksh.hu
Type: PDF},
	annote = {2 cites: https://scholar.google.com/scholar?cites=2176609117460270912\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cossio_comprehensive_2025,
	title = {A comprehensive taxonomy of hallucinations in large language models},
	url = {https://arxiv.org/abs/2508.01781},
	abstract = {… This report provides a comprehensive taxonomy of LLM hallucinations, beginning with a formal … For instance, Retrieval-Augmented Generation (RAG) is frequently cited as an effective …},
	journal = {arXiv preprint arXiv:2508.01781},
	author = {Cossio, M.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=5477778951353485041\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gutu_exploring_2024,
	title = {Exploring data analysis methods in generative models: from {Fine}-{Tuning} to {RAG} implementation},
	url = {https://www.mdpi.com/2073-431X/13/12/327},
	abstract = {… and timeliness in LLM outputs. By incorporating RAG, the problem of hallucination in LLMs is … the advantages of RAG by integrating real-time data retrieval with LLM capabilities, …},
	journal = {Computers},
	author = {Guțu, B. M. and Popescu, N.},
	year = {2024},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {8 cites: https://scholar.google.com/scholar?cites=13630773295225857349\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{azher_generating_2024,
	title = {Generating suggestive limitations from research articles using llm and graph-based approach},
	url = {https://dl.acm.org/doi/abs/10.1145/3677389.3702612},
	doi = {10.1145/3677389.3702612},
	abstract = {… Given that each paper may have many citations, we refine the graph by establishing … RAG with LLM: We made an additional vector database as a Retrieval Augmented Generation …},
	journal = {Proceedings of the 24th ACM/IEEE Joint Conference …},
	author = {Azher, I. A.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=9641126521198982\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_citation-enhanced_2024,
	title = {Citation-enhanced generation for {LLM}-based chatbots},
	url = {https://arxiv.org/abs/2402.16063},
	abstract = {… However, a vital challenge of LLMbased chatbots is that they may produce hallucinated … been made to alleviate hallucination, such as retrieval augmented generation and reinforcement …},
	journal = {arXiv preprint arXiv:2402.16063},
	author = {Li, W. and Li, J. and Ma, W. and Liu, Y.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {37 cites: https://scholar.google.com/scholar?cites=9427192213023154454\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{perron_ai-enhanced_2025,
	title = {{AI}-enhanced social work: {Developing} and evaluating retrieval-augmented generation ({RAG}) support systems},
	url = {https://www.tandfonline.com/doi/abs/10.1080/10437797.2024.2411172},
	doi = {10.1080/10437797.2024.2411172},
	abstract = {… the erosion of trust in generative AI technologies. Retrieval-augmented generation (RAG), is … However, when we connect the LLM to the knowledge base and use RAG, the response is …},
	journal = {Journal of Social Work …},
	author = {Perron, B. E. and Hiltz, B. S. and Khang, E. M. and {...}},
	year = {2025},
	note = {Publisher: Taylor \&Francis},
	annote = {6 cites: https://scholar.google.com/scholar?cites=3452522441290697481\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gutierrez_rag_2025,
	title = {From rag to memory: {Non}-parametric continual learning for large language models},
	url = {https://arxiv.org/abs/2502.14802},
	abstract = {… continual learning solution for production LLM systems. However, … Several RAG frameworks that engage an LLM to explicitly … To evaluate how well RAG systems retain factual memory …},
	journal = {arXiv preprint arXiv:2502.14802},
	author = {Gutiérrez, B. J. and Shu, Y. and Qi, W. and Zhou, S. and Su, Y.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {48 cites: https://scholar.google.com/scholar?cites=4370093944842488606\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kurland_augmenting_2025,
	title = {Augmenting large language models with automated, bibliometrics-powered literature search for knowledge distillation: a pilot study for common spinal pathologies},
	url = {https://journals.lww.com/neurosurgery/fulltext/2025/08000/augmenting_large_language_models_with_automated,.12.aspx},
	abstract = {… RAG retrieval augmented generation … that every statement in the LLM-generated summary is cited. By backing up LLM-generated summaries with citations, our approach provides …},
	journal = {…},
	author = {Kurland, D. B. and Alber, D. A. and Palla, A. and Souza, DN de and {...}},
	year = {2025},
	note = {Publisher: journals.lww.com},
	annote = {2 cites: https://scholar.google.com/scholar?cites=9562865735162372291\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yang_ragva_2025,
	title = {{RAGVA}: {Engineering} retrieval augmented generation-based virtual assistants in practice},
	url = {https://arxiv.org/abs/2502.14930},
	abstract = {… as how to update the LLM component within RAG systems while ensuring … hallucinations in LLM responses, the same approach might be excessive for evaluating hallucinations in RAG …},
	journal = {arXiv preprint arXiv …},
	author = {Yang, R. and Fu, M. and Tantithamthavorn, C. and Arora, C. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=14418171380637492742\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{arslan_driving_2024,
	title = {Driving sustainable energy transitions with a multi-source {RAG}-{LLM} system},
	url = {https://www.sciencedirect.com/science/article/pii/S0378778824009435},
	abstract = {… this gap, this research introduces an Energy Chatbot, a sustainable IS that utilizes Large Language Models (LLMs) integrated with multi-source Retrieval Augmented Generation (RAG). …},
	journal = {Energy and Buildings},
	author = {Arslan, M. and Mahdjoubi, L. and Munawar, S.},
	year = {2024},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {32 cites: https://scholar.google.com/scholar?cites=16302311826083610121\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jiao_duetrag_2024,
	title = {Duetrag: {Collaborative} retrieval-augmented generation},
	url = {https://arxiv.org/abs/2405.13002},
	abstract = {… RAG Recently, related work has studied how to improve the overall performance by fine-tuning the LLM or retriever in the RAG … learns to independently weigh the credibility of Mi and Me’…},
	journal = {arXiv preprint arXiv …},
	author = {Jiao, D. and Cai, L. and Huang, J. and Zhang, W. and Tang, S. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=5149747640294338321\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{simon_methodology_2024,
	title = {A methodology for evaluating rag systems: {A} case study on configuration dependency validation},
	url = {https://arxiv.org/abs/2410.08801},
	abstract = {… a RAG system and a vanilla LLM as they represent the factual and timely data on which an LLM can … What if we had not compared the RAG system to the vanilla LLM baseline? The …},
	journal = {arXiv preprint arXiv …},
	author = {Simon, S. and Mailach, A. and Dorn, J. and Siegmund, N.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {15 cites: https://scholar.google.com/scholar?cites=5407284471175610097\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{modran_llm_2024,
	title = {{LLM} intelligent agent tutoring in higher education courses using a {RAG} approach},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-83520-9_54},
	doi = {10.1007/978-3-031-83520-9_54},
	abstract = {… , integrating the Retrieval Augmented Generation (RAG) approach with a custom LLM. The … enhancing RAG models with auxiliary signals for improved factual consistency and reduced …},
	journal = {International Conference …},
	author = {Modran, H. A. and Bogdan, I. C. and Ursuțiu, D. and Samoilă, C. and {...}},
	year = {2024},
	note = {Publisher: Springer},
	annote = {17 cites: https://scholar.google.com/scholar?cites=7993910305260284188\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{saad-falcon_ares_2023,
	title = {Ares: {An} automated evaluation framework for retrieval-augmented generation systems},
	url = {https://arxiv.org/abs/2311.09476},
	abstract = {… confidence interval for each component of the RAG, we find the midpoint of each confidence interval and use the midpoints to rank the RAG … т for RAG ranking with the ARES LLM judge …},
	journal = {arXiv preprint arXiv …},
	author = {Saad-Falcon, J. and Khattab, O. and Potts, C. and {...}},
	year = {2023},
	note = {Publisher: arxiv.org},
	annote = {221 cites: https://scholar.google.com/scholar?cites=8307738739142450350\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{he_simple_2024,
	title = {A simple yet effective retrieval-augmented generation framework for the meta {KDD} cup 2024},
	url = {https://openreview.net/forum?id=s9QAadOn6H},
	abstract = {… and the full citation on the … LLM to generate reasoning trajectories and actions for specific tasks in an interleaved manner. For this task, we created a web retrieval tool that allows LLM …},
	journal = {… Augmented Generation},
	author = {He, L. and Li, R. and Shen, S. and Lu, J. and Zhu, L. and Su, Y. and {...}},
	year = {2024},
	note = {Publisher: openreview.net},
	annote = {1 cites: https://scholar.google.com/scholar?cites=5774590318351130086\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jacobs_leveraging_2024,
	title = {Leveraging lecture content for improved feedback: {Explorations} with gpt-4 and retrieval augmented generation},
	url = {https://ieeexplore.ieee.org/abstract/document/10663001/},
	abstract = {… to the Large Language Model GPT-4 as external knowledge source together with timestamps as metainformation by using RAG. The purpose of this is to prevent hallucinations and to …},
	journal = {2024 36th International Conference on …},
	author = {Jacobs, S. and Jaschke, S.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {22 cites: https://scholar.google.com/scholar?cites=6963657783652786698\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lu_boosting_2025,
	title = {Boosting {GPT} models for genomics analysis: generating trusted genetic variant annotations and interpretations through {RAG} and {Fine}-tuning},
	url = {https://academic.oup.com/bioinformaticsadvances/article-abstract/5/1/vbaf019/8002096},
	abstract = {… In our project, we aimed to improve LLM performance in genomics by adding variant annotation data to LLMs by retrieval-augmented generation (RAG) and fine-tuning techniques. …},
	journal = {Bioinformatics Advances},
	author = {Lu, S. and Cosgun, E.},
	year = {2025},
	note = {Publisher: academic.oup.com},
	annote = {6 cites: https://scholar.google.com/scholar?cites=15962531143552807802\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kazoom_vault_2025,
	title = {Vault: {Vigilant} adversarial updates via llm-driven retrieval-augmented generation for nli},
	url = {https://arxiv.org/abs/2508.00965},
	abstract = {… We introduce VAULT, a fully automated adversarial RAG pipeline … Next, we assemble these contexts into LLM prompts to generate ad… Then use high-confidence examples for training; …},
	journal = {arXiv preprint arXiv …},
	author = {Kazoom, R. and Cohen, O. and Puzis, R. and Shabtai, A. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=14838594765092081193\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{nazary_poison-rag_2025,
	title = {Poison-rag: {Adversarial} data poisoning attacks on retrieval-augmented generation in recommender systems},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-88717-8_18},
	doi = {10.1007/978-3-031-88717-8_18},
	abstract = {… Using item metadata generated through a large language model (LLM) and embeddings … LLMs now integrate RAG frameworks to address issues such as hallucinations and factual …},
	journal = {European Conference on Information …},
	author = {Nazary, F. and Deldjoo, Y. and Noia, T.},
	year = {2025},
	note = {Publisher: Springer},
	annote = {33 cites: https://scholar.google.com/scholar?cites=6960208266260787111\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_llm_2024,
	title = {Llm for data management},
	url = {https://dl.acm.org/doi/abs/10.14778/3685800.3685838},
	doi = {10.14778/3685800.3685838},
	abstract = {… for addressing these technical challenges, including hallucination of LLMs, high cost of … , we discuss retrieval augmented generation (RAG) techniques to address the hallucination …},
	journal = {Proceedings of the VLDB Endowment},
	author = {Li, G. and Zhou, X. and Zhao, X.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {32 cites: https://scholar.google.com/scholar?cites=14560112473923222841\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xiong_when_2024,
	title = {When graph meets retrieval augmented generation for wireless networks: {A} tutorial and case study},
	url = {https://arxiv.org/abs/2412.07189},
	abstract = {… frameworks in networking, including robust updates, mitigation of hallucination, and … In RAG, an LLM is augmented by an external knowledge base that retrieves and supplies relevant …},
	journal = {arXiv preprint arXiv …},
	author = {Xiong, Y. and Zhang, R. and Liu, Y. and Niyato, D. and Xiong, Z. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=527295384931914476\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lin_scirgen_2025,
	title = {{ScIRGen}: {Synthesize} {Realistic} and {Large}-{Scale} {RAG} {Dataset} for {Scientific} {Research}},
	url = {https://dl.acm.org/doi/abs/10.1145/3711896.3737432},
	doi = {10.1145/3711896.3737432},
	abstract = {… of relevant papers even in cases of ambiguous citations. … For each section, we design prompts to enable the LLM to … impact of LLM hallucinations, the second stage prompts the LLM to …},
	journal = {Proceedings of the 31st …},
	author = {Lin, J. and Dai, L. and Han, R. and Sui, Y. and Wang, R. and Sun, X. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=622604916009263386\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{han_rag-qa_2024,
	title = {{RAG}-{QA} arena: {Evaluating} domain robustness for long-form retrieval augmented question answering},
	url = {https://arxiv.org/abs/2407.13998},
	abstract = {… aligns with RAG-QA ARENA, but the 95\% confidence interval (… We rank these pairs with the same LLM evaluator as in the … We propose a reliable LLM-based evaluation framework, RAG…},
	journal = {arXiv preprint arXiv …},
	author = {Han, R. and Zhang, Y. and Qi, P. and Xu, Y. and Wang, J. and Liu, L. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {37 cites: https://scholar.google.com/scholar?cites=17625070466335194937\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{liu_how_2024,
	title = {How much can rag help the reasoning of llm?},
	url = {https://arxiv.org/abs/2410.02338},
	abstract = {… new knowledge and reducing hallucinations. However, the deep understanding of RAG remains limited, how does RAG help the reasoning process and can RAG help improve the …},
	journal = {arXiv preprint arXiv:2410.02338},
	author = {Liu, J. and Lin, J. and Liu, Y.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {28 cites: https://scholar.google.com/scholar?cites=13330534542726978415\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tang_symphony_2024,
	title = {Symphony: {Towards} {Trustworthy} {Question} {Answering} and {Verification} using {RAG} over {Multimodal} {Data} {Lakes}.},
	url = {http://sites.computer.org/debull/A24dec/p135.pdf},
	abstract = {… trust in LLM outputs. By 2023, analysts estimated that chatbots hallucinate as much as 27\% of the time1, and factual … natural language question Q requiring factual or objective answers, …},
	journal = {IEEE Data Eng …},
	author = {Tang, N. and Yang, C. and Zhang, Z. and Luo, Y. and Fan, J. and {...}},
	year = {2024},
	note = {Publisher: sites.computer.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=4008693753876353441\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{low_answering_2024,
	title = {Answering real-world clinical questions using large language model based systems},
	url = {https://arxiv.org/abs/2407.00541},
	abstract = {… is the use of a retrieval augmented generation (RAG), where an LLM is used to compile … or the whole reference from the LLM responses. For any citations that were still unmatched, …},
	journal = {arXiv preprint arXiv …},
	author = {Low, Y. S. and Jackson, M. L. and Hyde, R. J. and Brown, R. E. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=5293460211591113861\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{pradhan_ragevalx_2025,
	title = {{RAGEvalX}: {An} {Extended} {Framework} for {Measuring} {Core} {Accuracy}, {Context} {Integrity}, {Robustness}, and {Practical} {Statistics} in {RAG} {Pipelines}},
	url = {https://ijctece.com/index.php/IJCTEC/article/view/170},
	abstract = {… ABSTRACT: Retrieval-Augmented Generation (RAG) has emerged as a cornerstone for building context-aware and factual Large Language Model (LLM) applications. However, …},
	journal = {International Journal of Computer Technology and …},
	author = {Pradhan, R.},
	year = {2025},
	note = {Publisher: ijctece.com},
	annote = {2 cites: https://scholar.google.com/scholar?cites=4656182387844575639\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{shlyk_real_2024,
	title = {{REAL}: a retrieval-augmented entity linking approach for biomedical concept recognition},
	url = {https://air.unimi.it/handle/2434/1122499},
	abstract = {… RAG in the field of biomedical concept recognition (CR). In REAL, we employ RAG to assist the LLM … Our approach relies on the LLM to produce factual definitions for extracted mentions…},
	journal = {Proceedings of the 23rd …},
	author = {Shlyk, D. and Groza, T. and Montanelli, S. and Cavalleri, E. and {...}},
	year = {2024},
	note = {Publisher: air.unimi.it},
	annote = {22 cites: https://scholar.google.com/scholar?cites=4441233103482290795\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hohn_using_2024,
	title = {Using {Large} {Language} {Models} for {Robot}-{Assisted} {Therapeutic} {Role}-{Play}: {Factuality} is not enough!},
	url = {https://dl.acm.org/doi/abs/10.1145/3640794.3665886},
	doi = {10.1145/3640794.3665886},
	abstract = {… This article criticises hallucination-based LLM evaluations and … LLM language assessment at this stage. Positive effects of RAG as compared to the same implementation without RAG …},
	journal = {Proceedings of the 6th …},
	author = {Höhn, S. and Nasir, J. and Paikan, A. and Ziafati, P. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=2323704719943186501\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{belyi_luna_2024,
	title = {Luna: an evaluation foundation model to catch language model hallucinations with high accuracy and low cost},
	url = {https://arxiv.org/abs/2406.00975},
	abstract = {… of RAG in production settings, we identify long-context RAG … precision long-context RAG hallucination detection. Through extensive … We find that LLM responses often contain transition …},
	journal = {arXiv preprint arXiv:2406.00975},
	author = {Belyi, M. and Friel, R. and Shao, S. and Sanyal, A.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {13 cites: https://scholar.google.com/scholar?cites=12761075852832590516\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ayyamperumal_current_2024,
	title = {Current state of {LLM} {Risks} and {AI} {Guardrails}},
	url = {https://arxiv.org/abs/2406.12934},
	abstract = {… at the internal word embedding cite[] representation of an LLM without directly looking at the … RAG architectures address this vulnerability by grounding LLM responses in provided …},
	journal = {arXiv preprint arXiv:2406.12934},
	author = {Ayyamperumal, S. G. and Ge, L.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {66 cites: https://scholar.google.com/scholar?cites=5779214496612391258\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wu_automated_2025,
	title = {Automated literature research and review-generation method based on large language models},
	url = {https://academic.oup.com/nsr/article-abstract/12/6/nwaf169/8120226},
	abstract = {… ; LitLLM [20] combining RAG with LLM reranking to generate high-quality … hallucination mitigation, we employed a confusion matrix to classify outcomes according to whether the LLM …},
	journal = {National Science …},
	author = {Wu, S. and Ma, X. and Luo, D. and Li, L. and Shi, X. and Chang, X. and {...}},
	year = {2025},
	note = {Publisher: academic.oup.com},
	annote = {9 cites: https://scholar.google.com/scholar?cites=11318970096135449102\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{quddus_enhanced_2024,
	title = {Enhanced {VLSI} {Assertion} {Generation}: {Conforming} to {High}-{Level} {Specifications} and {Reducing} {LLM} {Hallucinations} with {RAG}},
	url = {https://ieeexplore.ieee.org/abstract/document/10830777/},
	abstract = {… of our proposed RAG-LLM framework for assertion generation. Our proposed approach can be divided into two broader categories: the RAG part and the LLM part. For RAG, we aim to …},
	journal = {DVCon Europe 2024 …},
	author = {Quddus, H. A. and Hossain, M. S. and Cevahir, Z. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=4817613609110234247\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{shandilya_boosting_2024,
	title = {Boosting the {Capabilities} of {Compact} {Models} in {Low}-{Data} {Contexts} with {Large} {Language} {Models} and {Retrieval}-{Augmented} {Generation}},
	url = {https://arxiv.org/abs/2410.00387},
	abstract = {… augmented generation (RAG) framework backed by a large language model (LLM) to correct … Instead of evaluating the retriever, we make the LLM itself generate confidence scores for …},
	journal = {arXiv preprint arXiv:2410.00387},
	author = {Shandilya, B. and Palmer, A.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=4883927227754094639\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{farias_chatbot_2025,
	title = {Chatbot {Based} on {Large} {Language} {Model} to {Improve} {Adherence} to {Exercise}-{Based} {Treatment} in {People} with {Knee} {Osteoarthritis}: {System} {Development}},
	url = {https://www.mdpi.com/2227-7080/13/4/140},
	abstract = {… In this work, we analyze three main types of RAG in the healthcare domain: RAG, Corrective … SELF-RAG benefits from the CoT structure by reducing hallucinations through the creation …},
	journal = {Technologies},
	author = {Farías, H. and Aroca, J. González and Ortiz, D.},
	year = {2025},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {2 cites: https://scholar.google.com/scholar?cites=3353181814962787603\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ateia_can_2025,
	title = {Can language models critique themselves? {Investigating} self-feedback for retrieval augmented generation at {BioASQ} 2025},
	url = {https://arxiv.org/abs/2508.05366},
	abstract = {… offers insights into LLM self-correction and informs future work on comparing the effectiveness of LLM-… However, challenges such as LLM hallucinations and the need to align with expert …},
	journal = {arXiv preprint arXiv:2508.05366},
	author = {Ateia, S. and Kruschwitz, U.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=18096421584188873796\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{earley_what_2023,
	title = {What executives need to know about knowledge management, large language models and generative {AI}},
	url = {https://www.ingentaconnect.com/content/hsp/ama/2023/00000009/00000003/art00003},
	abstract = {… in this paper is retrieval-augmented generation (RAG), which … The use of RAG virtually eliminated hallucinations, secured … entering the large language model (LLM)/ChatGPT market is …},
	journal = {Applied Marketing Analytics},
	author = {Earley, S.},
	year = {2023},
	note = {Publisher: ingentaconnect.com},
	annote = {21 cites: https://scholar.google.com/scholar?cites=8050187233294137761\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{serhan_vulnerabilities_2025,
	title = {Vulnerabilities of a {Medical} and {Scientific} based {RAG} {System}},
	url = {https://ieeexplore.ieee.org/abstract/document/11189974/},
	abstract = {… ) to extract the right answer using an LLM. RAG systems aim to reduce the problem of LLM hallucination and provide appropriate links to sources or references for the generated …},
	journal = {2025 Sixth International Conference …},
	author = {Serhan, J. H. and Nehme, B. F.},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{habib_taxtajweez_2024,
	title = {Taxtajweez: {A} large language model-based chatbot for income tax information in {Pakistan} using retrieval augmented generation ({RAG})},
	url = {https://journals.flvc.org/FLAIRS/article/view/135648},
	abstract = {… Generation (RAG) system powered by the OpenAI GPT-3.5-turbo LLM, designed specifically … , TaxTajweez leverages the RAG pipeline to mitigate model hallucinations, enhancing the …},
	journal = {The International …},
	author = {Habib, M. A. and Amin, S. and Oqba, M. and Jaipal, S. and {...}},
	year = {2024},
	note = {Publisher: journals.flvc.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=3752175312838229880\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{pelletier_evidence-based_2025,
	title = {Evidence-based knowledge synthesis and hypothesis validation: {Navigating} biomedical knowledge bases via explainable ai and agentic systems},
	url = {https://app.jove.com/t/67525/evidence-based-knowledge-synthesis-hypothesis-validation-navigating},
	abstract = {… Retrieval-Augmented Generation (RAG) is a system designed to minimize LLM hallucinations, grounding LLM … LLM (eg, ChatGPT) with PubMed, allowing for the identification of relevant …},
	journal = {Journal of Visualized …},
	author = {Pelletier, A. R. and Ramirez, J. and Sankar, B. S. and Adam, I. and {...}},
	year = {2025},
	note = {Publisher: app.jove.com},
	annote = {2 cites: https://scholar.google.com/scholar?cites=13515884443254744004\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kang_deficiency_2023,
	title = {Deficiency of large language models in finance: {An} empirical examination of hallucination},
	url = {https://arxiv.org/abs/2311.15548},
	abstract = {… LLM models’ capacity of querying historical stock prices. Third, to alleviate the hallucination … To mitigate hallucinations, we show the effectiveness of the RAG method and prompt-based …},
	journal = {arXiv preprint arXiv:2311.15548},
	author = {Kang, H. and Liu, X. Y.},
	year = {2023},
	note = {Publisher: arxiv.org},
	annote = {63 cites: https://scholar.google.com/scholar?cites=9687246067033995412\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{khadilkar_causal-counterfactual_2025,
	title = {Causal-{Counterfactual} {RAG}: {The} {Integration} of {Causal}-{Counterfactual} {Reasoning} into {RAG}},
	url = {https://arxiv.org/abs/2509.14435},
	abstract = {… This graph is populated by a powerful LLM that analyzes a … of fast vector search and LLM-based verification to ensure semantic … A synthesis LLM then analyzes both the factual evidence …},
	journal = {arXiv preprint arXiv:2509.14435},
	author = {Khadilkar, H. and Gupta, A.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=9282599006110180344\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mohsin_retrieval_2025,
	title = {Retrieval augmented generation with multi-modal llm framework for wireless environments},
	url = {https://arxiv.org/abs/2503.07670},
	abstract = {… captured in real time to train the RAG-based LLM for wireless environment perception. Due to … RAG-based LLM models do not hallucinate much in comparison to fine-tuned models due …},
	journal = {arXiv preprint arXiv …},
	author = {Mohsin, M. A. and Bilal, A. and Bhattacharya, S. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {12 cites: https://scholar.google.com/scholar?cites=2615256439138449109\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{qi_rag-optimized_2024,
	title = {Rag-optimized tibetan tourism llms: {Enhancing} accuracy and personalization},
	url = {https://dl.acm.org/doi/abs/10.1145/3703935.3704112},
	doi = {10.1145/3703935.3704112},
	abstract = {… within the LLM itself. This research demonstrates the potential of RAG technology in en… Therefore, we believe that RAG technology greatly helps optimize the hallucination problem …},
	journal = {Proceedings of the 2024 …},
	author = {Qi, J. and Yan, S. and Zhang, Y. and Zhang, W. and Jin, R. and Hu, Y. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=6338845751324332699\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sun_symbioticrag_2025,
	title = {Symbioticrag: {Enhancing} document intelligence through human-llm symbiotic collaboration},
	url = {https://arxiv.org/abs/2505.02418},
	abstract = {… reimagines RetrievalAugmented Generation (RAG) systems by … two critical challenges in current RAG systems: the inherently … Retrieval-Augmented Generation (RAG) LLM hallucination …},
	journal = {arXiv preprint arXiv …},
	author = {Sun, Q. and Bi, T. and Li, S. and Holden, E. J. and Duuring, P. and Niu, K. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=6426581733731892956\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sng_novel_2024,
	title = {A {Novel} {Approach} to {Eliminating} {Hallucinations} in {Large} {Language} {Model}-{Assisted} {Causal} {Discovery}},
	url = {https://ieeexplore.ieee.org/abstract/document/10937570/},
	abstract = {… Note that we share only the LLM hallucination rate for brevity as we are interested only if RAG improved the hallucination rate of each LLM in this experiment; whether edge …},
	journal = {2024 IEEE MIT Undergraduate …},
	author = {Sng, G. and Zhang, Y. and Mueller, K.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=12271180315485836117\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ong_surgeryllm_2024,
	title = {{SurgeryLLM}: a retrieval-augmented generation large language model framework for surgical decision support and workflow enhancement},
	url = {https://www.nature.com/articles/s41746-024-01391-3},
	abstract = {… RAG improves LLM output by incorporating information from an approved, trusted, curated … We sought to assess the feasibility of and potential benefits of incorporating RAG in a LLM …},
	journal = {npj Digital …},
	author = {Ong, C. S. and Obey, N. T. and Zheng, Y. and Cohan, A. and {...}},
	year = {2024},
	note = {Publisher: nature.com
Type: HTML},
	annote = {12 cites: https://scholar.google.com/scholar?cites=6914037088612671573\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yadav_aeroquery_2024,
	title = {Aeroquery rag and llm for aerospace query in designs, development, standards, certifications},
	url = {https://ieeexplore.ieee.org/abstract/document/10677028/},
	abstract = {… hallucinations, delays, and inefficiencies.To address this issue, our approach leverages the concepts of Retrieval-Augmented Generation (RAG) and … capabilities through RAG, enabling …},
	journal = {2024 IEEE International Conference on Electronics …},
	author = {Yadav, S.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=5892096234119712173\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{raja_rag-based_2024,
	title = {A rag-based medical assistant especially for infectious diseases},
	url = {https://ieeexplore.ieee.org/abstract/document/10544639/},
	abstract = {… retrieval augmented generation (RAG) blends external information sources with massive language models. Without requiring the LLM to be retrained, RAG ingests real-time factual … LLM…},
	journal = {2024 International Conference on …},
	author = {Raja, M. and Yuvaraajan, E.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {26 cites: https://scholar.google.com/scholar?cites=3607975816725138665\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zeeshan_llm-based_2025,
	title = {{LLM}-based retrieval-augmented generation: a novel framework for resource optimization in {6G} and beyond wireless networks},
	url = {https://ieeexplore.ieee.org/abstract/document/11180853/},
	abstract = {… For wireless resource optimization, grounding LLM decisions in up-to-date information from … distinguishes RAG-enhanced LLMs from standalone LLMs, which may hallucinate or rely on …},
	journal = {IEEE …},
	author = {Zeeshan, H. M. A. and Umer, M. and Akbar, M. and {...}},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=3538071448900057328\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{liu_judge_2025,
	title = {Judge as a judge: {Improving} the evaluation of retrieval-augmented generation through the judge-consistency of large language models},
	url = {https://arxiv.org/abs/2502.18817},
	abstract = {… that enhances LLM-based judgment models to generate more accurate evaluations for RAG … Additionally, the vanilla LLM prioritizes factual correctness, while the SFT model focuses on …},
	journal = {arXiv preprint arXiv …},
	author = {Liu, S. and Li, X. and Liu, Z. and Yan, Y. and Yang, C. and Zeng, Z. and Liu, Z. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=8610807125813307827\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bernardi_report_2024,
	title = {Report generation from x-ray imaging by retrieval-augmented generation and improved image-text matching},
	url = {https://ieeexplore.ieee.org/abstract/document/10650332/},
	abstract = {… the pretraining of the LLM network using RAG our approach is … A promising solution to improve LLM accuracy and credibility … represented by the Retrieval-Augmented Generation (RAG) […},
	journal = {2024 International Joint Conference …},
	author = {Bernardi, M. L. and Cimitile, M.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=14518371920370755733\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{pan_raglog_2024,
	title = {Raglog: {Log} anomaly detection using retrieval augmented generation},
	url = {https://ieeexplore.ieee.org/abstract/document/10607047/},
	abstract = {… responses with no other textual hallucination noted. … RAG construct with a locally deployed LLM. This is to address any privacy and confidentiality concerns with the use of online LLM. …},
	journal = {2024 IEEE World Forum on Public …},
	author = {Pan, J. and Liang, W. S. and Yidi, Y.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {32 cites: https://scholar.google.com/scholar?cites=10437888686392060556\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{craig_lmrac_2024,
	title = {{LmRaC}: a functionally extensible tool for {LLM} interrogation of user experimental results},
	url = {https://academic.oup.com/bioinformatics/article-abstract/40/12/btae679/7901216},
	abstract = {… LLM for reasoning tasks. In addition to making dynamic and quantitative data available to the LLM, RAG … Answers are drawn solely from this RAG with citations to the paragraph level, …},
	journal = {Bioinformatics},
	author = {Craig, D. B. and Drăghici, S.},
	year = {2024},
	note = {Publisher: academic.oup.com},
	annote = {6 cites: https://scholar.google.com/scholar?cites=13427567607201708204\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{reza_small_2025,
	title = {Small {Models}, {Big} {Support}: {A} {Local} {LLM} {Framework} for {Teacher}-{Centric} {Content} {Creation} and {Assessment} using {RAG} and {CAG}},
	url = {https://arxiv.org/abs/2506.05925},
	abstract = {… RAG and an LLM-based verifier layer, improves both factual … susceptible to jailbreaking and hallucination, where prompt … an additional small (3B) LLM acting as a dedicated response …},
	journal = {arXiv preprint arXiv …},
	author = {Reza, Z. and Mazur, A. and Dugdale, M. T. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=15888464459098242988\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{suri_visdom_2024,
	title = {Visdom: {Multi}-document qa with visually rich elements using multimodal retrieval-augmented generation},
	url = {https://arxiv.org/abs/2412.10704},
	abstract = {… Evidence Curation: As a first step, we prompt the LLM to extract relevant evidence from the … the model’s reasoning abilities by filtering out noise and helps mitigate LLM hallucinations. …},
	journal = {arXiv preprint arXiv …},
	author = {Suri, M. and Mathur, P. and Dernoncourt, F. and Goswami, K. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {15 cites: https://scholar.google.com/scholar?cites=16982561432449497178\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kimura_mapping_2024,
	title = {Mapping drug terms via integration of a retrieval-augmented generation algorithm with a large language model},
	url = {https://synapse.koreamed.org/articles/1516088909},
	abstract = {… RAG that distinguished the final candidates from the baseline. We assessed the efficacy of the LLM with RAG … To prevent LLM hallucinations, all candidate strings were verified against …},
	journal = {Healthcare Informatics …},
	author = {Kimura, E. and Kawakami, Y. and Inoue, S. and {...}},
	year = {2024},
	note = {Publisher: synapse.koreamed.org
Type: HTML},
	annote = {3 cites: https://scholar.google.com/scholar?cites=6438417688950679490\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_lokis_2025,
	title = {Loki's {Dance} of {Illusions}: {A} {Comprehensive} {Survey} of {Hallucination} in {Large} {Language} {Models}},
	url = {https://arxiv.org/abs/2507.02870},
	abstract = {… First, we establish the first unified theoretical framework for LLM hallucinations, formally re… In conclusion, RAG constitutes a fundamental approach to augmenting the capabilities of …},
	journal = {arXiv preprint arXiv …},
	author = {Li, C. and Wang, P. and Wang, C. and Zhang, L. and Liu, Z. and Ye, Q. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=8483581003262576050\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{leung_rag_2024,
	title = {{RAG} for {Question}-{Answering} for {Vocal} {Training} {Based} on {Domain} {Knowledge} {Base}},
	url = {https://ieeexplore.ieee.org/abstract/document/10780718/},
	abstract = {… details employing Retrieval-Augmented Generation (RAG) … inherent challenges such as hallucination, where large models … a vertical large language model utilizing the RAG framework …},
	journal = {… on Behavioural and …},
	author = {Leung, C. J. and Yi, Y. and Kuai, L. and Li, Z. and Yeung, S. A. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=2638836707594024886\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yang_implementation_2025,
	title = {Implementation of {Retrieval} {Augmented} {Generation} ({RAG}) {Model} {Using} {LLM}: {A} {RapidMiner}-{Based} {Approach}},
	journal = {Smart Media Journal},
	author = {Yang, C. B. and Kim, Y. S.},
	year = {2025},
	note = {Publisher: THE KOREAN INSTITUTE OF …
Type: CITATION},
	annote = {1 cites: https://scholar.google.com/scholar?cites=15042512177892548700\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{finardi_chronicles_2024,
	title = {The chronicles of rag: {The} retriever, the chunk and the generator},
	url = {https://arxiv.org/abs/2401.07883},
	abstract = {… possible to obtain the maximum score that an evaluated LLM could reach for a RAG system. … Demonstrating confidence in transfer learning, we found that a few examples were sufficient…},
	journal = {arXiv preprint arXiv …},
	author = {Finardi, P. and Avila, L. and Castaldoni, R. and Gengo, P. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {70 cites: https://scholar.google.com/scholar?cites=6322674734516933520\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{leemann_auto-gda_2024,
	title = {Auto-{GDA}: {Automatic} domain adaptation for efficient grounding verification in retrieval-augmented generation},
	url = {https://arxiv.org/abs/2410.03461},
	abstract = {… While retrieval-augmented generation (RAG) has been shown to enhance factuality of large language model (LLM) outputs, LLMs still suffer from hallucination, generating incorrect or …},
	journal = {arXiv preprint arXiv …},
	author = {Leemann, T. and Petridis, P. and Vietri, G. and Manousakas, D. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=16684932453437756581\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{erickson_llm_2025,
	title = {{LLM} experimentation through knowledge graphs: {Towards} improved management, repeatability, and verification},
	url = {https://www.sciencedirect.com/science/article/pii/S1570826824000398},
	abstract = {… hallucinations and hence provides more insight into where in the LLM’s response a hallucination … , verifying, and analyzing LLM responses using RAG systems and Knowledge Graphs (…},
	journal = {Journal of Web …},
	author = {Erickson, J. S. and Santos, H. and Pinheiro, V. and Mccusker, J. P. and {...}},
	year = {2025},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {6 cites: https://scholar.google.com/scholar?cites=15758768412692764075\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yu_defense_2024,
	title = {In defense of rag in the era of long-context language models},
	url = {https://arxiv.org/abs/2409.01666},
	abstract = {… making RAG less attractive. Recent studies show that long-context LLMs significantly … RAG in long-context applications. Unlike the existing works favoring the long-context LLM over RAG…},
	journal = {arXiv preprint arXiv:2409.01666},
	author = {Yu, T. and Xu, A. and Akkiraju, R.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {33 cites: https://scholar.google.com/scholar?cites=3261789221345650637\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{barron_domain-specific_2024,
	title = {Domain-specific retrieval-augmented generation using vector stores, knowledge graphs, and tensor factorization},
	url = {https://ieeexplore.ieee.org/abstract/document/10903241/},
	abstract = {… a highly domainspecific LLM framework, that integrates RAG with KG and a vector store (VS) that store factual domain specific information. Importantly, to avoid hallucinations in the KG, …},
	journal = {2024 International …},
	author = {Barron, R. C. and Grantcharov, V. and Wanna, S. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {26 cites: https://scholar.google.com/scholar?cites=18354744134457292298\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ma_knowledge_2025,
	title = {Knowledge graph-based retrieval-augmented generation for schema matching},
	url = {https://arxiv.org/abs/2501.08686},
	abstract = {… To highlight the hallucinations mitigation of our KGRAG4SM, we ask the LLM to return the results for the given schema-matching questions and provide explanations. Case Verification. …},
	journal = {arXiv preprint arXiv:2501.08686},
	author = {Ma, C. and Chakrabarti, S. and Khan, A. and Molnár, B.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {12 cites: https://scholar.google.com/scholar?cites=8052228466880312455\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_raft_2024,
	title = {Raft: {Adapting} language model to domain specific rag},
	url = {https://arxiv.org/abs/2403.10131},
	abstract = {… is trained as a general-purpose LLM is largely dependent on the … Here, we know apriori the domain in which the LLM will be … and in-addition, clearly citing sources enhances the model’s …},
	journal = {arXiv preprint arXiv …},
	author = {Zhang, T. and Patil, S. G. and Jain, N. and Shen, S. and Zaharia, M. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {293 cites: https://scholar.google.com/scholar?cites=13079680544097419518\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{friel_chainpoll_2023,
	title = {Chainpoll: {A} high efficacy method for llm hallucination detection},
	url = {https://arxiv.org/abs/2310.18344},
	abstract = {… We propose 2 new metrics to quantify LLM hallucinations - Adherence and Correctness. The former pertinent to Retrieval Augmented Generation (RAG) workflows measuring an LLM’s …},
	journal = {arXiv preprint arXiv:2310.18344},
	author = {Friel, R. and Sanyal, A.},
	year = {2023},
	note = {Publisher: arxiv.org},
	annote = {59 cites: https://scholar.google.com/scholar?cites=15516900341174820542\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{kurniawan_cykg-rag_2024,
	title = {{CyKG}-{RAG}: {Towards} knowledge-graph enhanced retrieval augmented generation for cybersecurity},
	url = {http://eprints.cs.univie.ac.at/8178/1/RAGE-KG_2024_paper_1_Andreas%20Ekelhart.pdf},
	abstract = {… RAG approaches do not allow to consider pivotal aspects such as network structure, threat attack patterns, and intricate factual … search are passed to the LLM together with the prompt 5G…},
	publisher = {eprints.cs.univie.ac.at},
	author = {Kurniawan, K. and Kiesling, E. and Ekelhart, A.},
	year = {2024},
	note = {Type: PDF},
	annote = {10 cites: https://scholar.google.com/scholar?cites=6794514740430011457\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_biomedrag_2025,
	title = {Biomedrag: {A} retrieval augmented large language model for biomedicine},
	url = {https://www.sciencedirect.com/science/article/pii/S1532046424001874},
	abstract = {… Retrieval-augmented generation (RAG) involves a solution by retrieving knowledge from an established database to enhance the performance of large language models (LLM)… the LLM. …},
	journal = {Journal of Biomedical Informatics},
	author = {Li, M. and Kilicoglu, H. and Xu, H. and Zhang, R.},
	year = {2025},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {54 cites: https://scholar.google.com/scholar?cites=3061707042905241241\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tan_prompt-based_2024,
	title = {Prompt-based code completion via multi-retrieval augmented generation},
	url = {https://dl.acm.org/doi/abs/10.1145/3725812},
	doi = {10.1145/3725812},
	abstract = {… For the LinUCB algorithm, we set the coefficient of the upper confidence bound = 0.1. We conduct LLM generation and embedding using the vLLM framework [31]. For fine-tuning (…},
	journal = {ACM Transactions on …},
	author = {Tan, H. and Luo, Q. and Jiang, L. and Zhan, Z. and Li, J. and Zhang, H. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {25 cites: https://scholar.google.com/scholar?cites=4301838894088811971\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{smajic_large_2025,
	title = {Large language models for structured and semi-structured data, recommender systems and knowledge base engineering: a survey of recent techniques and …},
	url = {https://www.mdpi.com/2079-9292/14/15/3153},
	abstract = {… Although this review primarily focuses on the technical and application aspects of LLM-… like RAG and KG enhancement significantly improve factual accuracy and reduce hallucinations. …},
	journal = {Electronics},
	author = {Smajić, A. and Karlović, R. and Dasko, M. Bobanović and Lorencin, I.},
	year = {2025},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {2 cites: https://scholar.google.com/scholar?cites=15246741090460759908\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{pyae_developing_2025,
	title = {Developing a {RAG} {Agent} for {Personalized} {Fitness} and {Dietary} {Guidance}},
	url = {https://ieeexplore.ieee.org/abstract/document/10961967/},
	abstract = {… retrieves and generates sequentially, while Advanced RAG ensures factual accuracy and … SouLLMate, an adaptive LLM-driven system that leverages advanced technologies like RAG …},
	journal = {… on Digital Arts …},
	author = {Pyae, M. S. and Phyo, S. S. and Kyaw, STMM and Lin, T. S. and {...}},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=3085699893652842577\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bezerra_llmquoter_2025,
	title = {Llmquoter: enhancing rag capabilities through efficient quote extraction from large contexts},
	url = {https://arxiv.org/abs/2501.05554},
	abstract = {… The applications of LLM distillation are diverse, ranging from mitigating hallucinations to … To achieve this, we employ a distillation process in which a large LLM generates high-…},
	journal = {arXiv preprint arXiv:2501.05554},
	author = {Bezerra, Y. F. and Weigang, L.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=10962313501956010851\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chan_entagents_2025,
	title = {{ENTAgents}: {AI} {Agents} for {Complex} {Knowledge} {Otolaryngology}},
	url = {https://www.medrxiv.org/content/10.1101/2025.01.01.25319863.abstract},
	doi = {10.1101/2025.01.01.25319863.abstract},
	abstract = {… for LLM applications to solve the problem of hallucinations. … LLM agentic framework, ENTAgents, which is a system addressing the medical specialty in otolaryngology and utilizing RAG …},
	journal = {medRxiv},
	author = {Chan, T. K. and Dinh, N. D.},
	year = {2025},
	note = {Publisher: medrxiv.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=371479613511824285\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{church_emerging_2024,
	title = {Emerging trends: a gentle introduction to {RAG}},
	url = {https://www.cambridge.org/core/journals/natural-language-engineering/article/emerging-trends-a-gentle-introduction-to-rag/4FF461F4066A0C16135F2D2849E3356A},
	abstract = {… Without RAG, an LLM trained on 2021 data would likely hallucinate when asked about 2023. RAG fills in gaps in the knowledge base by uploading a pdf file, sample\_files/World\_Series/…},
	journal = {Natural Language …},
	author = {Church, K. W. and Sun, J. and Yue, R. and Vickers, P. and {...}},
	year = {2024},
	note = {Publisher: cambridge.org},
	annote = {15 cites: https://scholar.google.com/scholar?cites=5107420906077054491\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kulkarni_reinforcement_2024,
	title = {Reinforcement learning for optimizing rag for domain chatbots},
	url = {https://arxiv.org/abs/2401.06800},
	abstract = {… and an LLM, we optimize the number of LLM tokens using … to the RAG, which interacts with the RAG pipeline through … a prompt that minimizes hallucinations with ChatGPT. Apart from …},
	journal = {arXiv preprint arXiv …},
	author = {Kulkarni, M. and Tangarajan, P. and Kim, K. and Trivedi, A.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {58 cites: https://scholar.google.com/scholar?cites=12979246661155719502\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{peng_data_2024,
	title = {Data extraction attacks in retrieval-augmented generation via backdoors},
	url = {https://arxiv.org/abs/2411.01705},
	abstract = {… Wikichat: Stopping the hallucination of large language model chatbots by few-shot … a scenario where the RAG system owner directly uses a publicly available LLM that has already been …},
	journal = {arXiv preprint arXiv:2411.01705},
	author = {Peng, Y. and Wang, J. and Yu, H. and Houmansadr, A.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {14 cites: https://scholar.google.com/scholar?cites=16166113158937249550\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{eghbali_-hallucinator_2024,
	title = {De-{Hallucinator}: {Mitigating} {LLM} {Hallucinations} in {Code} {Generation} {Tasks} via {Iterative} {Grounding}},
	url = {https://arxiv.org/abs/2401.01701},
	abstract = {… Retrieval-augmented generation (RAG) [28] proposes to retrieve relevant context based on … we refer to as the RAG prompt type. The idea of augmenting an LLM with well-grounded facts …},
	journal = {arXiv preprint arXiv:2401.01701},
	author = {Eghbali, A. and Pradel, M.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {12 cites: https://scholar.google.com/scholar?cites=5119097762907317543\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{dhole_conqret_2024,
	title = {{ConQRet}: {Benchmarking} fine-grained evaluation of retrieval augmented argumentation with {LLM} judges},
	url = {https://arxiv.org/abs/2412.05206},
	abstract = {… the LLM Judges are prompted to generate the individual RAG … LLM judges are reliable for identifying hallucinated content in their argument. To simulate varying levels of hallucinations, …},
	journal = {arXiv preprint arXiv:2412.05206},
	author = {Dhole, K. D. and Shu, K. and Agichtein, E.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=8460364279904819554\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{huly_old_2024,
	title = {Old ir methods meet rag},
	url = {https://dl.acm.org/doi/abs/10.1145/3626772.3657935},
	doi = {10.1145/3626772.3657935},
	abstract = {… reduce hallucinations in the generated content [23]. RAG improves the quality of the LLM … of sparse methods for RAG-LLM, is inferior by far to other sparse methods: MRF and RM3. …},
	journal = {Proceedings of the 47th …},
	author = {Huly, O. and Pogrebinsky, I. and Carmel, D. and Kurland, O. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {12 cites: https://scholar.google.com/scholar?cites=13354419230224441161\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{reichman_retrieval-augmented_2024,
	title = {Retrieval-{Augmented} {Generation}: {Is} {Dense} {Passage} {Retrieval} {Retrieving}},
	url = {https://southnlp.github.io/southnlp2024/papers/southnlp2024-poster-46.pdf},
	abstract = {… the retrieval augmented generation (RAG) paradigm for improving large language models (LLM… Trust in these systems to give accurate information is crucial to their ability to help people …},
	journal = {arXiv preprint arXiv:2402.11035},
	author = {Reichman, B. and Heck, L.},
	year = {2024},
	note = {Publisher: southnlp.github.io
Type: PDF},
	annote = {9 cites: https://scholar.google.com/scholar?cites=16615190141675526813\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wahidur_legal_2025,
	title = {Legal query rag},
	url = {https://ieeexplore.ieee.org/abstract/document/10887211/},
	abstract = {… RAG aids in reducing hallucinations and facilitates continuous knowledge updates and … embedding LLM and the generative LLM. In contrast, the RAG Layer integrates advanced RAG …},
	journal = {IEEE Access},
	author = {Wahidur, R. S. M. and Kim, S. and Choi, H. and Bhatti, D. S. and Lee, H. N.},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=18141756472948912294\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{suresh_towards_2024,
	title = {Towards a rag-based summarization agent for the electron-ion collider},
	url = {https://arxiv.org/abs/2403.15729},
	abstract = {… Since its proposal, RAG methods have continuously evolved to achieve superior performance in grounding LLM to truth and reducing hallucinations. Different RAG methods that involve …},
	journal = {arXiv preprint arXiv:2403.15729},
	author = {Suresh, K. and Kackar, N. and Schleck, L. and Fanelli, C.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=6003240469462917210\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tan_htmlrag_2025,
	title = {Htmlrag: {Html} is better than plain text for modeling retrieved knowledge in rag systems},
	url = {https://dl.acm.org/doi/abs/10.1145/3696410.3714546},
	doi = {10.1145/3696410.3714546},
	abstract = {… Retrieval-Augmented Generation (RAG) has been shown to improve knowledge capabilities and alleviate the hallucination … the overall performance of RAG, so we evaluate the LLM’s …},
	journal = {Proceedings of the ACM …},
	author = {Tan, J. and Dou, Z. and Wang, W. and Wang, M. and Chen, W. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {24 cites: https://scholar.google.com/scholar?cites=3896676312188928357\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{naik_probabilistic_2024,
	title = {Probabilistic consensus through ensemble validation: {A} framework for llm reliability},
	url = {https://arxiv.org/abs/2411.06535},
	abstract = {… Retrieval-Augmented Generation (RAG) (Lewis et al., 2020; Izacard \&Grave, 2021), aim to enhance factual accuracy by grounding LLM outputs in trusted … context, RAG systems have …},
	journal = {arXiv preprint arXiv:2411.06535},
	author = {Naik, N.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=14496573760623608614\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cao_learn_2023,
	title = {Learn to refuse: {Making} large language models more controllable and reliable through knowledge scope limitation and refusal mechanism},
	url = {https://arxiv.org/abs/2311.01041},
	abstract = {… type of hallucination, namely fact-conflicting hallucination, … Our objective is for the LLM to function solely as a machine … with the general retrieval augmented generation (RAG) method. In …},
	journal = {arXiv preprint arXiv:2311.01041},
	author = {Cao, L.},
	year = {2023},
	note = {Publisher: arxiv.org},
	annote = {30 cites: https://scholar.google.com/scholar?cites=10761848468626124652\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cederlund_llmrag_2024,
	title = {Llmrag: {An} optimized digital support service using llm and retrieval-augmented generation},
	url = {https://ieeexplore.ieee.org/abstract/document/10710181/},
	abstract = {… The introduction of an LLM agent as a digital co-worker to IT technicians in support … as Retrieval-Augmented Generation (RAG), the LLM is equipped to avoid generating hallucinations […},
	journal = {2024 9th International …},
	author = {Cederlund, O. and Alawadi, S. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=8688809595962775578\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xu_chattf_2024,
	title = {{ChatTf}: a knowledge graph-enhanced intelligent {Q}\&{A} system for mitigating factuality hallucinations in traditional folklore},
	url = {https://ieeexplore.ieee.org/abstract/document/10734210/},
	abstract = {… Retrieval-Augmented Generation framework (TFKG-RAG) based on TFKG to provide traditional folklore knowledge to large language models, mitigating factuality hallucinations in … LLM …},
	journal = {IEEE Access},
	author = {Xu, J. and Zhang, H. and Zhang, H. and Lu, J. and Xiao, G.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=3455721844744894169\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{temsah_authors_2025,
	title = {Authors' {Reply}: {Citation} {Accuracy} {Challenges} {Posed} by {Large} {Language} {Models}},
	url = {https://mededu.jmir.org/2025/1/e73698},
	abstract = {… In conclusion, while RAG augmented by HAT represents a potential advancement in reducing hallucinations, the … RAG-HAT: a hallucination-aware tuning pipeline for LLM in …},
	journal = {JMIR Medical …},
	author = {Temsah, M. H. and Al-Eyadhy, A. and Jamal, A. and {...}},
	year = {2025},
	note = {Publisher: mededu.jmir.org
Type: HTML},
	annote = {1 cites: https://scholar.google.com/scholar?cites=15465648315149913169\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wu_addressing_2025,
	title = {Addressing the sustainable {AI} trilemma: a case study on {LLM} agents and {RAG}},
	url = {https://arxiv.org/abs/2501.08262},
	abstract = {… While traditional LLM applications depend solely on the … -enabled LLM agents or Retrieval-Augmented Generation (RAG) [22… advanced applications by mitigating LLM …},
	journal = {arXiv preprint arXiv:2501.08262},
	author = {Wu, H. and Wang, X. and Fan, Z.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=4952354644127220339\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ngangmeni_swamped_2025,
	title = {Swamped with {Too} {Many} {Articles}? {GraphRAG} {Makes} {Getting} {Started} {Easy}},
	url = {https://www.mdpi.com/2673-2688/6/3/47},
	abstract = {… using two sets of Large Language Model (LLM)-generated … Additionally, the use of randomization gives more confidence … desirable for testing RAG performance than LLM-generated …},
	journal = {AI},
	author = {Ngangmeni, J. and Rawat, D. B.},
	year = {2025},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {3 cites: https://scholar.google.com/scholar?cites=14207712381092610439\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lima_know_2024,
	title = {Know {Your} {RAG}: {Dataset} {Taxonomy} and {Generation} {Strategies} for {Evaluating} {RAG} {Systems}},
	url = {https://arxiv.org/abs/2411.19710},
	abstract = {… ) have been developed for automated LLMassisted evaluation of RAG systems. While these … probability of an LLM hallucination grows with each query. These hallucinations can lead to …},
	journal = {arXiv preprint arXiv …},
	author = {Lima, RT De and Gupta, S. and Berrospi, C. and Mishra, L. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {11 cites: https://scholar.google.com/scholar?cites=1856366695649245396\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{stankov_application_2025,
	title = {Application of a {Large} {Language} {Model} for {Air} {Pollution} {Analysis} by {Using} a {RAG} {System}},
	url = {https://journals.ru.lv/index.php/ETR/article/view/8603},
	abstract = {… what RAG systems are and how they help increase the credibility of the text generated by LLM models (reducing their hallucinations) … An approach for the development of a RAG system …},
	journal = {… . Proceedings of the International Scientific and …},
	author = {Stankov, S. and Velinova, D.},
	year = {2025},
	note = {Publisher: journals.ru.lv},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{shi_mkrag_2025,
	title = {Mkrag: {Medical} knowledge retrieval augmented generation for medical question answering},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC12099378/},
	abstract = {… This work underscores the potential of RAG to enhance LLM performance, offering a … LLM performance on the CounterFact dataset 6 , which consists of general domain factual …},
	journal = {AMIA Annual …},
	author = {Shi, Y. and Xu, S. and Yang, T. and Liu, Z. and Liu, T. and Li, X. and {...}},
	year = {2025},
	note = {Publisher: pmc.ncbi.nlm.nih.gov
Type: HTML},
	annote = {12 cites: https://scholar.google.com/scholar?cites=12975153458587709981\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yang_knowing_2025,
	title = {Knowing {You} {Don}'t {Know}: {Learning} {When} to {Continue} {Search} in {Multi}-round {RAG} through {Self}-{Practicing}},
	url = {https://dl.acm.org/doi/abs/10.1145/3726302.3730018},
	doi = {10.1145/3726302.3730018},
	abstract = {… ) pairs has proven effective for single-step RAG [2, 11], when an LLM can rapidly learn to map a … We suspect that a general-purpose LLM may be over-confident and generate too many …},
	journal = {… of the 48th International ACM SIGIR …},
	author = {Yang, D. and Zeng, L. and Rao, J. and Zhang, Y.},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=1218776371926378040\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{suresh_towards_2024-1,
	title = {Towards a {RAG}-based summarization for the {Electron} {Ion} {Collider}},
	url = {https://iopscience.iop.org/article/10.1088/1748-0221/19/07/C07006/meta},
	doi = {10.1088/1748-0221/19/07/C07006},
	abstract = {… Since its proposal, RAG methods have continuously evolved to achieve superior performance in grounding LLM to truth and reducing hallucinations. Different RAG methods that involve …},
	journal = {Journal of …},
	author = {Suresh, K. and Kackar, N. and Schleck, L. and {...}},
	year = {2024},
	note = {Publisher: iopscience.iop.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=281290892611573152\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhao_ontology-aware_2024,
	title = {Ontology-aware rag for improved question-answering in cybersecurity education},
	url = {https://arxiv.org/abs/2412.14191},
	abstract = {… RAG approach helps reduce hallucinations and address domain knowledge issues to some extent, the reliability of LLM-… cybersecurity content using RAG and validate LLM outputs with …},
	journal = {arXiv preprint arXiv …},
	author = {Zhao, C. and Agrawal, G. and Kumarage, T. and Tan, Z. and Deng, Y. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {13 cites: https://scholar.google.com/scholar?cites=12234561701133786699\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{edwards_hybrid_2024,
	title = {Hybrid context retrieval augmented generation pipeline: {LLM}-augmented knowledge graphs and vector database for accreditation reporting assistance},
	url = {https://arxiv.org/abs/2405.15436},
	abstract = {… into an LLM as a prompt to generate a relevant response. The challenges of the Naive RAG … , and generation issues, including hallucinations where generated responses are not based …},
	journal = {arXiv preprint arXiv:2405.15436},
	author = {Edwards, C.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {13 cites: https://scholar.google.com/scholar?cites=10302777912516646186\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{filice_generating_2025,
	title = {Generating {Diverse} {Q}\&{A} {Benchmarks} for {RAG} {Evaluation} with {DataMorgana}},
	url = {https://arxiv.org/abs/2501.12789},
	abstract = {… Enhancing llm factual accuracy with rag to counter hallucinations: A case study on domain-specific queries in private knowledge-bases. arXiv preprint arXiv:2403.10446 (2024). [18] …},
	journal = {arXiv preprint arXiv …},
	author = {Filice, S. and Horowitz, G. and Carmel, D. and Karnin, Z. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {18 cites: https://scholar.google.com/scholar?cites=16001197041498721054\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{nian_w-rag_2025,
	title = {W-rag: {Weakly} supervised dense retrieval in rag for open-domain question answering},
	url = {https://dl.acm.org/doi/abs/10.1145/3731120.3744578},
	doi = {10.1145/3731120.3744578},
	abstract = {… -RAG, a method that draws weak training signals from the downstream task (such as OpenQA) of an LLM, … This consistency gives us confidence that the W-RAG method generalizes well …},
	journal = {… of the 2025 International ACM SIGIR …},
	author = {Nian, J. and Peng, Z. and Wang, Q. and Fang, Y.},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {11 cites: https://scholar.google.com/scholar?cites=909159631036313673\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cohen_wixqa_2025,
	title = {Wixqa: {A} multi-dataset benchmark for enterprise retrieval-augmented generation},
	url = {https://arxiv.org/abs/2505.08643},
	abstract = {… context and avoided introducing factual errors or hallucinations. For our experiments, we utilized GPT-4o as the LLM judge for this metric. • Context Recall: An LLM-based judge metric …},
	journal = {arXiv preprint arXiv …},
	author = {Cohen, D. and Burg, L. and Pykhnivskyi, S. and Gur, H. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=6262079592907767244\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{soto-jimenez_rag-based_2024,
	title = {{RAG}-based question-answering systems for closed-domains: {Development} of a prototype for the pollution domain},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-66329-1_37},
	doi = {10.1007/978-3-031-66329-1_37},
	abstract = {… This section presents the RAG-based proposal which uses a specific-domain database to reduce LLM hallucination. The scope of the proposal covers the design and development of a …},
	journal = {Intelligent Systems …},
	author = {Soto-Jiménez, F. and Martínez-Velásquez, M. and {...}},
	year = {2024},
	note = {Publisher: Springer},
	annote = {6 cites: https://scholar.google.com/scholar?cites=14707145771573377466\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_you_2025,
	title = {You {Don}'t {Need} {Pre}-built {Graphs} for {RAG}: {Retrieval} {Augmented} {Generation} with {Adaptive} {Reasoning} {Structures}},
	url = {https://arxiv.org/abs/2508.06105},
	abstract = {… Retrieval-augmented generation (RAG) addresses this by retrieving query-relevant contexts from knowledge bases to support LLM … becomes prematurely confident and produces an …},
	journal = {arXiv preprint arXiv …},
	author = {Chen, S. and Zhou, C. and Yuan, Z. and Zhang, Q. and Cui, Z. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=14964198666480567286\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kortukov_studying_2024,
	title = {Studying large language model behaviors under context-memory conflicts with real documents},
	url = {https://arxiv.org/abs/2404.16032},
	abstract = {… -world RAG application and allows us to study LLM knowledge-… , or irrelevant documents into the LLM prompt. However, … goal is to achieve factual correctness using RAG. Asserting the …},
	journal = {arXiv preprint arXiv …},
	author = {Kortukov, E. and Rubinstein, A. and Nguyen, E. and Oh, S. J.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=14824962745773710020\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{singh_advanced_2025,
	title = {Advanced {Real}-{Time} {Fraud} {Detection} {Using} {RAG}-{Based} {LLMs}},
	url = {https://arxiv.org/abs/2501.15290},
	abstract = {… This section discusses the primary advantages of the RAG based LLM model over the … Additionally, the challenge of LLM hallucination, where the model may generate unnecessary or …},
	journal = {arXiv preprint arXiv:2501.15290},
	author = {Singh, G. and Singh, P. and Singh, M.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=15174249190886148717\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jeong_study_2024,
	title = {A study on the implementation method of an agent-based advanced rag system using graph},
	url = {https://arxiv.org/abs/2407.19994},
	abstract = {… , and being less susceptible to hallucinations, this study aims … database and then using an LLM to verify the relevance of … standard RAG pipeline to generate a response using the LLM…},
	journal = {arXiv preprint arXiv:2407.19994},
	author = {Jeong, C.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {23 cites: https://scholar.google.com/scholar?cites=17450820596081688000\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_jmlr_2024,
	title = {Jmlr: {Joint} medical llm and retrieval training for enhancing reasoning and professional question answering capability},
	url = {https://arxiv.org/abs/2402.17887},
	abstract = {… (RAG) has limited success in addressing hallucinations. Unlike previous methods in RAG … separately from the LLM, we introduce JMLR (for Jointly trains LLM and information Retrieval) …},
	journal = {arXiv preprint arXiv:2402.17887},
	author = {Wang, J. and Yang, Z. and Yao, Z. and Yu, H.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {52 cites: https://scholar.google.com/scholar?cites=11300045855614682854\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tas_turk-lettucedetect_2025,
	title = {Turk-{LettuceDetect}: {A} {Hallucination} {Detection} {Models} for {Turkish} {RAG} {Applications}},
	url = {https://arxiv.org/abs/2509.17671},
	abstract = {… When analyzing LLM hallucination behavior, we observe that GPT-4.1 and Mistral models achieve high recall (up to 0.9938), indicating a strong tendency to generate content flagged as …},
	journal = {arXiv preprint arXiv …},
	author = {Taş, S. and Huseyni, M. E. and Ezerceli, Ö and Bayraktar, R. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{parekh_cc-rag_2025,
	title = {{CC}-{RAG}: {Structured} {Multi}-{Hop} {Reasoning} via {Theme}-{Based} {Causal} {Graphs}},
	url = {https://arxiv.org/abs/2506.08364},
	abstract = {… 2024) improves LLM factuality by retrieving … -RAG outperforms standard RAG and zero-shot LLM baselines both in terms of quantitative metrics and qualitative assessments using LLM-…},
	journal = {arXiv preprint arXiv:2506.08364},
	author = {Parekh, J. R. and Jiang, P. and Han, J.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yilma_telecomrag_2025,
	title = {Telecomrag: {Taming} telecom standards with retrieval augmented generation and llms},
	url = {https://dl.acm.org/doi/abs/10.1145/3711992.3711996},
	doi = {10.1145/3711992.3711996},
	abstract = {… to reduce the hallucination phenomenon and provide reliable factual information, other LLM-… The LLM input is passed to the Base LLM in the response generation \&optimization module…},
	journal = {ACM SIGCOMM …},
	author = {Yilma, G. M. and Ayala-Romero, J. A. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {22 cites: https://scholar.google.com/scholar?cites=10028848744718696803\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{tsai_comparative_2024,
	title = {Comparative analysis of automatic literature review using {Mistral} large language model and human reviewers},
	url = {https://assets-eu.researchsquare.com/files/rs-4022248/v1_covered_31b35741-397a-47a8-aa52-d71a4150153f.pdf},
	abstract = {… of applying the Mistral LLM, augmented with Retrieval-Augmented Generation, to the … LLM-powered literature review itself is not immune to the generic issue of LLM hallucination in LLM …},
	publisher = {assets-eu.researchsquare.com},
	author = {Tsai, H. C. and Huang, Y. F. and Kuo, C. W.},
	year = {2024},
	note = {Type: PDF},
	annote = {8 cites: https://scholar.google.com/scholar?cites=160372166208575874\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{umer_transforming_2025,
	title = {Transforming education: tackling the two sigma problem with {AI} in journal clubs–a proof of concept},
	url = {https://www.nature.com/articles/s41405-025-00338-4},
	abstract = {… Retrieval-Augmented Generation (RAG) mitigates this by … of a RAG-enhanced LLM to support journal club discussions. … neutral response, citing both advantages and limitations. The …},
	journal = {BDJ open},
	author = {Umer, F. and Naved, N. and Naseem, A. and Mansoor, A. and Kazmi, S. M. R.},
	year = {2025},
	note = {Publisher: nature.com
Type: HTML},
	annote = {2 cites: https://scholar.google.com/scholar?cites=3543525384991038758\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xu_enhancing_2024,
	title = {Enhancing retrieval-augmented generation models with knowledge graphs: {Innovative} practices through a dual-pathway approach},
	url = {https://link.springer.com/chapter/10.1007/978-981-97-5678-0_34},
	doi = {10.1007/978-981-97-5678-0_34},
	abstract = {… of RAG technology can alleviate the hallucination and data … graph extraction by the large language model is not the focus of … the optimization of large language model-based knowledge …},
	journal = {International Conference on Intelligent …},
	author = {Xu, S. and Chen, M. and Chen, S.},
	year = {2024},
	note = {Publisher: Springer},
	annote = {13 cites: https://scholar.google.com/scholar?cites=533969324374752324\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sundar_revolutionizing_2024,
	title = {Revolutionizing assessment: {Ai}-powered evaluation with rag and llm technologies},
	url = {https://ieeexplore.ieee.org/abstract/document/10760285/},
	abstract = {… We discovered ChatGPT's ability to advance medical … AI systems confront challenges like hallucinations, legal dangers, and … Next, we turn to the question of evaluation of RAG and other …},
	journal = {2024 2nd International …},
	author = {Sundar, K. and Manohar, E. and Vijay, K. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=6965386305768847184\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sahin_llm_2024,
	title = {{LLM} and {RAG}-{Based} {Question} {Answering} {Assistant} for {Enterprise} {Knowledge} {Management}},
	url = {https://ieeexplore.ieee.org/abstract/document/10773564/},
	abstract = {… hallucination. Methods such as RAG can be employed to mitigate the effects of hallucination… Consequently, the objective of this study is to develop a large language model-supported …},
	journal = {2024 9th International Conference …},
	author = {Şahin, G. and Varol, K. and Pak, B. K.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=6632073974883199209\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{khaled_evaluating_2024,
	title = {Evaluating large language models for {Arabic} sentiment analysis: {A} comparative study using retrieval-augmented generation},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050924030114},
	abstract = {… experimenting generative generative LLMs and RAG models on text classification and … LLM model and the RAG methodology for handling the generative generative LLM hallucinations…},
	journal = {Procedia Computer Science},
	author = {Khaled, S. and Mohamed, E. H. and Medhat, W.},
	year = {2024},
	note = {Publisher: Elsevier},
	annote = {7 cites: https://scholar.google.com/scholar?cites=14783660775537520257\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{rackauckas_evaluating_2024,
	title = {Evaluating rag-fusion with ragelo: an automated elo-based framework},
	url = {https://arxiv.org/abs/2406.14783},
	abstract = {… ,” we leverage an LLM-as-a-judge process, where a strong LLM is used to evaluate the … the judging LLM, enabling higher reliability and trust when evaluating different RAG pipelines. …},
	journal = {arXiv preprint arXiv:2406.14783},
	author = {Rackauckas, Z. and Câmara, A. and Zavrel, J.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {20 cites: https://scholar.google.com/scholar?cites=3803527351290174638\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tamanna_chatgpt_2024,
	title = {{ChatGPT} {Inaccuracy} {Mitigation} during {Technical} {Report} {Understanding}: {Are} {We} {There} {Yet}?},
	url = {https://arxiv.org/abs/2411.07360},
	abstract = {… RAG-based ChatGPT (ie, ChatGPT … hallucinated by producing incorrect or irrelevant answers. We manually examined each hallucination case and identified two limitations in ChatGPT …},
	journal = {arXiv preprint arXiv …},
	author = {Tamanna, S. B. and Uddin, G. and Wang, S. and Xia, L. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=14460566733887982835\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{fuad_llm-ref_2024,
	title = {Llm-ref: {Enhancing} reference handling in technical writing with large language models},
	url = {https://arxiv.org/abs/2411.00294},
	abstract = {… of our tool over existing RAG-based systems. The proposed LLM-Ref demonstrates significant per… Despite their popularity, RAG-based systems fall short in offering citations. While …},
	journal = {arXiv preprint arXiv:2411.00294},
	author = {Fuad, K. A. A. and Chen, L.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=8421619142305935819\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{saha_enhancing_2024,
	title = {Enhancing international graduate student experience through ai-driven support systems: {A} llm and rag-based approach},
	url = {https://ieeexplore.ieee.org/abstract/document/10651944/},
	abstract = {… 3 shows that the custom RAG-LLM provides specific, … useful, whereas the regular LLM provides general information lacking … generate fabricated responses or hallucinate, the use of a …},
	journal = {… Conference on Data Science and Its …},
	author = {Saha, B. and Saha, U.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {15 cites: https://scholar.google.com/scholar?cites=17389974647713734702\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_survey_2025,
	title = {A survey of personalization: {From} rag to agent},
	url = {https://arxiv.org/abs/2504.10147},
	abstract = {… RAG, we further extend its capabilities into the realm of Personalized LLM-based Agents, which enhance traditional RAG … as outdated responses and hallucinations, which severely …},
	journal = {arXiv preprint arXiv …},
	author = {Li, X. and Jia, P. and Xu, D. and Wen, Y. and Zhang, Y. and Zhang, W. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=13598375597135687351\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{reed_augmented_2025,
	title = {Augmented and {Programmatically} {Optimized} {LLM} {Prompts} {Reduce} {Chemical} {Hallucinations}},
	url = {https://pubs.acs.org/doi/abs/10.1021/acs.jcim.4c02322},
	doi = {10.1021/acs.jcim.4c02322},
	abstract = {… for predicting TPSA that combines RAG and MIPRO using a commercially available LLM, … -mini LLM directly to 11.76 RMSE when MIPRO and RAG were employed on top of that LLM for …},
	journal = {Journal of Chemical Information and Modeling},
	author = {Reed, S. M.},
	year = {2025},
	note = {Publisher: ACS Publications},
	annote = {7 cites: https://scholar.google.com/scholar?cites=1041803362683835489\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yao_controlnet_2025,
	title = {Controlnet: {A} firewall for rag-based llm system},
	url = {https://arxiv.org/abs/2504.09593},
	abstract = {… By incorporating external knowledge retrieval, RAG mitigates the hallucination problem … A typical RAG-based LLM system operates by processing user queries through a structured …},
	journal = {arXiv preprint arXiv …},
	author = {Yao, H. and Shi, H. and Chen, Y. and Jiang, Y. and Wang, C. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=17184153539705524448\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{vakilzadeh_development_2025,
	title = {The {Development} of a {RAG}-{Based} {Artificial} {Intelligence} {Research} {Assistant} ({AIRA})},
	url = {https://publications.aaahq.org/jis/article/doi/10.2308/ISYS-2024-041/13751},
	doi = {10.2308/ISYS-2024-041/13751},
	abstract = {… responses that ChatGPT provided academic citations, five of … retrieval-augmented generation. Prompt construction is about how we feed everything into the large language model (LLM) …},
	journal = {Journal of Information Systems},
	author = {Vakilzadeh, H. and Wood, D. A.},
	year = {2025},
	note = {Publisher: publications.aaahq.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=8935640156528460825\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tang_adapting_2025,
	title = {Adapting to non-stationary environments: {Multi}-armed bandit enhanced retrieval-augmented generation on knowledge graphs},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/33380},
	abstract = {… Retrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs that encapsulate extensive factual … method across different Large Language Model generators to …},
	journal = {Proceedings of the AAAI Conference on …},
	author = {Tang, X. and Li, J. and Du, N. and Xie, S.},
	year = {2025},
	note = {Publisher: ojs.aaai.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=11039882875941050259\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhu_rageval_2024,
	title = {Rageval: {Scenario} specific rag evaluation dataset generation framework},
	url = {https://arxiv.org/abs/2408.01262},
	abstract = {… To validate the consistency between LLM evaluations and human assessments, we compare the LLM-reported metrics—completeness, hallucination, and irrelevance—with those …},
	journal = {arXiv preprint arXiv …},
	author = {Zhu, K. and Luo, Y. and Xu, D. and Yan, Y. and Liu, Z. and Yu, S. and Wang, R. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {42 cites: https://scholar.google.com/scholar?cites=6231387698896710491\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{finlayson_post-training_2025,
	title = {Post-training an {LLM} for {RAG}? {Train} on {Self}-{Generated} {Demonstrations}},
	url = {https://arxiv.org/abs/2502.10596},
	abstract = {… LLM RAG performance by fine-tuning on retrievalaugmented instructions, but must beware that this can cause undesirable model behaviors like hallucinations… for training RAG-enabled …},
	journal = {arXiv preprint arXiv …},
	author = {Finlayson, M. and Kulikov, I. and Bikel, D. M. and Oguz, B. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=11621621758816681271\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{setty_improving_2024,
	title = {Improving retrieval for rag based question answering models on financial documents},
	url = {https://arxiv.org/abs/2404.07221},
	abstract = {… documents into the large language model. In order to prevent hallucinations, some sort of in-… Fake RAG uses the same LLM model but is given the correct context to answer the original …},
	journal = {arXiv preprint arXiv …},
	author = {Setty, S. and Thakkar, H. and Lee, A. and Chung, E. and Vidra, N.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {66 cites: https://scholar.google.com/scholar?cites=1059382806500561393\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{galat_llm_2025,
	title = {{LLM} {Ensemble} for {RAG}: {Role} of context length in zero-shot question answering for {BioASQ} {Challenge}},
	url = {https://arxiv.org/abs/2509.08596},
	abstract = {… through RAG consistently improves answer quality and factual accuracy compared to LLM … terms LLM or Large Language Model in their title, and 3 additional papers used the terms …},
	journal = {arXiv preprint arXiv:2509.08596},
	author = {Galat, D. and Molla-Aliod, D.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=8381388855515088697\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{iacob_are_2024,
	title = {Are {LLMs} {Hallucinating} {When} {Answering} {Specific} {Questions}? {Experiments} with a {RAG} {Pipeline}},
	url = {https://link.springer.com/chapter/10.1007/978-981-96-0161-5_39},
	doi = {10.1007/978-981-96-0161-5_39},
	abstract = {… To spot possible hallucinations of the LLM we strive to detect outliers in random variables … we could say that the response is a potential hallucination of the LLM. We could set k as being …},
	journal = {International Conference on Informatics in …},
	author = {Iacob, I. and Silaghi, G. Cosmin},
	year = {2024},
	note = {Publisher: Springer},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{belyi_luna_2025,
	title = {Luna: {A} lightweight evaluation model to catch language model hallucinations with high accuracy and low cost},
	url = {https://aclanthology.org/2025.coling-industry.34/},
	abstract = {… of RAG in production settings, we identify long-context RAG … high precision long-context RAG hallucination detection. Through … 2023) LLM judges leverage LLM’s inherent reasoning …},
	journal = {Proceedings of the 31st …},
	author = {Belyi, M. and Friel, R. and Shao, S. and Sanyal, A.},
	year = {2025},
	note = {Publisher: aclanthology.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=3741245355529004407\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sriramanan_llm-check_2024,
	title = {Llm-check: {Investigating} detection of hallucinations in large language models},
	url = {https://proceedings.neurips.cc/paper_files/paper/2024/hash/3c1e1fdf305195cd620c118aaa9717ad-Abstract-Conference.html},
	abstract = {… detection in scenarios where ground-truth references are also available, such as in the setting of Retrieval-Augmented Generation (RAG). We demonstrate that the proposed detection …},
	journal = {Advances in …},
	author = {Sriramanan, G. and Bharti, S. and Sadasivan, V. S. and {...}},
	year = {2024},
	note = {Publisher: proceedings.neurips.cc},
	annote = {78 cites: https://scholar.google.com/scholar?cites=2261074376577085139\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{freiberger_explainable_2025,
	title = {Explainable {AI} in {Usable} {Privacy} and {Security}: {Challenges} and {Opportunities}},
	url = {https://arxiv.org/abs/2504.12931},
	abstract = {… retrieval-augmented generation (RAG). We identify a need for adaptive explanation strategies tailored to different user profiles for LLM-… investigate LLM explanations and hallucinations …},
	journal = {arXiv preprint arXiv:2504.12931},
	author = {Freiberger, V. and Fleig, A. and Buchmann, E.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=12970304759239581855\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{su_hybrid_2024,
	title = {Hybrid {RAG}-empowered multi-modal {LLM} for secure data management in {Internet} of {Medical} {Things}: {A} diffusion-based contract approach},
	url = {https://ieeexplore.ieee.org/abstract/document/10812735/},
	abstract = {… To this end, this article proposes a hybrid Retrieval-Augmented Generation (RAG)-… of MLLMs by using hybrid RAG that filters different unimodal RAG results using multimodal metrics …},
	journal = {IEEE Internet of …},
	author = {Su, C. and Wen, J. and Kang, J. and Wang, Y. and Su, Y. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {17 cites: https://scholar.google.com/scholar?cites=12942681086641147734\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sacoransky_chatgpt_2024,
	title = {{ChatGPT} and assistive {AI} in structured radiology reporting: {A} systematic review},
	url = {https://www.sciencedirect.com/science/article/pii/S0363018824001130},
	abstract = {… ChatGPT and assistive AI have significant potential to transform radiology reporting, … few-shot prompting, ChatGPT, and Retrieval Augmented Generation (RAG) into diagnostic workflows…},
	journal = {Current Problems in Diagnostic …},
	author = {Sacoransky, E. and Kwan, B. Y. M. and Soboleski, D.},
	year = {2024},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {30 cites: https://scholar.google.com/scholar?cites=15743640941502575201\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_eyegpt_2024-1,
	title = {Eyegpt: {Ophthalmic} assistant with large language models},
	url = {https://arxiv.org/abs/2403.00840},
	abstract = {… LLM designed specifically for ophthalmology, using three optimization strategies including role-playing, finetuning, and retrieval-augmented generation. In … In this study, hallucination …},
	journal = {arXiv preprint arXiv …},
	author = {Chen, X. and Zhao, Z. and Zhang, W. and Xu, P. and Gao, L. and Xu, M. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {15 cites: https://scholar.google.com/scholar?cites=3715639277138225745\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_targeting_2024,
	title = {Targeting the core: {A} simple and effective method to attack rag-based agents via direct llm manipulation},
	url = {https://arxiv.org/abs/2412.04415},
	abstract = {… , hallucinations, privacy breaches, and a lack of transparency. This paper investigates a critical vulnerability: adversarial attacks targeting the LLM … the fragility of existing LLM defenses. …},
	journal = {arXiv preprint arXiv:2412.04415},
	author = {Li, X. and Li, Z. and Kosuga, Y. and Yoshida, Y. and Bian, V.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=16512403062065243353\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ateia_bioragent_2025,
	title = {{BioRAGent}: {A} {Retrieval}-{Augmented} {Generation} {System} for {Showcasing} {Generative} {Query} {Expansion} and {Domain}-{Specific} {Search} for {Scientific} {Q}\&{A}},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-88720-8_1},
	doi = {10.1007/978-3-031-88720-8_1},
	abstract = {We present BioRAGent, an interactive web-based retrieval-augmented generation (RAG) system for biomedical question answering. The system uses large language models (LLMs) for …},
	journal = {European Conference on Information Retrieval},
	author = {Ateia, S. and Kruschwitz, U.},
	year = {2025},
	note = {Publisher: Springer},
	annote = {8 cites: https://scholar.google.com/scholar?cites=18013506536045467981\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{esposito_beyond_2024,
	title = {Beyond words: {On} large language models actionability in mission-critical risk analysis},
	url = {https://dl.acm.org/doi/abs/10.1145/3674805.3695401},
	doi = {10.1145/3674805.3695401},
	abstract = {… A large language model can quickly summarize information … of Retrieval-Augmented Generation and fine-tuned LLM in … show that RAG-assisted LLMs have the lowest hallucination …},
	journal = {Proceedings of the 18th …},
	author = {Esposito, M. and Palagiano, F. and Lenarduzzi, V. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {17 cites: https://scholar.google.com/scholar?cites=3696068581501575709\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zheng_miriad_2025,
	title = {{MIRIAD}: {Augmenting} {LLMs} with millions of medical query-response pairs},
	url = {https://arxiv.org/abs/2506.06091},
	abstract = {… LLM-based annotation to a small sample of 15,000 QA pairs, instructing GPT-4 to assess each example along two axes: factual … retrieval-augmented generation (RAG), we compare RAG…},
	journal = {arXiv preprint arXiv …},
	author = {Zheng, Q. and Abdullah, S. and Rawal, S. and Zakka, C. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=8668798185947233115\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{koh_clara_2025,
	title = {Clara: {Context}-{Aware} {RAG}-{LLM} {Framework} for {Anomaly} {Detection} in {Mobile} {Device} {Sensors}},
	url = {https://ieeexplore.ieee.org/abstract/document/11058456/},
	abstract = {… Retrieval-Augmented Generation (RAG) with LLM for anomaly detection in mobile sensor data. RAG enhances LLM … that RAG can improve the factuality and relevance of LLM outputs …},
	journal = {2025 26th IEEE …},
	author = {Koh, C. Y. and DeMedeiros, K. and {...}},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=702829328491583192\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xue_enhanced_2024,
	title = {Enhanced multimodal rag-llm for accurate visual question answering},
	url = {https://arxiv.org/abs/2412.20927},
	abstract = {… an enhanced multimodal RAGLLM framework for accurate … Bing, “Can ChatGPT-like generative models guarantee factual … , “Overcoming llm challenges using rag-driven precision in …},
	journal = {arXiv preprint arXiv …},
	author = {Xue, J. and Deng, Q. and Yu, F. and Wang, Y. and Wang, J. and Li, Y.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=9306517477284890726\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{song_chain--thought_2025,
	title = {Chain-of-{Thought} {Poisoning} {Attacks} against {R1}-based {Retrieval}-{Augmented} {Generation} {Systems}},
	url = {https://arxiv.org/abs/2505.16367},
	abstract = {… bases, RAG systems can enhance the factual accuracy and reliability of LLM outputs. … To investigate the relationship between the size of the underlying large language model in RAG …},
	journal = {arXiv preprint arXiv:2505.16367},
	author = {Song, H. and Liu, Y. and Zhang, R. and Guo, J. and Fan, Y.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=5842729376700208042\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{liang_thames_2024,
	title = {Thames: {An} end-to-end tool for hallucination mitigation and evaluation in large language models},
	url = {https://arxiv.org/abs/2409.11353},
	abstract = {… Unlike these frameworks, our type definitions were designed not for retrievalaugmented generation (RAG) systems but for general LLM hallucination evaluation. We also introduced …},
	journal = {arXiv preprint arXiv …},
	author = {Liang, M. and Arun, A. and Wu, Z. and Munoz, C. and Lutch, J. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=1454726485119428388\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{liu_application_2025,
	title = {Application of large language models in medicine},
	url = {https://www.nature.com/articles/s44222-025-00279-5},
	abstract = {… to minimize hallucinations, … ChatGPT on clinical scenario evaluations, particularly in terms of completeness and safety. Another example is QA-RAG 61 , which utilizes RAG with LLM for …},
	journal = {Nature Reviews …},
	author = {Liu, F. and Zhou, H. and Gu, B. and Zou, X. and Huang, J. and Wu, J. and {...}},
	year = {2025},
	note = {Publisher: nature.com},
	annote = {36 cites: https://scholar.google.com/scholar?cites=14888431820532864449\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhu_emerge_2024,
	title = {Emerge: {Enhancing} multimodal electronic health records predictive modeling with retrieval-augmented generation},
	url = {https://dl.acm.org/doi/abs/10.1145/3627673.3679582},
	doi = {10.1145/3627673.3679582},
	abstract = {… entity, the entities extracted by LLM have hallucination issues. Accurately … RAG-driven enhancement pipeline. “LM” denotes Language Model (basically BERT-based model), while “LLM…},
	journal = {Proceedings of the 33rd …},
	author = {Zhu, Y. and Ren, C. and Wang, Z. and Zheng, X. and Xie, S. and Feng, J. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {16 cites: https://scholar.google.com/scholar?cites=10522475661334200264\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{saleh_sg-rag_2024,
	title = {{SG}-{RAG}: {Multi}-hop question answering with large language models through knowledge graphs},
	url = {https://aclanthology.org/2024.icnlsp-1.45.pdf},
	abstract = {… Large Language Models (LLM) such as GPT3 and Llama tend to hallucinate, especially for … LLM for our evaluation. To analyze that issue further, we evaluated SG-RAG, and RAG on the …},
	journal = {Proceedings of the 7th International …},
	author = {Saleh, A. O. M. and Tür, G. and Saygin, Y.},
	year = {2024},
	note = {Publisher: aclanthology.org
Type: PDF},
	annote = {14 cites: https://scholar.google.com/scholar?cites=12940249369471617569\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_r3-rag_2025,
	title = {R3-{RAG}: {Learning} {Step}-by-{Step} {Reasoning} and {Retrieval} for {LLMs} via {Reinforcement} {Learning}},
	url = {https://arxiv.org/abs/2505.23794},
	abstract = {… factual correctness and mitigate hallucination. However, dense retrievers often become the bottleneck of RAG … R3-RAG, which uses Reinforcement learning to make the LLM learn how …},
	journal = {arXiv preprint arXiv …},
	author = {Li, Y. and Luo, Q. and Li, X. and Li, B. and Cheng, Q. and Wang, B. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=2202413308951124685\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kamra_evaluating_2025,
	title = {Evaluating reinforcement learning based models for test time enhancement in rag},
	url = {https://ieeexplore.ieee.org/abstract/document/11086322/},
	abstract = {… context for LLMbased generation. The result is a retrieval-augmented system that not only improves factual accuracy and retrieval performance but also significantly reduces the …},
	journal = {2025 Second International …},
	author = {Kamra, V. and Gupta, L. and Arora, D. and {...}},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=8808588706033683880\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lesperance_taxonomic_2025,
	title = {Taxonomic {Reasoning} for {Rare} {Arthropods}: {Combining} {Dense} {Image} {Captioning} and {RAG} for {Interpretable} {Classification}},
	url = {https://arxiv.org/abs/2503.10886},
	abstract = {… the RAG model relative to the Naïve LLM shows reasoning over the additional retrieved context provides a small boost to LLM confidence … The RAG models did not see the same sharp …},
	journal = {arXiv preprint arXiv …},
	author = {Lesperance, N. and Ratnasingham, S. and Taylor, G. W.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{abeysinghe_challenges_2024,
	title = {The challenges of evaluating llm applications: {An} analysis of automated, human, and llm-based approaches},
	url = {https://arxiv.org/abs/2406.03339},
	abstract = {… Other components performance such as the semantic search used for retrieval in RAG is not … But this is not the case always, in most instances LLM evaluators tend to be overly confident …},
	journal = {arXiv preprint arXiv:2406.03339},
	author = {Abeysinghe, B. and Circi, R.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {45 cites: https://scholar.google.com/scholar?cites=8440309076377236445\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{susnjak_automating_2025,
	title = {Automating research synthesis with domain-specific large language model fine-tuning},
	url = {https://dl.acm.org/doi/abs/10.1145/3715964},
	doi = {10.1145/3715964},
	abstract = {… We also devise mechanisms to mitigate LLM hallucination and to ensure that all LLM … the setup of LLM technologies, the selection of LLM types, detailed RAG implementation, fine-…},
	journal = {ACM Transactions on …},
	author = {Susnjak, T. and Hwang, P. and Reyes, N. and Barczak, A. L. C. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {70 cites: https://scholar.google.com/scholar?cites=18108954119793305275\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{kieu_empowering_2024,
	title = {Empowering {Automotive} {Software} {Development} with {LLM}-{RAG} {Integration}-{A} study on leveraging the {RAG}-framework for {AUTOSAR} and automotive safety standards …},
	url = {https://gupea.ub.gu.se/handle/2077/83663},
	abstract = {… This study calls attention to the complex nature of hallucinations and errors that can occur even with accurate context. To overcome some of the challenges found in an …},
	publisher = {gupea.ub.gu.se},
	author = {KIEU, K. and BERGSTRAND, O.},
	year = {2024},
	annote = {1 cites: https://scholar.google.com/scholar?cites=470317404598937666\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ravi_lynx_2024,
	title = {Lynx: {An} open source hallucination evaluation model},
	url = {https://arxiv.org/abs/2407.08488},
	abstract = {… detection LLM that is capable of advanced reasoning on challenging real-world hallucination … , our work focuses on the problem of hallucination detection as it applies to RAG settings. …},
	journal = {arXiv preprint arXiv …},
	author = {Ravi, S. S. and Mielczarek, B. and Kannappan, A. and Kiela, D. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {39 cites: https://scholar.google.com/scholar?cites=5365173808562309956\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{benzinho_llm_2024,
	title = {{LLM} {Based} {Chatbot} for {Farm}-to-{Fork} {Blockchain} {Traceability} {Platform}},
	url = {https://www.mdpi.com/2076-3417/14/19/8856},
	abstract = {… RAG provides models with sources of information that can be cited and consulted by the user, thus enhancing confidence … agent powered by RAG-based LLM technology, we can …},
	journal = {applied sciences},
	author = {Benzinho, J. and Ferreira, J. and Batista, J. and Pereira, L. and {...}},
	year = {2024},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {14 cites: https://scholar.google.com/scholar?cites=8089360200515886142\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{park_development_2024,
	title = {Development of dental consultation chatbot using retrieval augmented llm},
	journal = {The Journal of the Institute of Internet …},
	author = {Park, J.},
	year = {2024},
	note = {Publisher: The Institute of Internet …
Type: CITATION},
	annote = {12 cites: https://scholar.google.com/scholar?cites=9885430596662511404\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{arslan_sustainable_2024,
	title = {Sustainable digitalization of business with multi-agent rag and llm},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050924023627},
	abstract = {… and enhance factuality and reasoning in LLMs. MetaGPT [33] introduces a specialized LLM … AutoGen2 [11], an open-source framework, enables developers to create LLM applications …},
	journal = {Procedia Computer Science},
	author = {Arslan, M. and Munawar, S. and Cruz, C.},
	year = {2024},
	note = {Publisher: Elsevier},
	annote = {9 cites: https://scholar.google.com/scholar?cites=16966315537929128694\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{leto_toward_2024,
	title = {Toward optimal search and retrieval for rag},
	url = {https://arxiv.org/abs/2411.07396},
	abstract = {… with separately trained retriever and LLM components, as training … citation metrics vary with more retrieved documents, adding new data to a small literature on attributed QA with RAG…},
	journal = {arXiv preprint arXiv …},
	author = {Leto, A. and Aguerrebere, C. and Bhati, I. and Willke, T. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=18044014408648081011\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tan_revprag_2024,
	title = {{RevPRAG}: {Revealing} {Poisoning} {Attacks} in {Retrieval}-{Augmented} {Generation} through {LLM} {Activation} {Analysis}},
	url = {https://arxiv.org/abs/2411.18948},
	abstract = {… We conducted experiments to test if our approach can distinguish hallucinations and RAG poisoning. Fig. 8 shows the t-SNE representation of mean activations for poisoned response …},
	journal = {arXiv preprint arXiv …},
	author = {Tan, X. and Luan, H. and Luo, M. and Sun, X. and Chen, P. and Dai, J.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=9301520858541085949\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sui_fidelis_2024,
	title = {Fidelis: {Faithful} reasoning in large language model for knowledge graph question answering},
	url = {https://arxiv.org/abs/2405.13873},
	abstract = {… hallucinations and enable verifiable reasoning, we propose FiDeLiS to improve the factuality of LLM … Our retrieval module Path-RAG mitigate this issue by constraining candidate set St …},
	journal = {arXiv preprint arXiv …},
	author = {Sui, Y. and He, Y. and Liu, N. and He, X. and Wang, K. and Hooi, B.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {23 cites: https://scholar.google.com/scholar?cites=6642180392331070871\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{filice_generating_2025-1,
	title = {Generating {Q}\&{A} benchmarks for {RAG} evaluation in enterprise settings},
	url = {https://aclanthology.org/2025.acl-industry.33/},
	abstract = {… LLM (Claude Sonnet 3.5). Appendix D provides further details about the metrics, as well as the LLM … Enhancing llm factual accuracy with rag to counter hallucinations: A case study on …},
	journal = {Proceedings of the …},
	author = {Filice, S. and Horowitz, G. and Carmel, D. and Karnin, Z. and {...}},
	year = {2025},
	note = {Publisher: aclanthology.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=4302723135814899985\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{grislain_rag_2025,
	title = {Rag with differential privacy},
	url = {https://ieeexplore.ieee.org/abstract/document/11050672/},
	abstract = {… (RAG) has emerged as the dominant technique to provide Large Language Models (LLM) with fresh and relevant context, mitigating the risk of hallucinations and improving the overall …},
	journal = {2025 IEEE Conference on Artificial Intelligence …},
	author = {Grislain, N.},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=5613457736743362108\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_ai-driven_2025,
	title = {{AI}-{Driven} {Post}-{Earthquake} {Emergency} {Material} {Demand} {Prediction}: {Integrating} {RAG} with {Reasoning} {Large} {Language} {Model}},
	url = {https://ieeexplore.ieee.org/abstract/document/11029010/},
	abstract = {… online information, employing retrieval-augmented generation (RAG) to mitigate the lack of specialized knowledge and reduce hallucinations in large language model outputs. Chain-of-…},
	journal = {IEEE …},
	author = {Zhang, S. and Huang, M. and Liu, S. and Meng, F. and Xie, Y. and Ren, X. and {...}},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ko_enhancing_2024,
	title = {Enhancing python learning through retrieval-augmented generation: {A} theoretical and applied innovation in generative ai education},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-65884-6_17},
	doi = {10.1007/978-3-031-65884-6_17},
	abstract = {… the synergy between Retrieval-Augmented Generation (RAG) and … how integrating RAG with LLMs like ChatGPT can overcome … learning, and boosting learner confidence. Implementing …},
	journal = {International Conference on Innovative …},
	author = {Ko, H. T. and Liu, Y. K. and Tsai, Y. C. and Suen, S.},
	year = {2024},
	note = {Publisher: Springer},
	annote = {6 cites: https://scholar.google.com/scholar?cites=9846713209787245063\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yang_agrigpt_2025,
	title = {Agrigpt: {A} large language model ecosystem for agriculture},
	url = {https://arxiv.org/abs/2508.08632},
	abstract = {… factual grounding, we employ Tri-RAG, a three-channel RetrievalAugmented Generation … , we propose a three channel RetrievalAugmented Generation (Tri-RAG) framework that incor…},
	journal = {arXiv preprint arXiv …},
	author = {Yang, B. and Zhang, Y. and Feng, L. and Chen, Y. and Zhang, J. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=14863072891034596372\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{radhakrishnan_knowing_2024,
	title = {Knowing {When} to {Ask}–{Bridging} {Large} {Language} {Models} and {Data}},
	url = {https://arxiv.org/abs/2409.13741},
	abstract = {… For RAG, we measure the fraction of LLM-generated statistical claims that are accurate (ie, not hallucinated). This means we evaluate the generated statistical value against the table …},
	journal = {arXiv preprint arXiv …},
	author = {Radhakrishnan, P. and Chen, J. and Xu, B. and Ramaswami, P. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=9836448788513950399\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{nikbakht_tspec-llm_2024,
	title = {Tspec-llm: {An} open-source dataset for llm understanding of 3gpp specifications},
	url = {https://arxiv.org/abs/2406.01768},
	abstract = {… the RAG framework, detail how to employ TSpecLLM for RAG, … Confidence levels: We analyze the confidence levels of … the questionnaire when applying RAG on the TSpec-LLM dataset. …},
	journal = {arXiv preprint arXiv:2406.01768},
	author = {Nikbakht, R. and Benzaghta, M. and Geraci, G.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {37 cites: https://scholar.google.com/scholar?cites=10123988245865699006\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xu_align-grag_2025,
	title = {Align-{GRAG}: {Reasoning}-{Guided} {Dual} {Alignment} for {Graph} {Retrieval}-{Augmented} {Generation}},
	url = {https://arxiv.org/abs/2505.16237},
	abstract = {… of LLM remain, leading to challenges like hallucinations (… Retrieval-augmented generation (RAG) systems have been … the LLM’s outputs in verifiable, external knowledge, RAG …},
	journal = {arXiv preprint arXiv …},
	author = {Xu, D. and Jia, P. and Li, X. and Zhang, Y. and Wang, M. and Liu, Q. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=16439823475077358507\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tufino_notebooklm_2025,
	title = {{NotebookLM}: {An} {LLM} with {RAG} for active learning and collaborative tutoring},
	url = {http://203.160.84.158:9988/papers/2504.09720v1.NotebookLM__An_LLM_with_RAG_for_active_learning_and_collaborative_tutoring.pdf},
	abstract = {… on internal training data, a RAG-based system actively retrieves relevant documents to ground its responses in factual information. Remarkable examples of RAG-based applications in …},
	journal = {arXiv preprint arXiv:2504.09720},
	author = {Tufino, E.},
	year = {2025},
	note = {Publisher: 203.160.84.158
Type: PDF},
	annote = {5 cites: https://scholar.google.com/scholar?cites=16509983307223241547\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{guo_empowering_2025,
	title = {Empowering graphrag with knowledge filtering and integration},
	url = {https://arxiv.org/abs/2503.13804},
	abstract = {… retrieval-augmented generation (GraphRAG) enhances LLM … between LLM with GraphRAG and LLM w/o GraphRAG (ie, LLM-… When do we trust the answers given by GraphRAG and …},
	journal = {arXiv preprint arXiv …},
	author = {Guo, K. and Shomer, H. and Zeng, S. and Han, H. and Wang, Y. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=11370523155871354997\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{manathunga_retrieval_2023,
	title = {Retrieval augmented generation and representative vector summarization for large unstructured textual data in medical education},
	url = {https://arxiv.org/abs/2308.00479},
	abstract = {… of hallucination and producing harmful answers. Retrieval Augmented Generation (RAG) … pharmacology from LLM without a non-parametric knowledgebase and a RAG model with …},
	journal = {arXiv preprint arXiv:2308.00479},
	author = {Manathunga, S. S. and Illangasekara, Y. A.},
	year = {2023},
	note = {Publisher: arxiv.org},
	annote = {30 cites: https://scholar.google.com/scholar?cites=15716504568227843949\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{patel_graph-enhanced_2025,
	title = {Graph-{Enhanced} {Retrieval}-{Augmented} {Question} {Answering} for {E}-{Commerce} {Customer} {Support}},
	url = {https://arxiv.org/abs/2509.14267},
	abstract = {… a novel retrieval-augmented generation (RAG) … the factual grounding. We examine recent advances in knowledge-augmented RAG and chatbots based on large language models (LLM…},
	journal = {arXiv preprint arXiv:2509.14267},
	author = {Patel, P.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {107 cites: https://scholar.google.com/scholar?cites=11297272303523530561\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{liu_xrag_2025,
	title = {{XRAG}: {Cross}-lingual {Retrieval}-{Augmented} {Generation}},
	url = {https://arxiv.org/abs/2505.10089},
	abstract = {… RAG setting (GPT-4o achieves only 62.4\% accuracy, see Table 4). We develop a novel LLM-… 2024), the Q\&A pairs generated by the LLM may contain factual errors. Therefore, we ask a …},
	journal = {arXiv preprint arXiv …},
	author = {Liu, W. and Trenous, S. and Ribeiro, L. F. R. and Byrne, B. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=9132975657205297860\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{raina_question-based_2024,
	title = {Question-based retrieval using atomic units for enterprise rag},
	url = {https://arxiv.org/abs/2405.12363},
	abstract = {… LLM using the RAG pipeline. … RAG as the information content of the context is based on extracts from novels. As the stories are fictional and not factual, the parametric memory of an LLM …},
	journal = {arXiv preprint arXiv:2405.12363},
	author = {Raina, V. and Gales, M.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {15 cites: https://scholar.google.com/scholar?cites=10955894617209840919\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ilapaka_comprehensive_2025,
	title = {A {Comprehensive} {RAG}-{Based} {LLM} for {AI}-{Driven} {Mental} {Health} {Chatbot}},
	url = {https://ieeexplore.ieee.org/abstract/document/11017017/},
	abstract = {… The chatbot uses Retrieval-Augmented Generation (RAG) to improve the relevance of its responses and make interactions more personalized. It also leverages LangChain’s …},
	journal = {2025 7th International Congress on …},
	author = {Ilapaka, A. and Ghosh, R.},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=9604948382163718712\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{liu_hallucination-aware_2024,
	title = {Hallucination-aware {Optimization} for {Large} {Language} {Model}-empowered {Communications}},
	url = {https://arxiv.org/abs/2412.06007},
	abstract = {… mitigation strategies, including both model-based approaches, such as prompt engineering and Retrieval Augmented Generation (RAG), and system-based methods, such as Mixture-of…},
	journal = {arXiv preprint arXiv …},
	author = {Liu, Y. and Liu, G. and Zhang, R. and Niyato, D. and Xiong, Z. and Kim, D. I. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=7720793578289690102\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{baek_probing-rag_2024,
	title = {Probing-rag: {Self}-probing to guide language models in selective document retrieval},
	url = {https://arxiv.org/abs/2410.13339},
	abstract = {… of Figure 1, Probing-RAG focuses on the hidden states of the LLM’s intermediate layers. … : external classifier based, LLM-based feedback, and confidence-based techniques. External …},
	journal = {arXiv preprint arXiv:2410.13339},
	author = {Baek, I. and Chang, H. and Kim, B. and Lee, J. and Lee, H.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {13 cites: https://scholar.google.com/scholar?cites=10659657128209438589\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{laban_summary_2024,
	title = {Summary of a haystack: {A} challenge to long-context llms and rag systems},
	url = {https://arxiv.org/abs/2407.01370},
	abstract = {… trade-offs exist when choosing between a RAG pipeline and a longcontext LLM, with RAG systems typically improving citation quality, at the cost of insight coverage, (3) using advanced …},
	journal = {arXiv preprint arXiv:2407.01370},
	author = {Laban, P. and Fabbri, A. R. and Xiong, C. and Wu, C. S.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {70 cites: https://scholar.google.com/scholar?cites=16239074899700290934\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{liu_hoprag_2025,
	title = {Hoprag: {Multi}-hop reasoning for logic-aware retrieval-augmented generation},
	url = {https://arxiv.org/abs/2502.12442},
	abstract = {… Specifically, we adopt LLM to generate two groups of pseudoqueries for each passage pi: (1… in the vertices and thus avoids LLM hallucination during summarization, information loss …},
	journal = {arXiv preprint arXiv …},
	author = {Liu, H. and Wang, Z. and Chen, X. and Li, Z. and Xiong, F. and Yu, Q. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {16 cites: https://scholar.google.com/scholar?cites=16062678968021009383\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_explainable_2025,
	title = {Explainable {Depression} {Detection} in {Clinical} {Interviews} with {Personalized} {Retrieval}-{Augmented} {Generation}},
	url = {https://arxiv.org/abs/2503.01315},
	abstract = {… -hoc LLM generation but suffer from hallucination. To address these limitations, we propose RED, a Retrievalaugmented generation … Additionally, to enhance LLM performance in social …},
	journal = {arXiv preprint arXiv:2503.01315},
	author = {Zhang, L. and Gao, Z. and Zhou, D. and He, Y.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=1961779381829290940\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kahl_evaluating_2024,
	title = {Evaluating the {Impact} of {Advanced} {LLM} {Techniques} on {AI} {Lecture} {Tutors} for a {Robotics} {Course}},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-93409-4_14},
	doi = {10.1007/978-3-031-93409-4_14},
	abstract = {… Our findings indicate that RAG combined with prompt engineering significantly enhances model responses and produces better factual answers. In the context of education, RAG …},
	journal = {… Workshop on AI in …},
	author = {Kahl, S. and Löffler, F. and Maciol, M. and Ridder, F. and Schmitz, M. and {...}},
	year = {2024},
	note = {Publisher: Springer},
	annote = {4 cites: https://scholar.google.com/scholar?cites=4872313199712956391\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_llm-lasso_2025,
	title = {{LLM}-{Lasso}: {A} {Robust} {Framework} for {Domain}-{Informed} {Feature} {Selection} and {Regularization}},
	url = {https://arxiv.org/abs/2502.10648},
	abstract = {… LLM-Lasso and LLMScore, the LLM analysis of the corrupted genes is heavily based on hallucinations… evaluate model performance (RAG LLM-Lasso, plain LLM-Lasso, and baselines) …},
	journal = {arXiv preprint arXiv …},
	author = {Zhang, E. and Goto, R. and Sagan, N. and Mutter, J. and Phillips, N. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=3929301187663137753\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ning_less_2025,
	title = {Less {LLM}, {More} {Documents}: {Searching} for {Improved} {RAG}},
	url = {https://arxiv.org/abs/2510.02657},
	abstract = {Retrieval-Augmented Generation (RAG) couples document … that corpus scaling consistently strengthens RAG and can often … stronger RAG, often comparable to enlarging the LLM itself. …},
	journal = {arXiv preprint arXiv:2510.02657},
	author = {Ning, J. and Kong, Y. and Long, Y. and Callan, J.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{penkov_mitigating_2024,
	title = {Mitigating hallucinations in large language models via semantic enrichment of prompts: {Insights} from biobert and ontological integration},
	url = {https://aclanthology.org/2024.clib-1.30/},
	abstract = {… By embedding deeper semantic understanding directly into LLM prompts, our approach extends the ethos behind RAG, enhancing its capability to improve LLM reliability. This proactive …},
	journal = {Proceedings of the Sixth International Conference on …},
	author = {Penkov, S.},
	year = {2024},
	note = {Publisher: aclanthology.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=13491980399545943951\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{dayarathne_comparing_2024,
	title = {Comparing the performance of llms in rag-based question-answering: {A} case study in computer science literature},
	url = {https://link.springer.com/chapter/10.1007/978-981-97-9255-9_26},
	doi = {10.1007/978-981-97-9255-9_26},
	abstract = {… RAG received attention from scholars as a remedy to mitigate the hallucination that comes with an LLM … Thus, unlike an off-the-shelf LLM, a RAG-based QA system powered by an LLM …},
	journal = {International Conference on …},
	author = {Dayarathne, R. and Ranaweera, U. and Ganegoda, U.},
	year = {2024},
	note = {Publisher: Springer},
	annote = {2 cites: https://scholar.google.com/scholar?cites=10141263910257719872\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wilkerson_implementing_2024,
	title = {On implementing case-based reasoning with large language models},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-63646-2_26},
	doi = {10.1007/978-3-031-63646-2_26},
	abstract = {… shown to improve LLM responses [3, 18]. RAG typically provides the LLM with knowledge in … We note that the ability to filter out such hallucinations follows from having the original case …},
	journal = {International Conference on Case-Based …},
	author = {Wilkerson, K. and Leake, D.},
	year = {2024},
	note = {Publisher: Springer},
	annote = {22 cites: https://scholar.google.com/scholar?cites=11214899861780785069\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{indebetou_enhancing_2025,
	title = {Enhancing {Troubleshooting} with {RAG}: {A} {Domain} {Specific} {LLM} {Approach} for {Vending} {Machine} {Repairs}},
	url = {https://www.diva-portal.org/smash/record.jsf?pid=diva2:1967184},
	abstract = {… These findings directly inform and validate the approach taken in this thesis: leveraging a RAG pipeline to enhance accuracy, reduce hallucinations, and improve the reliability of …},
	publisher = {diva-portal.org},
	author = {Indebetou, E. and Larsson, E.},
	year = {2025},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wellawatte_chemlit-qa_2025,
	title = {{ChemLit}-{QA}: a human evaluated dataset for chemistry {RAG} tasks},
	url = {https://iopscience.iop.org/article/10.1088/2632-2153/adc2d6/meta},
	doi = {10.1088/2632-2153/adc2d6},
	abstract = {… For the RAG case study, we prompted the LLM with the … In the baseline task, the LLM was only prompted with the … that a RAG approach is better at generating factual answers than …},
	journal = {Machine Learning …},
	author = {Wellawatte, G. P. and Guo, H. and Lederbauer, M. and {...}},
	year = {2025},
	note = {Publisher: iopscience.iop.org},
	annote = {15 cites: https://scholar.google.com/scholar?cites=6505661328475369240\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lang_automatic_2024,
	title = {Automatic question answering for the linguistic domain–an evaluation of {LLM} knowledge base extension with {RAG}},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-70242-6_16},
	doi = {10.1007/978-3-031-70242-6_16},
	abstract = {… In our contribution, we evaluate how expanding an LLM with RAG improves QA quality. We … hallucinations [20]. Besides, annotators seem to find RAG-improved answers more factual …},
	journal = {… on Applications of Natural Language to …},
	author = {Lang, C. and Schneider, R. and Tu, N. D. T.},
	year = {2024},
	note = {Publisher: Springer},
	annote = {2 cites: https://scholar.google.com/scholar?cites=1259835074289607956\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ong_development_2024,
	title = {Development and testing of a novel large language model-based clinical decision support systems for medication safety in 12 clinical specialties},
	url = {https://arxiv.org/abs/2402.01741},
	abstract = {… The accuracy of DRP detection with RAG-LLM improved in several categories but at the … This study established that a RAG-LLM based CDSS significantly boosts the accuracy of …},
	journal = {arXiv preprint arXiv …},
	author = {Ong, J. C. L. and Jin, L. and Elangovan, K. and Lim, G. Y. S. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {29 cites: https://scholar.google.com/scholar?cites=14719335212893811789\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{olawore_development_2024,
	title = {Development and {Evaluation} of a {University} {Chatbot} {Using} {Deep} {Learning}: {A} {RAG}-{Based} {Approach}},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-88045-2_7},
	doi = {10.1007/978-3-031-88045-2_7},
	abstract = {… In this paper we present an adaptive LLM-based chatbot that … known as Retrieval-Augmented Generation (RAG) which … data and may hallucinate information, the RAG system offers …},
	journal = {… on Chatbots and Human-Centered AI},
	author = {Olawore, K. and McTear, M. and Bi, Y.},
	year = {2024},
	note = {Publisher: Springer},
	annote = {5 cites: https://scholar.google.com/scholar?cites=5329281937577970012\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhao_chat2data_2024,
	title = {Chat2data: {An} interactive data analysis system with rag, vector databases and llms},
	url = {https://dl.acm.org/doi/abs/10.14778/3685800.3685905},
	doi = {10.14778/3685800.3685905},
	abstract = {… Retrieval-Augmented Generation (RAG) to embed domain knowledge in order to address the hallucination … , prompt generation via RAG, pipeline generation via LLM agent. Specifically, …},
	journal = {Proceedings of the VLDB Endowment},
	author = {Zhao, X. and Zhou, X. and Li, G.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {46 cites: https://scholar.google.com/scholar?cites=178358047445604689\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhao_lmar_2025,
	title = {Lmar: {Language} model augmented retriever for domain-specific knowledge indexing},
	url = {https://arxiv.org/abs/2508.05672},
	abstract = {… sources, RAG substantially mitigates hallucination and … LLM-augmented text clustering mechanism that distills the contextual understanding and discrimination capabilities of the LLM …},
	journal = {arXiv preprint arXiv:2508.05672},
	author = {Zhao, Y. and Ding, Y. and Zhang, Z. and Yao, D. and Xu, Y.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=7776980408606841314\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{rafat_ai-powered_2024,
	title = {{AI}-powered {Legal} {Virtual} {Assistant}: {Utilizing} {RAG}-optimized {LLM} for {Housing} {Dispute} {Resolution} in {Finland}.},
	url = {https://www.theseus.fi/handle/10024/859826},
	abstract = {… This question investigates the specific impact of RAG optimization on the factual accuracy of LLMgenerated responses within the domain of housing disputes in Finland, comparing the …},
	publisher = {theseus.fi},
	author = {Rafat, M. I.},
	year = {2024},
	annote = {9 cites: https://scholar.google.com/scholar?cites=5299113516814784899\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kim_vaiv_2024,
	title = {{VAIV} bio-discovery service using transformer model and retrieval augmented generation},
	url = {https://link.springer.com/article/10.1186/s12859-024-05903-6},
	doi = {10.1186/s12859-024-05903-6},
	abstract = {… ChatGPT model [3] is adopted as the LLM. By combining search capabilities with the LLM, we can mitigate the hallucination … By conditioning on retrieved relevant documents, the RAG …},
	journal = {BMC bioinformatics},
	author = {Kim, S. and Yoon, J.},
	year = {2024},
	note = {Publisher: Springer
Type: HTML},
	annote = {7 cites: https://scholar.google.com/scholar?cites=16579788276077817614\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{perak_incorporating_2024,
	title = {Incorporating dialect understanding into llm using rag and prompt engineering techniques for causal commonsense reasoning},
	url = {https://aclanthology.org/2024.vardial-1.19/},
	abstract = {… various prompts engineering and the Retrieval-Augmented Generation (RAG) technique. Initially, … Next, we enhance prompts using the RAG technique specifically for the Chakavian and …},
	journal = {… of the Eleventh Workshop on NLP …},
	author = {Perak, B. and Beliga, S. and Meštrović, A.},
	year = {2024},
	note = {Publisher: aclanthology.org},
	annote = {12 cites: https://scholar.google.com/scholar?cites=3648335498798341472\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{addad_homeopathic_2024,
	title = {Homeopathic {Poisoning} of {RAG} {Systems}},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-68738-9_28},
	doi = {10.1007/978-3-031-68738-9_28},
	abstract = {… LLM’s output quality and reduce hallucinations. The standard RAG architecture is composed of a knowledge base, an LLM, … The RAG processing flow is depicted in Fig. 1. First of all, the …},
	journal = {… Conference on Computer Safety, Reliability, and …},
	author = {Addad, B. and Kapusta, K.},
	year = {2024},
	note = {Publisher: Springer},
	annote = {3 cites: https://scholar.google.com/scholar?cites=6943278605538526682\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jovanovic_ward_2024,
	title = {Ward: {Provable} rag dataset inference via llm watermarks},
	url = {https://arxiv.org/abs/2410.03537},
	abstract = {… The query q is generally combined with Dq, and fed into an LLM to generate a more factual response r = M(q, Dq). Expanding D also enables access to new information without costly …},
	journal = {arXiv preprint arXiv …},
	author = {Jovanović, N. and Staab, R. and Baader, M. and Vechev, M.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=3668397931508962459\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yang_shizishangpt_2024,
	title = {{ShizishanGPT}: {An} agricultural large language model integrating tools and resources},
	url = {https://link.springer.com/chapter/10.1007/978-981-96-0573-6_21},
	doi = {10.1007/978-981-96-0573-6_21},
	abstract = {… Retrieval Augmented Generation (RAG) framework and agent architecture (ShizishanGPT). The system uses a large language model to … articles, RAG improves the factual accuracy and …},
	journal = {… Conference on Web …},
	author = {Yang, S. and Liu, Z. and Mayer, W. and Ding, N. and Wang, Y. and {...}},
	year = {2024},
	note = {Publisher: Springer},
	annote = {11 cites: https://scholar.google.com/scholar?cites=6791885379036105966\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jeon_hybrid_2025,
	title = {Hybrid large language model approach for prompt and sensitive defect management: {A} comparative analysis of hybrid, non-hybrid, and {GraphRAG} approaches},
	url = {https://www.sciencedirect.com/science/article/pii/S1474034624007274},
	abstract = {… closed-source LLM for generating a … retrieval-augmented generation (GraphRAG)-based QA systems, which have been extensively studied recently. Our results show that the hybrid LLM…},
	journal = {Advanced Engineering Informatics},
	author = {Jeon, K. and Lee, G.},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {15 cites: https://scholar.google.com/scholar?cites=15958464325487089848\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{ogbo-gebhardt_using_2024,
	title = {Using a {Large} {Language} {Model}-{Powered} {Assistant} in {Teaching}: {Stories} of {Acceptance}, {Use}, and {Impact} among {Ethnic} {Minority} {Students}},
	url = {https://www.econstor.eu/handle/10419/302517},
	abstract = {… LLM-powered assistant] was most useful?” and “On a scale of 1 to 5, where a higher number indicates more trust, to what extent do you trust … located the LLM inference servers and RAG …},
	publisher = {econstor.eu},
	author = {Ogbo-Gebhardt, E. and Ogbo, O.},
	year = {2024},
	annote = {3 cites: https://scholar.google.com/scholar?cites=2578571519312939764\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lee_rag-enhanced_2025,
	title = {{RAG}-{Enhanced} {Collaborative} {LLM} {Agents} for {Drug} {Discovery}},
	url = {https://arxiv.org/abs/2502.17506},
	abstract = {… retrieval-augmented generation (RAG)-empowered agentic system tailored to drug discovery tasks. Through the collaboration of multiple LLM … the LLM, enhancing its factual grounding …},
	journal = {arXiv preprint arXiv …},
	author = {Lee, N. and Brouwer, E. De and Hajiramezanali, E. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {17 cites: https://scholar.google.com/scholar?cites=17401680661582572753\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lin_domain_2024,
	title = {Domain {Adaption} and {Unified} {Knowledge} {Base} {Motivate} {Better} {Retrieval} {Models} in {Dialog} {Systems} {With} {RAG}},
	url = {https://ieeexplore.ieee.org/abstract/document/10832316/},
	abstract = {… ) has emerged as a paradigm to address problems like hallucination in dialog systems based on large language model (LLM). Retrieval model is a key component in RAG framework for …},
	journal = {2024 IEEE Spoken …},
	author = {Lin, H. and Chen, Y. and Tao, W. and Chen, M. and Xu, X. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=2349676581178352103\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mohammed_diabetiq_nodate,
	title = {{DiabetIQ}: {An} {Intelligent} {Diabetes} {Management} {Application} with an {Integrated} {LLM}-{Augmented} {RAG} {Chatbot} and {ML}-{Based} {Risk} {Early} {Prediction}},
	url = {https://www.researchgate.net/profile/Saif-Mohammed-18/publication/391479329_DiabetIQ_An_Intelligent_Diabetes_Management_Application_with_an_Integrated_LLM-Augmented_RAG_Chatbot_and_ML-Based_Risk_Early_Prediction/links/6819c216df0e3f544f52211e/DiabetIQ-An-Intelligent-Diabetes-Management-Application-with-an-Integrated-LLM-Augmented-RAG-Chatbot-and-ML-Based-Risk-Early-Prediction.pdf},
	abstract = {… is the Retrieval-Augmented Generation (RAG) pipeline, … base Large Language Model (LLM) while ensuring factual grounding. … the LLM with both the user’s question and relevant factual …},
	journal = {researchgate.net},
	author = {Mohammed, S. and Nabil, N. I. and Nipa, H. R. and Setu, U. S. H.},
	note = {Type: PDF},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gan_rag-mcp_2025,
	title = {Rag-mcp: {Mitigating} prompt bloat in llm tool selection via retrieval-augmented generation},
	url = {https://arxiv.org/abs/2505.03275},
	abstract = {… In particular, RAG-MCP yields substantially higher accuracy in choosing the appropriate tool and reduces errors such as hallucinated or mis-parameterized function calls. These results …},
	journal = {arXiv preprint arXiv:2505.03275},
	author = {Gan, T. and Sun, Q.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {11 cites: https://scholar.google.com/scholar?cites=10731483226687949367\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ju_flooding_2024,
	title = {Flooding spread of manipulated knowledge in llm-based multi-agent communities},
	url = {https://arxiv.org/abs/2407.07791},
	abstract = {… our attack method can successfully induce LLM-based agents to … through popular retrieval-augmented generation frameworks, … The LLM may not always verify the factual accuracy …},
	journal = {arXiv preprint arXiv …},
	author = {Ju, T. and Wang, Y. and Ma, X. and Cheng, P. and Zhao, H. and Wang, Y. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {51 cites: https://scholar.google.com/scholar?cites=3754562162800219526\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_llm_2024,
	title = {An llm agent for automatic geospatial data analysis},
	url = {https://arxiv.org/abs/2410.18792},
	abstract = {… However, we lack a geospatial RAG database to prompt … API hallucinations account for up to 15\% of all hallucinations … In this work, we opt to implement RAG only when the library …},
	journal = {arXiv preprint arXiv:2410.18792},
	author = {Chen, Y. and Wang, W. and Lobry, S. and Kurtz, C.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {23 cites: https://scholar.google.com/scholar?cites=14640444238073227595\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hsu_evaluating_2024,
	title = {Evaluating {ChatNetZero}, an {LLM}-chatbot to demystify climate pledges},
	url = {https://openreview.net/forum?id=MmTaM7lmvu},
	abstract = {… a large-language model (LLM) chatbot developed through Retrieval-Augmented Generation (RAG… for our assessment of the factual accuracy of five LLM outputs, including ChatNetZero. …},
	journal = {… meets Climate Change …},
	author = {Hsu, A. and Laney, M. and Zhang, J. and Manya, D. and {...}},
	year = {2024},
	note = {Publisher: openreview.net},
	annote = {10 cites: https://scholar.google.com/scholar?cites=8368690204840591851\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{krupp_talk2xopen-source_2025,
	title = {{Talk2X}–{An} {Open}-{Source} {Toolkit} {Facilitating} {Deployment} of {LLM}-{Powered} {Chatbots} on the {Web}},
	url = {https://arxiv.org/abs/2504.03343},
	abstract = {… Integrated into websites, LLM-powered chatbots offer … an adapted retrieval-augmented generation approach (RAG) … sources we enabled Talk2X to cite its sources of information, …},
	journal = {arXiv preprint arXiv …},
	author = {Krupp, L. and Geißler, D. and Hevesi, P. and Hirsch, M. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{nazar_enwar_2024,
	title = {Enwar: {A} rag-empowered multi-modal llm framework for wireless environment perception},
	url = {https://arxiv.org/abs/2410.18104},
	abstract = {… assessment of an LLM’s capabilities across various metrics such as answer relevancy, factual correctness, and hallucinations avoidance. However, RAG-based systems require a more …},
	journal = {arXiv preprint arXiv …},
	author = {Nazar, A. M. and Celik, A. and Selim, M. Y. and Abdallah, A. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=10473809589268660064\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{soman_human_2025,
	title = {Human guided empathetic {AI} agent for mental health support leveraging reinforcement learning-enhanced retrieval-augmented generation},
	url = {https://www.sciencedirect.com/science/article/pii/S1389041725000178},
	abstract = {… LLM-based conversational agent that relies on the integration of Retrieval Augmented Generation (RAG… , steady training dynamics, decreased hallucination rates with responses having …},
	journal = {Cognitive Systems Research},
	author = {Soman, G. and Judy, M. V. and Abou, A. M.},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {7 cites: https://scholar.google.com/scholar?cites=20670226938243807\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kloker_new_2024,
	title = {New {Curriculum}, {New} {Chance}–{Retrieval} {Augmented} {Generation} for {Lesson} {Planning} in {Ugandan} {Secondary} {Schools}. {Prototype} {Quality} {Evaluation}},
	url = {https://arxiv.org/abs/2408.07542},
	abstract = {… the "confidence conundrum": the LLM presents information … of RAG for lesson plan creation in the context of Ugandan secondary schools. We developed a prototype, that utilizes an LLM …},
	journal = {arXiv preprint arXiv:2408.07542},
	author = {Kloker, S. and Bukoli, H. and Kateete, T.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=16846219565165780139\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{papagiannopoulos_comparison_2025,
	title = {Comparison of explainability methods for hallucination analysis in {LLMs}},
	url = {https://open-research-europe.ec.europa.eu/articles/5-191},
	abstract = {… (LLM) hallucinations, which produce fluent yet factually incorrect or illogical outputs. This paper investigates hallucinations as … tools including Retrieval-Augmented Generation (RAG), …},
	journal = {Open …},
	author = {Papagiannopoulos, I. and {...}},
	year = {2025},
	note = {Publisher: open-research-europe.ec.europa.eu
Type: HTML},
	annote = {1 cites: https://scholar.google.com/scholar?cites=9667527786050051954\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{vungarala_tpu-gen_2025,
	title = {Tpu-gen: {Llm}-driven custom tensor processing unit generator},
	url = {https://ieeexplore.ieee.org/abstract/document/11106005/},
	abstract = {… hallucinations leveraging RAG and fine-tuning, to align best for the LLMs to streamline the approximate TPU design generation process considering budgetary constraints (eg, power, …},
	journal = {… Conference on LLM …},
	author = {Vungarala, D. and Elbtity, M. E. and Pandit, K. and {...}},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=7803623284536186355\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ahmed_codeqa_2024,
	title = {{CodeQA}: {Advanced} programming question-answering using {LLM} agent and {RAG}},
	url = {https://ieeexplore.ieee.org/abstract/document/10753267/},
	abstract = {… from Retrieval-Augmented Generation can be used to augment reduced hallucinated question-… Our study, by inte grating a sophisticated LLM model within the RAG framework, further …},
	journal = {2024 6th Novel …},
	author = {Ahmed, M. and Dorrah, M. and Ashraf, A. and Adel, Y. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=8259992752613190239\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mostafa_rag-enabled_2025,
	title = {Rag-enabled intent reasoning for application-network interaction},
	url = {https://arxiv.org/abs/2505.09339},
	abstract = {… translation, and avoid hallucination in the translated intents. … -RAG framework compared to LLM and vanilla-RAG benchmarks… it to an LLM (no-RAG) model, where a prompt and LLM are …},
	journal = {arXiv preprint arXiv …},
	author = {Mostafa, S. and Abdel-Aziz, M. K. and Elbamby, M. S. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=3962089596113734896\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{christmann_rag-based_2024,
	title = {Rag-based question answering over heterogeneous data and text},
	url = {https://arxiv.org/abs/2412.07420},
	abstract = {… The RAG paradigm came up as a principled way of enhancing LLM factuality incl. provenance and mitigating the risk of hallucination [12, 21]. It is highly related to the earlier retriever-…},
	journal = {arXiv preprint arXiv:2412.07420},
	author = {Christmann, P. and Weikum, G.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=5057664797735899316\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{moayeri_worldbench_2024,
	title = {Worldbench: {Quantifying} geographic disparities in llm factual recall},
	url = {https://dl.acm.org/doi/abs/10.1145/3630106.3658967},
	doi = {10.1145/3630106.3658967},
	abstract = {… we highlight is the impact of retrieval augmented generation (RAG), which is … , hallucinated citations pose a serious challenge in LLM reliability. On one hand, producing false citations …},
	journal = {… of the 2024 ACM Conference on …},
	author = {Moayeri, M. and Tabassi, E. and Feizi, S.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {38 cites: https://scholar.google.com/scholar?cites=8899655283752032480\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{qu_pncd_2025,
	title = {{PNCD}: {Mitigating} {LLM} {Hallucinations} in {Noisy} {Environments}—{A} {Medical} {Case} {Study}},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253525004014},
	abstract = {… ability to cope with the hallucinations of LLMs. The ability to … (PNCD) based on RAG to solve the hallucination of LLMs in … of negative examples that induce hallucinations for BaseLLMs. …},
	journal = {Information Fusion},
	author = {Qu, J. and Liu, J. and Liu, X. and Chen, M. and Li, J. and Wang, J.},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {2 cites: https://scholar.google.com/scholar?cites=13419550465609488121\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_combining_2025,
	title = {Combining {Lexicon} {Definitions} and the {Retrieval}-{Augmented} {Generation} of a {Large} {Language} {Model} for the {Automatic} {Annotation} of {Ancient} {Chinese} {Poetry}},
	url = {https://www.mdpi.com/2227-7390/13/12/2023},
	abstract = {… During evaluation, we observed that ChatGPT-4o and Taiyan 2.0 generate source citations only for allusion chunks. For instance, in the annotation of “大树” (referring to the historical …},
	journal = {Mathematics},
	author = {Li, J. and Wei, T. and Qu, W. and Li, B. and Feng, M. and Wang, D.},
	year = {2025},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {1 cites: https://scholar.google.com/scholar?cites=15438954874829524788\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cai_driving_2024,
	title = {Driving with regulation: {Interpretable} decision-making for autonomous vehicles with retrieval-augmented reasoning via llm},
	url = {https://arxiv.org/abs/2410.04759},
	abstract = {… (TRR) Agent based on Retrieval-Augmented Generation (RAG) to … powered by a Large Language Model (LLM) to interpret … effectiveness in enhancing LLM accuracy and factual correct…},
	journal = {arXiv preprint arXiv …},
	author = {Cai, T. and Liu, Y. and Zhou, Z. and Ma, H. and Zhao, S. Z. and Wu, Z. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {21 cites: https://scholar.google.com/scholar?cites=15850288977627466050\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{muhamed_ccrs_2025,
	title = {{CCRS}: {A} {Zero}-{Shot} {LLM}-as-a-{Judge} {Framework} for {Comprehensive} {RAG} {Evaluation}},
	url = {https://arxiv.org/abs/2506.20128},
	abstract = {… factual accuracy and upto-date information. However, evaluating the multifaceted quality of RAG outputs — spanning aspects such as contextual coherence, query relevance, factual …},
	journal = {arXiv preprint arXiv:2506.20128},
	author = {Muhamed, A.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cheung_hallucination_2025,
	title = {Hallucination {Detection} with {Small} {Language} {Models}},
	url = {https://arxiv.org/abs/2506.22486},
	abstract = {… may not exist within the LLM, necessitating retrieval-augmented generation (RAG) [4] to enhance its capacity by providing knowledge that does not exist in the LLM. Related context can …},
	journal = {arXiv preprint arXiv:2506.22486},
	author = {Cheung, M.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{marcantonio_artificial_2024,
	title = {Artificial {Intelligence}, {LLM} and {RAG} supporting {Library} and {Information} {Science}: challenges and opportunities},
	url = {https://u-pad.unimc.it/handle/11393/343610},
	abstract = {… research projects (such as INTERPARES TRUST AI) that seek to … by the use of LLM and RAG in digital environments designed … Users need to trust that the information they access about …},
	journal = {… 2024-Navigare la complessità-Infrastrutture e …},
	author = {Marcantonio, G. Di},
	year = {2024},
	note = {Publisher: u-pad.unimc.it},
	annote = {2 cites: https://scholar.google.com/scholar?cites=9061365593755802102\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_biorag_2024,
	title = {Biorag: {A} rag-llm framework for biological question reasoning},
	url = {https://arxiv.org/abs/2408.01107},
	abstract = {… To address these issues, we introduce BioRAG, a novel Retrieval-Augmented Generation (RAG) … fine-tuned LLM, LLM with search engines, and other scientific RAG frameworks across …},
	journal = {arXiv preprint arXiv …},
	author = {Wang, C. and Long, Q. and Xiao, M. and Cai, X. and Wu, C. and Meng, Z. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {44 cites: https://scholar.google.com/scholar?cites=6760124863574288334\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_traceback_2025,
	title = {Traceback of poisoning attacks to retrieval-augmented generation},
	url = {https://dl.acm.org/doi/abs/10.1145/3696410.3714756},
	doi = {10.1145/3696410.3714756},
	abstract = {… However, for the retriever and LLM, we consider a practical scenario where the RAG owner … : Improving LLM confidence in benign text: The core idea is to boost the LLM’s confidence in …},
	journal = {Proceedings of the ACM …},
	author = {Zhang, B. and Xin, H. and Fang, M. and Liu, Z. and Yi, B. and Li, T. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=11591082687847484319\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yu_evaluating_2025,
	title = {Evaluating {ChatGPT} on {Korea}'s {BIM} {Expertise} {Exam} and improving its performance through {RAG}},
	url = {https://academic.oup.com/jcde/article-abstract/12/4/94/8090188},
	abstract = {… could be improved and thus deploy ChatGPT with higher confidence. … how RAG was used with the goal of improving ChatGPT's response exclusively to this subcategory. As ChatGPT-4 …},
	journal = {Journal of Computational Design …},
	author = {Yu, Y. and Kim, S. and Lee, W. and Koo, B.},
	year = {2025},
	note = {Publisher: academic.oup.com},
	annote = {5 cites: https://scholar.google.com/scholar?cites=12137232736196477566\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ouyang_revisiting_2024,
	title = {Revisiting the solution of meta kdd cup 2024: {Crag}},
	url = {https://arxiv.org/abs/2409.15337},
	abstract = {… the RAG Baseline, our solutions demonstrate superior results with reduced hallucination rates … that this study will make a modest contribution to the broader RAG and LLM communities. …},
	journal = {arXiv preprint arXiv …},
	author = {Ouyang, J. and Luo, Y. and Cheng, M. and Wang, D. and Yu, S. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=3168276007310880093\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wu_pa-rag_2024,
	title = {Pa-rag: {Rag} alignment via multi-perspective preference optimization},
	url = {https://arxiv.org/abs/2412.14510},
	abstract = {… When constructing the training data, we employ ChatGPT-3.5 (GPT-3.5-Turbo-1106) and introduce a citation rewrite mechanism to create near-perfect responses. An overview of the …},
	journal = {arXiv preprint arXiv …},
	author = {Wu, J. and Cai, H. and Yan, L. and Sun, H. and Li, X. and Wang, S. and Yin, D. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=14835811638294428566\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{iivanainen_investigating_2024,
	title = {Investigating large language model ({LLM}) performance using in-context learning ({ICL}) for interpretation of {ESMO} and {NCCN} guidelines for lung cancer.},
	url = {https://ascopubs.org/doi/abs/10.1200/JCO.2024.42.16_suppl.e13637},
	abstract = {… Retrieval Augmented Generation (RAG) could improve the LLM performance and reduce hallucinations… (128k tokens) and ICL with RAG (ICL-RAG) heuristically including only the most …},
	publisher = {ascopubs.org},
	author = {Iivanainen, S. and Lagus, J. and Viertolahti, H. and Sippola, L. and {...}},
	year = {2024},
	doi = {10.1200/JCO.2024.42.16_suppl.e13637},
	annote = {10 cites: https://scholar.google.com/scholar?cites=9760324237451741881\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{iannelli_sla_2024,
	title = {{SLA} {Management} in {Reconfigurable} {Multi}-{Agent} {RAG}: {A} {Systems} {Approach} to {Question} {Answering}},
	url = {https://arxiv.org/abs/2412.06832},
	abstract = {… hallucination, ie the generation of false assertions [10]. Retrieval Augmented Generation (RAG) … , enabling the LLM to function as a reasoning layer rather than a static repository of facts. …},
	journal = {arXiv preprint arXiv:2412.06832},
	author = {Iannelli, M. and Kuchipudi, S. and Dvorak, V.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=16017283251179812575\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_conversation_2025,
	title = {From {Conversation} to {Standardized} {Terminology}: {An} {LLM}‐{RAG} {Approach} for {Automated} {Health} {Problem} {Identification} in {Home} {Healthcare}},
	url = {https://sigmapubs.onlinelibrary.wiley.com/doi/abs/10.1111/jnu.70039},
	doi = {10.1111/jnu.70039},
	abstract = {… RAG to enhance problem mapping, enabling the LLM to reference Omaha System terminology and retrieve relevant contextual data for improved accuracy and factual … , LLM- RAG …},
	journal = {Journal of Nursing …},
	author = {Zhang, Z. and Gupta, P. and Song, J. and Zolnoori, M. and {...}},
	year = {2025},
	note = {Publisher: Wiley Online Library},
	annote = {1 cites: https://scholar.google.com/scholar?cites=13548897879498407831\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ongris_towards_2024,
	title = {Towards an {Open} {NLI} {LLM}-based {System} for {KGs}: {A} {Case} {Study} of {Wikidata}},
	url = {https://ieeexplore.ieee.org/abstract/document/10963661/},
	abstract = {… However, we consider the limitation of the LLM’s context window and the hallucination … RAG [3] that uses LLM only as the generator to generate human-like responses, we use LLM …},
	journal = {2024 7th International …},
	author = {Ongris, J. G. and Tjitrahardja, E. and Darari, F. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=1471720944557575048\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{shin_qa_2023,
	title = {{QA} {Pair} {Passage} {RAG}-based {LLM} {Korean} chatbot service},
	journal = {Annual …},
	author = {Shin, J. and Lee, J. and Kim, K. and Lee, T. and {...}},
	year = {2023},
	note = {Publisher: Human and Language Technology
Type: CITATION},
	annote = {5 cites: https://scholar.google.com/scholar?cites=15054366805543214915\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jain_rag_2024,
	title = {From rag to riches: {Retrieval} interlaced with sequence generation},
	url = {https://arxiv.org/abs/2407.00361},
	abstract = {… , the typical approaches chain LLM generations with calls to … evidence corpus using a single LLM and decoding process. … is partially attributed, with LLM hallucinating based on partial …},
	journal = {arXiv preprint arXiv:2407.00361},
	author = {Jain, P. and Soares, L. B. and Kwiatkowski, T.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=610603018212270861\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xu_mantra_2025,
	title = {Mantra: {Enhancing} automated method-level refactoring with contextual rag and multi-agent llm collaboration},
	url = {https://arxiv.org/abs/2503.14340},
	abstract = {… Moreover, in comparison to IntelliJ’s LLM-powered refactoring … emphasize the growing potential of LLM-based systems in … copies bear this notice and the full citation on the first page. …},
	journal = {arXiv preprint arXiv:2503.14340},
	author = {Xu, Y. and Lin, F. and Yang, J. and Tsantalis, N.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=10995442587929646462\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_retcare_2024,
	title = {Retcare: {Towards} interpretable clinical decision making through llm-driven medical knowledge retrieval},
	url = {https://openreview.net/forum?id=jqo1vk63qE},
	abstract = {… that they place significant trust in authoritative medical literature. … leveraging the Retrieval-Augmented Generation (RAG) … medical large language model’s pretraining phase and …},
	journal = {… Intelligence and Data …},
	author = {Wang, Z. and Zhu, Y. and Gao, J. and Zheng, X. and Zeng, Y. and {...}},
	year = {2024},
	note = {Publisher: openreview.net},
	annote = {9 cites: https://scholar.google.com/scholar?cites=17843756896267926770\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{savage_large_2024,
	title = {Large language model uncertainty measurement and calibration for medical diagnosis and treatment},
	url = {https://www.medrxiv.org/content/10.1101/2024.06.06.24308399.abstract},
	doi = {10.1101/2024.06.06.24308399.abstract},
	abstract = {… metrics to quantify LLM confidence when performing … because extra context provided by RAG can errantly lead the model … LLM uncertainty are important for building medical LLM-RAG …},
	journal = {medRxiv},
	author = {Savage, T. and Wang, J. and Gallo, R. and Boukil, A. and Patel, V. and {...}},
	year = {2024},
	note = {Publisher: medrxiv.org},
	annote = {17 cites: https://scholar.google.com/scholar?cites=2730989494850141241\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{roychowdhury_evaluation_2024,
	title = {Evaluation of rag metrics for question answering in the telecom domain},
	url = {https://arxiv.org/abs/2407.12873},
	abstract = {… We establish, for RQ3, that Factual Correctness metric improves with instruction fine tuning … purposes in RAG pipeline. We demonstrate that domain adaptation of RAG LLM improves the …},
	journal = {arXiv preprint arXiv …},
	author = {Roychowdhury, S. and Soman, S. and Ranjani, H. G. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {36 cites: https://scholar.google.com/scholar?cites=4197609028362819739\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ngom_mallet_2024,
	title = {Mallet: {Sql} dialect translation with llm rule generation},
	url = {https://dl.acm.org/doi/abs/10.1145/3663742.3663973},
	doi = {10.1145/3663742.3663973},
	abstract = {… • We perform RAG over system documentation and over expertise from … the LLM produced a hallucination. Whenever such a hallucination is detected, we iteratively re-prompt the LLM in …},
	journal = {Proceedings of the Seventh International Workshop …},
	author = {Ngom, A. L. and Kraska, T.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=17967876041368781956\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{peng_eloq_2025,
	title = {Eloq: {Resources} for enhancing llm detection of out-of-scope questions},
	url = {https://dl.acm.org/doi/abs/10.1145/3726302.3730333},
	doi = {10.1145/3726302.3730333},
	abstract = {… RAG system retrieves a relevant document from a curated knowledge base and presents it to a large language model (LLM… in preventing an LLM from hallucinating or generating …},
	journal = {Proceedings of the 48th …},
	author = {Peng, Z. and Nian, J. and Evfimievski, A. and Fang, Y.},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=16744716043043841804\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{al-zuraiqi_evaluating_2024,
	title = {Evaluating {Alignment} {Techniques} for {Enhancing} {LLM} {Performance} in a {Closed}-{Domain} {Application}: a {RAG} {Bench}-{Marking} {Study}},
	url = {https://ieeexplore.ieee.org/abstract/document/10903215/},
	abstract = {… These methods aim to eliminate LLM hallucination, where the model … Retrieval-Augmented Generation (RAG) and the training dataset as benchmark systems for the fine-tuned LLM …},
	journal = {2024 International Conference on …},
	author = {Al-Zuraiqi, A. and Greer, D.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=12529667916730935443\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{dehbozorgi_personalized_2024,
	title = {Personalized pedagogy through a {LLM}-based recommender system},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-64312-5_8},
	doi = {10.1007/978-3-031-64312-5_8},
	abstract = {… adopt the RAG framework with LLM to enhance the recommendation result. RAG combines … We will further address the tendency of LLM to generate ’hallucinated’ content, and plan to …},
	journal = {International Conference on …},
	author = {Dehbozorgi, N. and Kunuku, M. T. and Pouriyeh, S.},
	year = {2024},
	note = {Publisher: Springer},
	annote = {30 cites: https://scholar.google.com/scholar?cites=3132790831020809536\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ding_automatic_2025,
	title = {An automatic patent literature retrieval system based on {LLM}-{RAG}},
	url = {https://arxiv.org/abs/2508.14064},
	abstract = {… in this study, RetrievalAugmented Generation (RAG) serves as a core framework, acting as a bridge between semantic retrieval and contextual generation. RAG combines the strengths …},
	journal = {arXiv preprint arXiv:2508.14064},
	author = {Ding, Y. and Wu, Y. and Ding, Z.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=9433516484399319481\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sanna_building_2024,
	title = {Building certified medical chatbots: {Overcoming} unstructured data limitations with modular rag},
	url = {https://aclanthology.org/2024.cl4health-1.15/},
	abstract = {… Finally, we propose a modular RAG model to implement a Large Language Model in a … Moreover, the model is quite sparse, with an average confidence on correct predictions of 0.27. …},
	journal = {Proceedings of the …},
	author = {Sanna, L. and Bellan, P. and Magnolini, S. and Segala, M. and {...}},
	year = {2024},
	note = {Publisher: aclanthology.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=9862849436123925210\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{shen_citelab_2025,
	title = {{CiteLab}: {Developing} and {Diagnosing} {LLM} {Citation} {Generation} {Workflows} via the {Human}-{LLM} {Interaction}},
	url = {https://aclanthology.org/2025.acl-demo.47/},
	abstract = {… Prompt self-RAG As for Llama3-8B and GPT-4o, there is no trained version for self-RAG, we use prompt to make the LLM retrieve documents and generate, then use an NLI model to …},
	journal = {Proceedings of the 63rd …},
	author = {Shen, J. and Zhou, T. and Chen, Y. and Liu, K. and {...}},
	year = {2025},
	note = {Publisher: aclanthology.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=14460781914093549556\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jiang_bi_2025,
	title = {Bi'an: {A} {Bilingual} {Benchmark} and {Model} for {Hallucination} {Detection} in {Retrieval}-{Augmented} {Generation}},
	url = {https://arxiv.org/abs/2502.19209},
	abstract = {… an LLM to assess whether the RAG system’s output aligns with the input text. However, the application of LLM-as-a-Judge in RAG hallucination … , for RAG hallucination detection and …},
	journal = {arXiv preprint arXiv:2502.19209},
	author = {Jiang, Z. and Sun, M. and Zhang, Z. and Liang, L.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_remflow_2025,
	title = {{REMFLOW}: {RAG}-enhanced multi-factor rainfall flooding warning in sponge airports via large language model},
	url = {https://link.springer.com/article/10.1007/s13042-025-02570-8},
	doi = {10.1007/s13042-025-02570-8},
	abstract = {… to provide prior knowledge of the LLM and enhanced the input … We propose REMFLOW, a RAG-based LLM approach for … for mitigating hallucinations in large language models [25]. …},
	journal = {International Journal of Machine …},
	author = {Wang, G. and Liu, Y. and Liu, S. and Zhang, L. and Yang, L.},
	year = {2025},
	note = {Publisher: Springer},
	annote = {5 cites: https://scholar.google.com/scholar?cites=15240823427426812856\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{posedaru_artificial_2024,
	title = {Artificial intelligence text processing using retrieval-augmented generation: {Applications} in business and education fields},
	url = {https://sciendo.com/2/v2/download/article/10.2478/picbe-2024-0018.pdf},
	doi = {10.2478/picbe-2024-0018},
	abstract = {… , having as its central tool ChatGPT and its capabilities. The … RetrievalAugmented Generation and is highlighted the potential of this technology to enhance the interpretability and trust in …},
	journal = {Proceedings of the …},
	author = {Posedaru, B. S. and Pantelimon, F. V. and Dulgheru, M. N. and {...}},
	year = {2024},
	note = {Publisher: sciendo.com
Type: PDF},
	annote = {9 cites: https://scholar.google.com/scholar?cites=6511141771222576281\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{pondel_ai_2024,
	title = {{AI} {Tools} for {Knowledge} {Management}–{Knowledge} {Base} {Creation} via {LLM} and {RAG} for {AI} {Assistant}},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-78468-2_1},
	doi = {10.1007/978-3-031-78468-2_1},
	abstract = {… -aware GPT-4 with RAG significantly enhanced the AI assistant’s utility. RAG’s ability to … In summary, IT - especially AI, LLM and RAG, offers powerful tools to support KM processes, …},
	journal = {… Conference on Artificial …},
	author = {Pondel, M. and Chomiak-Orsa, I. and Sobińska, M. and {...}},
	year = {2024},
	note = {Publisher: Springer},
	annote = {3 cites: https://scholar.google.com/scholar?cites=12370458610691218798\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wu_usable_2024,
	title = {Usable {XAI}: 10 strategies towards exploiting explainability in the {LLM} era},
	url = {https://arxiv.org/abs/2403.08946},
	abstract = {… Given a query prompt and its ChatGPT response, we aim to build a classifier to detect if the response contains hallucination. Since the gradients of ChatGPT is inaccessible, we apply …},
	journal = {arXiv preprint arXiv …},
	author = {Wu, X. and Zhao, H. and Zhu, Y. and Shi, Y. and Yang, F. and Hu, L. and Liu, T. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {77 cites: https://scholar.google.com/scholar?cites=2425381706097215272\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_dmqr-rag_2024,
	title = {Dmqr-rag: {Diverse} multi-query rewriting for rag},
	url = {https://arxiv.org/abs/2411.13154},
	abstract = {… In contrast, “What is the citation count for the Transformer paper?” is a general-purpose … In this section, we will first explore various LLM-based rewriting strategies from an informational …},
	journal = {arXiv preprint arXiv …},
	author = {Li, Z. and Wang, J. and Jiang, Z. and Mao, H. and Chen, Z. and Du, J. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {14 cites: https://scholar.google.com/scholar?cites=10364444343433055419\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{shen_citekit_2024,
	title = {Citekit: {A} modular toolkit for large language model citation generation},
	url = {https://arxiv.org/abs/2408.04662},
	abstract = {… Prompt self-RAG As for Llama3-8B and GPT-4o, there is no trained version for self-RAG, we use prompt to make the LLM retrieve documents and generate, then use an NLI model to …},
	journal = {arXiv preprint arXiv:2408.04662},
	author = {Shen, J. and Zhou, T. and Chen, Y. and Liu, K.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=8252601899749809203\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bao_faithbench_2024,
	title = {Faithbench: {A} diverse hallucination benchmark for summarization by modern llms},
	url = {https://arxiv.org/abs/2410.13210},
	abstract = {… Retrieval-Augmented Generation (RAG). However, existing evaluations of hallucinations in LLM-… Filtering samples by LLM To balance annotator effort with our goal of LLM diversity, we …},
	journal = {arXiv preprint arXiv …},
	author = {Bao, F. S. and Li, M. and Qu, R. and Luo, G. and Wan, E. and Tang, Y. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {16 cites: https://scholar.google.com/scholar?cites=6273198214973068547\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{antico_unimib_2024,
	title = {Unimib {Assistant}: designing a student-friendly {RAG}-based chatbot for all their needs},
	url = {https://arxiv.org/abs/2411.19554},
	abstract = {… between the LLM and the data. Finally, practical testing of how the RAG-LLM system … ChatGPT remains prone to hallucinations and provides unclickable links from time to time if …},
	journal = {arXiv preprint arXiv …},
	author = {Antico, C. and Giordano, S. and Koyuturk, C. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {13 cites: https://scholar.google.com/scholar?cites=18212093656119410079\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wu_unigen_2024,
	title = {Unigen: {A} unified framework for textual dataset generation using large language models},
	url = {https://arxiv.org/abs/2406.18966},
	abstract = {… Generation (RAG)-based validation method to check the factuality of generated statements to … Motivated by this finding, we require the LLM to generate Python code to solve the given …},
	journal = {arXiv preprint arXiv …},
	author = {Wu, S. and Huang, Y. and Gao, C. and Chen, D. and Zhang, Q. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {33 cites: https://scholar.google.com/scholar?cites=17720305255998286243\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{galitsky_enhancing_2025,
	title = {Enhancing {RAG} and {Knowledge} {Graphs} with {Discourse}},
	url = {https://dialogue-conf.org/wp-content/uploads/2025/04/GalitskyBIlvovskyDMorkovkinA.110.pdf},
	abstract = {… Retrieval Augmented Generation (RAG) architectures to address a lack of specific information and hallucination issues of Large Language Models (LLM)… on top of LLM and maintains a …},
	journal = {Proceedings of the …},
	author = {Galitsky, B. and Ilvovsky, D. and Morkovkin, A.},
	year = {2025},
	note = {Publisher: dialogue-conf.org
Type: PDF},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kang_bim_2024,
	title = {{BIM} knowledge expert agent research based on {LLM} and {RAG}},
	journal = {Journal of KIBIM},
	author = {Kang, T. W. and Park, S. H.},
	year = {2024},
	note = {Publisher: Korean Institute of Building …
Type: CITATION},
	annote = {3 cites: https://scholar.google.com/scholar?cites=7312297353203249951\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tang_lottery_2025,
	title = {The {Lottery} {LLM} {Hypothesis}, {Rethinking} {What} {Abilities} {Should} {LLM} {Compression} {Preserve}?},
	url = {https://arxiv.org/abs/2502.17535},
	abstract = {… in LLMs related to retrievalaugmented generation, multi-step … enhance LLM performance. Then, we propose a lottery … within LLM parameters if RAG can accurately retrieve factual …},
	journal = {arXiv preprint arXiv …},
	author = {Tang, Z. and Liu, X. and Wang, Q. and Dong, P. and He, B. and Chu, X. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=6906517982062333110\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_efficient_2025,
	title = {Efficient {Dynamic} {Clustering}-{Based} {Document} {Compression} for {Retrieval}-{Augmented}-{Generation}},
	url = {https://arxiv.org/abs/2504.03165},
	abstract = {… factual conflicts and duplicate content for the LLMs to handle. As an advanced approach, Graphbased RAG … step that leverages a large language model (LLM) to generate concise yet …},
	journal = {arXiv preprint arXiv:2504.03165},
	author = {Li, W. and Liu, K. and Zhang, X. and Lei, X. and Ma, W. and Liu, Y.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=11599630364484614033\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{basaran_beyond_2025,
	title = {Beyond traditional prognostics: integrating {RAG}-enhanced {AtlasGPT} and {ChatGPT} 4.0 into aneurysmal subarachnoid hemorrhage outcome prediction},
	url = {https://link.springer.com/article/10.1007/s10143-025-03194-w},
	doi = {10.1007/s10143-025-03194-w},
	abstract = {… putting trust in what conventional AI, like ChatGPT, predicts. Despite language model designers taking steps to prevent these consultations by making sure that language models are not …},
	journal = {Neurosurgical …},
	author = {Basaran, A. E. and Güresir, A. and Knoch, H. and Vychopen, M. and {...}},
	year = {2025},
	note = {Publisher: Springer
Type: HTML},
	annote = {5 cites: https://scholar.google.com/scholar?cites=952110246615330251\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ping_hdlcore_2025,
	title = {Hdlcore: {A} training-free framework for mitigating hallucinations in llm-generated hdl},
	url = {https://arxiv.org/abs/2503.16528},
	abstract = {… • Efficient Heterogeneous RAG: We establish a comprehensive heterogeneous database from carefully selected open-source HDL datasets. Our proposed RAG system extracts multiple …},
	journal = {arXiv preprint arXiv …},
	author = {Ping, H. and Li, S. and Zhang, P. and Cheng, A. and Duan, S. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=5577356983272021666\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bei_manufacturing_2024,
	title = {Manufacturing domain qa with integrated term enhanced rag},
	url = {https://ieeexplore.ieee.org/abstract/document/10649905/},
	abstract = {… hallucination issues in domain-specific LLMs, the most prevalent method currently is RetrievalAugmented Generation (RAG… is then input into a Large Language Model (LLM) to …},
	journal = {… Joint Conference on …},
	author = {Bei, Y. and Fang, Z. and Mao, S. and Yu, S. and Jiang, Y. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=18049019900847566147\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sanjani_performance_2025,
	title = {Performance {Analysis} of {LLM} {Models} with {RAG} and {Fine}-{Tuning} {T5} for {Chatbot} {Optimization} in {Call} {Centers}},
	url = {https://ieeexplore.ieee.org/abstract/document/11018908/},
	abstract = {… RAG also significantly reduces hallucinations by grounding the responses of chatbot in factual data retrieved from trusted … strengths and limitations of various LLM approaches, we aim to …},
	journal = {2025 International …},
	author = {Sanjani, L. A. and Sarno, R. and Sungkono, K. R. and {...}},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bazgir_agentichypothesis_2025,
	title = {Agentichypothesis: {A} survey on hypothesis generation using llm systems},
	url = {https://openreview.net/forum?id=UeeyfR4CUg},
	abstract = {… for LLM-based hypothesis generation, including Retrieval Augmented Generation (RAG), … LLMs employ citation graph integration to ground hypotheses in existing literature, thereby …},
	journal = {Towards Agentic AI for Science: Hypothesis …},
	author = {Bazgir, A. and Zhang, Y.},
	year = {2025},
	note = {Publisher: openreview.net},
	annote = {10 cites: https://scholar.google.com/scholar?cites=776480507503302332\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chavva_enhanced_2023,
	title = {Enhanced {Hybrid} {RAG}-{LLM} {Architecture} for {Domain}-{Specific} {Cloud} {Infrastructure} {Management}: {Advancing} {Context}-{Aware} {Decision}-{Making} {Strategies}},
	url = {https://journals.theusinsight.com/index.php/AJAI/article/view/70},
	abstract = {… This paper presents an enhanced Hybrid Retrieval-Augmented Generation with Large Language Model (RAG-LLM) architecture tailored for domain-specific cloud infrastructure …},
	journal = {American Journal of AI \&Innovation},
	author = {Chavva, M. and Veera, S.},
	year = {2023},
	note = {Publisher: journals.theusinsight.com},
	annote = {23 cites: https://scholar.google.com/scholar?cites=15357873704417974307\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jin_orthodoc_2024,
	title = {Orthodoc: {Multimodal} large language model for assisting diagnosis in computed tomography},
	url = {https://arxiv.org/abs/2409.09052},
	abstract = {… their conditions and enhancing doctor-patient trust. Computed Tomography (CT) is … Retrieval-Augmented Generation(RAG) module capable of effectively mitigating model hallucinations…},
	journal = {arXiv preprint arXiv:2409.09052},
	author = {Jin, Y. and Zhang, Y.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=3638377799234393369\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kumari_innovative_2024,
	title = {Innovative {Corporate} {Query} {Handling} with {Domain}-{Specific} {RAG}},
	url = {https://ieeexplore.ieee.org/abstract/document/10973648/},
	abstract = {… combines LLMs with Retrieval Augmented Generation (RAG). We … responses while reducing hallucinations. Keywords—… where RAG serves as the retriever component whereas the LLM …},
	journal = {2024 OITS …},
	author = {Kumari, S. and Chakraborty, U. K. and Nath, B. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{martineau_what_2023,
	title = {What is retrieval-augmented generation?},
	url = {https://research.ibm.com/blog/retrieval-augmented-generation-RAG?ref=blog.zatrok.com},
	abstract = {… Implementing RAG in an LLM-based question answering … By grounding an LLM on a set of external, verifiable facts, the … that an LLM will leak sensitive data, or ‘hallucinate’ incorrect …},
	journal = {IBM Research Blog},
	author = {Martineau, K. and Explainable, A. I. and Generative, A. I.},
	year = {2023},
	note = {Publisher: research.ibm.com
Type: HTML},
	annote = {147 cites: https://scholar.google.com/scholar?cites=7746764548504959819\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yang_timerag_2025,
	title = {Timerag: {Boosting} llm time series forecasting via retrieval-augmented generation},
	url = {https://ieeexplore.ieee.org/abstract/document/10889933/},
	abstract = {… Our work demonstrates the potential of RAG in amplifying LLM performance in time series forecasting, which offers a promising approach for future research in knowledgeenhanced …},
	journal = {ICASSP 2025-2025 IEEE …},
	author = {Yang, S. and Wang, D. and Zheng, H. and Jin, R.},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {30 cites: https://scholar.google.com/scholar?cites=12095553176507621667\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhu_multimodal_2025,
	title = {Multimodal large language model with knowledge retrieval using flowchart embedding for forming follow-up recommendations for pancreatic cystic lesions},
	url = {https://ajronline.org/doi/abs/10.2214/ajr.25.32729},
	doi = {10.2214/ajr.25.32729},
	abstract = {… RAG, a technique that allows domain-… LLM performance and reducing hallucinations (16,17) in other radiologic tasks (25,26). However, in the present analysis, the plain-text RAG …},
	journal = {American Journal of …},
	author = {Zhu, Z. and Liu, J. and Hong, C. W. and Houshmand, S. and {...}},
	year = {2025},
	note = {Publisher: ajronline.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=2004596255307087214\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{iranmanesh_llm-assisted_2025,
	title = {{LLM}-assisted {Graph}-{RAG} {Information} {Extraction} from {IFC} {Data}},
	url = {https://arxiv.org/abs/2504.16813},
	abstract = {… Mitigating large language model hallucinations via autonomous knowledge graph-based retrofitting. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages …},
	journal = {arXiv preprint arXiv:2504.16813},
	author = {Iranmanesh, S. and Saadany, H. and Vakaj, E.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{xian_understanding_2024,
	title = {Understanding {Data} {Poisoning} {Attacks} for {RAG}: {Insights} and {Algorithms}},
	url = {https://openreview.net/forum?id=2aL6gcFX7q},
	abstract = {… Retrieval-Augmented Generation (RAG) effectively alleviates these problems by … the factual accuracy of LLM-generated content. However, recent studies reveal that RAG systems are …},
	publisher = {openreview.net},
	author = {Xian, X. and Wang, T. and You, L. and Qi, Y.},
	year = {2024},
	annote = {5 cites: https://scholar.google.com/scholar?cites=14964506656781750024\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cremaschi_decoding_2025,
	title = {Decoding the mind: {A} {RAG}-{LLM} on {ICD}-11 for decision support in psychology},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417425008139},
	abstract = {… LLMind Chat leverages a Retrieval Augmented Generation (RAG) model based on the Gemma 2 (27B parameters), specifically adapted to the context of the ICD-11. This RAG model …},
	journal = {Expert Systems with …},
	author = {Cremaschi, M. and Ditolve, D. and Curcio, C. and Panzeri, A. and {...}},
	year = {2025},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {6 cites: https://scholar.google.com/scholar?cites=12097643248451710040\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sung_new_2024,
	title = {A new pipeline for generating instruction dataset via {RAG} and self fine-tuning},
	url = {https://ieeexplore.ieee.org/abstract/document/10633534/},
	abstract = {… of LLMs and the Retrieval-Augmented Generation (RAG) related … The resulting fine-tuned LLM demonstrates showcases the … domain intricacies while maintaining factual accuracy. …},
	journal = {2024 IEEE 48th Annual Computers …},
	author = {Sung, C. W. and Lee, Y. K. and Tsai, Y. T.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {13 cites: https://scholar.google.com/scholar?cites=4652605649783009256\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{dejean_let_2024,
	title = {Let your {LLM} generate a few tokens and you will reduce the need for retrieval},
	url = {https://arxiv.org/abs/2412.11536},
	abstract = {… , indicating that the LLM is confident in answering questions without resorting to RAG. TriviaQA is … efficient to halt the LLM as early as possible and then assess whether RAG activation is …},
	journal = {arXiv preprint arXiv:2412.11536},
	author = {Déjean, H.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=5029781833499893576\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{garza_privcomp-kg_2024,
	title = {{PrivComp}-{KG}: {Leveraging} {KG} and {LLM} for {Compliance} {Verification}},
	url = {https://ieeexplore.ieee.org/abstract/document/10835639/},
	abstract = {… that leverages a Large Language Model (LLM) in combination … By utilizing LLM and Retrieval Augmented Generation (RAG), … Our LLMbased retrieval system has demonstrated a high …},
	journal = {… Conference on Trust …},
	author = {Garza, L. and Elluri, L. and Piplai, A. and Kotal, A. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=9049142222470063392\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{thakur_mirage-bench_2024,
	title = {{MIRAGE}-bench: {Automatic} multilingual benchmark arena for retrieval-augmented generation systems},
	url = {https://arxiv.org/abs/2410.13716},
	abstract = {… ized arena-based multilingual RAG benchmark for 18 diverse … RAG extensively coupling both heuristic features and LLM as … We use boostrapping to obtain confidence bounds for better …},
	journal = {arXiv preprint arXiv:2410.13716},
	author = {Thakur, N. and Kazi, S. and Luo, G. and Lin, J. and Ahmad, A.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=11004530598829699834\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{massenon__2025,
	title = {” {My} {AI} is {Lying} to {Me}”: {User}-reported {LLM} hallucinations in {AI} mobile apps reviews},
	url = {https://www.nature.com/articles/s41598-025-15416-8},
	abstract = {… User-Reported LLM Hallucination Detection algorithm were … of user reports indicative of LLM hallucinations, which was … When a user reports a factual error in a RAG-powered app, it …},
	journal = {Scientific Reports},
	author = {Massenon, R. and Gambo, I. and Khan, J. A. and Agbonkhese, C. and {...}},
	year = {2025},
	note = {Publisher: nature.com
Type: HTML},
	annote = {3 cites: https://scholar.google.com/scholar?cites=4781210363604898198\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ferrag_llm_2025,
	title = {From llm reasoning to autonomous ai agents: {A} comprehensive review},
	url = {https://arxiv.org/abs/2504.19678},
	abstract = {… and hallucinated responses [7], [8], a limitation that RetrievalAugmented Generation (RAG) … employing reflection, planning, and multi-agent collaboration has given rise to Agentic RAG …},
	journal = {arXiv preprint arXiv:2504.19678},
	author = {Ferrag, M. A. and Tihanyi, N. and Debbah, M.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {59 cites: https://scholar.google.com/scholar?cites=18364990593051905415\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lavrinovics_multihal_2025,
	title = {{MultiHal}: {Multilingual} {Dataset} for {Knowledge}-{Graph} {Grounded} {Evaluation} of {LLM} {Hallucinations}},
	url = {https://arxiv.org/abs/2505.14101},
	abstract = {… the factuality of LLM outputs. The main advantage of RAG is that it does not require retraining the generator LLM, a … However, RAG is still limited by the LLM context window size [56], its …},
	journal = {arXiv preprint arXiv …},
	author = {Lavrinovics, E. and Biswas, R. and Hose, K. and Bjerva, J.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=5493390367884621206\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{werheid_designing_2024,
	title = {Designing an llm-based copilot for manufacturing equipment selection},
	url = {https://arxiv.org/abs/2412.13774},
	abstract = {… However, no studies have been identified that propose LLM-driven methods or tools … To address this gap, we propose a factual-driven copilot based on RAG-LLMs designed to …},
	journal = {arXiv preprint arXiv …},
	author = {Werheid, J. and Melnychuk, O. and Zhou, H. and Huber, M. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=1125704691026117952\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{alessio_improving_2024,
	title = {Improving rag systems via sentence clustering and reordering},
	url = {https://www.research.unipd.it/bitstream/11577/3538814/2/paper4.pdf},
	abstract = {… well-known Large Language Model (LLM) hallucination problem, … with LLM positional dependencies and the difficulties of RAG … of RAG responses and to the use of an “LLMas-a-judge”. …},
	journal = {CEUR WORKSHOP …},
	author = {Alessio, M. and Faggioli, G. and Ferro, N. and Nardini, F. M. and {...}},
	year = {2024},
	note = {Publisher: research.unipd.it
Type: PDF},
	annote = {8 cites: https://scholar.google.com/scholar?cites=16235161927663583163\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cheng_unified_2024,
	title = {Unified active retrieval for retrieval augmented generation},
	url = {https://arxiv.org/abs/2406.12534},
	abstract = {… with only LLM, RAG involves an additional retrieval process and the longer LLM input, … entries from Self-RAG’s non-retrieval-required data, and factual knowledge questions from TAQA …},
	journal = {arXiv preprint arXiv …},
	author = {Cheng, Q. and Li, X. and Li, S. and Zhu, Q. and Yin, Z. and Shao, Y. and Li, L. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {20 cites: https://scholar.google.com/scholar?cites=17986848028803620149\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_each_2025,
	title = {Each to their own: {Exploring} the optimal embedding in rag},
	url = {https://arxiv.org/abs/2507.17442},
	abstract = {… RAG methods: MixtureEmbedding RAG and Confident RAG. … RAG performs similarly to vanilla RAG, the Confident RAG … for the LLM, and (2) Confident RAG, which employs vanilla RAG …},
	journal = {arXiv preprint arXiv:2507.17442},
	author = {Chen, S. and Zhao, Z. and Chen, J.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=16997862768830810440\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{huang_datagen_2024,
	title = {Datagen: {Unified} synthetic dataset generation via large language models},
	url = {https://openreview.net/forum?id=F5R0lG74Tu},
	abstract = {… a Retrieval-Augmented Generation (RAG)-based validation method to check the factuality of … Motivated by this finding, we require the LLM to generate Python code to solve the given …},
	journal = {The Thirteenth …},
	author = {Huang, Y. and Wu, S. and Gao, C. and Chen, D. and Zhang, Q. and {...}},
	year = {2024},
	note = {Publisher: openreview.net},
	annote = {12 cites: https://scholar.google.com/scholar?cites=711809085430013125\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhou_efficiency_2025,
	title = {The {Efficiency} vs. {Accuracy} {Trade}-off: {Optimizing} {RAG}-{Enhanced} {LLM} {Recommender} {Systems} {Using} {Multi}-{Head} {Early} {Exit}},
	url = {https://arxiv.org/abs/2501.02173},
	abstract = {… that combines Retrieval-Augmented Generation (RAG) with … real-time predictive confidence assessments across multiple … efficient, real-time LLM deployment in commercial systems. …},
	journal = {arXiv preprint arXiv …},
	author = {Zhou, H. and Gu, H. and Liu, X. and Zhou, K. and Liang, M. and Xiao, Y. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=4076450707745541814\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_knowledge_2024,
	title = {Knowledge graph-enhanced large language model for domain-specific question answering systems},
	url = {https://www.techrxiv.org/doi/full/10.36227/techrxiv.172963127.77889256},
	doi = {10.36227/techrxiv.172963127.77889256},
	abstract = {… KGRA, a novel RAG method that leverages knowledge graphs … the risk of model hallucinations and improving the LLM’s ability to … 2) LLM-Driven Retrieval Method: We developed an LLM…},
	journal = {Authorea Preprints},
	author = {Li, D. and Li, Z. and Yang, Y. and Sun, L. and An, D. and Yang, Q.},
	year = {2024},
	note = {Publisher: techrxiv.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=9911717585450632323\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{besta_multi-head_2024,
	title = {Multi-head rag: {Solving} multi-aspect problems with llms},
	url = {https://arxiv.org/abs/2406.05085},
	abstract = {… hallucinations (by grounding the LLM reply in reliable … We ensure the relevance of our RAG datasets in real use cases … all of which actively use RAG in their own LLM infrastructures. Our …},
	journal = {arXiv preprint arXiv …},
	author = {Besta, M. and Kubicek, A. and Gerstenberger, R. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {16 cites: https://scholar.google.com/scholar?cites=8568092448515787338\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kashmira_tobugraph_2024,
	title = {{TOBUGraph}: {Knowledge} {Graph}-{Based} {Retrieval} for {Enhanced} {LLM} {Performance} {Beyond} {RAG}},
	url = {https://arxiv.org/abs/2412.05447},
	abstract = {… (I4) Hallucinations during memory retrieval failures: Baseline RAG models hallucinate when … Figure 5b shows RAGv2 hallucinating because RAG relies on unstructured data, losing …},
	journal = {arXiv preprint arXiv …},
	author = {Kashmira, S. and Dantanarayana, J. L. and Brodsky, J. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_financial_2025,
	title = {Financial analysis: {Intelligent} financial data analysis system based on llm-rag},
	url = {https://arxiv.org/abs/2504.06279},
	abstract = {… Our findings validate the effectiveness of integrating RAG technology with LLMs for financial analysis tasks and provide valuable insights for future developments in intelligent financial …},
	journal = {arXiv preprint arXiv:2504.06279},
	author = {Wang, J. and Ding, W. and Zhu, X.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {77 cites: https://scholar.google.com/scholar?cites=7947943057854748537\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_what_2025,
	title = {What are {Models} {Thinking} about? {Understanding} {Large} {Language} {Model} {Hallucinations}" {Psychology}" through {Model} {Inner} {State} {Analysis}},
	url = {https://arxiv.org/abs/2502.13490},
	abstract = {… of RAG on LLM inference. For each question, the answer was converted into a retrieval-augmented knowledge base (RAG) to assist the LLM. … : with and without RAG. Features such as …},
	journal = {arXiv preprint arXiv:2502.13490},
	author = {Wang, P. and Liu, Y. and Lu, Y. and Hong, J. and Wu, Y.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=5321492753762842684\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{masoudifard_leveraging_2024,
	title = {Leveraging graph-rag and prompt engineering to enhance llm-based automated requirement traceability and compliance checks},
	url = {https://arxiv.org/abs/2412.08593},
	abstract = {… Moreover, hallucination, where models generate factually incorrect yet plausible content, … Graph-RAG to retrieve the most relevant content from reference texts. Graph-RAG enhances …},
	journal = {arXiv preprint arXiv …},
	author = {Masoudifard, A. and Sorond, M. M. and Madadi, M. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=5369420773256391976\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sood_paradigm_2025,
	title = {The {Paradigm} of {Hallucinations} in {AI}-driven cybersecurity systems: {Understanding} taxonomy, classification outcomes, and mitigations},
	url = {https://www.sciencedirect.com/science/article/pii/S0045790625002502},
	abstract = {… We present a taxonomy of hallucinations in LLMs for cybersecurity, including mapping LLM responses to classification … Finally, we discuss mitigation strategies to combat hallucinations. …},
	journal = {Computers and Electrical Engineering},
	author = {Sood, A. K. and Zeadally, S. and Hong, E. K.},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {8 cites: https://scholar.google.com/scholar?cites=62549837386721607\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hong_innovative_2025,
	title = {{INNOVATIVE} {APPLICATIONS} {OF} {RAG}-{ENHANCED} {SMALL} {LLM} {FOR} {CLOSED}-{DOMAIN} {Q}\&{A}},
	url = {https://scholarworks.bwise.kr/ssu/handle/2018.sw.ssu/51008},
	abstract = {… ) into business operations requires addressing hallucination issues, incorporating proprietary … challenge involve implementing a Retrieval-Augmented Generation (RAG) methodology, …},
	journal = {International Journal of Innovative …},
	author = {Hong, Y. and Kim, D.},
	year = {2025},
	note = {Publisher: scholarworks.bwise.kr},
	annote = {1 cites: https://scholar.google.com/scholar?cites=10022020272948724276\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zeng_cite_2025,
	title = {Cite before you speak: {Enhancing} context-response grounding in e-commerce conversational llm-agents},
	url = {https://arxiv.org/abs/2503.04830},
	abstract = {… , suggesting that citation generation paradigm substantially … , which appends source citations to LLM outputs while preserving … To diagnose the intrinsic deficiency of LLM used in RAG …},
	journal = {arXiv preprint arXiv …},
	author = {Zeng, J. and Liu, H. and Dai, Z. and Tang, X. and Luo, C. and Varshney, S. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=13382540754743814223\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{fayyazi_llm_2025,
	title = {{LLM} {Embedding}-based {Attribution} ({LEA}): {Quantifying} {Source} {Contributions} to {Generative} {Model}'s {Response} for {Vulnerability} {Analysis}},
	url = {https://arxiv.org/abs/2506.12100},
	abstract = {… This analysis reveals how RAG affects the model’s confidence in generating specific tokens and provides insight into the contextual dependencies introduced by the retrieved …},
	journal = {arXiv preprint arXiv:2506.12100},
	author = {Fayyazi, R. and Zuzak, M. and Yang, S. J.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=11129302577659999264\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{shen_pentestagent_2025,
	title = {Pentestagent: {Incorporating} llm agents to automated penetration testing},
	url = {https://dl.acm.org/doi/abs/10.1145/3708821.3733882},
	doi = {10.1145/3708821.3733882},
	abstract = {… PentestAgent, a novel LLM-based automated penetration … LLM-based techniques like retrieval augmented generation to … LLM Hallucination: Another challenge is LLM hallucination, …},
	journal = {Proceedings of the 20th …},
	author = {Shen, X. and Wang, L. and Li, Z. and Chen, Y. and Zhao, W. and Sun, D. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {32 cites: https://scholar.google.com/scholar?cites=10951180727036118514\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{rezaei_at-rag_2024,
	title = {At-rag: {An} adaptive rag model enhancing query efficiency with topic filtering and iterative reasoning},
	url = {https://arxiv.org/abs/2410.12886},
	abstract = {… The Hallucination Grader: Verifies the factual accuracy of the answer by cross-… LLM to identify the date and reason for the visit. Our method retrieved the correct details, while naive RAG …},
	journal = {arXiv preprint arXiv …},
	author = {Rezaei, M. R. and Hafezi, M. and Satpathy, A. and Hodge, L. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=3784436570245362784\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{pradeep_initial_2024,
	title = {Initial nugget evaluation results for the trec 2024 rag track with the autonuggetizer framework},
	url = {https://arxiv.org/abs/2411.09607},
	abstract = {… (RAG) Track. There is, obviously, tremendous excitement and interest in RAG, but we feel that the evaluation of RAG … Thus, we do not consider possible LLM hallucinations at all. We will …},
	journal = {arXiv preprint arXiv …},
	author = {Pradeep, R. and Thakur, N. and Upadhyay, S. and Campos, D. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {22 cites: https://scholar.google.com/scholar?cites=15308537413565183479\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bianchini_enhancing_2024,
	title = {Enhancing complex linguistic tasks resolution through fine-tuning llms, rag and knowledge graphs (short paper)},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-61003-5_13},
	doi = {10.1007/978-3-031-61003-5_13},
	abstract = {… RAG … RAG, AI systems produce outputs grounded in factual information retrieved from external and heterogeneous sources [30], thus mitigating concerns regarding the reliability of LLM-…},
	journal = {International Conference …},
	author = {Bianchini, F. and Calamo, M. and Luzi, F. De and Macrì, M. and {...}},
	year = {2024},
	note = {Publisher: Springer},
	annote = {23 cites: https://scholar.google.com/scholar?cites=18404077464109973656\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{scire_truth_2025,
	title = {Truth or {Mirage}? {Towards} {End}-{To}-{End} {Factuality} {Evaluation} with {LLM}-{Oasis}},
	url = {https://direct.mit.edu/coli/article/doi/10.1162/COLI.a.575/133509},
	doi = {10.1162/COLI.a.575/133509},
	abstract = {… of LLM-OASIS for end-to-end factuality evaluation. We compare different models in Zero-Shot (ZS) and RAG … Figure 3: McNemar’s test p-values for all model comparisons in the RAG …},
	journal = {Computational …},
	author = {Scirè, A. and Bejgu, A. S. and Tedeschi, S. and Ghonim, K. and {...}},
	year = {2025},
	note = {Publisher: direct.mit.edu},
	annote = {7 cites: https://scholar.google.com/scholar?cites=3125523170850844498\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang__2025,
	title = {From" {Hallucination}" to" {Suture}": {Insights} from {Language} {Philosophy} to {Enhance} {Large} {Language} {Models}},
	url = {https://arxiv.org/abs/2503.14392},
	abstract = {… the Anchor-RAG framework to mitigate hallucinations. Unlike … analyze the root causes of hallucinations in LLMs. Based on … in reducing hallucinations, enhancing LLM performance, and …},
	journal = {arXiv preprint arXiv:2503.14392},
	author = {Wang, Q.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_alleviating_2024,
	title = {Alleviating action hallucination for llm-based embodied agents via inner and outer alignment},
	url = {https://ieeexplore.ieee.org/abstract/document/10826957/},
	abstract = {… strategy based on retrievalaugmented generation proposed in this … Secondly, the RAG system generates actions by retrieving … reducing the risk of hallucinatory content [19]. Finally, the …},
	journal = {2024 7th …},
	author = {Li, K. and Zheng, Q. and Zhan, Y. and Zhang, C. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=7314159833845774206\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bui_cross-data_2024,
	title = {Cross-data knowledge graph construction for {LLM}-enabled educational question-answering system: {A} case study at {HCMUT}},
	url = {https://dl.acm.org/doi/abs/10.1145/3643479.3662055},
	doi = {10.1145/3643479.3662055},
	abstract = {… However, an LLM’s completion might contain "hallucinations" [11] because of limited … of RAG from KG for LLMs in practical scenarios. In this paper, we aim to pioneer a KG-based RAG …},
	journal = {Proceedings of the 1st …},
	author = {Bui, T. and Tran, O. and Nguyen, P. and Ho, B. and Nguyen, L. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {44 cites: https://scholar.google.com/scholar?cites=15386040420363998979\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jeong_generative_2023,
	title = {Generative {AI} service implementation using {LLM} application architecture: based on {RAG} model and {LangChain} framework},
	journal = {Journal of Intelligence and Information …},
	author = {Jeong, C.},
	year = {2023},
	note = {Publisher: Korea Intelligent Information System …
Type: CITATION},
	annote = {88 cites: https://scholar.google.com/scholar?cites=8276398439154807073\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{junior_domain-driven_2024,
	title = {Domain-driven {LLM} development: insights into rag and fine-tuning practices},
	url = {https://dl.acm.org/doi/abs/10.1145/3637528.3671445},
	doi = {10.1145/3637528.3671445},
	abstract = {… is not covered by the LLM pre-training. This tutorial walks through the RAG and Fine-Tuning … best practices of adopting the methodologies for the LLM tasks and use cases. The hands-…},
	journal = {Proceedings of the 30th …},
	author = {Junior, JC dos Santos and Hu, R. and Song, R. and Bai, Y.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {17 cites: https://scholar.google.com/scholar?cites=15601825709455812299\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yao_elevating_2025,
	title = {Elevating legal {LLM} responses: harnessing trainable logical structures and semantic knowledge with legal reasoning},
	url = {https://arxiv.org/abs/2502.07912},
	abstract = {… to hallucination, providing answers that appear correct but are unreliable. RetrievalAugmented Generation (RAG) … Compared with the LLaMA-3-8B w/o RAG, our proposed LSIM model …},
	journal = {arXiv preprint arXiv …},
	author = {Yao, R. and Wu, Y. and Wang, C. and Xiong, J. and Wang, F. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=11164983937585786034\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gonzalez_exploring_2024,
	title = {Exploring augmentation and cognitive strategies for {AI} based synthetic personae},
	url = {https://arxiv.org/abs/2404.10890},
	abstract = {… of whether LLM hallucinations can be directly equated to human hallucinations remains … Augmented RAG (Autonoesis): GPT-3.5 with RAG using the LLM-generated autobiography (…},
	journal = {arXiv preprint arXiv:2404.10890},
	author = {Gonzalez, R. A. and DiPaola, S.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=15715793232283497256\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{shethiya_llm-powered_2023,
	title = {{LLM}-{Powered} {Architectures}: {Designing} the {Next} {Generation} of {Intelligent} {Software} {Systems}},
	url = {http://academianexusjournal.com/index.php/anj/article/view/21},
	abstract = {… is the Retrieval-Augmented Generation (RAG) architecture. RAG augments the LLM with … and capabilities of the LLM, possibly offering "why" explanations or citations where feasible. …},
	journal = {Academia Nexus Journal},
	author = {Shethiya, A. S.},
	year = {2023},
	note = {Publisher: academianexusjournal.com},
	annote = {30 cites: https://scholar.google.com/scholar?cites=3927938635219483331\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ayala_task_2025,
	title = {Task {Decomposition} and {RAG} as {Design} {Patterns} for {LLM}-{Based} {Systems}},
	url = {https://ieeexplore.ieee.org/abstract/document/11030033/},
	abstract = {… such as an LLM’s propensity to hallucinate, high latency … the LLM’s output. To this end, we leveraged two AI techniques: Task Decomposition and Retrieval-Augmented Generation (RAG…},
	journal = {2025 IEEE/ACM 4th International Conference on AI …},
	author = {Ayala, O. M.},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xiao_krail_2024,
	title = {Krail: {A} knowledge-driven framework for base human reliability analysis integrating idheas and large language models},
	url = {https://arxiv.org/abs/2412.18627},
	abstract = {… LLM-based two-stage framework: We propose a novel LLM- … of LLM factual accuracy with RAG to mitigate hallucinations, … Inspired by these advancements, we aim to leverage RAG to …},
	journal = {arXiv preprint arXiv …},
	author = {Xiao, X. and Chen, P. and Qi, B. and Zhao, H. and Liang, J. and Tong, J. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=3274946499313324684\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{garigliotti_sdg_2024,
	title = {{SDG} target detection in environmental reports using {Retrieval}-augmented {Generation} with {LLMs}},
	url = {https://aclanthology.org/2024.climatenlp-1.19/},
	abstract = {… by an LLM to refer to each passage that the LLM considers to … allowing that the LLM may hallucinate typical reference … as expected that ChatGPT is the best performing LLM in several …},
	journal = {Proceedings of the 1st Workshop on Natural …},
	author = {Garigliotti, D.},
	year = {2024},
	note = {Publisher: aclanthology.org},
	annote = {16 cites: https://scholar.google.com/scholar?cites=6433990517208109187\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{savage_large_2025,
	title = {Large language model uncertainty proxies: discrimination and calibration for medical diagnosis and treatment},
	url = {https://academic.oup.com/jamia/article-abstract/32/1/139/7819854},
	abstract = {… context provided by RAG can errantly lead the … LLM uncertainty are important for building medical LLM-RAG systems. In this study we evaluate 3 proxies of LLM uncertainty: confidence …},
	journal = {Journal of the …},
	author = {Savage, T. and Wang, J. and Gallo, R. and Boukil, A. and {...}},
	year = {2025},
	note = {Publisher: academic.oup.com},
	annote = {37 cites: https://scholar.google.com/scholar?cites=7776023650645605557\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lyu_retrieve-plan-generation_2024,
	title = {Retrieve-plan-generation: {An} iterative planning and answering framework for knowledge-intensive llm generation},
	url = {https://arxiv.org/abs/2406.14979},
	abstract = {… factual errors due to their limited internal knowledge. Retrieval-Augmented Generation (RAG), … And we evaluate the Self-RAG model, which enhances the standard RAG by introducing …},
	journal = {arXiv preprint arXiv …},
	author = {Lyu, Y. and Niu, Z. and Xie, Z. and Zhang, C. and Xu, T. and Wang, Y. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {15 cites: https://scholar.google.com/scholar?cites=17343332201754017303\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhao_smart_2025,
	title = {A smart multimodal healthcare copilot with powerful llm reasoning},
	url = {https://arxiv.org/abs/2506.02470},
	abstract = {… of the backbone LLM. Retrieval-Augmented Generation To provide backbone LLM with case-… information and mitigate hallucinations in generated outputs, we apply the RAG method, …},
	journal = {arXiv preprint arXiv:2506.02470},
	author = {Zhao, X. and Liu, S. and Yang, S. Y. and Miao, C.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=5373384322200628986\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lu_scchat_2024,
	title = {{scChat}: {A} large language model-powered co-pilot for contextualized single-cell {RNA} sequencing analysis},
	url = {https://www.biorxiv.org/content/10.1101/2024.10.01.616063.abstract},
	doi = {10.1101/2024.10.01.616063.abstract},
	abstract = {… , employs retrieval-augmented generation to reduce hallucination, and uses an LLM-powered … function calls, retrieval-augmented generation (RAG), and a powerful LLM-driven search …},
	journal = {bioRxiv},
	author = {Lu, Y. C. and Varghese, A. and Nahar, R. and Chen, H. and Shao, K. and Bao, X. and {...}},
	year = {2024},
	note = {Publisher: biorxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=10436522255536879306\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{okutan_leveraging_2024,
	title = {Leveraging {RAG}-{LLM} to {Translate} {C}++ to {Rust}},
	url = {https://ieeexplore.ieee.org/abstract/document/10765951/},
	abstract = {… The fact that an LLM is more strongly grounded in real factual knowledge makes it “… RAG-LLM-based translation of C++ to Rust. The main advantage of an LLM-based approach is that it …},
	journal = {… Conference on Assured …},
	author = {Okutan, A. and Merten, S. and Michael, C. C. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=9645416682635148936\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_synthetic_2024,
	title = {Synthetic {Knowledge} {Ingestion}: {Towards} {Knowledge} {Refinement} and {Injection} for {Enhancing} {Large} {Language} {Models}},
	url = {https://arxiv.org/abs/2410.09629},
	abstract = {… step towards enhancing the factual accuracy of LLM outputs by refining knowledge … Further evaluations were conducted on our method within RAG systems, detailed in Table 2. Inverse …},
	journal = {arXiv preprint arXiv …},
	author = {Zhang, J. and Cui, W. and Huang, Y. and Das, K. and Kumar, S.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {21 cites: https://scholar.google.com/scholar?cites=16498478336454264628\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jiang_rago_2025,
	title = {Rago: {Systematic} performance optimization for retrieval-augmented generation serving},
	url = {https://dl.acm.org/doi/abs/10.1145/3695053.3731093},
	doi = {10.1145/3695053.3731093},
	abstract = {… LLM-only systems often struggle to achieve high factual accuracy or providing up-todate … Our baseline is an extension of LLM-only systems, where additional RAG components are …},
	journal = {Proceedings of the …},
	author = {Jiang, W. and Subramanian, S. and Graves, C. and Alonso, G. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {11 cites: https://scholar.google.com/scholar?cites=4420416556283679194\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{devine_aloftrag_2025,
	title = {{ALoFTRAG}: {Automatic} {Local} {Fine} {Tuning} for {Retrieval} {Augmented} {Generation}},
	url = {https://arxiv.org/abs/2501.11929},
	abstract = {… LLM for RAG. We show that the ALoFTRAG approach improves both the citation accuracy and answer accuracy of RAG … increase the accuracy of LLM-based RAG systems while using …},
	journal = {arXiv preprint arXiv:2501.11929},
	author = {Devine, P.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=3619472201426854709\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{abshari_llm-assisted_2024,
	title = {Llm-assisted physical invariant extraction for cyber-physical systems anomaly detection},
	url = {https://www.researchgate.net/profile/Danial-Abshari/publication/385920298_LLM-assisted_Physical_Invariant_Extraction_for_Cyber-Physical_Systems_Anomaly_Detection/links/679c8c94207c0c20fa6b0b57/LLM-assisted-Physical-Invariant-Extraction-for-Cyber-Physical-Systems-Anomaly-Detection.pdf},
	abstract = {… To overcome the challenges of the unstructured documents format and LLM hallucination, we propose the enhancement of multi-modal RAG and dedicated chain-of-thought prompt …},
	journal = {arXiv preprint arXiv:2411.10918},
	author = {Abshari, D. and Fu, C. and Sridhar, M.},
	year = {2024},
	note = {Publisher: researchgate.net
Type: PDF},
	annote = {16 cites: https://scholar.google.com/scholar?cites=15067641177427931322\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{wu_joint_2025,
	title = {Joint modeling of intelligent retrieval-augmented generation in {LLM}-based knowledge fusion},
	url = {https://www.researchsquare.com/article/rs-7739042/latest},
	abstract = {… utilization by proposing a retrieval-augmented generation method enhanced with intelligent … generation and ensuring semantic coverage, factual consistency, and contextual coherence. …},
	publisher = {researchsquare.com},
	author = {Wu, D. and Pan, S.},
	year = {2025},
	annote = {2 cites: https://scholar.google.com/scholar?cites=3013295627961454480\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{fang_ingest-and-ground_2024,
	title = {Ingest-{And}-{Ground}: {Dispelling} {Hallucinations} from {Continually}-{Pretrained} {LLMs} with {RAG}},
	url = {https://arxiv.org/abs/2410.02825},
	abstract = {… efficiency with LLM and RAG. To reduce hallucination, we continually pre-train the base LLM model with a privacy-specific knowledge base and then augment it with a semantic RAG …},
	journal = {arXiv preprint arXiv …},
	author = {Fang, C. and Larson, D. and Zhu, S. and Zeng, S. and Summer, W. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=13053182460474427631\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wu_how_2024,
	title = {How well do {LLMs} cite relevant medical references? {An} evaluation framework and analyses},
	url = {https://arxiv.org/abs/2402.02008},
	abstract = {… of LLM responses are not fully supported by the sources they provide. We also evaluate GPT-4 with retrieval augmented generation (RAG… Given the rapid pace of LLM development and …},
	journal = {arXiv preprint arXiv …},
	author = {Wu, K. and Wu, E. and Cassasola, A. and Zhang, A. and Wei, K. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {50 cites: https://scholar.google.com/scholar?cites=7671002157057119978\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{anderson_design_2024,
	title = {The design of an llm-powered unstructured analytics system},
	url = {https://arxiv.org/abs/2409.00847},
	abstract = {… of simple LLM-based operations, we can make the query plan as a whole more reliable than RAG-… While the RAG approach somewhat mitigates hallucination, LLM context windows are …},
	journal = {arXiv preprint arXiv …},
	author = {Anderson, E. and Fritz, J. and Lee, A. and Li, B. and Lindblad, M. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {34 cites: https://scholar.google.com/scholar?cites=2095547634100159196\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gao_modular_2024,
	title = {Modular rag: {Transforming} rag systems into lego-like reconfigurable frameworks},
	url = {https://arxiv.org/abs/2407.21059},
	abstract = {… challenges, such as hallucination and … RAG technology has been accelerated by LLM technology and practical application needs. Researchers are examining and organizing the RAG …},
	journal = {arXiv preprint arXiv:2407.21059},
	author = {Gao, Y. and Xiong, Y. and Wang, M. and Wang, H.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {45 cites: https://scholar.google.com/scholar?cites=14243927376852563698\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mohammadjafari_natural_2024,
	title = {From natural language to sql: {Review} of llm-based text-to-sql systems},
	url = {https://arxiv.org/abs/2410.01066},
	abstract = {… of LLM-based text-to-SQL systems, from early rule-based models to advanced LLM approaches that use (RAG… transparent AI procedures to build trust in LLM-based text-to-SQL systems. …},
	journal = {arXiv preprint arXiv …},
	author = {Mohammadjafari, A. and Maida, A. S. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {27 cites: https://scholar.google.com/scholar?cites=8927920725698204235\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_review_2025,
	title = {A review of prominent paradigms for llm-based agents: {Tool} use, planning (including rag), and feedback learning},
	url = {https://aclanthology.org/2025.coling-main.652/},
	abstract = {… LLM-profiled roles as the foundation for the development of algorithmic frameworks across different paradigms. Notably, Wang et al. (2024a) also discuss LLM … to their citations on …},
	journal = {Proceedings of the 31st International Conference on …},
	author = {Li, X.},
	year = {2025},
	note = {Publisher: aclanthology.org},
	annote = {30 cites: https://scholar.google.com/scholar?cites=14352459729605501326\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{akarajaradwong_nitibench_2025,
	title = {Nitibench: {A} comprehensive study of llm framework capabilities for thai legal question answering},
	url = {https://arxiv.org/abs/2502.10868},
	abstract = {… We evaluate retrieval-augmented generation (RAG) and long-context LLM-based … In order to control the quality of judge LLM when assessing coverage and citation score, we iteratively …},
	journal = {arXiv preprint arXiv …},
	author = {Akarajaradwong, P. and Pothavorn, P. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=18370306115919373319\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bergman_leveraging_2025,
	title = {Leveraging {Approximate} {Caching} for {Faster} {Retrieval}-{Augmented} {Generation}},
	url = {https://dl.acm.org/doi/abs/10.1145/3721146.3721941},
	doi = {10.1145/3721146.3721941},
	abstract = {… trust their outputs without extensive verification by domain experts [2, 4]. Retrieval-augmented generation (RAG… cache specifically designed for RAG-based LLM systems. By intercepting …},
	journal = {Proceedings of the 5th …},
	author = {Bergman, S. A. and Ji, Z. and Kermarrec, A. M. and Petrescu, D. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=3166613913614901241\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kadam_enhancing_2025,
	title = {Enhancing {Comprehension} with {LLM}, {TTS}, and {RAG}: {Transcription} of {Text} into {Podcasts} and {Chatbots}},
	url = {https://ieeexplore.ieee.org/abstract/document/10915367/},
	abstract = {… When synthesizing the proposed LLMs, TTS, and RAG, the system can provide clear … related to LLM hallucinations and factuality errors that means, provide a more credible and …},
	journal = {… on Intelligent and …},
	author = {Kadam, A. J. and Kute, P. R. and Kale, C. A. and {...}},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=2493659548323094229\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yamin_applications_2024,
	title = {Applications of llms for generating cyber security exercise scenarios},
	url = {https://ieeexplore.ieee.org/abstract/document/10695083/},
	abstract = {… LLM hallucination to create a sophisticated and adaptive cyber threat scenario. Our approach transforms this hallucination … LLM The bounded rationality of this LLM, enhanced by RAG, …},
	journal = {IEEE Access},
	author = {Yamin, M. M. and Hashmi, E. and Ullah, M. and Katt, B.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {51 cites: https://scholar.google.com/scholar?cites=4830024562496431348\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wu_leveraging_2025,
	title = {Leveraging {FDA} labeling documents and large language model to enhance annotation, profiling, and classification of drug adverse events with {AskFDALabel}},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC12098182/},
	abstract = {… will not risk a hallucination in the results… RAG, which restricted the reference used in the LLM inference solely to the specific labeling documents instead of using the full scope of the LLM’…},
	journal = {Drug Safety},
	author = {Wu, L. and Fang, H. and Qu, Y. and Xu, J. and Tong, W.},
	year = {2025},
	note = {Publisher: pmc.ncbi.nlm.nih.gov
Type: HTML},
	annote = {4 cites: https://scholar.google.com/scholar?cites=7685169922092931131\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kalyuzhnaya_llm_2025,
	title = {{LLM} {Agents} for {Smart} {City} {Management}: {Enhancing} {Decision} {Support} {Through} {Multi}-{Agent} {AI} {Systems}.},
	url = {https://search.ebscohost.com/login.aspx?direct=true\&profile=ehost\&scope=site\&authtype=crawler\&jrnl=26246511\&AN=183336541\&h=0pICgql%2Bey7ZL1YAQE4iib5dbwaBiWjyLc6tqZE3sd6vLsiLGJ4U0smDycxB2boqa%2FC0RX3jT2MvCufSaSMFnw%3D%3D\&crl=c},
	abstract = {… Effectiveness In this subsection, we discuss the results of using RAG to answer questions. First, … Unlike LLMs generating answers without context, the LLM-based system relies on factual …},
	journal = {… Cities (2624-6511 …},
	author = {Kalyuzhnaya, A. and Mityagin, S. and Lutsenko, E. and {...}},
	year = {2025},
	note = {Publisher: search.ebscohost.com},
	annote = {25 cites: https://scholar.google.com/scholar?cites=6035672886755458924\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jiao_can_2024,
	title = {Can we trust embodied agents? exploring backdoor attacks against embodied {LLM}-based decision-making systems},
	url = {https://arxiv.org/abs/2405.20774},
	abstract = {… for RAG-based LLM decisionmaking systems (BALD-RAG). The … from a database to augment the LLM’s input context. Recent … attack mechanism for RAG-based LLM systems as follows. …},
	journal = {arXiv preprint arXiv …},
	author = {Jiao, R. and Xie, S. and Yue, J. and Sato, T. and Wang, L. and Wang, Y. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {19 cites: https://scholar.google.com/scholar?cites=8053163630363604823\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ma_think--graph_2024-1,
	title = {Think-on-graph 2.0: {Deep} and interpretable large language model reasoning with knowledge graph-guided retrieval},
	url = {https://ui.adsabs.harvard.edu/abs/2024arXiv240710805M/abstract},
	abstract = {… knowledge gaps and hallucinations in generated … RAG framework that aligns questions with the knowledge graph and uses it as a navigational tool, which deepens and refines the RAG …},
	journal = {arXiv e-prints},
	author = {Ma, S. and Xu, C. and Jiang, X. and Li, M. and Qu, H. and Guo, J.},
	year = {2024},
	note = {Publisher: ui.adsabs.harvard.edu},
	annote = {35 cites: https://scholar.google.com/scholar?cites=2174950604270309737\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{darwish_mitigating_2025,
	title = {Mitigating {LLM} {Hallucinations} {Using} a {Multi}-{Agent} {Framework}},
	url = {https://www.mdpi.com/2078-2489/16/7/517},
	abstract = {… For instance, models like MrRank and RAG-Prompter refine retrieval quality, while approaches such as WikiChat and Retrieval-Augmented Generation demonstrate the empirical …},
	journal = {Information},
	author = {Darwish, A. M. and Rashed, E. A. and Khoriba, G.},
	year = {2025},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {4 cites: https://scholar.google.com/scholar?cites=14578740355726212549\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{pattnayak_hybrid_2025,
	title = {Hybrid ai for responsive multi-turn online conversations with novel dynamic routing and feedback adaptation},
	url = {https://arxiv.org/abs/2506.02097},
	abstract = {… 2024) further optimizes RAG for precision and adaptability in complex applications. By re… inference, RAG systems mitigate common LLM challenges such as hallucinations and outdated …},
	journal = {arXiv preprint arXiv …},
	author = {Pattnayak, P. and Agarwal, A. and Meghwani, H. and Patel, H. L. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {14 cites: https://scholar.google.com/scholar?cites=14168321870423444774\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wilcock_new_2024,
	title = {New technologies for spoken dialogue systems: {LLMs}, {RAG} and the {GenAI} {Stack}},
	url = {https://researchportal.helsinki.fi/files/320056326/IWSDS-short-final-v10.pdf},
	abstract = {… RAG with Llama2 to generate natural language answers to user questions about the document contents. Note that the LLM generates confident … uses vector-based RAG with Llama2 to …},
	journal = {14th International Workshop on Spoken …},
	author = {Wilcock, G.},
	year = {2024},
	note = {Publisher: researchportal.helsinki.fi
Type: PDF},
	annote = {2 cites: https://scholar.google.com/scholar?cites=822024211649923730\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kaintura_orassistant_2024,
	title = {{ORAssistant}: {A} {Custom} {RAG}-based {Conversational} {Assistant} for {OpenROAD}},
	url = {https://arxiv.org/abs/2410.03845},
	abstract = {… as the base LLM model to build and test ORAssistant. Early evaluation results of the RAG-based … ’s output by ensuring that knowledge is retrieved from trusted data sources, generating …},
	journal = {arXiv preprint arXiv:2410.03845},
	author = {Kaintura, A. and Luar, S. S. and Almeida, I. I.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=11641719825243804670\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{adam_traceable_2025,
	title = {Traceable {LLM}-based validation of statements in knowledge graphs},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457325000706},
	abstract = {… , our approach is to avoid using internal LLM factual knowledge altogether. Instead, verified … To assess the possible application of this retrieval augmented generation (RAG) workflow …},
	journal = {Information Processing \&Management},
	author = {Adam, D. and Kliegr, T.},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {8 cites: https://scholar.google.com/scholar?cites=7282871419166504339\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{arun_chatgpt_2024,
	title = {{ChatGPT} versus a customized {AI} chatbot ({Anatbuddy}) for anatomy education: {A} comparative pilot study},
	url = {https://anatomypubs.onlinelibrary.wiley.com/doi/abs/10.1002/ase.2502},
	doi = {10.1002/ase.2502},
	abstract = {… resources used for Retrieval Augmented Generation (RAG). The … The relevant RAG documents are sent as context to the LLM, … AI model (ChatGPT 3.5) in terms of factual accuracy. This …},
	journal = {Anatomical Sciences …},
	author = {Arun, G. and Perumal, V. and Urias, FPJB and Ler, Y. E. and {...}},
	year = {2024},
	note = {Publisher: Wiley Online Library},
	annote = {25 cites: https://scholar.google.com/scholar?cites=5030621390045750677\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{park_literature_2024,
	title = {Literature review of {AI} hallucination research since the advent of {ChatGPT}: {Focusing} on papers from {arXiv}},
	journal = {Informatization Policy},
	author = {Park, D. M. and Lee, H. J.},
	year = {2024},
	note = {Publisher: National Information Society Agency
Type: CITATION},
	annote = {14 cites: https://scholar.google.com/scholar?cites=10505214880698559491\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yepes_financial_2024,
	title = {Financial report chunking for effective retrieval augmented generation},
	url = {https://arxiv.org/abs/2402.05131},
	abstract = {… problem with LLMs [15,43] when recovering factual information directly from an LLM. In RAG, instead of answering a user query directly using an LLM, the user query is used to retrieve …},
	journal = {arXiv preprint arXiv …},
	author = {Yepes, A. J. and You, Y. and Milczek, J. and Laverde, S. and Li, R.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {90 cites: https://scholar.google.com/scholar?cites=2674128702786811880\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mukherjee_llm-driven_2025,
	title = {{LLM}-driven {Provenance} {Forensics} for {Threat} {Investigation} and {Detection}},
	url = {https://arxiv.org/abs/2508.21323},
	abstract = {… We highlight how LLM and RAG introduce new opportunities and challenges in provenance-… A recurring risk with LLM-driven systems is hallucination when generated outputs diverge …},
	journal = {arXiv preprint arXiv:2508.21323},
	author = {Mukherjee, K. and Kantarcioglu, M.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=16825308825000715287\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{diaz-pace_helping_2024,
	title = {Helping novice architects to make quality design decisions using an llm-based assistant},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-70797-1_21},
	doi = {10.1007/978-3-031-70797-1_21},
	abstract = {… is crucial to mitigate “hallucinations” in the LLM outputs. … , RAG [4] is a practical way of adding knowledge to an LLM, … First, RAG ensures that the AK being retrieved is relevant to the …},
	journal = {European Conference on Software …},
	author = {Díaz-Pace, J. A. and Tommasel, A. and Capilla, R.},
	year = {2024},
	note = {Publisher: Springer},
	annote = {21 cites: https://scholar.google.com/scholar?cites=9928707167842593178\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{christodoulou_nlpdame_2025,
	title = {{NLPDame} at {EXIST}: sexism categorization in tweets via multi-head multi-task models, {LLM} \& {RAG} voting synergy},
	url = {https://ceur-ws.org/Vol-4038/paper_147.pdf},
	abstract = {… RAG was employed as it provides external knowledge from the most relevant texts and minimizes LLM hallucinations. It was used to provide context to assist the LLM in performing …},
	journal = {Working Notes of CLEF},
	author = {Christodoulou, C.},
	year = {2025},
	note = {Publisher: ceur-ws.org
Type: PDF},
	annote = {2 cites: https://scholar.google.com/scholar?cites=7203517318595260331\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mavromatis_gnn-rag_2025,
	title = {Gnn-rag: {Graph} neural retrieval for efficient large language model reasoning on knowledge graphs},
	url = {https://aclanthology.org/2025.findings-acl.856/},
	abstract = {… The input given to the LLM contains the KG factual information along with the question and a prompt. For instance, the input becomes “Knowledge: Jamaica → language\_spoken → …},
	journal = {Findings of the Association for …},
	author = {Mavromatis, C. and Karypis, G.},
	year = {2025},
	note = {Publisher: aclanthology.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=4360580807815257938\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{liu_ctrla_2024-1,
	title = {Ctrla: {Adaptive} retrieval-augmented generation via probe-guided control},
	url = {https://ui.adsabs.harvard.edu/abs/2024arXiv240518727L/abstract},
	abstract = {… to regulate the LLM's behavior by manipulating its representations for increased honesty, and a confidence probe to monitor the internal states of LLM and assess confidence levels, …},
	journal = {arXiv e …},
	author = {Liu, H. and Zhang, H. and Guo, Z. and Dong, K. and Li, X. and Lee, Y. Q. and {...}},
	year = {2024},
	note = {Publisher: ui.adsabs.harvard.edu},
	annote = {11 cites: https://scholar.google.com/scholar?cites=2164339214581178149\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_geofactory_2025,
	title = {{GeoFactory}: an {LLM} performance enhancement framework for geoscience factual and inferential tasks},
	url = {https://www.tandfonline.com/doi/abs/10.1080/20964471.2025.2506291},
	doi = {10.1080/20964471.2025.2506291},
	abstract = {… All five RAG algorithms evaluated in this study demonstrated significant improvements in LLM performance, particularly in geoscientific factual tasks. The experimental findings suggest …},
	journal = {Big Earth Data},
	author = {Chen, Z. and Wang, X. and Zhang, X. and Lin, M. and Liao, Y. and Li, J. and {...}},
	year = {2025},
	note = {Publisher: Taylor \&Francis},
	annote = {2 cites: https://scholar.google.com/scholar?cites=2218218514677461639\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zarza_optimized_2023,
	title = {Optimized financial planning: integrating individual and cooperative budgeting models with {LLM} recommendations},
	url = {https://www.mdpi.com/2673-2688/5/1/6},
	abstract = {… potential for LLM hallucination, the methodology could integrate a retrieval augmented generation (RAG) … The incorporation of RAG into our recommendation generation process can be …},
	journal = {AI},
	author = {Zarzà, I. De and Curtò, J. De and Roig, G. and Calafate, C. T.},
	year = {2023},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {49 cites: https://scholar.google.com/scholar?cites=12936357317340559471\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jiang_knowledge_2025,
	title = {Knowledge assimilation: {Implementing} knowledge-guided agricultural large language model},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705125002448},
	abstract = {… a novel Knowledge-guided Agriculture LLM (KALLM) designed … At the sentence level, we introduce a self-reflective RAG … LLMs and the current SFT-RAG pipeline show that our KALLM …},
	journal = {Knowledge-based …},
	author = {Jiang, J. and Yan, L. and Liu, H. and Xia, Z. and Wang, H. and Yang, Y. and {...}},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {11 cites: https://scholar.google.com/scholar?cites=6929162851903522944\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{rome__2024,
	title = {" {Ask} {Me} {Anything}": {How} {Comcast} {Uses} {LLMs} to {Assist} {Agents} in {Real} {Time}},
	url = {https://dl.acm.org/doi/abs/10.1145/3626772.3661345},
	doi = {10.1145/3626772.3661345},
	abstract = {… a typical RAG … ], our Citation Rail was accomplished by prompting the LLM to cite its sources in a specific manner (cf, Figure 1) combined with a post processing step where the citations …},
	journal = {Proceedings of the 47th …},
	author = {Rome, S. and Chen, T. and Tang, R. and Zhou, L. and Ture, F.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {17 cites: https://scholar.google.com/scholar?cites=12851761930214280483\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{burgan_developing_2024,
	title = {Developing a {Retrieval} {Augmented} {Generation} ({RAG}) {Chatbot} {App} {Using} {Adaptive} {Large} {Language} {Models} ({LLM}) and {LangChain} {Framework}},
	url = {https://www.pwvas.org/index.php/pwvas/article/view/1068},
	abstract = {… Testing each LLM helped assess answer types and accuracy. … a local LLM based on Google's Gemini model. Ollama framework aids in automatic LLM selection based on user prompts. …},
	journal = {… of the West Virginia Academy of Science},
	author = {Burgan, C. and Kowalski, J. and Liao, W.},
	year = {2024},
	note = {Publisher: pwvas.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=9838105862670130285\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{emonet_llm-based_2024,
	title = {Llm-based sparql query generation from natural language over federated knowledge graphs},
	url = {https://arxiv.org/abs/2410.06062},
	abstract = {… We introduce a Retrieval-Augmented Generation (RAG) system for translating user … To enhance accuracy and reduce hallucinations in query generation, our system utilises metadata …},
	journal = {arXiv preprint arXiv …},
	author = {Emonet, V. and Bolleman, J. and Duvaud, S. and Farias, TM de and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {20 cites: https://scholar.google.com/scholar?cites=12233193208001289634\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{shethiya_architecting_2024,
	title = {Architecting {Intelligent} {Systems}: {Opportunities} and {Challenges} of {Generative} {AI} and {LLM} {Integration}},
	url = {http://academianexusjournal.com/index.php/anj/article/view/25},
	abstract = {… patterns that support LLM integration, such as retrieval-augmented generation (RAG), … —such as showing source documents or confidence scores—can further reinforce trust[12]. …},
	journal = {Academia Nexus Journal},
	author = {Shethiya, A. S.},
	year = {2024},
	note = {Publisher: academianexusjournal.com},
	annote = {30 cites: https://scholar.google.com/scholar?cites=9605035258878768765\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_review_2024,
	title = {A review of prominent paradigms for llm-based agents: {Tool} use (including rag), planning, and feedback learning},
	url = {https://arxiv.org/abs/2406.05804},
	abstract = {… LLM-profiled roles as the foundation for the development of algorithmic frameworks across different paradigms. Notably, Wang et al. (2024a) also discuss LLM … to their citations on …},
	journal = {arXiv preprint arXiv:2406.05804},
	author = {Li, X.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {13 cites: https://scholar.google.com/scholar?cites=17739465334632350897\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{liu_stall_2024,
	title = {Stall+: {Boosting} llm-based repository-level code completion with static analysis},
	url = {https://arxiv.org/abs/2406.10018},
	abstract = {… RAG with individual or multiple integration strategies can further substantially improve LLM-based … To mitigate the hallucination of LLM-based generation, there is an increasing body of …},
	journal = {arXiv preprint arXiv:2406.10018},
	author = {Liu, J. and Chen, Y. and Liu, M. and Peng, X. and Lou, Y.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {25 cites: https://scholar.google.com/scholar?cites=7909751505479003017\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tsai_rtlfixer_2024,
	title = {Rtlfixer: {Automatically} fixing rtl syntax errors with large language model},
	url = {https://dl.acm.org/doi/abs/10.1145/3649329.3657353},
	doi = {10.1145/3649329.3657353},
	abstract = {… produce factual errors, a phenomenon termed hallucination [5]. To mitigate this challenge, the … with RAG, regardless of the quality of the compiler feedback message and LLM (GPT-4). …},
	journal = {Proceedings of the 61st ACM/IEEE Design …},
	author = {Tsai, Y. D. and Liu, M. and Ren, H.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {158 cites: https://scholar.google.com/scholar?cites=6446175719600702728\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jauhiainen_generative_2025,
	title = {Generative {AI} in education: {ChatGPT}-4 in evaluating students' written responses},
	url = {https://www.tandfonline.com/doi/abs/10.1080/14703297.2024.2422337},
	doi = {10.1080/14703297.2024.2422337},
	abstract = {… RAG framework ensured ChatGPT-4’s accurate recall of responses and secure alignment in the university’s evaluation criteria. ChatGPT-4’… ChatGPT-4 successfully assessed the factual …},
	journal = {Innovations in Education and …},
	author = {Jauhiainen, J. S. and Guerra, A. Garagorry},
	year = {2025},
	note = {Publisher: Taylor \&Francis},
	annote = {30 cites: https://scholar.google.com/scholar?cites=12026394492846067216\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tarabanis_performance_2024,
	title = {Performance of publicly available large language models on internal medicine board-style questions},
	url = {https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000604},
	abstract = {… To address this, ascribing a variable degree of confidence to each LLM … Retrieval Augmented Generation a viable technique for improving factual accuracy in medical examination LLM …},
	journal = {PLOS Digital …},
	author = {Tarabanis, C. and Zahid, S. and Mamalis, M. and Zhang, K. and {...}},
	year = {2024},
	note = {Publisher: journals.plos.org
Type: HTML},
	annote = {13 cites: https://scholar.google.com/scholar?cites=15790362540496032798\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{elsharef_facilitating_2024,
	title = {Facilitating threat modeling by leveraging large language models},
	url = {https://www.ndss-symposium.org/wp-content/uploads/aiscc2024-16-paper.pdf},
	abstract = {… Table V shows the example of hallucination from RAG-based LLM … this RAG-enhance LLM solution for threat modeling. Based on the observations in this study, the RAGenhanced LLM …},
	journal = {Workshop on AI Systems with …},
	author = {Elsharef, I. and Zeng, Z. and Gu, Z.},
	year = {2024},
	note = {Publisher: ndss-symposium.org
Type: PDF},
	annote = {15 cites: https://scholar.google.com/scholar?cites=13582849102086431410\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tan_chinese_2024,
	title = {Chinese safetyqa: {A} safety short-form factuality benchmark for large language models},
	url = {https://arxiv.org/abs/2412.15265},
	abstract = {… To address these challenges and better evaluate the factuality ability of LLMs to … factuality abilities of existing LLMs and analyze how these capabilities relate to LLM abilities, eg, RAG …},
	journal = {arXiv preprint arXiv …},
	author = {Tan, Y. and Zheng, B. and Zheng, B. and Cao, K. and Jing, H. and Wei, J. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=106626356778053405\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sharma_forensicllm_2025,
	title = {{ForensicLLM}: {A} local large language model for digital forensics},
	url = {https://www.sciencedirect.com/science/article/pii/S2666281725000113},
	abstract = {… , and response hallucinations could compromise their … and RAG model over the base model. ForensicLLM showed strength in “correctness” and “relevance” metrics, while the RAG …},
	journal = {Forensic Science …},
	author = {Sharma, B. and Ghawaly, J. and McCleary, K. and Webb, A. M. and {...}},
	year = {2025},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {7 cites: https://scholar.google.com/scholar?cites=2964121534625316080\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{trofimova_coderefine_2024,
	title = {{CodeRefine}: {A} {Pipeline} for {Enhancing} {LLM}-{Generated} {Code} {Implementations} of {Research} {Papers}},
	url = {https://arxiv.org/abs/2408.13366},
	abstract = {… Retrieval Augmented Generation (RAG) concept to improve the quality and accuracy of generated text. In RAG, … helps control LLM hallucinations, as we aim to avoid the LLM introducing …},
	journal = {arXiv preprint arXiv:2408.13366},
	author = {Trofimova, E. and Sataev, E. and Jowhari, A. S.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=10244356268795940465\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_healthq_2025,
	title = {Healthq: {Unveiling} questioning capabilities of llm chains in healthcare conversations},
	url = {https://www.sciencedirect.com/science/article/pii/S2352648325000315},
	abstract = {… for evaluating the questioning capabilities of LLM healthcare chains. By implementing advanced LLM chains, including Retrieval-Augmented Generation (RAG), Chain of Thought (CoT)…},
	journal = {Smart Health},
	author = {Wang, Z. and Li, H. and Huang, D. and Kim, H. S. and Shin, C. W. and {...}},
	year = {2025},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {16 cites: https://scholar.google.com/scholar?cites=17727973482330678576\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{goyal_hacking_2024,
	title = {Hacking, the lazy way: {LLM} augmented pentesting},
	url = {https://arxiv.org/abs/2409.09493},
	abstract = {… In our research, we introduce a new concept called “LLM Augmented Pentesting” … implementation of Retrieval-Augmented Generation (RAG) minimizes hallucinations and en…},
	journal = {arXiv preprint arXiv …},
	author = {Goyal, D. and Subramanian, S. and Peela, A. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {12 cites: https://scholar.google.com/scholar?cites=11681736498668369398\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ryu_retrieval-based_2023,
	title = {Retrieval-based evaluation for {LLMs}: a case study in {Korean} legal {QA}},
	url = {https://aclanthology.org/2023.nllp-1.13/},
	abstract = {… potential presence of factual errors. Motivated by this issue, we propose Eval-RAG, a new evaluation method for LLM-generated texts. Unlike existing methods, Eval-RAG evaluates the …},
	journal = {Proceedings of the …},
	author = {Ryu, C. and Lee, S. and Pang, S. and Choi, C. and Choi, H. and {...}},
	year = {2023},
	note = {Publisher: aclanthology.org},
	annote = {33 cites: https://scholar.google.com/scholar?cites=4148165545926420792\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{shirdel_aprescot_2025,
	title = {{AprèsCoT}: {Explaining} {LLM} answers with knowledge graphs and chain of thought},
	url = {https://www.openproceedings.org/2025/conf/edbt/paper-337.pdf},
	abstract = {… up the nearest documents to the output generated by the LLM as a form of citation. However, our … RAG mode, where the facts identified by the subgraph retriever are given to the LLM as …},
	publisher = {openproceedings.org},
	author = {Shirdel, M. and Rorseth, J. and Godfrey, P. and Golab, L. and Srivastava, D. and {...}},
	year = {2025},
	note = {Type: PDF},
	annote = {1 cites: https://scholar.google.com/scholar?cites=1977118286649842818\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{freire_knowledge_2024,
	title = {Knowledge sharing in manufacturing using {LLM}-powered tools: user study and model benchmarking},
	url = {https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1293084/full},
	doi = {10.3389/frai.2024.1293084},
	abstract = {… Using RAG also enables further transparency and explainability of the LLM's response. … We consider performance as the factuality, completeness, hallucinations, and conciseness …},
	journal = {Frontiers in Artificial …},
	author = {Freire, S. Kernan and Wang, C. and Foosherian, M. and {...}},
	year = {2024},
	note = {Publisher: frontiersin.org
Type: HTML},
	annote = {52 cites: https://scholar.google.com/scholar?cites=12137590192769434376\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hannah_legal_2025,
	title = {On the legal implications of {Large} {Language} {Model} answers: {A} prompt engineering approach and a view beyond by exploiting {Knowledge} {Graphs}},
	url = {https://www.sciencedirect.com/science/article/pii/S1570826824000295},
	abstract = {… Nevertheless, there are cases where the LLM recommends actions that have potential legal … the LLM answers, is also able to provide actual evidence for them by supplying citations of …},
	journal = {Journal of Web Semantics},
	author = {Hannah, G. and Sousa, R. T. and Dasoulas, I. and d'Amato, C.},
	year = {2025},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {9 cites: https://scholar.google.com/scholar?cites=14923469775773298472\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{he_chinese_2024,
	title = {Chinese simpleqa: {A} chinese factuality evaluation for large language models},
	url = {https://arxiv.org/abs/2411.07140},
	abstract = {… After that, to ensure the quality of Chinese SimpleQA, we use LLM to remove samples, … , which guides the LLM to evaluate the factual correctness of answers based on the RAG system. …},
	journal = {arXiv preprint arXiv …},
	author = {He, Y. and Li, S. and Liu, J. and Tan, Y. and Wang, W. and Huang, H. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {38 cites: https://scholar.google.com/scholar?cites=8420872629402902281\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jeong_study_2023,
	title = {A study on the implementation of generative ai services using an enterprise data-based llm application architecture},
	url = {https://arxiv.org/abs/2309.01105},
	abstract = {… , RAG informs the LLM of pertinent queries and associated reference materials in advance, mitigating hallucination … pertinent to LLM, as well as demarcates the realm of RAG that is the …},
	journal = {arXiv preprint arXiv:2309.01105},
	author = {Jeong, C.},
	year = {2023},
	note = {Publisher: arxiv.org},
	annote = {120 cites: https://scholar.google.com/scholar?cites=17577437034946074507\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bai_pistis-rag_2024,
	title = {Pistis-{RAG}: {A} {Scalable} {Cascading} {Framework} {Towards} {Trustworthy} {Retrieval}-{Augmented} {Generation}},
	url = {https://ui.adsabs.harvard.edu/abs/2024arXiv240700072B/abstract},
	abstract = {… , trust, and reliability, echoing the core principles of RAG in … RAG systems. It adheres to information retrieval principles while considering the unique business scenario captured by LLM …},
	journal = {arXiv e …},
	author = {Bai, Y. and Miao, Y. and Chen, L. and Li, D. and Ren, Y. and Xie, H. and {...}},
	year = {2024},
	note = {Publisher: ui.adsabs.harvard.edu},
	annote = {1 cites: https://scholar.google.com/scholar?cites=1554160539625499492\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{he_multi-faceted_2025,
	title = {Multi-{Faceted} {Studies} on {Data} {Poisoning} can {Advance} {LLM} {Development}},
	url = {https://arxiv.org/abs/2502.14182},
	abstract = {… applications such as Retrieval-augmented generation (RAG) and LLM agents which retrieve … We propose to explore how trust-centric data poisoning can be leveraged to defend against …},
	journal = {arXiv preprint arXiv:2502.14182},
	author = {He, P. and Xing, Y. and Xu, H. and Xiang, Z. and Tang, J.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=9520713967873276220\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_bioinformatics_2024,
	title = {Bioinformatics and biomedical informatics with {ChatGPT}: {Year} one review},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/qub2.67},
	doi = {10.1002/qub2.67},
	abstract = {… ChatGPT in bioinformatics and biomedical informatics. We also utilized backward and forward citation … This approach, known as RAG, improves ChatGPT’s reliability by sourcing facts …},
	journal = {Quantitative Biology},
	author = {Wang, J. and Cheng, Z. and Yao, Q. and Liu, L. and Xu, D. and {...}},
	year = {2024},
	note = {Publisher: Wiley Online Library},
	annote = {25 cites: https://scholar.google.com/scholar?cites=12390400818567472683\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{einy_cost-effective_2024,
	title = {Cost-{Effective} {LLM} {Utilization} for {Machine} {Learning} {Tasks} over {Tabular} {Data}},
	url = {https://dl.acm.org/doi/abs/10.1145/3665601.3669848},
	doi = {10.1145/3665601.3669848},
	abstract = {… Using a RAG LLM involves retrieval cost𝑐𝑟 (𝑀), processing cost for {\textbar}𝐷{\textbar} documents 𝑐𝑑𝑝 (𝑀, {\textbar}… To address LLM hallucinations, the iterative Data Enrichment Module verifies at each phase …},
	journal = {… Understanding and Integration of Data for …},
	author = {Einy, Y. and Milo, T. and Novgorodov, S.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=8084237541122172609\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{pu_customized_2024,
	title = {Customized retrieval augmented generation and benchmarking for {EDA} tool documentation {QA}},
	url = {https://dl.acm.org/doi/abs/10.1145/3676536.3676730},
	doi = {10.1145/3676536.3676730},
	abstract = {… During the process of RAG, the robust reasoning and … the hallucination issue and improves the reliability of LLM … tool-related questions, applying existing RAG flows for EDA tool …},
	journal = {Proceedings of the 43rd IEEE/ACM …},
	author = {Pu, Y. and He, Z. and Qiu, T. and Wu, H. and Yu, B.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {24 cites: https://scholar.google.com/scholar?cites=4521973927045761321\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ryan_enronqa_2025,
	title = {Enronqa: {Towards} personalized rag over private documents},
	url = {https://arxiv.org/abs/2505.00263},
	abstract = {… LLM training has made RAG the basis for many enterprise LLM workloads as it allows the company to augment LLM’… In our case study we explore factual memorization as an alternative …},
	journal = {arXiv preprint arXiv:2505.00263},
	author = {Ryan, M. J. and Xu, D. and Nivera, C. and Campos, D.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=14820744098017805640\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sun_r-bot_2024,
	title = {R-bot: {An} llm-based query rewrite system},
	url = {https://arxiv.org/abs/2412.01661},
	abstract = {… To address the hallucination problem of LLMs [25], we perform an offline stage to extract query … of LLMs, including LLM prompting and retrieval augmented generation (RAG), which are …},
	journal = {arXiv preprint arXiv …},
	author = {Sun, Z. and Zhou, X. and Li, G. and Yu, X. and Feng, J. and Zhang, Y.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {12 cites: https://scholar.google.com/scholar?cites=17301620609837234054\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{chen_dynamic_2024,
	title = {Dynamic supplementation of federated search results for reducing hallucinations in llms},
	url = {https://files.osf.io/v1/resources/x5vge/providers/osfstorage/66615e3565e1de503e893ab6?format=pdf\&action=download\&direct\&version=2},
	abstract = {… The use of retrieval-augmented generation (RAG) … in hallucinations by grounding responses in verifiable facts [34… inference for reducing large language model hallucinations. In: …},
	publisher = {files.osf.io},
	author = {Chen, J. and Huang, X. and Li, Y.},
	year = {2024},
	note = {Type: PDF},
	annote = {73 cites: https://scholar.google.com/scholar?cites=1886939745550837970\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hu_position_2025,
	title = {Position: {Towards} a responsible llm-empowered multi-agent systems},
	url = {https://arxiv.org/abs/2502.01714},
	abstract = {… and Large Language Modelpowered Multi-Agent Systems (LLM… and Retrieval-Augmented Generation have expanded LLM … on confidence levels and uses textual prompts to convey …},
	journal = {arXiv preprint arXiv …},
	author = {Hu, J. and Dong, Y. and Ao, S. and Li, Z. and Wang, B. and Singh, L. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=4456980999911017989\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_how_2025,
	title = {How llms react to industrial spatio-temporal data? assessing hallucination with a novel traffic incident benchmark dataset},
	url = {https://aclanthology.org/2025.naacl-industry.4/},
	abstract = {… Moreover, the predominance of English in LLM development … Generation (RAG) to further examine LLM hallucinations in … the types of hallucinations that RAG can mitigate and how it …},
	journal = {Proceedings of the …},
	author = {Li, Q. and Tan, M. and Zhao, X. and Zhang, D. and Zhang, D. and {...}},
	year = {2025},
	note = {Publisher: aclanthology.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=16954526754209095510\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{musumeci_llm_2024,
	title = {Llm based multi-agent generation of semi-structured documents from semantic templates in the public administration domain},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-60615-1_7},
	doi = {10.1007/978-3-031-60615-1_7},
	abstract = {… LLM) to retrieve relevant knowledge, showing promising potential in mitigating LLM hallucinations … However, existing RAG systems are often inadequate in answering multi-hop queries, …},
	journal = {… Conference on Human …},
	author = {Musumeci, E. and Brienza, M. and Suriani, V. and Nardi, D. and {...}},
	year = {2024},
	note = {Publisher: Springer},
	annote = {25 cites: https://scholar.google.com/scholar?cites=5664285517937280575\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sun_application_2024,
	title = {The {Application} of {Constructing} {Knowledge} {Graph} of {Oral} {Historical} {Archives} {Resources} {Based} on {LLM}-{RAG}},
	url = {https://dl.acm.org/doi/abs/10.1145/3686397.3686420},
	doi = {10.1145/3686397.3686420},
	abstract = {… It uses Large Language Model - Retrieval Augmented Generation (LLM-RAG) for knowledge extraction, and then uses a semantic model for knowledge organization and management. …},
	journal = {Proceedings of the 2024 8th International …},
	author = {Sun, Y. and Yang, W. and Liu, Y.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=17388027593482604555\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yu_scrag_2025,
	title = {{scRAG}: {Hybrid} {Retrieval}-{Augmented} {Generation} for {LLM}-based {Cross}-{Tissue} {Single}-{Cell} {Annotation}},
	url = {https://aclanthology.org/2025.findings-acl.53/},
	abstract = {… In this paper, we introduce scRAG, a novel framework that incorporates advanced LLM-based RAG techniques into cross-tissue single-cell annotation. scRAG utilizes LLMs to retrieve …},
	journal = {Findings of the …},
	author = {Yu, Z. and Zheng, C. and Chen, C. and Hua, X. S. and {...}},
	year = {2025},
	note = {Publisher: aclanthology.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=11357156214545675512\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hu_hedrarag_2025,
	title = {{HedraRAG}: {Coordinating} {LLM} {Generation} and {Database} {Retrieval} in {Heterogeneous} {RAG} {Serving}},
	url = {https://arxiv.org/abs/2507.09138},
	abstract = {… need for external knowledge integration, Retrieval-Augmented Generation (RAG) [43] has … ], while effectively reducing hallucinations [76] and better preserving data privacy [70]. Early …},
	journal = {arXiv preprint arXiv …},
	author = {Hu, Z. and Murthy, V. and Pan, Z. and Li, W. and Fang, X. and Ding, Y. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=5681936744536876255\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{omar_chatgpt_2024,
	title = {{ChatGPT} for digital pathology research},
	url = {https://www.thelancet.com/journals/landig/article/PIIS2589-7500(24)00114-6/fulltext},
	abstract = {… the performance of GPT4DFCI-RAG against the generic ChatGPT-4 model in responding to … ChatGPT-4 also showed a high rate of hallucinations, featuring papers or applications that …},
	journal = {The Lancet Digital …},
	author = {Omar, M. and Ullanat, V. and Loda, M. and Marchionni, L. and {...}},
	year = {2024},
	note = {Publisher: thelancet.com
Type: HTML},
	annote = {32 cites: https://scholar.google.com/scholar?cites=17613951834122220719\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sharifymoghaddam_chatbot_2025,
	title = {Chatbot {Arena} {Meets} {Nuggets}: {Towards} {Explanations} and {Diagnostics} in the {Evaluation} of {LLM} {Responses}},
	url = {https://arxiv.org/abs/2504.20006},
	abstract = {… the quality of RAG answers. Nuggets decompose long-form LLM-generated answers into … documents, which are then used by LLMs to generate long-form answers with citations [22…},
	journal = {arXiv preprint arXiv …},
	author = {Sharifymoghaddam, S. and Upadhyay, S. and Thakur, N. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=10367404813995406993\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yan_pdgpt_2024,
	title = {{PDGPT}: {A} large language model for acquiring phase diagram information in magnesium alloys},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mgea.77},
	doi = {10.1002/mgea.77},
	abstract = {… optimizes the LLM using the following two methods: SFT and RAG. The RAG approach … Even after adjusting ε, the LLM remained confident in providing the same incorrect answer. …},
	journal = {Materials Genome …},
	author = {Yan, Z. and Liang, H. and Wang, J. and Zhang, H. and {...}},
	year = {2024},
	note = {Publisher: Wiley Online Library},
	annote = {6 cites: https://scholar.google.com/scholar?cites=2577794528564893711\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yang_multimodal_2025,
	title = {Multimodal large language model for wheat breeding: a new exploration of smart breeding},
	url = {https://www.sciencedirect.com/science/article/pii/S0924271625001339},
	abstract = {… fine-tuning (SFT), retrieval-augmented generation (RAG), and … the combination of SFT, RAG, and RLHF technologies can … generated answer, and reduce hallucinations and biases. The …},
	journal = {ISPRS Journal of …},
	author = {Yang, G. and Li, Y. and He, Y. and Zhou, Z. and Ye, L. and Fang, H. and Luo, Y. and {...}},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {3 cites: https://scholar.google.com/scholar?cites=18120999532752613367\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{freund_enriching_2024,
	title = {Enriching {RDF} data with {LLM} based named entity recognition and linking on embedded natural language annotations},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-81221-7_8},
	doi = {10.1007/978-3-031-81221-7_8},
	abstract = {… additional input to the LLM. Specifically, we inject the additional factual knowledge from the … , which integrates NER, RAG-based entity linking, and LLM-based disambiguation with self-…},
	journal = {… Knowledge Graph and …},
	author = {Freund, M. and Dorsch, R. and Schmid, S. and Wehr, T. and {...}},
	year = {2024},
	note = {Publisher: Springer},
	annote = {3 cites: https://scholar.google.com/scholar?cites=14720038965385366682\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhou_cogmg_2024,
	title = {Cogmg: {Collaborative} augmentation between large language model and knowledge graph},
	url = {https://arxiv.org/abs/2406.17231},
	abstract = {… hallucinations and factually inaccurate content. Querying knowledge graphs to reduce hallucinations in LLM … preference alignment are familiar with RAG, we utilize prompt engineering …},
	journal = {arXiv preprint arXiv:2406.17231},
	author = {Zhou, T. and Chen, Y. and Liu, K. and Zhao, J.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {12 cites: https://scholar.google.com/scholar?cites=11459734557791533972\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{anaroua_ai-driven_2025,
	title = {{AI}-driven formative assessment and adaptive learning in data-science education: {Evaluating} an {LLM}-powered virtual teaching assistant},
	url = {https://arxiv.org/abs/2509.20369},
	abstract = {… The paper concludes with implementation lessons and a roadmap (RAG integration, hallucination mitigation, and LTI 1.3/OpenID Connect) to guide multi-course evaluations and …},
	journal = {arXiv preprint arXiv:2509.20369},
	author = {Anaroua, F. I. and Li, Q. and Tang, Y. and Liu, H. P.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=12962038995635268292\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_chineseecomqa_2025,
	title = {Chineseecomqa: {A} scalable e-commerce concept evaluation benchmark for large language models},
	url = {https://dl.acm.org/doi/abs/10.1145/3711896.3737374},
	doi = {10.1145/3711896.3737374},
	abstract = {… of LLM validation, Retrieval-Augmented Generation (RAG) … [23] A perfectly calibrated model should exhibit confidence … , we prompt the LLM to generate confidence scores (ranging 0 …},
	journal = {Proceedings of the 31st …},
	author = {Chen, H. and Lv, K. and Hu, C. and Li, Y. and Yuan, Y. and He, Y. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=17512295077856864424\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xu_hlsrewriter_2025,
	title = {{HLSRewriter}: {Efficient} {Refactoring} and {Optimization} of {C}/{C}++ {Code} with {LLMs} for {High}-{Level} {Synthesis}},
	url = {https://dl.acm.org/doi/abs/10.1145/3749986},
	doi = {10.1145/3749986},
	abstract = {… To mitigate LLM hallucinations, a repair library containing … a Retrieval-Augmented Generation (RAG) paradigm to guide the … the LLM, we incorporate a Retrieval-Augmented Generation (…},
	journal = {ACM Transactions on …},
	author = {Xu, K. and Zhang, G. L. and Yin, X. and Zhuo, C. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=14072155719603832777\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yue_democratizing_2023,
	title = {Democratizing financial knowledge with {ChatGPT} by {OpenAI}: {Unleashing} the {Power} of {Technology}},
	url = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4346152},
	abstract = {… Within the RAG framework, the LLM model is allowed to reference external data during … significant issues with AI hallucinations. We recognize that LLM hallucinations are likely to …},
	journal = {Available at SSRN 4346152},
	author = {Yue, T. and Au, D. and Au, C. C. and Iu, K. Y.},
	year = {2023},
	note = {Publisher: papers.ssrn.com},
	annote = {81 cites: https://scholar.google.com/scholar?cites=3860270407022401100\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{matsumoto_escargot_2025,
	title = {{ESCARGOT}: an {AI} agent leveraging large language models, dynamic graph of thoughts, and biomedical knowledge graphs for enhanced reasoning},
	url = {https://academic.oup.com/bioinformatics/article-pdf/doi/10.1093/bioinformatics/btaf031/61561980/btaf031.pdf},
	doi = {10.1093/bioinformatics/btaf031/61561980/btaf031},
	abstract = {… hallucinations and struggle with integrating external knowledge effectively. While Retrieval-Augmented Generation (RAG… to the black-box nature of LLM-only or RAG-based …},
	journal = {…},
	author = {Matsumoto, N. and Choi, H. and Moran, J. and Hernandez, M. E. and {...}},
	year = {2025},
	note = {Publisher: academic.oup.com
Type: PDF},
	annote = {17 cites: https://scholar.google.com/scholar?cites=11981644313365899252\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gubanov_cancerkg_2024,
	title = {Cancerkg. org-a web-scale, interactive, verifiable knowledge graph-llm hybrid for assisting with optimal cancer treatment and care},
	url = {https://dl.acm.org/doi/abs/10.1145/3627673.3680094},
	doi = {10.1145/3627673.3680094},
	abstract = {… the user needs better than just an LLM, KG or a search-engine in … RAG-based hybrid scales to thousands of data sources, “understands” multi-modal knowledge, does not hallucinate, …},
	journal = {Proceedings of the 33rd ACM …},
	author = {Gubanov, M. and Pyayt, A. and Karolak, A.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=7910236128733794731\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_human-llm_2025,
	title = {Human-llm collaboration in generative design for customization},
	url = {https://www.sciencedirect.com/science/article/pii/S0278612525000731},
	abstract = {… Against the background, this paper explores the potential of LLM in redefining GDfC. Based … three human-LLM collaboration schemes to demonstrate the potential roles of LLM in GDfC. …},
	journal = {Journal of Manufacturing Systems},
	author = {Wang, X. and Jiang, Z. and Xiong, Y. and Liu, A.},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {5 cites: https://scholar.google.com/scholar?cites=6073823879020529608\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{taiwo_generative_2024,
	title = {Generative {AI} in the {Construction} {Industry}: {A} {State}-of-the-art {Analysis}},
	url = {https://arxiv.org/abs/2402.09939},
	abstract = {… A retrievalaugmented generation (RAG) system was implemented to improve the base LLM further. This mitigated hallucinated text by grounding outputs in relevant dataset …},
	journal = {arXiv preprint arXiv …},
	author = {Taiwo, R. and Bello, I. T. and Abdulai, S. F. and Yussif, A. M. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {51 cites: https://scholar.google.com/scholar?cites=2632252777406362330\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sharma_decoding_2024,
	title = {Decoding {BACnet} packets: {A} large language model approach for packet interpretation},
	url = {https://arxiv.org/abs/2407.15428},
	abstract = {… ’s outputs in factual information retrieved from trusted sources [Nightfall]. … RAG (Method 1) In summarization generation without RAG, we pass the processed packet content to the LLM …},
	journal = {arXiv preprint arXiv …},
	author = {Sharma, R. and Okada, H. and Oba, T. and Subramanian, K. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=6852922242899402479\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{miao_how_2024,
	title = {How to improve {ChatGPT} performance for nephrologists: a technique guide},
	url = {https://link.springer.com/article/10.1007/s40620-024-01974-z},
	doi = {10.1007/s40620-024-01974-z},
	abstract = {… Such hallucinations compromise the dependability of large language model outputs, casting … impact of both chain-of-thought and retrieval-augmented generation methods on enhancing …},
	journal = {Journal of …},
	author = {Miao, J. and Thongprayoon, C. and Craici, I. M. and {...}},
	year = {2024},
	note = {Publisher: Springer},
	annote = {21 cites: https://scholar.google.com/scholar?cites=16133210476955112718\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{doyle_if_2025,
	title = {If {You} {Give} an {LLM} a {Legal} {Practice} {Guide}},
	url = {https://dl.acm.org/doi/abs/10.1145/3709025.3712220},
	doi = {10.1145/3709025.3712220},
	abstract = {… RAG pipelines are most successful when retrieving factual information that an LLM can … -oriented question of how well RAG improves performance on an LLM task, along with the …},
	journal = {Proceedings of the 2025 Symposium on Computer …},
	author = {Doyle, C. and Tucker, A. D.},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=3106940811863493654\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{_rag_2023,
	title = {{RAG} 기반 랭체인을 이용한 생성형 {AI} 챗봇 구현},
	url = {https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE11652073},
	abstract = {… LLM is widely used to support chatbots. However, LLM is susceptible to hallucinations that … framework, a type of RAG, to solve the hallucination problem. The proposed architecture uses …},
	journal = {Proceedings of KIIT Conference},
	author = {{조찬영} and {강성준} and {정현준}},
	year = {2023},
	note = {Publisher: dbpia.co.kr},
	annote = {5 cites: https://scholar.google.com/scholar?cites=15422384383506635017\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yang_transforming_2025,
	title = {Transforming hematological research documentation with large language models: an approach to scientific writing and data analysis},
	url = {https://link.springer.com/article/10.1007/s44313-025-00062-w},
	doi = {10.1007/s44313-025-00062-w},
	abstract = {… engineering, Retrieval-Augmented Generation (RAG) enhances LLM … RAG systems dynamically retrieve information from verified … To reduce hallucinations and ensure a reliable LLM …},
	journal = {Blood research},
	author = {Yang, J. J. and Hwang, S. H.},
	year = {2025},
	note = {Publisher: Springer
Type: HTML},
	annote = {9 cites: https://scholar.google.com/scholar?cites=7332776272436576366\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{andersson_bridging_2024,
	title = {Bridging the {Skills} {Gap}: {Applying} an {LLM} and {RAG} {Architecture} for {Recommending} {Competence} {Development} in the {IT} {JobMarket}},
	url = {https://www.diva-portal.org/smash/record.jsf?pid=diva2:1883256},
	abstract = {… ) is an architecture that strengthens the capabilities of the LLM. It … In this thesis, the notion of using an LLM and the RAG … the general trust towards and evaluation of AI and RAG in …},
	publisher = {diva-portal.org},
	author = {Andersson, M. and Enqvist, T.},
	year = {2024},
	annote = {1 cites: https://scholar.google.com/scholar?cites=6596200144262751392\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kang_nadine_2024,
	title = {Nadine: an {LLM}-driven intelligent social robot with affective capabilities and human-like memory},
	url = {https://arxiv.org/abs/2405.20189},
	abstract = {… This approach aims to reduce LLM hallucinations and incorporate data from external … In this section, we demonstrate the RAG system adopted in our interaction module. The RAG …},
	journal = {arXiv preprint arXiv …},
	author = {Kang, H. and Moussa, M. B. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {12 cites: https://scholar.google.com/scholar?cites=11318018451126431117\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cao_video_2025,
	title = {Video simpleqa: {Towards} factuality evaluation in large video language models},
	url = {https://arxiv.org/abs/2503.18923},
	abstract = {… To further enhance the reliability, we train expert annotators to refine the LLM-generated QA … RAG yields significant gains at the cost of inference efficiency: We explore RAG to facilitate …},
	journal = {arXiv preprint arXiv …},
	author = {Cao, M. and Hu, P. and Wang, Y. and Gu, J. and Tang, H. and Zhao, H. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=524794470609432985\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kirshner_talking_2025,
	title = {Talking terms: {Agent} information in {LLM} supply chain bargaining},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/deci.70010},
	doi = {10.1111/deci.70010},
	abstract = {… show that tailored retrieval-augmented generation (RAG) … with LLM agents, (3) highlight the effectiveness of tailoring RAG … , LLM agents could be given the ability to disclose credible or …},
	journal = {Decision Sciences},
	author = {Kirshner, S. N. and Pan, Y. and Wu, J. X. and Gould, A.},
	year = {2025},
	note = {Publisher: Wiley Online Library},
	annote = {2 cites: https://scholar.google.com/scholar?cites=576043738257212224\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{fossi_swiftdossier_2024,
	title = {Swiftdossier: {Tailored} automatic dossier for drug discovery with llms and agents},
	url = {https://arxiv.org/abs/2409.15817},
	abstract = {… of an advanced RAG system can help the LLM to … citations to allow us to track back which sources are used for each section and slide. For example, when the LLM is using the RAG, the …},
	journal = {arXiv preprint arXiv …},
	author = {Fossi, G. and Boulaimen, Y. and Outemzabet, L. and Jeanray, N. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=15826120815436256729\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tavasoli_responsible_2025,
	title = {Responsible innovation: {A} strategic framework for financial {LLM} integration},
	url = {https://arxiv.org/abs/2504.02165},
	abstract = {… deploy RAG for up-to-date references while using parameter-efficient tuning to embed … could opt for a proprietary model supplemented by RAG for continuous factual grounding. …},
	journal = {arXiv preprint arXiv:2504.02165},
	author = {Tavasoli, A. and Sharbaf, M. and Madani, S. M.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=8185862829913414122\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cinquin_steering_2025,
	title = {Steering veridical large language model analyses by correcting and enriching generated database queries: first steps toward {ChatGPT} bioinformatics},
	url = {https://academic.oup.com/bib/article-abstract/26/1/bbaf045/8002976},
	abstract = {… hallucination lead ChatGPT to err, as do incorrect sequence manipulations. To address this, we propose a system basing LLM … It may gain from explicit control of the RAG process, for …},
	journal = {Briefings in Bioinformatics},
	author = {Cinquin, O.},
	year = {2025},
	note = {Publisher: academic.oup.com},
	annote = {2 cites: https://scholar.google.com/scholar?cites=2730972510524844795\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{huang_understanding_2024,
	title = {Understanding the planning of {LLM} agents: {A} survey},
	url = {https://www.researchgate.net/profile/Xu-Huang-37/publication/380756642_Understanding_the_planning_of_LLM_agents_A_survey/links/664d5a9dbc86444c72f64b6f/Understanding-the-planning-of-LLM-agents-A-survey.pdf},
	abstract = {… trajectories may lead to LLM experiencing hallucinations, deviating from the … LLM-Agents, there are currently two major approaches to enhance planning abilities through memory: RAG…},
	journal = {arXiv preprint arXiv …},
	author = {Huang, X. and Liu, W. and Chen, X. and Wang, X. and Wang, H. and {...}},
	year = {2024},
	note = {Publisher: researchgate.net
Type: PDF},
	annote = {308 cites: https://scholar.google.com/scholar?cites=5384087220746207566\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_agentpoison_2024,
	title = {Agentpoison: {Red}-teaming llm agents via poisoning memory or knowledge bases},
	url = {https://proceedings.neurips.cc/paper_files/paper/2024/hash/eb113910e9c3f6242541c1652e30dfd6-Abstract-Conference.html},
	abstract = {… We consider LLM agents with a RAG mechanism based on corpus retrieval. For a user query q, we retrieve knowledge or past experiences from a memory database D, containing a set …},
	journal = {Advances in Neural …},
	author = {Chen, Z. and Xiang, Z. and Xiao, C. and Song, D. and {...}},
	year = {2024},
	note = {Publisher: proceedings.neurips.cc},
	annote = {144 cites: https://scholar.google.com/scholar?cites=11160490014772190558\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yin_chathpc_2024,
	title = {chathpc: {Empowering} hpc users with large language models},
	url = {https://www.osti.gov/biblio/2538074},
	abstract = {… technical complexities and gaps, LLM trustworthiness, safety, … Retrieval augmented generation (RAG) has emerged as a … hybrid deployment integrates RAG with LLM generation, …},
	journal = {Journal of …},
	author = {Yin, J. and Hines, J. and Herron, E. and Ghosal, T. and Liu, H. and {...}},
	year = {2024},
	note = {Publisher: osti.gov},
	annote = {10 cites: https://scholar.google.com/scholar?cites=12720147132289525705\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{miroyan_analyzing_2025,
	title = {Analyzing {Pedagogical} {Quality} and {Efficiency} of {LLM} {Responses} with {TA} {Feedback} to {Live} {Student} {Questions}},
	url = {https://dl.acm.org/doi/abs/10.1145/3641554.3701965},
	doi = {10.1145/3641554.3701965},
	abstract = {… LLM assistant, Edison, a GPT-4-based method that leverages Optical Character Recognition (OCR), retrieval-augmented generation (RAG… responses more relevant and factual. Overall, …},
	journal = {Proceedings of the 56th …},
	author = {Miroyan, M. and Mitra, C. and Jain, R. and Ranade, G. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=3576615794786994908\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_plantgpt_2025,
	title = {{PlantGPT}: {An} {Arabidopsis}‐{Based} {Intelligent} {Agent} that {Answers} {Questions} about {Plant} {Functional} {Genomics}},
	url = {https://advanced.onlinelibrary.wiley.com/doi/abs/10.1002/advs.202503926},
	doi = {10.1002/advs.202503926},
	abstract = {… To minimize such hallucinations and produce high-quality knowledge-based … RAG+LLM-based tool PlantGPT can achieve better responses than Claude Opus with a relatively low RAG …},
	journal = {Advanced …},
	author = {Zhang, R. and Wang, Y. and Yang, W. and Wen, J. and Liu, W. and {...}},
	year = {2025},
	note = {Publisher: Wiley Online Library},
	annote = {10 cites: https://scholar.google.com/scholar?cites=1749284489337554009\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{khurana_why_2024,
	title = {Why and when llm-based assistants can go wrong: {Investigating} the effectiveness of prompt-based interactions for software help-seeking},
	url = {https://dl.acm.org/doi/abs/10.1145/3640543.3645200},
	doi = {10.1145/3640543.3645200},
	abstract = {… is known as Retrieval Augmented Generation (RAG) Vector search … For the search approach used in RAG, we tried different … that the LLM outputs were credible: “... it [LLM] gave me what …},
	journal = {Proceedings of the 29th …},
	author = {Khurana, A. and Subramonyam, H. and Chilana, P. K.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {56 cites: https://scholar.google.com/scholar?cites=14845361003667532258\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{liang_learning_2024,
	title = {Learning to trust your feelings: {Leveraging} self-awareness in llms for hallucination mitigation},
	url = {https://arxiv.org/abs/2401.15449},
	abstract = {… of fact-conflicting hallucination, where LLM produces fluent … hallucination mitigation methods, such as retrieval augmentation generation (RAG), address fact-conflict hallucination of LLM …},
	journal = {arXiv preprint arXiv:2401.15449},
	author = {Liang, Y. and Song, Z. and Wang, H. and Zhang, J.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {47 cites: https://scholar.google.com/scholar?cites=10520548047958338813\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tan_chatgpt_2025,
	title = {{ChatGPT} performance in assessing musculoskeletal {MRI} scan appropriateness based on {ACR} appropriateness criteria},
	url = {https://www.nature.com/articles/s41598-025-88925-1},
	abstract = {… cLLM, and a standard LLM without RAG. We also aimed to compare LLM performance against … , which provides better transparency and confidence in the LLM output. Furthermore, the …},
	journal = {Scientific Reports},
	author = {Tan, J. R. and Lim, D. Y. Z. and Le, Q. and Karande, G. Y. and Chan, L. P. and {...}},
	year = {2025},
	note = {Publisher: nature.com
Type: HTML},
	annote = {5 cites: https://scholar.google.com/scholar?cites=13032207481929904463\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hu_patchwork_2025,
	title = {Patchwork: {A} {Unified} {Framework} for {RAG} {Serving}},
	url = {https://arxiv.org/abs/2505.07833},
	abstract = {… As illustrated, a RAG system supplements an LLM with a knowledge base—often an … both the factual accuracy and generation quality of LLM outputs. Moreover, RAG systems offer a …},
	journal = {arXiv preprint arXiv:2505.07833},
	author = {Hu, B. and Pabon, L. and Agarwal, S. and Akella, A.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=9701717841598226134\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yao_cacheblend_2025,
	title = {{CacheBlend}: {Fast} large language model serving for {RAG} with cached knowledge fusion},
	url = {https://dl.acm.org/doi/abs/10.1145/3689031.3696098},
	doi = {10.1145/3689031.3696098},
	abstract = {… LLM inputs, one can pre-compute the KV cache of a text and re-use the KV cache when the context is reused as the prefix of another LLM … : when an LLM input contains multiple text …},
	journal = {Proceedings of the …},
	author = {Yao, J. and Li, H. and Liu, Y. and Ray, S. and Cheng, Y. and Zhang, Q. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {20 cites: https://scholar.google.com/scholar?cites=4523108450804406413\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{tomkou_bridging_2025,
	title = {Bridging industrial expertise and xr with llm-powered conversational agents},
	url = {https://arxiv.org/abs/2504.05527},
	abstract = {… Building upon this existing research, our work integrates RAG-enhanced LLM conversational … from LLM Chat Engine to a user query requesting assistance in troubleshooting citing the …},
	journal = {arXiv preprint arXiv …},
	author = {Tomkou, D. and Fatouros, G. and Andreou, A. and Makridis, G. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=665950199627025975\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{riedler_beyond_2024,
	title = {Beyond text: {Optimizing} rag with multimodal inputs for industrial applications},
	url = {https://arxiv.org/abs/2410.21943},
	abstract = {… LLM-as-a-Judge approach. Our results reveal that multimodal RAG can outperform single-modality RAG … they share common LLM limitations, including inaccuracies, hallucinations, and …},
	journal = {arXiv preprint arXiv:2410.21943},
	author = {Riedler, M. and Langer, S.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {34 cites: https://scholar.google.com/scholar?cites=15060240828719064797\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gregory_chatgpt_2024,
	title = {{ChatGPT}: {A} canary in the coal mine or a parrot in the echo chamber? {Detecting} fraud with {LLM}: {The} case of {FTX}},
	url = {https://www.sciencedirect.com/science/article/pii/S1544612324013783},
	abstract = {… known as Retrieval Augmented Generation (RAG)… Retrieval Augmented Generation (RAG) techniques generate more “specific, diverse, and factual language than a state-of-the-art LLM …},
	journal = {Finance Research Letters},
	author = {Gregory, G. and Vito, L.},
	year = {2024},
	note = {Publisher: Elsevier},
	annote = {5 cites: https://scholar.google.com/scholar?cites=11999482375757700101\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xu_automated_2024,
	title = {Automated c/c++ program repair for high-level synthesis via large language models},
	url = {https://dl.acm.org/doi/abs/10.1145/3670474.3685953},
	doi = {10.1145/3670474.3685953},
	abstract = {… To mitigate the hallucinations in LLMs and enhance the … Employing RAG to the LLM for repairing HLS incompatibility … of using LLM, we compared the cost of the proposed joint LLM-…},
	journal = {Proceedings of the 2024 …},
	author = {Xu, K. and Zhang, G. L. and Yin, X. and Zhuo, C. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {40 cites: https://scholar.google.com/scholar?cites=9448834807240656514\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{nikolakopoulos_large_2024,
	title = {Large language models in modern forensic investigations: {Harnessing} the power of generative artificial intelligence in crime resolution and suspect identification},
	url = {https://ieeexplore.ieee.org/abstract/document/10654427/},
	abstract = {… of a Retrieval Augmented Generation (RAG) LLM, trained with … Suspect recommendation with confidence level estimation: … confidence level, feeding them to the RAG LLM for the …},
	journal = {… \& Education (EEITE)},
	author = {Nikolakopoulos, A. and Evangelatos, S. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {13 cites: https://scholar.google.com/scholar?cites=17349259121354705644\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wen_perception_2024,
	title = {Perception of knowledge boundary for large language models through semi-open-ended question answering},
	url = {https://proceedings.neurips.cc/paper_files/paper/2024/hash/a1e0d6fa0c30b7d4f75dd9c7ed6189f2-Abstract-Conference.html},
	abstract = {… the results from the RAG-based evaluation and LLM self-… the knowledge boundary of the target LLM. Following our method, … that advanced LLM (ie GPT-4) is easy to hallucinate on semi-…},
	journal = {Advances in …},
	author = {Wen, Z. and Tian, Z. and Jian, Z. and Huang, Z. and Ke, P. and {...}},
	year = {2024},
	note = {Publisher: proceedings.neurips.cc},
	annote = {16 cites: https://scholar.google.com/scholar?cites=206660155729022009\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xu_does_2025,
	title = {Does context matter? contextualjudgebench for evaluating llm-based judges in contextual settings},
	url = {https://arxiv.org/abs/2503.15620},
	abstract = {… survey specifically cite trust loss due to hallucinations as a top concern. Hallucinations are … For QA-Feedback, we use approach H to create preference pairs from RAG responses …},
	journal = {arXiv preprint arXiv:2503.15620},
	author = {Xu, A. and Bansal, S. and Ming, Y. and Yavuz, S. and Joty, S.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=4694277635380098830\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhu_emerge_2024-1,
	title = {Emerge: {Integrating} rag for improved multimodal ehr predictive modeling},
	url = {https://www.researchgate.net/profile/Zixiang-Wang-13/publication/381126633_EMERGE_Integrating_RAG_for_Improved_Multimodal_EHR_Predictive_Modeling/links/6668192da54c5f0b945da986/EMERGE-Integrating-RAG-for-Improved-Multimodal-EHR-Predictive-Modeling.pdf},
	abstract = {… Entities Refinement: Considering the hallucination issue associated with LLM, we design a … in the original text; secondly, we leverage LLM to filter entities not in disease type; and finally, …},
	journal = {arXiv preprint arXiv …},
	author = {Zhu, Y. and Ren, C. and Wang, Z. and Zheng, X. and Xie, S. and {...}},
	year = {2024},
	note = {Publisher: researchgate.net
Type: PDF},
	annote = {16 cites: https://scholar.google.com/scholar?cites=13406028020657304376\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yue_survey_2025,
	title = {A survey of large language model agents for question answering},
	url = {https://arxiv.org/abs/2503.19213},
	abstract = {… in retrieval-augmented generation systems is determining when to trust the LLM’s internal knowledge versus relying on external documents. The critical LLM in SelfRAG addresses this …},
	journal = {arXiv preprint arXiv:2503.19213},
	author = {Yue, M.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {19 cites: https://scholar.google.com/scholar?cites=14620262647154052358\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{razafinirina_pedagogical_2024,
	title = {Pedagogical alignment of large language models (llm) for personalized learning: a survey, trends and challenges},
	journal = {Journal of …},
	author = {Razafinirina, M. A. and Dimbisoa, W. G. and {...}},
	year = {2024},
	note = {Publisher: Scientific Research Publishing
Type: CITATION},
	annote = {40 cites: https://scholar.google.com/scholar?cites=8018640794599225262\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{rorseth_rage_2024,
	title = {{RAGE} against the machine: {Retrieval}-augmented {LLM} explanations},
	url = {https://ieeexplore.ieee.org/abstract/document/10598017/},
	abstract = {… reducing their tendency to hallucinate plausible yet incorrect … tool designed to enable RAG Explainability for LLMs.Our tool … RAG, exposing the in-context learning behaviors of the LLM. …},
	journal = {2024 IEEE 40th …},
	author = {Rorseth, J. and Godfrey, P. and Golab, L. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=366857065552466891\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{arslan_sustainable_2024-1,
	title = {Sustainable {Energy} {Decision}-{Making} {With} an {RAG}-{LLM} {System}},
	url = {https://ieeexplore.ieee.org/abstract/document/10836639/},
	abstract = {… This section starts by describing the process of creating a dataset aimed at enhancing RAG-LLM-based IS, developed for the Energy sector to serve as an Energy QA Assistant. The …},
	journal = {… International Conference on …},
	author = {Arslan, M. and Munawar, S. and Sibilla, M.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=8298703199496940220\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kang_nadine_2024-1,
	title = {Nadine: {A} large language model‐driven intelligent social robot with affective capabilities and human‐like memory},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cav.2290},
	doi = {10.1002/cav.2290},
	abstract = {… This approach aims to reduce LLM hallucinations and incorporate data from external … In this section, we demonstrate the RAG system adopted in our interaction module. The RAG …},
	journal = {Computer Animation and …},
	author = {Kang, H. and Moussa, M. Ben and {...}},
	year = {2024},
	note = {Publisher: Wiley Online Library},
	annote = {12 cites: https://scholar.google.com/scholar?cites=12015710115269132747\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{an_vitality_2024,
	title = {Vitality 2: {Reviewing} academic literature using large language models},
	url = {https://arxiv.org/abs/2408.13450},
	abstract = {… uses a Large Language Model or LLM-… RAG mitigates LLMs hallucinations by providing additional contextual information. In future work, we can further reduce hallucinations in RAG by …},
	journal = {arXiv preprint arXiv:2408.13450},
	author = {An, H. and Narechania, A. and Wall, E. and Xu, K.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {12 cites: https://scholar.google.com/scholar?cites=17020714871491877576\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{desrochers_reducing_2024,
	title = {Reducing hallucinations in large language models through contextual position encoding},
	url = {https://files.osf.io/v1/resources/exjqb_v1/providers/osfstorage/665921bd65e1de48d5893f4d?action=download\&direct\&version=2},
	abstract = {… to lower hallucination rates [16], [17]. Retrieval-augmented generation (RAG) techniques … Mistral Large, a state-of-the-art large language model, was chosen for this study due to its …},
	publisher = {files.osf.io},
	author = {Desrochers, S. and Wilson, J. and Beauchesne, M.},
	year = {2024},
	note = {Type: PDF},
	annote = {81 cites: https://scholar.google.com/scholar?cites=8956484354427513659\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{fu_encchain_2024,
	title = {{EncChain}: {Enhancing} {Large} {Language} {Model} {Applications} with {Advanced} {Privacy} {Preservation} {Techniques}},
	url = {https://dl.acm.org/doi/abs/10.14778/3685800.3685888},
	doi = {10.14778/3685800.3685888},
	abstract = {… Remote Attestation for Enhanced Trust: EncChain enables … the deployed LLM, providing users with additional confidence in the … privacy attributes in LLM applications using RAG-based …},
	journal = {Proceedings of the VLDB …},
	author = {Fu, Z. and Sha, M. and Li, Y. and Li, H. and Ma, Y. and Wang, S. and Li, F.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=12987085170664405755\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_generative_2024,
	title = {Generative {AI} in medicine and healthcare: moving beyond the 'peak of inflated expectations'},
	url = {https://www.mdpi.com/1999-5903/16/12/462},
	abstract = {… LLM hallucinations, to mitigate the high costs and time associated with a completely manual review of LLM… NVIDIA’s ‘Chat with RTX’ is a free tool for building a custom LLM using a RAG …},
	journal = {Future Internet},
	author = {Zhang, P. and Shi, J. and Boulos, MN Kamel},
	year = {2024},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {16 cites: https://scholar.google.com/scholar?cites=18000879698894657897\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sun_pankb_2025,
	title = {{PanKB}: {An} interactive microbial pangenome knowledgebase for research, biotechnological innovation, and knowledge mining},
	url = {https://academic.oup.com/nar/article-abstract/53/D1/D806/7906839},
	abstract = {… hallucinations (40–42). Modern databases can benefit from the integration of a RAG-LLM … -access pangenomics articles and integrates a RAG-enhanced LLM interface (AI Assistant). …},
	journal = {Nucleic Acids …},
	author = {Sun, B. and Pashkova, L. and Pieters, P. A. and Harke, A. S. and {...}},
	year = {2025},
	note = {Publisher: academic.oup.com},
	annote = {9 cites: https://scholar.google.com/scholar?cites=4003758939693392233\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bilal_onrl-rag_2025,
	title = {Onrl-rag: {Real}-time personalized mental health dialogue system},
	url = {https://arxiv.org/abs/2504.02894},
	abstract = {… While RAG offers the correct information, it may not best … -based Retrieval-Augmented Generation (OnRL-RAG) system … compared to standard RAG and simple LLM via GPT-4o, GPT-4o-…},
	journal = {arXiv preprint arXiv:2504.02894},
	author = {Bilal, A. and Lin, B.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=14310460660493698643\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{basit_pennylang_2025,
	title = {Pennylang: {Pioneering} llm-based quantum code generation with a novel pennylane-centric dataset},
	url = {https://arxiv.org/abs/2503.02497},
	abstract = {… curated to train/fine-tune LLM-based quantum code assistance. Our key … LLM training efficiency; and (3) a thorough evaluation, based on a Retrieval-Augmented Generation (RAG) …},
	journal = {arXiv preprint arXiv …},
	author = {Basit, A. and Innan, N. and Asif, M. H. and Shao, M. and Kashif, M. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=14511295459869059175\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{odubola_ai_2025,
	title = {{AI} in {Social} {Good}: {LLM} {Powered} {Interventions} in {Crisis} {Management} and {Disaster} {Response}},
	url = {https://www.researchgate.net/profile/Oluwatimilehin-Odubola/publication/389525988_AI_in_Social_Good_LLM_powered_Interventions_in_Crisis_Management_and_Disaster_Response/links/67ddb99e35f7044c924f6afe/AI-in-Social-Good-LLM-powered-Interventions-in-Crisis-Management-and-Disaster-Response.pdf},
	abstract = {… retrieval-augmented generation (RAG) for flood disaster reporting has also been explored, with studies demonstrating that LLM… databases, improving factual accuracy and reducing the …},
	journal = {Journal of Artificial …},
	author = {Odubola, O. and Adeyemi, T. S. and Olajuwon, O. O. and {...}},
	year = {2025},
	note = {Publisher: researchgate.net
Type: PDF},
	annote = {7 cites: https://scholar.google.com/scholar?cites=16824960358129746222\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wu_perspectives_2025,
	title = {Perspectives: {LLM} agents reshaping the foundation of geotechnical problem-solving},
	url = {https://www.sciencedirect.com/science/article/pii/S3050483X25000358},
	abstract = {This paper explores the transformative potential of Large Language Model (LLM)-based agentic artificial intelligence (AI) in addressing longstanding challenges in geotechnical …},
	journal = {Geodata and AI},
	author = {Wu, S. and Shi, C. and Leung, A. and Otake, Y. and Konishi, C. and Zhou, M. and {...}},
	year = {2025},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {1 cites: https://scholar.google.com/scholar?cites=16190897137189685383\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{aksoy_architecting_2024,
	title = {Architecting and {Evaluating} a {RAG} based {Question} {Answering} {System} for {SQuAD} {Dataset}},
	url = {https://www.researchgate.net/profile/Yeliz-Karaca/publication/382079038_Demystifying_Fractional_Order_Chaotic_Respiratory_Disease_System_with_XAI/links/668c9a85c1cf0d77ffc38d60/Demystifying-Fractional-Order-Chaotic-Respiratory-Disease-System-with-XAI.pdf#page=214},
	abstract = {… , and it was observed that LLM did not create hallucinations when a correct" prompt" was … LLM was observed to answer questions not included in the dataset and produce hallucinations…},
	journal = {ICAMƩ'24},
	author = {Aksoy, N. and Güven, Z. A. and Ünalır, M. O.},
	year = {2024},
	note = {Publisher: researchgate.net
Type: PDF},
	annote = {2 cites: https://scholar.google.com/scholar?cites=11890033790756668102\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhao_language_2025,
	title = {Language models are few-shot graders},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-98459-4_1},
	doi = {10.1007/978-3-031-98459-4_1},
	abstract = {… Our new LLM-based ASAG pipeline achieves better … We employ one of two selection strategies: Random or RAG. The … To mitigate the risk of LLM hallucination, such as inventing new …},
	journal = {International Conference on Artificial …},
	author = {Zhao, C. and Silva, M. and Poulsen, S.},
	year = {2025},
	note = {Publisher: Springer},
	annote = {6 cites: https://scholar.google.com/scholar?cites=4473598404582817726\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{rothman__2024,
	title = {… for {Natural} {Language} {Processing} and {Computer} {Vision}: {Explore} {Generative} {AI} and {Large} {Language} {Models} with {Hugging} {Face}, {ChatGPT}, {GPT}-{4V}, and …},
	url = {https://books.google.com/books?hl=en\&lr=\&id=q9P3EAAAQBAJ\&oi=fnd\&pg=PP1\&dq=%22retrieval+augmented+generation%22%7C%22rag%22+%22large+language+model%22%7C%22llm%22%7C%22chatgpt%22+trust%7Cconfidence%7Ccredibility%7Challucination%7Cfactuality%7Ccitation\&ots=-g2PrskpL0\&sig=pnxifQa6ht_TYS3vx4v8LABKL9U},
	abstract = {… I want to thank the corporations that trusted me from the start to deliver artificial intelligence … Retrieval Augmented Generation (RAG). We will implement an example of automated RAG …},
	publisher = {books.google.com},
	author = {Rothman, D.},
	year = {2024},
	note = {Type: BOOK},
	annote = {30 cites: https://scholar.google.com/scholar?cites=3119231595448292551\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bui_rambo_2024,
	title = {Rambo: {Enhancing} rag-based repository-level method body completion},
	url = {https://arxiv.org/abs/2409.15204},
	abstract = {… However, the employed code LLM may hallucinate code, … To mitigate code LLM hallucination, after analyzing, RAMBO … Code LLM’s Size: We studied the effect of code LLM sizes on …},
	journal = {arXiv preprint arXiv …},
	author = {Bui, T. D. and Luu-Van, D. T. and Nguyen, T. P. and Nguyen, T. T. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=13513089980820474198\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{bouvard_derby_2024,
	title = {Derby {LLM}: Évaluation comparative des approches {RAG} et fine-tuning},
	url = {https://hal.science/hal-04638460/},
	abstract = {… le processus expérimental mis en place pour comparer la RAG et le fine-tuning d’un LLM. … La fidélité peut facilement être liée à la détection d’hallucinations. La plupart des outils …},
	journal = {10 ème Conférence …},
	author = {Bouvard, C. and Ciancone, M. and Gourru, A. and {...}},
	year = {2024},
	note = {Publisher: hal.science},
	annote = {5 cites: https://scholar.google.com/scholar?cites=9214449809168603245\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xu_context-aware_2023,
	title = {Context-aware decoding reduces hallucination in query-focused summarization},
	url = {https://arxiv.org/abs/2312.14335},
	abstract = {… However, applying large language models (LLM) potentially leads to hallucinations, especially … In retrieval augmented generation, we mainly focus on intrinsic hallucination. Pre-trained …},
	journal = {arXiv preprint arXiv:2312.14335},
	author = {Xu, Z.},
	year = {2023},
	note = {Publisher: arxiv.org},
	annote = {16 cites: https://scholar.google.com/scholar?cites=14794149332658043603\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chung_verifact_2025,
	title = {Verifact: {Verifying} facts in llm-generated clinical text with electronic health records},
	url = {https://arxiv.org/abs/2501.16672},
	abstract = {… factuality of LLM-generated text given the needle-in-a-haystack challenge of identifying subtle errors and hallucinations[… that atomic claims improve information retrieval for RAG[29], but …},
	journal = {arXiv preprint arXiv …},
	author = {Chung, P. and Swaminathan, A. and Goodell, A. J. and Kim, Y. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=14258488608106751960\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lin_novel_2024,
	title = {Novel {Preprocessing} {Technique} for {Data} {Embedding} in {Engineering} {Code} {Generation} {Using} {Large} {Language} {Model}},
	url = {https://ieeexplore.ieee.org/abstract/document/10691715/},
	abstract = {… based on RAG without requiring any kind of pre-training or fine-tuning of the LLM. Our Data … By semantically segmenting text and renovating content with high LLM confidence levels, …},
	journal = {2024 IEEE LLM …},
	author = {Lin, Y. C. and Kumar, A. and Chang, N. and Zhang, W. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=5236529851351430436\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mauliana_exploring_2025,
	title = {Exploring {LLM}-powered multi-session human-robot interactions with university students},
	url = {https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2025.1585589/abstract},
	doi = {10.3389/frobt.2025.1585589},
	abstract = {… Two approaches were used to generate responses: RAG + LLM and LLM functionality. A … factual information. Consequently, we activate the RAG + LLM function; otherwise, the LLM …},
	journal = {Frontiers in Robotics …},
	author = {Mauliana, M. and Ashok, A. and Czernochowski, D. and {...}},
	year = {2025},
	note = {Publisher: frontiersin.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=16086526663674876088\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yang_pseudo-knowledge_2025,
	title = {Pseudo-{Knowledge} {Graph}: {Meta}-{Path} {Guided} {Retrieval} and {In}-{Graph} {Text} for {RAG}-{Equipped} {LLM}},
	url = {https://arxiv.org/abs/2503.00309},
	abstract = {… , RAG enhances factual … LLM-VDB (LLM with Vector Database RAG). In this setup, we enhance the language model’s capabilities by integrating a retrievalaugmented generation (RAG) …},
	journal = {arXiv preprint arXiv …},
	author = {Yang, Y. and Wu, H. and Wang, T. and Yang, J. and Ma, H. and Luo, G.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=18128963869843155572\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_veridebug_2025,
	title = {Veridebug: {A} unified llm for verilog debugging via contrastive embedding and guided correction},
	url = {https://ieeexplore.ieee.org/abstract/document/11106068/},
	abstract = {… to enhance the LLM’s outputs during debugging tasks [5]. However, RAG methods introduce … Figure 5 illustrates hallucination in LLM debugging. Instruction (Figure 5a) shows the actual …},
	journal = {… Conference on LLM …},
	author = {Wang, N. and Yao, B. and Zhou, J. and Hu, Y. and Wang, X. and {...}},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=6580488253048378010\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{baek_crafting_2025,
	title = {Crafting the path: {Robust} query rewriting for information retrieval},
	url = {https://ieeexplore.ieee.org/abstract/document/10870252/},
	abstract = {… generates queries with fewer factual inaccuracies. Furthermore, we … in the retrieval-augmented generation scenarios. … of each LLM, we divide the dataset into problems where each LLM …},
	journal = {IEEE Access},
	author = {Baek, I. and Lee, J. and Yang, J. and Lee, H.},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=14987376558729858867\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{maio_pirates_2024,
	title = {Pirates of the rag: {Adaptively} attacking llms to leak knowledge bases},
	url = {https://arxiv.org/abs/2412.18295},
	abstract = {… Given a pre-trained LLM, we describe a RAG system by an architectures composed of four … dentiality within the system, undermining its trustworthiness and security guarantees not only …},
	journal = {arXiv preprint arXiv …},
	author = {Maio, C. Di and Cosci, C. and Maggini, M. and Poggioni, V. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=6053948175569769564\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lee_evaluating_2024,
	title = {Evaluating consistencies in llm responses through a semantic clustering of question answering},
	url = {https://arxiv.org/abs/2410.15440},
	abstract = {… as context like the RAG pattern or use Zero-shot-CoT to improve performance of LLM itself. We apply … We do not consider model confidence in this study, but plan to do so in future work. …},
	journal = {arXiv preprint arXiv:2410.15440},
	author = {Lee, Y. and Kim, J.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=17953322781686842975\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mensah_all_2024,
	title = {All you need is context: {Clinician} evaluations of various iterations of a large language model-based first aid decision support tool in ghana},
	url = {https://ieeexplore.ieee.org/abstract/document/10628781/},
	doi = {10.1101/2024.04.03.24305276.full},
	abstract = {… LLM framework based on OpenAI's "text-davinci-003" combined with RAG, versus ChatGPT … Almanac's answers as safer and more factual, they still preferred ChatGPT's answers [10]. …},
	journal = {2024 IEEE 12th …},
	author = {Mensah, P. B. and Quao, N. S. and Dagadu, S. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=15733469312634759490\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{duan_research_2025,
	title = {Research on a traditional {Chinese} medicine case-based question-answering system integrating large language models and knowledge graphs},
	url = {https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2024.1512329/full},
	doi = {10.3389/fmed.2024.1512329},
	abstract = {… factual statements by utilizing the knowledge stored in KGs. This method directly addresses the hallucination … with LLM and knowledge graphs, and a LLM without RAG technology. The …},
	journal = {Frontiers in …},
	author = {Duan, Y. and Zhou, Q. and Li, Y. and Qin, C. and Wang, Z. and Kan, H. and {...}},
	year = {2025},
	note = {Publisher: frontiersin.org},
	annote = {19 cites: https://scholar.google.com/scholar?cites=18099675217765363447\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhao_embodied_2024,
	title = {Embodied {AI}-guided interactive digital teachers for education},
	url = {https://dl.acm.org/doi/abs/10.1145/3680533.3697070},
	doi = {10.1145/3680533.3697070},
	abstract = {… answers without hallucination, we employ a novel retrieval-augmented generation (RAG) … We design a novel hybrid RAG paradigm to enhance the LLM’s ability to provide more …},
	journal = {SIGGRAPH Asia 2024 Educator's Forum},
	author = {Zhao, Z. and Yin, Z. and Sun, J. and Hui, P.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=10259100566682810873\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{antal_evaluating_2025,
	title = {Evaluating {Open}-{Source} {LLMs} in {RAG} {Systems}: {A} {Benchmark} on {Diploma} {Theses} {Abstracts} {Using} {Ragas}: {M}. {Antal}, {K}. {Buza}},
	url = {https://link.springer.com/article/10.1007/s44427-025-00006-3},
	doi = {10.1007/s44427-025-00006-3},
	abstract = {… Retrieval Augmented Generation (RAG) systems have emerged as a powerful paradigm for enhancing Large Language Model (LLM) … It supports the evaluation of hallucinations, …},
	journal = {Acta Universitatis Sapientiae, Informatica},
	author = {Antal, M. and Buza, K.},
	year = {2025},
	note = {Publisher: Springer
Type: HTML},
	annote = {2 cites: https://scholar.google.com/scholar?cites=15342779653536420084\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{nouzri_beyond_2024,
	title = {Beyond {Chatbots}: {Enhancing} {Luxembourgish} {Language} {Learning} {Through} {Multi}-agent {Systems} and {Large} {Language} {Model}},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-77367-9_29},
	doi = {10.1007/978-3-031-77367-9_29},
	abstract = {… To address the issue of model hallucination, we are developing a RAG architecture for this … We will systematically present our methodology for constructing knowledge bases using RAG …},
	journal = {… on Principles and …},
	author = {Nouzri, S. and Fatimi, M. EL and Guerin, T. and Othmane, M. and {...}},
	year = {2024},
	note = {Publisher: Springer},
	annote = {5 cites: https://scholar.google.com/scholar?cites=3271837004383987077\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chang_conversational_2024,
	title = {Conversational product recommendation using {LLM}},
	url = {https://ieeexplore.ieee.org/abstract/document/10602608/},
	abstract = {… Retrieval augmented generation (RAG) is expected to serve … key for LLM to avoid hallucinations, provide credible information, … In this study, we used LLM as a user and sales …},
	journal = {… Internet of Things and Big Data …},
	author = {Chang, T. J. and Lin, L. H. M. and Tsai, R. T. H.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=1944017020741454283\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_empirical_2025,
	title = {An empirical study on challenges for llm application developers},
	url = {https://dl.acm.org/doi/abs/10.1145/3715007},
	doi = {10.1145/3715007},
	abstract = {… issues where RAG fails to improve output quality76 or cause hallucinations after processing… Despite their potential to enhance LLM outputs, advanced techniques like CoT and RAG …},
	journal = {ACM Transactions on …},
	author = {Chen, X. and Gao, C. and Chen, C. and Zhang, G. and Liu, Y.},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {29 cites: https://scholar.google.com/scholar?cites=14745587841390118609\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mamalis_can_2023,
	title = {Can large language models revolutionalize open government data portals? a case of using chatgpt in statistics. gov. scot},
	url = {https://dl.acm.org/doi/abs/10.1145/3635059.3635068},
	doi = {10.1145/3635059.3635068},
	abstract = {… only is it possible to augment the large language model’s factuality of responses, but also … Retrieval Augmented Generation, a system could overcome the LLM’s inability to retain factual …},
	journal = {Proceedings of the 27th …},
	author = {Mamalis, M. E. and Kalampokis, E. and Karamanou, A. and {...}},
	year = {2023},
	note = {Publisher: dl.acm.org},
	annote = {19 cites: https://scholar.google.com/scholar?cites=15493545666085423536\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wan_aviationllm_2025,
	title = {{AviationLLM}: {An} {LLM}-based {Knowledge} {System} for {Aviation} {Training}},
	url = {https://arxiv.org/abs/2506.14336},
	abstract = {… LLM Qwen and adapt it to aviation theory training through DPO-based domain alignment. Simultaneously, to mitigate hallucinations … RAG to develop an aviation training-oriented LLM. …},
	journal = {arXiv preprint arXiv …},
	author = {Wan, J. and Shen, F. and Li, F. and Sun, Y. and Li, Y. and Zhang, S.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wu_lighter_2025,
	title = {Lighter and better: {Towards} flexible context adaptation for retrieval augmented generation},
	url = {https://dl.acm.org/doi/abs/10.1145/3701551.3703580},
	doi = {10.1145/3701551.3703580},
	abstract = {… As no modification is made to the LLM’s original parameters, we can optimize the performance in RAG … relevant knowledge, RAG significantly enhances the truthfulness and credibility of …},
	journal = {Proceedings of the …},
	author = {Wu, C. and Shao, N. and Liu, Z. and Xiao, S. and Li, C. and Zhang, C. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=16728768618453401417\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sezgin_decoypot_2025,
	title = {{DecoyPot}: {A} large language model-driven web {API} honeypot for realistic attacker engagement},
	url = {https://www.sciencedirect.com/science/article/pii/S0167404825001476},
	abstract = {… requests to create prompt-response pairs that improve a Retrieval-Augmented Generation based (RAG) large language model (LLM). DecoyPot can instantly adjust its answers to mimic …},
	journal = {Computers \&Security},
	author = {Sezgin, A. and Boyacı, A.},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {6 cites: https://scholar.google.com/scholar?cites=8254852855301070005\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{maes_fixing_2024,
	title = {Fixing {Reference} {Hallucinations} of {LLMs}},
	publisher = {OSF},
	author = {Maes, S. H.},
	year = {2024},
	note = {Type: CITATION},
	annote = {4 cites: https://scholar.google.com/scholar?cites=1591470420343954442\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hashemi_llm-rubric_2024,
	title = {{LLM}-rubric: {A} multidimensional, calibrated approach to automated evaluation of natural language texts},
	url = {https://arxiv.org/abs/2501.00274},
	abstract = {… But can LLM evaluation be trusted? It solves the time, scaling, and … LLM but by a real human. The assistant in these three systems may be summarized as “no RAG” (DS1), “oracle RAG …},
	journal = {arXiv preprint arXiv …},
	author = {Hashemi, H. and Eisner, J. and Rosset, C. and Durme, B. Van and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {59 cites: https://scholar.google.com/scholar?cites=9070214546251138741\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gajjar_oran-bench-13k_2025,
	title = {Oran-bench-13k: {An} open source benchmark for assessing llms in open radio access networks},
	url = {https://ieeexplore.ieee.org/abstract/document/10975994/},
	abstract = {… Our findings indicate that current popular LLM models are not … We also propose a RAG-based pipeline named ORANSight … Fung, “Towards mitigating llm hallucination via self reflection,…},
	journal = {2025 IEEE 22nd Consumer …},
	author = {Gajjar, P. and Shah, V. K.},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {19 cites: https://scholar.google.com/scholar?cites=6047472275583988812\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{aratchige_llms_2025,
	title = {Llms working in harmony: {A} survey on the technological aspects of building effective llm-based multi agent systems},
	url = {https://arxiv.org/abs/2504.01963},
	abstract = {… To tackle the issue of LLM hallucinations, the authors implement a code… RAG’s impact goes beyond immediate performance gains; it laid the groundwork for future developments in LLM …},
	journal = {arXiv preprint arXiv:2504.01963},
	author = {Aratchige, R. M. and Ilmini, W.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {11 cites: https://scholar.google.com/scholar?cites=8582832746674589423\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yu_textual_2024,
	title = {Textual {Differential} {Privacy} for {Context}-{Aware} {Reasoning} with {Large} {Language} {Model}},
	url = {https://ieeexplore.ieee.org/abstract/document/10633584/},
	abstract = {… Implementation of RAG within LLM-based question answering systems offers dual … made by the model, thereby engendering trust in its outputs. RAG elevates the proficiency of LLMs in …},
	journal = {2024 IEEE 48th Annual …},
	author = {Yu, J. and Zhou, J. and Ding, Y. and Zhang, L. and Guo, Y. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=9165721665826103115\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_identifying_2024,
	title = {Identifying performance-sensitive configurations in software systems through code analysis with llm agents},
	url = {https://arxiv.org/abs/2406.12806},
	abstract = {… and that copies bear this notice and the full citation on the first page. Copyrights for components of … on large language models (LLM) agents and retrieval-augmented generation (RAG). …},
	journal = {arXiv preprint arXiv:2406.12806},
	author = {Wang, Z. and Kim, D. J. and Chen, T. H.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=3087553114886959405\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{fortuna_natural_2024,
	title = {Natural {Language} {Interaction} with a {Household} {Electricity} {Knowledge}-based {Digital} {Twin}},
	url = {https://ieeexplore.ieee.org/abstract/document/10738062/},
	abstract = {… manner while avoiding LLM hallucinations and deep … LLM responses via RAG using electrical energy data is missing. This paper is the first to assess and report on the potential of RAG-…},
	journal = {2024 IEEE International …},
	author = {Fortuna, C. and Hanžel, V. and Bertalanič, B.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=2916316979586739640\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{garigliotti_explainable_2023,
	title = {Explainable {LLM}-powered {RAG} {To} {Tackle} {Tasks} {In} {The} {Unstructured}-structured {Data} {Spectrum}},
	url = {https://ceur-ws.org/Vol-3953/368.pdf},
	abstract = {… LLM is also requested to cite the passages that support the correctness of the generated answer, and answer and citation … through the entire RAG assessment while the LLM has access …},
	publisher = {ceur-ws.org},
	author = {Garigliotti, D.},
	year = {2023},
	note = {Type: PDF},
	annote = {1 cites: https://scholar.google.com/scholar?cites=10645002365457007126\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ma_unifying_2025,
	title = {Unifying {Large} {Language} {Models} and {Knowledge} {Graphs} for {Question} {Answering}: {Recent} {Advances} and {Opportunities}.},
	url = {https://www.openproceedings.org/2025/conf/edbt/paper-T4.pdf},
	abstract = {… The Graph RAG enhances the explainability of LLM responses by tracing relevant subgraphs … Mitigating large language model hallucinations via autonomous knowledge graph-based …},
	journal = {EDBT},
	author = {Ma, C. and Chen, Y. and Wu, T. and Khan, A. and Wang, H.},
	year = {2025},
	note = {Publisher: openproceedings.org
Type: PDF},
	annote = {2 cites: https://scholar.google.com/scholar?cites=13059531785754917343\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gong_potential_2024,
	title = {The potential clinical utility of the customized large language model in gastroenterology: {A} pilot study},
	url = {https://www.mdpi.com/2306-5354/12/1/1},
	abstract = {… Conventional GPT-4o is an advanced LLM capable of retrieval-augmented generation (RAG… and reproducibility of LLM outputs is another key regulatory requirement to foster trust and …},
	journal = {Bioengineering},
	author = {Gong, E. J. and Bang, C. S. and Lee, J. J. and Park, J. and Kim, E. and Kim, S. and {...}},
	year = {2024},
	note = {Publisher: mdpi.com
Type: HTML},
	annote = {5 cites: https://scholar.google.com/scholar?cites=16300397443727148097\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{yang_addrllm_2025,
	title = {{AddrLLM}: {Address} rewriting via large language model on nationwide logistics data},
	url = {https://dl.acm.org/doi/abs/10.1145/3690624.3709425},
	doi = {10.1145/3690624.3709425},
	abstract = {… based on retrieval augmented large language model. We build a RAG framework specifically for … Not only does RAG help in improving the factual accuracy of answers, but it also allows …},
	journal = {Proceedings of the 31st …},
	author = {Yang, Q. and Hong, Z. and Cao, D. and Wang, H. and Xie, Z. and He, T. and {...}},
	year = {2025},
	note = {Publisher: dl.acm.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=10545920283812527962\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{restrepo_multi-ophthalingua_2025,
	title = {Multi-{OphthaLingua}: {A} {Multilingual} {Benchmark} for {Assessing} and {Debiasing} {LLM} {Ophthalmological} {QA} in {LMICs}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/35053},
	abstract = {… ities in LLM performance for ophthalmology, we present … We curated a diverse set of RAG corpora from three distinct sources… Full details of our RAG sources can be found in Table 4. We …},
	journal = {Proceedings of the …},
	author = {Restrepo, D. and Wu, C. and Tang, Z. and Shuai, Z. and {...}},
	year = {2025},
	note = {Publisher: ojs.aaai.org},
	annote = {13 cites: https://scholar.google.com/scholar?cites=10193917702599239920\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{fatouros_marketsenseai_2025,
	title = {Marketsenseai 2.0: {Enhancing} stock analysis through llm agents},
	url = {https://arxiv.org/abs/2502.00415},
	abstract = {… combining Retrieval-Augmented Generation and LLM agents… This work marks a significant advancement in applying LLM … lengthy documents, mitigating hallucination risks, and …},
	journal = {arXiv preprint arXiv …},
	author = {Fatouros, G. and Metaxas, K. and Soldatos, J. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {13 cites: https://scholar.google.com/scholar?cites=9423858950778319063\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_arl2_2024,
	title = {Arl2: {Aligning} retrievers for black-box large language models via self-guided adaptive relevance labeling},
	url = {https://arxiv.org/abs/2402.13542},
	abstract = {… RAG has shown promising results in improving LLM re- … more effectively to LLM because it’s trained on LLM-labeled … in middle, LLM can still obtain some external factual information …},
	journal = {arXiv preprint arXiv:2402.13542},
	author = {Zhang, L. and Yu, Y. and Wang, K. and Zhang, C.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {20 cites: https://scholar.google.com/scholar?cites=9268838720588163838\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mansurova_development_2023,
	title = {Development of a question answering chatbot for blockchain domain},
	url = {https://sj.astanait.edu.kz/wp-content/uploads/2023/11/Journal_AITU_15vol_sept23-%D0%B2%D0%B5%D1%80%D1%81%D0%B8%D1%8F-4-27-40.pdf},
	abstract = {… of simplified reports created using ChatGPT was mostly accurate. … They do, however, tend to generate hallucinations. Therefore… Retrieval-augmented generation (RAG) is a technique in …},
	journal = {Scientific Journal of …},
	author = {Mansurova, A. and Nugumanova, A. and {...}},
	year = {2023},
	note = {Publisher: sj.astanait.edu.kz
Type: PDF},
	annote = {21 cites: https://scholar.google.com/scholar?cites=7769166705131119265\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{blanchard_making_2025,
	title = {Making {Generative} {AI} {Hallucinations} {Useful} by {Reassessing} the {Troublemaker} {Agent} {Strategy}},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-99264-3_36},
	doi = {10.1007/978-3-031-99264-3_36},
	abstract = {… To evaluate RH2, we chose ChatGPT-4o as our reference LLM, as it was able to … RAG configurations for our evaluation, which results in 3 generation conditions: ChatGPT, RAG …},
	journal = {… Conference on Artificial …},
	author = {Blanchard, E. G. and Callahan, J. C. and Akretche, I. and {...}},
	year = {2025},
	note = {Publisher: Springer},
	annote = {3 cites: https://scholar.google.com/scholar?cites=12523406076162582861\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kermani_systematic_2025,
	title = {A {Systematic} {Evaluation} of {LLM} {Strategies} for {Mental} {Health} {Text} {Analysis}: {Fine}-tuning vs. {Prompt} {Engineering} vs. {RAG}},
	url = {https://arxiv.org/abs/2503.24307},
	abstract = {… RAG can operate with much fewer training examples than is usually required to fine-tune an LLM model on a specific task, we consider RAG … We implement a RAG model that …},
	journal = {arXiv preprint arXiv:2503.24307},
	author = {Kermani, A. and Perez-Rosas, V. and Metsis, V.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=7449926822953454853\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{dong_survey_2024,
	title = {A survey of llm-based agents: {Theories}, technologies, applications and suggestions},
	url = {https://ieeexplore.ieee.org/abstract/document/10748304/},
	abstract = {… With the scheme, RAG has demonstrated impressive strength for knowledge retrieval and … , LLM-based agents ought to invoke the planning reflection to handle hallucination and “…},
	journal = {2024 3rd International …},
	author = {Dong, X. and Zhang, X. and Bu, W. and Zhang, D. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {14 cites: https://scholar.google.com/scholar?cites=14546474376125080307\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{abedu_llm-based_2024,
	title = {Llm-based chatbots for mining software repositories: {Challenges} and opportunities},
	url = {https://dl.acm.org/doi/abs/10.1145/3661167.3661218},
	doi = {10.1145/3661167.3661218},
	abstract = {… To prevent the LLM from hallucinating, we instructed it to respond with “I don’t … LLM in answering questions related to software repositories. Therefore, we build a chatbot using the RAG …},
	journal = {… of the 28th International Conference on …},
	author = {Abedu, S. and Abdellatif, A. and Shihab, E.},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {22 cites: https://scholar.google.com/scholar?cites=8475280004805750202\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{goyal_healai_2024,
	title = {Healai: {A} healthcare llm for effective medical documentation},
	url = {https://dl.acm.org/doi/abs/10.1145/3616855.3635739},
	doi = {10.1145/3616855.3635739},
	abstract = {… notice and the full citation on the first page. … Retrieval Augmented Generation (RAG) [1] [5] - solving our large context problem and which has shown to perform better than using raw LLM …},
	journal = {Proceedings of the 17th …},
	author = {Goyal, S. and Rastogi, E. and Rajagopal, S. P. and Yuan, D. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {80 cites: https://scholar.google.com/scholar?cites=12445702246558870287\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kortukov_studying_2024-1,
	title = {Studying large language model behaviors under realistic knowledge conflicts},
	url = {https://openreview.net/forum?id=N0VeagzHq1},
	abstract = {… : Retrieval-augmented generation (RAG) mitigates many problems of fully parametric language models, such as temporal degradation, hallucinations, and lack of grounding. In RAG, …},
	journal = {CoRR},
	author = {Kortukov, E. and Rubinstein, A. and Nguyen, E. and Oh, S. J.},
	year = {2024},
	note = {Publisher: openreview.net},
	annote = {7 cites: https://scholar.google.com/scholar?cites=4243586992244962675\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wan_what_2024,
	title = {What evidence do language models find convincing?},
	url = {https://arxiv.org/abs/2402.11782},
	abstract = {… We use this dataset to perform sensitivity and counterfactual analyses to explore which text … production RAG models work. However, we could have instead just directly asked the LLM, “…},
	journal = {arXiv preprint arXiv:2402.11782},
	author = {Wan, A. and Wallace, E. and Klein, D.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {42 cites: https://scholar.google.com/scholar?cites=4559243449149521145\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wu_thinking_2024,
	title = {Thinking with knowledge graphs: {Enhancing} {LLM} reasoning through structured data},
	url = {https://arxiv.org/abs/2412.10654},
	abstract = {… These summaries are subsequently used by the LLM via RAG to help answer questions … relationships helps improve LLM multi-hop reasoning ability and reduce hallucination. The …},
	journal = {arXiv preprint arXiv:2412.10654},
	author = {Wu, X. and Tsioutsiouliklis, K.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=3691954758092470588\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_large_2025,
	title = {Large language model as a catalyst: {A} paradigm shift in base station siting optimization},
	url = {https://ieeexplore.ieee.org/abstract/document/10915543/},
	abstract = {… , our framework integrates retrieval-augmented generation (RAG), … to explore the use of LLM and RAG to solve the BSS problem… LLM interaction can mitigate the impact of hallucinations, …},
	journal = {IEEE Transactions …},
	author = {Wang, Y. and Afzal, M. M. and Li, Z. and Zhou, J. and Feng, C. and {...}},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {8 cites: https://scholar.google.com/scholar?cites=3560126677379336093\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{singh_stop_2024,
	title = {Stop {Hallucinations} with {RAG}},
	url = {https://link.springer.com/chapter/10.1007/979-8-8688-0569-1_5},
	doi = {10.1007/979-8-8688-0569-1_5},
	abstract = {… build your fundamentals about RAG, which lets you customize the LLM as per your need … LLM-based applications. You will also learn in detail about the three components of RAG and …},
	journal = {Building Applications with Large Language Models …},
	author = {Singh, B.},
	year = {2024},
	note = {Publisher: Springer},
	annote = {1 cites: https://scholar.google.com/scholar?cites=2759019455989700455\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_leverage_2024,
	title = {Leverage knowledge graph and large language model for law article recommendation: {A} case study of chinese criminal law},
	url = {https://arxiv.org/abs/2410.04949},
	abstract = {… TFIDF-RAG, LightRAG, Graph-RAG method. This indicates that the proposed approach effectively mitigates the hallucinations in LLMs. We believe this is because other RAG method …},
	journal = {arXiv preprint arXiv …},
	author = {Chen, Y. and Chen, M. and Zhu, Y. and Pei, J. and Chen, S. and Zhou, Y. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=16549767970889786588\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hsu_addressing_2024,
	title = {Addressing {LLM} {Challenges}: {A} {Hybrid} {Framework} for {Duplicate} {Question} {Detection}},
	url = {https://ieeexplore.ieee.org/abstract/document/10900148/},
	abstract = {… LLM hallucinations and outdated information have highlighted the continued importance of information retrieval techniques. The integration of retrievalaugmented generation (RAG… RAG …},
	journal = {2024 4th International Conference on …},
	author = {Hsu, H. H. and Huang, N. F.},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{sheng_talk2traffic_2025,
	title = {Talk2traffic: {Interactive} and editable traffic scenario generation for autonomous driving with multimodal large language model},
	url = {https://openaccess.thecvf.com/content/CVPR2025W/WDFM-AD/html/Sheng_Talk2Traffic_Interactive_and_Editable_Traffic_Scenario_Generation_for_Autonomous_Driving_CVPRW_2025_paper.html},
	abstract = {… a retrieval-augmented generation (RAG) approach that grounds MLLMs’ outputs in verified code snippets, effectively reducing hallucinations … that reduces hallucinations and ensures …},
	journal = {Proceedings of the …},
	author = {Sheng, Z. and Huang, Z. and Qu, Y. and Leng, Y. and {...}},
	year = {2025},
	note = {Publisher: openaccess.thecvf.com},
	annote = {1 cites: https://scholar.google.com/scholar?cites=8409829718378654064\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{deventer_interests_2024,
	title = {From {Interests} to {Insights}: {An} {LLM} {Approach} to {Course} {Recommendations} {Using} {Natural} {Language} {Queries}},
	url = {https://arxiv.org/abs/2412.19312},
	abstract = {… We introduce a two-stage retrieval process for a RAG-based LLM course recommender … with both an explanation and a confidence rating. We show that the LLM’s embedding space …},
	journal = {arXiv preprint arXiv:2412.19312},
	author = {Deventer, H. Van and Mills, M. and Evrard, A.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=10466074081775540291\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{fernandez_syllabusqa_2024,
	title = {{SyllabusQA}: {A} course logistics question answering dataset},
	url = {https://arxiv.org/abs/2403.14666},
	abstract = {… Factuality Metrics We design a novel LLMbased (GPT-4) evaluation … RAG provides a significant boost in LLM performance. In the zero-shot setting, LLaMA-2-70B combined with RAG …},
	journal = {arXiv preprint arXiv:2403.14666},
	author = {Fernandez, N. and Scarlatos, A. and Lan, A.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=15707700657783546486\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kommineni_human_2024,
	title = {From human experts to machines: {An} {LLM} supported approach to ontology and knowledge graph construction},
	url = {https://arxiv.org/abs/2403.08345},
	abstract = {… Retrieval-Augmented-Generation (RAG) as well as the KG concepts automatically extracted using LLMs, we design a judge LLM, … studies, a prerequisite to trust and validation of results. …},
	journal = {arXiv preprint arXiv:2403.08345},
	author = {Kommineni, V. K. and König-Ries, B. and Samuel, S.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {118 cites: https://scholar.google.com/scholar?cites=15190279717137021285\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{goodell_large_2025,
	title = {Large language model agents can use tools to perform clinical calculations},
	url = {https://www.nature.com/articles/s41746-025-01475-8},
	abstract = {… questions in medicine but are prone to hallucinations and arithmetic errors. Early evidence suggests … To assess the incremental value of each additional tool (code interpreter, RAG, and …},
	journal = {npj Digital Medicine},
	author = {Goodell, A. J. and Chu, S. N. and Rouholiman, D. and Chu, L. F.},
	year = {2025},
	note = {Publisher: nature.com
Type: HTML},
	annote = {15 cites: https://scholar.google.com/scholar?cites=14517652808608566307\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zhang_rag4itops_2024,
	title = {{RAG4ITOps}: {A} supervised fine-tunable and comprehensive {RAG} framework for {IT} operations and maintenance},
	url = {https://arxiv.org/abs/2410.15805},
	abstract = {… LLM to utilize relevant and latest background knowledge, and it enables the LLM to generate factual … In addition to using RAG to enhance the LLM’s understanding of documents, we …},
	journal = {arXiv preprint arXiv …},
	author = {Zhang, T. and Jiang, Z. and Bai, S. and Zhang, T. and Lin, L. and Liu, Y. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=11274013698757647102\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_commercial_2025,
	title = {Commercial llm agents are already vulnerable to simple yet dangerous attacks},
	url = {https://arxiv.org/abs/2502.08586},
	abstract = {… agents may make decisions based on falsified information provided by previously trusted … vulnerabilities in LLM agents, especially in memory and retrieval-augmented generation (RAG)…},
	journal = {arXiv preprint arXiv …},
	author = {Li, A. and Zhou, Y. and Raghuram, V. C. and Goldstein, T. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {23 cites: https://scholar.google.com/scholar?cites=10391305435070620916\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{xiao_network_2025,
	title = {Network for knowledge {Organization} ({NEKO}): {An} {AI} knowledge mining workflow for synthetic biology research},
	url = {https://www.sciencedirect.com/science/article/pii/S1096717624001484},
	abstract = {… pipeline to store and distillate factual knowledge. Knowledge graphs have emerged as a … an example LLM in this study due to its exceptional Retrieval Augmented Generation (RAG) …},
	journal = {Metabolic Engineering},
	author = {Xiao, Z. and Pakrasi, H. B. and Chen, Y. and Tang, Y. J.},
	year = {2025},
	note = {Publisher: Elsevier
Type: HTML},
	annote = {9 cites: https://scholar.google.com/scholar?cites=14336639007218617186\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_llm_2024-1,
	title = {Llm inference serving: {Survey} of recent advances and opportunities},
	url = {https://ieeexplore.ieee.org/abstract/document/10938426/},
	abstract = {… LLM serving include retrieval-augmented generation (RAG) and mixtureof-experts (MoE) inference. RAG … tendency to generate inaccurate or fabricated information (hallucinations) [45]. …},
	journal = {2024 IEEE High …},
	author = {Li, B. and Jiang, Y. and Gadepally, V. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {55 cites: https://scholar.google.com/scholar?cites=13003764236938561095\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{paul_llm-assisted_2025,
	title = {{LLM}-{Assisted} {Proactive} {Threat} {Intelligence} for {Automated} {Reasoning}},
	url = {https://arxiv.org/abs/2504.00428},
	abstract = {… reduces hallucinations and enhances factual accuracy [5], [41]. Additionally, RAG allows … This review of the literature evaluates the leading technologies in LLM and RAG techniques …},
	journal = {arXiv preprint arXiv:2504.00428},
	author = {Paul, S. and Alemi, F. and Macwan, R.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=3320081937179699187\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jain_mitigating_2025,
	title = {On mitigating code {LLM} hallucinations with {API} documentation},
	url = {https://ieeexplore.ieee.org/abstract/document/11121691/},
	abstract = {… Hence, to address API hallucinations, we adopt retrieval augmented generation with documentation, ie, Documentation Augmented Generation (DAG), which has shown early promise […},
	journal = {2025 IEEE/ACM 47th …},
	author = {Jain, N. and Kwiatkowski, R. and Ray, B. and {...}},
	year = {2025},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=14024326980949805334\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{fu_spell_2025,
	title = {{SpeLL}: {An} {Agent} for {Natural} {Language}-{Driven} {Intelligent} {Spectral} {Modeling}},
	url = {https://pubs.acs.org/doi/abs/10.1021/acs.jcim.5c01236},
	doi = {10.1021/acs.jcim.5c01236},
	abstract = {… their potential for “hallucination,” retrieval-augmented generation (RAG) technology offers an … recent advancements in LLMs and RAG technology, we developed Spectrum LLM (SpeLL), …},
	journal = {Journal of Chemical Information …},
	author = {Fu, J. and Liu, X. and Cai, W. and Fu, H. and Shao, X.},
	year = {2025},
	note = {Publisher: ACS Publications},
	annote = {1 cites: https://scholar.google.com/scholar?cites=10082954720937730274\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lin_flame_2024,
	title = {Flame: {Factuality}-aware alignment for large language models},
	url = {https://proceedings.neurips.cc/paper_files/paper/2024/hash/d16152d53088ad779ffa634e7bf66166-Abstract-Conference.html},
	abstract = {… the LLM alignment process more factual, by first identifying factors that lead to hallucination in … This is likely because the supervision from RAG contains information unknown to the LLM; …},
	journal = {Advances in Neural …},
	author = {Lin, S. C. and Gao, L. and Oguz, B. and Xiong, W. and {...}},
	year = {2024},
	note = {Publisher: proceedings.neurips.cc},
	annote = {51 cites: https://scholar.google.com/scholar?cites=14797496204644076539\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gu_survey_2024,
	title = {A survey on llm-as-a-judge},
	url = {https://arxiv.org/abs/2411.15594},
	abstract = {… survey of LLM-as-a-Judge, addressing the core question: How can reliable LLM-as-a-Judge … Additionally, we propose methodologies for evaluating the reliability of LLM-as-a-Judge …},
	journal = {arXiv preprint arXiv …},
	author = {Gu, J. and Jiang, X. and Shi, Z. and Tan, H. and Zhai, X. and Xu, C. and Li, W. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {682 cites: https://scholar.google.com/scholar?cites=6262087471931650262\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wen_interactivesurvey_2025,
	title = {Interactivesurvey: {An} llm-based personalized and interactive survey paper generation system},
	url = {https://arxiv.org/abs/2504.08762},
	abstract = {… Citation Generation To facilitate researchers’ reading experience, we also generate citations in … Categorization also includes the time for LLM-based RAG, we anticipate that with more …},
	journal = {arXiv preprint arXiv …},
	author = {Wen, Z. and Cao, J. and Wang, Z. and Guo, B. and Yang, R. and Liu, S.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=10350401383690961573\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{barnett_fine-tuning_2024,
	title = {Fine-tuning or fine-failing? debunking performance myths in large language models},
	url = {https://arxiv.org/abs/2406.11201},
	abstract = {… integration allows RAG systems to enhance LLM responses by leveraging domain-specific … , demonstrated a significant reduction in hallucination compared to other generalised LLMs …},
	journal = {arXiv preprint arXiv …},
	author = {Barnett, S. and Brannelly, Z. and Kurniawan, S. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {14 cites: https://scholar.google.com/scholar?cites=142368437276204417\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{liu_secure_2025,
	title = {Secure multi-llm agentic ai and agentification for edge general intelligence by zero-trust: {A} survey},
	url = {https://arxiv.org/abs/2508.19870},
	abstract = {… [93] presented ControlNet, an AI firewall specifically designed for Retrieval-Augmented Generation (RAG)-based LLM systems. Leveraging neuron activation shift phenomena, …},
	journal = {arXiv preprint arXiv …},
	author = {Liu, Y. and Zhang, R. and Luo, H. and Lin, Y. and Sun, G. and Niyato, D. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=5781896119950920734\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{guo_malgta_2025,
	title = {Malgta: large language model-based guided malware tactical analysis: {W}. {Guo} et al.},
	url = {https://link.springer.com/article/10.1007/s11227-025-07545-8},
	doi = {10.1007/s11227-025-07545-8},
	abstract = {… experiments using the open-source LLM phi3-14B. Additionally, we investigate the effectiveness of RAG in mitigating hallucinations by exploring how integrating multiple corpora …},
	journal = {The Journal of Supercomputing},
	author = {Guo, W. and Xue, J. and Liu, Z. and Han, W. and Hu, J.},
	year = {2025},
	note = {Publisher: Springer},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{meyer_comparison_2024,
	title = {A {Comparison} of {LLM} {Finetuning} {Methods} \&{Evaluation} {Metrics} with {Travel} {Chatbot} {Use} {Case}},
	url = {https://arxiv.org/abs/2408.03562},
	abstract = {… [9] RAG is a text generation method for outsourcing relevant information, from a knowledge … , factual and quality information, to supply an LLM with contextual clues for producing factual …},
	journal = {arXiv preprint arXiv:2408.03562},
	author = {Meyer, S. and Singh, S. and Tam, B. and Ton, C. and Ren, A.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {11 cites: https://scholar.google.com/scholar?cites=18360714897547536379\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{neumann_llm-driven_2024,
	title = {An llm-driven chatbot in higher education for databases and information systems},
	url = {https://ieeexplore.ieee.org/abstract/document/10706931/},
	abstract = {… “hallucinations,” where it produces incorrect content [47], [48], [49], [50]. The presented solution in this article adopts an retrieval-augmented generation (RAG… utilizing an RAG approach […},
	journal = {IEEE Transactions on …},
	author = {Neumann, A. T. and Yin, Y. and Sowe, S. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {76 cites: https://scholar.google.com/scholar?cites=16324176200624998188\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ardimento_rag-based_2024,
	title = {A {RAG}-based {Feedback} {Tool} to {Augment} {UML} {Class} {Diagram} {Learning}},
	url = {https://dl.acm.org/doi/abs/10.1145/3652620.3687784},
	doi = {10.1145/3652620.3687784},
	abstract = {… bear this notice and the full citation on the first page. Copyrights … Retrieval Augmented Generation Large Language Model (RAG-based LLM), also referred to more simply as RAG-LLM…},
	journal = {Proceedings of the ACM …},
	author = {Ardimento, P. and Bernardi, M. L. and Cimitile, M. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {7 cites: https://scholar.google.com/scholar?cites=8921796060434874791\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ang_tsgassist_2024,
	title = {Tsgassist: {An} interactive assistant harnessing llms and rag for time series generation recommendations and benchmarking},
	url = {https://dl.acm.org/doi/abs/10.14778/3685800.3685862},
	doi = {10.14778/3685800.3685862},
	abstract = {… and reducing content hallucinations [9]. In … RAG-enhanced LLM in TSG Recommender to be significantly more effective in terms of relevance and faithfulness than the standalone LLM. …},
	journal = {Proceedings of the VLDB …},
	author = {Ang, Y. and Bao, Y. and Huang, Q. and Tung, A. K. H. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {13 cites: https://scholar.google.com/scholar?cites=762665417141071277\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{wang_scholarcopilot_2025,
	title = {Scholarcopilot: {Training} large language models for academic writing with accurate citations},
	url = {https://arxiv.org/abs/2504.00824},
	abstract = {… Retrieval Augmented Generation In the era of LLM, the Retrieval Augmented Generation (RAG… , improving the generation’s correctness and factuality for downstream tasks, such as …},
	journal = {arXiv preprint arXiv …},
	author = {Wang, Y. and Ma, X. and Nie, P. and Zeng, H. and Lyu, Z. and Zhang, Y. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {6 cites: https://scholar.google.com/scholar?cites=7704660234463949638\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kumari_can_2025,
	title = {Can {LLMs} revolutionize text mining in chemistry? {A} comparative study with domain-specific tools},
	url = {https://www.sciencedirect.com/science/article/pii/S0920548925000261},
	abstract = {… and integrated a Retrieval-Augmented Generation (RAG) pipeline to enhance performance. The results revealed that fine-tuned LLaMA-2 models, particularly those incorporating RAG, …},
	journal = {Computer Standards \&Interfaces},
	author = {Kumari, M. and Chauhan, R. and Garg, P.},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {4 cites: https://scholar.google.com/scholar?cites=9593669623378045718\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{paudel_hallucinot_2025,
	title = {Hallucinot: {Hallucination} detection through context and common knowledge verification},
	url = {https://arxiv.org/abs/2504.07069},
	abstract = {… for detecting hallucinations in large language model (LLM) … taxonomy of LLM responses specific to hallucination in enterprise … to LLM response verification builds on established RAG …},
	journal = {arXiv preprint arXiv:2504.07069},
	author = {Paudel, B. and Lyzhov, A. and Joshi, P. and Anand, P.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {2 cites: https://scholar.google.com/scholar?cites=14442471979837863994\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{nazar_revolutionizing_2024,
	title = {Revolutionizing undergraduate learning: {CourseGPT} and its generative {AI} advancements},
	url = {https://arxiv.org/abs/2407.18310},
	abstract = {… This work evaluates RAG-based-LLM effectiveness as intelligent university course … RAGs overcome outdated knowledge and hallucination by combining the LLM’s intrinsic knowledge …},
	journal = {arXiv preprint arXiv:2407.18310},
	author = {Nazar, A. M. and Selim, M. Y. and Gaffar, A. and Ahmed, S.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=9107585769755295550\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{qian_large_2025,
	title = {Large language model-empowered paradigm for automated geotechnical site planning and geological characterization},
	url = {https://www.sciencedirect.com/science/article/pii/S0926580525001438},
	abstract = {… LLM-based agent named “Geologist” to streamline geotechnical site planning and subsequent geological interpretation. A Multihop-Retrieval-Augmented Generation … the proposed LLM-…},
	journal = {Automation in Construction},
	author = {Qian, Z. and Shi, C.},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {7 cites: https://scholar.google.com/scholar?cites=16756766074868635670\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{pang_reconstruction_2025,
	title = {Reconstruction of landslide events using {LLM}-based {Agentic} {AI} with multimodal data},
	url = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5340542},
	abstract = {… In 100 this study, RAG is applied to extract … agentic LLM that processes witness accounts and 154 outputs a report summarizing technical information related to a landslide, with citations …},
	journal = {Available at SSRN 5340542},
	author = {Pang, H. and Lo, M. K. and Leung, Y. F. and Wu, S.},
	year = {2025},
	note = {Publisher: papers.ssrn.com},
	annote = {1 cites: https://scholar.google.com/scholar?cites=9105324882058925166\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{edge_local_2024,
	title = {From local to global: {A} graph rag approach to query-focused summarization},
	url = {https://arxiv.org/abs/2404.16130},
	abstract = {… Specifically, our approach uses the LLM to infer the potential users would use the RAG … AFaCTA: Assisting the annotation of factual claim detection with reliable LLM annotators. In Ku, L.…},
	journal = {arXiv preprint arXiv …},
	author = {Edge, D. and Trinh, H. and Cheng, N. and Bradley, J. and Chao, A. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {974 cites: https://scholar.google.com/scholar?cites=7114827848288921330\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{liu_adaptive_2025,
	title = {Adaptive {Contextual} {Caching} for {Mobile} {Edge} {Large} {Language} {Model} {Service}},
	url = {https://arxiv.org/abs/2501.09383},
	abstract = {… Biased or skewed training data may cause the LLM to generate hallucinations, ie, … This paper has introduced an ACC framework for mobileedge LLM services, enhancing RAG through …},
	journal = {arXiv preprint arXiv …},
	author = {Liu, G. and Liu, Y. and Wang, J. and Du, H. and Niyato, D. and Kang, J. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {5 cites: https://scholar.google.com/scholar?cites=9518199809448063062\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{garza_privcomp-kg_2024-1,
	title = {Privcomp-kg: {Leveraging} knowledge graph and large language models for privacy policy compliance verification},
	url = {https://arxiv.org/abs/2404.19744},
	abstract = {… In our approach, we have utilized the power of RAG to limit the possibilities of hallucinations … of the retrieved article numbers by the LLM. As RAG is integral to the LLM, we assess the …},
	journal = {arXiv preprint arXiv …},
	author = {Garza, L. and Elluri, L. and Kotal, A. and Piplai, A. and Gupta, D. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=16899971013747504163\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{ying_beyond_2025,
	title = {Beyond words: evaluating large language models in transportation planning},
	url = {https://www.tandfonline.com/doi/abs/10.1080/10095020.2025.2493073},
	doi = {10.1080/10095020.2025.2493073},
	abstract = {… for fine-tuning and retrieval-augmented generation (RAG) to enhance LLM performance in structured … in workflow structuring and susceptibility to hallucinations limit its practical utility for …},
	journal = {Geo-spatial Information Science},
	author = {Ying, S. and Li, Z. and Yu, M.},
	year = {2025},
	note = {Publisher: Taylor \&Francis},
	annote = {6 cites: https://scholar.google.com/scholar?cites=3785536287847315510\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{beasley_tarragon_2025,
	title = {{TARRAGON}: {Therapeutic} {Target} {Applicability} {Ranking} and {Retrieval}-{Augmented} {Generation} {Over} {Networks}},
	url = {https://www.biorxiv.org/content/10.1101/2025.04.19.649662.abstract},
	doi = {10.1101/2025.04.19.649662.abstract},
	abstract = {… -is from LLM-generation, and any inaccurate claims or citations are the … Retrieval-Augmented Generation (RAG) for Target Feasibility Reports We generated large language model (LLM)…},
	journal = {bioRxiv},
	author = {Beasley, J. M. T. and Schatz, K. and Ding, E. and DeLuca, M. and Zaid, N. A. and {...}},
	year = {2025},
	note = {Publisher: biorxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=10103160374611480175\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lu_multimodal_2024,
	title = {Multimodal large language model driven scenario testing for autonomous vehicles},
	url = {https://arxiv.org/abs/2409.06450},
	abstract = {… but also encourages rational thought with minimal hallucination. For further evidence of the … testing an LLM-driven AV within them. Thirdly, we showcase the effectiveness of RAG module…},
	journal = {arXiv preprint arXiv …},
	author = {Lu, Q. and Wang, X. and Jiang, Y. and Zhao, G. and Ma, M. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {21 cites: https://scholar.google.com/scholar?cites=6819811123099300322\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{mullins_enhancing_2024,
	title = {Enhancing classroom teaching with {LLMs} and {RAG}},
	url = {https://dl.acm.org/doi/abs/10.1145/3686852.3687083},
	doi = {10.1145/3686852.3687083},
	abstract = {… and that copies bear this notice and the full citation on the first page. Copyrights for third-party … the answer correctness of the LLM. We used Llama as our LLM because of its availability. …},
	journal = {Proceedings of the 25th …},
	author = {Mullins, E. and Portillo, A. and Rohena, K. Ruiz and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {10 cites: https://scholar.google.com/scholar?cites=12594161772498139048\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{rachha_incorporating_2024,
	title = {Incorporating {LLM}-based {Interactive} {Learning} {Environments} in {CS} {Education}: {Learning} {Data} {Structures} and {Algorithms} using the {Gurukul} platform},
	url = {https://vtechworks.lib.vt.edu/items/3d08a8cd-effe-4e41-9830-0204637e53da},
	abstract = {… This section leverages the feature of RAG to enhance LLM capabilities to provide accurate and contextually … The reviewers highlighted the reliability of the LLM to counter hallucinations. …},
	publisher = {vtechworks.lib.vt.edu},
	author = {Rachha, A. K.},
	year = {2024},
	annote = {1 cites: https://scholar.google.com/scholar?cites=18158374253595981205\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{kumar_tfhe-coder_2025,
	title = {Tfhe-coder: {Evaluating} llm-agentic fully homomorphic encryption code generation},
	url = {https://arxiv.org/abs/2503.12217},
	abstract = {… generation (RAG) is introduced to provide the LLM with … LLM has access to accurate API definitions and usage examples, reducing errors such as incorrect function calls or hallucinated …},
	journal = {arXiv preprint arXiv:2503.12217},
	author = {Kumar, M. and Xue, J. and Zheng, M. and Lou, Q.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {4 cites: https://scholar.google.com/scholar?cites=7316131829321318196\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{febrian_kemenkeugpt_2024,
	title = {{KemenkeuGPT}: {Leveraging} a {Large} {Language} {Model} on {Indonesia}'s {Government} {Financial} {Data} and {Regulations} to {Enhance} {Decision} {Making}},
	url = {https://arxiv.org/abs/2407.21459},
	abstract = {… LLM … ChatGPT and LLaMA, this approach achieves a 15\% to 48\% performance gain in accuracy and F1 scores [Zhang et al. 2023]. RAG addresses the issue of factual accuracy in LLM …},
	journal = {arXiv preprint arXiv:2407.21459},
	author = {Febrian, G. F. and Figueredo, G.},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=764669969432545296\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{soule_enhancing_2025,
	title = {Enhancing {LLM} {Capability} to {Generate} a {Problem} {Statement} in {Mission} {Engineering} {Using} {RAG}},
	url = {https://digitalcommons.odu.edu/gradresearch_achievementday/2025/engineering/14/},
	abstract = {… in the LLM. This approach minimizes "hallucinations," where LLMs generate plausible but incorrect information by grounding responses in retrieved facts. Additionally, RAG enables AI …},
	publisher = {digitalcommons.odu.edu},
	author = {Soule, R.},
	year = {2025},
	note = {Type: HTML},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cui_bailicai_2025,
	title = {Bailicai: {A} {Domain}-{Optimized} {Retrieval}-{Augmented} {Generation} {Framework} for {Medical} {Applications}},
	url = {https://file.sciopen.com/sciopen_public/1895014766676131841.pdf},
	abstract = {… In addition, the integration of RAG and LLM in the medical field is still in its infancy[25], and … from factual accuracy[15, 16]. Early research on RAG primarily focused on developing …},
	journal = {Big Data Mining and …},
	author = {Cui, L. and Liu, Y. and Ouyang, C. and Yu, Y. and Zhang, J. and {...}},
	year = {2025},
	note = {Publisher: file.sciopen.com
Type: PDF},
	annote = {1 cites: https://scholar.google.com/scholar?cites=8088099220949070141\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zeng_cancer_2025,
	title = {Cancer gene identification through integrating causal prompting large language model with omics data–driven causal inference},
	doi = {10.1093/bib/bbaf113/62386227/bbaf113},
	journal = {Briefings in …},
	author = {Zeng, H. and Yin, C. and Chai, C. and Wang, Y. and Dai, Q. and {...}},
	year = {2025},
	note = {Publisher: Oxford Academic
Type: CITATION},
	annote = {4 cites: https://scholar.google.com/scholar?cites=1894555954830987837\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{luo_agentauditor_2025,
	title = {Agentauditor: {Human}-level safety and security evaluation for llm agents},
	url = {https://arxiv.org/abs/2506.00641},
	abstract = {… aware retrieval-augmented generation process then dynamically retrieves the most relevant reasoning experiences to guide the LLM … of LLM outputs and reducing model hallucinations, …},
	journal = {arXiv preprint arXiv …},
	author = {Luo, H. and Dai, S. and Ni, C. and Li, X. and Zhang, G. and Wang, K. and Liu, T. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {9 cites: https://scholar.google.com/scholar?cites=523652018719672976\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{salminen_using_2024,
	title = {Using {Cipherbot}: an exploratory analysis of student interaction with an {LLM}-based educational chatbot},
	url = {https://dl.acm.org/doi/abs/10.1145/3657604.3664690},
	doi = {10.1145/3657604.3664690},
	abstract = {… hallucination [8] whereupon the LLM “invents” factually incorrect answers. The particular approach Cipherbot applies is retrieval-augmented generation (RAG… for the LLM to generate its …},
	journal = {Proceedings of the …},
	author = {Salminen, J. and Jung, S. and Medina, J. and Aldous, K. and {...}},
	year = {2024},
	note = {Publisher: dl.acm.org},
	annote = {23 cites: https://scholar.google.com/scholar?cites=4658854175036739229\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{cao_multi-agent_2025,
	title = {Multi-{Agent} {LLM} {Judge}: automatic personalized {LLM} judge design for evaluating natural language generation applications},
	url = {https://arxiv.org/abs/2504.02867},
	abstract = {… LLM based applications such as Retrieval Augmented Generation (RAG) systems, several … answer and the factual similarity based on arguments measured by LLM judge to arrive at the …},
	journal = {arXiv preprint arXiv:2504.02867},
	author = {Cao, H. and Driouich, I. and Singh, R. and Thomas, E.},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {3 cites: https://scholar.google.com/scholar?cites=1440084718709141719\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{hyk_queries_2025,
	title = {From queries to criteria: {Understanding} how astronomers evaluate {LLMs}},
	url = {https://arxiv.org/abs/2507.15715},
	abstract = {… : an LLM-powered retrieval-augmented generation bot for … we deploy is a retrieval augmented generation (RAG) LLM: a … passed to an LLM to provide a response with citations to the user…},
	journal = {arXiv preprint arXiv …},
	author = {Hyk, A. and McCormick, K. and Zhong, M. and Ciucă, I. and {...}},
	year = {2025},
	note = {Publisher: arxiv.org},
	annote = {1 cites: https://scholar.google.com/scholar?cites=14221546082987630813\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{chen_meet2mitigate_2025,
	title = {{Meet2Mitigate}: {An} {LLM}-powered framework for real-time issue identification and mitigation from construction meeting discourse},
	url = {https://www.sciencedirect.com/science/article/pii/S1474034624007195},
	abstract = {… (M2M) framework, which integrates cutting-edge technologies, including speaker diarization, automatic speech recognition (ASR), LLMs, and retrieval-augmented generation (RAG) to …},
	journal = {Advanced Engineering …},
	author = {Chen, G. and Alsharef, A. and Ovid, A. and Albert, A. and {...}},
	year = {2025},
	note = {Publisher: Elsevier},
	annote = {12 cites: https://scholar.google.com/scholar?cites=16556331274770837666\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{lin_pe-gpt_2024,
	title = {{PE}-{GPT}: {A} new paradigm for power electronics design},
	url = {https://ieeexplore.ieee.org/abstract/document/10701612/},
	abstract = {… LLM tailored for PE design applications, named PE-GPT. The methodology involves enhancing PE-GPT with retrieval augmented generation … LLM,s hallucination by the PE-tailored RAG…},
	journal = {IEEE Transactions …},
	author = {Lin, F. and Li, X. and Lei, W. and Rodriguez-Andina, J. J. and {...}},
	year = {2024},
	note = {Publisher: ieeexplore.ieee.org},
	annote = {13 cites: https://scholar.google.com/scholar?cites=10572407611927111620\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jiang_efficient_2024,
	title = {Efficient knowledge infusion via {KG}-{LLM} alignment},
	url = {https://arxiv.org/abs/2406.03746},
	abstract = {… -hallucination responses. Firstly, we train a knowledge extraction model based on an LLM using … As for basic 2-shot RAG experiment on ChatGPT-3.5, although there is an improvement …},
	journal = {arXiv preprint arXiv …},
	author = {Jiang, Z. and Zhong, L. and Sun, M. and Xu, J. and Sun, R. and Cai, H. and {...}},
	year = {2024},
	note = {Publisher: arxiv.org},
	annote = {17 cites: https://scholar.google.com/scholar?cites=9707258913750169807\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{rajendran_uppgiftsanpassning_2025,
	title = {Uppgiftsanpassning av {LLM}: er för programvarutillförlitlighet},
	url = {https://www.diva-portal.org/smash/record.jsf?pid=diva2:1969027},
	abstract = {… introduces a hybrid approach that combines LoRA and RAG… patterns efficiently, while RAG injects relevant external knowledge … of LoRA and RAG based on the model's confidence. This …},
	publisher = {diva-portal.org},
	author = {Rajendran, A. Asalatha and Saji, B. Annamma},
	year = {2025},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{zheng_-device_nodate,
	title = {On-{Device} {Hybrid} {LLM}-{RAG} {Agents} for {Adaptive} {Display} {Optimization}},
	url = {https://dqzheng.com/wp-content/uploads/2025/10/SEA_2025-2.pdf},
	abstract = {… The agentric system uses a hybrid LLM-RAG architecture with … we demonstrate 90\% LLM success rate with 10\% RAG fallback, … confidence scores fall below threshold (confidence {\textless}0.7), …},
	journal = {dqzheng.com},
	author = {Zheng, D.},
	note = {Type: PDF},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{gu_radalign_2025,
	title = {Radalign: {Advancing} radiology report generation with vision-language concept alignment},
	url = {https://link.springer.com/chapter/10.1007/978-3-032-04981-0_46},
	doi = {10.1007/978-3-032-04981-0_46},
	abstract = {… Our image-based RAG system addresses this by providing … diagnoses, we enable the LLM to better contextualize the … retrieval-augmented generation, RadAlign enhances factual …},
	journal = {International Conference on …},
	author = {Gu, D. and Gao, Y. and Zhou, Y. and Zhou, M. and Metaxas, D.},
	year = {2025},
	note = {Publisher: Springer},
	annote = {6 cites: https://scholar.google.com/scholar?cites=3428000850146151999\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{jho_leveraging_2024,
	title = {Leveraging generative {AI} in physics education: {Addressing} hallucination issues in large language models},
	url = {https://www.researchgate.net/profile/Hunkoog-Jho/publication/383561189_Leveraging_Generative_AI_in_Physics_Education_Addressing_Hallucination_Issues_in_Large_Language_Models/links/6819b0a0d1054b0207ea3d26/Leveraging-Generative-AI-in-Physics-Education-Addressing-Hallucination-Issues-in-Large-Language-Models.pdf},
	abstract = {… , reasoning, iterative querying, and Retrieval-Augmented Generation (RAG). These methods aim … Comparison of answers about the same question generated by generic LLM and RAG. …},
	journal = {New Phys},
	author = {Jho, H.},
	year = {2024},
	note = {Publisher: researchgate.net
Type: PDF},
	annote = {5 cites: https://scholar.google.com/scholar?cites=9016265747349008761\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{xing_investigating_2025,
	title = {Investigating knowledge graphs as structured external memory to enhance large language models' generation for mathematical concept answering},
	url = {https://osf.io/mx83s_v2/},
	abstract = {… However, the issue of LLM hallucination has been well-documented in the research … RAG is using a knowledge graph (KG). In this paper, we design a method to construct a KG with LLM…},
	publisher = {osf.io},
	author = {Xing, W. and Li, C. and Li, H. and Zhu, W. and Lyu, B. and Yan, Z.},
	year = {2025},
	annote = {2 cites: https://scholar.google.com/scholar?cites=4448315847458677476\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{li_seeing_2024,
	title = {Seeing is believing: {Black}-box membership inference attacks against retrieval augmented generation},
	url = {https://ui.adsabs.harvard.edu/abs/2024arXiv240619234L/abstract},
	abstract = {… to mitigate common LLM issues such as hallucinations and outdated … RAG systems, making them susceptible to attacks like jailbreaks and prompt injections, the security of the RAG …},
	journal = {arXiv e-prints},
	author = {Li, Y. and Liu, G. and Yang, Y. and Wang, C.},
	year = {2024},
	note = {Publisher: ui.adsabs.harvard.edu},
	annote = {15 cites: https://scholar.google.com/scholar?cites=10260174688940924824\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{__2024,
	title = {검색 증강 생성 ({RAG}) 기술의 최신 연구 동향에 대한 조사},
	url = {https://kiss.kstudy.com/Detail/Ar?key=4118382},
	abstract = {… databases, thereby reducing the hallucination phenomenon often seen in LLMs … RAG, reviews recent research trends aimed at enhancing the retrieval capabilities of LLMs through RAG…},
	journal = {정보처리학회 논문지 (KTSDE)},
	author = {{이은빈} and {배호}},
	year = {2024},
	note = {Publisher: kiss.kstudy.com},
	annote = {3 cites: https://scholar.google.com/scholar?cites=7929822992515306547\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{greengard_shining_2025,
	title = {Shining a {Light} on {AI} {Hallucinations}},
	url = {https://dl.acm.org/doi/full/10.1145/3715691},
	abstract = {… example, RAG prompts the LLM to … LLM could check to see who now serves as the governor of a state, or the current price of gasoline, rather than relying on outdated training data. RAG …},
	publisher = {dl.acm.org},
	author = {Greengard, S.},
	year = {2025},
	doi = {10.1145/3715691},
	note = {Type: HTML},
	annote = {3 cites: https://scholar.google.com/scholar?cites=4489504618185424983\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{_rag_2024,
	title = {{RAG} 기반 {LLM} 성능 평가 및 검증을 위한 {LangChain} 활용 {RAGA} 방법론 연구},
	url = {https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE11891076},
	abstract = {… hallucination problems. Therefore, we introduce the framework that can evaluate the performance of RAG methods using the RAG … , answer, and context, LLM answers to queries. Then, …},
	journal = {대한전자공학회 학술 …},
	author = {{정효정} and {송주현} and {서상훈} and {임진효} and {이현상} and {...}},
	year = {2024},
	note = {Publisher: dbpia.co.kr},
	annote = {2 cites: https://scholar.google.com/scholar?cites=12048782958405332918\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@book{lea_reducing_2024,
	title = {Reducing {AI} {RAG} {Hallucination} by {Optimizing} {Routing} {Techniques}},
	url = {https://www.osti.gov/biblio/2474834},
	abstract = {… ) attempts to diminish hallucination by providing context to the LLM from data stores (… The LLM uses this context to formulate its response. RAG systems can still suffer from hallucination …},
	publisher = {osti.gov},
	author = {Lea, D. M. and Cooley, R. S. and Cutshaw, M. A. and Priest, Z. M.},
	year = {2024},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{_llm_2023,
	title = {{LLM} 애플리케이션 아키텍처를 활용한 생성형 {AI} 서비스 구현: {RAG} 모델과 {LangChain} 프레임워크 기반},
	url = {https://www.researchgate.net/profile/Cheonsu-Jeong/publication/376893991_Generative_AI_service_implementation_using_LLM_application_architecture_based_on_RAG_model_and_LangChain_framework/links/658e9c136f6e450f19b310b1/Generative-AI-service-implementation-using-LLM-application-architecture-based-on-RAG-model-and-LangChain-framework.pdf},
	abstract = {… Accordingly, this study presents a method of implementing generative AI services using the LLM application architecture using the most widely used LangChain framework. To this end, …},
	journal = {지능정보연구},
	author = {{정천수}},
	year = {2023},
	note = {Publisher: researchgate.net
Type: PDF},
	annote = {22 cites: https://scholar.google.com/scholar?cites=11219808415324187274\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{_llm_2024,
	title = {{LLM} 과 {RAG} 기반 {BIM} 지식 전문가 에이전트 연구},
	url = {https://scholar.kyobobook.co.kr/article/detail/4010069980447},
	abstract = {… processing, and hallucination problems must be solved. This study proposes an LLM-based … This study focuses on the RAG (Retrieval- Augmented Generation) document generation …},
	journal = {KIBIM Magazine},
	author = {{강태욱} and {박승화}},
	year = {2024},
	note = {Publisher: scholar.kyobobook.co.kr},
	annote = {1 cites: https://scholar.google.com/scholar?cites=3508751681095378707\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{__2023,
	title = {カスタマーサポートにおける {LLM} を用いた {RAG} ベース対話システムの評価と事業活用に向けた取り組み},
	url = {https://www.jstage.jst.go.jp/article/jsaislud/99/0/99_191/_article/-char/ja/},
	abstract = {… , including issues like hallucination, necessitating … an LLM-simulated user interacts with the RAG-based dialogue system, and the resulting dialogue data is evaluated using the LLM. …},
	journal = {人工知能学会研究会資料 言語・音声理解と対話処理研究 …},
	author = {{二宮大空}},
	year = {2023},
	note = {Publisher: jstage.jst.go.jp},
	annote = {1 cites: https://scholar.google.com/scholar?cites=2091738773450386649\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}

@article{_fine-tuning_2024,
	title = {Fine-tuning 과 {RAG} 를 활용한 특정 도메인 챗봇 제작 방법 비교},
	url = {https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE11825516},
	abstract = {… the RAG method … , hallucinations and answer errors occurred frequently, and accuracy and correct response rate were low. On the other hand, the RAG method had fewer hallucinations …},
	journal = {Proceedings of KIIT …},
	author = {{손지원} and {김민성} and {김부건} and {박상준} and {표성민} and {...}},
	year = {2024},
	note = {Publisher: dbpia.co.kr},
	annote = {2 cites: https://scholar.google.com/scholar?cites=13467013935103390078\&as\_sdt=2005\&sciodt=2007\&hl=en},
	annote = {Query date: 2025-10-25 20:50:36},
}
